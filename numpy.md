# NumPy how-tos[#](#numpy-how-tos)
These documents are intended as recipes to common tasks using NumPy. For
detailed reference documentation of the functions and classes contained in
the package, see the [API reference](../reference/index.html#reference).

These documents are intended as recipes to common tasks using NumPy. For
detailed reference documentation of the functions and classes contained in
the package, see the [API reference](../reference/index.html#reference).# NumPy project governance and decision-making[#](#numpy-project-governance-and-decision-making)
The purpose of this document is to formalize the governance process used by the NumPy project in both ordinary and extraordinary situations, and to clarify how decisions are made and how the various elements of our community interact, including the relationship between open source collaborative development and work that may be funded by for-profit or non-profit entities.

## Summary[#](#summary)
NumPy is a community-owned and community-run project. To the maximum extent possible, decisions about project direction are made by community consensus (but note that “consensus” here has a somewhat technical meaning that might not match everyone’s expectations – see below). Some members of the community additionally contribute by serving on the NumPy steering council, where they are responsible for facilitating the establishment of community consensus, for stewarding project resources, and – in extreme cases – for making project decisions if the normal community-based process breaks down.

## The Project[#](#the-project)
The NumPy Project (The Project) is an open source software project
affiliated with the 501(c)3 NumFOCUS Foundation. The goal of The Project
is to develop open source software for array-based computing in Python,
and in particular the `numpy`
package, along with related software
such as `f2py`
and the NumPy Sphinx extensions. The Software developed
by The Project is released under the BSD (or similar) open source
license, developed openly and hosted on public GitHub repositories under
the `numpy`
GitHub organization.

The Project is developed by a team of distributed developers, called Contributors. Contributors are individuals who have contributed code, documentation, designs or other work to the Project. Anyone can be a Contributor. Contributors can be affiliated with any legal entity or none. Contributors participate in the project by submitting, reviewing and discussing GitHub Pull Requests and Issues and participating in open and public Project discussions on GitHub, mailing lists, and other channels. The foundation of Project participation is openness and transparency.

The Project Community consists of all Contributors and Users of the Project. Contributors work on behalf of and are responsible to the larger Project Community and we strive to keep the barrier between Contributors and Users as low as possible.

The Project is formally affiliated with the 501(c)3 NumFOCUS Foundation
([http://numfocus.org](http://numfocus.org)), which serves as its fiscal sponsor, may hold
project trademarks and other intellectual property, helps manage project
donations and acts as a parent legal entity. NumFOCUS is the only legal
entity that has a formal relationship with the project (see
Institutional Partners section below).

## Governance[#](#governance)
This section describes the governance and leadership model of The Project.

The foundations of Project governance are:

Openness & Transparency

Active Contribution

Institutional Neutrality

### Consensus-based decision making by the community[#](#consensus-based-decision-making-by-the-community)
Normally, all project decisions will be made by consensus of all interested Contributors. The primary goal of this approach is to ensure that the people who are most affected by and involved in any given change can contribute their knowledge in the confidence that their voices will be heard, because thoughtful review from a broad community is the best mechanism we know of for creating high-quality software.

The mechanism we use to accomplish this goal may be unfamiliar for those
who are not experienced with the cultural norms around free/open-source
software development. We provide a summary here, and highly recommend
that all Contributors additionally read [Chapter 4: Social and Political
Infrastructure](http://producingoss.com/en/producingoss.html#social-infrastructure)
of Karl Fogel’s classic *Producing Open Source Software*, and in
particular the section on [Consensus-based
Democracy](http://producingoss.com/en/producingoss.html#consensus-democracy),
for a more detailed discussion.

In this context, consensus does *not* require:

that we wait to solicit everybody’s opinion on every change,

that we ever hold a vote on anything,

or that everybody is happy or agrees with every decision.

For us, what consensus means is that we entrust *everyone* with the
right to veto any change if they feel it necessary. While this may sound
like a recipe for obstruction and pain, this is not what happens.
Instead, we find that most people take this responsibility seriously,
and only invoke their veto when they judge that a serious problem is
being ignored, and that their veto is necessary to protect the project.
And in practice, it turns out that such vetoes are almost never formally
invoked, because their mere possibility ensures that Contributors are
motivated from the start to find some solution that everyone can live
with – thus accomplishing our goal of ensuring that all interested
perspectives are taken into account.

How do we know when consensus has been achieved? In principle, this is
rather difficult, since consensus is defined by the absence of vetos,
which requires us to somehow prove a negative. In practice, we use a
combination of our best judgement (e.g., a simple and uncontroversial
bug fix posted on GitHub and reviewed by a core developer is probably
fine) and best efforts (e.g., all substantive API changes must be posted
to the mailing list in order to give the broader community a chance to
catch any problems and suggest improvements; we assume that anyone who
cares enough about NumPy to invoke their veto right should be on the
mailing list). If no-one bothers to comment on the mailing list after a
few days, then it’s probably fine. And worst case, if a change is more
controversial than expected, or a crucial critique is delayed because
someone was on vacation, then it’s no big deal: we apologize for
misjudging the situation, [back up, and sort things
out](http://producingoss.com/en/producingoss.html#version-control-relaxation).

If one does need to invoke a formal veto, then it should consist of:

an unambiguous statement that a veto is being invoked,

an explanation of why it is being invoked, and

a description of what conditions (if any) would convince the vetoer to withdraw their veto.

If all proposals for resolving some issue are vetoed, then the status quo wins by default.

In the worst case, if a Contributor is genuinely misusing their veto in an obstructive fashion to the detriment of the project, then they can be ejected from the project by consensus of the Steering Council – see below.

### Steering Council[#](#steering-council)
The Project will have a Steering Council that consists of Project Contributors who have produced contributions that are substantial in quality and quantity, and sustained over at least one year. The overall role of the Council is to ensure, with input from the Community, the long-term well-being of the project, both technically and as a community.

During the everyday project activities, council members participate in all discussions, code review and other project activities as peers with all other Contributors and the Community. In these everyday activities, Council Members do not have any special power or privilege through their membership on the Council. However, it is expected that because of the quality and quantity of their contributions and their expert knowledge of the Project Software and Services that Council Members will provide useful guidance, both technical and in terms of project direction, to potentially less experienced contributors.

The Steering Council and its Members play a special role in certain situations. In particular, the Council may, if necessary:

Make decisions about the overall scope, vision and direction of the project.

Make decisions about strategic collaborations with other organizations or individuals.

Make decisions about specific technical issues, features, bugs and pull requests. They are the primary mechanism of guiding the code review process and merging pull requests.

Make decisions about the Services that are run by The Project and manage those Services for the benefit of the Project and Community.

Update policy documents such as this one.

Make decisions when regular community discussion doesn’t produce consensus on an issue in a reasonable time frame.

However, the Council’s primary responsibility is to facilitate the ordinary community-based decision making procedure described above. If we ever have to step in and formally override the community for the health of the Project, then we will do so, but we will consider reaching this point to indicate a failure in our leadership.

#### Council decision making[#](#council-decision-making)
If it becomes necessary for the Steering Council to produce a formal
decision, then they will use a form of the [Apache Foundation voting
process](https://www.apache.org/foundation/voting.html). This is a
formalized version of consensus, in which +1 votes indicate agreement,
-1 votes are vetoes (and must be accompanied with a rationale, as
above), and one can also vote fractionally (e.g. -0.5, +0.5) if one
wishes to express an opinion without registering a full veto. These
numeric votes are also often used informally as a way of getting a
general sense of people’s feelings on some issue, and should not
normally be taken as formal votes. A formal vote only occurs if
explicitly declared, and if this does occur then the vote should be held
open for long enough to give all interested Council Members a chance to
respond – at least one week.

In practice, we anticipate that for most Steering Council decisions (e.g., voting in new members) a more informal process will suffice.

#### Council membership[#](#council-membership)
A list of current Steering Council Members is maintained at the
page [About Us](https://numpy.org/about/).

To become eligible to join the Steering Council, an individual must be a Project Contributor who has produced contributions that are substantial in quality and quantity, and sustained over at least one year. Potential Council Members are nominated by existing Council members, and become members following consensus of the existing Council members, and confirmation that the potential Member is interested and willing to serve in that capacity. The Council will be initially formed from the set of existing Core Developers who, as of late 2015, have been significantly active over the last year.

When considering potential Members, the Council will look at candidates with a comprehensive view of their contributions. This will include but is not limited to code, code review, infrastructure work, mailing list and chat participation, community help/building, education and outreach, design work, etc. We are deliberately not setting arbitrary quantitative metrics (like “100 commits in this repo”) to avoid encouraging behavior that plays to the metrics rather than the project’s overall well-being. We want to encourage a diverse array of backgrounds, viewpoints and talents in our team, which is why we explicitly do not define code as the sole metric on which council membership will be evaluated.

If a Council member becomes inactive in the project for a period of one year, they will be considered for removal from the Council. Before removal, inactive Member will be approached to see if they plan on returning to active participation. If not they will be removed immediately upon a Council vote. If they plan on returning to active participation soon, they will be given a grace period of one year. If they don’t return to active participation within that time period they will be removed by vote of the Council without further grace period. All former Council members can be considered for membership again at any time in the future, like any other Project Contributor. Retired Council members will be listed on the project website, acknowledging the period during which they were active in the Council.

The Council reserves the right to eject current Members, if they are deemed to be actively harmful to the project’s well-being, and attempts at communication and conflict resolution have failed. This requires the consensus of the remaining Members.

#### Conflict of interest[#](#conflict-of-interest)
It is expected that the Council Members will be employed at a wide range of companies, universities and non-profit organizations. Because of this, it is possible that Members will have conflict of interests. Such conflict of interests include, but are not limited to:

Financial interests, such as investments, employment or contracting work, outside of The Project that may influence their work on The Project.

Access to proprietary information of their employer that could potentially leak into their work with the Project.

All members of the Council shall disclose to the rest of the Council any conflict of interest they may have. Members with a conflict of interest in a particular issue may participate in Council discussions on that issue, but must recuse themselves from voting on the issue.

#### Private communications of the Council[#](#private-communications-of-the-council)
To the maximum extent possible, Council discussions and activities will be public and done in collaboration and discussion with the Project Contributors and Community. The Council will have a private mailing list that will be used sparingly and only when a specific matter requires privacy. When private communications and decisions are needed, the Council will do its best to summarize those to the Community after eliding personal/private/sensitive information that should not be posted to the public internet.

#### Subcommittees[#](#subcommittees)
The Council can create subcommittees that provide leadership and guidance for specific aspects of the project. Like the Council as a whole, subcommittees should conduct their business in an open and public manner unless privacy is specifically called for. Private subcommittee communications should happen on the main private mailing list of the Council unless specifically called for.

#### NumFOCUS Subcommittee[#](#numfocus-subcommittee)
The Council will maintain one narrowly focused subcommittee to manage its interactions with NumFOCUS.

The NumFOCUS Subcommittee is comprised of 5 persons who manage project funding that comes through NumFOCUS. It is expected that these funds will be spent in a manner that is consistent with the non-profit mission of NumFOCUS and the direction of the Project as determined by the full Council.

This Subcommittee shall NOT make decisions about the direction, scope or technical direction of the Project.

This Subcommittee will have 5 members, 4 of whom will be current Council Members and 1 of whom will be external to the Steering Council. No more than 2 Subcommittee Members can report to one person through employment or contracting work (including the reportee, i.e. the reportee + 1 is the max). This avoids effective majorities resting on one person.

The current membership of the NumFOCUS Subcommittee is listed at the
page [About Us](https://numpy.org/about/).

## Institutional Partners and Funding[#](#institutional-partners-and-funding)
The Steering Council are the primary leadership for the project. No outside institution, individual or legal entity has the ability to own, control, usurp or influence the project other than by participating in the Project as Contributors and Council Members. However, because institutions can be an important funding mechanism for the project, it is important to formally acknowledge institutional participation in the project. These are Institutional Partners.

An Institutional Contributor is any individual Project Contributor who contributes to the project as part of their official duties at an Institutional Partner. Likewise, an Institutional Council Member is any Project Steering Council Member who contributes to the project as part of their official duties at an Institutional Partner.

With these definitions, an Institutional Partner is any recognized legal entity in the United States or elsewhere that employs at least 1 Institutional Contributor of Institutional Council Member. Institutional Partners can be for-profit or non-profit entities.

Institutions become eligible to become an Institutional Partner by employing individuals who actively contribute to The Project as part of their official duties. To state this another way, the only way for a Partner to influence the project is by actively contributing to the open development of the project, in equal terms to any other member of the community of Contributors and Council Members. Merely using Project Software in institutional context does not allow an entity to become an Institutional Partner. Financial gifts do not enable an entity to become an Institutional Partner. Once an institution becomes eligible for Institutional Partnership, the Steering Council must nominate and approve the Partnership.

If at some point an existing Institutional Partner stops having any contributing employees, then a one year grace period commences. If at the end of this one year period they continue not to have any contributing employees, then their Institutional Partnership will lapse, and resuming it will require going through the normal process for new Partnerships.

An Institutional Partner is free to pursue funding for their work on The Project through any legal means. This could involve a non-profit organization raising money from private foundations and donors or a for-profit company building proprietary products and services that leverage Project Software and Services. Funding acquired by Institutional Partners to work on The Project is called Institutional Funding. However, no funding obtained by an Institutional Partner can override the Steering Council. If a Partner has funding to do NumPy work and the Council decides to not pursue that work as a project, the Partner is free to pursue it on their own. However in this situation, that part of the Partner’s work will not be under the NumPy umbrella and cannot use the Project trademarks in a way that suggests a formal relationship.

Institutional Partner benefits are:

Acknowledgement on the NumPy websites, in talks and T-shirts.

Ability to acknowledge their own funding sources on the NumPy websites, in talks and T-shirts.

Ability to influence the project through the participation of their Council Member.

Council Members invited to NumPy Developer Meetings.

A list of current Institutional Partners is maintained at the page
[About Us](https://numpy.org/about/).

## Document history[#](#document-history)
[https://github.com/numpy/numpy/commits/main/doc/source/dev/governance/governance.rst](https://github.com/numpy/numpy/commits/main/doc/source/dev/governance/governance.rst)
## Acknowledgements[#](#acknowledgements)
Substantial portions of this document were adapted from the
[Jupyter/IPython project’s governance document](https://github.com/jupyter/governance)

## License[#](#license)
To the extent possible under law, the authors have waived all
copyright and related or neighboring rights to the NumPy project
governance and decision-making document, as per the [CC-0 public
domain dedication / license](https://creativecommons.org/publicdomain/zero/1.0/).# Two and three dots in difference specs[#](#two-and-three-dots-in-difference-specs)
Thanks to Yarik Halchenko for this explanation.

Imagine a series of commits A, B, C, D… Imagine that there are two
branches, *topic* and *main*. You branched *topic* off *main* when
*main* was at commit ‘E’. The graph of the commits looks like this:

```
A---B---C topic
/
D---E---F---G main
```
Then:

```
git diff main..topic
```
will output the difference from G to C (i.e. with effects of F and G), while:

```
git diff main...topic
```
would output just differences in the topic branch (i.e. only A, B, and C).# NumPy fundamentals[#](#numpy-fundamentals)
These documents clarify concepts, design decisions, and technical constraints in NumPy. This is a great place to understand the fundamental NumPy ideas and philosophy.

These documents clarify concepts, design decisions, and technical constraints in NumPy. This is a great place to understand the fundamental NumPy ideas and philosophy.# Input and output[#](#input-and-output)
## NumPy binary files (NPY, NPZ)[#](#numpy-binary-files-npy-npz)
|
Load arrays or pickled objects from

|
|
Save an array to a binary file in NumPy

|
|
Save several arrays into a single file in uncompressed

|
|
Save several arrays into a single file in compressed

|
The format of these binary file types is documented in
`numpy.lib.format`

## Text files[#](#text-files)
|
Load data from a text file.

|
|
Save an array to a text file.

|
|
Load data from a text file, with missing values handled as specified.

|
|
Construct an array from a text file, using regular expression parsing.

|
|
A new 1-D array initialized from text data in a string.

|
|
Write array to a file as text or binary (default).

|
Return the array as an

|
## Raw binary files[#](#raw-binary-files)
|
Construct an array from data in a text or binary file.

|
|
Write array to a file as text or binary (default).

|
## String formatting[#](#string-formatting)
|
Return a string representation of an array.

|
|
Return the string representation of an array.

|
|
Return a string representation of the data in an array.

|
|
Format a floating-point scalar as a decimal string in positional notation.

|
|
Format a floating-point scalar as a decimal string in scientific notation.

|
## Memory mapping files[#](#memory-mapping-files)
|
Create a memory-map to an array stored in a

|
|
Open a .npy file as a memory-mapped array.

|
## Text formatting options[#](#text-formatting-options)
|
Set printing options.

|
Return the current print options.

|
|
Set a Python function to be used when pretty printing arrays.

|
|
Context manager for setting print options.

|
## Base-n representations[#](#base-n-representations)
|
Return the binary representation of the input number as a string.

|
|
Return a string representation of a number in the given base system.

|
## Data sources[#](#data-sources)
|
A generic data source file (file, http, ftp, ...).

|
## Binary format description[#](#binary-format-description)
Binary serialization

|# numpy.ndarray.flatten[#](#numpy-ndarray-flatten)
method

ndarray.flatten(*order='C'*)[#](#numpy.ndarray.flatten)
-
Return a copy of the array collapsed into one dimension.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
‘C’ means to flatten in row-major (C-style) order. ‘F’ means to flatten in column-major (Fortran- style) order. ‘A’ means to flatten in column-major order if

*a*is Fortran*contiguous*in memory, row-major order otherwise. ‘K’ means to flatten*a*in the order the elements occur in memory. The default is ‘C’.
Returns:
-
**y**ndarray
A copy of the input array, flattened to one dimension.

Examples

>>> a = np.array([[1,2], [3,4]]) >>> a.flatten() array([1, 2, 3, 4]) >>> a.flatten('F') array([1, 3, 2, 4])# Advanced debugging tools[#](#advanced-debugging-tools)
If you reached here, you want to dive into, or use, more advanced tooling. This is usually not necessary for first time contributors and most day-to-day development. These are used more rarely, for example close to a new NumPy release, or when a large or particular complex change was made.

Since not all of these tools are used on a regular bases and only available on some systems, please expect differences, issues, or quirks; we will be happy to help if you get stuck and appreciate any improvements or suggestions to these workflows.

## Finding C errors with additional tooling[#](#finding-c-errors-with-additional-tooling)
Most development will not require more than a typical debugging toolchain
as shown in [Debugging](development_environment.html#debugging).
But for example memory leaks can be particularly subtle or difficult to
narrow down.

We do not expect any of these tools to be run by most contributors. However, you can ensure that we can track down such issues more easily:

Tests should cover all code paths, including error paths.

Try to write short and simple tests. If you have a very complicated test consider creating an additional simpler test as well. This can be helpful, because often it is only easy to find which test triggers an issue and not which line of the test.

Never use

`np.empty`
if data is read/used.`valgrind`
will notice this and report an error. When you do not care about values, you can generate random values instead.
This will help us catch any oversights before your change is released and means you do not have to worry about making reference counting errors, which can be intimidating.

### Python debug build[#](#python-debug-build)
Debug builds of Python are easily available for example via the system package
manager on Linux systems, but are also available on other platforms, possibly in
a less convenient format. If you cannot easily install a debug build of Python
from a system package manager, you can build one yourself using [pyenv](https://github.com/pyenv/pyenv). For example, to install and globally
activate a debug build of Python 3.10.8, one would do:

```
pyenv install -g 3.10.8
pyenv global 3.10.8
```
Note that `pyenv install`
builds Python from source, so you must ensure that
Python’s dependencies are installed before building, see the pyenv documentation
for platform-specific installation instructions. You can use `pip`
to install
Python dependencies you may need for your debugging session. If there is no
debug wheel available on *pypi,* you will need to build the dependencies from
source and ensure that your dependencies are also compiled as debug builds.

Often debug builds of Python name the Python executable `pythond`
instead of
`python`
. To check if you have a debug build of Python installed, you can run
e.g. `pythond -m sysconfig`
to get the build configuration for the Python
executable. A debug build will be built with debug compiler options in
`CFLAGS`
(e.g. `-g -Og`
).

Running the Numpy tests or an interactive terminal is usually as easy as:

```
python3.8d runtests.py
# or
python3.8d runtests.py --ipython
```
and were already mentioned in [Debugging](development_environment.html#debugging).

A Python debug build will help:

Find bugs which may otherwise cause random behaviour. One example is when an object is still used after it has been deleted.

Python debug builds allows to check correct reference counting. This works using the additional commands:

sys.gettotalrefcount() sys.getallocatedblocks()
Python debug builds allow easier debugging with gdb and other C debuggers.

#### Use together with `pytest`
[#](#use-together-with-pytest)
Running the test suite only with a debug python build will not find many errors on its own. An additional advantage of a debug build of Python is that it allows detecting memory leaks.

A tool to make this easier is [pytest-leaks](https://github.com/abalkin/pytest-leaks), which can be installed using `pip`
.
Unfortunately, `pytest`
itself may leak memory, but good results can usually
(currently) be achieved by removing:

```
@pytest.fixture(autouse=True)
def add_np(doctest_namespace):
doctest_namespace['np'] = numpy
@pytest.fixture(autouse=True)
def env_setup(monkeypatch):
monkeypatch.setenv('PYTHONHASHSEED', '0')
```
from `numpy/conftest.py`
(This may change with new `pytest-leaks`
versions
or `pytest`
updates).

This allows to run the test suite, or part of it, conveniently:

```
python3.8d runtests.py -t numpy/core/tests/test_multiarray.py -- -R2:3 -s
```
where `-R2:3`
is the `pytest-leaks`
command (see its documentation), the
`-s`
causes output to print and may be necessary (in some versions captured
output was detected as a leak).

Note that some tests are known (or even designed) to leak references, we try to mark them, but expect some false positives.

`valgrind`
[#](#valgrind)
Valgrind is a powerful tool to find certain memory access problems and should
be run on complicated C code.
Basic use of `valgrind`
usually requires no more than:

```
PYTHONMALLOC=malloc valgrind python runtests.py
```
where `PYTHONMALLOC=malloc`
is necessary to avoid false positives from python
itself.
Depending on the system and valgrind version, you may see more false positives.
`valgrind`
supports “suppressions” to ignore some of these, and Python does
have a suppression file (and even a compile time option) which may help if you
find it necessary.

Valgrind helps:

Find use of uninitialized variables/memory.

Detect memory access violations (reading or writing outside of allocated memory).

Find

*many*memory leaks. Note that for*most*leaks the python debug build approach (and`pytest-leaks`
) is much more sensitive. The reason is that`valgrind`
can only detect if memory is definitely lost. If:dtype = np.dtype(np.int64) arr.astype(dtype=dtype)
Has incorrect reference counting for

`dtype`
, this is a bug, but valgrind cannot see it because`np.dtype(np.int64)`
always returns the same object. However, not all dtypes are singletons, so this might leak memory for different input. In rare cases NumPy uses`malloc`
and not the Python memory allocators which are invisible to the Python debug build.`malloc`
should normally be avoided, but there are some exceptions (e.g. the`PyArray_Dims`
structure is public API and cannot use the Python allocators.)
Even though using valgrind for memory leak detection is slow and less sensitive it can be a convenient: you can run most programs with valgrind without modification.

Things to be aware of:

Valgrind does not support the numpy

`longdouble`
, this means that tests will fail or be flagged errors that are completely fine.
Expect some errors before and after running your NumPy code.

Caches can mean that errors (specifically memory leaks) may not be detected or are only detect at a later, unrelated time.

A big advantage of valgrind is that it has no requirements aside from valgrind itself (although you probably want to use debug builds for better tracebacks).

#### Use together with `pytest`
[#](#id1)
You can run the test suite with valgrind which may be sufficient when you are only interested in a few tests:

```
PYTHOMMALLOC=malloc valgrind python runtests.py \
-t numpy/core/tests/test_multiarray.py -- --continue-on-collection-errors
```
Note the `--continue-on-collection-errors`
, which is currently necessary due to
missing `longdouble`
support causing failures (this will usually not be
necessary if you do not run the full test suite).

If you wish to detect memory leaks you will also require `--show-leak-kinds=definite`
and possibly more valgrind options. Just as for `pytest-leaks`
certain
tests are known to leak cause errors in valgrind and may or may not be marked
as such.

We have developed [pytest-valgrind](https://github.com/seberg/pytest-valgrind) which:

Reports errors for each test individually

Narrows down memory leaks to individual tests (by default valgrind only checks for memory leaks after a program stops, which is very cumbersome).

Please refer to its `README`
for more information (it includes an example
command for NumPy).# numpy.flip[#](#numpy-flip)
numpy.flip(*m*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L254-L345)[#](#numpy.flip)
-
Reverse the order of elements in an array along the given axis.

The shape of the array is preserved, but the elements are reordered.

New in version 1.12.0.

Parameters:
-
**m**array_like
Input array.

**axis**None or int or tuple of ints, optional
Axis or axes along which to flip over. The default, axis=None, will flip over all of the axes of the input array. If axis is negative it counts from the last to the first axis.

If axis is a tuple of ints, flipping is performed on all of the axes specified in the tuple.

Changed in version 1.15.0: None and tuples of axes are supported

Returns:
-
**out**array_like
A view of

*m*with the entries of axis reversed. Since a view is returned, this operation is done in constant time.
Notes

flip(m, 0) is equivalent to flipud(m).

flip(m, 1) is equivalent to fliplr(m).

flip(m, n) corresponds to

`m[...,::-1,...]`
with`::-1`
at position n.flip(m) corresponds to

`m[::-1,::-1,...,::-1]`
with`::-1`
at all positions.flip(m, (0, 1)) corresponds to

`m[::-1,::-1,...]`
with`::-1`
at position 0 and position 1.Examples

>>> A = np.arange(8).reshape((2,2,2)) >>> A array([[[0, 1], [2, 3]], [[4, 5], [6, 7]]]) >>> np.flip(A, 0) array([[[4, 5], [6, 7]], [[0, 1], [2, 3]]]) >>> np.flip(A, 1) array([[[2, 3], [0, 1]], [[6, 7], [4, 5]]]) >>> np.flip(A) array([[[7, 6], [5, 4]], [[3, 2], [1, 0]]]) >>> np.flip(A, (0, 2)) array([[[5, 4], [7, 6]], [[1, 0], [3, 2]]]) >>> A = np.random.randn(3,4,5) >>> np.all(np.flip(A,2) == A[:,:,::-1,...]) True# NumPy for MATLAB users[#](#numpy-for-matlab-users)
## Introduction[#](#introduction)
MATLAB® and NumPy have a lot in common, but NumPy was created to work with Python, not to be a MATLAB clone. This guide will help MATLAB users get started with NumPy.

## Some key differences[#](#some-key-differences)
In MATLAB, the basic type, even for scalars, is a multidimensional array. Array assignments in MATLAB are stored as 2D arrays of double precision floating point numbers, unless you specify the number of dimensions and type. Operations on the 2D instances of these arrays are modeled on matrix operations in linear algebra.

|
In NumPy, the basic type is a multidimensional

|
MATLAB numbers indices from 1;

|
NumPy, like Python, numbers indices from 0;

|
MATLAB’s scripting language was created for linear algebra so the syntax for some array manipulations is more compact than NumPy’s. On the other hand, the API for adding GUIs and creating full-fledged applications is more or less an afterthought.

|
NumPy is based on Python, a
general-purpose language. The advantage to NumPy
is access to Python libraries including:

|
MATLAB array slicing uses pass-by-value semantics, with a lazy copy-on-write scheme to prevent creating copies until they are needed. Slicing operations copy parts of the array.

|
NumPy array slicing uses pass-by-reference, that does not copy the arguments. Slicing operations are views into an array.

|
## Rough equivalents[#](#rough-equivalents)
The table below gives rough equivalents for some common MATLAB
expressions. These are similar expressions, not equivalents. For
details, see the [documentation](../reference/index.html#reference).

In the table below, it is assumed that you have executed the following commands in Python:

```
import numpy as np
from scipy import io, integrate, linalg, signal
from scipy.sparse.linalg import cg, eigs
```
Also assume below that if the Notes talk about “matrix” that the arguments are two-dimensional entities.

### General purpose equivalents[#](#general-purpose-equivalents)
MATLAB

|
NumPy

|
Notes

|
---|---|---|
|
|
get help on the function

|
|
find out where

|
|
|
print source for

|
|
|
comment a line of code with the text

|
```
for i=1:3
fprintf('%i\n',i)
end
```
|
```
for i in range(1, 4):
print(i)
```
|
use a for-loop to print the numbers 1, 2, and 3 using

|
|
|
short-circuiting logical AND operator (

|
|
|
short-circuiting logical OR operator (

|
```
>> 4 == 4
ans = 1
>> 4 == 5
ans = 0
```
|
```
>>> 4 == 4
True
>>> 4 == 5
False
```
|
The

|
```
a=4
if a==4
fprintf('a = 4\n')
elseif a==5
fprintf('a = 5\n')
end
```
|
```
a = 4
if a == 4:
print('a = 4')
elif a == 5:
print('a = 5')
```
|
create an if-else statement to check if

|
|
|
complex numbers

|
|
|
distance from 1 to the next larger representable real number in double precision

|
|
|
Load MATLAB variables saved to the file

|
|
|
integrate an ODE with Runge-Kutta 4,5

|
|
|
integrate an ODE with BDF method

|
### Linear algebra equivalents[#](#linear-algebra-equivalents)
MATLAB

|
NumPy

|
Notes

|
---|---|---|
|
|
number of dimensions of array

|
|
|
number of elements of array

|
|
|
“size” of array

|
|
|
get the number of elements of the n-th dimension of array

|
|
|
define a 2x3 2D array

|
|
|
construct a matrix from blocks

|
|
|
access last element in MATLAB vector (1xn or nx1) or 1D NumPy array

|
|
|
access element in second row, fifth column in 2D array

|
|
|
entire second row of 2D array

|
|
|
first 5 rows of 2D array

|
|
|
last 5 rows of 2D array

|
|
|
The first through third rows and fifth through ninth columns of a 2D array,

|
|
|
rows 2,4 and 5 and columns 1 and 3. This allows the matrix to be modified, and doesn’t require a regular slice.

|
|
|
every other row of

|
|
|
every other row of

|
|
|
|
|
|
|
|
|
transpose of

|
|
|
conjugate transpose of

|
|
|
matrix multiply

|
|
|
element-wise multiply

|
|
|
element-wise divide

|
|
|
element-wise exponentiation

|
|
|
matrix whose i,jth element is (a_ij > 0.5). The MATLAB result is an
array of logical values 0 and 1. The NumPy result is an array of the boolean
values

|
|
|
find the indices where (

|
|
|
extract the columns of

|
|
|
extract the columns of

|
|
|
|
|
|
|
|
|
set all values to the same scalar value

|
|
|
NumPy assigns by reference

|
|
|
NumPy slices are by reference

|
|
|
turn array into vector (note that this forces a copy). To obtain the
same data ordering as in MATLAB, use

|
|
|
create an increasing vector (see note

|
|
|
create an increasing vector (see note

|
|
|
create a column vector

|
|
|
3x4 two-dimensional array full of 64-bit floating point zeros

|
|
|
3x4x5 three-dimensional array full of 64-bit floating point zeros

|
|
|
3x4 two-dimensional array full of 64-bit floating point ones

|
|
|
3x3 identity matrix

|
|
|
returns a vector of the diagonal elements of 2D array,

|
|
|
returns a square diagonal matrix whose nonzero values are the elements of
vector,

|
```
rng(42,'twister')
rand(3,4)
```
|
```
from numpy.random import default_rng
rng = default_rng(42)
rng.random(3, 4)
```
or older version:

|
generate a random 3x4 array with default random number generator and seed = 42

|
|
|
4 equally spaced samples between 1 and 3, inclusive

|
|
|
two 2D arrays: one of x values, the other of y values

|
|
the best way to eval functions on a grid

|
|
|
|
the best way to eval functions on a grid

|
|
|
create m by n copies of

|
|
|
concatenate columns of

|
|
|
concatenate rows of

|
|
|
maximum element of

|
|
|
maximum element of each column of array

|
|
|
maximum element of each row of array

|
|
|
compares

|
|
|
L2 norm of vector

|
|
|
element-by-element AND operator (NumPy ufunc)

|
|
|
element-by-element OR operator (NumPy ufunc)

|
|
|
bitwise AND operator (Python native and NumPy ufunc)

|
|
|
bitwise OR operator (Python native and NumPy ufunc)

|
|
|
inverse of square 2D array

|
|
|
pseudo-inverse of 2D array

|
|
|
matrix rank of a 2D array

|
|
|
solution of a x = b for x

|
|
Solve

|
solution of x a = b for x

|
|
|
singular value decomposition of

|
|
|
Cholesky factorization of a 2D array

|
|
|
eigenvalues \(\lambda\) and eigenvectors \(v\) of

|
|
|
eigenvalues \(\lambda\) and eigenvectors \(v\) of

|
|
|
find the

|
|
|
QR decomposition

|
|
|
LU decomposition with partial pivoting (note: P(MATLAB) == transpose(P(NumPy)))

|
|
|
conjugate gradients solver

|
|
|
Fourier transform of

|
|
|
inverse Fourier transform of

|
|
|
sort each column of a 2D array,

|
|
|
sort the each row of 2D array,

|
|
|
save the array

|
|
|
perform a linear regression of the form \(\mathbf{Zx}=\mathbf{y}\)

|
|
|
downsample with low-pass filtering

|
|
|
a vector of unique values in array

|
|
|
remove singleton dimensions of array

|
## Notes[#](#notes)
**Submatrix**: Assignment to a submatrix can be done with lists of
indices using the `ix_`
command. E.g., for 2D array `a`
, one might
do: `ind=[1, 3]; a[np.ix_(ind, ind)] += 100`
.
**HELP**: There is no direct equivalent of MATLAB’s `which`
command,
but the commands [ help](https://docs.python.org/3/library/functions.html#help) and
[will usually list the filename where the function is located. Python also has an](../reference/generated/numpy.source.html#numpy.source)
`numpy.source`
`inspect`
module (do
`import inspect`
) which provides a `getfile`
that often works.**INDEXING**: MATLAB uses one based indexing, so the initial element
of a sequence has index 1. Python uses zero based indexing, so the
initial element of a sequence has index 0. Confusion and flamewars arise
because each has advantages and disadvantages. One based indexing is
consistent with common human language usage, where the “first” element
of a sequence has index 1. Zero based indexing [simplifies
indexing](https://groups.google.com/group/comp.lang.python/msg/1bf4d925dfbf368?q=g:thl3498076713d&hl=en).
See also [a text by prof.dr. Edsger W.
Dijkstra](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html).
**RANGES**: In MATLAB, `0:5`
can be used as both a range literal
and a ‘slice’ index (inside parentheses); however, in Python, constructs
like `0:5`
can *only* be used as a slice index (inside square
brackets). Thus the somewhat quirky `r_`
object was created to allow
NumPy to have a similarly terse range construction mechanism. Note that
`r_`
is not called like a function or a constructor, but rather
*indexed* using square brackets, which allows the use of Python’s slice
syntax in the arguments.
**LOGICOPS**: `&`
or `|`
in NumPy is bitwise AND/OR, while in MATLAB &
and `|`
are logical AND/OR. The two can appear to work the same,
but there are important differences. If you would have used MATLAB’s `&`
or `|`
operators, you should use the NumPy ufuncs
`logical_and`
/`logical_or`
. The notable differences between MATLAB’s and
NumPy’s `&`
and `|`
operators are:
Non-logical {0,1} inputs: NumPy’s output is the bitwise AND of the inputs. MATLAB treats any non-zero value as 1 and returns the logical AND. For example

`(3 & 4)`
in NumPy is`0`
, while in MATLAB both`3`
and`4`
are considered logical true and`(3 & 4)`
returns`1`
.
Precedence: NumPy’s & operator is higher precedence than logical operators like

`<`
and`>`
; MATLAB’s is the reverse.
If you know you have boolean arguments, you can get away with using
NumPy’s bitwise operators, but be careful with parentheses, like this: ```
z
= (x > 1) & (x < 2)
```
. The absence of NumPy operator forms of `logical_and`
and `logical_or`
is an unfortunate consequence of Python’s design.

**RESHAPE and LINEAR INDEXING**: MATLAB always allows multi-dimensional
arrays to be accessed using scalar or linear indices, NumPy does not.
Linear indices are common in MATLAB programs, e.g. `find()`
on a matrix
returns them, whereas NumPy’s find behaves differently. When converting
MATLAB code it might be necessary to first reshape a matrix to a linear
sequence, perform some indexing operations and then reshape back. As
reshape (usually) produces views onto the same storage, it should be
possible to do this fairly efficiently. Note that the scan order used by
reshape in NumPy defaults to the ‘C’ order, whereas MATLAB uses the
Fortran order. If you are simply converting to a linear sequence and
back this doesn’t matter. But if you are converting reshapes from MATLAB
code which relies on the scan order, then this MATLAB code: ```
z =
reshape(x,3,4);
```
should become `z = x.reshape(3,4,order='F').copy()`
in
NumPy.
## ‘array’ or ‘matrix’? Which should I use?[#](#array-or-matrix-which-should-i-use)
Historically, NumPy has provided a special matrix type, *np.matrix*, which
is a subclass of ndarray which makes binary operations linear algebra
operations. You may see it used in some existing code instead of *np.array*.
So, which one to use?

### Short answer[#](#short-answer)
**Use arrays**.
They support multidimensional array algebra that is supported in MATLAB

They are the standard vector/matrix/tensor type of NumPy. Many NumPy functions return arrays, not matrices.

There is a clear distinction between element-wise operations and linear algebra operations.

You can have standard vectors or row/column vectors if you like.

Until Python 3.5 the only disadvantage of using the array type was that you
had to use `dot`
instead of `*`
to multiply (reduce) two tensors
(scalar product, matrix vector multiplication etc.). Since Python 3.5 you
can use the matrix multiplication `@`
operator.

Given the above, we intend to deprecate `matrix`
eventually.

### Long answer[#](#long-answer)
NumPy contains both an `array`
class and a `matrix`
class. The
`array`
class is intended to be a general-purpose n-dimensional array
for many kinds of numerical computing, while `matrix`
is intended to
facilitate linear algebra computations specifically. In practice there
are only a handful of key differences between the two.

Operators

`*`
and`@`
, functions`dot()`
, and`multiply()`
:For

`array`
,**``*`` means element-wise multiplication**, while**``@`` means matrix multiplication**; they have associated functions`multiply()`
and`dot()`
. (Before Python 3.5,`@`
did not exist and one had to use`dot()`
for matrix multiplication).
For

`matrix`
,**``*`` means matrix multiplication**, and for element-wise multiplication one has to use the`multiply()`
function.
Handling of vectors (one-dimensional arrays)

For

`array`
, the**vector shapes 1xN, Nx1, and N are all different things**. Operations like`A[:,1]`
return a one-dimensional array of shape N, not a two-dimensional array of shape Nx1. Transpose on a one-dimensional`array`
does nothing.
For

`matrix`
,**one-dimensional arrays are always upconverted to 1xN or Nx1 matrices**(row or column vectors).`A[:,1]`
returns a two-dimensional matrix of shape Nx1.
Handling of higher-dimensional arrays (ndim > 2)

`array`
objects**can have number of dimensions > 2**;
`matrix`
objects**always have exactly two dimensions**.
Convenience attributes

`array`
**has a .T attribute**, which returns the transpose of the data.
`matrix`
**also has .H, .I, and .A attributes**, which return the conjugate transpose, inverse, and`asarray()`
of the matrix, respectively.
Convenience constructor

The

`array`
constructor**takes (nested) Python sequences as initializers**. As in,`array([[1,2,3],[4,5,6]])`
.
The

`matrix`
constructor additionally**takes a convenient string initializer**. As in`matrix("[1 2 3; 4 5 6]")`
.
There are pros and cons to using both:

`array`
`:)`
Element-wise multiplication is easy:`A*B`
.
`:(`
You have to remember that matrix multiplication has its own operator,`@`
.
`:)`
You can treat one-dimensional arrays as*either*row or column vectors.`A @ v`
treats`v`
as a column vector, while`v @ A`
treats`v`
as a row vector. This can save you having to type a lot of transposes.
`:)`
`array`
is the “default” NumPy type, so it gets the most testing, and is the type most likely to be returned by 3rd party code that uses NumPy.
`:)`
Is quite at home handling data of any number of dimensions.
`:)`
Closer in semantics to tensor algebra, if you are familiar with that.
`:)`
*All*operations (`*`
,`/`
,`+`
,`-`
etc.) are element-wise.
`:(`
Sparse matrices from`scipy.sparse`
do not interact as well with arrays.
`matrix`
`:\\`
Behavior is more like that of MATLAB matrices.
`<:(`
Maximum of two-dimensional. To hold three-dimensional data you need`array`
or perhaps a Python list of`matrix`
.
`<:(`
Minimum of two-dimensional. You cannot have vectors. They must be cast as single-column or single-row matrices.
`<:(`
Since`array`
is the default in NumPy, some functions may return an`array`
even if you give them a`matrix`
as an argument. This shouldn’t happen with NumPy functions (if it does it’s a bug), but 3rd party code based on NumPy may not honor type preservation like NumPy does.
`:)`
`A*B`
is matrix multiplication, so it looks just like you write it in linear algebra (For Python >= 3.5 plain arrays have the same convenience with the`@`
operator).
`<:(`
Element-wise multiplication requires calling a function,`multiply(A,B)`
.
`<:(`
The use of operator overloading is a bit illogical:`*`
does not work element-wise but`/`
does.
Interaction with

`scipy.sparse`
is a bit cleaner.
The `array`
is thus much more advisable to use. Indeed, we intend to
deprecate `matrix`
eventually.

## Customizing your environment[#](#customizing-your-environment)
In MATLAB the main tool available to you for customizing the environment is to modify the search path with the locations of your favorite functions. You can put such customizations into a startup script that MATLAB will run on startup.

NumPy, or rather Python, has similar facilities.

To modify your Python search path to include the locations of your own modules, define the

`PYTHONPATH`
environment variable.
To have a particular script file executed when the interactive Python interpreter is started, define the

`PYTHONSTARTUP`
environment variable to contain the name of your startup script.
Unlike MATLAB, where anything on your path can be called immediately, with Python you need to first do an ‘import’ statement to make functions in a particular file accessible.

For example you might make a startup script that looks like this (Note: this is just an example, not a statement of “best practices”):

```
# Make all numpy available via shorter 'np' prefix
import numpy as np
#
# Make the SciPy linear algebra functions available as linalg.func()
# e.g. linalg.lu, linalg.eig (for general l*B@u==A@u solution)
from scipy import linalg
#
# Define a Hermitian function
def hermitian(A, **kwargs):
return np.conj(A,**kwargs).T
# Make a shortcut for hermitian:
# hermitian(A) --> H(A)
H = hermitian
```
To use the deprecated *matrix* and other *matlib* functions:

```
# Make all matlib functions accessible at the top level via M.func()
import numpy.matlib as M
# Make some matlib functions accessible directly at the top level via, e.g. rand(3,3)
from numpy.matlib import matrix,rand,zeros,ones,empty,eye
```
## Links[#](#links)
Another somewhat outdated MATLAB/NumPy cross-reference can be found at
[http://mathesaurus.sf.net/](http://mathesaurus.sf.net/)

An extensive list of tools for scientific work with Python can be
found in the [topical software page](https://scipy.org/topical-software.html).

See
[List of Python software: scripting](https://en.wikipedia.org/wiki/List_of_Python_software#Embedded_as_a_scripting_language)
for a list of software that use Python as a scripting language

MATLAB® and SimuLink® are registered trademarks of The MathWorks, Inc.# Setting up git for NumPy development[#](#setting-up-git-for-numpy-development)
To contribute code or documentation, you first need

git installed on your machine

a GitHub account

a fork of NumPy

## Install git[#](#install-git)
You may already have git; check by typing `git --version`
. If it’s
installed you’ll see some variation of `git version 2.11.0`
.
If instead you see `command is not recognized`
, ```
command not
found
```
, etc.,
[install git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).

Then set your name and email:

```
git config --global user.email you@yourdomain.example.com
git config --global user.name "Your Name"
```
## Create a GitHub account[#](#create-a-github-account)
If you don’t have a GitHub account, visit [https://github.com/join](https://github.com/join) to create
one.

## Create a NumPy fork[#](#create-a-numpy-fork)
`Forking`
has two steps – visit GitHub to create a fork repo in your
account, then make a copy of it on your own machine.
### Create the fork repo[#](#create-the-fork-repo)
Log into your GitHub account.

Go to the

[NumPy GitHub home](https://github.com/numpy/numpy).
At the upper right of the page, click

`Fork`
:You’ll see

and then you’ll be taken to the home page of your forked copy:

### Make the local copy[#](#make-the-local-copy)
In the directory where you want the copy created, run

git clone https://github.com/your-user-name/numpy.git
You’ll see something like:

$ git clone https://github.com/your-user-name/numpy.git Cloning into 'numpy'... remote: Enumerating objects: 12, done. remote: Counting objects: 100% (12/12), done. remote: Compressing objects: 100% (12/12), done. remote: Total 175837 (delta 0), reused 0 (delta 0), pack-reused 175825 Receiving objects: 100% (175837/175837), 78.16 MiB | 9.87 MiB/s, done. Resolving deltas: 100% (139317/139317), done.
A directory

`numpy`
is created on your machine. (If you already have a numpy directory, GitHub will choose a different name like`numpy-1`
.)$ ls -l total 0 drwxrwxrwx 1 bjn bjn 4096 Jun 20 07:20 numpy
Give the name

`upstream`
to the main NumPy repo:cd numpy git remote add upstream https://github.com/numpy/numpy.git
Set up your repository so

`git pull`
pulls from`upstream`
by default:git config branch.main.remote upstream git config branch.main.merge refs/heads/main
Initialize the required git submodules:

git submodule update --init
Pull from upstream to get latest tag information:

git pull
## Look it over[#](#look-it-over)
The branches shown by

`git branch -a`
will includethe

`main`
branch you just cloned on your own machine
the

`main`
branch from your fork on GitHub, which git named`origin`
by default
the

`main`
branch on the main NumPy repo, which you named`upstream`
.
main remotes/origin/main remotes/upstream/main
If

`upstream`
isn’t there, it will be added after you access the NumPy repo with a command like`git fetch`
or`git pull`
.
The repos shown by

`git remote -v show`
will include your fork on GitHub and the main repo:upstream https://github.com/numpy/numpy.git (fetch) upstream https://github.com/numpy/numpy.git (push) origin https://github.com/your-user-name/numpy.git (fetch) origin https://github.com/your-user-name/numpy.git (push)
`git config --list`
will includeuser.email=your_email@example.com user.name=Your Name remote.origin.url=git@github.com:your-github-id/numpy.git remote.origin.fetch=+refs/heads/*:refs/remotes/origin/* branch.main.remote=upstream branch.main.merge=refs/heads/main remote.upstream.url=https://github.com/numpy/numpy.git remote.upstream.fetch=+refs/heads/*:refs/remotes/upstream/*
## Optional: set up SSH keys to avoid passwords[#](#optional-set-up-ssh-keys-to-avoid-passwords)
Cloning your NumPy fork repo required no password, because it read the remote
repo without changing it. Later, though, submitting your pull requests will
write to it, and GitHub will ask for your username and password – even though
it’s your own repo. You can eliminate this authentication without compromising
security by [setting up SSH keys ](https://help.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh).

**If you set up the keys before cloning**, the instructions above change
slightly. Instead of
```
git clone https://github.com/your-user-name/numpy.git
```
run

```
git clone git@github.com:your-user-name/numpy.git
```
and instead of showing an `https`
URL, `git remote -v`
will show

```
origin git@github.com:your-user-name/numpy.git (fetch)
origin git@github.com:your-user-name/numpy.git (push)
```
**If you have cloned already** and want to start using SSH, see
[Switching remote URLs from HTTPS to SSH ](https://help.github.com/en/github/using-git/changing-a-remotes-url#switching-remote-urls-from-https-to-ssh).# Array creation routines[#](#array-creation-routines)
See also

## From shape or value[#](#from-shape-or-value)
|
Return a new array of given shape and type, without initializing entries.

|
|
Return a new array with the same shape and type as a given array.

|
|
Return a 2-D array with ones on the diagonal and zeros elsewhere.

|
|
Return the identity array.

|
|
Return a new array of given shape and type, filled with ones.

|
|
Return an array of ones with the same shape and type as a given array.

|
|
Return a new array of given shape and type, filled with zeros.

|
|
Return an array of zeros with the same shape and type as a given array.

|
|
Return a new array of given shape and type, filled with

|
|
Return a full array with the same shape and type as a given array.

|
## From existing data[#](#from-existing-data)
|
Create an array.

|
|
Convert the input to an array.

|
|
Convert the input to an ndarray, but pass ndarray subclasses through.

|
|
Return a contiguous array (ndim >= 1) in memory (C order).

|
|
Interpret the input as a matrix.

|
|
Return an array copy of the given object.

|
|
Interpret a buffer as a 1-dimensional array.

|
|
Create a NumPy array from an object implementing the

|
|
Construct an array from data in a text or binary file.

|
|
Construct an array by executing a function over each coordinate.

|
|
Create a new 1-dimensional array from an iterable object.

|
|
A new 1-D array initialized from text data in a string.

|
|
Load data from a text file.

|
## Creating record arrays (`numpy.rec`
)[#](#creating-record-arrays-numpy-rec)
Note

`numpy.rec`
is the preferred alias for
`numpy.core.records`
.
|
Construct a record array from a wide-variety of objects.

|
|
Create a record array from a (flat) list of arrays

|
|
Create a recarray from a list of records in text form.

|
|
Create a record array from binary data

|
|
Create an array from binary file data

|
## Creating character arrays (`numpy.char`
)[#](#creating-character-arrays-numpy-char)
`numpy.char`
Note

[ numpy.char](routines.char.html#module-numpy.char) is the preferred alias for
`numpy.core.defchararray`
.
|
Create a

|
|
Convert the input to a

|
## Numerical ranges[#](#numerical-ranges)
|
Return evenly spaced values within a given interval.

|
|
Return evenly spaced numbers over a specified interval.

|
|
Return numbers spaced evenly on a log scale.

|
|
Return numbers spaced evenly on a log scale (a geometric progression).

|
|
Return a list of coordinate matrices from coordinate vectors.

|
An instance which returns a dense multi-dimensional "meshgrid".

|
An instance which returns an open multi-dimensional "meshgrid".

|
## Building matrices[#](#building-matrices)
|
Extract a diagonal or construct a diagonal array.

|
|
Create a two-dimensional array with the flattened input as a diagonal.

|
|
An array with ones at and below the given diagonal and zeros elsewhere.

|
|
Lower triangle of an array.

|
|
Upper triangle of an array.

|
|
Generate a Vandermonde matrix.

|
## The Matrix class[#](#the-matrix-class)
|
Interpret the input as a matrix.

|
|
Build a matrix object from a string, nested sequence, or array.

|# numpy.expand_dims[#](#numpy-expand-dims)
numpy.expand_dims(*a*,*axis*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L512-L602)[#](#numpy.expand_dims)
-
Expand the shape of an array.

Insert a new axis that will appear at the

*axis*position in the expanded array shape.Parameters:
-
**a**array_like
Input array.

**axis**int or tuple of ints
Position in the expanded axes where the new axis (or axes) is placed.

Deprecated since version 1.13.0: Passing an axis where

`axis > a.ndim`
will be treated as`axis == a.ndim`
, and passing`axis < -a.ndim - 1`
will be treated as`axis == 0`
. This behavior is deprecated.Changed in version 1.18.0: A tuple of axes is now supported. Out of range axes as described above are now forbidden and raise an

`AxisError`
.
Returns:
-
**result**ndarray
View of

*a*with the number of dimensions increased.
See also

`squeeze`
The inverse operation, removing singleton dimensions

`reshape`
Insert, remove, and combine dimensions, and resize existing ones

`doc.indexing`
,,`atleast_1d`
,`atleast_2d`
`atleast_3d`
Examples

>>> x = np.array([1, 2]) >>> x.shape (2,)
The following is equivalent to

`x[np.newaxis, :]`
or`x[np.newaxis]`
:>>> y = np.expand_dims(x, axis=0) >>> y array([[1, 2]]) >>> y.shape (1, 2)
The following is equivalent to

`x[:, np.newaxis]`
:>>> y = np.expand_dims(x, axis=1) >>> y array([[1], [2]]) >>> y.shape (2, 1)
`axis`
may also be a tuple:>>> y = np.expand_dims(x, axis=(0, 1)) >>> y array([[[1, 2]]])
>>> y = np.expand_dims(x, axis=(2, 0)) >>> y array([[[1], [2]]])
Note that some examples may use

`None`
instead of`np.newaxis`
. These are the same objects:>>> np.newaxis is None True# numpy.genfromtxt[#](#numpy-genfromtxt)
numpy.genfromtxt(*fname*,*dtype=<class 'float'>*,*comments='#'*,*delimiter=None*,*skip_header=0*,*skip_footer=0*,*converters=None*,*missing_values=None*,*filling_values=None*,*usecols=None*,*names=None*,*excludelist=None*,*deletechars=" !#$%&'()*+*,*-./:;<=>?@[\\]^{|}~"*,*replace_space='_'*,*autostrip=False*,*case_sensitive=True*,*defaultfmt='f%i'*,*unpack=None*,*usemask=False*,*loose=True*,*invalid_raise=True*,*max_rows=None*,*encoding='bytes'*,***,*ndmin=0*,*like=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/npyio.py#L1742-L2474)[#](#numpy.genfromtxt)
-
Load data from a text file, with missing values handled as specified.

Each line past the first

*skip_header*lines is split at the*delimiter*character, and characters following the*comments*character are discarded.Parameters:
-
**fname**file, str, pathlib.Path, list of str, generator
File, filename, list, or generator to read. If the filename extension is

`.gz`
or`.bz2`
, the file is first decompressed. Note that generators must return bytes or strings. The strings in a list or produced by a generator are treated as lines.
**dtype**dtype, optional
Data type of the resulting array. If None, the dtypes will be determined by the contents of each column, individually.

**comments**str, optional
The character used to indicate the start of a comment. All the characters occurring on a line after a comment are discarded.

**delimiter**str, int, or sequence, optional
The string used to separate values. By default, any consecutive whitespaces act as delimiter. An integer or sequence of integers can also be provided as width(s) of each field.

**skiprows**int, optional
*skiprows*was removed in numpy 1.10. Please use*skip_header*instead.
**skip_header**int, optional
The number of lines to skip at the beginning of the file.

**skip_footer**int, optional
The number of lines to skip at the end of the file.

**converters**variable, optional
The set of functions that convert the data of a column to a value. The converters can also be used to provide a default value for missing data:

`converters = {3: lambda s: float(s or 0)}`
.
**missing**variable, optional
*missing*was removed in numpy 1.10. Please use*missing_values*instead.
**missing_values**variable, optional
The set of strings corresponding to missing data.

**filling_values**variable, optional
The set of values to be used as default when the data are missing.

**usecols**sequence, optional
Which columns to read, with 0 being the first. For example,

`usecols = (1, 4, 5)`
will extract the 2nd, 5th and 6th columns.
**names**{None, True, str, sequence}, optional
If

*names*is True, the field names are read from the first line after the first*skip_header*lines. This line can optionally be preceded by a comment delimiter. If*names*is a sequence or a single-string of comma-separated names, the names will be used to define the field names in a structured dtype. If*names*is None, the names of the dtype fields will be used, if any.
**excludelist**sequence, optional
A list of names to exclude. This list is appended to the default list [‘return’,’file’,’print’]. Excluded names are appended with an underscore: for example,

*file*would become*file_*.
**deletechars**str, optional
A string combining invalid characters that must be deleted from the names.

**defaultfmt**str, optional
A format used to define default field names, such as “f%i” or “f_%02i”.

**autostrip**bool, optional
Whether to automatically strip white spaces from the variables.

**replace_space**char, optional
Character(s) used in replacement of white spaces in the variable names. By default, use a ‘_’.

**case_sensitive**{True, False, ‘upper’, ‘lower’}, optional
If True, field names are case sensitive. If False or ‘upper’, field names are converted to upper case. If ‘lower’, field names are converted to lower case.

**unpack**bool, optional
If True, the returned array is transposed, so that arguments may be unpacked using

`x, y, z = genfromtxt(...)`
. When used with a structured data-type, arrays are returned for each field. Default is False.
**usemask**bool, optional
If True, return a masked array. If False, return a regular array.

**loose**bool, optional
If True, do not raise errors for invalid values.

**invalid_raise**bool, optional
If True, an exception is raised if an inconsistency is detected in the number of columns. If False, a warning is emitted and the offending lines are skipped.

**max_rows**int, optional
The maximum number of rows to read. Must not be used with skip_footer at the same time. If given, the value must be at least 1. Default is to read the entire file.

New in version 1.10.0.

**encoding**str, optional
Encoding used to decode the inputfile. Does not apply when

*fname*is a file object. The special value ‘bytes’ enables backward compatibility workarounds that ensure that you receive byte arrays when possible and passes latin1 encoded strings to converters. Override this value to receive unicode arrays and pass strings as input to converters. If set to None the system default is used. The default value is ‘bytes’.New in version 1.14.0.

**ndmin**int, optional
Same parameter as

`loadtxt`
New in version 1.23.0.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**out**ndarray
Data read from the text file. If

*usemask*is True, this is a masked array.
See also

`numpy.loadtxt`
equivalent function when no data is missing.

Notes

When spaces are used as delimiters, or when no delimiter has been given as input, there should not be any missing data between two fields.

When the variables are named (either by a flexible dtype or with

*names*), there must not be any header in the file (else a ValueError exception is raised).
Individual values are not stripped of spaces by default. When using a custom converter, make sure the function does remove spaces.

References

[1]NumPy User Guide, section

[I/O with NumPy](https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html).Examples

>>> from io import StringIO >>> import numpy as np
Comma delimited file with mixed dtype

>>> s = StringIO(u"1,1.3,abcde") >>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'), ... ('mystring','S5')], delimiter=",") >>> data array((1, 1.3, b'abcde'), dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])
Using dtype = None

>>> _ = s.seek(0) # needed for StringIO example only >>> data = np.genfromtxt(s, dtype=None, ... names = ['myint','myfloat','mystring'], delimiter=",") >>> data array((1, 1.3, b'abcde'), dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])
Specifying dtype and names

>>> _ = s.seek(0) >>> data = np.genfromtxt(s, dtype="i8,f8,S5", ... names=['myint','myfloat','mystring'], delimiter=",") >>> data array((1, 1.3, b'abcde'), dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])
An example with fixed-width columns

>>> s = StringIO(u"11.3abcde") >>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'], ... delimiter=[1,3,5]) >>> data array((1, 1.3, b'abcde'), dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', 'S5')])
An example to show comments

>>> f = StringIO(''' ... text,# of chars ... hello world,11 ... numpy,5''') >>> np.genfromtxt(f, dtype='S12,S12', delimiter=',') array([(b'text', b''), (b'hello world', b'11'), (b'numpy', b'5')], dtype=[('f0', 'S12'), ('f1', 'S12')])# Building from source[#](#building-from-source)
Building locally on your machine gives you complete control over build options. If you are a MacOS or Linux user familiar with using the command line, you can continue with building NumPy locally by following the instructions below.

Note

If you want to build NumPy for development purposes, please refer to
[Setting up and using your development environment](../dev/development_environment.html#development-environment) for additional information.

## Prerequisites[#](#prerequisites)
Building NumPy requires the following software installed:

Python 3.9.x or newer

Please note that the Python development headers also need to be installed, e.g., on Debian/Ubuntu one needs to install both

*python3*and*python3-dev*. On Windows and macOS this is normally not an issue.
Compilers

Much of NumPy is written in C and C++. You will need a C compiler that complies with the C99 standard, and a C++ compiler that complies with the C++17 standard.

While a FORTRAN 77 compiler is not necessary for building NumPy, it is needed to run the

`numpy.f2py`
tests. These tests are skipped if the compiler is not auto-detected.Note that NumPy is developed mainly using GNU compilers and tested on MSVC and Clang compilers. Compilers from other vendors such as Intel, Absoft, Sun, NAG, Compaq, Vast, Portland, Lahey, HP, IBM are only supported in the form of community feedback, and may not work out of the box. GCC 6.5 (and later) compilers are recommended. On ARM64 (aarch64) GCC 8.x (and later) are recommended.

Linear Algebra libraries

NumPy does not require any external linear algebra libraries to be installed. However, if these are available, NumPy’s setup script can detect them and use them for building. A number of different LAPACK library setups can be used, including optimized LAPACK libraries such as OpenBLAS or MKL. The choice and location of these libraries as well as include paths and other such build options can be specified in a

`.pc`
file, as documented in[BLAS and LAPACK](https://docs.scipy.org/doc/scipy/building/blas_lapack.html#building-blas-and-lapack).
Cython

For building NumPy, you’ll need a recent version of Cython.

The NumPy source code

Clone the repository following the instructions in

[Contributing to NumPy](../dev/index.html).
Note

Starting on version 1.26, NumPy will adopt Meson as its build system (see
[Status of numpy.distutils and migration advice](../reference/distutils_status_migration.html#distutils-status-migration) and
[Understanding Meson](https://docs.scipy.org/doc/scipy/building/understanding_meson.html) for more details.)

## Basic installation[#](#basic-installation)
To build and install NumPy from a local copy of the source code, run:

```
pip install .
```
This will install all build dependencies and use Meson to compile and install the NumPy C-extensions and Python modules. If you need more control of build options and commands, see the following sections.

To perform an in-place build that can be run from the source folder run:

```
pip install -r build_requirements.txt
pip install -e . --no-build-isolation
```
*Note: for build instructions to do development work on NumPy itself, see*
[Setting up and using your development environment](../dev/development_environment.html#development-environment).
### Advanced building with Meson[#](#advanced-building-with-meson)
Meson supports the standard environment variables `CC`
, `CXX`
and `FC`
to
select specific C, C++ and/or Fortran compilers. These environment variables are
documented in [the reference tables in the Meson docs](https://mesonbuild.com/Reference-tables.html#compiler-and-linker-flag-environment-variables).

Note that environment variables only get applied from a clean build, because
they affect the configure stage (i.e., meson setup). An incremental rebuild does
not react to changes in environment variables - you have to run
`git clean -xdf`
and do a full rebuild, or run `meson setup --reconfigure`
.

For more options including selecting compilers, setting custom compiler flags
and controlling parallelism, see [Compiler selection and customizing a build](https://docs.scipy.org/doc/scipy/building/compilers_and_options.html)
(from the SciPy documentation) and [the Meson FAQ](https://mesonbuild.com/howtox.html#set-extra-compiler-and-linker-flags-from-the-outside-when-eg-building-distro-packages).

## Testing[#](#testing)
Make sure to test your builds. To ensure everything stays in shape, see if all tests pass.

The test suite requires additional dependencies, which can easily be installed with:

```
python -m pip install -r test_requirements.txt
```
Run the full test suite with:

```
cd .. # avoid picking up the source tree
pytest --pyargs numpy
```
For detailed info on testing, see [Testing builds](../dev/development_environment.html#testing-builds).

## Accelerated BLAS/LAPACK libraries[#](#accelerated-blas-lapack-libraries)
NumPy searches for optimized linear algebra libraries such as BLAS and LAPACK.
There are specific orders for searching these libraries, as described below and
in the
[meson_options.txt](https://github.com/numpy/numpy/blob/main/meson_options.txt)
file.

## Cross compilation[#](#cross-compilation)
For cross compilation instructions, see [Cross compilation](https://docs.scipy.org/doc/scipy/building/cross_compilation.html)
and the [Meson documentation](meson).# Array objects[#](#array-objects)
NumPy provides an N-dimensional array type, the [ndarray](arrays.ndarray.html#arrays-ndarray), which describes a collection of “items” of the same
type. The items can be [indexed](arrays.indexing.html#arrays-indexing) using for
example N integers.

All ndarrays are [homogeneous](../glossary.html#term-homogeneous): every item takes up the same size
block of memory, and all blocks are interpreted in exactly the same
way. How each item in the array is to be interpreted is specified by a
separate [data-type object](arrays.dtypes.html#arrays-dtypes), one of which is associated
with every array. In addition to basic types (integers, floats,
*etc.*), the data type objects can also represent data structures.

An item extracted from an array, *e.g.*, by indexing, is represented
by a Python object whose type is one of the [array scalar types](arrays.scalars.html#arrays-scalars) built in NumPy. The array scalars allow easy manipulation
of also more complicated arrangements of data.

[The N-dimensional array (](arrays.ndarray.html)`ndarray`
)
[Scalars](arrays.scalars.html)
[Data type objects (](arrays.dtypes.html)`dtype`
)
[Indexing routines](arrays.indexing.html)
[Iterating over arrays](arrays.nditer.html)
[Standard array subclasses](arrays.classes.html)
[Masked arrays](maskedarray.html)
[The array interface protocol](arrays.interface.html)
[Datetimes and Timedeltas](arrays.datetime.html)# Indexing on `ndarrays`
[#](#indexing-on-ndarrays)
`ndarrays`
See also

[ ndarrays](../reference/generated/numpy.ndarray.html#numpy.ndarray) can be indexed using the standard Python
`x[obj]`
syntax, where *x*is the array and
*obj*the selection. There are different kinds of indexing available depending on
*obj*: basic indexing, advanced indexing and field access.
Most of the following examples show the use of indexing when
referencing data in an array. The examples work just as well
when assigning to an array. See [Assigning values to indexed arrays](#assigning-values-to-indexed-arrays) for
specific examples and explanations on how assignments work.

Note that in Python, `x[(exp1, exp2, ..., expN)]`
is equivalent to
`x[exp1, exp2, ..., expN]`
; the latter is just syntactic sugar
for the former.

## Basic indexing[#](#basic-indexing)
### Single element indexing[#](#single-element-indexing)
Single element indexing works exactly like that for other standard Python sequences. It is 0-based, and accepts negative indices for indexing from the end of the array.

```
>>> x = np.arange(10)
>>> x[2]
2
>>> x[-2]
8
```
It is not necessary to separate each dimension’s index into its own set of square brackets.

```
>>> x.shape = (2, 5) # now x is 2-dimensional
>>> x[1, 3]
8
>>> x[1, -1]
9
```
Note that if one indexes a multidimensional array with fewer indices than dimensions, one gets a subdimensional array. For example:

```
>>> x[0]
array([0, 1, 2, 3, 4])
```
That is, each index specified selects the array corresponding to the
rest of the dimensions selected. In the above example, choosing 0
means that the remaining dimension of length 5 is being left unspecified,
and that what is returned is an array of that dimensionality and size.
It must be noted that the returned array is a [view](../glossary.html#term-view), i.e., it is not a
copy of the original, but points to the same values in memory as does the
original array.
In this case, the 1-D array at the first position (0) is returned.
So using a single index on the returned array, results in a single
element being returned. That is:

```
>>> x[0][2]
2
```
So note that `x[0, 2] == x[0][2]`
though the second case is more
inefficient as a new temporary array is created after the first index
that is subsequently indexed by 2.

Note

NumPy uses C-order indexing. That means that the last index usually represents the most rapidly changing memory location, unlike Fortran or IDL, where the first index represents the most rapidly changing location in memory. This difference represents a great potential for confusion.

### Slicing and striding[#](#slicing-and-striding)
Basic slicing extends Python’s basic concept of slicing to N
dimensions. Basic slicing occurs when *obj* is a [ slice](https://docs.python.org/3/library/functions.html#slice) object
(constructed by

`start:stop:step`
notation inside of brackets), an
integer, or a tuple of slice objects and integers. [and](https://docs.python.org/3/library/constants.html#Ellipsis)
`Ellipsis`
[objects can be interspersed with these as well.](../reference/constants.html#numpy.newaxis)
`newaxis`
The simplest case of indexing with *N* integers returns an [array
scalar](../reference/arrays.scalars.html#arrays-scalars) representing the corresponding item. As in
Python, all indices are zero-based: for the *i*-th index \(n_i\),
the valid range is \(0 \le n_i < d_i\) where \(d_i\) is the
*i*-th element of the shape of the array. Negative indices are
interpreted as counting from the end of the array (*i.e.*, if
\(n_i < 0\), it means \(n_i + d_i\)).

All arrays generated by basic slicing are always [views](../glossary.html#term-view)
of the original array.

Note

NumPy slicing creates a [view](../glossary.html#term-view) instead of a copy as in the case of
built-in Python sequences such as string, tuple and list.
Care must be taken when extracting
a small portion from a large array which becomes useless after the
extraction, because the small portion extracted contains a reference
to the large original array whose memory will not be released until
all arrays derived from it are garbage-collected. In such cases an
explicit `copy()`
is recommended.

The standard rules of sequence slicing apply to basic slicing on a per-dimension basis (including using a step index). Some useful concepts to remember include:

The basic slice syntax is

`i:j:k`
where*i*is the starting index,*j*is the stopping index, and*k*is the step (\(k\neq0\)). This selects the*m*elements (in the corresponding dimension) with index values*i*,*i + k*, …,*i + (m - 1) k*where \(m = q + (r\neq0)\) and*q*and*r*are the quotient and remainder obtained by dividing*j - i*by*k*:*j - i = q k + r*, so that*i + (m - 1) k < j*. For example:>>> x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) >>> x[1:7:2] array([1, 3, 5])
Negative

*i*and*j*are interpreted as*n + i*and*n + j*where*n*is the number of elements in the corresponding dimension. Negative*k*makes stepping go towards smaller indices. From the above example:>>> x[-2:10] array([8, 9]) >>> x[-3:3:-1] array([7, 6, 5, 4])
Assume

*n*is the number of elements in the dimension being sliced. Then, if*i*is not given it defaults to 0 for*k > 0*and*n - 1*for*k < 0*. If*j*is not given it defaults to*n*for*k > 0*and*-n-1*for*k < 0*. If*k*is not given it defaults to 1. Note that`::`
is the same as`:`
and means select all indices along this axis. From the above example:>>> x[5:] array([5, 6, 7, 8, 9])
If the number of objects in the selection tuple is less than

*N*, then`:`
is assumed for any subsequent dimensions. For example:>>> x = np.array([[[1],[2],[3]], [[4],[5],[6]]]) >>> x.shape (2, 3, 1) >>> x[1:2] array([[[4], [5], [6]]])
An integer,

*i*, returns the same values as`i:i+1`
**except**the dimensionality of the returned object is reduced by 1. In particular, a selection tuple with the*p*-th element an integer (and all other entries`:`
) returns the corresponding sub-array with dimension*N - 1*. If*N = 1*then the returned object is an array scalar. These objects are explained in[Scalars](../reference/arrays.scalars.html#arrays-scalars).
If the selection tuple has all entries

`:`
except the*p*-th entry which is a slice object`i:j:k`
, then the returned array has dimension*N*formed by concatenating the sub-arrays returned by integer indexing of elements*i*,*i+k*, …,*i + (m - 1) k < j*,
Basic slicing with more than one non-

`:`
entry in the slicing tuple, acts like repeated application of slicing using a single non-`:`
entry, where the non-`:`
entries are successively taken (with all other non-`:`
entries replaced by`:`
). Thus,`x[ind1, ..., ind2,:]`
acts like`x[ind1][..., ind2, :]`
under basic slicing.Warning

The above is

**not**true for advanced indexing.
You may use slicing to set values in the array, but (unlike lists) you can never grow the array. The size of the value to be set in

`x[obj] = value`
must be (broadcastable to) the same shape as`x[obj]`
.
A slicing tuple can always be constructed as

*obj*and used in the`x[obj]`
notation. Slice objects can be used in the construction in place of the`[start:stop:step]`
notation. For example,`x[1:10:5, ::-1]`
can also be implemented as`obj = (slice(1, 10, 5), slice(None, None, -1)); x[obj]`
. This can be useful for constructing generic code that works on arrays of arbitrary dimensions. See[Dealing with variable numbers of indices within programs](#dealing-with-variable-indices)for more information.
### Dimensional indexing tools[#](#dimensional-indexing-tools)
There are some tools to facilitate the easy matching of array shapes with expressions and in assignments.

[ Ellipsis](https://docs.python.org/3/library/constants.html#Ellipsis) expands to the number of
`:`
objects needed for the
selection tuple to index all dimensions. In most cases, this means that the
length of the expanded selection tuple is `x.ndim`
. There may only be a
single ellipsis present.
From the above example:```
>>> x[..., 0]
array([[1, 2, 3],
[4, 5, 6]])
```
This is equivalent to:

```
>>> x[:, :, 0]
array([[1, 2, 3],
[4, 5, 6]])
```
Each [ newaxis](../reference/constants.html#numpy.newaxis) object in the selection tuple serves to expand
the dimensions of the resulting selection by one unit-length
dimension. The added dimension is the position of the

[object in the selection tuple.](../reference/constants.html#numpy.newaxis)
`newaxis`
[is an alias for](../reference/constants.html#numpy.newaxis)
`newaxis`
`None`
, and `None`
can be used in place of this with the same result.
From the above example:```
>>> x[:, np.newaxis, :, :].shape
(2, 1, 3, 1)
>>> x[:, None, :, :].shape
(2, 1, 3, 1)
```
This can be handy to combine two arrays in a way that otherwise would require explicit reshaping operations. For example:

```
>>> x = np.arange(5)
>>> x[:, np.newaxis] + x[np.newaxis, :]
array([[0, 1, 2, 3, 4],
[1, 2, 3, 4, 5],
[2, 3, 4, 5, 6],
[3, 4, 5, 6, 7],
[4, 5, 6, 7, 8]])
```
## Advanced indexing[#](#advanced-indexing)
Advanced indexing is triggered when the selection object, *obj*, is a
non-tuple sequence object, an [ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray) (of data type integer or bool),
or a tuple with at least one sequence object or ndarray (of data type
integer or bool). There are two types of advanced indexing: integer
and Boolean.

Advanced indexing always returns a *copy* of the data (contrast with
basic slicing that returns a [view](../glossary.html#term-view)).

Warning

The definition of advanced indexing means that `x[(1, 2, 3),]`
is
fundamentally different than `x[(1, 2, 3)]`
. The latter is
equivalent to `x[1, 2, 3]`
which will trigger basic selection while
the former will trigger advanced indexing. Be sure to understand
why this occurs.

### Integer array indexing[#](#integer-array-indexing)
Integer array indexing allows selection of arbitrary items in the array
based on their *N*-dimensional index. Each integer array represents a number
of indices into that dimension.

Negative values are permitted in the index arrays and work as they do with single indices or slices:

```
>>> x = np.arange(10, 1, -1)
>>> x
array([10, 9, 8, 7, 6, 5, 4, 3, 2])
>>> x[np.array([3, 3, 1, 8])]
array([7, 7, 9, 2])
>>> x[np.array([3, 3, -3, 8])]
array([7, 7, 4, 2])
```
If the index values are out of bounds then an `IndexError`
is thrown:

```
>>> x = np.array([[1, 2], [3, 4], [5, 6]])
>>> x[np.array([1, -1])]
array([[3, 4],
[5, 6]])
>>> x[np.array([3, 4])]
Traceback (most recent call last):
...
IndexError: index 3 is out of bounds for axis 0 with size 3
```
When the index consists of as many integer arrays as dimensions of the array being indexed, the indexing is straightforward, but different from slicing.

Advanced indices always are [broadcast](basics.broadcasting.html#basics-broadcasting) and
iterated as *one*:

```
result[i_1, ..., i_M] == x[ind_1[i_1, ..., i_M], ind_2[i_1, ..., i_M],
..., ind_N[i_1, ..., i_M]]
```
Note that the resulting shape is identical to the (broadcast) indexing array
shapes `ind_1, ..., ind_N`
. If the indices cannot be broadcast to the
same shape, an exception ```
IndexError: shape mismatch: indexing arrays could
not be broadcast together with shapes...
```
is raised.

Indexing with multidimensional index arrays tend to be more unusual uses, but they are permitted, and they are useful for some problems. We’ll start with the simplest multidimensional case:

```
>>> y = np.arange(35).reshape(5, 7)
>>> y
array([[ 0, 1, 2, 3, 4, 5, 6],
[ 7, 8, 9, 10, 11, 12, 13],
[14, 15, 16, 17, 18, 19, 20],
[21, 22, 23, 24, 25, 26, 27],
[28, 29, 30, 31, 32, 33, 34]])
>>> y[np.array([0, 2, 4]), np.array([0, 1, 2])]
array([ 0, 15, 30])
```
In this case, if the index arrays have a matching shape, and there is an
index array for each dimension of the array being indexed, the resultant
array has the same shape as the index arrays, and the values correspond
to the index set for each position in the index arrays. In this example,
the first index value is 0 for both index arrays, and thus the first value
of the resultant array is `y[0, 0]`
. The next value is `y[2, 1]`
, and
the last is `y[4, 2]`
.

If the index arrays do not have the same shape, there is an attempt to broadcast them to the same shape. If they cannot be broadcast to the same shape, an exception is raised:

```
>>> y[np.array([0, 2, 4]), np.array([0, 1])]
Traceback (most recent call last):
...
IndexError: shape mismatch: indexing arrays could not be broadcast
together with shapes (3,) (2,)
```
The broadcasting mechanism permits index arrays to be combined with scalars for other indices. The effect is that the scalar value is used for all the corresponding values of the index arrays:

```
>>> y[np.array([0, 2, 4]), 1]
array([ 1, 15, 29])
```
Jumping to the next level of complexity, it is possible to only partially index an array with index arrays. It takes a bit of thought to understand what happens in such cases. For example if we just use one index array with y:

```
>>> y[np.array([0, 2, 4])]
array([[ 0, 1, 2, 3, 4, 5, 6],
[14, 15, 16, 17, 18, 19, 20],
[28, 29, 30, 31, 32, 33, 34]])
```
It results in the construction of a new array where each value of the index array selects one row from the array being indexed and the resultant array has the resulting shape (number of index elements, size of row).

In general, the shape of the resultant array will be the concatenation of the shape of the index array (or the shape that all the index arrays were broadcast to) with the shape of any unused dimensions (those not indexed) in the array being indexed.

Example

From each row, a specific element should be selected. The row index is just
`[0, 1, 2]`
and the column index specifies the element to choose for the
corresponding row, here `[0, 1, 0]`
. Using both together the task
can be solved using advanced indexing:

```
>>> x = np.array([[1, 2], [3, 4], [5, 6]])
>>> x[[0, 1, 2], [0, 1, 0]]
array([1, 4, 5])
```
To achieve a behaviour similar to the basic slicing above, broadcasting can be
used. The function [ ix_](../reference/generated/numpy.ix_.html#numpy.ix_) can help with this broadcasting. This is best
understood with an example.

Example

From a 4x3 array the corner elements should be selected using advanced
indexing. Thus all elements for which the column is one of `[0, 2]`
and
the row is one of `[0, 3]`
need to be selected. To use advanced indexing
one needs to select all elements *explicitly*. Using the method explained
previously one could write:

```
>>> x = np.array([[ 0, 1, 2],
... [ 3, 4, 5],
... [ 6, 7, 8],
... [ 9, 10, 11]])
>>> rows = np.array([[0, 0],
... [3, 3]], dtype=np.intp)
>>> columns = np.array([[0, 2],
... [0, 2]], dtype=np.intp)
>>> x[rows, columns]
array([[ 0, 2],
[ 9, 11]])
```
However, since the indexing arrays above just repeat themselves,
broadcasting can be used (compare operations such as
`rows[:, np.newaxis] + columns`
) to simplify this:

```
>>> rows = np.array([0, 3], dtype=np.intp)
>>> columns = np.array([0, 2], dtype=np.intp)
>>> rows[:, np.newaxis]
array([[0],
[3]])
>>> x[rows[:, np.newaxis], columns]
array([[ 0, 2],
[ 9, 11]])
```
This broadcasting can also be achieved using the function [ ix_](../reference/generated/numpy.ix_.html#numpy.ix_):

```
>>> x[np.ix_(rows, columns)]
array([[ 0, 2],
[ 9, 11]])
```
Note that without the `np.ix_`
call, only the diagonal elements would
be selected:

```
>>> x[rows, columns]
array([ 0, 11])
```
This difference is the most important thing to remember about indexing with multiple advanced indices.

Example

A real-life example of where advanced indexing may be useful is for a color lookup table where we want to map the values of an image into RGB triples for display. The lookup table could have a shape (nlookup, 3). Indexing such an array with an image with shape (ny, nx) with dtype=np.uint8 (or any integer type so long as values are with the bounds of the lookup table) will result in an array of shape (ny, nx, 3) where a triple of RGB values is associated with each pixel location.

### Boolean array indexing[#](#boolean-array-indexing)
This advanced indexing occurs when *obj* is an array object of Boolean
type, such as may be returned from comparison operators. A single
boolean index array is practically identical to `x[obj.nonzero()]`
where,
as described above, [ obj.nonzero()](../reference/generated/numpy.ndarray.nonzero.html#numpy.ndarray.nonzero) returns a
tuple (of length

[) of integer index arrays showing the](../reference/generated/numpy.ndarray.ndim.html#numpy.ndarray.ndim)
`obj.ndim`
[elements of](https://docs.python.org/3/library/constants.html#True)
`True`
*obj*. However, it is faster when
`obj.shape == x.shape`
.If `obj.ndim == x.ndim`
, `x[obj]`
returns a 1-dimensional array filled with the elements of *x*
corresponding to the [ True](https://docs.python.org/3/library/constants.html#True) values of

*obj*. The search order will be
[row-major](../glossary.html#term-row-major), C-style. An index error will be raised if the shape of
*obj*does not match the corresponding dimensions of
*x*, regardless of whether those values are
[or](https://docs.python.org/3/library/constants.html#True)
`True`
[.](https://docs.python.org/3/library/constants.html#False)
`False`
A common use case for this is filtering for desired element values.
For example, one may wish to select all entries from an array which
are not [ NaN](../reference/constants.html#numpy.NaN):

```
>>> x = np.array([[1., 2.], [np.nan, 3.], [np.nan, np.nan]])
>>> x[~np.isnan(x)]
array([1., 2., 3.])
```
Or wish to add a constant to all negative elements:

```
>>> x = np.array([1., -1., -2., 3])
>>> x[x < 0] += 20
>>> x
array([ 1., 19., 18., 3.])
```
In general if an index includes a Boolean array, the result will be
identical to inserting `obj.nonzero()`
into the same position
and using the integer array indexing mechanism described above.
`x[ind_1, boolean_array, ind_2]`
is equivalent to
`x[(ind_1,) + boolean_array.nonzero() + (ind_2,)]`
.

If there is only one Boolean array and no integer indexing array present,
this is straightforward. Care must only be taken to make sure that the
boolean index has *exactly* as many dimensions as it is supposed to work
with.

In general, when the boolean array has fewer dimensions than the array being
indexed, this is equivalent to `x[b, ...]`
, which means x is indexed by b
followed by as many `:`
as are needed to fill out the rank of x. Thus the
shape of the result is one dimension containing the number of True elements of
the boolean array, followed by the remaining dimensions of the array being
indexed:

```
>>> x = np.arange(35).reshape(5, 7)
>>> b = x > 20
>>> b[:, 5]
array([False, False, False, True, True])
>>> x[b[:, 5]]
array([[21, 22, 23, 24, 25, 26, 27],
[28, 29, 30, 31, 32, 33, 34]])
```
Here the 4th and 5th rows are selected from the indexed array and combined to make a 2-D array.

Example

From an array, select all rows which sum up to less or equal two:

```
>>> x = np.array([[0, 1], [1, 1], [2, 2]])
>>> rowsum = x.sum(-1)
>>> x[rowsum <= 2, :]
array([[0, 1],
[1, 1]])
```
Combining multiple Boolean indexing arrays or a Boolean with an integer
indexing array can best be understood with the
[ obj.nonzero()](../reference/generated/numpy.ndarray.nonzero.html#numpy.ndarray.nonzero) analogy. The function

[also supports boolean arrays and will work without any surprises.](../reference/generated/numpy.ix_.html#numpy.ix_)
`ix_`
Example

Use boolean indexing to select all rows adding up to an even
number. At the same time columns 0 and 2 should be selected with an
advanced integer index. Using the [ ix_](../reference/generated/numpy.ix_.html#numpy.ix_) function this can be done
with:

```
>>> x = np.array([[ 0, 1, 2],
... [ 3, 4, 5],
... [ 6, 7, 8],
... [ 9, 10, 11]])
>>> rows = (x.sum(-1) % 2) == 0
>>> rows
array([False, True, False, True])
>>> columns = [0, 2]
>>> x[np.ix_(rows, columns)]
array([[ 3, 5],
[ 9, 11]])
```
Without the `np.ix_`
call, only the diagonal elements would be
selected.

Or without `np.ix_`
(compare the integer array examples):

```
>>> rows = rows.nonzero()[0]
>>> x[rows[:, np.newaxis], columns]
array([[ 3, 5],
[ 9, 11]])
```
Example

Use a 2-D boolean array of shape (2, 3) with four True elements to select rows from a 3-D array of shape (2, 3, 5) results in a 2-D result of shape (4, 5):

```
>>> x = np.arange(30).reshape(2, 3, 5)
>>> x
array([[[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9],
[10, 11, 12, 13, 14]],
[[15, 16, 17, 18, 19],
[20, 21, 22, 23, 24],
[25, 26, 27, 28, 29]]])
>>> b = np.array([[True, True, False], [False, True, True]])
>>> x[b]
array([[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9],
[20, 21, 22, 23, 24],
[25, 26, 27, 28, 29]])
```
### Combining advanced and basic indexing[#](#combining-advanced-and-basic-indexing)
When there is at least one slice (`:`
), ellipsis (`...`
) or [ newaxis](../reference/constants.html#numpy.newaxis)
in the index (or the array has more dimensions than there are advanced indices),
then the behaviour can be more complicated. It is like concatenating the
indexing result for each advanced index element.

In the simplest case, there is only a *single* advanced index combined with
a slice. For example:

```
>>> y = np.arange(35).reshape(5,7)
>>> y[np.array([0, 2, 4]), 1:3]
array([[ 1, 2],
[15, 16],
[29, 30]])
```
In effect, the slice and index array operation are independent. The slice operation extracts columns with index 1 and 2, (i.e. the 2nd and 3rd columns), followed by the index array operation which extracts rows with index 0, 2 and 4 (i.e the first, third and fifth rows). This is equivalent to:

```
>>> y[:, 1:3][np.array([0, 2, 4]), :]
array([[ 1, 2],
[15, 16],
[29, 30]])
```
A single advanced index can, for example, replace a slice and the result array will be the same. However, it is a copy and may have a different memory layout. A slice is preferable when it is possible. For example:

```
>>> x = np.array([[ 0, 1, 2],
... [ 3, 4, 5],
... [ 6, 7, 8],
... [ 9, 10, 11]])
>>> x[1:2, 1:3]
array([[4, 5]])
>>> x[1:2, [1, 2]]
array([[4, 5]])
```
The easiest way to understand a combination of *multiple* advanced indices may
be to think in terms of the resulting shape. There are two parts to the indexing
operation, the subspace defined by the basic indexing (excluding integers) and
the subspace from the advanced indexing part. Two cases of index combination
need to be distinguished:

The advanced indices are separated by a slice,

or`Ellipsis`
. For example`newaxis`
`x[arr1, :, arr2]`
.
The advanced indices are all next to each other. For example

`x[..., arr1, arr2, :]`
but*not*`x[arr1, :, 1]`
since`1`
is an advanced index in this regard.
In the first case, the dimensions resulting from the advanced indexing operation come first in the result array, and the subspace dimensions after that. In the second case, the dimensions from the advanced indexing operations are inserted into the result array at the same spot as they were in the initial array (the latter logic is what makes simple advanced indexing behave just like slicing).

Example

Suppose `x.shape`
is (10, 20, 30) and `ind`
is a (2, 3, 4)-shaped
indexing [ intp](../reference/arrays.scalars.html#numpy.intp) array, then

`result = x[..., ind, :]`
has
shape (10, 2, 3, 4, 30) because the (20,)-shaped subspace has been
replaced with a (2, 3, 4)-shaped broadcasted indexing subspace. If
we let *i, j, k*loop over the (2, 3, 4)-shaped subspace then
`result[..., i, j, k, :] = x[..., ind[i, j, k], :]`
. This example
produces the same result as [.](../reference/generated/numpy.ndarray.take.html#numpy.ndarray.take)
`x.take(ind, axis=-2)`
Example

Let `x.shape`
be (10, 20, 30, 40, 50) and suppose `ind_1`
and `ind_2`
can be broadcast to the shape (2, 3, 4). Then
`x[:, ind_1, ind_2]`
has shape (10, 2, 3, 4, 40, 50) because the
(20, 30)-shaped subspace from X has been replaced with the
(2, 3, 4) subspace from the indices. However,
`x[:, ind_1, :, ind_2]`
has shape (2, 3, 4, 10, 30, 50) because there
is no unambiguous place to drop in the indexing subspace, thus
it is tacked-on to the beginning. It is always possible to use
[ .transpose()](../reference/generated/numpy.ndarray.transpose.html#numpy.ndarray.transpose) to move the subspace
anywhere desired. Note that this example cannot be replicated
using

[.](../reference/generated/numpy.take.html#numpy.take)
`take`
Example

Slicing can be combined with broadcasted boolean indices:

```
>>> x = np.arange(35).reshape(5, 7)
>>> b = x > 20
>>> b
array([[False, False, False, False, False, False, False],
[False, False, False, False, False, False, False],
[False, False, False, False, False, False, False],
[ True, True, True, True, True, True, True],
[ True, True, True, True, True, True, True]])
>>> x[b[:, 5], 1:3]
array([[22, 23],
[29, 30]])
```
## Field access[#](#field-access)
See also

If the [ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray) object is a structured array the

[fields](../glossary.html#term-field)of the array can be accessed by indexing the array with strings, dictionary-like.
Indexing `x['field-name']`
returns a new [view](../glossary.html#term-view) to the array,
which is of the same shape as *x* (except when the field is a
sub-array) but of data type `x.dtype['field-name']`
and contains
only the part of the data in the specified field. Also,
[record array](../reference/arrays.classes.html#arrays-classes-rec) scalars can be “indexed” this way.

Indexing into a structured array can also be done with a list of field names,
e.g. `x[['field-name1', 'field-name2']]`
. As of NumPy 1.16, this returns a
view containing only those fields. In older versions of NumPy, it returned a
copy. See the user guide section on [Structured arrays](basics.rec.html#structured-arrays) for more
information on multifield indexing.

If the accessed field is a sub-array, the dimensions of the sub-array are appended to the shape of the result. For example:

```
>>> x = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])
>>> x['a'].shape
(2, 2)
>>> x['a'].dtype
dtype('int32')
>>> x['b'].shape
(2, 2, 3, 3)
>>> x['b'].dtype
dtype('float64')
```
## Flat Iterator indexing[#](#flat-iterator-indexing)
[ x.flat](../reference/generated/numpy.ndarray.flat.html#numpy.ndarray.flat) returns an iterator that will iterate
over the entire array (in C-contiguous style with the last index
varying the fastest). This iterator object can also be indexed using
basic slicing or advanced indexing as long as the selection object is
not a tuple. This should be clear from the fact that
[is a 1-dimensional view. It can be used for integer indexing with 1-dimensional C-style-flat indices. The shape of any returned array is therefore the shape of the integer indexing object.](../reference/generated/numpy.ndarray.flat.html#numpy.ndarray.flat)
`x.flat`
## Assigning values to indexed arrays[#](#assigning-values-to-indexed-arrays)
As mentioned, one can select a subset of an array to assign to using a single index, slices, and index and mask arrays. The value being assigned to the indexed array must be shape consistent (the same shape or broadcastable to the shape the index produces). For example, it is permitted to assign a constant to a slice:

```
>>> x = np.arange(10)
>>> x[2:7] = 1
```
or an array of the right size:

```
>>> x[2:7] = np.arange(5)
```
Note that assignments may result in changes if assigning higher types to lower types (like floats to ints) or even exceptions (assigning complex to floats or ints):

```
>>> x[1] = 1.2
>>> x[1]
1
>>> x[1] = 1.2j
Traceback (most recent call last):
...
TypeError: can't convert complex to int
```
Unlike some of the references (such as array and mask indices) assignments are always made to the original data in the array (indeed, nothing else would make sense!). Note though, that some actions may not work as one may naively expect. This particular example is often surprising to people:

```
>>> x = np.arange(0, 50, 10)
>>> x
array([ 0, 10, 20, 30, 40])
>>> x[np.array([1, 1, 3, 1])] += 1
>>> x
array([ 0, 11, 20, 31, 40])
```
Where people expect that the 1st location will be incremented by 3.
In fact, it will only be incremented by 1. The reason is that
a new array is extracted from the original (as a temporary) containing
the values at 1, 1, 3, 1, then the value 1 is added to the temporary,
and then the temporary is assigned back to the original array. Thus
the value of the array at `x[1] + 1`
is assigned to `x[1]`
three times,
rather than being incremented 3 times.

## Dealing with variable numbers of indices within programs[#](#dealing-with-variable-numbers-of-indices-within-programs)
The indexing syntax is very powerful but limiting when dealing with a variable number of indices. For example, if you want to write a function that can handle arguments with various numbers of dimensions without having to write special case code for each number of possible dimensions, how can that be done? If one supplies to the index a tuple, the tuple will be interpreted as a list of indices. For example:

```
>>> z = np.arange(81).reshape(3, 3, 3, 3)
>>> indices = (1, 1, 1, 1)
>>> z[indices]
40
```
So one can use code to construct tuples of any number of indices and then use these within an index.

Slices can be specified within programs by using the slice() function in Python. For example:

```
>>> indices = (1, 1, 1, slice(0, 2)) # same as [1, 1, 1, 0:2]
>>> z[indices]
array([39, 40])
```
Likewise, ellipsis can be specified by code by using the Ellipsis object:

```
>>> indices = (1, Ellipsis, 1) # same as [1, ..., 1]
>>> z[indices]
array([[28, 31, 34],
[37, 40, 43],
[46, 49, 52]])
```
For this reason, it is possible to use the output from the
[ np.nonzero()](../reference/generated/numpy.ndarray.nonzero.html#numpy.ndarray.nonzero) function directly as an index since
it always returns a tuple of index arrays.

Because of the special treatment of tuples, they are not automatically converted to an array as a list would be. As an example:

```
>>> z[[1, 1, 1, 1]] # produces a large array
array([[[[27, 28, 29],
[30, 31, 32], ...
>>> z[(1, 1, 1, 1)] # returns a single value
40
```
## Detailed notes[#](#detailed-notes)
These are some detailed notes, which are not of importance for day to day indexing (in no particular order):

The native NumPy indexing type is

`intp`
and may differ from the default integer array type.`intp`
is the smallest data type sufficient to safely index any array; for advanced indexing it may be faster than other types.
For advanced assignments, there is in general no guarantee for the iteration order. This means that if an element is set more than once, it is not possible to predict the final result.

An empty (tuple) index is a full scalar index into a zero-dimensional array.

`x[()]`
returns a*scalar*if`x`
is zero-dimensional and a view otherwise. On the other hand,`x[...]`
always returns a view.
If a zero-dimensional array is present in the index

*and*it is a full integer index the result will be a*scalar*and not a zero-dimensional array. (Advanced indexing is not triggered.)
When an ellipsis (

`...`
) is present but has no size (i.e. replaces zero`:`
) the result will still always be an array. A view if no advanced index is present, otherwise a copy.
The

`nonzero`
equivalence for Boolean arrays does not hold for zero dimensional boolean arrays.
When the result of an advanced indexing operation has no elements but an individual index is out of bounds, whether or not an

`IndexError`
is raised is undefined (e.g.`x[[], [123]]`
with`123`
being out of bounds).
When a

*casting*error occurs during assignment (for example updating a numerical array using a sequence of strings), the array being assigned to may end up in an unpredictable partially updated state. However, if any other error (such as an out of bounds index) occurs, the array will remain unchanged.
The memory layout of an advanced indexing result is optimized for each indexing operation and no particular memory order can be assumed.

When using a subclass (especially one which manipulates its shape), the default

`ndarray.__setitem__`
behaviour will call`__getitem__`
for*basic*indexing but not for*advanced*indexing. For such a subclass it may be preferable to call`ndarray.__setitem__`
with a*base class*ndarray view on the data. This*must*be done if the subclasses`__getitem__`
does not return views.# Array creation[#](#array-creation)
See also

## Introduction[#](#introduction)
There are 6 general mechanisms for creating arrays:

Conversion from other Python structures (i.e. lists and tuples)

Intrinsic NumPy array creation functions (e.g. arange, ones, zeros, etc.)

Replicating, joining, or mutating existing arrays

Reading arrays from disk, either from standard or custom formats

Creating arrays from raw bytes through the use of strings or buffers

Use of special library functions (e.g., random)

You can use these methods to create ndarrays or [Structured arrays](basics.rec.html#structured-arrays).
This document will cover general methods for ndarray creation.

## 1) Converting Python sequences to NumPy Arrays[#](#converting-python-sequences-to-numpy-arrays)
NumPy arrays can be defined using Python sequences such as lists and
tuples. Lists and tuples are defined using `[...]`
and `(...)`
,
respectively. Lists and tuples can define ndarray creation:

a list of numbers will create a 1D array,

a list of lists will create a 2D array,

further nested lists will create higher-dimensional arrays. In general, any array object is called an

**ndarray**in NumPy.
```
>>> a1D = np.array([1, 2, 3, 4])
>>> a2D = np.array([[1, 2], [3, 4]])
>>> a3D = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
```
When you use [ numpy.array](../reference/generated/numpy.array.html#numpy.array) to define a new array, you should
consider the

[dtype](basics.types.html)of the elements in the array, which can be specified explicitly. This feature gives you more control over the underlying data structures and how the elements are handled in C/C++ functions. If you are not careful with
`dtype`
assignments, you can get unwanted overflow, as such```
>>> a = np.array([127, 128, 129], dtype=np.int8)
>>> a
array([ 127, -128, -127], dtype=int8)
```
An 8-bit signed integer represents integers from -128 to 127.
Assigning the `int8`
array to integers outside of this range results
in overflow. This feature can often be misunderstood. If you
perform calculations with mismatching `dtypes`
, you can get unwanted
results, for example:

```
>>> a = np.array([2, 3, 4], dtype=np.uint32)
>>> b = np.array([5, 6, 7], dtype=np.uint32)
>>> c_unsigned32 = a - b
>>> print('unsigned c:', c_unsigned32, c_unsigned32.dtype)
unsigned c: [4294967293 4294967293 4294967293] uint32
>>> c_signed32 = a - b.astype(np.int32)
>>> print('signed c:', c_signed32, c_signed32.dtype)
signed c: [-3 -3 -3] int64
```
Notice when you perform operations with two arrays of the same
`dtype`
: `uint32`
, the resulting array is the same type. When you
perform operations with different `dtype`
, NumPy will
assign a new type that satisfies all of the array elements involved in
the computation, here `uint32`
and `int32`
can both be represented in
as `int64`
.

The default NumPy behavior is to create arrays in either 32 or 64-bit signed
integers (platform dependent and matches C `long`
size) or double precision
floating point numbers. If you expect your
integer arrays to be a specific type, then you need to specify the dtype while
you create the array.

## 2) Intrinsic NumPy array creation functions[#](#intrinsic-numpy-array-creation-functions)
NumPy has over 40 built-in functions for creating arrays as laid
out in the [Array creation routines](../reference/routines.array-creation.html#routines-array-creation).
These functions can be split into roughly three categories, based on the
dimension of the array they create:

1D arrays

2D arrays

ndarrays

### 1 - 1D array creation functions[#](#d-array-creation-functions)
The 1D array creation functions e.g. [ numpy.linspace](../reference/generated/numpy.linspace.html#numpy.linspace) and

[generally need at least two inputs,](../reference/generated/numpy.arange.html#numpy.arange)
`numpy.arange`
`start`
and
`stop`
.[ numpy.arange](../reference/generated/numpy.arange.html#numpy.arange) creates arrays with regularly incrementing values.
Check the documentation for complete information and examples. A few
examples are shown:
```
>>> np.arange(10)
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> np.arange(2, 10, dtype=float)
array([2., 3., 4., 5., 6., 7., 8., 9.])
>>> np.arange(2, 3, 0.1)
array([2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9])
```
Note: best practice for [ numpy.arange](../reference/generated/numpy.arange.html#numpy.arange) is to use integer start, end, and
step values. There are some subtleties regarding

`dtype`
. In the second
example, the `dtype`
is defined. In the third example, the array is
`dtype=float`
to accommodate the step size of `0.1`
. Due to roundoff error,
the `stop`
value is sometimes included.[ numpy.linspace](../reference/generated/numpy.linspace.html#numpy.linspace) will create arrays with a specified number of elements, and
spaced equally between the specified beginning and end values. For
example:
```
>>> np.linspace(1., 4., 6)
array([1. , 1.6, 2.2, 2.8, 3.4, 4. ])
```
The advantage of this creation function is that you guarantee the
number of elements and the starting and end point. The previous
`arange(start, stop, step)`
will not include the value `stop`
.

### 2 - 2D array creation functions[#](#id1)
The 2D array creation functions e.g. [ numpy.eye](../reference/generated/numpy.eye.html#numpy.eye),

[, and](../reference/generated/numpy.diag.html#numpy.diag)
`numpy.diag`
[define properties of special matrices represented as 2D arrays.](../reference/generated/numpy.vander.html#numpy.vander)
`numpy.vander`
`np.eye(n, m)`
defines a 2D identity matrix. The elements where i=j (row index and column index are equal) are 1
and the rest are 0, as such:
```
>>> np.eye(3)
array([[1., 0., 0.],
[0., 1., 0.],
[0., 0., 1.]])
>>> np.eye(3, 5)
array([[1., 0., 0., 0., 0.],
[0., 1., 0., 0., 0.],
[0., 0., 1., 0., 0.]])
```
[ numpy.diag](../reference/generated/numpy.diag.html#numpy.diag) can define either a square 2D array with given values along
the diagonal
*or*if given a 2D array returns a 1D array that is only the diagonal elements. The two array creation functions can be helpful while doing linear algebra, as such:
```
>>> np.diag([1, 2, 3])
array([[1, 0, 0],
[0, 2, 0],
[0, 0, 3]])
>>> np.diag([1, 2, 3], 1)
array([[0, 1, 0, 0],
[0, 0, 2, 0],
[0, 0, 0, 3],
[0, 0, 0, 0]])
>>> a = np.array([[1, 2], [3, 4]])
>>> np.diag(a)
array([1, 4])
```
`vander(x, n)`
defines a Vandermonde matrix as a 2D NumPy array. Each column
of the Vandermonde matrix is a decreasing power of the input 1D array or
list or tuple,
`x`
where the highest polynomial order is `n-1`
. This array creation
routine is helpful in generating linear least squares models, as such:
```
>>> np.vander(np.linspace(0, 2, 5), 2)
array([[0. , 1. ],
[0.5, 1. ],
[1. , 1. ],
[1.5, 1. ],
[2. , 1. ]])
>>> np.vander([1, 2, 3, 4], 2)
array([[1, 1],
[2, 1],
[3, 1],
[4, 1]])
>>> np.vander((1, 2, 3, 4), 4)
array([[ 1, 1, 1, 1],
[ 8, 4, 2, 1],
[27, 9, 3, 1],
[64, 16, 4, 1]])
```
### 3 - general ndarray creation functions[#](#general-ndarray-creation-functions)
The ndarray creation functions e.g. [ numpy.ones](../reference/generated/numpy.ones.html#numpy.ones),

[, and](../reference/generated/numpy.zeros.html#numpy.zeros)
`numpy.zeros`
[define arrays based upon the desired shape. The ndarray creation functions can create arrays with any dimension by specifying how many dimensions and length along that dimension in a tuple or list.](../reference/random/generated/numpy.random.Generator.random.html#numpy.random.Generator.random)
`random`
[ numpy.zeros](../reference/generated/numpy.zeros.html#numpy.zeros) will create an array filled with 0 values with the
specified shape. The default dtype is
`float64`
:```
>>> np.zeros((2, 3))
array([[0., 0., 0.],
[0., 0., 0.]])
>>> np.zeros((2, 3, 2))
array([[[0., 0.],
[0., 0.],
[0., 0.]],
[[0., 0.],
[0., 0.],
[0., 0.]]])
```
[ numpy.ones](../reference/generated/numpy.ones.html#numpy.ones) will create an array filled with 1 values. It is identical to
`zeros`
in all other respects as such:```
>>> np.ones((2, 3))
array([[1., 1., 1.],
[1., 1., 1.]])
>>> np.ones((2, 3, 2))
array([[[1., 1.],
[1., 1.],
[1., 1.]],
[[1., 1.],
[1., 1.],
[1., 1.]]])
```
The [ random](../reference/random/generated/numpy.random.Generator.random.html#numpy.random.Generator.random) method of the result of

`default_rng`
will create an array filled with random
values between 0 and 1. It is included with the [library. Below, two arrays are created with shapes (2,3) and (2,3,2), respectively. The seed is set to 42 so you can reproduce these pseudorandom numbers:](../reference/random/index.html#module-numpy.random)
`numpy.random`
```
>>> from numpy.random import default_rng
>>> default_rng(42).random((2,3))
array([[0.77395605, 0.43887844, 0.85859792],
[0.69736803, 0.09417735, 0.97562235]])
>>> default_rng(42).random((2,3,2))
array([[[0.77395605, 0.43887844],
[0.85859792, 0.69736803],
[0.09417735, 0.97562235]],
[[0.7611397 , 0.78606431],
[0.12811363, 0.45038594],
[0.37079802, 0.92676499]]])
```
[ numpy.indices](../reference/generated/numpy.indices.html#numpy.indices) will create a set of arrays (stacked as a one-higher
dimensioned array), one per dimension with each representing variation in that
dimension:
```
>>> np.indices((3,3))
array([[[0, 0, 0],
[1, 1, 1],
[2, 2, 2]],
[[0, 1, 2],
[0, 1, 2],
[0, 1, 2]]])
```
This is particularly useful for evaluating functions of multiple dimensions on a regular grid.

## 3) Replicating, joining, or mutating existing arrays[#](#replicating-joining-or-mutating-existing-arrays)
Once you have created arrays, you can replicate, join, or mutate those
existing arrays to create new arrays. When you assign an array or its
elements to a new variable, you have to explicitly [ numpy.copy](../reference/generated/numpy.copy.html#numpy.copy) the array,
otherwise the variable is a view into the original array. Consider the
following example:

```
>>> a = np.array([1, 2, 3, 4, 5, 6])
>>> b = a[:2]
>>> b += 1
>>> print('a =', a, '; b =', b)
a = [2 3 3 4 5 6] ; b = [2 3]
```
In this example, you did not create a new array. You created a variable,
`b`
that viewed the first 2 elements of `a`
. When you added 1 to `b`
you
would get the same result by adding 1 to `a[:2]`
. If you want to create a
*new* array, use the [ numpy.copy](../reference/generated/numpy.copy.html#numpy.copy) array creation routine as such:

```
>>> a = np.array([1, 2, 3, 4])
>>> b = a[:2].copy()
>>> b += 1
>>> print('a = ', a, 'b = ', b)
a = [1 2 3 4] b = [2 3]
```
For more information and examples look at [Copies and Views](quickstart.html#quickstart-copies-and-views).

There are a number of routines to join existing arrays e.g. [ numpy.vstack](../reference/generated/numpy.vstack.html#numpy.vstack),

[, and](../reference/generated/numpy.hstack.html#numpy.hstack)
`numpy.hstack`
[. Here is an example of joining four 2-by-2 arrays into a 4-by-4 array using](../reference/generated/numpy.block.html#numpy.block)
`numpy.block`
`block`
:```
>>> A = np.ones((2, 2))
>>> B = np.eye(2, 2)
>>> C = np.zeros((2, 2))
>>> D = np.diag((-3, -4))
>>> np.block([[A, B], [C, D]])
array([[ 1., 1., 1., 0.],
[ 1., 1., 0., 1.],
[ 0., 0., -3., 0.],
[ 0., 0., 0., -4.]])
```
Other routines use similar syntax to join ndarrays. Check the routine’s documentation for further examples and syntax.

## 4) Reading arrays from disk, either from standard or custom formats[#](#reading-arrays-from-disk-either-from-standard-or-custom-formats)
This is the most common case of large array creation. The details depend
greatly on the format of data on disk. This section gives general pointers on
how to handle various formats. For more detailed examples of IO look at
[How to Read and Write files](how-to-io.html#how-to-io).

### Standard Binary Formats[#](#standard-binary-formats)
Various fields have standard formats for array data. The following lists the ones with known Python libraries to read them and return NumPy arrays (there may be others for which it is possible to read and convert to NumPy arrays so check the last section as well)

```
HDF5: h5py
FITS: Astropy
```
Examples of formats that cannot be read directly but for which it is not hard to convert are those formats supported by libraries like PIL (able to read and write many image formats such as jpg, png, etc).

### Common ASCII Formats[#](#common-ascii-formats)
Delimited files such as comma separated value (csv) and tab separated
value (tsv) files are used for programs like Excel and LabView. Python
functions can read and parse these files line-by-line. NumPy has two
standard routines for importing a file with delimited data [ numpy.loadtxt](../reference/generated/numpy.loadtxt.html#numpy.loadtxt)
and

[. These functions have more involved use cases in](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)
`numpy.genfromtxt`
[Reading and writing files](how-to-io.html). A simple example given a
`simple.csv`
:```
$ cat simple.csv
x, y
0, 0
1, 1
2, 4
3, 9
```
Importing `simple.csv`
is accomplished using [ numpy.loadtxt](../reference/generated/numpy.loadtxt.html#numpy.loadtxt):

```
>>> np.loadtxt('simple.csv', delimiter = ',', skiprows = 1)
array([[0., 0.],
[1., 1.],
[2., 4.],
[3., 9.]])
```
More generic ASCII files can be read using [ scipy.io](https://docs.scipy.org/doc/scipy/reference/io.html#module-scipy.io) and

[Pandas](https://pandas.pydata.org/).
## 5) Creating arrays from raw bytes through the use of strings or buffers[#](#creating-arrays-from-raw-bytes-through-the-use-of-strings-or-buffers)
There are a variety of approaches one can use. If the file has a relatively
simple format then one can write a simple I/O library and use the NumPy
`fromfile()`
function and `.tofile()`
method to read and write NumPy arrays
directly (mind your byteorder though!) If a good C or C++ library exists that
read the data, one can wrap that library with a variety of techniques though
that certainly is much more work and requires significantly more advanced
knowledge to interface with C or C++.

## 6) Use of special library functions (e.g., SciPy, Pandas, and OpenCV)[#](#use-of-special-library-functions-e-g-scipy-pandas-and-opencv)
NumPy is the fundamental library for array containers in the Python Scientific Computing stack. Many Python libraries, including SciPy, Pandas, and OpenCV, use NumPy ndarrays as the common format for data exchange, These libraries can create, operate on, and work with NumPy arrays.# Copies and views[#](#copies-and-views)
When operating on NumPy arrays, it is possible to access the internal data
buffer directly using a [view](#view) without copying data around. This
ensures good performance but can also cause unwanted problems if the user is
not aware of how this works. Hence, it is important to know the difference
between these two terms and to know which operations return copies and
which return views.

The NumPy array is a data structure consisting of two parts:
the [contiguous](../glossary.html#term-contiguous) data buffer with the actual data elements and the
metadata that contains information about the data buffer. The metadata
includes data type, strides, and other important information that helps
manipulate the [ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray) easily. See the

[Internal organization of NumPy arrays](../dev/internals.html#numpy-internals)section for a detailed look.
## View[#](#view)
It is possible to access the array differently by just changing certain
metadata like [stride](../glossary.html#term-stride) and [dtype](../glossary.html#term-dtype) without changing the
data buffer. This creates a new way of looking at the data and these new
arrays are called views. The data buffer remains the same, so any changes made
to a view reflects in the original copy. A view can be forced through the
[ ndarray.view](../reference/generated/numpy.ndarray.view.html#numpy.ndarray.view) method.

## Copy[#](#copy)
When a new array is created by duplicating the data buffer as well as the
metadata, it is called a copy. Changes made to the copy
do not reflect on the original array. Making a copy is slower and
memory-consuming but sometimes necessary. A copy can be forced by using
[ ndarray.copy](../reference/generated/numpy.ndarray.copy.html#numpy.ndarray.copy).

## Indexing operations[#](#indexing-operations)
See also

Views are created when elements can be addressed with offsets and strides in the original array. Hence, basic indexing always creates views. For example:

```
>>> x = np.arange(10)
>>> x
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> y = x[1:3] # creates a view
>>> y
array([1, 2])
>>> x[1:3] = [10, 11]
>>> x
array([ 0, 10, 11, 3, 4, 5, 6, 7, 8, 9])
>>> y
array([10, 11])
```
Here, `y`
gets changed when `x`
is changed because it is a view.

[Advanced indexing](basics.indexing.html#advanced-indexing), on the other hand, always creates copies.
For example:
```
>>> x = np.arange(9).reshape(3, 3)
>>> x
array([[0, 1, 2],
[3, 4, 5],
[6, 7, 8]])
>>> y = x[[1, 2]]
>>> y
array([[3, 4, 5],
[6, 7, 8]])
>>> y.base is None
True
```
Here, `y`
is a copy, as signified by the [ base](../reference/generated/numpy.ndarray.base.html#numpy.ndarray.base)
attribute. We can also confirm this by assigning new values to

`x[[1, 2]]`
which in turn will not affect `y`
at all:```
>>> x[[1, 2]] = [[10, 11, 12], [13, 14, 15]]
>>> x
array([[ 0, 1, 2],
[10, 11, 12],
[13, 14, 15]])
>>> y
array([[3, 4, 5],
[6, 7, 8]])
```
It must be noted here that during the assignment of `x[[1, 2]]`
no view
or copy is created as the assignment happens in-place.

## Other operations[#](#other-operations)
The [ numpy.reshape](../reference/generated/numpy.reshape.html#numpy.reshape) function creates a view where possible or a copy
otherwise. In most cases, the strides can be modified to reshape the
array with a view. However, in some cases where the array becomes
non-contiguous (perhaps after a

[operation), the reshaping cannot be done by modifying strides and requires a copy. In these cases, we can raise an error by assigning the new shape to the shape attribute of the array. For example:](../reference/generated/numpy.ndarray.transpose.html#numpy.ndarray.transpose)
`ndarray.transpose`
```
>>> x = np.ones((2, 3))
>>> y = x.T # makes the array non-contiguous
>>> y
array([[1., 1.],
[1., 1.],
[1., 1.]])
>>> z = y.view()
>>> z.shape = 6
Traceback (most recent call last):
...
AttributeError: Incompatible shape for in-place modification. Use
`.reshape()` to make a copy with the desired shape.
```
Taking the example of another operation, [ ravel](../reference/generated/numpy.ravel.html#numpy.ravel) returns a contiguous
flattened view of the array wherever possible. On the other hand,

[always returns a flattened copy of the array. However, to guarantee a view in most cases,](../reference/generated/numpy.ndarray.flatten.html#numpy.ndarray.flatten)
`ndarray.flatten`
`x.reshape(-1)`
may be preferable.## How to tell if the array is a view or a copy[#](#how-to-tell-if-the-array-is-a-view-or-a-copy)
The [ base](../reference/generated/numpy.ndarray.base.html#numpy.ndarray.base) attribute of the ndarray makes it easy
to tell if an array is a view or a copy. The base attribute of a view returns
the original array while it returns

`None`
for a copy.```
>>> x = np.arange(9)
>>> x
array([0, 1, 2, 3, 4, 5, 6, 7, 8])
>>> y = x.reshape(3, 3)
>>> y
array([[0, 1, 2],
[3, 4, 5],
[6, 7, 8]])
>>> y.base # .reshape() creates a view
array([0, 1, 2, 3, 4, 5, 6, 7, 8])
>>> z = y[[2, 1]]
>>> z
array([[6, 7, 8],
[3, 4, 5]])
>>> z.base is None # advanced indexing creates a copy
True
```
Note that the `base`
attribute should not be used to determine
if an ndarray object is *new*; only if it is a view or a copy
of another ndarray.# Polynomials[#](#polynomials)
Polynomials in NumPy can be *created*, *manipulated*, and even *fitted* using
the [convenience classes](routines.polynomials.classes.html)
of the [ numpy.polynomial](routines.polynomials.package.html#module-numpy.polynomial) package, introduced in NumPy 1.4.

Prior to NumPy 1.4, [ numpy.poly1d](generated/numpy.poly1d.html#numpy.poly1d) was the class of choice and it is still
available in order to maintain backward compatibility.
However, the newer

[is more complete and its](routines.polynomials.package.html#module-numpy.polynomial)
`polynomial package`
*convenience classes*provide a more consistent, better-behaved interface for working with polynomial expressions. Therefore
[is recommended for new coding.](routines.polynomials.package.html#module-numpy.polynomial)
`numpy.polynomial`
Note

**Terminology**
The term *polynomial module* refers to the old API defined in
`numpy.lib.polynomial`
, which includes the [ numpy.poly1d](generated/numpy.poly1d.html#numpy.poly1d) class and
the polynomial functions prefixed with

*poly*accessible from the
[namespace (e.g.](index.html#module-numpy)
`numpy`
[,](generated/numpy.polyadd.html#numpy.polyadd)
`numpy.polyadd`
[,](generated/numpy.polyval.html#numpy.polyval)
`numpy.polyval`
[, etc.).](generated/numpy.polyfit.html#numpy.polyfit)
`numpy.polyfit`
The term *polynomial package* refers to the new API defined in
[ numpy.polynomial](routines.polynomials.package.html#module-numpy.polynomial), which includes the convenience classes for the
different kinds of polynomials (

`numpy.polynomial.Polynomial`
,
`numpy.polynomial.Chebyshev`
, etc.).## Transitioning from `numpy.poly1d`
to `numpy.polynomial`
[#](#transitioning-from-numpy-poly1d-to-numpy-polynomial)
`numpy.poly1d`
`numpy.polynomial`
As noted above, the [ poly1d class](generated/numpy.poly1d.html#numpy.poly1d) and associated
functions defined in

`numpy.lib.polynomial`
, such as [and](generated/numpy.polyfit.html#numpy.polyfit)
`numpy.polyfit`
[, are considered legacy and should](generated/numpy.poly.html#numpy.poly)
`numpy.poly`
**not**be used in new code. Since NumPy version 1.4, the
[package is preferred for working with polynomials.](routines.polynomials.package.html#module-numpy.polynomial)
`numpy.polynomial`
### Quick Reference[#](#quick-reference)
The following table highlights some of the main differences between the
legacy polynomial module and the polynomial package for common tasks.
The [ Polynomial](generated/numpy.polynomial.polynomial.Polynomial.html#numpy.polynomial.polynomial.Polynomial) class is imported for brevity:

```
from numpy.polynomial import Polynomial
```
|
Legacy (

|
Create a
polynomial object
from coefficients

|
|
|
Create a polynomial object from roots

|
|
|
Fit a polynomial of
degree

|
|
|
### Transition Guide[#](#transition-guide)
There are significant differences between `numpy.lib.polynomial`
and
[ numpy.polynomial](routines.polynomials.package.html#module-numpy.polynomial).
The most significant difference is the ordering of the coefficients for the
polynomial expressions.
The various routines in

[all deal with series whose coefficients go from degree zero upward, which is the](routines.polynomials.package.html#module-numpy.polynomial)
`numpy.polynomial`
*reverse order*of the poly1d convention. The easy way to remember this is that indices correspond to degree, i.e.,
`coef[i]`
is the coefficient of the term of
degree *i*.
Though the difference in convention may be confusing, it is straightforward to
convert from the legacy polynomial API to the new.
For example, the following demonstrates how you would convert a [ numpy.poly1d](generated/numpy.poly1d.html#numpy.poly1d)
instance representing the expression \(x^{2} + 2x + 3\) to a

[instance representing the same expression:](generated/numpy.polynomial.polynomial.Polynomial.html#numpy.polynomial.polynomial.Polynomial)
`Polynomial`
```
>>> p1d = np.poly1d([1, 2, 3])
>>> p = np.polynomial.Polynomial(p1d.coef[::-1])
```
In addition to the `coef`
attribute, polynomials from the polynomial
package also have `domain`
and `window`
attributes.
These attributes are most relevant when fitting
polynomials to data, though it should be noted that polynomials with
different `domain`
and `window`
attributes are not considered equal, and
can’t be mixed in arithmetic:

```
>>> p1 = np.polynomial.Polynomial([1, 2, 3])
>>> p1
Polynomial([1., 2., 3.], domain=[-1, 1], window=[-1, 1], symbol='x')
>>> p2 = np.polynomial.Polynomial([1, 2, 3], domain=[-2, 2])
>>> p1 == p2
False
>>> p1 + p2
Traceback (most recent call last):
...
TypeError: Domains differ
```
See the documentation for the
[convenience classes](routines.polynomials.classes) for further details on
the `domain`
and `window`
attributes.

Another major difference between the legacy polynomial module and the
polynomial package is polynomial fitting. In the old module, fitting was
done via the [ polyfit](generated/numpy.polyfit.html#numpy.polyfit) function. In the polynomial package, the

[class method is preferred. For example, consider a simple linear fit to the following data:](generated/numpy.polynomial.polynomial.Polynomial.fit.html#numpy.polynomial.polynomial.Polynomial.fit)
`fit`
```
In [1]: rng = np.random.default_rng()
In [2]: x = np.arange(10)
In [3]: y = np.arange(10) + rng.standard_normal(10)
```
With the legacy polynomial module, a linear fit (i.e. polynomial of degree 1)
could be applied to these data with [ polyfit](generated/numpy.polyfit.html#numpy.polyfit):

```
In [4]: np.polyfit(x, y, deg=1)
Out[4]: array([0.89217112, 0.20829838])
```
With the new polynomial API, the [ fit](generated/numpy.polynomial.polynomial.Polynomial.fit.html#numpy.polynomial.polynomial.Polynomial.fit)
class method is preferred:

```
In [5]: p_fitted = np.polynomial.Polynomial.fit(x, y, deg=1)
In [6]: p_fitted
Out[6]: Polynomial([4.22306843, 4.01477004], domain=[0., 9.], window=[-1., 1.], symbol='x')
```
Note that the coefficients are given *in the scaled domain* defined by the
linear mapping between the `window`
and `domain`
.
[ convert](generated/numpy.polynomial.polynomial.Polynomial.convert.html#numpy.polynomial.polynomial.Polynomial.convert) can be used to get the
coefficients in the unscaled data domain.

```
In [7]: p_fitted.convert()
Out[7]: Polynomial([0.20829838, 0.89217112], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
## Documentation for the `polynomial`
Package[#](#documentation-for-the-polynomial-package)
`polynomial`
In addition to standard power series polynomials, the polynomial package
provides several additional kinds of polynomials including Chebyshev,
Hermite (two subtypes), Laguerre, and Legendre polynomials.
Each of these has an associated
*convenience class* available from the
[ numpy.polynomial](routines.polynomials.package.html#module-numpy.polynomial) namespace that provides a consistent interface for working
with polynomials regardless of their type.

Documentation pertaining to specific functions defined for each kind of polynomial individually can be found in the corresponding module documentation:

[Power Series (](routines.polynomials.polynomial.html)`numpy.polynomial.polynomial`
)
[Chebyshev Series (](routines.polynomials.chebyshev.html)`numpy.polynomial.chebyshev`
)
[Hermite Series, “Physicists” (](routines.polynomials.hermite.html)`numpy.polynomial.hermite`
)
[HermiteE Series, “Probabilists” (](routines.polynomials.hermite_e.html)`numpy.polynomial.hermite_e`
)
[Laguerre Series (](routines.polynomials.laguerre.html)`numpy.polynomial.laguerre`
)
[Legendre Series (](routines.polynomials.legendre.html)`numpy.polynomial.legendre`
)
[Polyutils](routines.polynomials.polyutils.html)# Constants[#](#module-numpy.doc.constants)
NumPy includes several constants:

numpy.Inf[#](#numpy.Inf)
-
IEEE 754 floating point representation of (positive) infinity.

Use

because`inf`
,`Inf`
,`Infinity`
and`PINF`
are aliases for`infty`
. For more details, see`inf`
.`inf`
See Also

inf

numpy.Infinity[#](#numpy.Infinity)
-
IEEE 754 floating point representation of (positive) infinity.

Use

because`inf`
,`Inf`
,`Infinity`
and`PINF`
are aliases for`infty`
. For more details, see`inf`
.`inf`
See Also

inf

numpy.NAN[#](#numpy.NAN)
-
IEEE 754 floating point representation of Not a Number (NaN).

and`NaN`
are equivalent definitions of`NAN`
. Please use`nan`
instead of`nan`
.`NAN`
See Also

nan

numpy.NINF[#](#numpy.NINF)
-
IEEE 754 floating point representation of negative infinity.

Returns

yfloat
-
A floating point representation of negative infinity.

See Also

isinf : Shows which elements are positive or negative infinity

isposinf : Shows which elements are positive infinity

isneginf : Shows which elements are negative infinity

isnan : Shows which elements are Not a Number

isfinite : Shows which elements are finite (not one of Not a Number, positive infinity and negative infinity)

Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). This means that Not a Number is not equivalent to infinity. Also that positive infinity is not equivalent to negative infinity. But infinity is equivalent to positive infinity.

Examples

>>> np.NINF -inf >>> np.log(0) -inf
numpy.NZERO[#](#numpy.NZERO)
-
IEEE 754 floating point representation of negative zero.

Returns

yfloat
-
A floating point representation of negative zero.

See Also

PZERO : Defines positive zero.

isinf : Shows which elements are positive or negative infinity.

isposinf : Shows which elements are positive infinity.

isneginf : Shows which elements are negative infinity.

isnan : Shows which elements are Not a Number.

isfiniteShows which elements are finite - not one of
-
Not a Number, positive infinity and negative infinity.

Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). Negative zero is considered to be a finite number.

Examples

>>> np.NZERO -0.0 >>> np.PZERO 0.0
>>> np.isfinite([np.NZERO]) array([ True]) >>> np.isnan([np.NZERO]) array([False]) >>> np.isinf([np.NZERO]) array([False])
numpy.NaN[#](#numpy.NaN)
-
IEEE 754 floating point representation of Not a Number (NaN).

and`NaN`
are equivalent definitions of`NAN`
. Please use`nan`
instead of`nan`
.`NaN`
See Also

nan

numpy.PINF[#](#numpy.PINF)
-
IEEE 754 floating point representation of (positive) infinity.

Use

because`inf`
,`Inf`
,`Infinity`
and`PINF`
are aliases for`infty`
. For more details, see`inf`
.`inf`
See Also

inf

numpy.PZERO[#](#numpy.PZERO)
-
IEEE 754 floating point representation of positive zero.

Returns

yfloat
-
A floating point representation of positive zero.

See Also

NZERO : Defines negative zero.

isinf : Shows which elements are positive or negative infinity.

isposinf : Shows which elements are positive infinity.

isneginf : Shows which elements are negative infinity.

isnan : Shows which elements are Not a Number.

isfiniteShows which elements are finite - not one of
-
Not a Number, positive infinity and negative infinity.

Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). Positive zero is considered to be a finite number.

Examples

>>> np.PZERO 0.0 >>> np.NZERO -0.0
>>> np.isfinite([np.PZERO]) array([ True]) >>> np.isnan([np.PZERO]) array([False]) >>> np.isinf([np.PZERO]) array([False])
numpy.e[#](#numpy.e)
-
Euler’s constant, base of natural logarithms, Napier’s constant.

`e = 2.71828182845904523536028747135266249775724709369995...`
See Also

exp : Exponential function log : Natural logarithm

References

numpy.euler_gamma[#](#numpy.euler_gamma)
-
`γ = 0.5772156649015328606065120900824024310421...`
References

numpy.inf[#](#numpy.inf)
-
IEEE 754 floating point representation of (positive) infinity.

Returns

yfloat
-
A floating point representation of positive infinity.

See Also

isinf : Shows which elements are positive or negative infinity

isposinf : Shows which elements are positive infinity

isneginf : Shows which elements are negative infinity

isnan : Shows which elements are Not a Number

isfinite : Shows which elements are finite (not one of Not a Number, positive infinity and negative infinity)

Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). This means that Not a Number is not equivalent to infinity. Also that positive infinity is not equivalent to negative infinity. But infinity is equivalent to positive infinity.

,`Inf`
,`Infinity`
and`PINF`
are aliases for`infty`
.`inf`
Examples

>>> np.inf inf >>> np.array([1]) / 0. array([ Inf])
numpy.infty[#](#numpy.infty)
-
IEEE 754 floating point representation of (positive) infinity.

Use

because`inf`
,`Inf`
,`Infinity`
and`PINF`
are aliases for`infty`
. For more details, see`inf`
.`inf`
See Also

inf

numpy.nan[#](#numpy.nan)
-
IEEE 754 floating point representation of Not a Number (NaN).

Returns

y : A floating point representation of Not a Number.

See Also

isnan : Shows which elements are Not a Number.

isfinite : Shows which elements are finite (not one of Not a Number, positive infinity and negative infinity)

Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). This means that Not a Number is not equivalent to infinity.

and`NaN`
are aliases of`NAN`
.`nan`
Examples

>>> np.nan nan >>> np.log(-1) nan >>> np.log([-1, 1, 2]) array([ NaN, 0. , 0.69314718])
numpy.newaxis[#](#numpy.newaxis)
-
A convenient alias for None, useful for indexing arrays.

Examples

>>> newaxis is None True >>> x = np.arange(3) >>> x array([0, 1, 2]) >>> x[:, newaxis] array([[0], [1], [2]]) >>> x[:, newaxis, newaxis] array([[[0]], [[1]], [[2]]]) >>> x[:, newaxis] * x array([[0, 0, 0], [0, 1, 2], [0, 2, 4]])
Outer product, same as

`outer(x, y)`
:>>> y = np.arange(3, 6) >>> x[:, newaxis] * y array([[ 0, 0, 0], [ 3, 4, 5], [ 6, 8, 10]])
`x[newaxis, :]`
is equivalent to`x[newaxis]`
and`x[None]`
:>>> x[newaxis, :].shape (1, 3) >>> x[newaxis].shape (1, 3) >>> x[None].shape (1, 3) >>> x[:, newaxis].shape (3, 1)
numpy.pi[#](#numpy.pi)
-
`pi = 3.1415926535897932384626433...`
References# Global state[#](#global-state)
NumPy has a few import-time, compile-time, or runtime options which change the global behaviour. Most of these are related to performance or for debugging purposes and will not be interesting to the vast majority of users.

## Testing planned future behavior[#](#testing-planned-future-behavior)
NumPy has some code paths which are planned to be activated in the future but are not yet the default behavior. You can try testing some of these which may be shipped with a new “major” release (NumPy 2.0) by setting an environment before importing NumPy:

NPY_NUMPY_2_BEHAVIOR=1

By default this will also activate the [NEP 50](https://numpy.org/neps/nep-0050-scalar-promotion.html#nep50) related setting
`NPY_PROMOTION_STATE`
(please see the NEP for details on this).

Changed in version 1.25.2: This variable is only checked on the first import.# Masked arrays[#](#masked-arrays)
Masked arrays are arrays that may have missing or invalid entries.
The [ numpy.ma](maskedarray.generic.html#module-numpy.ma) module provides a nearly work-alike replacement for numpy
that supports data arrays with masks.

[The](maskedarray.generic.html)`numpy.ma`
module
[Using numpy.ma](maskedarray.generic.html#using-numpy-ma)
[Examples](maskedarray.generic.html#examples)
[Constants of the](maskedarray.baseclass.html)`numpy.ma`
module
[The](maskedarray.baseclass.html#the-maskedarray-class)`MaskedArray`
class
`MaskedArray`
methods
[Masked array operations](routines.ma.html)# NumPy distutils - users guide[#](#numpy-distutils-users-guide)
Warning

`numpy.distutils`
is deprecated, and will be removed for
Python >= 3.12. For more details, see [Status of numpy.distutils and migration advice](distutils_status_migration.html#distutils-status-migration)
## SciPy structure[#](#scipy-structure)
Currently SciPy project consists of two packages:

NumPy — it provides packages like:

numpy.distutils - extension to Python distutils

numpy.f2py - a tool to bind Fortran/C codes to Python

numpy.core - future replacement of Numeric and numarray packages

numpy.lib - extra utility functions

numpy.testing - numpy-style tools for unit testing

etc

SciPy — a collection of scientific tools for Python.

The aim of this document is to describe how to add new tools to SciPy.

## Requirements for SciPy packages[#](#requirements-for-scipy-packages)
SciPy consists of Python packages, called SciPy packages, that are
available to Python users via the `scipy`
namespace. Each SciPy package
may contain other SciPy packages. And so on. Therefore, the SciPy
directory tree is a tree of packages with arbitrary depth and width.
Any SciPy package may depend on NumPy packages but the dependence on other
SciPy packages should be kept minimal or zero.

A SciPy package contains, in addition to its sources, the following files and directories:

-
`setup.py`
— building script
-
`__init__.py`
— package initializer
-
`tests/`
— directory of unittests
Their contents are described below.

## The `setup.py`
file[#](#the-setup-py-file)
In order to add a Python package to SciPy, its build script (`setup.py`
)
must meet certain requirements. The most important requirement is that the
package define a `configuration(parent_package='',top_path=None)`
function
which returns a dictionary suitable for passing to
`numpy.distutils.core.setup(..)`
. To simplify the construction of
this dictionary, `numpy.distutils.misc_util`
provides the
`Configuration`
class, described below.

### SciPy pure Python package example[#](#scipy-pure-python-package-example)
Below is an example of a minimal `setup.py`
file for a pure SciPy package:

```
#!/usr/bin/env python3
def configuration(parent_package='',top_path=None):
from numpy.distutils.misc_util import Configuration
config = Configuration('mypackage',parent_package,top_path)
return config
if __name__ == "__main__":
from numpy.distutils.core import setup
#setup(**configuration(top_path='').todict())
setup(configuration=configuration)
```
The arguments of the `configuration`
function specify the name of
parent SciPy package (`parent_package`
) and the directory location
of the main `setup.py`
script (`top_path`
). These arguments,
along with the name of the current package, should be passed to the
`Configuration`
constructor.

The `Configuration`
constructor has a fourth optional argument,
`package_path`
, that can be used when package files are located in
a different location than the directory of the `setup.py`
file.

Remaining `Configuration`
arguments are all keyword arguments that will
be used to initialize attributes of `Configuration`
instance. Usually, these keywords are the same as the ones that
`setup(..)`
function would expect, for example, `packages`
,
`ext_modules`
, `data_files`
, `include_dirs`
, `libraries`
,
`headers`
, `scripts`
, `package_dir`
, etc. However, the direct
specification of these keywords is not recommended as the content of
these keyword arguments will not be processed or checked for the
consistency of SciPy building system.

Finally, `Configuration`
has `.todict()`
method that returns all
the configuration data as a dictionary suitable for passing on to the
`setup(..)`
function.

`Configuration`
instance attributes[#](#configuration-instance-attributes)
In addition to attributes that can be specified via keyword arguments
to `Configuration`
constructor, `Configuration`
instance (let us
denote as `config`
) has the following attributes that can be useful
in writing setup scripts:

`config.name`
- full name of the current package. The names of parent packages can be extracted as`config.name.split('.')`
.
`config.local_path`
- path to the location of current`setup.py`
file.
`config.top_path`
- path to the location of main`setup.py`
file.
`Configuration`
instance methods[#](#configuration-instance-methods)
`config.todict()`
— returns configuration dictionary suitable for passing to`numpy.distutils.core.setup(..)`
function.
`config.paths(*paths) --- applies ``glob.glob(..)`
to items of`paths`
if necessary. Fixes`paths`
item that is relative to`config.local_path`
.
`config.get_subpackage(subpackage_name,subpackage_path=None)`
— returns a list of subpackage configurations. Subpackage is looked in the current directory under the name`subpackage_name`
but the path can be specified also via optional`subpackage_path`
argument. If`subpackage_name`
is specified as`None`
then the subpackage name will be taken the basename of`subpackage_path`
. Any`*`
used for subpackage names are expanded as wildcards.
`config.add_subpackage(subpackage_name,subpackage_path=None)`
— add SciPy subpackage configuration to the current one. The meaning and usage of arguments is explained above, see`config.get_subpackage()`
method.
`config.add_data_files(*files)`
— prepend`files`
to`data_files`
list. If`files`
item is a tuple then its first element defines the suffix of where data files are copied relative to package installation directory and the second element specifies the path to data files. By default data files are copied under package installation directory. For example,config.add_data_files('foo.dat', ('fun',['gun.dat','nun/pun.dat','/tmp/sun.dat']), 'bar/car.dat'. '/full/path/to/can.dat', )
will install data files to the following locations

<installation path of config.name package>/ foo.dat fun/ gun.dat pun.dat sun.dat bar/ car.dat can.dat
Path to data files can be a function taking no arguments and returning path(s) to data files – this is a useful when data files are generated while building the package. (XXX: explain the step when this function are called exactly)

`config.add_data_dir(data_path)`
— add directory`data_path`
recursively to`data_files`
. The whole directory tree starting at`data_path`
will be copied under package installation directory. If`data_path`
is a tuple then its first element defines the suffix of where data files are copied relative to package installation directory and the second element specifies the path to data directory. By default, data directory are copied under package installation directory under the basename of`data_path`
. For example,config.add_data_dir('fun') # fun/ contains foo.dat bar/car.dat config.add_data_dir(('sun','fun')) config.add_data_dir(('gun','/full/path/to/fun'))
will install data files to the following locations

<installation path of config.name package>/ fun/ foo.dat bar/ car.dat sun/ foo.dat bar/ car.dat gun/ foo.dat bar/ car.dat
`config.add_include_dirs(*paths)`
— prepend`paths`
to`include_dirs`
list. This list will be visible to all extension modules of the current package.
`config.add_headers(*files)`
— prepend`files`
to`headers`
list. By default, headers will be installed under`<prefix>/include/pythonX.X/<config.name.replace('.','/')>/`
directory. If`files`
item is a tuple then it’s first argument specifies the installation suffix relative to`<prefix>/include/pythonX.X/`
path. This is a Python distutils method; its use is discouraged for NumPy and SciPy in favour of`config.add_data_files(*files)`
.
`config.add_scripts(*files)`
— prepend`files`
to`scripts`
list. Scripts will be installed under`<prefix>/bin/`
directory.
`config.add_extension(name,sources,**kw)`
— create and add an`Extension`
instance to`ext_modules`
list. The first argument`name`
defines the name of the extension module that will be installed under`config.name`
package. The second argument is a list of sources.`add_extension`
method takes also keyword arguments that are passed on to the`Extension`
constructor. The list of allowed keywords is the following:`include_dirs`
,`define_macros`
,`undef_macros`
,`library_dirs`
,`libraries`
,`runtime_library_dirs`
,`extra_objects`
,`extra_compile_args`
,`extra_link_args`
,`export_symbols`
,`swig_opts`
,`depends`
,`language`
,`f2py_options`
,`module_dirs`
,`extra_info`
,`extra_f77_compile_args`
,`extra_f90_compile_args`
.Note that

`config.paths`
method is applied to all lists that may contain paths.`extra_info`
is a dictionary or a list of dictionaries that content will be appended to keyword arguments. The list`depends`
contains paths to files or directories that the sources of the extension module depend on. If any path in the`depends`
list is newer than the extension module, then the module will be rebuilt.The list of sources may contain functions (‘source generators’) with a pattern

`def <funcname>(ext, build_dir): return <source(s) or None>`
. If`funcname`
returns`None`
, no sources are generated. And if the`Extension`
instance has no sources after processing all source generators, no extension module will be built. This is the recommended way to conditionally define extension modules. Source generator functions are called by the`build_src`
sub-command of`numpy.distutils`
.For example, here is a typical source generator function:

def generate_source(ext,build_dir): import os from distutils.dep_util import newer target = os.path.join(build_dir,'somesource.c') if newer(target,__file__): # create target file return target
The first argument contains the Extension instance that can be useful to access its attributes like

`depends`
,`sources`
, etc. lists and modify them during the building process. The second argument gives a path to a build directory that must be used when creating files to a disk.
`config.add_library(name, sources, **build_info)`
— add a library to`libraries`
list. Allowed keywords arguments are`depends`
,`macros`
,`include_dirs`
,`extra_compiler_args`
,`f2py_options`
,`extra_f77_compile_args`
,`extra_f90_compile_args`
. See`.add_extension()`
method for more information on arguments.
`config.have_f77c()`
— return True if Fortran 77 compiler is available (read: a simple Fortran 77 code compiled successfully).
`config.have_f90c()`
— return True if Fortran 90 compiler is available (read: a simple Fortran 90 code compiled successfully).
`config.get_version()`
— return version string of the current package,`None`
if version information could not be detected. This methods scans files`__version__.py`
,`<packagename>_version.py`
,`version.py`
,`__svn_version__.py`
for string variables`version`
,`__version__`
,`<packagename>_version`
.
`config.make_svn_version_py()`
— appends a data function to`data_files`
list that will generate`__svn_version__.py`
file to the current package directory. The file will be removed from the source directory when Python exits.
`config.get_build_temp_dir()`
— return a path to a temporary directory. This is the place where one should build temporary files.
`config.get_distribution()`
— return distutils`Distribution`
instance.
`config.get_config_cmd()`
— returns`numpy.distutils`
config command instance.
`config.get_info(*names)`
—
### Conversion of `.src`
files using Templates[#](#conversion-of-src-files-using-templates)
NumPy distutils supports automatic conversion of source files named <somefile>.src. This facility can be used to maintain very similar code blocks requiring only simple changes between blocks. During the build phase of setup, if a template file named <somefile>.src is encountered, a new file named <somefile> is constructed from the template and placed in the build directory to be used instead. Two forms of template conversion are supported. The first form occurs for files named <file>.ext.src where ext is a recognized Fortran extension (f, f90, f95, f77, for, ftn, pyf). The second form is used for all other cases.

### Fortran files[#](#fortran-files)
This template converter will replicate all **function** and
**subroutine** blocks in the file with names that contain ‘<…>’
according to the rules in ‘<…>’. The number of comma-separated words
in ‘<…>’ determines the number of times the block is repeated. What
these words are indicates what that repeat rule, ‘<…>’, should be
replaced with in each block. All of the repeat rules in a block must
contain the same number of comma-separated words indicating the number
of times that block should be repeated. If the word in the repeat rule
needs a comma, leftarrow, or rightarrow, then prepend it with a
backslash ‘ '. If a word in the repeat rule matches ‘ \<index>’ then
it will be replaced with the <index>-th word in the same repeat
specification. There are two forms for the repeat rule: named and
short.

#### Named repeat rule[#](#named-repeat-rule)
A named repeat rule is useful when the same set of repeats must be
used several times in a block. It is specified using <rule1=item1,
item2, item3,…, itemN>, where N is the number of times the block
should be repeated. On each repeat of the block, the entire
expression, ‘<…>’ will be replaced first with item1, and then with
item2, and so forth until N repeats are accomplished. Once a named
repeat specification has been introduced, the same repeat rule may be
used **in the current block** by referring only to the name
(i.e. <rule1>).

#### Short repeat rule[#](#short-repeat-rule)
A short repeat rule looks like <item1, item2, item3, …, itemN>. The rule specifies that the entire expression, ‘<…>’ should be replaced first with item1, and then with item2, and so forth until N repeats are accomplished.

#### Pre-defined names[#](#pre-defined-names)
The following predefined named repeat rules are available:

<prefix=s,d,c,z>

<_c=s,d,c,z>

<_t=real, double precision, complex, double complex>

<ftype=real, double precision, complex, double complex>

<ctype=float, double, complex_float, complex_double>

<ftypereal=float, double precision, \0, \1>

<ctypereal=float, double, \0, \1>

### Other files[#](#other-files)
Non-Fortran files use a separate syntax for defining template blocks that should be repeated using a variable expansion similar to the named repeat rules of the Fortran-specific repeats.

NumPy Distutils preprocesses C source files (extension: `.c.src`
) written
in a custom templating language to generate C code. The `@`
symbol is
used to wrap macro-style variables to empower a string substitution mechanism
that might describe (for instance) a set of data types.

The template language blocks are delimited by `/**begin repeat`
and `/**end repeat**/`
lines, which may also be nested using
consecutively numbered delimiting lines such as `/**begin repeat1`
and `/**end repeat1**/`
:

`/**begin repeat`
on a line by itself marks the beginning of a segment that should be repeated.
Named variable expansions are defined using

`#name=item1, item2, item3, ..., itemN#`
and placed on successive lines. These variables are replaced in each repeat block with corresponding word. All named variables in the same repeat block must define the same number of words.
In specifying the repeat rule for a named variable,

`item*N`
is short- hand for`item, item, ..., item`
repeated N times. In addition, parenthesis in combination with`*N`
can be used for grouping several items that should be repeated. Thus,`#name=(item1, item2)*4#`
is equivalent to`#name=item1, item2, item1, item2, item1, item2, item1, item2#`
.
`*/`
on a line by itself marks the end of the variable expansion naming. The next line is the first line that will be repeated using the named rules.
Inside the block to be repeated, the variables that should be expanded are specified as

`@name@`
.
`/**end repeat**/`
on a line by itself marks the previous line as the last line of the block to be repeated.
A loop in the NumPy C source code may have a

`@TYPE@`
variable, targeted for string substitution, which is preprocessed to a number of otherwise identical loops with several strings such as`INT`
,`LONG`
,`UINT`
,`ULONG`
. The`@TYPE@`
style syntax thus reduces code duplication and maintenance burden by mimicking languages that have generic type support.
The above rules may be clearer in the following template source example:

```
1 /* TIMEDELTA to non-float types */
2
3 /**begin repeat
4 *
5 * #TOTYPE = BYTE, UBYTE, SHORT, USHORT, INT, UINT, LONG, ULONG,
6 * LONGLONG, ULONGLONG, DATETIME,
7 * TIMEDELTA#
8 * #totype = npy_byte, npy_ubyte, npy_short, npy_ushort, npy_int, npy_uint,
9 * npy_long, npy_ulong, npy_longlong, npy_ulonglong,
10 * npy_datetime, npy_timedelta#
11 */
12
13 /**begin repeat1
14 *
15 * #FROMTYPE = TIMEDELTA#
16 * #fromtype = npy_timedelta#
17 */
18 static void
19 @FROMTYPE@_to_@TOTYPE@(void *input, void *output, npy_intp n,
20 void *NPY_UNUSED(aip), void *NPY_UNUSED(aop))
21 {
22 const @fromtype@ *ip = input;
23 @totype@ *op = output;
24
25 while (n--) {
26 *op++ = (@totype@)*ip++;
27 }
28 }
29 /**end repeat1**/
30
31 /**end repeat**/
```
The preprocessing of generically-typed C source files (whether in NumPy
proper or in any third party package using NumPy Distutils) is performed
by [conv_template.py](https://github.com/numpy/numpy/blob/main/numpy/distutils/conv_template.py).
The type-specific C files generated (extension: `.c`
)
by these modules during the build process are ready to be compiled. This
form of generic typing is also supported for C header files (preprocessed
to produce `.h`
files).

### Useful functions in `numpy.distutils.misc_util`
[#](#useful-functions-in-numpy-distutils-misc-util)
`get_numpy_include_dirs()`
— return a list of NumPy base include directories. NumPy base include directories contain header files such as`numpy/arrayobject.h`
,`numpy/funcobject.h`
etc. For installed NumPy the returned list has length 1 but when building NumPy the list may contain more directories, for example, a path to`config.h`
file that`numpy/base/setup.py`
file generates and is used by`numpy`
header files.
`append_path(prefix,path)`
— smart append`path`
to`prefix`
.
`gpaths(paths, local_path='')`
— apply glob to paths and prepend`local_path`
if needed.
`njoin(*path)`
— join pathname components + convert`/`
-separated path to`os.sep`
-separated path and resolve`..`
,`.`
from paths. Ex.`njoin('a',['b','./c'],'..','g') -> os.path.join('a','b','g')`
.
`minrelpath(path)`
— resolves dots in`path`
.
`rel_path(path, parent_path)`
— return`path`
relative to`parent_path`
.
`def get_cmd(cmdname,_cache={})`
— returns`numpy.distutils`
command instance.
`all_strings(lst)`
`has_f_sources(sources)`
`has_cxx_sources(sources)`
`filter_sources(sources)`
— return`c_sources, cxx_sources, f_sources, fmodule_sources`
`get_dependencies(sources)`
`is_local_src_dir(directory)`
`get_ext_source_files(ext)`
`get_script_files(scripts)`
`get_lib_source_files(lib)`
`get_data_files(data)`
`dot_join(*args)`
— join non-zero arguments with a dot.
`get_frame(level=0)`
— return frame object from call stack with given level.
`cyg2win32(path)`
`mingw32()`
— return`True`
when using mingw32 environment.
`terminal_has_colors()`
,`red_text(s)`
,`green_text(s)`
,`yellow_text(s)`
,`blue_text(s)`
,`cyan_text(s)`
`get_path(mod_name,parent_path=None)`
— return path of a module relative to parent_path when given. Handles also`__main__`
and`__builtin__`
modules.
`allpath(name)`
— replaces`/`
with`os.sep`
in`name`
.
`cxx_ext_match`
,`fortran_ext_match`
,`f90_ext_match`
,`f90_module_name_match`
`numpy.distutils.system_info`
module[#](#numpy-distutils-system-info-module)
`get_info(name,notfound_action=0)`
`combine_paths(*args,**kws)`
`show_all()`
`numpy.distutils.cpuinfo`
module[#](#numpy-distutils-cpuinfo-module)
`cpuinfo`
`numpy.distutils.log`
module[#](#numpy-distutils-log-module)
`set_verbosity(v)`
`numpy.distutils.exec_command`
module[#](#numpy-distutils-exec-command-module)
`get_pythonexe()`
`find_executable(exe, path=None)`
`exec_command( command, execute_in='', use_shell=None, use_tee=None, **env )`
## The `__init__.py`
file[#](#the-init-py-file)
The header of a typical SciPy `__init__.py`
is:

```
"""
Package docstring, typically with a brief description and function listing.
"""
# import functions into module namespace
from .subpackage import *
...
__all__ = [s for s in dir() if not s.startswith('_')]
from numpy.testing import Tester
test = Tester().test
bench = Tester().bench
```
## Extra features in NumPy Distutils[#](#extra-features-in-numpy-distutils)
### Specifying config_fc options for libraries in setup.py script[#](#specifying-config-fc-options-for-libraries-in-setup-py-script)
It is possible to specify config_fc options in setup.py scripts. For example, using

config.add_library(‘library’,
-
-
sources=[…], config_fc={‘noopt’:(__file__,1)})

will compile the `library`
sources without optimization flags.

It’s recommended to specify only those config_fc options in such a way that are compiler independent.

### Getting extra Fortran 77 compiler options from source[#](#getting-extra-fortran-77-compiler-options-from-source)
Some old Fortran codes need special compiler options in order to
work correctly. In order to specify compiler options per source
file, `numpy.distutils`
Fortran compiler looks for the following
pattern:

```
CF77FLAGS(<fcompiler type>) = <fcompiler f77flags>
```
in the first 20 lines of the source and use the `f77flags`
for
specified type of the fcompiler (the first character `C`
is optional).

TODO: This feature can be easily extended for Fortran 90 codes as well. Let us know if you would need such a feature.# Status of `numpy.distutils`
and migration advice[#](#status-of-numpy-distutils-and-migration-advice)
[ numpy.distutils](distutils.html#module-numpy.distutils) has been deprecated in NumPy
`1.23.0`
. It will be removed
for Python 3.12; for Python <= 3.11 it will not be removed until 2 years after
the Python 3.12 release (Oct 2025).Warning

`numpy.distutils`
is only tested with `setuptools < 60.0`
, newer
versions may break. See [Interaction of numpy.distutils with setuptools](#numpy-setuptools-interaction) for details.
## Migration advice[#](#migration-advice)
There are several build systems which are good options to migrate to. Assuming you have compiled code in your package (if not, you have several good options, e.g. the build backends offered by Poetry, Hatch or PDM) and you want to be using a well-designed, modern and reliable build system, we recommend:

[Meson](https://mesonbuild.com/), and the[meson-python](https://meson-python.readthedocs.io)build backend
[CMake](https://cmake.org/), and the[scikit-build-core](https://scikit-build-core.readthedocs.io/en/latest/)build backend
If you have modest needs (only simple Cython/C extensions; no need for Fortran,
BLAS/LAPACK, nested `setup.py`
files, or other features of
`numpy.distutils`
) and have been happy with `numpy.distutils`
so far, you
can also consider switching to `setuptools`
. Note that most functionality of
`numpy.distutils`
is unlikely to be ported to `setuptools`
.

### Moving to Meson[#](#moving-to-meson)
SciPy has moved to Meson and meson-python for its 1.9.0 release. During
this process, remaining issues with Meson’s Python support and
feature parity with `numpy.distutils`
were resolved. *Note: parity means a
large superset (because Meson is a good general-purpose build system); only
a few BLAS/LAPACK library selection niceties are missing*. SciPy uses almost
all functionality that `numpy.distutils`
offers, so if SciPy has successfully
made a release with Meson as the build system, there should be no blockers left
to migrate, and SciPy will be a good reference for other packages who are
migrating. For more details about the SciPy migration, see:

NumPy will migrate to Meson for the 1.26 release.

### Moving to CMake / scikit-build[#](#moving-to-cmake-scikit-build)
The next generation of scikit-build is called [scikit-build-core](https://scikit-build-core.readthedocs.io/en/latest/). Where the
older `scikit-build`
used `setuptools`
underneath, the rewrite does not.
Like Meson, CMake is a good general-purpose build system.

### Moving to `setuptools`
[#](#moving-to-setuptools)
For projects that only use `numpy.distutils`
for historical reasons, and do
not actually use features beyond those that `setuptools`
also supports,
moving to `setuptools`
is likely the solution which costs the least effort.
To assess that, there are the `numpy.distutils`
features that are *not*
present in `setuptools`
:

Nested

`setup.py`
files
Fortran build support

BLAS/LAPACK library support (OpenBLAS, MKL, ATLAS, Netlib LAPACK/BLAS, BLIS, 64-bit ILP interface, etc.)

Support for a few other scientific libraries, like FFTW and UMFPACK

Better MinGW support

Per-compiler build flag customization (e.g.

*-O3*and*SSE2*flags are default)
a simple user build config system, see

[site.cfg.example](https://github.com/numpy/numpy/blob/master/site.cfg.example)
SIMD intrinsics support

The most widely used feature is nested `setup.py`
files. This feature may
perhaps still be ported to `setuptools`
in the future (it needs a volunteer
though, see [gh-18588](https://github.com/numpy/numpy/issues/18588) for
status). Projects only using that feature could move to `setuptools`
after
that is done. In case a project uses only a couple of `setup.py`
files, it
also could make sense to simply aggregate all the content of those files into a
single `setup.py`
file and then move to `setuptools`
. This involves
dropping all `Configuration`
instances, and using `Extension`
instead.
E.g.,:

```
from distutils.core import setup
from distutils.extension import Extension
setup(name='foobar',
version='1.0',
ext_modules=[
Extension('foopkg.foo', ['foo.c']),
Extension('barpkg.bar', ['bar.c']),
],
)
```
For more details, see the
[setuptools documentation](https://setuptools.pypa.io/en/latest/setuptools.html)

## Interaction of `numpy.distutils`
with `setuptools`
[#](#interaction-of-numpy-distutils-with-setuptools)
It is recommended to use `setuptools < 60.0`
. Newer versions may work, but
are not guaranteed to. The reason for this is that `setuptools`
60.0 enabled
a vendored copy of `distutils`
, including backwards incompatible changes that
affect some functionality in `numpy.distutils`
.

If you are using only simple Cython or C extensions with minimal use of
`numpy.distutils`
functionality beyond nested `setup.py`
files (its most
popular feature, see [ Configuration](distutils.html#numpy.distutils.misc_util.Configuration)),
then latest

`setuptools`
is likely to continue working. In case of problems,
you can also try `SETUPTOOLS_USE_DISTUTILS=stdlib`
to avoid the backwards
incompatible changes in `setuptools`
.Whatever you do, it is recommended to put an upper bound on your `setuptools`
build requirement in `pyproject.toml`
to avoid future breakage - see
[For downstream package authors](../dev/depending_on_numpy.html#for-downstream-package-authors).NumPy and SWIG# numpy.i: a SWIG Interface File for NumPy Introduction Using numpy.i Available Typemaps NumPy Array Scalars and SWIG Helper Functions Beyond the Provided Typemaps Summary Testing the numpy.i Typemaps Introduction Testing Organization Testing Header Files Testing Source Files Testing SWIG Interface Files Testing Python Scripts# How does the CPU dispatcher work?[#](#how-does-the-cpu-dispatcher-work)
NumPy dispatcher is based on multi-source compiling, which means taking
a certain source and compiling it multiple times with different compiler
flags and also with different **C** definitions that affect the code
paths. This enables certain instruction-sets for each compiled object
depending on the required optimizations and ends with linking the
returned objects together.

This mechanism should support all compilers and it doesn’t require any compiler-specific extension, but at the same time it adds a few steps to normal compilation that are explained as follows.

## 1- Configuration[#](#configuration)
Configuring the required optimization by the user before starting to build the source files via the two command arguments as explained above:

`--cpu-baseline`
: minimal set of required optimizations.
`--cpu-dispatch`
: dispatched set of additional optimizations.
## 2- Discovering the environment[#](#discovering-the-environment)
In this part, we check the compiler and platform architecture and cache some of the intermediary results to speed up rebuilding.

## 3- Validating the requested optimizations[#](#validating-the-requested-optimizations)
By testing them against the compiler, and seeing what the compiler can support according to the requested optimizations.

## 4- Generating the main configuration header[#](#generating-the-main-configuration-header)
The generated header `_cpu_dispatch.h`
contains all the definitions and
headers of instruction-sets for the required optimizations that have been
validated during the previous step.

It also contains extra C definitions that are used for defining NumPy’s
Python-level module attributes `__cpu_baseline__`
and `__cpu_dispatch__`
.

**What is in this header?**
The example header was dynamically generated by gcc on an X86 machine.
The compiler supports `--cpu-baseline="sse sse2 sse3"`
and
`--cpu-dispatch="ssse3 sse41"`
, and the result is below.

```
// The header should be located at numpy/numpy/core/src/common/_cpu_dispatch.h
/**NOTE
** C definitions prefixed with "NPY_HAVE_" represent
** the required optimizations.
**
** C definitions prefixed with 'NPY__CPU_TARGET_' are protected and
** shouldn't be used by any NumPy C sources.
*/
/******* baseline features *******/
/** SSE **/
#define NPY_HAVE_SSE 1
#include <xmmintrin.h>
/** SSE2 **/
#define NPY_HAVE_SSE2 1
#include <emmintrin.h>
/** SSE3 **/
#define NPY_HAVE_SSE3 1
#include <pmmintrin.h>
/******* dispatch-able features *******/
#ifdef NPY__CPU_TARGET_SSSE3
/** SSSE3 **/
#define NPY_HAVE_SSSE3 1
#include <tmmintrin.h>
#endif
#ifdef NPY__CPU_TARGET_SSE41
/** SSE41 **/
#define NPY_HAVE_SSE41 1
#include <smmintrin.h>
#endif
```
**Baseline features** are the minimal set of required optimizations configured
via `--cpu-baseline`
. They have no preprocessor guards and they’re
always on, which means they can be used in any source.
Does this mean NumPy’s infrastructure passes the compiler’s flags of baseline features to all sources?

Definitely, yes. But the [dispatch-able sources](#dispatchable-sources) are
treated differently.

What if the user specifies certain **baseline features** during the
build but at runtime the machine doesn’t support even these
features? Will the compiled code be called via one of these definitions, or
maybe the compiler itself auto-generated/vectorized certain piece of code
based on the provided command line compiler flags?

During the loading of the NumPy module, there’s a validation step which detects this behavior. It will raise a Python runtime error to inform the user. This is to prevent the CPU reaching an illegal instruction error causing a segfault.

**Dispatch-able features** are our dispatched set of additional optimizations
that were configured via `--cpu-dispatch`
. They are not activated by
default and are always guarded by other C definitions prefixed with
`NPY__CPU_TARGET_`
. C definitions `NPY__CPU_TARGET_`
are only
enabled within **dispatch-able sources**.
## 5- Dispatch-able sources and configuration statements[#](#dispatch-able-sources-and-configuration-statements)
Dispatch-able sources are special **C** files that can be compiled multiple
times with different compiler flags and also with different **C**
definitions. These affect code paths to enable certain
instruction-sets for each compiled object according to “**the
configuration statements**” that must be declared between a **C**
comment`(/**/)`
and start with a special mark **@targets** at the
top of each dispatch-able source. At the same time, dispatch-able
sources will be treated as normal **C** sources if the optimization was
disabled by the command argument `--disable-optimization`
.

**What are configuration statements?**
Configuration statements are sort of keywords combined together to determine the required optimization for the dispatch-able source.

Example:

```
/*@targets avx2 avx512f vsx2 vsx3 asimd asimdhp */
// C code
```
The keywords mainly represent the additional optimizations configured
through `--cpu-dispatch`
, but it can also represent other options such as:

Target groups: pre-configured configuration statements used for managing the required optimizations from outside the dispatch-able source.

Policies: collections of options used for changing the default behaviors or forcing the compilers to perform certain things.

“baseline”: a unique keyword represents the minimal optimizations that configured through

`--cpu-baseline`
**Numpy’s infrastructure handles dispatch-able sources in four steps**:
**(A) Recognition**: Just like source templates and F2PY, the dispatch-able sources requires a special extension`*.dispatch.c`
to mark C dispatch-able source files, and for C++`*.dispatch.cpp`
or`*.dispatch.cxx`
**NOTE**: C++ not supported yet.
**(B) Parsing and validating**: In this step, the dispatch-able sources that had been filtered by the previous step are parsed and validated by the configuration statements for each one of them one by one in order to determine the required optimizations.
**(C) Wrapping**: This is the approach taken by NumPy’s infrastructure, which has proved to be sufficiently flexible in order to compile a single source multiple times with different**C**definitions and flags that affect the code paths. The process is achieved by creating a temporary**C**source for each required optimization that related to the additional optimization, which contains the declarations of the**C**definitions and includes the involved source via the**C**directive**#include**. For more clarification take a look at the following code for AVX512F :/* * this definition is used by NumPy utilities as suffixes for the * exported symbols */ #define NPY__CPU_TARGET_CURRENT AVX512F /* * The following definitions enable * definitions of the dispatch-able features that are defined within the main * configuration header. These are definitions for the implied features. */ #define NPY__CPU_TARGET_SSE #define NPY__CPU_TARGET_SSE2 #define NPY__CPU_TARGET_SSE3 #define NPY__CPU_TARGET_SSSE3 #define NPY__CPU_TARGET_SSE41 #define NPY__CPU_TARGET_POPCNT #define NPY__CPU_TARGET_SSE42 #define NPY__CPU_TARGET_AVX #define NPY__CPU_TARGET_F16C #define NPY__CPU_TARGET_FMA3 #define NPY__CPU_TARGET_AVX2 #define NPY__CPU_TARGET_AVX512F // our dispatch-able source #include "/the/absuolate/path/of/hello.dispatch.c"
**(D) Dispatch-able configuration header**: The infrastructure generates a config header for each dispatch-able source, this header mainly contains two abstract**C**macros used for identifying the generated objects, so they can be used for runtime dispatching certain symbols from the generated objects by any**C**source. It is also used for forward declarations.The generated header takes the name of the dispatch-able source after excluding the extension and replace it with

`.h`
, for example assume we have a dispatch-able source called`hello.dispatch.c`
and contains the following:// hello.dispatch.c /*@targets baseline sse42 avx512f */ #include <stdio.h> #include "numpy/utils.h" // NPY_CAT, NPY_TOSTR #ifndef NPY__CPU_TARGET_CURRENT // wrapping the dispatch-able source only happens to the additional optimizations // but if the keyword 'baseline' provided within the configuration statements, // the infrastructure will add extra compiling for the dispatch-able source by // passing it as-is to the compiler without any changes. #define CURRENT_TARGET(X) X #define NPY__CPU_TARGET_CURRENT baseline // for printing only #else // since we reach to this point, that's mean we're dealing with // the additional optimizations, so it could be SSE42 or AVX512F #define CURRENT_TARGET(X) NPY_CAT(NPY_CAT(X, _), NPY__CPU_TARGET_CURRENT) #endif // Macro 'CURRENT_TARGET' adding the current target as suffux to the exported symbols, // to avoid linking duplications, NumPy already has a macro called // 'NPY_CPU_DISPATCH_CURFX' similar to it, located at // numpy/numpy/core/src/common/npy_cpu_dispatch.h // NOTE: we tend to not adding suffixes to the baseline exported symbols void CURRENT_TARGET(simd_whoami)(const char *extra_info) { printf("I'm " NPY_TOSTR(NPY__CPU_TARGET_CURRENT) ", %s\n", extra_info); }
Now assume you attached

**hello.dispatch.c**to the source tree, then the infrastructure should generate a temporary config header called**hello.dispatch.h**that can be reached by any source in the source tree, and it should contain the following code :#ifndef NPY__CPU_DISPATCH_EXPAND_ // To expand the macro calls in this header #define NPY__CPU_DISPATCH_EXPAND_(X) X #endif // Undefining the following macros, due to the possibility of including config headers // multiple times within the same source and since each config header represents // different required optimizations according to the specified configuration // statements in the dispatch-able source that derived from it. #undef NPY__CPU_DISPATCH_BASELINE_CALL #undef NPY__CPU_DISPATCH_CALL // nothing strange here, just a normal preprocessor callback // enabled only if 'baseline' specified within the configuration statements #define NPY__CPU_DISPATCH_BASELINE_CALL(CB, ...) \ NPY__CPU_DISPATCH_EXPAND_(CB(__VA_ARGS__)) // 'NPY__CPU_DISPATCH_CALL' is an abstract macro is used for dispatching // the required optimizations that specified within the configuration statements. // // @param CHK, Expected a macro that can be used to detect CPU features // in runtime, which takes a CPU feature name without string quotes and // returns the testing result in a shape of boolean value. // NumPy already has macro called "NPY_CPU_HAVE", which fits this requirement. // // @param CB, a callback macro that expected to be called multiple times depending // on the required optimizations, the callback should receive the following arguments: // 1- The pending calls of @param CHK filled up with the required CPU features, // that need to be tested first in runtime before executing call belong to // the compiled object. // 2- The required optimization name, same as in 'NPY__CPU_TARGET_CURRENT' // 3- Extra arguments in the macro itself // // By default the callback calls are sorted depending on the highest interest // unless the policy "$keep_sort" was in place within the configuration statements // see "Dive into the CPU dispatcher" for more clarification. #define NPY__CPU_DISPATCH_CALL(CHK, CB, ...) \ NPY__CPU_DISPATCH_EXPAND_(CB((CHK(AVX512F)), AVX512F, __VA_ARGS__)) \ NPY__CPU_DISPATCH_EXPAND_(CB((CHK(SSE)&&CHK(SSE2)&&CHK(SSE3)&&CHK(SSSE3)&&CHK(SSE41)), SSE41, __VA_ARGS__))
An example of using the config header in light of the above:

// NOTE: The following macros are only defined for demonstration purposes only. // NumPy already has a collections of macros located at // numpy/numpy/core/src/common/npy_cpu_dispatch.h, that covers all dispatching // and declarations scenarios. #include "numpy/npy_cpu_features.h" // NPY_CPU_HAVE #include "numpy/utils.h" // NPY_CAT, NPY_EXPAND // An example for setting a macro that calls all the exported symbols at once // after checking if they're supported by the running machine. #define DISPATCH_CALL_ALL(FN, ARGS) \ NPY__CPU_DISPATCH_CALL(NPY_CPU_HAVE, DISPATCH_CALL_ALL_CB, FN, ARGS) \ NPY__CPU_DISPATCH_BASELINE_CALL(DISPATCH_CALL_BASELINE_ALL_CB, FN, ARGS) // The preprocessor callbacks. // The same suffixes as we define it in the dispatch-able source. #define DISPATCH_CALL_ALL_CB(CHECK, TARGET_NAME, FN, ARGS) \ if (CHECK) { NPY_CAT(NPY_CAT(FN, _), TARGET_NAME) ARGS; } #define DISPATCH_CALL_BASELINE_ALL_CB(FN, ARGS) \ FN NPY_EXPAND(ARGS); // An example for setting a macro that calls the exported symbols of highest // interest optimization, after checking if they're supported by the running machine. #define DISPATCH_CALL_HIGH(FN, ARGS) \ if (0) {} \ NPY__CPU_DISPATCH_CALL(NPY_CPU_HAVE, DISPATCH_CALL_HIGH_CB, FN, ARGS) \ NPY__CPU_DISPATCH_BASELINE_CALL(DISPATCH_CALL_BASELINE_HIGH_CB, FN, ARGS) // The preprocessor callbacks // The same suffixes as we define it in the dispatch-able source. #define DISPATCH_CALL_HIGH_CB(CHECK, TARGET_NAME, FN, ARGS) \ else if (CHECK) { NPY_CAT(NPY_CAT(FN, _), TARGET_NAME) ARGS; } #define DISPATCH_CALL_BASELINE_HIGH_CB(FN, ARGS) \ else { FN NPY_EXPAND(ARGS); } // NumPy has a macro called 'NPY_CPU_DISPATCH_DECLARE' can be used // for forward declarations any kind of prototypes based on // 'NPY__CPU_DISPATCH_CALL' and 'NPY__CPU_DISPATCH_BASELINE_CALL'. // However in this example, we just handle it manually. void simd_whoami(const char *extra_info); void simd_whoami_AVX512F(const char *extra_info); void simd_whoami_SSE41(const char *extra_info); void trigger_me(void) { // bring the auto-generated config header // which contains config macros 'NPY__CPU_DISPATCH_CALL' and // 'NPY__CPU_DISPATCH_BASELINE_CALL'. // it is highly recommended to include the config header before executing // the dispatching macros in case if there's another header in the scope. #include "hello.dispatch.h" DISPATCH_CALL_ALL(simd_whoami, ("all")) DISPATCH_CALL_HIGH(simd_whoami, ("the highest interest")) // An example of including multiple config headers in the same source // #include "hello2.dispatch.h" // DISPATCH_CALL_HIGH(another_function, ("the highest interest")) }# Iterating over arrays[#](#iterating-over-arrays)
Note

Arrays support the iterator protocol and can be iterated over like Python
lists. See the [Indexing, Slicing and Iterating](../user/quickstart.html#quickstart-indexing-slicing-and-iterating) section in
the Quickstart guide for basic usage and examples. The remainder of
this document presents the [ nditer](generated/numpy.nditer.html#numpy.nditer) object and covers more
advanced usage.

The iterator object [ nditer](generated/numpy.nditer.html#numpy.nditer), introduced in NumPy 1.6, provides
many flexible ways to visit all the elements of one or more arrays in
a systematic fashion. This page introduces some basic ways to use the
object for computations on arrays in Python, then concludes with how one
can accelerate the inner loop in Cython. Since the Python exposure of

[is a relatively straightforward mapping of the C array iterator API, these ideas will also provide help working with array iteration from C or C++.](generated/numpy.nditer.html#numpy.nditer)
`nditer`
## Single array iteration[#](#single-array-iteration)
The most basic task that can be done with the [ nditer](generated/numpy.nditer.html#numpy.nditer) is to
visit every element of an array. Each element is provided one by one
using the standard Python iterator interface.

Example

```
>>> a = np.arange(6).reshape(2,3)
>>> for x in np.nditer(a):
... print(x, end=' ')
...
0 1 2 3 4 5
```
An important thing to be aware of for this iteration is that the order is chosen to match the memory layout of the array instead of using a standard C or Fortran ordering. This is done for access efficiency, reflecting the idea that by default one simply wants to visit each element without concern for a particular ordering. We can see this by iterating over the transpose of our previous array, compared to taking a copy of that transpose in C order.

Example

```
>>> a = np.arange(6).reshape(2,3)
>>> for x in np.nditer(a.T):
... print(x, end=' ')
...
0 1 2 3 4 5
```
```
>>> for x in np.nditer(a.T.copy(order='C')):
... print(x, end=' ')
...
0 3 1 4 2 5
```
The elements of both *a* and *a.T* get traversed in the same order,
namely the order they are stored in memory, whereas the elements of
*a.T.copy(order=’C’)* get visited in a different order because they
have been put into a different memory layout.

### Controlling iteration order[#](#controlling-iteration-order)
There are times when it is important to visit the elements of an array
in a specific order, irrespective of the layout of the elements in memory.
The [ nditer](generated/numpy.nditer.html#numpy.nditer) object provides an

*order*parameter to control this aspect of iteration. The default, having the behavior described above, is order=’K’ to keep the existing order. This can be overridden with order=’C’ for C order and order=’F’ for Fortran order.
Example

```
>>> a = np.arange(6).reshape(2,3)
>>> for x in np.nditer(a, order='F'):
... print(x, end=' ')
...
0 3 1 4 2 5
>>> for x in np.nditer(a.T, order='C'):
... print(x, end=' ')
...
0 3 1 4 2 5
```
### Modifying array values[#](#modifying-array-values)
By default, the [ nditer](generated/numpy.nditer.html#numpy.nditer) treats the input operand as a read-only
object. To be able to modify the array elements, you must specify either
read-write or write-only mode using the

*‘readwrite’*or
*‘writeonly’*per-operand flags.
The nditer will then yield writeable buffer arrays which you may modify. However, because the nditer must copy this buffer data back to the original array once iteration is finished, you must signal when the iteration is ended, by one of two methods. You may either:

-
used the nditer as a context manager using the

withstatement, and the temporary data will be written back when the context is exited.
-
call the iterator’s

closemethod once finished iterating, which will trigger the write-back.
The nditer can no longer be iterated once either *close* is called or its
context is exited.

Example

```
>>> a = np.arange(6).reshape(2,3)
>>> a
array([[0, 1, 2],
[3, 4, 5]])
>>> with np.nditer(a, op_flags=['readwrite']) as it:
... for x in it:
... x[...] = 2 * x
...
>>> a
array([[ 0, 2, 4],
[ 6, 8, 10]])
```
If you are writing code that needs to support older versions of numpy,
note that prior to 1.15, [ nditer](generated/numpy.nditer.html#numpy.nditer) was not a context manager and
did not have a

*close*method. Instead it relied on the destructor to initiate the writeback of the buffer.
### Using an external loop[#](#using-an-external-loop)
In all the examples so far, the elements of *a* are provided by the
iterator one at a time, because all the looping logic is internal to the
iterator. While this is simple and convenient, it is not very efficient.
A better approach is to move the one-dimensional innermost loop into your
code, external to the iterator. This way, NumPy’s vectorized operations
can be used on larger chunks of the elements being visited.

The [ nditer](generated/numpy.nditer.html#numpy.nditer) will try to provide chunks that are
as large as possible to the inner loop. By forcing ‘C’ and ‘F’ order,
we get different external loop sizes. This mode is enabled by specifying
an iterator flag.

Observe that with the default of keeping native memory order, the iterator is able to provide a single one-dimensional chunk, whereas when forcing Fortran order, it has to provide three chunks of two elements each.

Example

```
>>> a = np.arange(6).reshape(2,3)
>>> for x in np.nditer(a, flags=['external_loop']):
... print(x, end=' ')
...
[0 1 2 3 4 5]
```
```
>>> for x in np.nditer(a, flags=['external_loop'], order='F'):
... print(x, end=' ')
...
[0 3] [1 4] [2 5]
```
### Tracking an index or multi-index[#](#tracking-an-index-or-multi-index)
During iteration, you may want to use the index of the current element in a computation. For example, you may want to visit the elements of an array in memory order, but use a C-order, Fortran-order, or multidimensional index to look up values in a different array.

The index is tracked by the iterator object itself, and accessible
through the *index* or *multi_index* properties, depending on what was
requested. The examples below show printouts demonstrating the
progression of the index:

Example

```
>>> a = np.arange(6).reshape(2,3)
>>> it = np.nditer(a, flags=['f_index'])
>>> for x in it:
... print("%d <%d>" % (x, it.index), end=' ')
...
0 <0> 1 <2> 2 <4> 3 <1> 4 <3> 5 <5>
```
```
>>> it = np.nditer(a, flags=['multi_index'])
>>> for x in it:
... print("%d <%s>" % (x, it.multi_index), end=' ')
...
0 <(0, 0)> 1 <(0, 1)> 2 <(0, 2)> 3 <(1, 0)> 4 <(1, 1)> 5 <(1, 2)>
```
```
>>> with np.nditer(a, flags=['multi_index'], op_flags=['writeonly']) as it:
... for x in it:
... x[...] = it.multi_index[1] - it.multi_index[0]
...
>>> a
array([[ 0, 1, 2],
[-1, 0, 1]])
```
Tracking an index or multi-index is incompatible with using an external
loop, because it requires a different index value per element. If
you try to combine these flags, the [ nditer](generated/numpy.nditer.html#numpy.nditer) object will
raise an exception.

Example

```
>>> a = np.zeros((2,3))
>>> it = np.nditer(a, flags=['c_index', 'external_loop'])
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
ValueError: Iterator flag EXTERNAL_LOOP cannot be used if an index or multi-index is being tracked
```
### Alternative looping and element access[#](#alternative-looping-and-element-access)
To make its properties more readily accessible during iteration,
[ nditer](generated/numpy.nditer.html#numpy.nditer) has an alternative syntax for iterating, which works
explicitly with the iterator object itself. With this looping construct,
the current value is accessible by indexing into the iterator. Other
properties, such as tracked indices remain as before. The examples below
produce identical results to the ones in the previous section.

Example

```
>>> a = np.arange(6).reshape(2,3)
>>> it = np.nditer(a, flags=['f_index'])
>>> while not it.finished:
... print("%d <%d>" % (it[0], it.index), end=' ')
... is_not_finished = it.iternext()
...
0 <0> 1 <2> 2 <4> 3 <1> 4 <3> 5 <5>
```
```
>>> it = np.nditer(a, flags=['multi_index'])
>>> while not it.finished:
... print("%d <%s>" % (it[0], it.multi_index), end=' ')
... is_not_finished = it.iternext()
...
0 <(0, 0)> 1 <(0, 1)> 2 <(0, 2)> 3 <(1, 0)> 4 <(1, 1)> 5 <(1, 2)>
```
```
>>> with np.nditer(a, flags=['multi_index'], op_flags=['writeonly']) as it:
... while not it.finished:
... it[0] = it.multi_index[1] - it.multi_index[0]
... is_not_finished = it.iternext()
...
>>> a
array([[ 0, 1, 2],
[-1, 0, 1]])
```
### Buffering the array elements[#](#buffering-the-array-elements)
When forcing an iteration order, we observed that the external loop option may provide the elements in smaller chunks because the elements can’t be visited in the appropriate order with a constant stride. When writing C code, this is generally fine, however in pure Python code this can cause a significant reduction in performance.

By enabling buffering mode, the chunks provided by the iterator to the inner loop can be made larger, significantly reducing the overhead of the Python interpreter. In the example forcing Fortran iteration order, the inner loop gets to see all the elements in one go when buffering is enabled.

Example

```
>>> a = np.arange(6).reshape(2,3)
>>> for x in np.nditer(a, flags=['external_loop'], order='F'):
... print(x, end=' ')
...
[0 3] [1 4] [2 5]
```
```
>>> for x in np.nditer(a, flags=['external_loop','buffered'], order='F'):
... print(x, end=' ')
...
[0 3 1 4 2 5]
```
### Iterating as a specific data type[#](#iterating-as-a-specific-data-type)
There are times when it is necessary to treat an array as a different data type than it is stored as. For instance, one may want to do all computations on 64-bit floats, even if the arrays being manipulated are 32-bit floats. Except when writing low-level C code, it’s generally better to let the iterator handle the copying or buffering instead of casting the data type yourself in the inner loop.

There are two mechanisms which allow this to be done, temporary copies and buffering mode. With temporary copies, a copy of the entire array is made with the new data type, then iteration is done in the copy. Write access is permitted through a mode which updates the original array after all the iteration is complete. The major drawback of temporary copies is that the temporary copy may consume a large amount of memory, particularly if the iteration data type has a larger itemsize than the original one.

Buffering mode mitigates the memory usage issue and is more cache-friendly than making temporary copies. Except for special cases, where the whole array is needed at once outside the iterator, buffering is recommended over temporary copying. Within NumPy, buffering is used by the ufuncs and other functions to support flexible inputs with minimal memory overhead.

In our examples, we will treat the input array with a complex data type, so that we can take square roots of negative numbers. Without enabling copies or buffering mode, the iterator will raise an exception if the data type doesn’t match precisely.

Example

```
>>> a = np.arange(6).reshape(2,3) - 3
>>> for x in np.nditer(a, op_dtypes=['complex128']):
... print(np.sqrt(x), end=' ')
...
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
TypeError: Iterator operand required copying or buffering, but neither copying nor buffering was enabled
```
In copying mode, ‘copy’ is specified as a per-operand flag. This is done to provide control in a per-operand fashion. Buffering mode is specified as an iterator flag.

Example

```
>>> a = np.arange(6).reshape(2,3) - 3
>>> for x in np.nditer(a, op_flags=['readonly','copy'],
... op_dtypes=['complex128']):
... print(np.sqrt(x), end=' ')
...
1.7320508075688772j 1.4142135623730951j 1j 0j (1+0j) (1.4142135623730951+0j)
```
```
>>> for x in np.nditer(a, flags=['buffered'], op_dtypes=['complex128']):
... print(np.sqrt(x), end=' ')
...
1.7320508075688772j 1.4142135623730951j 1j 0j (1+0j) (1.4142135623730951+0j)
```
The iterator uses NumPy’s casting rules to determine whether a specific conversion is permitted. By default, it enforces ‘safe’ casting. This means, for example, that it will raise an exception if you try to treat a 64-bit float array as a 32-bit float array. In many cases, the rule ‘same_kind’ is the most reasonable rule to use, since it will allow conversion from 64 to 32-bit float, but not from float to int or from complex to float.

Example

```
>>> a = np.arange(6.)
>>> for x in np.nditer(a, flags=['buffered'], op_dtypes=['float32']):
... print(x, end=' ')
...
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
TypeError: Iterator operand 0 dtype could not be cast from dtype('float64') to dtype('float32') according to the rule 'safe'
```
```
>>> for x in np.nditer(a, flags=['buffered'], op_dtypes=['float32'],
... casting='same_kind'):
... print(x, end=' ')
...
0.0 1.0 2.0 3.0 4.0 5.0
```
```
>>> for x in np.nditer(a, flags=['buffered'], op_dtypes=['int32'], casting='same_kind'):
... print(x, end=' ')
...
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
TypeError: Iterator operand 0 dtype could not be cast from dtype('float64') to dtype('int32') according to the rule 'same_kind'
```
One thing to watch out for is conversions back to the original data type when using a read-write or write-only operand. A common case is to implement the inner loop in terms of 64-bit floats, and use ‘same_kind’ casting to allow the other floating-point types to be processed as well. While in read-only mode, an integer array could be provided, read-write mode will raise an exception because conversion back to the array would violate the casting rule.

Example

```
>>> a = np.arange(6)
>>> for x in np.nditer(a, flags=['buffered'], op_flags=['readwrite'],
... op_dtypes=['float64'], casting='same_kind'):
... x[...] = x / 2.0
...
Traceback (most recent call last):
File "<stdin>", line 2, in <module>
TypeError: Iterator requested dtype could not be cast from dtype('float64') to dtype('int64'), the operand 0 dtype, according to the rule 'same_kind'
```
## Broadcasting array iteration[#](#broadcasting-array-iteration)
NumPy has a set of rules for dealing with arrays that have differing
shapes which are applied whenever functions take multiple operands
which combine element-wise. This is called
[broadcasting](../user/basics.ufuncs.html#ufuncs-broadcasting). The [ nditer](generated/numpy.nditer.html#numpy.nditer)
object can apply these rules for you when you need to write such a function.

As an example, we print out the result of broadcasting a one and a two dimensional array together.

Example

```
>>> a = np.arange(3)
>>> b = np.arange(6).reshape(2,3)
>>> for x, y in np.nditer([a,b]):
... print("%d:%d" % (x,y), end=' ')
...
0:0 1:1 2:2 0:3 1:4 2:5
```
When a broadcasting error occurs, the iterator raises an exception which includes the input shapes to help diagnose the problem.

Example

```
>>> a = np.arange(2)
>>> b = np.arange(6).reshape(2,3)
>>> for x, y in np.nditer([a,b]):
... print("%d:%d" % (x,y), end=' ')
...
Traceback (most recent call last):
...
ValueError: operands could not be broadcast together with shapes (2,) (2,3)
```
### Iterator-allocated output arrays[#](#iterator-allocated-output-arrays)
A common case in NumPy functions is to have outputs allocated based
on the broadcasting of the input, and additionally have an optional
parameter called ‘out’ where the result will be placed when it is
provided. The [ nditer](generated/numpy.nditer.html#numpy.nditer) object provides a convenient idiom that
makes it very easy to support this mechanism.

We’ll show how this works by creating a function [ square](generated/numpy.square.html#numpy.square) which squares
its input. Let’s start with a minimal function definition excluding ‘out’
parameter support.

Example

```
>>> def square(a):
... with np.nditer([a, None]) as it:
... for x, y in it:
... y[...] = x*x
... return it.operands[1]
...
>>> square([1,2,3])
array([1, 4, 9])
```
By default, the [ nditer](generated/numpy.nditer.html#numpy.nditer) uses the flags ‘allocate’ and ‘writeonly’
for operands that are passed in as None. This means we were able to provide
just the two operands to the iterator, and it handled the rest.

When adding the ‘out’ parameter, we have to explicitly provide those flags, because if someone passes in an array as ‘out’, the iterator will default to ‘readonly’, and our inner loop would fail. The reason ‘readonly’ is the default for input arrays is to prevent confusion about unintentionally triggering a reduction operation. If the default were ‘readwrite’, any broadcasting operation would also trigger a reduction, a topic which is covered later in this document.

While we’re at it, let’s also introduce the ‘no_broadcast’ flag, which will prevent the output from being broadcast. This is important, because we only want one input value for each output. Aggregating more than one input value is a reduction operation which requires special handling. It would already raise an error because reductions must be explicitly enabled in an iterator flag, but the error message that results from disabling broadcasting is much more understandable for end-users. To see how to generalize the square function to a reduction, look at the sum of squares function in the section about Cython.

For completeness, we’ll also add the ‘external_loop’ and ‘buffered’ flags, as these are what you will typically want for performance reasons.

Example

```
>>> def square(a, out=None):
... it = np.nditer([a, out],
... flags = ['external_loop', 'buffered'],
... op_flags = [['readonly'],
... ['writeonly', 'allocate', 'no_broadcast']])
... with it:
... for x, y in it:
... y[...] = x*x
... return it.operands[1]
...
```
```
>>> square([1,2,3])
array([1, 4, 9])
```
```
>>> b = np.zeros((3,))
>>> square([1,2,3], out=b)
array([1., 4., 9.])
>>> b
array([1., 4., 9.])
```
```
>>> square(np.arange(6).reshape(2,3), out=b)
Traceback (most recent call last):
...
ValueError: non-broadcastable output operand with shape (3,) doesn't
match the broadcast shape (2,3)
```
### Outer Product Iteration[#](#outer-product-iteration)
Any binary operation can be extended to an array operation in an outer
product fashion like in [ outer](generated/numpy.outer.html#numpy.outer), and the

[object provides a way to accomplish this by explicitly mapping the axes of the operands. It is also possible to do this with](generated/numpy.nditer.html#numpy.nditer)
`nditer`
[indexing, but we will show you how to directly use the nditer](constants.html#numpy.newaxis)
`newaxis`
*op_axes*parameter to accomplish this with no intermediate views.
We’ll do a simple outer product, placing the dimensions of the first
operand before the dimensions of the second operand. The *op_axes*
parameter needs one list of axes for each operand, and provides a mapping
from the iterator’s axes to the axes of the operand.

Suppose the first operand is one dimensional and the second operand is
two dimensional. The iterator will have three dimensions, so *op_axes*
will have two 3-element lists. The first list picks out the one
axis of the first operand, and is -1 for the rest of the iterator axes,
with a final result of [0, -1, -1]. The second list picks out the two
axes of the second operand, but shouldn’t overlap with the axes picked
out in the first operand. Its list is [-1, 0, 1]. The output operand
maps onto the iterator axes in the standard manner, so we can provide
None instead of constructing another list.

The operation in the inner loop is a straightforward multiplication. Everything to do with the outer product is handled by the iterator setup.

Example

```
>>> a = np.arange(3)
>>> b = np.arange(8).reshape(2,4)
>>> it = np.nditer([a, b, None], flags=['external_loop'],
... op_axes=[[0, -1, -1], [-1, 0, 1], None])
>>> with it:
... for x, y, z in it:
... z[...] = x*y
... result = it.operands[2] # same as z
...
>>> result
array([[[ 0, 0, 0, 0],
[ 0, 0, 0, 0]],
[[ 0, 1, 2, 3],
[ 4, 5, 6, 7]],
[[ 0, 2, 4, 6],
[ 8, 10, 12, 14]]])
```
Note that once the iterator is closed we can not access [ operands](generated/numpy.nditer.operands.html#numpy.nditer.operands)
and must use a reference created inside the context manager.

### Reduction Iteration[#](#reduction-iteration)
Whenever a writeable operand has fewer elements than the full iteration space,
that operand is undergoing a reduction. The [ nditer](generated/numpy.nditer.html#numpy.nditer) object requires
that any reduction operand be flagged as read-write, and only allows
reductions when ‘reduce_ok’ is provided as an iterator flag.

For a simple example, consider taking the sum of all elements in an array.

Example

```
>>> a = np.arange(24).reshape(2,3,4)
>>> b = np.array(0)
>>> with np.nditer([a, b], flags=['reduce_ok'],
... op_flags=[['readonly'], ['readwrite']]) as it:
... for x,y in it:
... y[...] += x
...
>>> b
array(276)
>>> np.sum(a)
276
```
Things are a little bit more tricky when combining reduction and allocated
operands. Before iteration is started, any reduction operand must be
initialized to its starting values. Here’s how we can do this, taking
sums along the last axis of *a*.

Example

```
>>> a = np.arange(24).reshape(2,3,4)
>>> it = np.nditer([a, None], flags=['reduce_ok'],
... op_flags=[['readonly'], ['readwrite', 'allocate']],
... op_axes=[None, [0,1,-1]])
>>> with it:
... it.operands[1][...] = 0
... for x, y in it:
... y[...] += x
... result = it.operands[1]
...
>>> result
array([[ 6, 22, 38],
[54, 70, 86]])
>>> np.sum(a, axis=2)
array([[ 6, 22, 38],
[54, 70, 86]])
```
To do buffered reduction requires yet another adjustment during the setup. Normally the iterator construction involves copying the first buffer of data from the readable arrays into the buffer. Any reduction operand is readable, so it may be read into a buffer. Unfortunately, initialization of the operand after this buffering operation is complete will not be reflected in the buffer that the iteration starts with, and garbage results will be produced.

The iterator flag “delay_bufalloc” is there to allow iterator-allocated reduction operands to exist together with buffering. When this flag is set, the iterator will leave its buffers uninitialized until it receives a reset, after which it will be ready for regular iteration. Here’s how the previous example looks if we also enable buffering.

Example

```
>>> a = np.arange(24).reshape(2,3,4)
>>> it = np.nditer([a, None], flags=['reduce_ok',
... 'buffered', 'delay_bufalloc'],
... op_flags=[['readonly'], ['readwrite', 'allocate']],
... op_axes=[None, [0,1,-1]])
>>> with it:
... it.operands[1][...] = 0
... it.reset()
... for x, y in it:
... y[...] += x
... result = it.operands[1]
...
>>> result
array([[ 6, 22, 38],
[54, 70, 86]])
```
## Putting the Inner Loop in Cython[#](#putting-the-inner-loop-in-cython)
Those who want really good performance out of their low level operations
should strongly consider directly using the iteration API provided
in C, but for those who are not comfortable with C or C++, Cython
is a good middle ground with reasonable performance tradeoffs. For
the [ nditer](generated/numpy.nditer.html#numpy.nditer) object, this means letting the iterator take care
of broadcasting, dtype conversion, and buffering, while giving the inner
loop to Cython.

For our example, we’ll create a sum of squares function. To start,
let’s implement this function in straightforward Python. We want to
support an ‘axis’ parameter similar to the numpy [ sum](generated/numpy.sum.html#numpy.sum) function,
so we will need to construct a list for the

*op_axes*parameter. Here’s how this looks.
Example

```
>>> def axis_to_axeslist(axis, ndim):
... if axis is None:
... return [-1] * ndim
... else:
... if type(axis) is not tuple:
... axis = (axis,)
... axeslist = [1] * ndim
... for i in axis:
... axeslist[i] = -1
... ax = 0
... for i in range(ndim):
... if axeslist[i] != -1:
... axeslist[i] = ax
... ax += 1
... return axeslist
...
>>> def sum_squares_py(arr, axis=None, out=None):
... axeslist = axis_to_axeslist(axis, arr.ndim)
... it = np.nditer([arr, out], flags=['reduce_ok',
... 'buffered', 'delay_bufalloc'],
... op_flags=[['readonly'], ['readwrite', 'allocate']],
... op_axes=[None, axeslist],
... op_dtypes=['float64', 'float64'])
... with it:
... it.operands[1][...] = 0
... it.reset()
... for x, y in it:
... y[...] += x*x
... return it.operands[1]
...
>>> a = np.arange(6).reshape(2,3)
>>> sum_squares_py(a)
array(55.)
>>> sum_squares_py(a, axis=-1)
array([ 5., 50.])
```
To Cython-ize this function, we replace the inner loop (y[…] += x*x) with Cython code that’s specialized for the float64 dtype. With the ‘external_loop’ flag enabled, the arrays provided to the inner loop will always be one-dimensional, so very little checking needs to be done.

Here’s the listing of sum_squares.pyx:

```
import numpy as np
cimport numpy as np
cimport cython
def axis_to_axeslist(axis, ndim):
if axis is None:
return [-1] * ndim
else:
if type(axis) is not tuple:
axis = (axis,)
axeslist = [1] * ndim
for i in axis:
axeslist[i] = -1
ax = 0
for i in range(ndim):
if axeslist[i] != -1:
axeslist[i] = ax
ax += 1
return axeslist
@cython.boundscheck(False)
def sum_squares_cy(arr, axis=None, out=None):
cdef np.ndarray[double] x
cdef np.ndarray[double] y
cdef int size
cdef double value
axeslist = axis_to_axeslist(axis, arr.ndim)
it = np.nditer([arr, out], flags=['reduce_ok', 'external_loop',
'buffered', 'delay_bufalloc'],
op_flags=[['readonly'], ['readwrite', 'allocate']],
op_axes=[None, axeslist],
op_dtypes=['float64', 'float64'])
with it:
it.operands[1][...] = 0
it.reset()
for xarr, yarr in it:
x = xarr
y = yarr
size = x.shape[0]
for i in range(size):
value = x[i]
y[i] = y[i] + value * value
return it.operands[1]
```
On this machine, building the .pyx file into a module looked like the following, but you may have to find some Cython tutorials to tell you the specifics for your system configuration.:

```
$ cython sum_squares.pyx
$ gcc -shared -pthread -fPIC -fwrapv -O2 -Wall -I/usr/include/python2.7 -fno-strict-aliasing -o sum_squares.so sum_squares.c
```
Running this from the Python interpreter produces the same answers as our native Python/NumPy code did.

Example

```
>>> from sum_squares import sum_squares_cy
>>> a = np.arange(6).reshape(2,3)
>>> sum_squares_cy(a)
array(55.0)
>>> sum_squares_cy(a, axis=-1)
array([ 5., 50.])
```
Doing a little timing in IPython shows that the reduced overhead and memory allocation of the Cython inner loop is providing a very nice speedup over both the straightforward Python code and an expression using NumPy’s built-in sum function.:

```
>>> a = np.random.rand(1000,1000)
>>> timeit sum_squares_py(a, axis=-1)
10 loops, best of 3: 37.1 ms per loop
>>> timeit np.sum(a*a, axis=-1)
10 loops, best of 3: 20.9 ms per loop
>>> timeit sum_squares_cy(a, axis=-1)
100 loops, best of 3: 11.8 ms per loop
>>> np.all(sum_squares_cy(a, axis=-1) == np.sum(a*a, axis=-1))
True
>>> np.all(sum_squares_py(a, axis=-1) == np.sum(a*a, axis=-1))
True
```# Binary operations[#](#binary-operations)
## Elementwise bit operations[#](#elementwise-bit-operations)
|
Compute the bit-wise AND of two arrays element-wise.

|
|
Compute the bit-wise OR of two arrays element-wise.

|
|
Compute the bit-wise XOR of two arrays element-wise.

|
|
Compute bit-wise inversion, or bit-wise NOT, element-wise.

|
|
Shift the bits of an integer to the left.

|
|
Shift the bits of an integer to the right.

|
## Bit packing[#](#bit-packing)
|
Packs the elements of a binary-valued array into bits in a uint8 array.

|
|
Unpacks elements of a uint8 array into a binary-valued output array.

|
## Output formatting[#](#output-formatting)
|
Return the binary representation of the input number as a string.

|# Test Support (`numpy.testing`
)[#](#test-support-numpy-testing)
`numpy.testing`
Common test support for all numpy test scripts.

This single module should provide all the common functionality for numpy
tests in a single location, so that [test scripts](../dev/development_environment.html#development-environment) can just import it and work right away. For
background, see the [Testing Guidelines](testing.html#testing-guidelines)

## Asserts[#](#asserts)
|
Raises an AssertionError if two objects are not equal up to desired tolerance.

|
|
Compare two arrays relatively to their spacing.

|
|
Check that all items of arrays differ in at most N Units in the Last Place.

|
|
Raises an AssertionError if two array_like objects are not equal.

|
|
Raises an AssertionError if two array_like objects are not ordered by less than.

|
|
Raises an AssertionError if two objects are not equal.

|
|
Fail unless an exception of class exception_class is thrown by callable when invoked with arguments args and keyword arguments kwargs.

|
|
Fail unless an exception of class exception_class and with message that matches expected_regexp is thrown by callable when invoked with arguments args and keyword arguments kwargs.

|
|
Fail unless the given callable throws the specified warning.

|
|
Fail if the given callable produces any warnings.

|
|
Fail if the given callable produces any reference cycles.

|
|
Test if two strings are equal.

|
## Asserts (not recommended)[#](#asserts-not-recommended)
It is recommended to use one of [ assert_allclose](generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose),

[or](generated/numpy.testing.assert_array_almost_equal_nulp.html#numpy.testing.assert_array_almost_equal_nulp)
`assert_array_almost_equal_nulp`
[instead of these functions for more consistent floating point comparisons.](generated/numpy.testing.assert_array_max_ulp.html#numpy.testing.assert_array_max_ulp)
`assert_array_max_ulp`
|
Assert that works in release mode.

|
|
Raises an AssertionError if two items are not equal up to desired precision.

|
|
Raises an AssertionError if two items are not equal up to significant digits.

|
|
Raises an AssertionError if two objects are not equal up to desired precision.

|
|
Test if two objects are equal, and print an error message if test fails.

|
## Decorators[#](#decorators)
|
Apply a decorator to all methods in a class matching a regular expression.

|
## Test Running[#](#test-running)
|
Context manager that resets warning registry for catching warnings

|
|
Return elapsed time for executing code in the namespace of the caller.

|
|
Run doctests found in the given file.

|
|
Context manager and decorator doing much the same as

|
## Guidelines[#](#guidelines)
[Testing Guidelines](testing.html)[Introduction](testing.html#introduction)
[Testing NumPy](testing.html#testing-numpy)
[Writing your own tests](testing.html#writing-your-own-tests)
[Tips & Tricks](testing.html#tips-tricks)# Functional programming[#](#functional-programming)
|
Apply a function to 1-D slices along the given axis.

|
|
Apply a function repeatedly over multiple axes.

|
|
Returns an object that acts like pyfunc, but takes arrays as input.

|
|
Takes an arbitrary Python function and returns a NumPy ufunc.

|
|
Evaluate a piecewise-defined function.

|# Mathematical functions with automatic domain[#](#mathematical-functions-with-automatic-domain)
Note

[ numpy.emath](#module-numpy.emath) is a preferred alias for
`numpy.lib.scimath`
,
available after [is imported.](index.html#module-numpy)
`numpy`
Wrapper functions to more user-friendly calling of certain math functions whose output data-type is different than the input data-type in certain domains of the input.

For example, for functions like [ log](generated/numpy.emath.log.html#numpy.emath.log) with branch cuts, the versions in this
module provide the mathematically valid answers in the complex plane:

```
>>> import math
>>> np.emath.log(-math.exp(1)) == (1+1j*math.pi)
True
```
Similarly, [ sqrt](generated/numpy.emath.sqrt.html#numpy.emath.sqrt), other base logarithms,

[and trig functions are correctly handled. See their respective docstrings for specific examples.](generated/numpy.emath.power.html#numpy.emath.power)
`power`
## Functions[#](#functions)
|
Compute the square root of x.

|
|
Compute the natural logarithm of

|
|
Compute the logarithm base 2 of

|
|
Take log base n of x.

|
|
Compute the logarithm base 10 of

|
|
Return x to the power p, (x**p).

|
|
Compute the inverse cosine of x.

|
|
Compute the inverse sine of x.

|
|
Compute the inverse hyperbolic tangent of

|# Generalized Universal Function API[#](#generalized-universal-function-api)
There is a general need for looping over not only functions on scalars but also over functions on vectors (or arrays). This concept is realized in NumPy by generalizing the universal functions (ufuncs). In regular ufuncs, the elementary function is limited to element-by-element operations, whereas the generalized version (gufuncs) supports “sub-array” by “sub-array” operations. The Perl vector library PDL provides a similar functionality and its terms are re-used in the following.

Each generalized ufunc has information associated with it that states
what the “core” dimensionality of the inputs is, as well as the
corresponding dimensionality of the outputs (the element-wise ufuncs
have zero core dimensions). The list of the core dimensions for all
arguments is called the “signature” of a ufunc. For example, the
ufunc numpy.add has signature `(),()->()`
defining two scalar inputs
and one scalar output.

Another example is the function `inner1d(a, b)`
with a signature of
`(i),(i)->()`
. This applies the inner product along the last axis of
each input, but keeps the remaining indices intact.
For example, where `a`
is of shape `(3, 5, N)`
and `b`
is of shape
`(5, N)`
, this will return an output of shape `(3,5)`
.
The underlying elementary function is called `3 * 5`
times. In the
signature, we specify one core dimension `(i)`
for each input and zero core
dimensions `()`
for the output, since it takes two 1-d arrays and
returns a scalar. By using the same name `i`
, we specify that the two
corresponding dimensions should be of the same size.

The dimensions beyond the core dimensions are called “loop” dimensions. In
the above example, this corresponds to `(3, 5)`
.

The signature determines how the dimensions of each input/output array are split into core and loop dimensions:

Each dimension in the signature is matched to a dimension of the corresponding passed-in array, starting from the end of the shape tuple. These are the core dimensions, and they must be present in the arrays, or an error will be raised.

Core dimensions assigned to the same label in the signature (e.g. the

`i`
in`inner1d`
’s`(i),(i)->()`
) must have exactly matching sizes, no broadcasting is performed.
The core dimensions are removed from all inputs and the remaining dimensions are broadcast together, defining the loop dimensions.

The shape of each output is determined from the loop dimensions plus the output’s core dimensions

Typically, the size of all core dimensions in an output will be determined by
the size of a core dimension with the same label in an input array. This is
not a requirement, and it is possible to define a signature where a label
comes up for the first time in an output, although some precautions must be
taken when calling such a function. An example would be the function
`euclidean_pdist(a)`
, with signature `(n,d)->(p)`
, that given an array of
`n`
`d`
-dimensional vectors, computes all unique pairwise Euclidean
distances among them. The output dimension `p`
must therefore be equal to
`n * (n - 1) / 2`
, but it is the caller’s responsibility to pass in an
output array of the right size. If the size of a core dimension of an output
cannot be determined from a passed in input or output array, an error will be
raised.

Note: Prior to NumPy 1.10.0, less strict checks were in place: missing core dimensions were created by prepending 1’s to the shape as necessary, core dimensions with the same label were broadcast together, and undetermined dimensions were created with size 1.

## Definitions[#](#definitions)
Elementary Function
-
Each ufunc consists of an elementary function that performs the most basic operation on the smallest portion of array arguments (e.g. adding two numbers is the most basic operation in adding two arrays). The ufunc applies the elementary function multiple times on different parts of the arrays. The input/output of elementary functions can be vectors; e.g., the elementary function of inner1d takes two vectors as input.

Signature
-
A signature is a string describing the input/output dimensions of the elementary function of a ufunc. See section below for more details.

Core Dimension
-
The dimensionality of each input/output of an elementary function is defined by its core dimensions (zero core dimensions correspond to a scalar input/output). The core dimensions are mapped to the last dimensions of the input/output arrays.

Dimension Name
-
A dimension name represents a core dimension in the signature. Different dimensions may share a name, indicating that they are of the same size.

Dimension Index
-
A dimension index is an integer representing a dimension name. It enumerates the dimension names according to the order of the first occurrence of each name in the signature.

## Details of Signature[#](#details-of-signature)
The signature defines “core” dimensionality of input and output variables, and thereby also defines the contraction of the dimensions. The signature is represented by a string of the following format:

Core dimensions of each input or output array are represented by a list of dimension names in parentheses,

`(i_1,...,i_N)`
; a scalar input/output is denoted by`()`
. Instead of`i_1`
,`i_2`
, etc, one can use any valid Python variable name.
Dimension lists for different arguments are separated by

`","`
. Input/output arguments are separated by`"->"`
.
If one uses the same dimension name in multiple locations, this enforces the same size of the corresponding dimensions.

The formal syntax of signatures is as follows:

```
<Signature> ::= <Input arguments> "->" <Output arguments>
<Input arguments> ::= <Argument list>
<Output arguments> ::= <Argument list>
<Argument list> ::= nil | <Argument> | <Argument> "," <Argument list>
<Argument> ::= "(" <Core dimension list> ")"
<Core dimension list> ::= nil | <Core dimension> |
<Core dimension> "," <Core dimension list>
<Core dimension> ::= <Dimension name> <Dimension modifier>
<Dimension name> ::= valid Python variable name | valid integer
<Dimension modifier> ::= nil | "?"
```
Notes:

All quotes are for clarity.

Unmodified core dimensions that share the same name must have the same size. Each dimension name typically corresponds to one level of looping in the elementary function’s implementation.

White spaces are ignored.

An integer as a dimension name freezes that dimension to the value.

If the name is suffixed with the “?” modifier, the dimension is a core dimension only if it exists on all inputs and outputs that share it; otherwise it is ignored (and replaced by a dimension of size 1 for the elementary function).

Here are some examples of signatures:

name

|
signature

|
common usage

|
---|---|---|
add

|
|
binary ufunc

|
sum1d

|
|
reduction

|
inner1d

|
|
vector-vector multiplication

|
matmat

|
|
matrix multiplication

|
vecmat

|
|
vector-matrix multiplication

|
matvec

|
|
matrix-vector multiplication

|
matmul

|
|
combination of the four above

|
outer_inner

|
|
inner over the last dimension, outer over the second to last, and loop/broadcast over the rest.

|
cross1d

|
|
cross product where the last dimension is frozen and must be 3

|
The last is an instance of freezing a core dimension and can be used to improve ufunc performance

## C-API for implementing Elementary Functions[#](#c-api-for-implementing-elementary-functions)
The current interface remains unchanged, and `PyUFunc_FromFuncAndData`
can still be used to implement (specialized) ufuncs, consisting of
scalar elementary functions.

One can use `PyUFunc_FromFuncAndDataAndSignature`
to declare a more
general ufunc. The argument list is the same as
`PyUFunc_FromFuncAndData`
, with an additional argument specifying the
signature as C string.

Furthermore, the callback function is of the same type as before,
`void (*foo)(char **args, intp *dimensions, intp *steps, void *func)`
.
When invoked, `args`
is a list of length `nargs`
containing
the data of all input/output arguments. For a scalar elementary
function, `steps`
is also of length `nargs`
, denoting the strides used
for the arguments. `dimensions`
is a pointer to a single integer
defining the size of the axis to be looped over.

For a non-trivial signature, `dimensions`
will also contain the sizes
of the core dimensions as well, starting at the second entry. Only
one size is provided for each unique dimension name and the sizes are
given according to the first occurrence of a dimension name in the
signature.

The first `nargs`
elements of `steps`
remain the same as for scalar
ufuncs. The following elements contain the strides of all core
dimensions for all arguments in order.

For example, consider a ufunc with signature `(i,j),(i)->()`
. In
this case, `args`
will contain three pointers to the data of the
input/output arrays `a`
, `b`
, `c`
. Furthermore, `dimensions`
will be
`[N, I, J]`
to define the size of `N`
of the loop and the sizes `I`
and `J`
for the core dimensions `i`
and `j`
. Finally, `steps`
will be
`[a_N, b_N, c_N, a_i, a_j, b_i]`
, containing all necessary strides.# Mathematical functions[#](#mathematical-functions)
## Trigonometric functions[#](#trigonometric-functions)
|
Trigonometric sine, element-wise.

|
|
Cosine element-wise.

|
|
Compute tangent element-wise.

|
|
Inverse sine, element-wise.

|
|
Trigonometric inverse cosine, element-wise.

|
|
Trigonometric inverse tangent, element-wise.

|
|
Given the "legs" of a right triangle, return its hypotenuse.

|
|
Element-wise arc tangent of

|
|
Convert angles from radians to degrees.

|
|
Convert angles from degrees to radians.

|
|
Unwrap by taking the complement of large deltas with respect to the period.

|
|
Convert angles from degrees to radians.

|
|
Convert angles from radians to degrees.

|
## Hyperbolic functions[#](#hyperbolic-functions)
|
Hyperbolic sine, element-wise.

|
|
Hyperbolic cosine, element-wise.

|
|
Compute hyperbolic tangent element-wise.

|
|
Inverse hyperbolic sine element-wise.

|
|
Inverse hyperbolic cosine, element-wise.

|
|
Inverse hyperbolic tangent element-wise.

|
## Rounding[#](#rounding)
|
Evenly round to the given number of decimals.

|
|
Round an array to the given number of decimals.

|
|
Round elements of the array to the nearest integer.

|
|
Round to nearest integer towards zero.

|
|
Return the floor of the input, element-wise.

|
|
Return the ceiling of the input, element-wise.

|
|
Return the truncated value of the input, element-wise.

|
## Sums, products, differences[#](#sums-products-differences)
|
Return the product of array elements over a given axis.

|
|
Sum of array elements over a given axis.

|
|
Return the product of array elements over a given axis treating Not a Numbers (NaNs) as ones.

|
|
Return the sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.

|
|
Return the cumulative product of elements along a given axis.

|
|
Return the cumulative sum of the elements along a given axis.

|
|
Return the cumulative product of array elements over a given axis treating Not a Numbers (NaNs) as one.

|
|
Return the cumulative sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.

|
|
Calculate the n-th discrete difference along the given axis.

|
|
The differences between consecutive elements of an array.

|
|
Return the gradient of an N-dimensional array.

|
|
Return the cross product of two (arrays of) vectors.

|
|
Integrate along the given axis using the composite trapezoidal rule.

|
## Exponents and logarithms[#](#exponents-and-logarithms)
|
Calculate the exponential of all elements in the input array.

|
|
Calculate

|
|
Calculate

|
|
Natural logarithm, element-wise.

|
|
Return the base 10 logarithm of the input array, element-wise.

|
|
Base-2 logarithm of

|
|
Return the natural logarithm of one plus the input array, element-wise.

|
|
Logarithm of the sum of exponentiations of the inputs.

|
|
Logarithm of the sum of exponentiations of the inputs in base-2.

|
## Other special functions[#](#other-special-functions)
|
Modified Bessel function of the first kind, order 0.

|
|
Return the normalized sinc function.

|
## Floating point routines[#](#floating-point-routines)
|
Returns element-wise True where signbit is set (less than zero).

|
|
Change the sign of x1 to that of x2, element-wise.

|
|
Decompose the elements of x into mantissa and twos exponent.

|
|
Returns x1 * 2**x2, element-wise.

|
|
Return the next floating-point value after x1 towards x2, element-wise.

|
|
Return the distance between x and the nearest adjacent number.

|
## Rational routines[#](#rational-routines)
|
Returns the lowest common multiple of

|
|
Returns the greatest common divisor of

|
## Arithmetic operations[#](#arithmetic-operations)
|
Add arguments element-wise.

|
|
Return the reciprocal of the argument, element-wise.

|
|
Numerical positive, element-wise.

|
|
Numerical negative, element-wise.

|
|
Multiply arguments element-wise.

|
|
Divide arguments element-wise.

|
|
First array elements raised to powers from second array, element-wise.

|
|
Subtract arguments, element-wise.

|
|
Divide arguments element-wise.

|
|
Return the largest integer smaller or equal to the division of the inputs.

|
|
First array elements raised to powers from second array, element-wise.

|
|
Returns the element-wise remainder of division.

|
|
Returns the element-wise remainder of division.

|
|
Return the fractional and integral parts of an array, element-wise.

|
|
Returns the element-wise remainder of division.

|
|
Return element-wise quotient and remainder simultaneously.

|
## Handling complex numbers[#](#handling-complex-numbers)
|
Return the angle of the complex argument.

|
|
Return the real part of the complex argument.

|
|
Return the imaginary part of the complex argument.

|
|
Return the complex conjugate, element-wise.

|
|
Return the complex conjugate, element-wise.

|
## Extrema Finding[#](#extrema-finding)
|
Element-wise maximum of array elements.

|
|
Return the maximum of an array or maximum along an axis.

|
|
Return the maximum of an array or maximum along an axis.

|
|
Element-wise maximum of array elements.

|
|
Return the maximum of an array or maximum along an axis, ignoring any NaNs.

|
|
Element-wise minimum of array elements.

|
|
Return the minimum of an array or minimum along an axis.

|
|
Return the minimum of an array or minimum along an axis.

|
|
Element-wise minimum of array elements.

|
|
Return minimum of an array or minimum along an axis, ignoring any NaNs.

|
## Miscellaneous[#](#miscellaneous)
|
Returns the discrete, linear convolution of two one-dimensional sequences.

|
|
Clip (limit) the values in an array.

|
|
Return the non-negative square-root of an array, element-wise.

|
|
Return the cube-root of an array, element-wise.

|
|
Return the element-wise square of the input.

|
|
Calculate the absolute value element-wise.

|
|
Compute the absolute values element-wise.

|
|
Returns an element-wise indication of the sign of a number.

|
|
Compute the Heaviside step function.

|
|
Replace NaN with zero and infinity with large finite numbers (default behaviour) or with the numbers defined by the user using the

posinf and/or neginf keywords. |
|
If input is complex with all imaginary parts close to zero, return real parts.

|
|
One-dimensional linear interpolation for monotonically increasing sample points.

|# C API Deprecations[#](#c-api-deprecations)
## Background[#](#background)
The API exposed by NumPy for third-party extensions has grown over years of releases, and has allowed programmers to directly access NumPy functionality from C. This API can be best described as “organic”. It has emerged from multiple competing desires and from multiple points of view over the years, strongly influenced by the desire to make it easy for users to move to NumPy from Numeric and Numarray. The core API originated with Numeric in 1995 and there are patterns such as the heavy use of macros written to mimic Python’s C-API as well as account for compiler technology of the late 90’s. There is also only a small group of volunteers who have had very little time to spend on improving this API.

There is an ongoing effort to improve the API. It is important in this effort to ensure that code that compiles for NumPy 1.X continues to compile for NumPy 1.X. At the same time, certain API’s will be marked as deprecated so that future-looking code can avoid these API’s and follow better practices.

Another important role played by deprecation markings in the C API is to move towards hiding internal details of the NumPy implementation. For those needing direct, easy, access to the data of ndarrays, this will not remove this ability. Rather, there are many potential performance optimizations which require changing the implementation details, and NumPy developers have been unable to try them because of the high value of preserving ABI compatibility. By deprecating this direct access, we will in the future be able to improve NumPy’s performance in ways we cannot presently.

## Deprecation Mechanism NPY_NO_DEPRECATED_API[#](#deprecation-mechanism-npy-no-deprecated-api)
In C, there is no equivalent to the deprecation warnings that Python supports. One way to do deprecations is to flag them in the documentation and release notes, then remove or change the deprecated features in a future major version (NumPy 2.0 and beyond). Minor versions of NumPy should not have major C-API changes, however, that prevent code that worked on a previous minor release. For example, we will do our best to ensure that code that compiled and worked on NumPy 1.4 should continue to work on NumPy 1.7 (but perhaps with compiler warnings).

To use the NPY_NO_DEPRECATED_API mechanism, you need to #define it to the target API version of NumPy before #including any NumPy headers. If you want to confirm that your code is clean against 1.7, use:

```
#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION
```
On compilers which support a #warning mechanism, NumPy issues a compiler warning if you do not define the symbol NPY_NO_DEPRECATED_API. This way, the fact that there are deprecations will be flagged for third-party developers who may not have read the release notes closely.

Note that defining NPY_NO_DEPRECATED_API is not sufficient to make your
extension ABI compatible with a given NumPy version. See
[For downstream package authors](../../dev/depending_on_numpy.html#for-downstream-package-authors).# CPU/SIMD Optimizations[#](#cpu-simd-optimizations)
NumPy comes with a flexible working mechanism that allows it to harness the SIMD features that CPUs own, in order to provide faster and more stable performance on all popular platforms. Currently, NumPy supports the X86, IBM/Power, ARM7 and ARM8 architectures.

The optimization process in NumPy is carried out in three layers:

Code is

*written*using the universal intrinsics which is a set of types, macros and functions that are mapped to each supported instruction-sets by using guards that will enable use of the them only when the compiler recognizes them. This allow us to generate multiple kernels for the same functionality, in which each generated kernel represents a set of instructions that related one or multiple certain CPU features. The first kernel represents the minimum (baseline) CPU features, and the other kernels represent the additional (dispatched) CPU features.
At

*compile*time, CPU build options are used to define the minimum and additional features to support, based on user choice and compiler support. The appropriate intrinsics are overlaid with the platform / architecture intrinsics, and multiple kernels are compiled.
At

*runtime import*, the CPU is probed for the set of supported CPU features. A mechanism is used to grab the pointer to the most appropriate kernel, and this will be the one called for the function.
Note

NumPy community had a deep discussion before implementing this work,
please check [NEP-38](https://numpy.org/neps/nep-0038-SIMD-optimizations.html) for more clarification.

[CPU build options](build-options.html)[Description](build-options.html#description)
[Quick Start](build-options.html#quick-start)
[Supported Features](build-options.html#supported-features)
[Special Options](build-options.html#special-options)
[Behaviors](build-options.html#behaviors)
[Platform differences](build-options.html#platform-differences)
[Build report](build-options.html#build-report)
[Runtime dispatch](build-options.html#runtime-dispatch)
[How does the CPU dispatcher work?](how-it-works.html)# NumPy 1.17.0 Release Notes[#](#numpy-1-17-0-release-notes)
This NumPy release contains a number of new features that should substantially improve its performance and usefulness, see Highlights below for a summary. The Python versions supported are 3.5-3.7, note that Python 2.7 has been dropped. Python 3.8b2 should work with the released source packages, but there are no future guarantees.

Downstream developers should use Cython >= 0.29.11 for Python 3.8 support and OpenBLAS >= 3.7 (not currently out) to avoid problems on the Skylake architecture. The NumPy wheels on PyPI are built from the OpenBLAS development branch in order to avoid those problems.

## Highlights[#](#highlights)
A new extensible

module along with four selectable`random`
*random number generators*and improved seeding designed for use in parallel processes has been added. The currently available bit generators are*MT19937*,*PCG64*,*Philox*, and*SFC64*. See below under New Features.
NumPy’s

implementation was changed from fftpack to pocketfft, resulting in faster, more accurate transforms and better handling of datasets of prime length. See below under Improvements.`FFT`
New radix sort and timsort sorting methods. It is currently not possible to choose which will be used. They are hardwired to the datatype and used when either

`stable`
or`mergesort`
is passed as the method. See below under Improvements.
Overriding numpy functions is now possible by default, see

`__array_function__`
below.
## New functions[#](#new-functions)
is now also a function decorator`numpy.errstate`
## Deprecations[#](#deprecations)
`numpy.polynomial`
functions warn when passed `float`
in place of `int`
[#](#numpy-polynomial-functions-warn-when-passed-float-in-place-of-int)
`numpy.polynomial`
Previously functions in this module would accept `float`
values provided they
were integral (`1.0`
, `2.0`
, etc). For consistency with the rest of numpy,
doing so is now deprecated, and in future will raise a `TypeError`
.

Similarly, passing a float like `0.5`
in place of an integer will now raise a
`TypeError`
instead of the previous `ValueError`
.

### Deprecate `numpy.distutils.exec_command`
and `temp_file_name`
[#](#deprecate-numpy-distutils-exec-command-and-temp-file-name)
`numpy.distutils.exec_command`
The internal use of these functions has been refactored and there are better
alternatives. Replace `exec_command`
with [ subprocess.Popen](https://docs.python.org/3/library/subprocess.html#subprocess.Popen) and

[with](../reference/generated/numpy.distutils.exec_command.html#module-numpy.distutils.exec_command)
`temp_file_name`
[.](https://docs.python.org/3/library/tempfile.html#tempfile.mkstemp)
`tempfile.mkstemp`
### Writeable flag of C-API wrapped arrays[#](#writeable-flag-of-c-api-wrapped-arrays)
When an array is created from the C-API to wrap a pointer to data, the only
indication we have of the read-write nature of the data is the `writeable`
flag set during creation. It is dangerous to force the flag to writeable.
In the future it will not be possible to switch the writeable flag to `True`
from python.
This deprecation should not affect many users since arrays created in such
a manner are very rare in practice and only available through the NumPy C-API.

`numpy.nonzero`
should no longer be called on 0d arrays[#](#numpy-nonzero-should-no-longer-be-called-on-0d-arrays)
`numpy.nonzero`
The behavior of [ numpy.nonzero](../reference/generated/numpy.nonzero.html#numpy.nonzero) on 0d arrays was surprising, making uses of it
almost always incorrect. If the old behavior was intended, it can be preserved
without a warning by using

`nonzero(atleast_1d(arr))`
instead of
`nonzero(arr)`
. In a future release, it is most likely this will raise a
`ValueError`
.### Writing to the result of `numpy.broadcast_arrays`
will warn[#](#writing-to-the-result-of-numpy-broadcast-arrays-will-warn)
`numpy.broadcast_arrays`
Commonly [ numpy.broadcast_arrays](../reference/generated/numpy.broadcast_arrays.html#numpy.broadcast_arrays) returns a writeable array with internal
overlap, making it unsafe to write to. A future version will set the

`writeable`
flag to `False`
, and require users to manually set it to
`True`
if they are sure that is what they want to do. Now writing to it will
emit a deprecation warning with instructions to set the `writeable`
flag
`True`
. Note that if one were to inspect the flag before setting it, one
would find it would already be `True`
. Explicitly setting it, though, as one
will need to do in future versions, clears an internal flag that is used to
produce the deprecation warning. To help alleviate confusion, an additional
*FutureWarning*will be emitted when accessing the
`writeable`
flag state to
clarify the contradiction.Note that for the C-side buffer protocol such an array will return a
readonly buffer immediately unless a writable buffer is requested. If
a writeable buffer is requested a warning will be given. When using
cython, the `const`
qualifier should be used with such arrays to avoid
the warning (e.g. `cdef const double[::1] view`
).

## Future Changes[#](#future-changes)
### Shape-1 fields in dtypes won’t be collapsed to scalars in a future version[#](#shape-1-fields-in-dtypes-won-t-be-collapsed-to-scalars-in-a-future-version)
Currently, a field specified as `[(name, dtype, 1)]`
or `"1type"`
is
interpreted as a scalar field (i.e., the same as `[(name, dtype)]`
or
`[(name, dtype, ()]`
). This now raises a FutureWarning; in a future version,
it will be interpreted as a shape-(1,) field, i.e. the same as ```
[(name,
dtype, (1,))]
```
or `"(1,)type"`
(consistently with `[(name, dtype, n)]`
/ `"ntype"`
with `n>1`
, which is already equivalent to ```
[(name, dtype,
(n,)]
```
/ `"(n,)type"`
).

## Compatibility notes[#](#compatibility-notes)
`float16`
subnormal rounding[#](#float16-subnormal-rounding)
Casting from a different floating point precision to `float16`
used incorrect
rounding in some edge cases. This means in rare cases, subnormal results will
now be rounded up instead of down, changing the last bit (ULP) of the result.

### Signed zero when using divmod[#](#signed-zero-when-using-divmod)
Starting in version *1.12.0*, numpy incorrectly returned a negatively signed zero
when using the `divmod`
and `floor_divide`
functions when the result was
zero. For example:

```
>>> np.zeros(10)//1
array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.])
```
With this release, the result is correctly returned as a positively signed zero:

```
>>> np.zeros(10)//1
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
```
`MaskedArray.mask`
now returns a view of the mask, not the mask itself[#](#maskedarray-mask-now-returns-a-view-of-the-mask-not-the-mask-itself)
Returning the mask itself was unsafe, as it could be reshaped in place which
would violate expectations of the masked array code. The behavior of [ mask](../reference/maskedarray.baseclass.html#numpy.ma.MaskedArray.mask) is now consistent with

[, which also returns a view.](../reference/maskedarray.baseclass.html#numpy.ma.MaskedArray.data)
`data`
The underlying mask can still be accessed with `._mask`
if it is needed.
Tests that contain `assert x.mask is not y.mask`
or similar will need to be
updated.

### Do not lookup `__buffer__`
attribute in `numpy.frombuffer`
[#](#do-not-lookup-buffer-attribute-in-numpy-frombuffer)
`numpy.frombuffer`
Looking up `__buffer__`
attribute in [ numpy.frombuffer](../reference/generated/numpy.frombuffer.html#numpy.frombuffer) was undocumented and
non-functional. This code was removed. If needed, use

`frombuffer(memoryview(obj), ...)`
instead.`out`
is buffered for memory overlaps in `take`
, `choose`
, `put`
[#](#out-is-buffered-for-memory-overlaps-in-take-choose-put)
`take`
`choose`
`put`
If the out argument to these functions is provided and has memory overlap with the other arguments, it is now buffered to avoid order-dependent behavior.

### Unpickling while loading requires explicit opt-in[#](#unpickling-while-loading-requires-explicit-opt-in)
The functions [ load](../reference/generated/numpy.load.html#numpy.load), and

`lib.format.read_array`
take an
`allow_pickle`
keyword which now defaults to `False`
in response to
[CVE-2019-6446](https://nvd.nist.gov/vuln/detail/CVE-2019-6446).
### Potential changes to the random stream in old random module[#](#potential-changes-to-the-random-stream-in-old-random-module)
Due to bugs in the application of `log`
to random floating point numbers,
the stream may change when sampling from [ beta](../reference/random/generated/numpy.random.RandomState.beta.html#numpy.random.RandomState.beta),

[,](../reference/random/generated/numpy.random.RandomState.binomial.html#numpy.random.RandomState.binomial)
`binomial`
[,](../reference/random/generated/numpy.random.RandomState.laplace.html#numpy.random.RandomState.laplace)
`laplace`
[,](../reference/random/generated/numpy.random.RandomState.logistic.html#numpy.random.RandomState.logistic)
`logistic`
[or](../reference/random/generated/numpy.random.RandomState.logseries.html#numpy.random.RandomState.logseries)
`logseries`
[if a](../reference/random/generated/numpy.random.RandomState.multinomial.html#numpy.random.RandomState.multinomial)
`multinomial`
`0`
is generated in the underlying [random stream. There is a](../reference/random/bit_generators/mt19937.html#numpy.random.MT19937)
`MT19937`
`1`
in
\(10^{53}\) chance of this occurring, so the probability that the stream
changes for any given seed is extremely small. If a `0`
is encountered in the
underlying generator, then the incorrect value produced (either [or](../reference/constants.html#numpy.inf)
`numpy.inf`
[) is now dropped.](../reference/constants.html#numpy.nan)
`numpy.nan`
`i0`
now always returns a result with the same shape as the input[#](#i0-now-always-returns-a-result-with-the-same-shape-as-the-input)
`i0`
Previously, the output was squeezed, such that, e.g., input with just a single
element would lead to an array scalar being returned, and inputs with shapes
such as `(10, 1)`
would yield results that would not broadcast against the
input.

Note that we generally recommend the SciPy implementation over the numpy one: it is a proper ufunc written in C, and more than an order of magnitude faster.

`can_cast`
no longer assumes all unsafe casting is allowed[#](#can-cast-no-longer-assumes-all-unsafe-casting-is-allowed)
`can_cast`
Previously, [ can_cast](../reference/generated/numpy.can_cast.html#numpy.can_cast) returned

*True*for almost all inputs for
`casting='unsafe'`
, even for cases where casting was not possible, such as
from a structured dtype to a regular one. This has been fixed, making it
more consistent with actual casting using, e.g., the [method.](../reference/generated/numpy.ndarray.astype.html#numpy.ndarray.astype)
`.astype`
`ndarray.flags.writeable`
can be switched to true slightly more often[#](#ndarray-flags-writeable-can-be-switched-to-true-slightly-more-often)
In rare cases, it was not possible to switch an array from not writeable
to writeable, although a base array is writeable. This can happen if an
intermediate [ ndarray.base](../reference/generated/numpy.ndarray.base.html#numpy.ndarray.base) object is writeable. Previously, only the deepest
base object was considered for this decision. However, in rare cases this
object does not have the necessary information. In that case switching to
writeable was never allowed. This has now been fixed.

## C API changes[#](#c-api-changes)
### dimension or stride input arguments are now passed by `npy_intp const*`
[#](#dimension-or-stride-input-arguments-are-now-passed-by-npy-intp-const)
Previously these function arguments were declared as the more strict
`npy_intp*`
, which prevented the caller passing constant data.
This change is backwards compatible, but now allows code like:

```
npy_intp const fixed_dims[] = {1, 2, 3};
// no longer complains that the const-qualifier is discarded
npy_intp size = PyArray_MultiplyList(fixed_dims, 3);
```
## New Features[#](#new-features)
### New extensible `numpy.random`
module with selectable random number generators[#](#new-extensible-numpy-random-module-with-selectable-random-number-generators)
`numpy.random`
A new extensible [ numpy.random](../reference/random/index.html#module-numpy.random) module along with four selectable random number
generators and improved seeding designed for use in parallel processes has been
added. The currently available

*Bit Generators*are
*MT19937*,
*PCG64*,
*Philox*, and
*SFC64*.
`PCG64`
is the new default while `MT19937`
is retained for backwards
compatibility. Note that the legacy random module is unchanged and is now
frozen, your current results will not change. More information is available in
the [API change description](../reference/random/new-or-different.html#new-or-different)and in the
[documentation.](../reference/random/index.html#module-numpy.random)
`top-level view`
### libFLAME[#](#libflame)
Support for building NumPy with the libFLAME linear algebra package as the LAPACK,
implementation, see
[libFLAME](https://www.cs.utexas.edu/~flame/web/libFLAME.html) for details.

### User-defined BLAS detection order[#](#user-defined-blas-detection-order)
[ distutils](../reference/distutils.html#module-numpy.distutils) now uses an environment variable, comma-separated and case
insensitive, to determine the detection order for BLAS libraries.
By default
`NPY_BLAS_ORDER=mkl,blis,openblas,atlas,accelerate,blas`
.
However, to force the use of OpenBLAS simply do:```
NPY_BLAS_ORDER=openblas python setup.py build
```
which forces the use of OpenBLAS. This may be helpful for users which have a MKL installation but wishes to try out different implementations.

### User-defined LAPACK detection order[#](#user-defined-lapack-detection-order)
`numpy.distutils`
now uses an environment variable, comma-separated and case
insensitive, to determine the detection order for LAPACK libraries.
By default `NPY_LAPACK_ORDER=mkl,openblas,flame,atlas,accelerate,lapack`
.
However, to force the use of OpenBLAS simply do:
```
NPY_LAPACK_ORDER=openblas python setup.py build
```
which forces the use of OpenBLAS. This may be helpful for users which have a MKL installation but wishes to try out different implementations.

### Timsort and radix sort have replaced mergesort for stable sorting[#](#timsort-and-radix-sort-have-replaced-mergesort-for-stable-sorting)
Both radix sort and timsort have been implemented and are now used in place of
mergesort. Due to the need to maintain backward compatibility, the sorting
`kind`
options `"stable"`
and `"mergesort"`
have been made aliases of
each other with the actual sort implementation depending on the array type.
Radix sort is used for small integer types of 16 bits or less and timsort for
the remaining types. Timsort features improved performance on data containing
already or nearly sorted data and performs like mergesort on random data and
requires \(O(n/2)\) working space. Details of the timsort algorithm can be
found at [CPython listsort.txt](https://github.com/python/cpython/blob/3.7/Objects/listsort.txt).

`packbits`
and `unpackbits`
accept an `order`
keyword[#](#packbits-and-unpackbits-accept-an-order-keyword)
`packbits`
`unpackbits`
The `order`
keyword defaults to `big`
, and will order the **bits**
accordingly. For `'order=big'`
3 will become `[0, 0, 0, 0, 0, 0, 1, 1]`
,
and `[1, 1, 0, 0, 0, 0, 0, 0]`
for `order=little`

`unpackbits`
now accepts a `count`
parameter[#](#unpackbits-now-accepts-a-count-parameter)
`unpackbits`
`count`
allows subsetting the number of bits that will be unpacked up-front,
rather than reshaping and subsetting later, making the [ packbits](../reference/generated/numpy.packbits.html#numpy.packbits) operation
invertible, and the unpacking less wasteful. Counts larger than the number of
available bits add zero padding. Negative counts trim bits off the end instead
of counting from the beginning. None counts implement the existing behavior of
unpacking everything.
`linalg.svd`
and `linalg.pinv`
can be faster on hermitian inputs[#](#linalg-svd-and-linalg-pinv-can-be-faster-on-hermitian-inputs)
`linalg.svd`
`linalg.pinv`
These functions now accept a `hermitian`
argument, matching the one added
to [ linalg.matrix_rank](../reference/generated/numpy.linalg.matrix_rank.html#numpy.linalg.matrix_rank) in 1.14.0.

### divmod operation is now supported for two `timedelta64`
operands[#](#divmod-operation-is-now-supported-for-two-timedelta64-operands)
The divmod operator now handles two `timedelta64`
operands, with
type signature `mm->qm`
.

`fromfile`
now takes an `offset`
argument[#](#fromfile-now-takes-an-offset-argument)
`fromfile`
This function now takes an `offset`
keyword argument for binary files,
which specifics the offset (in bytes) from the file’s current position.
Defaults to `0`
.

### New mode “empty” for `pad`
[#](#new-mode-empty-for-pad)
`pad`
This mode pads an array to a desired shape without initializing the new entries.

### Floating point scalars implement `as_integer_ratio`
to match the builtin float[#](#floating-point-scalars-implement-as-integer-ratio-to-match-the-builtin-float)
This returns a (numerator, denominator) pair, which can be used to construct a
[ fractions.Fraction](https://docs.python.org/3/library/fractions.html#fractions.Fraction).

### Structured `dtype`
objects can be indexed with multiple fields names[#](#structured-dtype-objects-can-be-indexed-with-multiple-fields-names)
`arr.dtype[['a', 'b']]`
now returns a dtype that is equivalent to
`arr[['a', 'b']].dtype`
, for consistency with
`arr.dtype['a'] == arr['a'].dtype`
.
Like the dtype of structured arrays indexed with a list of fields, this dtype
has the same `itemsize`
as the original, but only keeps a subset of the fields.

This means that `arr[['a', 'b']]`
and `arr.view(arr.dtype[['a', 'b']])`
are
equivalent.

`.npy`
files support unicode field names[#](#npy-files-support-unicode-field-names)
A new format version of 3.0 has been introduced, which enables structured types with non-latin1 field names. This is used automatically when needed.

## Improvements[#](#improvements)
### Array comparison assertions include maximum differences[#](#array-comparison-assertions-include-maximum-differences)
Error messages from array comparison tests such as
[ testing.assert_allclose](../reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose) now include “max absolute difference” and
“max relative difference,” in addition to the previous “mismatch” percentage.
This information makes it easier to update absolute and relative error
tolerances.

### Replacement of the fftpack based `fft`
module by the pocketfft library[#](#replacement-of-the-fftpack-based-fft-module-by-the-pocketfft-library)
`fft`
Both implementations have the same ancestor (Fortran77 FFTPACK by Paul N. Swarztrauber), but pocketfft contains additional modifications which improve both accuracy and performance in some circumstances. For FFT lengths containing large prime factors, pocketfft uses Bluestein’s algorithm, which maintains \(O(N log N)\) run time complexity instead of deteriorating towards \(O(N*N)\) for prime lengths. Also, accuracy for real valued FFTs with near prime lengths has improved and is on par with complex valued FFTs.

### Further improvements to `ctypes`
support in `numpy.ctypeslib`
[#](#further-improvements-to-ctypes-support-in-numpy-ctypeslib)
`numpy.ctypeslib`
A new [ numpy.ctypeslib.as_ctypes_type](../reference/routines.ctypeslib.html#numpy.ctypeslib.as_ctypes_type) function has been added, which can be
used to converts a

[into a best-guess](../reference/generated/numpy.dtype.html#numpy.dtype)
`dtype`
[type. Thanks to this new function,](https://docs.python.org/3/library/ctypes.html#module-ctypes)
`ctypes`
[now supports a much wider range of array types, including structures, booleans, and integers of non-native endianness.](../reference/routines.ctypeslib.html#numpy.ctypeslib.as_ctypes)
`numpy.ctypeslib.as_ctypes`
`numpy.errstate`
is now also a function decorator[#](#numpy-errstate-is-now-also-a-function-decorator)
`numpy.errstate`
Currently, if you have a function like:

```
def foo():
pass
```
and you want to wrap the whole thing in [ errstate](../reference/generated/numpy.errstate.html#numpy.errstate), you have to rewrite it
like so:

```
def foo():
with np.errstate(...):
pass
```
but with this change, you can do:

```
@np.errstate(...)
def foo():
pass
```
thereby saving a level of indentation

`numpy.exp`
and `numpy.log`
speed up for float32 implementation[#](#numpy-exp-and-numpy-log-speed-up-for-float32-implementation)
`numpy.exp`
`numpy.log`
float32 implementation of [ exp](../reference/generated/numpy.exp.html#numpy.exp) and

[now benefit from AVX2/AVX512 instruction set which are detected during runtime.](../reference/generated/numpy.log.html#numpy.log)
`log`
[has a max ulp error of 2.52 and](../reference/generated/numpy.exp.html#numpy.exp)
`exp`
[has a max ulp error or 3.83.](../reference/generated/numpy.log.html#numpy.log)
`log`
### Improve performance of `numpy.pad`
[#](#improve-performance-of-numpy-pad)
`numpy.pad`
The performance of the function has been improved for most cases by filling in a preallocated array with the desired padded shape instead of using concatenation.

`numpy.interp`
handles infinities more robustly[#](#numpy-interp-handles-infinities-more-robustly)
`numpy.interp`
In some cases where [ interp](../reference/generated/numpy.interp.html#numpy.interp) would previously return

[, it now returns an appropriate infinity.](../reference/constants.html#numpy.nan)
`nan`
### Pathlib support for `fromfile`
, *tofile* and `ndarray.dump`
[#](#pathlib-support-for-fromfile-tofile-and-ndarray-dump)
`fromfile`
`ndarray.dump`
[ fromfile](../reference/generated/numpy.fromfile.html#numpy.fromfile),
*ndarray.ndarray.tofile*and
[now support the](../reference/generated/numpy.ndarray.dump.html#numpy.ndarray.dump)
`ndarray.dump`
[type for the](https://docs.python.org/3/library/pathlib.html#pathlib.Path)
`pathlib.Path`
`file`
/`fid`
parameter.### Specialized `isnan`
, `isinf`
, and `isfinite`
ufuncs for bool and int types[#](#specialized-isnan-isinf-and-isfinite-ufuncs-for-bool-and-int-types)
`isnan`
`isinf`
`isfinite`
The boolean and integer types are incapable of storing [ nan](../reference/constants.html#numpy.nan) and

[values, which allows us to provide specialized ufuncs that are up to 250x faster than the previous approach.](../reference/constants.html#numpy.inf)
`inf`
`isfinite`
supports `datetime64`
and `timedelta64`
types[#](#isfinite-supports-datetime64-and-timedelta64-types)
`isfinite`
Previously, [ isfinite](../reference/generated/numpy.isfinite.html#numpy.isfinite) used to raise a

*TypeError*on being used on these two types.
### New keywords added to `nan_to_num`
[#](#new-keywords-added-to-nan-to-num)
`nan_to_num`
[ nan_to_num](../reference/generated/numpy.nan_to_num.html#numpy.nan_to_num) now accepts keywords
`nan`
, `posinf`
and `neginf`
allowing the user to define the value to replace the `nan`
, positive and
negative `np.inf`
values respectively.### MemoryErrors caused by allocated overly large arrays are more descriptive[#](#memoryerrors-caused-by-allocated-overly-large-arrays-are-more-descriptive)
Often the cause of a MemoryError is incorrect broadcasting, which results in a very large and incorrect shape. The message of the error now includes this shape to help diagnose the cause of failure.

`floor`
, `ceil`
, and `trunc`
now respect builtin magic methods[#](#floor-ceil-and-trunc-now-respect-builtin-magic-methods)
`floor`
`ceil`
`trunc`
These ufuncs now call the `__floor__`
, `__ceil__`
, and `__trunc__`
methods when called on object arrays, making them compatible with
[ decimal.Decimal](https://docs.python.org/3/library/decimal.html#decimal.Decimal) and

[objects.](https://docs.python.org/3/library/fractions.html#fractions.Fraction)
`fractions.Fraction`
`quantile`
now works on *fraction.Fraction* and `decimal.Decimal`
objects[#](#quantile-now-works-on-fraction-fraction-and-decimal-decimal-objects)
`quantile`
`decimal.Decimal`
In general, this handles object arrays more gracefully, and avoids floating- point operations if exact arithmetic types are used.

### Support of object arrays in `matmul`
[#](#support-of-object-arrays-in-matmul)
`matmul`
It is now possible to use [ matmul](../reference/generated/numpy.matmul.html#numpy.matmul) (or the

`@`
operator) with object arrays.
For instance, it is now possible to do:```
from fractions import Fraction
a = np.array([[Fraction(1, 2), Fraction(1, 3)], [Fraction(1, 3), Fraction(1, 2)]])
b = a @ a
```
## Changes[#](#changes)
`median`
and `percentile`
family of functions no longer warn about `nan`
[#](#median-and-percentile-family-of-functions-no-longer-warn-about-nan)
`median`
`percentile`
[ numpy.median](../reference/generated/numpy.median.html#numpy.median),
[, and](../reference/generated/numpy.percentile.html#numpy.percentile)
`numpy.percentile`
[used to emit a](../reference/generated/numpy.quantile.html#numpy.quantile)
`numpy.quantile`
`RuntimeWarning`
when encountering an [. Since they return the](../reference/constants.html#numpy.nan)
`nan`
`nan`
value, the warning is redundant and has been removed.`timedelta64 % 0`
behavior adjusted to return `NaT`
[#](#timedelta64-0-behavior-adjusted-to-return-nat)
The modulus operation with two `np.timedelta64`
operands now returns
`NaT`
in the case of division by zero, rather than returning zero

### NumPy functions now always support overrides with `__array_function__`
[#](#numpy-functions-now-always-support-overrides-with-array-function)
NumPy now always checks the `__array_function__`
method to implement overrides
of NumPy functions on non-NumPy arrays, as described in [NEP 18](http://www.numpy.org/neps/nep-0018-array-function-protocol.html). The feature
was available for testing with NumPy 1.16 if appropriate environment variables
are set, but is now always enabled.

`lib.recfunctions.structured_to_unstructured`
does not squeeze single-field views[#](#lib-recfunctions-structured-to-unstructured-does-not-squeeze-single-field-views)
Previously `structured_to_unstructured(arr[['a']])`
would produce a squeezed
result inconsistent with `structured_to_unstructured(arr[['a', b']])`
. This
was accidental. The old behavior can be retained with
`structured_to_unstructured(arr[['a']]).squeeze(axis=-1)`
or far more simply,
`arr['a']`
.

`clip`
now uses a ufunc under the hood[#](#clip-now-uses-a-ufunc-under-the-hood)
`clip`
This means that registering clip functions for custom dtypes in C via
`descr->f->fastclip`
is deprecated - they should use the ufunc registration
mechanism instead, attaching to the `np.core.umath.clip`
ufunc.

It also means that `clip`
accepts `where`
and `casting`
arguments,
and can be override with `__array_ufunc__`
.

A consequence of this change is that some behaviors of the old `clip`
have
been deprecated:

Passing

`nan`
to mean “do not clip” as one or both bounds. This didn’t work in all cases anyway, and can be better handled by passing infinities of the appropriate sign.
Using “unsafe” casting by default when an

`out`
argument is passed. Using`casting="unsafe"`
explicitly will silence this warning.
Additionally, there are some corner cases with behavior changes:

Padding

`max < min`
has changed to be more consistent across dtypes, but should not be relied upon.
Scalar

`min`
and`max`
take part in promotion rules like they do in all other ufuncs.
`__array_interface__`
offset now works as documented[#](#array-interface-offset-now-works-as-documented)
The interface may use an `offset`
value that was mistakenly ignored.

### Pickle protocol in `savez`
set to 3 for `force zip64`
flag[#](#pickle-protocol-in-savez-set-to-3-for-force-zip64-flag)
`savez`
[ savez](../reference/generated/numpy.savez.html#numpy.savez) was not using the
`force_zip64`
flag, which limited the size of
the archive to 2GB. But using the flag requires us to use pickle protocol 3 to
write `object`
arrays. The protocol used was bumped to 3, meaning the archive
will be unreadable by Python2.### Structured arrays indexed with non-existent fields raise `KeyError`
not `ValueError`
[#](#structured-arrays-indexed-with-non-existent-fields-raise-keyerror-not-valueerror)
`arr['bad_field']`
on a structured type raises `KeyError`
, for consistency
with `dict['bad_field']`
.# NumPy 1.7.0 Release Notes[#](#numpy-1-7-0-release-notes)
This release includes several new features as well as numerous bug fixes and refactorings. It supports Python 2.4 - 2.7 and 3.1 - 3.3 and is the last release that supports Python 2.4 - 2.5.

## Highlights[#](#highlights)
`where=`
parameter to ufuncs (allows the use of boolean arrays to choose where a computation should be done)
`vectorize`
improvements (added ‘excluded’ and ‘cache’ keyword, general cleanup and bug fixes)
`numpy.random.choice`
(random sample generating function)
## Compatibility notes[#](#compatibility-notes)
In a future version of numpy, the functions np.diag, np.diagonal, and the diagonal method of ndarrays will return a view onto the original array, instead of producing a copy as they do now. This makes a difference if you write to the array returned by any of these functions. To facilitate this transition, numpy 1.7 produces a FutureWarning if it detects that you may be attempting to write to such an array. See the documentation for np.diagonal for details.

Similar to np.diagonal above, in a future version of numpy, indexing a record array by a list of field names will return a view onto the original array, instead of producing a copy as they do now. As with np.diagonal, numpy 1.7 produces a FutureWarning if it detects that you may be attempting to write to such an array. See the documentation for array indexing for details.

In a future version of numpy, the default casting rule for UFunc out= parameters will be changed from ‘unsafe’ to ‘same_kind’. (This also applies to in-place operations like a += b, which is equivalent to np.add(a, b, out=a).) Most usages which violate the ‘same_kind’ rule are likely bugs, so this change may expose previously undetected errors in projects that depend on NumPy. In this version of numpy, such usages will continue to succeed, but will raise a DeprecationWarning.

Full-array boolean indexing has been optimized to use a different, optimized code path. This code path should produce the same results, but any feedback about changes to your code would be appreciated.

Attempting to write to a read-only array (one with `arr.flags.writeable`
set to `False`
) used to raise either a RuntimeError, ValueError, or
TypeError inconsistently, depending on which code path was taken. It now
consistently raises a ValueError.

The <ufunc>.reduce functions evaluate some reductions in a different order than in previous versions of NumPy, generally providing higher performance. Because of the nature of floating-point arithmetic, this may subtly change some results, just as linking NumPy to a different BLAS implementations such as MKL can.

If upgrading from 1.5, then generally in 1.6 and 1.7 there have been substantial code added and some code paths altered, particularly in the areas of type resolution and buffered iteration over universal functions. This might have an impact on your code particularly if you relied on accidental behavior in the past.

## New features[#](#new-features)
### Reduction UFuncs Generalize axis= Parameter[#](#reduction-ufuncs-generalize-axis-parameter)
Any ufunc.reduce function call, as well as other reductions like sum, prod, any, all, max and min support the ability to choose a subset of the axes to reduce over. Previously, one could say axis=None to mean all the axes or axis=# to pick a single axis. Now, one can also say axis=(#,#) to pick a list of axes for reduction.

### Reduction UFuncs New keepdims= Parameter[#](#reduction-ufuncs-new-keepdims-parameter)
There is a new keepdims= parameter, which if set to True, doesn’t throw away the reduction axes but instead sets them to have size one. When this option is set, the reduction result will broadcast correctly to the original operand which was reduced.

### Datetime support[#](#datetime-support)
Note

The datetime API is *experimental* in 1.7.0, and may undergo changes
in future versions of NumPy.

There have been a lot of fixes and enhancements to datetime64 compared to NumPy 1.6:

the parser is quite strict about only accepting ISO 8601 dates, with a few convenience extensions

converts between units correctly

datetime arithmetic works correctly

business day functionality (allows the datetime to be used in contexts where only certain days of the week are valid)

The notes in [doc/source/reference/arrays.datetime.rst](https://github.com/numpy/numpy/blob/maintenance/1.7.x/doc/source/reference/arrays.datetime.rst)
(also available in the online docs at [arrays.datetime.html](https://docs.scipy.org/doc/numpy/reference/arrays.datetime.html)) should be
consulted for more details.

### Custom formatter for printing arrays[#](#custom-formatter-for-printing-arrays)
See the new `formatter`
parameter of the `numpy.set_printoptions`
function.

### New function numpy.random.choice[#](#new-function-numpy-random-choice)
A generic sampling function has been added which will generate samples from a given array-like. The samples can be with or without replacement, and with uniform or given non-uniform probabilities.

### New function isclose[#](#new-function-isclose)
Returns a boolean array where two arrays are element-wise equal within a tolerance. Both relative and absolute tolerance can be specified.

### Preliminary multi-dimensional support in the polynomial package[#](#preliminary-multi-dimensional-support-in-the-polynomial-package)
Axis keywords have been added to the integration and differentiation functions and a tensor keyword was added to the evaluation functions. These additions allow multi-dimensional coefficient arrays to be used in those functions. New functions for evaluating 2-D and 3-D coefficient arrays on grids or sets of points were added together with 2-D and 3-D pseudo-Vandermonde matrices that can be used for fitting.

### Ability to pad rank-n arrays[#](#ability-to-pad-rank-n-arrays)
A pad module containing functions for padding n-dimensional arrays has been added. The various private padding functions are exposed as options to a public ‘pad’ function. Example:

```
pad(a, 5, mode='mean')
```
Current modes are `constant`
, `edge`
, `linear_ramp`
, `maximum`
,
`mean`
, `median`
, `minimum`
, `reflect`
, `symmetric`
, `wrap`
, and
`<function>`
.

### New argument to searchsorted[#](#new-argument-to-searchsorted)
The function searchsorted now accepts a ‘sorter’ argument that is a permutation array that sorts the array to search.

### Build system[#](#build-system)
Added experimental support for the AArch64 architecture.

### C API[#](#c-api)
New function `PyArray_FailUnlessWriteable`
provides a consistent interface
for checking array writeability – any C code which works with arrays whose
WRITEABLE flag is not known to be True a priori, should make sure to call
this function before writing.

NumPy C Style Guide added (`doc/C_STYLE_GUIDE.rst`
).

## Changes[#](#changes)
### General[#](#general)
The function np.concatenate tries to match the layout of its input arrays. Previously, the layout did not follow any particular reason, and depended in an undesirable way on the particular axis chosen for concatenation. A bug was also fixed which silently allowed out of bounds axis arguments.

The ufuncs logical_or, logical_and, and logical_not now follow Python’s behavior with object arrays, instead of trying to call methods on the objects. For example the expression (3 and ‘test’) produces the string ‘test’, and now np.logical_and(np.array(3, ‘O’), np.array(‘test’, ‘O’)) produces ‘test’ as well.

The `.base`
attribute on ndarrays, which is used on views to ensure that the
underlying array owning the memory is not deallocated prematurely, now
collapses out references when you have a view-of-a-view. For example:

```
a = np.arange(10)
b = a[1:]
c = b[1:]
```
In numpy 1.6, `c.base`
is `b`
, and `c.base.base`
is `a`
. In numpy 1.7,
`c.base`
is `a`
.

To increase backwards compatibility for software which relies on the old
behaviour of `.base`
, we only ‘skip over’ objects which have exactly the same
type as the newly created view. This makes a difference if you use `ndarray`
subclasses. For example, if we have a mix of `ndarray`
and `matrix`
objects
which are all views on the same original `ndarray`
:

```
a = np.arange(10)
b = np.asmatrix(a)
c = b[0, 1:]
d = c[0, 1:]
```
then `d.base`
will be `b`
. This is because `d`
is a `matrix`
object,
and so the collapsing process only continues so long as it encounters other
`matrix`
objects. It considers `c`
, `b`
, and `a`
in that order, and
`b`
is the last entry in that list which is a `matrix`
object.

### Casting Rules[#](#casting-rules)
Casting rules have undergone some changes in corner cases, due to the NA-related work. In particular for combinations of scalar+scalar:

the

*longlong*type (*q*) now stays*longlong*for operations with any other number (*? b h i l q p B H I*), previously it was cast as*int_*(*l*). The*ulonglong*type (*Q*) now stays as*ulonglong*instead of*uint*(*L*).
the

*timedelta64*type (*m*) can now be mixed with any integer type (*b h i l q p B H I L Q P*), previously it raised*TypeError*.
For array + scalar, the above rules just broadcast except the case when the array and scalars are unsigned/signed integers, then the result gets converted to the array type (of possibly larger size) as illustrated by the following examples:

```
>>> (np.zeros((2,), dtype=np.uint8) + np.int16(257)).dtype
dtype('uint16')
>>> (np.zeros((2,), dtype=np.int8) + np.uint16(257)).dtype
dtype('int16')
>>> (np.zeros((2,), dtype=np.int16) + np.uint32(2**17)).dtype
dtype('int32')
```
Whether the size gets increased depends on the size of the scalar, for example:

```
>>> (np.zeros((2,), dtype=np.uint8) + np.int16(255)).dtype
dtype('uint8')
>>> (np.zeros((2,), dtype=np.uint8) + np.int16(256)).dtype
dtype('uint16')
```
Also a `complex128`
scalar + `float32`
array is cast to `complex64`
.

In NumPy 1.7 the *datetime64* type (*M*) must be constructed by explicitly
specifying the type as the second argument (e.g. `np.datetime64(2000, 'Y')`
).

## Deprecations[#](#deprecations)
### General[#](#id1)
Specifying a custom string formatter with a *_format* array attribute is
deprecated. The new *formatter* keyword in `numpy.set_printoptions`
or
`numpy.array2string`
can be used instead.

The deprecated imports in the polynomial package have been removed.

`concatenate`
now raises DepractionWarning for 1D arrays if `axis != 0`
.
Versions of numpy < 1.7.0 ignored axis argument value for 1D arrays. We
allow this for now, but in due course we will raise an error.
### C-API[#](#id2)
Direct access to the fields of PyArrayObject* has been deprecated. Direct access has been recommended against for many releases. Expect similar deprecations for PyArray_Descr* and other core objects in the future as preparation for NumPy 2.0.

The macros in old_defines.h are deprecated and will be removed in the next major release (>= 2.0). The sed script tools/replace_old_macros.sed can be used to replace these macros with the newer versions.

You can test your code against the deprecated C API by adding a line
composed of `#define NPY_NO_DEPRECATED_API`
and the target version number,
such as `NPY_1_7_API_VERSION`
, before including any NumPy headers.

The `NPY_CHAR`
member of the `NPY_TYPES`
enum is deprecated and will be
removed in NumPy 1.8. See the discussion at
[gh-2801](https://github.com/numpy/numpy/issues/2801) for more details.# NumPy 1.10.2 Release Notes[#](#numpy-1-10-2-release-notes)
This release deals with a number of bugs that turned up in 1.10.1 and adds various build and release improvements.

Numpy 1.10.1 supports Python 2.6 - 2.7 and 3.2 - 3.5.

## Compatibility notes[#](#compatibility-notes)
### Relaxed stride checking is no longer the default[#](#relaxed-stride-checking-is-no-longer-the-default)
There were back compatibility problems involving views changing the dtype of multidimensional Fortran arrays that need to be dealt with over a longer timeframe.

### Fix swig bug in `numpy.i`
[#](#fix-swig-bug-in-numpy-i)
Relaxed stride checking revealed a bug in `array_is_fortran(a)`
, that was
using PyArray_ISFORTRAN to check for Fortran contiguity instead of
PyArray_IS_F_CONTIGUOUS. You may want to regenerate swigged files using the
updated numpy.i

### Deprecate views changing dimensions in fortran order[#](#deprecate-views-changing-dimensions-in-fortran-order)
This deprecates assignment of a new descriptor to the dtype attribute of a non-C-contiguous array if it result in changing the shape. This effectively bars viewing a multidimensional Fortran array using a dtype that changes the element size along the first axis.

The reason for the deprecation is that, when relaxed strides checking is enabled, arrays that are both C and Fortran contiguous are always treated as C contiguous which breaks some code that depended the two being mutually exclusive for non-scalar arrays of ndim > 1. This deprecation prepares the way to always enable relaxed stride checking.

## Issues Fixed[#](#issues-fixed)
gh-6019 Masked array repr fails for structured array with multi-dimensional column.

gh-6462 Median of empty array produces IndexError.

gh-6467 Performance regression for record array access.

gh-6468 numpy.interp uses ‘left’ value even when x[0]==xp[0].

gh-6475 np.allclose returns a memmap when one of its arguments is a memmap.

gh-6491 Error in broadcasting stride_tricks array.

gh-6495 Unrecognized command line option ‘-ffpe-summary’ in gfortran.

gh-6497 Failure of reduce operation on recarrays.

gh-6498 Mention change in default casting rule in 1.10 release notes.

gh-6530 The partition function errors out on empty input.

gh-6532 numpy.inner return wrong inaccurate value sometimes.

gh-6563 Intent(out) broken in recent versions of f2py.

gh-6569 Cannot run tests after ‘python setup.py build_ext -i’

gh-6572 Error in broadcasting stride_tricks array component.

gh-6575 BUG: Split produces empty arrays with wrong number of dimensions

gh-6590 Fortran Array problem in numpy 1.10.

gh-6602 Random __all__ missing choice and dirichlet.

gh-6611 ma.dot no longer always returns a masked array in 1.10.

gh-6618 NPY_FORTRANORDER in make_fortran() in numpy.i

gh-6636 Memory leak in nested dtypes in numpy.recarray

gh-6641 Subsetting recarray by fields yields a structured array.

gh-6667 ma.make_mask handles ma.nomask input incorrectly.

gh-6675 Optimized blas detection broken in master and 1.10.

gh-6678 Getting unexpected error from: X.dtype = complex (or Y = X.view(complex))

gh-6718 f2py test fail in pip installed numpy-1.10.1 in virtualenv.

gh-6719 Error compiling Cython file: Pythonic division not allowed without gil.

gh-6771 Numpy.rec.fromarrays losing dtype metadata between versions 1.9.2 and 1.10.1

gh-6781 The travis-ci script in maintenance/1.10.x needs fixing.

gh-6807 Windows testing errors for 1.10.2

## Merged PRs[#](#merged-prs)
The following PRs have been merged into 1.10.2. When the PR is a backport, the PR number for the original PR against master is listed.

gh-5773 MAINT: Hide testing helper tracebacks when using them with pytest.

gh-6094 BUG: Fixed a bug with string representation of masked structured arrays.

gh-6208 MAINT: Speedup field access by removing unneeded safety checks.

gh-6460 BUG: Replacing the os.environ.clear by less invasive procedure.

gh-6470 BUG: Fix AttributeError in numpy distutils.

gh-6472 MAINT: Use Python 3.5 instead of 3.5-dev for travis 3.5 testing.

gh-6474 REL: Update Paver script for sdist and auto-switch test warnings.

gh-6478 BUG: Fix Intel compiler flags for OS X build.

gh-6481 MAINT: LIBPATH with spaces is now supported Python 2.7+ and Win32.

gh-6487 BUG: Allow nested use of parameters in definition of arrays in f2py.

gh-6488 BUG: Extend common blocks rather than overwriting in f2py.

gh-6499 DOC: Mention that default casting for inplace operations has changed.

gh-6500 BUG: Recarrays viewed as subarrays don’t convert to np.record type.

gh-6501 REL: Add “make upload” command for built docs, update “make dist”.

gh-6526 BUG: Fix use of __doc__ in setup.py for -OO mode.

gh-6527 BUG: Fix the IndexError when taking the median of an empty array.

gh-6537 BUG: Make ma.atleast_* with scalar argument return arrays.

gh-6538 BUG: Fix ma.masked_values does not shrink mask if requested.

gh-6546 BUG: Fix inner product regression for non-contiguous arrays.

gh-6553 BUG: Fix partition and argpartition error for empty input.

gh-6556 BUG: Error in broadcast_arrays with as_strided array.

gh-6558 MAINT: Minor update to “make upload” doc build command.

gh-6562 BUG: Disable view safety checks in recarray.

gh-6567 BUG: Revert some import * fixes in f2py.

gh-6574 DOC: Release notes for Numpy 1.10.2.

gh-6577 BUG: Fix for #6569, allowing build_ext –inplace

gh-6579 MAINT: Fix mistake in doc upload rule.

gh-6596 BUG: Fix swig for relaxed stride checking.

gh-6606 DOC: Update 1.10.2 release notes.

gh-6614 BUG: Add choice and dirichlet to numpy.random.__all__.

gh-6621 BUG: Fix swig make_fortran function.

gh-6628 BUG: Make allclose return python bool.

gh-6642 BUG: Fix memleak in _convert_from_dict.

gh-6643 ENH: make recarray.getitem return a recarray.

gh-6653 BUG: Fix ma dot to always return masked array.

gh-6668 BUG: ma.make_mask should always return nomask for nomask argument.

gh-6686 BUG: Fix a bug in assert_string_equal.

gh-6695 BUG: Fix removing tempdirs created during build.

gh-6697 MAINT: Fix spurious semicolon in macro definition of PyArray_FROM_OT.

gh-6698 TST: test np.rint bug for large integers.

gh-6717 BUG: Readd fallback CBLAS detection on linux.

gh-6721 BUG: Fix for #6719.

gh-6726 BUG: Fix bugs exposed by relaxed stride rollback.

gh-6757 BUG: link cblas library if cblas is detected.

gh-6756 TST: only test f2py, not f2py2.7 etc, fixes #6718.

gh-6747 DEP: Deprecate changing shape of non-C-contiguous array via descr.

gh-6775 MAINT: Include from __future__ boilerplate in some files missing it.

gh-6780 BUG: metadata is not copied to base_dtype.

gh-6783 BUG: Fix travis ci testing for new google infrastructure.

gh-6785 BUG: Quick and dirty fix for interp.

gh-6813 TST,BUG: Make test_mvoid_multidim_print work for 32 bit systems.

gh-6817 BUG: Disable 32-bit msvc9 compiler optimizations for npy_rint.

gh-6819 TST: Fix test_mvoid_multidim_print failures on Python 2.x for Windows.

Initial support for mingwpy was reverted as it was causing problems for non-windows builds.

gh-6536 BUG: Revert gh-5614 to fix non-windows build problems

A fix for np.lib.split was reverted because it resulted in “fixing” behavior that will be present in the Numpy 1.11 and that was already present in Numpy 1.9. See the discussion of the issue at gh-6575 for clarification.

gh-6576 BUG: Revert gh-6376 to fix split behavior for empty arrays.

Relaxed stride checking was reverted. There were back compatibility problems involving views changing the dtype of multidimensional Fortran arrays that need to be dealt with over a longer timeframe.

gh-6735 MAINT: Make no relaxed stride checking the default for 1.10.

## Notes[#](#notes)
A bug in the Numpy 1.10.1 release resulted in exceptions being raised for
`RuntimeWarning`
and `DeprecationWarning`
in projects depending on Numpy.
That has been fixed.# The array interface protocol[#](#the-array-interface-protocol)
Note

This page describes the NumPy-specific API for accessing the contents of
a NumPy array from other C extensions. [ PEP 3118](https://peps.python.org/pep-3118/) –

[introduces similar, standardized API to Python 2.6 and 3.0 for any extension module to use.](https://docs.python.org/3/c-api/buffer.html#c.PyObject_GetBuffer)
`The Revised Buffer Protocol`
[Cython](http://cython.org/)’s buffer array support uses the
[API; see the](https://peps.python.org/pep-3118/)
**PEP 3118**[Cython NumPy tutorial](https://github.com/cython/cython/wiki/tutorials-numpy). Cython provides a way to write code that supports the buffer protocol with Python versions older than 2.6 because it has a backward-compatible implementation utilizing the array interface described here.
version:
-
3

The array interface (sometimes called array protocol) was created in 2005 as a means for array-like Python objects to re-use each other’s data buffers intelligently whenever possible. The homogeneous N-dimensional array interface is a default mechanism for objects to share N-dimensional array memory and information. The interface consists of a Python-side and a C-side using two attributes. Objects wishing to be considered an N-dimensional array in application code should support at least one of these attributes. Objects wishing to support an N-dimensional array in application code should look for at least one of these attributes and use the information provided appropriately.

This interface describes homogeneous arrays in the sense that each item of the array has the same “type”. This type can be very simple or it can be a quite arbitrary and complicated C-like structure.

There are two ways to use the interface: A Python side and a C-side. Both are separate attributes.

## Python side[#](#python-side)
This approach to the interface consists of the object having an
[ __array_interface__](#object.__array_interface__) attribute.

object.__array_interface__[#](#object.__array_interface__)
-
A dictionary of items (3 required and 5 optional). The optional keys in the dictionary have implied defaults if they are not provided.

The keys are:

**shape**(required)
Tuple whose elements are the array size in each dimension. Each entry is an integer (a Python

). Note that these integers could be larger than the platform`int`
`int`
or`long`
could hold (a Pythonis a C`int`
`long`
). It is up to the code using this attribute to handle this appropriately; either by raising an error when overflow is possible, or by using`long long`
as the C type for the shapes.
**typestr**(required)
A string providing the basic type of the homogeneous array The basic string format consists of 3 parts: a character describing the byteorder of the data (

`<`
: little-endian,`>`
: big-endian,`|`
: not-relevant), a character code giving the basic type of the array, and an integer providing the number of bytes the type uses.The basic type character codes are:

`t`
Bit field (following integer gives the number of bits in the bit field).

`b`
Boolean (integer type where all values are only

`True`
or`False`
)`i`
Integer

`u`
Unsigned integer

`f`
Floating point

`c`
Complex floating point

`m`
Timedelta

`M`
Datetime

`O`
Object (i.e. the memory contains a pointer to

)`PyObject`
`S`
String (fixed-length sequence of char)

`U`
Unicode (fixed-length sequence of

)`Py_UCS4`
`V`
Other (void * – each item is a fixed-size chunk of memory)

**descr**(optional)
A list of tuples providing a more detailed description of the memory layout for each item in the homogeneous array. Each tuple in the list has two or three elements. Normally, this attribute would be used when

*typestr*is`V[0-9]+`
, but this is not a requirement. The only requirement is that the number of bytes represented in the*typestr*key is the same as the total number of bytes represented here. The idea is to support descriptions of C-like structs that make up array elements. The elements of each tuple in the list areA string providing a name associated with this portion of the datatype. This could also be a tuple of

`('full name', 'basic_name')`
where basic name would be a valid Python variable name representing the full name of the field.
Either a basic-type description string as in

*typestr*or another list (for nested structured types)
An optional shape tuple providing how many times this part of the structure should be repeated. No repeats are assumed if this is not given. Very complicated structures can be described using this generic interface. Notice, however, that each element of the array is still of the same data-type. Some examples of using this interface are given below.

**Default**:`[('', typestr)]`
**data**(optional)
A 2-tuple whose first argument is a

[Python integer](https://docs.python.org/3/c-api/long.html)that points to the data-area storing the array contents.Note

When converting from C/C++ via

`PyLong_From*`
or high-level bindings such as Cython or pybind11, make sure to use an integer of sufficiently large bitness.This pointer must point to the first element of data (in other words any offset is always ignored in this case). The second entry in the tuple is a read-only flag (true means the data area is read-only).

This attribute can also be an object exposing the

[buffer interface](https://docs.python.org/3/c-api/buffer.html#bufferobjects)which will be used to share the data. If this key is not present (or returns None), then memory sharing will be done through the buffer interface of the object itself. In this case, the offset key can be used to indicate the start of the buffer. A reference to the object exposing the array interface must be stored by the new object if the memory area is to be secured.**Default**:`None`
**strides**(optional)
Either

`None`
to indicate a C-style contiguous array or a tuple of strides which provides the number of bytes needed to jump to the next array element in the corresponding dimension. Each entry must be an integer (a Python). As with shape, the values may be larger than can be represented by a C`int`
`int`
or`long`
; the calling code should handle this appropriately, either by raising an error, or by using`long long`
in C. The default is`None`
which implies a C-style contiguous memory buffer. In this model, the last dimension of the array varies the fastest. For example, the default strides tuple for an object whose array entries are 8 bytes long and whose shape is`(10, 20, 30)`
would be`(4800, 240, 8)`
.**Default**:`None`
(C-style contiguous)
**mask**(optional)
`None`
or an object exposing the array interface. All elements of the mask array should be interpreted only as true or not true indicating which elements of this array are valid. The shape of this object should be*“broadcastable”*to the shape of the original array.**Default**:`None`
(All array values are valid)
**offset**(optional)
An integer offset into the array data region. This can only be used when data is

`None`
or returns a`buffer`
object.**Default**:`0`
.
**version**(required)
An integer showing the version of the interface (i.e. 3 for this version). Be careful not to use this to invalidate objects exposing future versions of the interface.

## C-struct access[#](#c-struct-access)
This approach to the array interface allows for faster access to an array using only one attribute lookup and a well-defined C-structure.

object.__array_struct__[#](#object.__array_struct__)
-
A

whose`PyCapsule`
`pointer`
member contains a pointer to a filledstructure. Memory for the structure is dynamically created and the`PyArrayInterface`
is also created with an appropriate destructor so the retriever of this attribute simply has to apply`PyCapsule`
to the object returned by this attribute when it is finished. Also, either the data needs to be copied out, or a reference to the object exposing this attribute must be held to ensure the data is not freed. Objects exposing the`Py_DECREF`
interface must also not reallocate their memory if other objects are referencing them.`__array_struct__`
The [ PyArrayInterface](c-api/types-and-structures.html#c.PyArrayInterface) structure is defined in

`numpy/ndarrayobject.h`
as:```
typedef struct {
int two; /* contains the integer 2 -- simple sanity check */
int nd; /* number of dimensions */
char typekind; /* kind in array --- character code of typestr */
int itemsize; /* size of each element */
int flags; /* flags indicating how the data should be interpreted */
/* must set ARR_HAS_DESCR bit to validate descr */
Py_intptr_t *shape; /* A length-nd array of shape information */
Py_intptr_t *strides; /* A length-nd array of stride information */
void *data; /* A pointer to the first element of the array */
PyObject *descr; /* NULL or data-description (same as descr key
of __array_interface__) -- must set ARR_HAS_DESCR
flag or this will be ignored. */
} PyArrayInterface;
```
The flags member may consist of 5 bits showing how the data should be
interpreted and one bit showing how the Interface should be
interpreted. The data-bits are [ NPY_ARRAY_C_CONTIGUOUS](c-api/array.html#c.NPY_ARRAY_C_CONTIGUOUS) (0x1),

[(0x2),](c-api/array.html#c.NPY_ARRAY_F_CONTIGUOUS)
`NPY_ARRAY_F_CONTIGUOUS`
[(0x100),](c-api/array.html#c.NPY_ARRAY_ALIGNED)
`NPY_ARRAY_ALIGNED`
[(0x200), and](c-api/array.html#c.NPY_ARRAY_NOTSWAPPED)
`NPY_ARRAY_NOTSWAPPED`
[(0x400). A final flag](c-api/array.html#c.NPY_ARRAY_WRITEABLE)
`NPY_ARRAY_WRITEABLE`
[(0x800) indicates whether or not this structure has the arrdescr field. The field should not be accessed unless this flag is present.](#c.NPY_ARR_HAS_DESCR)
`NPY_ARR_HAS_DESCR`
NPY_ARR_HAS_DESCR
-
[#]
New since June 16, 2006:

In the past most implementations used the `desc`
member of the `PyCObject`
(now [ PyCapsule](https://docs.python.org/3/c-api/capsule.html#c.PyCapsule)) itself (do not confuse this with the “descr” member of
the

[structure above — they are two separate things) to hold the pointer to the object exposing the interface. This is now an explicit part of the interface. Be sure to take a reference to the object and call](c-api/types-and-structures.html#c.PyArrayInterface)
`PyArrayInterface`
[before returning the](https://docs.python.org/3/c-api/capsule.html#c.PyCapsule_SetContext)
`PyCapsule_SetContext`
[, and configure a destructor to decref this reference.](https://docs.python.org/3/c-api/capsule.html#c.PyCapsule)
`PyCapsule`
Note

`__array_struct__`
is considered legacy and should not be used for new
code. Use the [buffer protocol](https://docs.python.org/3/c-api/buffer.html) or the DLPack protocol
[ numpy.from_dlpack](generated/numpy.from_dlpack.html#numpy.from_dlpack) instead.
## Type description examples[#](#type-description-examples)
For clarity it is useful to provide some examples of the type
description and corresponding [ __array_interface__](#object.__array_interface__) ‘descr’
entries. Thanks to Scott Gilbert for these examples:

In every case, the ‘descr’ key is optional, but of course provides more information which may be important for various applications:

```
* Float data
typestr == '>f4'
descr == [('','>f4')]
* Complex double
typestr == '>c8'
descr == [('real','>f4'), ('imag','>f4')]
* RGB Pixel data
typestr == '|V3'
descr == [('r','|u1'), ('g','|u1'), ('b','|u1')]
* Mixed endian (weird but could happen).
typestr == '|V8' (or '>u8')
descr == [('big','>i4'), ('little','<i4')]
* Nested structure
struct {
int ival;
struct {
unsigned short sval;
unsigned char bval;
unsigned char cval;
} sub;
}
typestr == '|V8' (or '<u8' if you want)
descr == [('ival','<i4'), ('sub', [('sval','<u2'), ('bval','|u1'), ('cval','|u1') ]) ]
* Nested array
struct {
int ival;
double data[16*4];
}
typestr == '|V516'
descr == [('ival','>i4'), ('data','>f8',(16,4))]
* Padded structure
struct {
int ival;
double dval;
}
typestr == '|V16'
descr == [('ival','>i4'),('','|V4'),('dval','>f8')]
```
It should be clear that any structured type could be described using this interface.

## Differences with Array interface (Version 2)[#](#differences-with-array-interface-version-2)
The version 2 interface was very similar. The differences were largely aesthetic. In particular:

The PyArrayInterface structure had no descr member at the end (and therefore no flag ARR_HAS_DESCR)

The

`context`
member of the(formally the`PyCapsule`
`desc`
member of the`PyCObject`
) returned from`__array_struct__`
was not specified. Usually, it was the object exposing the array (so that a reference to it could be kept and destroyed when the C-object was destroyed). It is now an explicit requirement that this field be used in some way to hold a reference to the owning object.Note

Until August 2020, this said:

Now it must be a tuple whose first element is a string with “PyArrayInterface Version #” and whose second element is the object exposing the array.

This design was retracted almost immediately after it was proposed, in <

[https://mail.python.org/pipermail/numpy-discussion/2006-June/020995.html](https://mail.python.org/pipermail/numpy-discussion/2006-June/020995.html)>. Despite 14 years of documentation to the contrary, at no point was it valid to assume that`__array_interface__`
capsules held this tuple content.
The tuple returned from

`__array_interface__['data']`
used to be a hex-string (now it is an integer or a long integer).
There was no

`__array_interface__`
attribute instead all of the keys (except for version) in the`__array_interface__`
dictionary were their own attribute: Thus to obtain the Python-side information you had to access separately the attributes:`__array_data__`
`__array_shape__`
`__array_strides__`
`__array_typestr__`
`__array_descr__`
`__array_offset__`
`__array_mask__`# NumPy 1.6.0 Release Notes[#](#numpy-1-6-0-release-notes)
This release includes several new features as well as numerous bug fixes and improved documentation. It is backward compatible with the 1.5.0 release, and supports Python 2.4 - 2.7 and 3.1 - 3.2.

## Highlights[#](#highlights)
Re-introduction of datetime dtype support to deal with dates in arrays.

A new 16-bit floating point type.

A new iterator, which improves performance of many functions.

## New features[#](#new-features)
### New 16-bit floating point type[#](#new-16-bit-floating-point-type)
This release adds support for the IEEE 754-2008 binary16 format, available as
the data type `numpy.half`
. Within Python, the type behaves similarly to
*float* or *double*, and C extensions can add support for it with the exposed
half-float API.

### New iterator[#](#new-iterator)
A new iterator has been added, replacing the functionality of the existing iterator and multi-iterator with a single object and API. This iterator works well with general memory layouts different from C or Fortran contiguous, and handles both standard NumPy and customized broadcasting. The buffering, automatic data type conversion, and optional output parameters, offered by ufuncs but difficult to replicate elsewhere, are now exposed by this iterator.

### Legendre, Laguerre, Hermite, HermiteE polynomials in `numpy.polynomial`
[#](#legendre-laguerre-hermite-hermitee-polynomials-in-numpy-polynomial)
Extend the number of polynomials available in the polynomial package. In
addition, a new `window`
attribute has been added to the classes in
order to specify the range the `domain`
maps to. This is mostly useful
for the Laguerre, Hermite, and HermiteE polynomials whose natural domains
are infinite and provides a more intuitive way to get the correct mapping
of values without playing unnatural tricks with the domain.

### Fortran assumed shape array and size function support in `numpy.f2py`
[#](#fortran-assumed-shape-array-and-size-function-support-in-numpy-f2py)
F2py now supports wrapping Fortran 90 routines that use assumed shape arrays. Before such routines could be called from Python but the corresponding Fortran routines received assumed shape arrays as zero length arrays which caused unpredicted results. Thanks to Lorenz Hüdepohl for pointing out the correct way to interface routines with assumed shape arrays.

In addition, f2py supports now automatic wrapping of Fortran routines
that use two argument `size`
function in dimension specifications.

### Other new functions[#](#other-new-functions)
`numpy.ravel_multi_index`
: Converts a multi-index tuple into
an array of flat indices, applying boundary modes to the indices.
`numpy.einsum`
: Evaluate the Einstein summation convention. Using the
Einstein summation convention, many common multi-dimensional array operations
can be represented in a simple fashion. This function provides a way compute
such summations.
`numpy.count_nonzero`
: Counts the number of non-zero elements in an array.
`numpy.result_type`
and `numpy.min_scalar_type`
: These functions expose
the underlying type promotion used by the ufuncs and other operations to
determine the types of outputs. These improve upon the `numpy.common_type`
and `numpy.mintypecode`
which provide similar functionality but do
not match the ufunc implementation.
## Changes[#](#changes)
`default error handling`
[#](#default-error-handling)
The default error handling has been change from `print`
to `warn`
for
all except for `underflow`
, which remains as `ignore`
.

`numpy.distutils`
[#](#numpy-distutils)
Several new compilers are supported for building Numpy: the Portland Group Fortran compiler on OS X, the PathScale compiler suite and the 64-bit Intel C compiler on Linux.

`numpy.testing`
[#](#numpy-testing)
The testing framework gained `numpy.testing.assert_allclose`
, which provides
a more convenient way to compare floating point arrays than
*assert_almost_equal*, *assert_approx_equal* and *assert_array_almost_equal*.

`C API`
[#](#c-api)
In addition to the APIs for the new iterator and half data type, a number
of other additions have been made to the C API. The type promotion
mechanism used by ufuncs is exposed via `PyArray_PromoteTypes`
,
`PyArray_ResultType`
, and `PyArray_MinScalarType`
. A new enumeration
`NPY_CASTING`
has been added which controls what types of casts are
permitted. This is used by the new functions `PyArray_CanCastArrayTo`
and `PyArray_CanCastTypeTo`
. A more flexible way to handle
conversion of arbitrary python objects into arrays is exposed by
`PyArray_GetArrayParamsFromObject`
.

## Deprecated features[#](#deprecated-features)
The “normed” keyword in `numpy.histogram`
is deprecated. Its functionality
will be replaced by the new “density” keyword.

## Removed features[#](#removed-features)
`numpy.fft`
[#](#numpy-fft)
The functions *refft*, *refft2*, *refftn*, *irefft*, *irefft2*, *irefftn*,
which were aliases for the same functions without the ‘e’ in the name, were
removed.

`numpy.memmap`
[#](#numpy-memmap)
The *sync()* and *close()* methods of memmap were removed. Use *flush()* and
“del memmap” instead.

`numpy.lib`
[#](#numpy-lib)
The deprecated functions `numpy.unique1d`
, `numpy.setmember1d`
,
`numpy.intersect1d_nu`
and `numpy.lib.ufunclike.log2`
were removed.

`numpy.ma`
[#](#numpy-ma)
Several deprecated items were removed from the `numpy.ma`
module:

```
* ``numpy.ma.MaskedArray`` "raw_data" method
* ``numpy.ma.MaskedArray`` constructor "flag" keyword
* ``numpy.ma.make_mask`` "flag" keyword
* ``numpy.ma.allclose`` "fill_value" keyword
```
`numpy.distutils`
[#](#id1)
The `numpy.get_numpy_include`
function was removed, use `numpy.get_include`
instead.# NumPy 1.23.4 Release Notes[#](#numpy-1-23-4-release-notes)
NumPy 1.23.4 is a maintenance release that fixes bugs discovered after the
1.23.3 release and keeps the build infrastructure current. The main
improvements are fixes for some annotation corner cases, a fix for a long time
`nested_iters`
memory leak, and a fix of complex vector dot for very large
arrays. The Python versions supported for this release are 3.8-3.11.

Note that the mypy version needs to be 0.981+ if you test using Python 3.10.7, otherwise the typing tests will fail.

## Contributors[#](#contributors)
A total of 8 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Bas van Beek

Charles Harris

Matthew Barber

Matti Picus

Ralf Gommers

Ross Barnowski

Sebastian Berg

Sicheng Zeng +

## Pull requests merged[#](#pull-requests-merged)
A total of 13 pull requests were merged for this release.

[#22368](https://github.com/numpy/numpy/pull/22368): BUG: Add`__array_api_version__`
to`numpy.array_api`
namespace
[#22370](https://github.com/numpy/numpy/pull/22370): MAINT: update sde toolkit to 9.0, fix download link
[#22382](https://github.com/numpy/numpy/pull/22382): BLD: use macos-11 image on azure, macos-1015 is deprecated
[#22383](https://github.com/numpy/numpy/pull/22383): MAINT: random: remove`get_info`
from “extending with Cython”…
[#22384](https://github.com/numpy/numpy/pull/22384): BUG: Fix complex vector dot with more than NPY_CBLAS_CHUNK elements
[#22387](https://github.com/numpy/numpy/pull/22387): REV: Loosen`lookfor`
’s import try/except again
[#22388](https://github.com/numpy/numpy/pull/22388): TYP,ENH: Mark`numpy.typing`
protocols as runtime checkable
[#22389](https://github.com/numpy/numpy/pull/22389): TYP,MAINT: Change more overloads to play nice with pyright
[#22390](https://github.com/numpy/numpy/pull/22390): TST,TYP: Bump mypy to 0.981
[#22391](https://github.com/numpy/numpy/pull/22391): DOC: Update delimiter param description.
[#22392](https://github.com/numpy/numpy/pull/22392): BUG: Memory leaks in numpy.nested_iters
[#22413](https://github.com/numpy/numpy/pull/22413): REL: Prepare for the NumPy 1.23.4 release.
[#22424](https://github.com/numpy/numpy/pull/22424): TST: Fix failing aarch64 wheel builds.# NumPy 1.12.0 Release Notes[#](#numpy-1-12-0-release-notes)
This release supports Python 2.7 and 3.4 - 3.6.

## Highlights[#](#highlights)
The NumPy 1.12.0 release contains a large number of fixes and improvements, but few that stand out above all others. That makes picking out the highlights somewhat arbitrary but the following may be of particular interest or indicate areas likely to have future consequences.

Order of operations in

`np.einsum`
can now be optimized for large speed improvements.
New

`signature`
argument to`np.vectorize`
for vectorizing with core dimensions.
The

`keepdims`
argument was added to many functions.
New context manager for testing warnings

Support for BLIS in numpy.distutils

Much improved support for PyPy (not yet finished)

## Dropped Support[#](#dropped-support)
Support for Python 2.6, 3.2, and 3.3 has been dropped.

## Added Support[#](#added-support)
Support for PyPy 2.7 v5.6.0 has been added. While not complete (nditer

`updateifcopy`
is not supported yet), this is a milestone for PyPy’s C-API compatibility layer.
## Build System Changes[#](#build-system-changes)
Library order is preserved, instead of being reordered to match that of the directories.

## Deprecations[#](#deprecations)
### Assignment of ndarray object’s `data`
attribute[#](#assignment-of-ndarray-object-s-data-attribute)
Assigning the ‘data’ attribute is an inherently unsafe operation as pointed out in gh-7083. Such a capability will be removed in the future.

### Unsafe int casting of the num attribute in `linspace`
[#](#unsafe-int-casting-of-the-num-attribute-in-linspace)
`np.linspace`
now raises DeprecationWarning when num cannot be safely
interpreted as an integer.
### Insufficient bit width parameter to `binary_repr`
[#](#insufficient-bit-width-parameter-to-binary-repr)
If a ‘width’ parameter is passed into `binary_repr`
that is insufficient to
represent the number in base 2 (positive) or 2’s complement (negative) form,
the function used to silently ignore the parameter and return a representation
using the minimal number of bits needed for the form in question. Such behavior
is now considered unsafe from a user perspective and will raise an error in the
future.

## Future Changes[#](#future-changes)
In 1.13 NAT will always compare False except for

`NAT != NAT`
, which will be True. In short, NAT will behave like NaN
In 1.13

`np.average`
will preserve subclasses, to match the behavior of most other numpy functions such as np.mean. In particular, this means calls which returned a scalar may return a 0-d subclass object instead.
### Multiple-field manipulation of structured arrays[#](#multiple-field-manipulation-of-structured-arrays)
In 1.13 the behavior of structured arrays involving multiple fields will change in two ways:

First, indexing a structured array with multiple fields (eg,
`arr[['f1', 'f3']]`
) will return a view into the original array in 1.13,
instead of a copy. Note the returned view will have extra padding bytes
corresponding to intervening fields in the original array, unlike the copy in
1.12, which will affect code such as `arr[['f1', 'f3']].view(newdtype)`
.

Second, for numpy versions 1.6 to 1.12 assignment between structured arrays occurs “by field name”: Fields in the destination array are set to the identically-named field in the source array or to 0 if the source does not have a field:

```
>>> a = np.array([(1,2),(3,4)], dtype=[('x', 'i4'), ('y', 'i4')])
>>> b = np.ones(2, dtype=[('z', 'i4'), ('y', 'i4'), ('x', 'i4')])
>>> b[:] = a
>>> b
array([(0, 2, 1), (0, 4, 3)],
dtype=[('z', '<i4'), ('y', '<i4'), ('x', '<i4')])
```
In 1.13 assignment will instead occur “by position”: The Nth field of the
destination will be set to the Nth field of the source regardless of field
name. The old behavior can be obtained by using indexing to reorder the fields
before
assignment, e.g., `b[['x', 'y']] = a[['y', 'x']]`
.

## Compatibility notes[#](#compatibility-notes)
### DeprecationWarning to error[#](#deprecationwarning-to-error)
Indexing with floats raises

`IndexError`
, e.g., a[0, 0.0].
Indexing with non-integer array_like raises

`IndexError`
, e.g.,`a['1', '2']`
Indexing with multiple ellipsis raises

`IndexError`
, e.g.,`a[..., ...]`
.
Non-integers used as index values raise

`TypeError`
, e.g., in`reshape`
,`take`
, and specifying reduce axis.
### FutureWarning to changed behavior[#](#futurewarning-to-changed-behavior)
`np.full`
now returns an array of the fill-value’s dtype if no dtype is given, instead of defaulting to float.
`np.average`
will emit a warning if the argument is a subclass of ndarray, as the subclass will be preserved starting in 1.13. (see Future Changes)
`power`
and `**`
raise errors for integer to negative integer powers[#](#power-and-raise-errors-for-integer-to-negative-integer-powers)
The previous behavior depended on whether numpy scalar integers or numpy integer arrays were involved.

For arrays

Zero to negative integer powers returned least integral value.

Both 1, -1 to negative integer powers returned correct values.

The remaining integers returned zero when raised to negative integer powers.

For scalars

Zero to negative integer powers returned least integral value.

Both 1, -1 to negative integer powers returned correct values.

The remaining integers sometimes returned zero, sometimes the correct float depending on the integer type combination.

All of these cases now raise a `ValueError`
except for those integer
combinations whose common type is float, for instance uint64 and int8. It was
felt that a simple rule was the best way to go rather than have special
exceptions for the integer units. If you need negative powers, use an inexact
type.

### Relaxed stride checking is the default[#](#relaxed-stride-checking-is-the-default)
This will have some impact on code that assumed that `F_CONTIGUOUS`
and
`C_CONTIGUOUS`
were mutually exclusive and could be set to determine the
default order for arrays that are now both.

### The `np.percentile`
‘midpoint’ interpolation method fixed for exact indices[#](#the-np-percentile-midpoint-interpolation-method-fixed-for-exact-indices)
The ‘midpoint’ interpolator now gives the same result as ‘lower’ and ‘higher’ when the two coincide. Previous behavior of ‘lower’ + 0.5 is fixed.

`keepdims`
kwarg is passed through to user-class methods[#](#keepdims-kwarg-is-passed-through-to-user-class-methods)
numpy functions that take a `keepdims`
kwarg now pass the value
through to the corresponding methods on ndarray sub-classes. Previously the
`keepdims`
keyword would be silently dropped. These functions now have
the following behavior:

If user does not provide

`keepdims`
, no keyword is passed to the underlying method.
Any user-provided value of

`keepdims`
is passed through as a keyword argument to the method.
This will raise in the case where the method does not support a
`keepdims`
kwarg and the user explicitly passes in `keepdims`
.

The following functions are changed: `sum`
, `product`
,
`sometrue`
, `alltrue`
, `any`
, `all`
, `amax`
, `amin`
,
`prod`
, `mean`
, `std`
, `var`
, `nanmin`
, `nanmax`
,
`nansum`
, `nanprod`
, `nanmean`
, `nanmedian`
, `nanvar`
,
`nanstd`

`bitwise_and`
identity changed[#](#bitwise-and-identity-changed)
The previous identity was 1, it is now -1. See entry in Improvements for more explanation.

### ma.median warns and returns nan when unmasked invalid values are encountered[#](#ma-median-warns-and-returns-nan-when-unmasked-invalid-values-are-encountered)
Similar to unmasked median the masked median *ma.median* now emits a Runtime
warning and returns *NaN* in slices where an unmasked *NaN* is present.

### Greater consistency in `assert_almost_equal`
[#](#greater-consistency-in-assert-almost-equal)
The precision check for scalars has been changed to match that for arrays. It is now:

```
abs(actual - desired) < 1.5 * 10**(-decimal)
```
Note that this is looser than previously documented, but agrees with the
previous implementation used in `assert_array_almost_equal`
. Due to the
change in implementation some very delicate tests may fail that did not
fail before.

`NoseTester`
behaviour of warnings during testing[#](#nosetester-behaviour-of-warnings-during-testing)
When `raise_warnings="develop"`
is given, all uncaught warnings will now
be considered a test failure. Previously only selected ones were raised.
Warnings which are not caught or raised (mostly when in release mode)
will be shown once during the test cycle similar to the default python
settings.

`assert_warns`
and `deprecated`
decorator more specific[#](#assert-warns-and-deprecated-decorator-more-specific)
The `assert_warns`
function and context manager are now more specific
to the given warning category. This increased specificity leads to them
being handled according to the outer warning settings. This means that
no warning may be raised in cases where a wrong category warning is given
and ignored outside the context. Alternatively the increased specificity
may mean that warnings that were incorrectly ignored will now be shown
or raised. See also the new `suppress_warnings`
context manager.
The same is true for the `deprecated`
decorator.

### C API[#](#c-api)
No changes.

## New Features[#](#new-features)
### Writeable keyword argument for `as_strided`
[#](#writeable-keyword-argument-for-as-strided)
`np.lib.stride_tricks.as_strided`
now has a `writeable`
keyword argument. It can be set to False when no write operation
to the returned array is expected to avoid accidental
unpredictable writes.
`axes`
keyword argument for `rot90`
[#](#axes-keyword-argument-for-rot90)
The `axes`
keyword argument in `rot90`
determines the plane in which the
array is rotated. It defaults to `axes=(0,1)`
as in the original function.

### Generalized `flip`
[#](#generalized-flip)
`flipud`
and `fliplr`
reverse the elements of an array along axis=0 and
axis=1 respectively. The newly added `flip`
function reverses the elements of
an array along any given axis.
`np.count_nonzero`
now has an`axis`
parameter, allowing non-zero counts to be generated on more than just a flattened array object.
### BLIS support in `numpy.distutils`
[#](#blis-support-in-numpy-distutils)
Building against the BLAS implementation provided by the BLIS library is now
supported. See the `[blis]`
section in `site.cfg.example`
(in the root of
the numpy repo or source distribution).

### Hook in `numpy/__init__.py`
to run distribution-specific checks[#](#hook-in-numpy-init-py-to-run-distribution-specific-checks)
Binary distributions of numpy may need to run specific hardware checks or load specific libraries during numpy initialization. For example, if we are distributing numpy with a BLAS library that requires SSE2 instructions, we would like to check the machine on which numpy is running does have SSE2 in order to give an informative error.

Add a hook in `numpy/__init__.py`
to import a `numpy/_distributor_init.py`
file that will remain empty (bar a docstring) in the standard numpy source,
but that can be overwritten by people making binary distributions of numpy.

### New nanfunctions `nancumsum`
and `nancumprod`
added[#](#new-nanfunctions-nancumsum-and-nancumprod-added)
Nan-functions `nancumsum`
and `nancumprod`
have been added to
compute `cumsum`
and `cumprod`
by ignoring nans.

`np.interp`
can now interpolate complex values[#](#np-interp-can-now-interpolate-complex-values)
`np.lib.interp(x, xp, fp)`
now allows the interpolated array `fp`
to be complex and will interpolate at `complex128`
precision.
### New polynomial evaluation function `polyvalfromroots`
added[#](#new-polynomial-evaluation-function-polyvalfromroots-added)
The new function `polyvalfromroots`
evaluates a polynomial at given points
from the roots of the polynomial. This is useful for higher order polynomials,
where expansion into polynomial coefficients is inaccurate at machine
precision.

### New array creation function `geomspace`
added[#](#new-array-creation-function-geomspace-added)
The new function `geomspace`
generates a geometric sequence. It is similar
to `logspace`
, but with start and stop specified directly:
`geomspace(start, stop)`
behaves the same as
`logspace(log10(start), log10(stop))`
.

### New context manager for testing warnings[#](#new-context-manager-for-testing-warnings)
A new context manager `suppress_warnings`
has been added to the testing
utils. This context manager is designed to help reliably test warnings.
Specifically to reliably filter/ignore warnings. Ignoring warnings
by using an “ignore” filter in Python versions before 3.4.x can quickly
result in these (or similar) warnings not being tested reliably.

The context manager allows to filter (as well as record) warnings similar
to the `catch_warnings`
context, but allows for easier specificity.
Also printing warnings that have not been filtered or nesting the
context manager will work as expected. Additionally, it is possible
to use the context manager as a decorator which can be useful when
multiple tests give need to hide the same warning.

### New masked array functions `ma.convolve`
and `ma.correlate`
added[#](#new-masked-array-functions-ma-convolve-and-ma-correlate-added)
These functions wrapped the non-masked versions, but propagate through masked values. There are two different propagation modes. The default causes masked values to contaminate the result with masks, but the other mode only outputs masks if there is no alternative.

### New `float_power`
ufunc[#](#new-float-power-ufunc)
The new `float_power`
ufunc is like the `power`
function except all
computation is done in a minimum precision of float64. There was a long
discussion on the numpy mailing list of how to treat integers to negative
integer powers and a popular proposal was that the `__pow__`
operator should
always return results of at least float64 precision. The `float_power`
function implements that option. Note that it does not support object arrays.

`np.loadtxt`
now supports a single integer as `usecol`
argument[#](#np-loadtxt-now-supports-a-single-integer-as-usecol-argument)
Instead of using `usecol=(n,)`
to read the nth column of a file
it is now allowed to use `usecol=n`
. Also the error message is
more user friendly when a non-integer is passed as a column index.

### Improved automated bin estimators for `histogram`
[#](#improved-automated-bin-estimators-for-histogram)
Added ‘doane’ and ‘sqrt’ estimators to `histogram`
via the `bins`
argument. Added support for range-restricted histograms with automated
bin estimation.

`np.roll`
can now roll multiple axes at the same time[#](#np-roll-can-now-roll-multiple-axes-at-the-same-time)
The `shift`
and `axis`
arguments to `roll`
are now broadcast against each
other, and each specified axis is shifted accordingly.

### The `__complex__`
method has been implemented for the ndarrays[#](#the-complex-method-has-been-implemented-for-the-ndarrays)
Calling `complex()`
on a size 1 array will now cast to a python
complex.

`pathlib.Path`
objects now supported[#](#pathlib-path-objects-now-supported)
The standard `np.load`
, `np.save`
, `np.loadtxt`
, `np.savez`
, and similar
functions can now take `pathlib.Path`
objects as an argument instead of a
filename or open file object.

### New `bits`
attribute for `np.finfo`
[#](#new-bits-attribute-for-np-finfo)
This makes `np.finfo`
consistent with `np.iinfo`
which already has that
attribute.

### New `signature`
argument to `np.vectorize`
[#](#new-signature-argument-to-np-vectorize)
This argument allows for vectorizing user defined functions with core
dimensions, in the style of NumPy’s
[generalized universal functions](../reference/c-api/generalized-ufuncs.html#c-api-generalized-ufuncs). This allows
for vectorizing a much broader class of functions. For example, an arbitrary
distance metric that combines two vectors to produce a scalar could be
vectorized with `signature='(n),(n)->()'`
. See `np.vectorize`
for full
details.

### Emit py3kwarnings for division of integer arrays[#](#emit-py3kwarnings-for-division-of-integer-arrays)
To help people migrate their code bases from Python 2 to Python 3, the python interpreter has a handy option -3, which issues warnings at runtime. One of its warnings is for integer division:

```
$ python -3 -c "2/3"
-c:1: DeprecationWarning: classic int division
```
In Python 3, the new integer division semantics also apply to numpy arrays. With this version, numpy will emit a similar warning:

```
$ python -3 -c "import numpy as np; np.array(2)/np.array(3)"
-c:1: DeprecationWarning: numpy: classic int division
```
### numpy.sctypes now includes bytes on Python3 too[#](#numpy-sctypes-now-includes-bytes-on-python3-too)
Previously, it included str (bytes) and unicode on Python2, but only str (unicode) on Python3.

## Improvements[#](#improvements)
`bitwise_and`
identity changed[#](#id1)
The previous identity was 1 with the result that all bits except the LSB were masked out when the reduce method was used. The new identity is -1, which should work properly on twos complement machines as all bits will be set to one.

### Generalized Ufuncs will now unlock the GIL[#](#generalized-ufuncs-will-now-unlock-the-gil)
Generalized Ufuncs, including most of the linalg module, will now unlock the Python global interpreter lock.

### Caches in *np.fft* are now bounded in total size and item count[#](#caches-in-np-fft-are-now-bounded-in-total-size-and-item-count)
The caches in *np.fft* that speed up successive FFTs of the same length can no
longer grow without bounds. They have been replaced with LRU (least recently
used) caches that automatically evict no longer needed items if either the
memory size or item count limit has been reached.

### Improved handling of zero-width string/unicode dtypes[#](#improved-handling-of-zero-width-string-unicode-dtypes)
Fixed several interfaces that explicitly disallowed arrays with zero-width
string dtypes (i.e. `dtype('S0')`
or `dtype('U0')`
, and fixed several
bugs where such dtypes were not handled properly. In particular, changed
`ndarray.__new__`
to not implicitly convert `dtype('S0')`
to
`dtype('S1')`
(and likewise for unicode) when creating new arrays.

### Integer ufuncs vectorized with AVX2[#](#integer-ufuncs-vectorized-with-avx2)
If the cpu supports it at runtime the basic integer ufuncs now use AVX2 instructions. This feature is currently only available when compiled with GCC.

### Order of operations optimization in `np.einsum`
[#](#order-of-operations-optimization-in-np-einsum)
`np.einsum`
now supports the `optimize`
argument which will optimize the
order of contraction. For example, `np.einsum`
would complete the chain dot
example `np.einsum(‘ij,jk,kl->il’, a, b, c)`
in a single pass which would
scale like `N^4`
; however, when `optimize=True`
`np.einsum`
will create
an intermediate array to reduce this scaling to `N^3`
or effectively
`np.dot(a, b).dot(c)`
. Usage of intermediate tensors to reduce scaling has
been applied to the general einsum summation notation. See `np.einsum_path`
for more details.
### quicksort has been changed to an introsort[#](#quicksort-has-been-changed-to-an-introsort)
The quicksort kind of `np.sort`
and `np.argsort`
is now an introsort which
is regular quicksort but changing to a heapsort when not enough progress is
made. This retains the good quicksort performance while changing the worst case
runtime from `O(N^2)`
to `O(N*log(N))`
.

`ediff1d`
improved performance and subclass handling[#](#ediff1d-improved-performance-and-subclass-handling)
The ediff1d function uses an array instead on a flat iterator for the subtraction. When to_begin or to_end is not None, the subtraction is performed in place to eliminate a copy operation. A side effect is that certain subclasses are handled better, namely astropy.Quantity, since the complete array is created, wrapped, and then begin and end values are set, instead of using concatenate.

### Improved precision of `ndarray.mean`
for float16 arrays[#](#improved-precision-of-ndarray-mean-for-float16-arrays)
The computation of the mean of float16 arrays is now carried out in float32 for improved precision. This should be useful in packages such as Theano where the precision of float16 is adequate and its smaller footprint is desirable.

## Changes[#](#changes)
### All array-like methods are now called with keyword arguments in fromnumeric.py[#](#all-array-like-methods-are-now-called-with-keyword-arguments-in-fromnumeric-py)
Internally, many array-like methods in fromnumeric.py were being called with positional arguments instead of keyword arguments as their external signatures were doing. This caused a complication in the downstream ‘pandas’ library that encountered an issue with ‘numpy’ compatibility. Now, all array-like methods in this module are called with keyword arguments instead.

### Operations on np.memmap objects return numpy arrays in most cases[#](#operations-on-np-memmap-objects-return-numpy-arrays-in-most-cases)
Previously operations on a memmap object would misleadingly return a memmap
instance even if the result was actually not memmapped. For example,
`arr + 1`
or `arr + arr`
would return memmap instances, although no memory
from the output array is memmapped. Version 1.12 returns ordinary numpy arrays
from these operations.

Also, reduction of a memmap (e.g. `.sum(axis=None`
) now returns a numpy
scalar instead of a 0d memmap.

### stacklevel of warnings increased[#](#stacklevel-of-warnings-increased)
The stacklevel for python based warnings was increased so that most warnings
will report the offending line of the user code instead of the line the
warning itself is given. Passing of stacklevel is now tested to ensure that
new warnings will receive the `stacklevel`
argument.

This causes warnings with the “default” or “module” filter to be shown once for every offending user code line or user module instead of only once. On python versions before 3.4, this can cause warnings to appear that were falsely ignored before, which may be surprising especially in test suits.# NumPy 1.11.0 Release Notes[#](#numpy-1-11-0-release-notes)
This release supports Python 2.6 - 2.7 and 3.2 - 3.5 and contains a number of enhancements and improvements. Note also the build system changes listed below as they may have subtle effects.

No Windows (TM) binaries are provided for this release due to a broken toolchain. One of the providers of Python packages for Windows (TM) is your best bet.

## Highlights[#](#highlights)
Details of these improvements can be found below.

The datetime64 type is now timezone naive.

A dtype parameter has been added to

`randint`
.
Improved detection of two arrays possibly sharing memory.

Automatic bin size estimation for

`np.histogram`
.
Speed optimization of A @ A.T and dot(A, A.T).

New function

`np.moveaxis`
for reordering array axes.
## Build System Changes[#](#build-system-changes)
Numpy now uses

`setuptools`
for its builds instead of plain distutils. This fixes usage of`install_requires='numpy'`
in the`setup.py`
files of projects that depend on Numpy (see gh-6551). It potentially affects the way that build/install methods for Numpy itself behave though. Please report any unexpected behavior on the Numpy issue tracker.
Bento build support and related files have been removed.

Single file build support and related files have been removed.

## Future Changes[#](#future-changes)
The following changes are scheduled for Numpy 1.12.0.

Support for Python 2.6, 3.2, and 3.3 will be dropped.

Relaxed stride checking will become the default. See the 1.8.0 release notes for a more extended discussion of what this change implies.

The behavior of the datetime64 “not a time” (NaT) value will be changed to match that of floating point “not a number” (NaN) values: all comparisons involving NaT will return False, except for NaT != NaT which will return True.

Indexing with floats will raise IndexError, e.g., a[0, 0.0].

Indexing with non-integer array_like will raise

`IndexError`
, e.g.,`a['1', '2']`
Indexing with multiple ellipsis will raise

`IndexError`
, e.g.,`a[..., ...]`
.
Non-integers used as index values will raise

`TypeError`
, e.g., in`reshape`
,`take`
, and specifying reduce axis.
In a future release the following changes will be made.

The

`rand`
function exposed in`numpy.testing`
will be removed. That function is left over from early Numpy and was implemented using the Python random module. The random number generators from`numpy.random`
should be used instead.
The

`ndarray.view`
method will only allow c_contiguous arrays to be viewed using a dtype of different size causing the last dimension to change. That differs from the current behavior where arrays that are f_contiguous but not c_contiguous can be viewed as a dtype type of different size causing the first dimension to change.
Slicing a

`MaskedArray`
will return views of both data**and**mask. Currently the mask is copy-on-write and changes to the mask in the slice do not propagate to the original mask. See the FutureWarnings section below for details.
## Compatibility notes[#](#compatibility-notes)
### datetime64 changes[#](#datetime64-changes)
In prior versions of NumPy the experimental datetime64 type always stored times in UTC. By default, creating a datetime64 object from a string or printing it would convert from or to local time:

```
# old behavior
>>> np.datetime64('2000-01-01T00:00:00')
numpy.datetime64('2000-01-01T00:00:00-0800') # note the timezone offset -08:00
```
A consensus of datetime64 users agreed that this behavior is undesirable
and at odds with how datetime64 is usually used (e.g., by [pandas](http://pandas.pydata.org)). For most use cases, a timezone naive datetime
type is preferred, similar to the `datetime.datetime`
type in the Python
standard library. Accordingly, datetime64 no longer assumes that input is in
local time, nor does it print local times:

```
>>> np.datetime64('2000-01-01T00:00:00')
numpy.datetime64('2000-01-01T00:00:00')
```
For backwards compatibility, datetime64 still parses timezone offsets, which it handles by converting to UTC. However, the resulting datetime is timezone naive:

```
>>> np.datetime64('2000-01-01T00:00:00-08')
DeprecationWarning: parsing timezone aware datetimes is deprecated;
this will raise an error in the future
numpy.datetime64('2000-01-01T08:00:00')
```
As a corollary to this change, we no longer prohibit casting between datetimes with date units and datetimes with time units. With timezone naive datetimes, the rule for casting from dates to times is no longer ambiguous.

`linalg.norm`
return type changes[#](#linalg-norm-return-type-changes)
The return type of the `linalg.norm`
function is now floating point without
exception. Some of the norm types previously returned integers.

### polynomial fit changes[#](#polynomial-fit-changes)
The various fit functions in the numpy polynomial package no longer accept non-integers for degree specification.

*np.dot* now raises `TypeError`
instead of `ValueError`
[#](#np-dot-now-raises-typeerror-instead-of-valueerror)
This behaviour mimics that of other functions such as `np.inner`
. If the two
arguments cannot be cast to a common type, it could have raised a `TypeError`
or `ValueError`
depending on their order. Now, `np.dot`
will now always
raise a `TypeError`
.

### FutureWarning to changed behavior[#](#futurewarning-to-changed-behavior)
In

`np.lib.split`
an empty array in the result always had dimension`(0,)`
no matter the dimensions of the array being split. This has been changed so that the dimensions will be preserved. A`FutureWarning`
for this change has been in place since Numpy 1.9 but, due to a bug, sometimes no warning was raised and the dimensions were already preserved.
`%`
and `//`
operators[#](#and-operators)
These operators are implemented with the `remainder`
and `floor_divide`
functions respectively. Those functions are now based around `fmod`
and are
computed together so as to be compatible with each other and with the Python
versions for float types. The results should be marginally more accurate or
outright bug fixes compared to the previous results, but they may
differ significantly in cases where roundoff makes a difference in the integer
returned by `floor_divide`
. Some corner cases also change, for instance, NaN
is always returned for both functions when the divisor is zero,
`divmod(1.0, inf)`
returns `(0.0, 1.0)`
except on MSVC 2008, and
`divmod(-1.0, inf)`
returns `(-1.0, inf)`
.

### C API[#](#c-api)
Removed the `check_return`
and `inner_loop_selector`
members of
the `PyUFuncObject`
struct (replacing them with `reserved`
slots
to preserve struct layout). These were never used for anything, so
it’s unlikely that any third-party code is using them either, but we
mention it here for completeness.

### object dtype detection for old-style classes[#](#object-dtype-detection-for-old-style-classes)
In python 2, objects which are instances of old-style user-defined classes no
longer automatically count as ‘object’ type in the dtype-detection handler.
Instead, as in python 3, they may potentially count as sequences, but only if
they define both a *__len__* and a *__getitem__* method. This fixes a segfault
and inconsistency between python 2 and 3.

## New Features[#](#new-features)
`np.histogram`
now provides plugin estimators for automatically estimating the optimal number of bins. Passing one of [‘auto’, ‘fd’, ‘scott’, ‘rice’, ‘sturges’] as the argument to ‘bins’ results in the corresponding estimator being used.
A benchmark suite using

[Airspeed Velocity](https://asv.readthedocs.io/)has been added, converting the previous vbench-based one. You can run the suite locally via`python runtests.py --bench`
. For more details, see`benchmarks/README.rst`
.
A new function

`np.shares_memory`
that can check exactly whether two arrays have memory overlap is added.`np.may_share_memory`
also now has an option to spend more effort to reduce false positives.
`SkipTest`
and`KnownFailureException`
exception classes are exposed in the`numpy.testing`
namespace. Raise them in a test function to mark the test to be skipped or mark it as a known failure, respectively.
`f2py.compile`
has a new`extension`
keyword parameter that allows the fortran extension to be specified for generated temp files. For instance, the files can be specifies to be`*.f90`
. The`verbose`
argument is also activated, it was previously ignored.
A

`dtype`
parameter has been added to`np.random.randint`
Random ndarrays of the following types can now be generated:`np.bool_`
,
`np.int8`
,`np.uint8`
,
`np.int16`
,`np.uint16`
,
`np.int32`
,`np.uint32`
,
`np.int64`
,`np.uint64`
,
`np.int_ ``, ``np.intp`
The specification is by precision rather than by C type. Hence, on some platforms

`np.int64`
may be a`long`
instead of`long long`
even if the specified dtype is`long long`
because the two may have the same precision. The resulting type depends on which C type numpy uses for the given precision. The byteorder specification is also ignored, the generated arrays are always in native byte order.
A new

`np.moveaxis`
function allows for moving one or more array axes to a new position by explicitly providing source and destination axes. This function should be easier to use than the current`rollaxis`
function as well as providing more functionality.
The

`deg`
parameter of the various`numpy.polynomial`
fits has been extended to accept a list of the degrees of the terms to be included in the fit, the coefficients of all other terms being constrained to zero. The change is backward compatible, passing a scalar`deg`
will behave as before.
A divmod function for float types modeled after the Python version has been added to the npy_math library.

## Improvements[#](#improvements)
`np.gradient`
now supports an `axis`
argument[#](#np-gradient-now-supports-an-axis-argument)
The `axis`
parameter was added to `np.gradient`
for consistency. It
allows to specify over which axes the gradient is calculated.

`np.lexsort`
now supports arrays with object data-type[#](#np-lexsort-now-supports-arrays-with-object-data-type)
The function now internally calls the generic `npy_amergesort`
when the
type does not implement a merge-sort kind of `argsort`
method.

`np.ma.core.MaskedArray`
now supports an `order`
argument[#](#np-ma-core-maskedarray-now-supports-an-order-argument)
When constructing a new `MaskedArray`
instance, it can be configured with
an `order`
argument analogous to the one when calling `np.ndarray`
. The
addition of this argument allows for the proper processing of an `order`
argument in several MaskedArray-related utility functions such as
`np.ma.core.array`
and `np.ma.core.asarray`
.

### Memory and speed improvements for masked arrays[#](#memory-and-speed-improvements-for-masked-arrays)
Creating a masked array with `mask=True`
(resp. `mask=False`
) now uses
`np.ones`
(resp. `np.zeros`
) to create the mask, which is faster and
avoid a big memory peak. Another optimization was done to avoid a memory
peak and useless computations when printing a masked array.

`ndarray.tofile`
now uses fallocate on linux[#](#ndarray-tofile-now-uses-fallocate-on-linux)
The function now uses the fallocate system call to reserve sufficient disk space on file systems that support it.

### Optimizations for operations of the form `A.T @ A`
and `A @ A.T`
[#](#optimizations-for-operations-of-the-form-a-t-a-and-a-a-t)
Previously, `gemm`
BLAS operations were used for all matrix products. Now,
if the matrix product is between a matrix and its transpose, it will use
`syrk`
BLAS operations for a performance boost. This optimization has been
extended to `@`
, `numpy.dot`
, `numpy.inner`
, and `numpy.matmul`
.

**Note:** Requires the transposed and non-transposed matrices to share data.
`np.testing.assert_warns`
can now be used as a context manager[#](#np-testing-assert-warns-can-now-be-used-as-a-context-manager)
This matches the behavior of `assert_raises`
.

### Speed improvement for np.random.shuffle[#](#speed-improvement-for-np-random-shuffle)
`np.random.shuffle`
is now much faster for 1d ndarrays.
## Changes[#](#changes)
### Pyrex support was removed from `numpy.distutils`
[#](#pyrex-support-was-removed-from-numpy-distutils)
The method `build_src.generate_a_pyrex_source`
will remain available; it
has been monkeypatched by users to support Cython instead of Pyrex. It’s
recommended to switch to a better supported method of build Cython
extensions though.

`np.broadcast`
can now be called with a single argument[#](#np-broadcast-can-now-be-called-with-a-single-argument)
The resulting object in that case will simply mimic iteration over a single array. This change obsoletes distinctions like

if len(x) == 1:
-
-
shape = x[0].shape

else:
-
-
shape = np.broadcast(*x).shape

Instead, `np.broadcast`
can be used in all cases.

`np.trace`
now respects array subclasses[#](#np-trace-now-respects-array-subclasses)
This behaviour mimics that of other functions such as `np.diagonal`
and
ensures, e.g., that for masked arrays `np.trace(ma)`
and `ma.trace()`
give
the same result.

`np.dot`
now raises `TypeError`
instead of `ValueError`
[#](#id1)
This behaviour mimics that of other functions such as `np.inner`
. If the two
arguments cannot be cast to a common type, it could have raised a `TypeError`
or `ValueError`
depending on their order. Now, `np.dot`
will now always
raise a `TypeError`
.

`linalg.norm`
return type changes[#](#id2)
The `linalg.norm`
function now does all its computations in floating point
and returns floating results. This change fixes bugs due to integer overflow
and the failure of abs with signed integers of minimum value, e.g., int8(-128).
For consistency, floats are used even where an integer might work.

## Deprecations[#](#deprecations)
### Views of arrays in Fortran order[#](#views-of-arrays-in-fortran-order)
The F_CONTIGUOUS flag was used to signal that views using a dtype that
changed the element size would change the first index. This was always
problematical for arrays that were both F_CONTIGUOUS and C_CONTIGUOUS
because C_CONTIGUOUS took precedence. Relaxed stride checking results in
more such dual contiguous arrays and breaks some existing code as a result.
Note that this also affects changing the dtype by assigning to the dtype
attribute of an array. The aim of this deprecation is to restrict views to
C_CONTIGUOUS arrays at some future time. A work around that is backward
compatible is to use `a.T.view(...).T`
instead. A parameter may also be
added to the view method to explicitly ask for Fortran order views, but
that will not be backward compatible.

### Invalid arguments for array ordering[#](#invalid-arguments-for-array-ordering)
It is currently possible to pass in arguments for the `order`
parameter in methods like `array.flatten`
or `array.ravel`
that were not one of the following: ‘C’, ‘F’, ‘A’, ‘K’ (note that
all of these possible values are both unicode and case insensitive).
Such behavior will not be allowed in future releases.

### Random number generator in the `testing`
namespace[#](#random-number-generator-in-the-testing-namespace)
The Python standard library random number generator was previously exposed
in the `testing`
namespace as `testing.rand`
. Using this generator is
not recommended and it will be removed in a future release. Use generators
from `numpy.random`
namespace instead.

### Random integer generation on a closed interval[#](#random-integer-generation-on-a-closed-interval)
In accordance with the Python C API, which gives preference to the half-open
interval over the closed one, `np.random.random_integers`
is being
deprecated in favor of calling `np.random.randint`
, which has been
enhanced with the `dtype`
parameter as described under “New Features”.
However, `np.random.random_integers`
will not be removed anytime soon.

## FutureWarnings[#](#futurewarnings)
### Assigning to slices/views of `MaskedArray`
[#](#assigning-to-slices-views-of-maskedarray)
Currently a slice of a masked array contains a view of the original data and a
copy-on-write view of the mask. Consequently, any changes to the slice’s mask
will result in a copy of the original mask being made and that new mask being
changed rather than the original. For example, if we make a slice of the
original like so, `view = original[:]`
, then modifications to the data in one
array will affect the data of the other but, because the mask will be copied
during assignment operations, changes to the mask will remain local. A similar
situation occurs when explicitly constructing a masked array using
`MaskedArray(data, mask)`
, the returned array will contain a view of `data`
but the mask will be a copy-on-write view of `mask`
.

In the future, these cases will be normalized so that the data and mask arrays
are treated the same way and modifications to either will propagate between
views. In 1.11, numpy will issue a `MaskedArrayFutureWarning`
warning
whenever user code modifies the mask of a view that in the future may cause
values to propagate back to the original. To silence these warnings and make
your code robust against the upcoming changes, you have two options: if you
want to keep the current behavior, call `masked_view.unshare_mask()`
before
modifying the mask. If you want to get the future behavior early, use
`masked_view._sharedmask = False`
. However, note that setting the
`_sharedmask`
attribute will break following explicit calls to
`masked_view.unshare_mask()`
.# CPU build options[#](#cpu-build-options)
## Description[#](#description)
The following options are mainly used to change the default behavior of optimizations that target certain CPU features:

`--cpu-baseline`
: minimal set of required CPU features.
Default value is

`min`
which provides the minimum CPU features that can safely run on a wide range of platforms within the processor family.Note

During the runtime, NumPy modules will fail to load if any of specified features are not supported by the target CPU (raises Python runtime error).

`--cpu-dispatch`
: dispatched set of additional CPU features.
Default value is

`max -xop -fma4`
which enables all CPU features, except for AMD legacy features (in case of X86).Note

During the runtime, NumPy modules will skip any specified features that are not available in the target CPU.

These options are accessible through [ distutils](https://docs.python.org/3/library/distutils.html#module-distutils) commands

[,](https://docs.python.org/3/distutils/apiref.html#module-distutils.command.build)
`distutils.command.build`
[and](https://docs.python.org/3/distutils/apiref.html#module-distutils.command.build_clib)
`distutils.command.build_clib`
[. They accept a set of](https://docs.python.org/3/distutils/apiref.html#module-distutils.command.build_ext)
`distutils.command.build_ext`
[CPU features](#opt-supported-features)or groups of features that gather several features or
[special options](#opt-special-options)that perform a series of procedures.
Note

If `build_clib`
or `build_ext`
are not specified by the user,
the arguments of `build`
will be used instead, which also holds the default values.

To customize both `build_ext`
and `build_clib`
:

```
cd /path/to/numpy
python setup.py build --cpu-baseline="avx2 fma3" install --user
```
To customize only `build_ext`
:

```
cd /path/to/numpy
python setup.py build_ext --cpu-baseline="avx2 fma3" install --user
```
To customize only `build_clib`
:

```
cd /path/to/numpy
python setup.py build_clib --cpu-baseline="avx2 fma3" install --user
```
You can also customize CPU/build options through PIP command:

```
pip install --no-use-pep517 --global-option=build \
--global-option="--cpu-baseline=avx2 fma3" \
--global-option="--cpu-dispatch=max" ./
```
## Quick Start[#](#quick-start)
In general, the default settings tend to not impose certain CPU features that may not be available on some older processors. Raising the ceiling of the baseline features will often improve performance and may also reduce binary size.

The following are the most common scenarios that may require changing the default settings:

### I am building NumPy for my local use[#](#i-am-building-numpy-for-my-local-use)
And I do not intend to export the build to other users or target a different CPU than what the host has.

Set *native* for baseline, or manually specify the CPU features in case of option
*native* isn’t supported by your platform:

```
python setup.py build --cpu-baseline="native" bdist
```
Building NumPy with extra CPU features isn’t necessary for this case, since all supported features are already defined within the baseline features:

```
python setup.py build --cpu-baseline=native --cpu-dispatch=none bdist
```
Note

A fatal error will be raised if *native* isn’t supported by the host platform.

### I do not want to support the old processors of the *x86* architecture[#](#i-do-not-want-to-support-the-old-processors-of-the-x86-architecture)
Since most of the CPUs nowadays support at least *AVX*, *F16C* features, you can use:

```
python setup.py build --cpu-baseline="avx f16c" bdist
```
Note

`--cpu-baseline`
force combine all implied features, so there’s no need
to add SSE features.
### I’m facing the same case above but with *ppc64* architecture[#](#i-m-facing-the-same-case-above-but-with-ppc64-architecture)
Then raise the ceiling of the baseline features to Power8:

```
python setup.py build --cpu-baseline="vsx2" bdist
```
### Having issues with *AVX512* features?[#](#having-issues-with-avx512-features)
You may have some reservations about including of *AVX512* or
any other CPU feature and you want to exclude from the dispatched features:

```
python setup.py build --cpu-dispatch="max -avx512f -avx512cd \
-avx512_knl -avx512_knm -avx512_skx -avx512_clx -avx512_cnl -avx512_icl" \
bdist
```
## Supported Features[#](#supported-features)
The names of the features can express one feature or a group of features, as shown in the following tables supported depend on the lowest interest:

Note

The following features may not be supported by all compilers,
also some compilers may produce different set of implied features
when it comes to features like `AVX512`
, `AVX2`
, and `FMA3`
.
See [Platform differences](#opt-platform-differences) for more details.

### On x86[#](#on-x86)
Name

|
Implies

|
Gathers

|
---|---|---|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
### On IBM/POWER big-endian[#](#on-ibm-power-big-endian)
Name

|
Implies

|
---|---|
|
|
|
|
|
|
|
### On IBM/POWER little-endian[#](#on-ibm-power-little-endian)
Name

|
Implies

|
---|---|
|
|
|
|
|
|
|
|
### On ARMv7/A32[#](#on-armv7-a32)
Name

|
Implies

|
---|---|
|
|
|
|
|
|
|
|
|
|
|
|
|
### On ARMv8/A64[#](#on-armv8-a64)
Name

|
Implies

|
---|---|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
### On IBM/ZSYSTEM(S390X)[#](#on-ibm-zsystem-s390x)
Name

|
Implies

|
---|---|
|
|
|
|
|
## Special Options[#](#special-options)
`NONE`
: enable no features.
`NATIVE`
: Enables all CPU features that supported by the host CPU, this operation is based on the compiler flags (`-march=native`
,`-xHost`
,`/QxHost`
)
`MIN`
: Enables the minimum CPU features that can safely run on a wide range of platforms:For Arch

Implies

x86 (32-bit mode)

`SSE`
`SSE2`
x86_64

`SSE`
`SSE2`
`SSE3`
IBM/POWER (big-endian mode)

`NONE`
IBM/POWER (little-endian mode)

`VSX`
`VSX2`
ARMHF

`NONE`
ARM64 A.K. AARCH64

`NEON`
`NEON_FP16`
`NEON_VFPV4`
`ASIMD`
IBM/ZSYSTEM(S390X)

`NONE`
`MAX`
: Enables all supported CPU features by the compiler and platform.
`Operators-/+`
: remove or add features, useful with options`MAX`
,`MIN`
and`NATIVE`
.
## Behaviors[#](#behaviors)
CPU features and other options are case-insensitive, for example:

python setup.py build --cpu-dispatch="SSE41 avx2 FMA3"
The order of the requested optimizations doesn’t matter:

python setup.py build --cpu-dispatch="SSE41 AVX2 FMA3" # equivalent to python setup.py build --cpu-dispatch="FMA3 AVX2 SSE41"
Either commas or spaces or ‘+’ can be used as a separator, for example:

python setup.py build --cpu-dispatch="avx2 avx512f" # or python setup.py build --cpu-dispatch=avx2,avx512f # or python setup.py build --cpu-dispatch="avx2+avx512f"
all works but arguments should be enclosed in quotes or escaped by backslash if any spaces are used.

`--cpu-baseline`
combines all implied CPU features, for example:python setup.py build --cpu-baseline=sse42 # equivalent to python setup.py build --cpu-baseline="sse sse2 sse3 ssse3 sse41 popcnt sse42"
`--cpu-baseline`
will be treated as “native” if compiler native flag`-march=native`
or`-xHost`
or`/QxHost`
is enabled through environment variable*CFLAGS*:export CFLAGS="-march=native" python setup.py install --user # is equivalent to python setup.py build --cpu-baseline=native install --user
`--cpu-baseline`
escapes any specified features that aren’t supported by the target platform or compiler rather than raising fatal errors.Note

Since

`--cpu-baseline`
combines all implied features, the maximum supported of implied features will be enabled rather than escape all of them. For example:# Requesting `AVX2,FMA3` but the compiler only support **SSE** features python setup.py build --cpu-baseline="avx2 fma3" # is equivalent to python setup.py build --cpu-baseline="sse sse2 sse3 ssse3 sse41 popcnt sse42"
`--cpu-dispatch`
does not combain any of implied CPU features, so you must add them unless you want to disable one or all of them:# Only dispatches AVX2 and FMA3 python setup.py build --cpu-dispatch=avx2,fma3 # Dispatches AVX and SSE features python setup.py build --cpu-baseline=ssse3,sse41,sse42,avx,avx2,fma3
`--cpu-dispatch`
escapes any specified baseline features and also escapes any features not supported by the target platform or compiler without raising fatal errors.
Eventually, you should always check the final report through the build log
to verify the enabled features. See [Build report](#opt-build-report) for more details.

## Platform differences[#](#platform-differences)
Some exceptional conditions force us to link some features together when it come to certain compilers or architectures, resulting in the impossibility of building them separately.

These conditions can be divided into two parts, as follows:

**Architectural compatibility**
The need to align certain CPU features that are assured to be supported by successive generations of the same architecture, some cases:

On ppc64le

`VSX(ISA 2.06)`
and`VSX2(ISA 2.07)`
both imply one another since the first generation that supports little-endian mode is Power-8`(ISA 2.07)`
On AArch64

`NEON NEON_FP16 NEON_VFPV4 ASIMD`
implies each other since they are part of the hardware baseline.
For example:

```
# On ARMv8/A64, specify NEON is going to enable Advanced SIMD
# and all predecessor extensions
python setup.py build --cpu-baseline=neon
# which equivalent to
python setup.py build --cpu-baseline="neon neon_fp16 neon_vfpv4 asimd"
```
Note

Please take a deep look at [Supported Features](#opt-supported-features),
in order to determine the features that imply one another.

**Compilation compatibility**
Some compilers don’t provide independent support for all CPU features. For instance
**Intel**’s compiler doesn’t provide separated flags for `AVX2`
and `FMA3`
,
it makes sense since all Intel CPUs that comes with `AVX2`
also support `FMA3`
,
but this approach is incompatible with other **x86** CPUs from **AMD** or **VIA**.

For example:

```
# Specify AVX2 will force enables FMA3 on Intel compilers
python setup.py build --cpu-baseline=avx2
# which equivalent to
python setup.py build --cpu-baseline="avx2 fma3"
```
The following tables only show the differences imposed by some compilers from the
general context that been shown in the [Supported Features](#opt-supported-features) tables:

Note

Features names with strikeout represent the unsupported CPU features.

### On x86::Intel Compiler[#](#on-x86-intel-compiler)
Name

|
Implies

|
Gathers

|
---|---|---|
FMA3

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C AVX2

|
AVX2

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3

|
AVX512F

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512CD

|
XOP

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX

|
FMA4

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX

|
AVX512_SPR

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL

|
AVX512FP16

|
### On x86::Microsoft Visual C/C++[#](#on-x86-microsoft-visual-c-c)
Name

|
Implies

|
Gathers

|
---|---|---|
FMA3

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C AVX2

|
AVX2

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3

|
AVX512F

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512CD AVX512_SKX

|
AVX512CD

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512_SKX

|
AVX512_KNL

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD

|
AVX512ER AVX512PF

|
AVX512_KNM

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL

|
AVX5124FMAPS AVX5124VNNIW AVX512VPOPCNTDQ

|
AVX512_SPR

|
SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL

|
AVX512FP16

|
## Build report[#](#build-report)
In most cases, the CPU build options do not produce any fatal errors that lead to hanging the build. Most of the errors that may appear in the build log serve as heavy warnings due to the lack of some expected CPU features by the compiler.

So we strongly recommend checking the final report log, to be aware of what kind of CPU features are enabled and what are not.

You can find the final report of CPU optimizations at the end of the build log, and here is how it looks on x86_64/gcc:

```
########### EXT COMPILER OPTIMIZATION ###########
Platform :
Architecture: x64
Compiler : gcc
CPU baseline :
Requested : 'min'
Enabled : SSE SSE2 SSE3
Flags : -msse -msse2 -msse3
Extra checks: none
CPU dispatch :
Requested : 'max -xop -fma4'
Enabled : SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL AVX512_KNM AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL
Generated :
:
SSE41 : SSE SSE2 SSE3 SSSE3
Flags : -msse -msse2 -msse3 -mssse3 -msse4.1
Extra checks: none
Detect : SSE SSE2 SSE3 SSSE3 SSE41
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_arithmetic.dispatch.c
: numpy/core/src/umath/_umath_tests.dispatch.c
:
SSE42 : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT
Flags : -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2
Extra checks: none
Detect : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42
: build/src.linux-x86_64-3.9/numpy/core/src/_simd/_simd.dispatch.c
:
AVX2 : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C
Flags : -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mavx2
Extra checks: none
Detect : AVX F16C AVX2
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_arithm_fp.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_arithmetic.dispatch.c
: numpy/core/src/umath/_umath_tests.dispatch.c
:
(FMA3 AVX2) : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C
Flags : -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2
Extra checks: none
Detect : AVX F16C FMA3 AVX2
: build/src.linux-x86_64-3.9/numpy/core/src/_simd/_simd.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_exponent_log.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_trigonometric.dispatch.c
:
AVX512F : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2
Flags : -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2 -mavx512f
Extra checks: AVX512F_REDUCE
Detect : AVX512F
: build/src.linux-x86_64-3.9/numpy/core/src/_simd/_simd.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_arithm_fp.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_arithmetic.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_exponent_log.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_trigonometric.dispatch.c
:
AVX512_SKX : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD
Flags : -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2 -mavx512f -mavx512cd -mavx512vl -mavx512bw -mavx512dq
Extra checks: AVX512BW_MASK AVX512DQ_MASK
Detect : AVX512_SKX
: build/src.linux-x86_64-3.9/numpy/core/src/_simd/_simd.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_arithmetic.dispatch.c
: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops_exponent_log.dispatch.c
CCompilerOpt.cache_flush[804] : write cache to path -> /home/seiko/work/repos/numpy/build/temp.linux-x86_64-3.9/ccompiler_opt_cache_ext.py
########### CLIB COMPILER OPTIMIZATION ###########
Platform :
Architecture: x64
Compiler : gcc
CPU baseline :
Requested : 'min'
Enabled : SSE SSE2 SSE3
Flags : -msse -msse2 -msse3
Extra checks: none
CPU dispatch :
Requested : 'max -xop -fma4'
Enabled : SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL AVX512_KNM AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL
Generated : none
```
There is a separate report for each of `build_ext`
and `build_clib`
that includes several sections, and each section has several values, representing the following:

**Platform**:
Architecture: The architecture name of target CPU. It should be one of

`x86`
,`x64`
,`ppc64`
,`ppc64le`
,`armhf`
,`aarch64`
,`s390x`
or`unknown`
.
Compiler: The compiler name. It should be one of gcc, clang, msvc, icc, iccw or unix-like.

**CPU baseline**:
Requested: The specific features and options to

`--cpu-baseline`
as-is.
Enabled: The final set of enabled CPU features.

Flags: The compiler flags that were used to all NumPy

*C/C++*sources during the compilation except for temporary sources that have been used for generating the binary objects of dispatched features.
Extra checks: list of internal checks that activate certain functionality or intrinsics related to the enabled features, useful for debugging when it comes to developing SIMD kernels.

**CPU dispatch**:
Requested: The specific features and options to

`--cpu-dispatch`
as-is.
Enabled: The final set of enabled CPU features.

Generated: At the beginning of the next row of this property, the features for which optimizations have been generated are shown in the form of several sections with similar properties explained as follows:

One or multiple dispatched feature: The implied CPU features.

Flags: The compiler flags that been used for these features.

Extra checks: Similar to the baseline but for these dispatched features.

Detect: Set of CPU features that need be detected in runtime in order to execute the generated optimizations.

The lines that come after the above property and end with a ‘:’ on a separate line, represent the paths of c/c++ sources that define the generated optimizations.

## Runtime dispatch[#](#runtime-dispatch)
Importing NumPy triggers a scan of the available CPU features from the set
of dispatchable features. This can be further restricted by setting the
environment variable `NPY_DISABLE_CPU_FEATURES`
to a comma-, tab-, or
space-separated list of features to disable. This will raise an error if
parsing fails or if the feature was not enabled. For instance, on `x86_64`
this will disable `AVX2`
and `FMA3`
:

```
NPY_DISABLE_CPU_FEATURES="AVX2,FMA3"
```
If the feature is not available, a warning will be emitted.# NumPy 1.23.3 Release Notes[#](#numpy-1-23-3-release-notes)
NumPy 1.23.3 is a maintenance release that fixes bugs discovered after the 1.23.2 release. There is no major theme for this release, the main improvements are for some downstream builds and some annotation corner cases. The Python versions supported for this release are 3.8-3.11.

Note that we will move to MacOS 11 for the NumPy 1.23.4 release, the 10.15 version currently used will no longer be supported by our build infrastructure at that point.

## Contributors[#](#contributors)
A total of 16 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Aaron Meurer

Bas van Beek

Charles Harris

Ganesh Kathiresan

Gavin Zhang +

Iantra Solari+

Jyn Spring 琴春 +

Matti Picus

Rafael Cardoso Fernandes Sousa

Rafael Sousa +

Ralf Gommers

Rin Cat (鈴猫) +

Saransh Chopra +

Sayed Adel

Sebastian Berg

Serge Guelton

## Pull requests merged[#](#pull-requests-merged)
A total of 14 pull requests were merged for this release.

[#22136](https://github.com/numpy/numpy/pull/22136): BLD: Add Python 3.11 wheels to aarch64 build
[#22148](https://github.com/numpy/numpy/pull/22148): MAINT: Update setup.py for Python 3.11.
[#22155](https://github.com/numpy/numpy/pull/22155): CI: Test NumPy build against old versions of GCC(6, 7, 8)
[#22156](https://github.com/numpy/numpy/pull/22156): MAINT: support IBM i system
[#22195](https://github.com/numpy/numpy/pull/22195): BUG: Fix circleci build
[#22214](https://github.com/numpy/numpy/pull/22214): BUG: Expose heapsort algorithms in a shared header
[#22215](https://github.com/numpy/numpy/pull/22215): BUG: Support using libunwind for backtrack
[#22216](https://github.com/numpy/numpy/pull/22216): MAINT: fix an incorrect pointer type usage in f2py
[#22220](https://github.com/numpy/numpy/pull/22220): BUG: change overloads to play nice with pyright.
[#22221](https://github.com/numpy/numpy/pull/22221): TST,BUG: Use fork context to fix MacOS savez test
[#22222](https://github.com/numpy/numpy/pull/22222): TYP,BUG: Reduce argument validation in C-based`__class_getitem__`
[#22223](https://github.com/numpy/numpy/pull/22223): TST: ensure`np.equal.reduce`
raises a`TypeError`
[#22224](https://github.com/numpy/numpy/pull/22224): BUG: Fix the implementation of numpy.array_api.vecdot
[#22230](https://github.com/numpy/numpy/pull/22230): BUG: Better report integer division overflow (backport)# NumPy 1.19.0 Release Notes[#](#numpy-1-19-0-release-notes)
This NumPy release is marked by the removal of much technical debt: support for Python 2 has been removed, many deprecations have been expired, and documentation has been improved. The polishing of the random module continues apace with bug fixes and better usability from Cython.

The Python versions supported for this release are 3.6-3.8. Downstream developers should use Cython >= 0.29.16 for Python 3.8 support and OpenBLAS >= 3.7 to avoid problems on the Skylake architecture.

## Highlights[#](#highlights)
Code compatibility with Python versions < 3.6 (including Python 2) was dropped from both the python and C code. The shims in

`numpy.compat`
will remain to support third-party packages, but they may be deprecated in a future release. Note that 1.19.x will*not*compile with earlier versions of Python due to the use of f-strings.(

[gh-15233](https://github.com/numpy/numpy/pull/15233))
## Expired deprecations[#](#expired-deprecations)
`numpy.insert`
and `numpy.delete`
can no longer be passed an axis on 0d arrays[#](#numpy-insert-and-numpy-delete-can-no-longer-be-passed-an-axis-on-0d-arrays)
This concludes a deprecation from 1.9, where when an `axis`
argument was
passed to a call to `~numpy.insert`
and `~numpy.delete`
on a 0d array, the
`axis`
and `obj`
argument and indices would be completely ignored.
In these cases, `insert(arr, "nonsense", 42, axis=0)`
would actually overwrite the
entire array, while `delete(arr, "nonsense", axis=0)`
would be `arr.copy()`

Now passing `axis`
on a 0d array raises `~numpy.AxisError`
.

([gh-15802](https://github.com/numpy/numpy/pull/15802))

`numpy.delete`
no longer ignores out-of-bounds indices[#](#numpy-delete-no-longer-ignores-out-of-bounds-indices)
This concludes deprecations from 1.8 and 1.9, where `np.delete`
would ignore
both negative and out-of-bounds items in a sequence of indices. This was at
odds with its behavior when passed a single index.

Now out-of-bounds items throw `IndexError`
, and negative items index from the
end.

([gh-15804](https://github.com/numpy/numpy/pull/15804))

`numpy.insert`
and `numpy.delete`
no longer accept non-integral indices[#](#numpy-insert-and-numpy-delete-no-longer-accept-non-integral-indices)
This concludes a deprecation from 1.9, where sequences of non-integers indices
were allowed and cast to integers. Now passing sequences of non-integral
indices raises `IndexError`
, just like it does when passing a single
non-integral scalar.

([gh-15805](https://github.com/numpy/numpy/pull/15805))

`numpy.delete`
no longer casts boolean indices to integers[#](#numpy-delete-no-longer-casts-boolean-indices-to-integers)
This concludes a deprecation from 1.8, where `np.delete`
would cast boolean
arrays and scalars passed as an index argument into integer indices. The
behavior now is to treat boolean arrays as a mask, and to raise an error
on boolean scalars.

([gh-15815](https://github.com/numpy/numpy/pull/15815))

## Compatibility notes[#](#compatibility-notes)
### Changed random variate stream from `numpy.random.Generator.dirichlet`
[#](#changed-random-variate-stream-from-numpy-random-generator-dirichlet)
A bug in the generation of random variates for the Dirichlet distribution
with small ‘alpha’ values was fixed by using a different algorithm when
`max(alpha) < 0.1`
. Because of the change, the stream of variates
generated by `dirichlet`
in this case will be different from previous
releases.

([gh-14924](https://github.com/numpy/numpy/pull/14924))

### Scalar promotion in `PyArray_ConvertToCommonType`
[#](#scalar-promotion-in-pyarray-converttocommontype)
The promotion of mixed scalars and arrays in `PyArray_ConvertToCommonType`
has been changed to adhere to those used by `np.result_type`
.
This means that input such as `(1000, np.array([1], dtype=np.uint8)))`
will now return `uint16`
dtypes. In most cases the behaviour is unchanged.
Note that the use of this C-API function is generally discouraged.
This also fixes `np.choose`
to behave the same way as the rest of NumPy
in this respect.

([gh-14933](https://github.com/numpy/numpy/pull/14933))

### Fasttake and fastputmask slots are deprecated and NULL’ed[#](#fasttake-and-fastputmask-slots-are-deprecated-and-null-ed)
The fasttake and fastputmask slots are now never used and must always be set to NULL. This will result in no change in behaviour. However, if a user dtype should set one of these a DeprecationWarning will be given.

([gh-14942](https://github.com/numpy/numpy/pull/14942))

`np.ediff1d`
casting behaviour with `to_end`
and `to_begin`
[#](#np-ediff1d-casting-behaviour-with-to-end-and-to-begin)
`np.ediff1d`
now uses the `"same_kind"`
casting rule for
its additional `to_end`
and `to_begin`
arguments. This
ensures type safety except when the input array has a smaller
integer type than `to_begin`
or `to_end`
.
In rare cases, the behaviour will be more strict than it was
previously in 1.16 and 1.17. This is necessary to solve issues
with floating point NaN.
([gh-14981](https://github.com/numpy/numpy/pull/14981))

### Converting of empty array-like objects to NumPy arrays[#](#converting-of-empty-array-like-objects-to-numpy-arrays)
Objects with `len(obj) == 0`
which implement an “array-like” interface,
meaning an object implementing `obj.__array__()`
,
`obj.__array_interface__`
, `obj.__array_struct__`
, or the python
buffer interface and which are also sequences (i.e. Pandas objects)
will now always retain there shape correctly when converted to an array.
If such an object has a shape of `(0, 1)`
previously, it could
be converted into an array of shape `(0,)`
(losing all dimensions
after the first 0).

([gh-14995](https://github.com/numpy/numpy/pull/14995))

### Removed `multiarray.int_asbuffer`
[#](#removed-multiarray-int-asbuffer)
As part of the continued removal of Python 2 compatibility,
`multiarray.int_asbuffer`
was removed. On Python 3, it threw a
`NotImplementedError`
and was unused internally. It is expected that there
are no downstream use cases for this method with Python 3.

([gh-15229](https://github.com/numpy/numpy/pull/15229))

`numpy.distutils.compat`
has been removed[#](#numpy-distutils-compat-has-been-removed)
This module contained only the function `get_exception()`
, which was used as:

```
try:
...
except Exception:
e = get_exception()
```
Its purpose was to handle the change in syntax introduced in Python 2.6, from
`except Exception, e:`
to `except Exception as e:`
, meaning it was only
necessary for codebases supporting Python 2.5 and older.

([gh-15255](https://github.com/numpy/numpy/pull/15255))

`issubdtype`
no longer interprets `float`
as `np.floating`
[#](#issubdtype-no-longer-interprets-float-as-np-floating)
`numpy.issubdtype`
had a FutureWarning since NumPy 1.14 which
has expired now. This means that certain input where the second
argument was neither a datatype nor a NumPy scalar type
(such as a string or a python type like `int`
or `float`
)
will now be consistent with passing in `np.dtype(arg2).type`
.
This makes the result consistent with expectations and leads to
a false result in some cases which previously returned true.
([gh-15773](https://github.com/numpy/numpy/pull/15773))

### Change output of `round`
on scalars to be consistent with Python[#](#change-output-of-round-on-scalars-to-be-consistent-with-python)
Output of the `__round__`
dunder method and consequently the Python
built-in `round`
has been changed to be a Python `int`
to be consistent
with calling it on Python `float`
objects when called with no arguments.
Previously, it would return a scalar of the `np.dtype`
that was passed in.

([gh-15840](https://github.com/numpy/numpy/pull/15840))

### The `numpy.ndarray`
constructor no longer interprets `strides=()`
as `strides=None`
[#](#the-numpy-ndarray-constructor-no-longer-interprets-strides-as-strides-none)
The former has changed to have the expected meaning of setting
`numpy.ndarray.strides`
to `()`
, while the latter continues to result in
strides being chosen automatically.

([gh-15882](https://github.com/numpy/numpy/pull/15882))

### C-Level string to datetime casts changed[#](#c-level-string-to-datetime-casts-changed)
The C-level casts from strings were simplified. This changed
also fixes string to datetime and timedelta casts to behave
correctly (i.e. like Python casts using `string_arr.astype("M8")`
while previously the cast would behave like
`string_arr.astype(np.int_).astype("M8")`
.
This only affects code using low-level C-API to do manual casts
(not full array casts) of single scalar values or using e.g.
`PyArray_GetCastFunc`
, and should thus not affect the vast majority
of users.

([gh-16068](https://github.com/numpy/numpy/pull/16068))

`SeedSequence`
with small seeds no longer conflicts with spawning[#](#seedsequence-with-small-seeds-no-longer-conflicts-with-spawning)
Small seeds (less than `2**96`
) were previously implicitly 0-padded out to
128 bits, the size of the internal entropy pool. When spawned, the spawn key
was concatenated before the 0-padding. Since the first spawn key is `(0,)`
,
small seeds before the spawn created the same states as the first spawned
`SeedSequence`
. Now, the seed is explicitly 0-padded out to the internal
pool size before concatenating the spawn key. Spawned `SeedSequences`
will
produce different results than in the previous release. Unspawned
`SeedSequences`
will still produce the same results.

([gh-16551](https://github.com/numpy/numpy/pull/16551))

## Deprecations[#](#deprecations)
### Deprecate automatic `dtype=object`
for ragged input[#](#deprecate-automatic-dtype-object-for-ragged-input)
Calling `np.array([[1, [1, 2, 3]])`
will issue a `DeprecationWarning`
as
per [NEP 34](https://numpy.org/neps/nep-0034.html). Users should explicitly use `dtype=object`
to avoid the
warning.

([gh-15119](https://github.com/numpy/numpy/pull/15119))

### Passing `shape=0`
to factory functions in `numpy.rec`
is deprecated[#](#passing-shape-0-to-factory-functions-in-numpy-rec-is-deprecated)
`0`
is treated as a special case and is aliased to `None`
in the functions:
`numpy.core.records.fromarrays`
`numpy.core.records.fromrecords`
`numpy.core.records.fromstring`
`numpy.core.records.fromfile`
In future, `0`
will not be special cased, and will be treated as an array
length like any other integer.

([gh-15217](https://github.com/numpy/numpy/pull/15217))

### Deprecation of probably unused C-API functions[#](#deprecation-of-probably-unused-c-api-functions)
The following C-API functions are probably unused and have been deprecated:

`PyArray_GetArrayParamsFromObject`
`PyUFunc_GenericFunction`
`PyUFunc_SetUsesArraysAsData`
In most cases `PyArray_GetArrayParamsFromObject`
should be replaced
by converting to an array, while `PyUFunc_GenericFunction`
can be
replaced with `PyObject_Call`
(see documentation for details).

([gh-15427](https://github.com/numpy/numpy/pull/15427))

### Converting certain types to dtypes is Deprecated[#](#converting-certain-types-to-dtypes-is-deprecated)
The super classes of scalar types, such as `np.integer`
, `np.generic`
,
or `np.inexact`
will now give a deprecation warning when converted
to a dtype (or used in a dtype keyword argument).
The reason for this is that `np.integer`
is converted to `np.int_`
,
while it would be expected to represent *any* integer (e.g. also
`int8`
, `int16`
, etc.
For example, `dtype=np.floating`
is currently identical to
`dtype=np.float64`
, even though also `np.float32`
is a subclass of
`np.floating`
.

([gh-15534](https://github.com/numpy/numpy/pull/15534))

### Deprecation of `round`
for `np.complexfloating`
scalars[#](#deprecation-of-round-for-np-complexfloating-scalars)
Output of the `__round__`
dunder method and consequently the Python built-in
`round`
has been deprecated on complex scalars. This does not affect
`np.round`
.

([gh-15840](https://github.com/numpy/numpy/pull/15840))

`numpy.ndarray.tostring()`
is deprecated in favor of `tobytes()`
[#](#numpy-ndarray-tostring-is-deprecated-in-favor-of-tobytes)
`~numpy.ndarray.tobytes`
has existed since the 1.9 release, but until this
release `~numpy.ndarray.tostring`
emitted no warning. The change to emit a
warning brings NumPy in line with the builtin `array.array`
methods of the
same name.
([gh-15867](https://github.com/numpy/numpy/pull/15867))

## C API changes[#](#c-api-changes)
### Better support for `const`
dimensions in API functions[#](#better-support-for-const-dimensions-in-api-functions)
The following functions now accept a constant array of `npy_intp`
:

`PyArray_BroadcastToShape`
`PyArray_IntTupleFromIntp`
`PyArray_OverflowMultiplyList`
Previously the caller would have to cast away the const-ness to call these functions.

([gh-15251](https://github.com/numpy/numpy/pull/15251))

### Const qualify UFunc inner loops[#](#const-qualify-ufunc-inner-loops)
`UFuncGenericFunction`
now expects pointers to const `dimension`
and
`strides`
as arguments. This means inner loops may no longer modify
either `dimension`
or `strides`
. This change leads to an
`incompatible-pointer-types`
warning forcing users to either ignore
the compiler warnings or to const qualify their own loop signatures.
([gh-15355](https://github.com/numpy/numpy/pull/15355))

## New Features[#](#new-features)
`numpy.frompyfunc`
now accepts an identity argument[#](#numpy-frompyfunc-now-accepts-an-identity-argument)
This allows the [ numpy.ufunc.identity](../reference/generated/numpy.ufunc.identity.html#numpy.ufunc.identity) attribute to be set on the
resulting ufunc, meaning it can be used for empty and multi-dimensional
calls to

[.](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce)
`numpy.ufunc.reduce`
([gh-8255](https://github.com/numpy/numpy/pull/8255))

`np.str_`
scalars now support the buffer protocol[#](#np-str-scalars-now-support-the-buffer-protocol)
`np.str_`
arrays are always stored as UCS4, so the corresponding scalars
now expose this through the buffer interface, meaning
`memoryview(np.str_('test'))`
now works.
([gh-15385](https://github.com/numpy/numpy/pull/15385))

`subok`
option for `numpy.copy`
[#](#subok-option-for-numpy-copy)
A new kwarg, `subok`
, was added to `numpy.copy`
to allow users to toggle
the behavior of `numpy.copy`
with respect to array subclasses. The default
value is `False`
which is consistent with the behavior of `numpy.copy`
for
previous numpy versions. To create a copy that preserves an array subclass with
`numpy.copy`
, call `np.copy(arr, subok=True)`
. This addition better
documents that the default behavior of `numpy.copy`
differs from the
`numpy.ndarray.copy`
method which respects array subclasses by default.

([gh-15685](https://github.com/numpy/numpy/pull/15685))

`numpy.linalg.multi_dot`
now accepts an `out`
argument[#](#numpy-linalg-multi-dot-now-accepts-an-out-argument)
`out`
can be used to avoid creating unnecessary copies of the final product
computed by `numpy.linalg.multidot`
.
([gh-15715](https://github.com/numpy/numpy/pull/15715))

`keepdims`
parameter for `numpy.count_nonzero`
[#](#keepdims-parameter-for-numpy-count-nonzero)
The parameter `keepdims`
was added to `numpy.count_nonzero`
. The
parameter has the same meaning as it does in reduction functions such
as `numpy.sum`
or `numpy.mean`
.

([gh-15870](https://github.com/numpy/numpy/pull/15870))

`equal_nan`
parameter for `numpy.array_equal`
[#](#equal-nan-parameter-for-numpy-array-equal)
The keyword argument `equal_nan`
was added to `numpy.array_equal`
.
`equal_nan`
is a boolean value that toggles whether or not `nan`
values are
considered equal in comparison (default is `False`
). This matches API used in
related functions such as `numpy.isclose`
and `numpy.allclose`
.

([gh-16128](https://github.com/numpy/numpy/pull/16128))

## Improvements[#](#improvements)
## Improve detection of CPU features[#](#improve-detection-of-cpu-features)
Replace `npy_cpu_supports`
which was a gcc specific mechanism to test support
of AVX with more general functions `npy_cpu_init`
and `npy_cpu_have`
, and
expose the results via a `NPY_CPU_HAVE`
c-macro as well as a python-level
`__cpu_features__`
dictionary.

([gh-13421](https://github.com/numpy/numpy/pull/13421))

### Use 64-bit integer size on 64-bit platforms in fallback lapack_lite[#](#use-64-bit-integer-size-on-64-bit-platforms-in-fallback-lapack-lite)
Use 64-bit integer size on 64-bit platforms in the fallback LAPACK library, which is used when the system has no LAPACK installed, allowing it to deal with linear algebra for large arrays.

([gh-15218](https://github.com/numpy/numpy/pull/15218))

### Use AVX512 intrinsic to implement `np.exp`
when input is `np.float64`
[#](#use-avx512-intrinsic-to-implement-np-exp-when-input-is-np-float64)
Use AVX512 intrinsic to implement `np.exp`
when input is `np.float64`
,
which can improve the performance of `np.exp`
with `np.float64`
input 5-7x
faster than before. The `_multiarray_umath.so`
module has grown about 63 KB
on linux64.

([gh-15648](https://github.com/numpy/numpy/pull/15648))

### Ability to disable madvise hugepages[#](#ability-to-disable-madvise-hugepages)
On Linux NumPy has previously added support for madavise hugepages which can improve performance for very large arrays. Unfortunately, on older Kernel versions this led to performance regressions, thus by default the support has been disabled on kernels before version 4.6. To override the default, you can use the environment variable:

```
NUMPY_MADVISE_HUGEPAGE=0
```
or set it to 1 to force enabling support. Note that this only makes a difference if the operating system is set up to use madvise transparent hugepage.

([gh-15769](https://github.com/numpy/numpy/pull/15769))

`numpy.einsum`
accepts NumPy `int64`
type in subscript list[#](#numpy-einsum-accepts-numpy-int64-type-in-subscript-list)
There is no longer a type error thrown when `numpy.einsum`
is passed
a NumPy `int64`
array as its subscript list.

([gh-16080](https://github.com/numpy/numpy/pull/16080))

`np.logaddexp2.identity`
changed to `-inf`
[#](#np-logaddexp2-identity-changed-to-inf)
The ufunc `~numpy.logaddexp2`
now has an identity of `-inf`
, allowing it to
be called on empty sequences. This matches the identity of `~numpy.logaddexp`
.

([gh-16102](https://github.com/numpy/numpy/pull/16102))

## Changes[#](#changes)
### Remove handling of extra argument to `__array__`
[#](#remove-handling-of-extra-argument-to-array)
A code path and test have been in the code since NumPy 0.4 for a two-argument
variant of `__array__(dtype=None, context=None)`
. It was activated when
calling `ufunc(op)`
or `ufunc.reduce(op)`
if `op.__array__`
existed.
However that variant is not documented, and it is not clear what the intention
was for its use. It has been removed.

([gh-15118](https://github.com/numpy/numpy/pull/15118))

`numpy.random._bit_generator`
moved to `numpy.random.bit_generator`
[#](#numpy-random-bit-generator-moved-to-numpy-random-bit-generator)
In order to expose `numpy.random.BitGenerator`
and
`numpy.random.SeedSequence`
to Cython, the `_bitgenerator`
module is now
public as `numpy.random.bit_generator`

### Cython access to the random distributions is provided via a `pxd`
file[#](#cython-access-to-the-random-distributions-is-provided-via-a-pxd-file)
`c_distributions.pxd`
provides access to the c functions behind many of the
random distributions from Cython, making it convenient to use and extend them.
([gh-15463](https://github.com/numpy/numpy/pull/15463))

### Fixed `eigh`
and `cholesky`
methods in `numpy.random.multivariate_normal`
[#](#fixed-eigh-and-cholesky-methods-in-numpy-random-multivariate-normal)
Previously, when passing `method='eigh'`
or `method='cholesky'`
,
`numpy.random.multivariate_normal`
produced samples from the wrong
distribution. This is now fixed.

([gh-15872](https://github.com/numpy/numpy/pull/15872))

### Fixed the jumping implementation in `MT19937.jumped`
[#](#fixed-the-jumping-implementation-in-mt19937-jumped)
This fix changes the stream produced from jumped MT19937 generators. It does
not affect the stream produced using `RandomState`
or `MT19937`
that
are directly seeded.

The translation of the jumping code for the MT19937 contained a reversed loop
ordering. `MT19937.jumped`
matches the Makoto Matsumoto’s original
implementation of the Horner and Sliding Window jump methods.

([gh-16153](https://github.com/numpy/numpy/pull/16153))# NumPy 1.8.0 Release Notes[#](#numpy-1-8-0-release-notes)
This release supports Python 2.6 -2.7 and 3.2 - 3.3.

## Highlights[#](#highlights)
New, no 2to3, Python 2 and Python 3 are supported by a common code base.

New, gufuncs for linear algebra, enabling operations on stacked arrays.

New, inplace fancy indexing for ufuncs with the

`.at`
method.
New,

`partition`
function, partial sorting via selection for fast median.
New,

`nanmean`
,`nanvar`
, and`nanstd`
functions skipping NaNs.
New,

`full`
and`full_like`
functions to create value initialized arrays.
New,

`PyUFunc_RegisterLoopForDescr`
, better ufunc support for user dtypes.
Numerous performance improvements in many areas.

## Dropped Support[#](#dropped-support)
Support for Python versions 2.4 and 2.5 has been dropped,

Support for SCons has been removed.

## Future Changes[#](#future-changes)
The Datetime64 type remains experimental in this release. In 1.9 there will probably be some changes to make it more usable.

The diagonal method currently returns a new array and raises a FutureWarning. In 1.9 it will return a readonly view.

Multiple field selection from an array of structured type currently returns a new array and raises a FutureWarning. In 1.9 it will return a readonly view.

The numpy/oldnumeric and numpy/numarray compatibility modules will be removed in 1.9.

## Compatibility notes[#](#compatibility-notes)
The doc/sphinxext content has been moved into its own github repository, and is included in numpy as a submodule. See the instructions in doc/HOWTO_BUILD_DOCS.rst for how to access the content.

The hash function of numpy.void scalars has been changed. Previously the pointer to the data was hashed as an integer. Now, the hash function uses the tuple-hash algorithm to combine the hash functions of the elements of the scalar, but only if the scalar is read-only.

Numpy has switched its build system to using ‘separate compilation’ by default. In previous releases this was supported, but not default. This should produce the same results as the old system, but if you’re trying to do something complicated like link numpy statically or using an unusual compiler, then it’s possible you will encounter problems. If so, please file a bug and as a temporary workaround you can re-enable the old build system by exporting the shell variable NPY_SEPARATE_COMPILATION=0.

For the AdvancedNew iterator the `oa_ndim`
flag should now be -1 to indicate
that no `op_axes`
and `itershape`
are passed in. The `oa_ndim == 0`
case, now indicates a 0-D iteration and `op_axes`
being NULL and the old
usage is deprecated. This does not effect the `NpyIter_New`
or
`NpyIter_MultiNew`
functions.

The functions nanargmin and nanargmax now return np.iinfo[‘intp’].min for the index in all-NaN slices. Previously the functions would raise a ValueError for array returns and NaN for scalar returns.

### NPY_RELAXED_STRIDES_CHECKING[#](#npy-relaxed-strides-checking)
There is a new compile time environment variable
`NPY_RELAXED_STRIDES_CHECKING`
. If this variable is set to 1, then
numpy will consider more arrays to be C- or F-contiguous – for
example, it becomes possible to have a column vector which is
considered both C- and F-contiguous simultaneously. The new definition
is more accurate, allows for faster code that makes fewer unnecessary
copies, and simplifies numpy’s code internally. However, it may also
break third-party libraries that make too-strong assumptions about the
stride values of C- and F-contiguous arrays. (It is also currently
known that this breaks Cython code using memoryviews, which will be
fixed in Cython.) THIS WILL BECOME THE DEFAULT IN A FUTURE RELEASE, SO
PLEASE TEST YOUR CODE NOW AGAINST NUMPY BUILT WITH:

```
NPY_RELAXED_STRIDES_CHECKING=1 python setup.py install
```
You can check whether NPY_RELAXED_STRIDES_CHECKING is in effect by running:

```
np.ones((10, 1), order="C").flags.f_contiguous
```
This will be `True`
if relaxed strides checking is enabled, and
`False`
otherwise. The typical problem we’ve seen so far is C code
that works with C-contiguous arrays, and assumes that the itemsize can
be accessed by looking at the last element in the `PyArray_STRIDES(arr)`
array. When relaxed strides are in effect, this is not true (and in
fact, it never was true in some corner cases). Instead, use
`PyArray_ITEMSIZE(arr)`
.

For more information check the “Internal memory layout of an ndarray” section in the documentation.

### Binary operations with non-arrays as second argument[#](#binary-operations-with-non-arrays-as-second-argument)
Binary operations of the form `<array-or-subclass> * <non-array-subclass>`
where `<non-array-subclass>`
declares an `__array_priority__`
higher than
that of `<array-or-subclass>`
will now unconditionally return
*NotImplemented*, giving `<non-array-subclass>`
a chance to handle the
operation. Previously, *NotImplemented* would only be returned if
`<non-array-subclass>`
actually implemented the reversed operation, and after
a (potentially expensive) array conversion of `<non-array-subclass>`
had been
attempted. ([bug](https://github.com/numpy/numpy/issues/3375), [pull request](https://github.com/numpy/numpy/pull/3501))

### Function *median* used with *overwrite_input* only partially sorts array[#](#function-median-used-with-overwrite-input-only-partially-sorts-array)
If *median* is used with *overwrite_input* option the input array will now only
be partially sorted instead of fully sorted.

### Fix to financial.npv[#](#fix-to-financial-npv)
The npv function had a bug. Contrary to what the documentation stated, it
summed from indexes `1`
to `M`
instead of from `0`
to `M - 1`
. The
fix changes the returned value. The mirr function called the npv function,
but worked around the problem, so that was also fixed and the return value
of the mirr function remains unchanged.

### Runtime warnings when comparing NaN numbers[#](#runtime-warnings-when-comparing-nan-numbers)
Comparing `NaN`
floating point numbers now raises the `invalid`
runtime
warning. If a `NaN`
is expected the warning can be ignored using np.errstate.
E.g.:

```
with np.errstate(invalid='ignore'):
operation()
```
## New Features[#](#new-features)
### Support for linear algebra on stacked arrays[#](#support-for-linear-algebra-on-stacked-arrays)
The gufunc machinery is now used for np.linalg, allowing operations on stacked arrays and vectors. For example:

```
>>> a
array([[[ 1., 1.],
[ 0., 1.]],
[[ 1., 1.],
[ 0., 1.]]])
>>> np.linalg.inv(a)
array([[[ 1., -1.],
[ 0., 1.]],
[[ 1., -1.],
[ 0., 1.]]])
```
### In place fancy indexing for ufuncs[#](#in-place-fancy-indexing-for-ufuncs)
The function `at`
has been added to ufunc objects to allow in place
ufuncs with no buffering when fancy indexing is used. For example, the
following will increment the first and second items in the array, and will
increment the third item twice: `numpy.add.at(arr, [0, 1, 2, 2], 1)`

This is what many have mistakenly thought `arr[[0, 1, 2, 2]] += 1`
would do,
but that does not work as the incremented value of `arr[2]`
is simply copied
into the third slot in `arr`
twice, not incremented twice.

### New functions *partition* and *argpartition*[#](#new-functions-partition-and-argpartition)
New functions to partially sort arrays via a selection algorithm.

A `partition`
by index `k`
moves the `k`
smallest element to the front of
an array. All elements before `k`
are then smaller or equal than the value
in position `k`
and all elements following `k`
are then greater or equal
than the value in position `k`
. The ordering of the values within these
bounds is undefined.
A sequence of indices can be provided to sort all of them into their sorted
position at once iterative partitioning.
This can be used to efficiently obtain order statistics like median or
percentiles of samples.
`partition`
has a linear time complexity of `O(n)`
while a full sort has
`O(n log(n))`
.

### New functions *nanmean*, *nanvar* and *nanstd*[#](#new-functions-nanmean-nanvar-and-nanstd)
New nan aware statistical functions are added. In these functions the results are what would be obtained if nan values were omitted from all computations.

### New functions *full* and *full_like*[#](#new-functions-full-and-full-like)
New convenience functions to create arrays filled with a specific value;
complementary to the existing *zeros* and *zeros_like* functions.

### IO compatibility with large files[#](#io-compatibility-with-large-files)
Large NPZ files >2GB can be loaded on 64-bit systems.

### Building against OpenBLAS[#](#building-against-openblas)
It is now possible to build numpy against OpenBLAS by editing site.cfg.

### New constant[#](#new-constant)
Euler’s constant is now exposed in numpy as euler_gamma.

### New modes for qr[#](#new-modes-for-qr)
New modes ‘complete’, ‘reduced’, and ‘raw’ have been added to the qr factorization and the old ‘full’ and ‘economic’ modes are deprecated. The ‘reduced’ mode replaces the old ‘full’ mode and is the default as was the ‘full’ mode, so backward compatibility can be maintained by not specifying the mode.

The ‘complete’ mode returns a full dimensional factorization, which can be useful for obtaining a basis for the orthogonal complement of the range space. The ‘raw’ mode returns arrays that contain the Householder reflectors and scaling factors that can be used in the future to apply q without needing to convert to a matrix. The ‘economic’ mode is simply deprecated, there isn’t much use for it and it isn’t any more efficient than the ‘raw’ mode.

### New *invert* argument to *in1d*[#](#new-invert-argument-to-in1d)
The function *in1d* now accepts a *invert* argument which, when *True*,
causes the returned array to be inverted.

### Advanced indexing using *np.newaxis*[#](#advanced-indexing-using-np-newaxis)
It is now possible to use *np.newaxis*/*None* together with index
arrays instead of only in simple indices. This means that
`array[np.newaxis, [0, 1]]`
will now work as expected and select the first
two rows while prepending a new axis to the array.

### C-API[#](#c-api)
New ufuncs can now be registered with builtin input types and a custom output type. Before this change, NumPy wouldn’t be able to find the right ufunc loop function when the ufunc was called from Python, because the ufunc loop signature matching logic wasn’t looking at the output operand type. Now the correct ufunc loop is found, as long as the user provides an output argument with the correct output type.

### runtests.py[#](#runtests-py)
A simple test runner script `runtests.py`
was added. It also builds Numpy via
`setup.py build`
and can be used to run tests easily during development.

## Improvements[#](#improvements)
### IO performance improvements[#](#io-performance-improvements)
Performance in reading large files was improved by chunking (see also IO compatibility).

### Performance improvements to *pad*[#](#performance-improvements-to-pad)
The *pad* function has a new implementation, greatly improving performance for
all inputs except *mode=* (retained for backwards compatibility).
Scaling with dimensionality is dramatically improved for rank >= 4.

### Performance improvements to *isnan*, *isinf*, *isfinite* and *byteswap*[#](#performance-improvements-to-isnan-isinf-isfinite-and-byteswap)
*isnan*, *isinf*, *isfinite* and *byteswap* have been improved to take
advantage of compiler builtins to avoid expensive calls to libc.
This improves performance of these operations by about a factor of two on gnu
libc systems.
### Performance improvements via SSE2 vectorization[#](#performance-improvements-via-sse2-vectorization)
Several functions have been optimized to make use of SSE2 CPU SIMD instructions.

Float32 and float64:
-
base math (

*add*,*subtract*,*divide*,*multiply*)
*sqrt*
*minimum/maximum*
*absolute*
Bool:
-
*logical_or*
*logical_and*
*logical_not*
This improves performance of these operations up to 4x/2x for float32/float64 and up to 10x for bool depending on the location of the data in the CPU caches. The performance gain is greatest for in-place operations.

In order to use the improved functions the SSE2 instruction set must be enabled at compile time. It is enabled by default on x86_64 systems. On x86_32 with a capable CPU it must be enabled by passing the appropriate flag to the CFLAGS build variable (-msse2 with gcc).

### Performance improvements to *median*[#](#performance-improvements-to-median)
*median* is now implemented in terms of *partition* instead of *sort* which
reduces its time complexity from O(n log(n)) to O(n).
If used with the *overwrite_input* option the array will now only be partially
sorted instead of fully sorted.
### Overridable operand flags in ufunc C-API[#](#overridable-operand-flags-in-ufunc-c-api)
When creating a ufunc, the default ufunc operand flags can be overridden via the new op_flags attribute of the ufunc object. For example, to set the operand flag for the first input to read/write:

PyObject *ufunc = PyUFunc_FromFuncAndData(…); ufunc->op_flags[0] = NPY_ITER_READWRITE;

This allows a ufunc to perform an operation in place. Also, global nditer flags can be overridden via the new iter_flags attribute of the ufunc object. For example, to set the reduce flag for a ufunc:

ufunc->iter_flags = NPY_ITER_REDUCE_OK;

## Changes[#](#changes)
### General[#](#general)
The function np.take now allows 0-d arrays as indices.

The separate compilation mode is now enabled by default.

Several changes to np.insert and np.delete:

Previously, negative indices and indices that pointed past the end of the array were simply ignored. Now, this will raise a Future or Deprecation Warning. In the future they will be treated like normal indexing treats them – negative indices will wrap around, and out-of-bound indices will generate an error.

Previously, boolean indices were treated as if they were integers (always referring to either the 0th or 1st item in the array). In the future, they will be treated as masks. In this release, they raise a FutureWarning warning of this coming change.

In Numpy 1.7. np.insert already allowed the syntax

*np.insert(arr, 3, [1,2,3])*to insert multiple items at a single position. In Numpy 1.8. this is also possible for*np.insert(arr, [3], [1, 2, 3])*.
Padded regions from np.pad are now correctly rounded, not truncated.

### C-API Array Additions[#](#c-api-array-additions)
Four new functions have been added to the array C-API.

PyArray_Partition

PyArray_ArgPartition

PyArray_SelectkindConverter

PyDataMem_NEW_ZEROED

### C-API Ufunc Additions[#](#c-api-ufunc-additions)
One new function has been added to the ufunc C-API that allows to register an inner loop for user types using the descr.

PyUFunc_RegisterLoopForDescr

### C-API Developer Improvements[#](#c-api-developer-improvements)
The `PyArray_Type`
instance creation function `tp_new`
now
uses `tp_basicsize`
to determine how much memory to allocate.
In previous releases only `sizeof(PyArrayObject)`
bytes of
memory were allocated, often requiring C-API subtypes to
reimplement `tp_new`
.

## Deprecations[#](#deprecations)
The ‘full’ and ‘economic’ modes of qr factorization are deprecated.

### General[#](#id1)
The use of non-integer for indices and most integer arguments has been
deprecated. Previously float indices and function arguments such as axes or
shapes were truncated to integers without warning. For example
*arr.reshape(3., -1)* or *arr[0.]* will trigger a deprecation warning in
NumPy 1.8., and in some future version of NumPy they will raise an error.# NumPy 1.20.3 Release Notes[#](#numpy-1-20-3-release-notes)
NumPy 1.20.3 is a bugfix release containing several fixes merged to the main branch after the NumPy 1.20.2 release.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Anne Archibald

Bas van Beek

Charles Harris

Dong Keun Oh +

Kamil Choudhury +

Sayed Adel

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 15 pull requests were merged for this release.

[#18763](https://github.com/numpy/numpy/pull/18763): BUG: Correct`datetime64`
missing type overload for`datetime.date`
…
[#18764](https://github.com/numpy/numpy/pull/18764): MAINT: Remove`__all__`
in favor of explicit re-exports
[#18768](https://github.com/numpy/numpy/pull/18768): BLD: Strip extra newline when dumping gfortran version on MacOS
[#18769](https://github.com/numpy/numpy/pull/18769): BUG: fix segfault in object/longdouble operations
[#18794](https://github.com/numpy/numpy/pull/18794): MAINT: Use towncrier build explicitly
[#18887](https://github.com/numpy/numpy/pull/18887): MAINT: Relax certain integer-type constraints
[#18915](https://github.com/numpy/numpy/pull/18915): MAINT: Remove unsafe unions and ABCs from return-annotations
[#18921](https://github.com/numpy/numpy/pull/18921): MAINT: Allow more recursion depth for scalar tests.
[#18922](https://github.com/numpy/numpy/pull/18922): BUG: Initialize the full nditer buffer in case of error
[#18923](https://github.com/numpy/numpy/pull/18923): BLD: remove unnecessary flag`-faltivec`
on macOS
[#18924](https://github.com/numpy/numpy/pull/18924): MAINT, CI: treats _SIMD module build warnings as errors through…
[#18925](https://github.com/numpy/numpy/pull/18925): BUG: for MINGW, threads.h existence test requires GLIBC > 2.12
[#18941](https://github.com/numpy/numpy/pull/18941): BUG: Make changelog recognize gh- as a PR number prefix.
[#18948](https://github.com/numpy/numpy/pull/18948): REL, DOC: Prepare for the NumPy 1.20.3 release.
[#18953](https://github.com/numpy/numpy/pull/18953): BUG: Fix failing mypy test in 1.20.x.# NumPy 1.22.1 Release Notes[#](#numpy-1-22-1-release-notes)
The NumPy 1.22.1 is a maintenance release that fixes bugs discovered after the 1.22.0 release. Notable fixes are:

Fix f2PY docstring problems (SciPy)

Fix reduction type problems (AstroPy)

Fix various typing bugs.

The Python versions supported for this release are 3.8-3.10.

## Contributors[#](#contributors)
A total of 14 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Arryan Singh

Bas van Beek

Charles Harris

Denis Laxalde

Isuru Fernando

Kevin Sheppard

Matthew Barber

Matti Picus

Melissa Weber Mendonça

Mukulika Pahari

Omid Rajaei +

Pearu Peterson

Ralf Gommers

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 20 pull requests were merged for this release.

[#20702](https://github.com/numpy/numpy/pull/20702): MAINT, DOC: Post 1.22.0 release fixes.
[#20703](https://github.com/numpy/numpy/pull/20703): DOC, BUG: Use pngs instead of svgs.
[#20704](https://github.com/numpy/numpy/pull/20704): DOC: Fixed the link on user-guide landing page
[#20714](https://github.com/numpy/numpy/pull/20714): BUG: Restore vc141 support
[#20724](https://github.com/numpy/numpy/pull/20724): BUG: Fix array dimensions solver for multidimensional arguments…
[#20725](https://github.com/numpy/numpy/pull/20725): TYP: change type annotation for`__array_namespace__`
to ModuleType
[#20726](https://github.com/numpy/numpy/pull/20726): TYP, MAINT: Allow`ndindex`
to accept integer tuples
[#20757](https://github.com/numpy/numpy/pull/20757): BUG: Relax dtype identity check in reductions
[#20763](https://github.com/numpy/numpy/pull/20763): TYP: Allow time manipulation functions to accept`date`
and`timedelta`
…
[#20768](https://github.com/numpy/numpy/pull/20768): TYP: Relax the type of`ndarray.__array_finalize__`
[#20795](https://github.com/numpy/numpy/pull/20795): MAINT: Raise RuntimeError if setuptools version is too recent.
[#20796](https://github.com/numpy/numpy/pull/20796): BUG, DOC: Fixes SciPy docs build warnings
[#20797](https://github.com/numpy/numpy/pull/20797): DOC: fix OpenBLAS version in release note
[#20798](https://github.com/numpy/numpy/pull/20798): PERF: Optimize array check for bounded 0,1 values
[#20805](https://github.com/numpy/numpy/pull/20805): BUG: Fix that reduce-likes honor out always (and live in the…
[#20806](https://github.com/numpy/numpy/pull/20806): BUG:`array_api.argsort(descending=True)`
respects relative…
[#20807](https://github.com/numpy/numpy/pull/20807): BUG: Allow integer inputs for pow-related functions in`array_api`
[#20814](https://github.com/numpy/numpy/pull/20814): DOC: Refer to NumPy, not pandas, in main page
[#20815](https://github.com/numpy/numpy/pull/20815): DOC: Update Copyright to 2022 [License]
[#20819](https://github.com/numpy/numpy/pull/20819): BUG: Return correctly shaped inverse indices in array_api set…# NumPy 1.10.0 Release Notes[#](#numpy-1-10-0-release-notes)
This release supports Python 2.6 - 2.7 and 3.2 - 3.5.

## Highlights[#](#highlights)
numpy.distutils now supports parallel compilation via the –parallel/-j argument passed to setup.py build

numpy.distutils now supports additional customization via site.cfg to control compilation parameters, i.e. runtime libraries, extra linking/compilation flags.

Addition of

*np.linalg.multi_dot*: compute the dot product of two or more arrays in a single function call, while automatically selecting the fastest evaluation order.
The new function

*np.stack*provides a general interface for joining a sequence of arrays along a new axis, complementing*np.concatenate*for joining along an existing axis.
Addition of

*nanprod*to the set of nanfunctions.
Support for the ‘@’ operator in Python 3.5.

## Dropped Support[#](#dropped-support)
The _dotblas module has been removed. CBLAS Support is now in Multiarray.

The testcalcs.py file has been removed.

The polytemplate.py file has been removed.

npy_PyFile_Dup and npy_PyFile_DupClose have been removed from npy_3kcompat.h.

splitcmdline has been removed from numpy/distutils/exec_command.py.

try_run and get_output have been removed from numpy/distutils/command/config.py

The a._format attribute is no longer supported for array printing.

Keywords

`skiprows`
and`missing`
removed from np.genfromtxt.
Keyword

`old_behavior`
removed from np.correlate.
## Future Changes[#](#future-changes)
In array comparisons like

`arr1 == arr2`
, many corner cases involving strings or structured dtypes that used to return scalars now issue`FutureWarning`
or`DeprecationWarning`
, and in the future will be change to either perform elementwise comparisons or raise an error.
In

`np.lib.split`
an empty array in the result always had dimension`(0,)`
no matter the dimensions of the array being split. In Numpy 1.11 that behavior will be changed so that the dimensions will be preserved. A`FutureWarning`
for this change has been in place since Numpy 1.9 but, due to a bug, sometimes no warning was raised and the dimensions were already preserved.
The SafeEval class will be removed in Numpy 1.11.

The alterdot and restoredot functions will be removed in Numpy 1.11.

See below for more details on these changes.

## Compatibility notes[#](#compatibility-notes)
### Default casting rule change[#](#default-casting-rule-change)
Default casting for inplace operations has changed to `'same_kind'`
. For
instance, if n is an array of integers, and f is an array of floats, then
`n += f`
will result in a `TypeError`
, whereas in previous Numpy
versions the floats would be silently cast to ints. In the unlikely case
that the example code is not an actual bug, it can be updated in a backward
compatible way by rewriting it as `np.add(n, f, out=n, casting='unsafe')`
.
The old `'unsafe'`
default has been deprecated since Numpy 1.7.

### numpy version string[#](#numpy-version-string)
The numpy version string for development builds has been changed from
`x.y.z.dev-githash`
to `x.y.z.dev0+githash`
(note the +) in order to comply
with PEP 440.

### relaxed stride checking[#](#relaxed-stride-checking)
NPY_RELAXED_STRIDE_CHECKING is now true by default.

UPDATE: In 1.10.2 the default value of NPY_RELAXED_STRIDE_CHECKING was changed to false for back compatibility reasons. More time is needed before it can be made the default. As part of the roadmap a deprecation of dimension changing views of f_contiguous not c_contiguous arrays was also added.

### Concatenation of 1d arrays along any but `axis=0`
raises `IndexError`
[#](#concatenation-of-1d-arrays-along-any-but-axis-0-raises-indexerror)
Using axis != 0 has raised a DeprecationWarning since NumPy 1.7, it now raises an error.

*np.ravel*, *np.diagonal* and *np.diag* now preserve subtypes[#](#np-ravel-np-diagonal-and-np-diag-now-preserve-subtypes)
There was inconsistent behavior between *x.ravel()* and *np.ravel(x)*, as
well as between *x.diagonal()* and *np.diagonal(x)*, with the methods
preserving subtypes while the functions did not. This has been fixed and
the functions now behave like the methods, preserving subtypes except in
the case of matrices. Matrices are special cased for backward
compatibility and still return 1-D arrays as before. If you need to
preserve the matrix subtype, use the methods instead of the functions.

*rollaxis* and *swapaxes* always return a view[#](#rollaxis-and-swapaxes-always-return-a-view)
Previously, a view was returned except when no change was made in the order of the axes, in which case the input array was returned. A view is now returned in all cases.

*nonzero* now returns base ndarrays[#](#nonzero-now-returns-base-ndarrays)
Previously, an inconsistency existed between 1-D inputs (returning a
base ndarray) and higher dimensional ones (which preserved subclasses).
Behavior has been unified, and the return will now be a base ndarray.
Subclasses can still override this behavior by providing their own
*nonzero* method.

### C API[#](#c-api)
The changes to *swapaxes* also apply to the *PyArray_SwapAxes* C function,
which now returns a view in all cases.

The changes to *nonzero* also apply to the *PyArray_Nonzero* C function,
which now returns a base ndarray in all cases.

The dtype structure (PyArray_Descr) has a new member at the end to cache its hash value. This shouldn’t affect any well-written applications.

The change to the concatenation function DeprecationWarning also affects PyArray_ConcatenateArrays,

### recarray field return types[#](#recarray-field-return-types)
Previously the returned types for recarray fields accessed by attribute and by index were inconsistent, and fields of string type were returned as chararrays. Now, fields accessed by either attribute or indexing will return an ndarray for fields of non-structured type, and a recarray for fields of structured type. Notably, this affect recarrays containing strings with whitespace, as trailing whitespace is trimmed from chararrays but kept in ndarrays of string type. Also, the dtype.type of nested structured fields is now inherited.

### recarray views[#](#recarray-views)
Viewing an ndarray as a recarray now automatically converts the dtype to np.record. See new record array documentation. Additionally, viewing a recarray with a non-structured dtype no longer converts the result’s type to ndarray - the result will remain a recarray.

### ‘out’ keyword argument of ufuncs now accepts tuples of arrays[#](#out-keyword-argument-of-ufuncs-now-accepts-tuples-of-arrays)
When using the ‘out’ keyword argument of a ufunc, a tuple of arrays, one per
ufunc output, can be provided. For ufuncs with a single output a single array
is also a valid ‘out’ keyword argument. Previously a single array could be
provided in the ‘out’ keyword argument, and it would be used as the first
output for ufuncs with multiple outputs, is deprecated, and will result in a
*DeprecationWarning* now and an error in the future.

### byte-array indices now raises an IndexError[#](#byte-array-indices-now-raises-an-indexerror)
Indexing an ndarray using a byte-string in Python 3 now raises an IndexError instead of a ValueError.

### Masked arrays containing objects with arrays[#](#masked-arrays-containing-objects-with-arrays)
For such (rare) masked arrays, getting a single masked item no longer returns a corrupted masked array, but a fully masked version of the item.

### Median warns and returns nan when invalid values are encountered[#](#median-warns-and-returns-nan-when-invalid-values-are-encountered)
Similar to mean, median and percentile now emits a Runtime warning and
returns *NaN* in slices where a *NaN* is present.
To compute the median or percentile while ignoring invalid values use the
new *nanmedian* or *nanpercentile* functions.

### Functions available from numpy.ma.testutils have changed[#](#functions-available-from-numpy-ma-testutils-have-changed)
All functions from numpy.testing were once available from numpy.ma.testutils but not all of them were redefined to work with masked arrays. Most of those functions have now been removed from numpy.ma.testutils with a small subset retained in order to preserve backward compatibility. In the long run this should help avoid mistaken use of the wrong functions, but it may cause import problems for some.

## New Features[#](#new-features)
### Reading extra flags from site.cfg[#](#reading-extra-flags-from-site-cfg)
Previously customization of compilation of dependency libraries and numpy
itself was only accomblishable via code changes in the distutils package.
Now numpy.distutils reads in the following extra flags from each group of the
*site.cfg*:

`runtime_library_dirs/rpath`
, sets runtime library directories to override
`LD_LIBRARY_PATH`
`extra_compile_args`
, add extra flags to the compilation of sources
`extra_link_args`
, add extra flags when linking libraries
This should, at least partially, complete user customization.

*np.cbrt* to compute cube root for real floats[#](#np-cbrt-to-compute-cube-root-for-real-floats)
*np.cbrt* wraps the C99 cube root function *cbrt*.
Compared to *np.power(x, 1./3.)* it is well defined for negative real floats
and a bit faster.
### numpy.distutils now allows parallel compilation[#](#numpy-distutils-now-allows-parallel-compilation)
By passing *–parallel=n* or *-j n* to *setup.py build* the compilation of
extensions is now performed in *n* parallel processes.
The parallelization is limited to files within one extension so projects using
Cython will not profit because it builds extensions from single files.

*genfromtxt* has a new `max_rows`
argument[#](#genfromtxt-has-a-new-max-rows-argument)
A `max_rows`
argument has been added to *genfromtxt* to limit the
number of rows read in a single call. Using this functionality, it is
possible to read in multiple arrays stored in a single file by making
repeated calls to the function.

### New function *np.broadcast_to* for invoking array broadcasting[#](#new-function-np-broadcast-to-for-invoking-array-broadcasting)
*np.broadcast_to* manually broadcasts an array to a given shape according to
numpy’s broadcasting rules. The functionality is similar to broadcast_arrays,
which in fact has been rewritten to use broadcast_to internally, but only a
single array is necessary.
### New context manager *clear_and_catch_warnings* for testing warnings[#](#new-context-manager-clear-and-catch-warnings-for-testing-warnings)
When Python emits a warning, it records that this warning has been emitted in
the module that caused the warning, in a module attribute
`__warningregistry__`
. Once this has happened, it is not possible to emit
the warning again, unless you clear the relevant entry in
`__warningregistry__`
. This makes is hard and fragile to test warnings,
because if your test comes after another that has already caused the warning,
you will not be able to emit the warning or test it. The context manager
`clear_and_catch_warnings`
clears warnings from the module registry on entry
and resets them on exit, meaning that warnings can be re-raised.

*cov* has new `fweights`
and `aweights`
arguments[#](#cov-has-new-fweights-and-aweights-arguments)
The `fweights`
and `aweights`
arguments add new functionality to
covariance calculations by applying two types of weighting to observation
vectors. An array of `fweights`
indicates the number of repeats of each
observation vector, and an array of `aweights`
provides their relative
importance or probability.

### Support for the ‘@’ operator in Python 3.5+[#](#support-for-the-operator-in-python-3-5)
Python 3.5 adds support for a matrix multiplication operator ‘@’ proposed
in PEP465. Preliminary support for that has been implemented, and an
equivalent function `matmul`
has also been added for testing purposes and
use in earlier Python versions. The function is preliminary and the order
and number of its optional arguments can be expected to change.

### New argument `norm`
to fft functions[#](#new-argument-norm-to-fft-functions)
The default normalization has the direct transforms unscaled and the inverse
transforms are scaled by \(1/n\). It is possible to obtain unitary
transforms by setting the keyword argument `norm`
to `"ortho"`
(default is
*None*) so that both direct and inverse transforms will be scaled by
\(1/\\sqrt{n}\).

## Improvements[#](#improvements)
*np.digitize* using binary search[#](#np-digitize-using-binary-search)
*np.digitize* is now implemented in terms of *np.searchsorted*. This means
that a binary search is used to bin the values, which scales much better
for larger number of bins than the previous linear search. It also removes
the requirement for the input array to be 1-dimensional.
*np.poly* now casts integer inputs to float[#](#np-poly-now-casts-integer-inputs-to-float)
*np.poly* will now cast 1-dimensional input arrays of integer type to double
precision floating point, to prevent integer overflow when computing the monic
polynomial. It is still possible to obtain higher precision results by
passing in an array of object type, filled e.g. with Python ints.
*np.interp* can now be used with periodic functions[#](#np-interp-can-now-be-used-with-periodic-functions)
*np.interp* now has a new parameter *period* that supplies the period of the
input data *xp*. In such case, the input data is properly normalized to the
given period and one end point is added to each extremity of *xp* in order to
close the previous and the next period cycles, resulting in the correct
interpolation behavior.
*np.pad* supports more input types for `pad_width`
and `constant_values`
[#](#np-pad-supports-more-input-types-for-pad-width-and-constant-values)
`constant_values`
parameters now accepts NumPy arrays and float values.
NumPy arrays are supported as input for `pad_width`
, and an exception is
raised if its values are not of integral type.
*np.argmax* and *np.argmin* now support an `out`
argument[#](#np-argmax-and-np-argmin-now-support-an-out-argument)
The `out`
parameter was added to *np.argmax* and *np.argmin* for consistency
with *ndarray.argmax* and *ndarray.argmin*. The new parameter behaves exactly
as it does in those methods.

### More system C99 complex functions detected and used[#](#more-system-c99-complex-functions-detected-and-used)
All of the functions `in complex.h`
are now detected. There are new
fallback implementations of the following functions.

npy_ctan,

npy_cacos, npy_casin, npy_catan

npy_ccosh, npy_csinh, npy_ctanh,

npy_cacosh, npy_casinh, npy_catanh

As a result of these improvements, there will be some small changes in returned values, especially for corner cases.

*np.loadtxt* support for the strings produced by the `float.hex`
method[#](#np-loadtxt-support-for-the-strings-produced-by-the-float-hex-method)
The strings produced by `float.hex`
look like `0x1.921fb54442d18p+1`
,
so this is not the hex used to represent unsigned integer types.

*np.isclose* properly handles minimal values of integer dtypes[#](#np-isclose-properly-handles-minimal-values-of-integer-dtypes)
In order to properly handle minimal values of integer types, *np.isclose* will
now cast to the float dtype during comparisons. This aligns its behavior with
what was provided by *np.allclose*.

*np.allclose* uses *np.isclose* internally.[#](#np-allclose-uses-np-isclose-internally)
*np.allclose* now uses *np.isclose* internally and inherits the ability to
compare NaNs as equal by setting `equal_nan=True`
. Subclasses, such as
*np.ma.MaskedArray*, are also preserved now.
*np.genfromtxt* now handles large integers correctly[#](#np-genfromtxt-now-handles-large-integers-correctly)
*np.genfromtxt* now correctly handles integers larger than `2**31-1`
on
32-bit systems and larger than `2**63-1`
on 64-bit systems (it previously
crashed with an `OverflowError`
in these cases). Integers larger than
`2**63-1`
are converted to floating-point values.
*np.load*, *np.save* have pickle backward compatibility flags[#](#np-load-np-save-have-pickle-backward-compatibility-flags)
The functions *np.load* and *np.save* have additional keyword
arguments for controlling backward compatibility of pickled Python
objects. This enables Numpy on Python 3 to load npy files containing
object arrays that were generated on Python 2.

### MaskedArray support for more complicated base classes[#](#maskedarray-support-for-more-complicated-base-classes)
Built-in assumptions that the baseclass behaved like a plain array are being
removed. In particular, setting and getting elements and ranges will respect
baseclass overrides of `__setitem__`
and `__getitem__`
, and arithmetic
will respect overrides of `__add__`
, `__sub__`
, etc.

## Changes[#](#changes)
### dotblas functionality moved to multiarray[#](#dotblas-functionality-moved-to-multiarray)
The cblas versions of dot, inner, and vdot have been integrated into the multiarray module. In particular, vdot is now a multiarray function, which it was not before.

### stricter check of gufunc signature compliance[#](#stricter-check-of-gufunc-signature-compliance)
Inputs to generalized universal functions are now more strictly checked against the function’s signature: all core dimensions are now required to be present in input arrays; core dimensions with the same label must have the exact same size; and output core dimension’s must be specified, either by a same label input core dimension or by a passed-in output array.

### views returned from *np.einsum* are writeable[#](#views-returned-from-np-einsum-are-writeable)
Views returned by *np.einsum* will now be writeable whenever the input
array is writeable.

*np.argmin* skips NaT values[#](#np-argmin-skips-nat-values)
*np.argmin* now skips NaT values in datetime64 and timedelta64 arrays,
making it consistent with *np.min*, *np.argmax* and *np.max*.
## Deprecations[#](#deprecations)
### Array comparisons involving strings or structured dtypes[#](#array-comparisons-involving-strings-or-structured-dtypes)
Normally, comparison operations on arrays perform elementwise comparisons and return arrays of booleans. But in some corner cases, especially involving strings are structured dtypes, NumPy has historically returned a scalar instead. For example:

```
### Current behaviour
np.arange(2) == "foo"
# -> False
np.arange(2) < "foo"
# -> True on Python 2, error on Python 3
np.ones(2, dtype="i4,i4") == np.ones(2, dtype="i4,i4,i4")
# -> False
```
Continuing work started in 1.9, in 1.10 these comparisons will now
raise `FutureWarning`
or `DeprecationWarning`
, and in the future
they will be modified to behave more consistently with other
comparison operations, e.g.:

```
### Future behaviour
np.arange(2) == "foo"
# -> array([False, False])
np.arange(2) < "foo"
# -> error, strings and numbers are not orderable
np.ones(2, dtype="i4,i4") == np.ones(2, dtype="i4,i4,i4")
# -> [False, False]
```
### SafeEval[#](#safeeval)
The SafeEval class in numpy/lib/utils.py is deprecated and will be removed in the next release.

### alterdot, restoredot[#](#alterdot-restoredot)
The alterdot and restoredot functions no longer do anything, and are deprecated.

### pkgload, PackageLoader[#](#pkgload-packageloader)
These ways of loading packages are now deprecated.

### bias, ddof arguments to corrcoef[#](#bias-ddof-arguments-to-corrcoef)
The values for the `bias`
and `ddof`
arguments to the `corrcoef`
function canceled in the division implied by the correlation coefficient and
so had no effect on the returned values.

We now deprecate these arguments to `corrcoef`
and the masked array version
`ma.corrcoef`
.

Because we are deprecating the `bias`
argument to `ma.corrcoef`
, we also
deprecate the use of the `allow_masked`
argument as a positional argument,
as its position will change with the removal of `bias`
. `allow_masked`
will in due course become a keyword-only argument.

### dtype string representation changes[#](#dtype-string-representation-changes)
Since 1.6, creating a dtype object from its string representation, e.g.
`'f4'`
, would issue a deprecation warning if the size did not correspond
to an existing type, and default to creating a dtype of the default size
for the type. Starting with this release, this will now raise a `TypeError`
.

The only exception is object dtypes, where both `'O4'`
and `'O8'`
will
still issue a deprecation warning. This platform-dependent representation
will raise an error in the next release.

In preparation for this upcoming change, the string representation of an
object dtype, i.e. `np.dtype(object).str`
, no longer includes the item
size, i.e. will return `'|O'`
instead of `'|O4'`
or `'|O8'`
as
before.# NumPy 1.9.0 Release Notes[#](#numpy-1-9-0-release-notes)
This release supports Python 2.6 - 2.7 and 3.2 - 3.4.

## Highlights[#](#highlights)
Numerous performance improvements in various areas, most notably indexing and operations on small arrays are significantly faster. Indexing operations now also release the GIL.

Addition of

*nanmedian*and*nanpercentile*rounds out the nanfunction set.
## Dropped Support[#](#dropped-support)
The oldnumeric and numarray modules have been removed.

The doc/pyrex and doc/cython directories have been removed.

The doc/numpybook directory has been removed.

The numpy/testing/numpytest.py file has been removed together with the importall function it contained.

## Future Changes[#](#future-changes)
The numpy/polynomial/polytemplate.py file will be removed in NumPy 1.10.0.

Default casting for inplace operations will change to ‘same_kind’ in Numpy 1.10.0. This will certainly break some code that is currently ignoring the warning.

Relaxed stride checking will be the default in 1.10.0

String version checks will break because, e.g., ‘1.9’ > ‘1.10’ is True. A NumpyVersion class has been added that can be used for such comparisons.

The diagonal and diag functions will return writeable views in 1.10.0

The

*S*and/or*a*dtypes may be changed to represent Python strings instead of bytes, in Python 3 these two types are very different.
## Compatibility notes[#](#compatibility-notes)
### The diagonal and diag functions return readonly views.[#](#the-diagonal-and-diag-functions-return-readonly-views)
In NumPy 1.8, the diagonal and diag functions returned readonly copies, in NumPy 1.9 they return readonly views, and in 1.10 they will return writeable views.

### Special scalar float values don’t cause upcast to double anymore[#](#special-scalar-float-values-don-t-cause-upcast-to-double-anymore)
In previous numpy versions operations involving floating point scalars
containing special values `NaN`
, `Inf`
and `-Inf`
caused the result
type to be at least `float64`
. As the special values can be represented
in the smallest available floating point type, the upcast is not performed
anymore.

For example the dtype of:


`np.array([1.], dtype=np.float32) * float('nan')`
now remains `float32`
instead of being cast to `float64`
.
Operations involving non-special values have not been changed.

### Percentile output changes[#](#percentile-output-changes)
If given more than one percentile to compute numpy.percentile returns an
array instead of a list. A single percentile still returns a scalar. The
array is equivalent to converting the list returned in older versions
to an array via `np.array`
.

If the `overwrite_input`
option is used the input is only partially
instead of fully sorted.

### ndarray.tofile exception type[#](#ndarray-tofile-exception-type)
All `tofile`
exceptions are now `IOError`
, some were previously
`ValueError`
.

### Invalid fill value exceptions[#](#invalid-fill-value-exceptions)
Two changes to numpy.ma.core._check_fill_value:

When the fill value is a string and the array type is not one of ‘OSUV’, TypeError is raised instead of the default fill value being used.

When the fill value overflows the array type, TypeError is raised instead of OverflowError.

### Polynomial Classes no longer derived from PolyBase[#](#polynomial-classes-no-longer-derived-from-polybase)
This may cause problems with folks who depended on the polynomial classes being derived from PolyBase. They are now all derived from the abstract base class ABCPolyBase. Strictly speaking, there should be a deprecation involved, but no external code making use of the old baseclass could be found.

### Using numpy.random.binomial may change the RNG state vs. numpy < 1.9[#](#using-numpy-random-binomial-may-change-the-rng-state-vs-numpy-1-9)
A bug in one of the algorithms to generate a binomial random variate has been fixed. This change will likely alter the number of random draws performed, and hence the sequence location will be different after a call to distribution.c::rk_binomial_btpe. Any tests which rely on the RNG being in a known state should be checked and/or updated as a result.

### Random seed enforced to be a 32 bit unsigned integer[#](#random-seed-enforced-to-be-a-32-bit-unsigned-integer)
`np.random.seed`
and `np.random.RandomState`
now throw a `ValueError`
if the seed cannot safely be converted to 32 bit unsigned integers.
Applications that now fail can be fixed by masking the higher 32 bit values to
zero: `seed = seed & 0xFFFFFFFF`
. This is what is done silently in older
versions so the random stream remains the same.
### Argmin and argmax out argument[#](#argmin-and-argmax-out-argument)
The `out`
argument to `np.argmin`
and `np.argmax`
and their
equivalent C-API functions is now checked to match the desired output shape
exactly. If the check fails a `ValueError`
instead of `TypeError`
is
raised.

### Einsum[#](#einsum)
Remove unnecessary broadcasting notation restrictions.
`np.einsum('ijk,j->ijk', A, B)`
can also be written as
`np.einsum('ij...,j->ij...', A, B)`
(ellipsis is no longer required on ‘j’)

### Indexing[#](#indexing)
The NumPy indexing has seen a complete rewrite in this version. This makes most advanced integer indexing operations much faster and should have no other implications. However some subtle changes and deprecations were introduced in advanced indexing operations:

Boolean indexing into scalar arrays will always return a new 1-d array. This means that

`array(1)[array(True)]`
gives`array([1])`
and not the original array.
Advanced indexing into one dimensional arrays used to have (undocumented) special handling regarding repeating the value array in assignments when the shape of the value array was too small or did not match. Code using this will raise an error. For compatibility you can use

`arr.flat[index] = values`
, which uses the old code branch. (for example`a = np.ones(10); a[np.arange(10)] = [1, 2, 3]`
)
The iteration order over advanced indexes used to be always C-order. In NumPy 1.9. the iteration order adapts to the inputs and is not guaranteed (with the exception of a

*single*advanced index which is never reversed for compatibility reasons). This means that the result is undefined if multiple values are assigned to the same element. An example for this is`arr[[0, 0], [1, 1]] = [1, 2]`
, which may set`arr[0, 1]`
to either 1 or 2.
Equivalent to the iteration order, the memory layout of the advanced indexing result is adapted for faster indexing and cannot be predicted.

All indexing operations return a view or a copy. No indexing operation will return the original array object. (For example

`arr[...]`
)
In the future Boolean array-likes (such as lists of python bools) will always be treated as Boolean indexes and Boolean scalars (including python

`True`
) will be a legal*boolean*index. At this time, this is already the case for scalar arrays to allow the general`positive = a[a > 0]`
to work when`a`
is zero dimensional.
In NumPy 1.8 it was possible to use

`array(True)`
and`array(False)`
equivalent to 1 and 0 if the result of the operation was a scalar. This will raise an error in NumPy 1.9 and, as noted above, treated as a boolean index in the future.
All non-integer array-likes are deprecated, object arrays of custom integer like objects may have to be cast explicitly.

The error reporting for advanced indexing is more informative, however the error type has changed in some cases. (Broadcasting errors of indexing arrays are reported as

`IndexError`
)
Indexing with more then one ellipsis (

`...`
) is deprecated.
### Non-integer reduction axis indexes are deprecated[#](#non-integer-reduction-axis-indexes-are-deprecated)
Non-integer axis indexes to reduction ufuncs like *add.reduce* or *sum* are
deprecated.

`promote_types`
and string dtype[#](#promote-types-and-string-dtype)
`promote_types`
function now returns a valid string length when given an
integer or float dtype as one argument and a string dtype as another
argument. Previously it always returned the input string dtype, even if it
wasn’t long enough to store the max integer/float value converted to a
string.
`can_cast`
and string dtype[#](#can-cast-and-string-dtype)
`can_cast`
function now returns False in “safe” casting mode for
integer/float dtype and string dtype if the string dtype length is not long
enough to store the max integer/float value converted to a string.
Previously `can_cast`
in “safe” mode returned True for integer/float
dtype and a string dtype of any length.
### astype and string dtype[#](#astype-and-string-dtype)
The `astype`
method now returns an error if the string dtype to cast to
is not long enough in “safe” casting mode to hold the max value of
integer/float array that is being casted. Previously the casting was
allowed even if the result was truncated.

*npyio.recfromcsv* keyword arguments change[#](#npyio-recfromcsv-keyword-arguments-change)
*npyio.recfromcsv* no longer accepts the undocumented *update* keyword,
which used to override the *dtype* keyword.
### The `doc/swig`
directory moved[#](#the-doc-swig-directory-moved)
The `doc/swig`
directory has been moved to `tools/swig`
.

### The `npy_3kcompat.h`
header changed[#](#the-npy-3kcompat-h-header-changed)
The unused `simple_capsule_dtor`
function has been removed from
`npy_3kcompat.h`
. Note that this header is not meant to be used outside
of numpy; other projects should be using their own copy of this file when
needed.

### Negative indices in C-Api `sq_item`
and `sq_ass_item`
sequence methods[#](#negative-indices-in-c-api-sq-item-and-sq-ass-item-sequence-methods)
When directly accessing the `sq_item`
or `sq_ass_item`
PyObject slots
for item getting, negative indices will not be supported anymore.
`PySequence_GetItem`
and `PySequence_SetItem`
however fix negative
indices so that they can be used there.

### NDIter[#](#nditer)
When `NpyIter_RemoveAxis`
is now called, the iterator range will be reset.

When a multi index is being tracked and an iterator is not buffered, it is
possible to use `NpyIter_RemoveAxis`
. In this case an iterator can shrink
in size. Because the total size of an iterator is limited, the iterator
may be too large before these calls. In this case its size will be set to `-1`
and an error issued not at construction time but when removing the multi
index, setting the iterator range, or getting the next function.

This has no effect on currently working code, but highlights the necessity of checking for an error return if these conditions can occur. In most cases the arrays being iterated are as large as the iterator so that such a problem cannot occur.

This change was already applied to the 1.8.1 release.

`zeros_like`
for string dtypes now returns empty strings[#](#zeros-like-for-string-dtypes-now-returns-empty-strings)
To match the *zeros* function *zeros_like* now returns an array initialized
with empty strings instead of an array filled with *‘0’*.

## New Features[#](#new-features)
### Percentile supports more interpolation options[#](#percentile-supports-more-interpolation-options)
`np.percentile`
now has the interpolation keyword argument to specify in
which way points should be interpolated if the percentiles fall between two
values. See the documentation for the available options.
### Generalized axis support for median and percentile[#](#generalized-axis-support-for-median-and-percentile)
`np.median`
and `np.percentile`
now support generalized axis arguments like
ufunc reductions do since 1.7. One can now say axis=(index, index) to pick a
list of axes for the reduction. The `keepdims`
keyword argument was also
added to allow convenient broadcasting to arrays of the original shape.
### Dtype parameter added to `np.linspace`
and `np.logspace`
[#](#dtype-parameter-added-to-np-linspace-and-np-logspace)
The returned data type from the `linspace`
and `logspace`
functions can
now be specified using the dtype parameter.

### More general `np.triu`
and `np.tril`
broadcasting[#](#more-general-np-triu-and-np-tril-broadcasting)
For arrays with `ndim`
exceeding 2, these functions will now apply to the
final two axes instead of raising an exception.

`tobytes`
alias for `tostring`
method[#](#tobytes-alias-for-tostring-method)
`ndarray.tobytes`
and `MaskedArray.tobytes`
have been added as aliases
for `tostring`
which exports arrays as `bytes`
. This is more consistent
in Python 3 where `str`
and `bytes`
are not the same.
### Build system[#](#build-system)
Added experimental support for the ppc64le and OpenRISC architecture.

### Compatibility to python `numbers`
module[#](#compatibility-to-python-numbers-module)
All numerical numpy types are now registered with the type hierarchy in
the python `numbers`
module.

`increasing`
parameter added to `np.vander`
[#](#increasing-parameter-added-to-np-vander)
The ordering of the columns of the Vandermonde matrix can be specified with this new boolean argument.

`unique_counts`
parameter added to `np.unique`
[#](#unique-counts-parameter-added-to-np-unique)
The number of times each unique item comes up in the input can now be obtained as an optional return value.

### Support for median and percentile in nanfunctions[#](#support-for-median-and-percentile-in-nanfunctions)
The `np.nanmedian`
and `np.nanpercentile`
functions behave like
the median and percentile functions except that NaNs are ignored.

### NumpyVersion class added[#](#numpyversion-class-added)
The class may be imported from numpy.lib and can be used for version comparison when the numpy version goes to 1.10.devel. For example:

```
>>> from numpy.lib import NumpyVersion
>>> if NumpyVersion(np.__version__) < '1.10.0'):
... print('Wow, that is an old NumPy version!')
```
### Allow saving arrays with large number of named columns[#](#allow-saving-arrays-with-large-number-of-named-columns)
The numpy storage format 1.0 only allowed the array header to have a total size
of 65535 bytes. This can be exceeded by structured arrays with a large number
of columns. A new format 2.0 has been added which extends the header size to 4
GiB. *np.save* will automatically save in 2.0 format if the data requires it,
else it will always use the more compatible 1.0 format.

### Full broadcasting support for `np.cross`
[#](#full-broadcasting-support-for-np-cross)
`np.cross`
now properly broadcasts its two input arrays, even if they
have different number of dimensions. In earlier versions this would result
in either an error being raised, or wrong results computed.
## Improvements[#](#improvements)
### Better numerical stability for sum in some cases[#](#better-numerical-stability-for-sum-in-some-cases)
Pairwise summation is now used in the sum method, but only along the fast axis and for groups of the values <= 8192 in length. This should also improve the accuracy of var and std in some common cases.

### Percentile implemented in terms of `np.partition`
[#](#percentile-implemented-in-terms-of-np-partition)
`np.percentile`
has been implemented in terms of `np.partition`
which
only partially sorts the data via a selection algorithm. This improves the
time complexity from `O(nlog(n))`
to `O(n)`
.
### Performance improvement for `np.array`
[#](#performance-improvement-for-np-array)
The performance of converting lists containing arrays to arrays using
`np.array`
has been improved. It is now equivalent in speed to
`np.vstack(list)`
.

### Performance improvement for `np.searchsorted`
[#](#performance-improvement-for-np-searchsorted)
For the built-in numeric types, `np.searchsorted`
no longer relies on the
data type’s `compare`
function to perform the search, but is now
implemented by type specific functions. Depending on the size of the
inputs, this can result in performance improvements over 2x.

### Optional reduced verbosity for np.distutils[#](#optional-reduced-verbosity-for-np-distutils)
Set `numpy.distutils.system_info.system_info.verbosity = 0`
and then
calls to `numpy.distutils.system_info.get_info('blas_opt')`
will not
print anything on the output. This is mostly for other packages using
numpy.distutils.

### Covariance check in `np.random.multivariate_normal`
[#](#covariance-check-in-np-random-multivariate-normal)
A `RuntimeWarning`
warning is raised when the covariance matrix is not
positive-semidefinite.

### Polynomial Classes no longer template based[#](#polynomial-classes-no-longer-template-based)
The polynomial classes have been refactored to use an abstract base class rather than a template in order to implement a common interface. This makes importing the polynomial package faster as the classes do not need to be compiled on import.

### More GIL releases[#](#more-gil-releases)
Several more functions now release the Global Interpreter Lock allowing more
efficient parallelization using the `threading`
module. Most notably the GIL is
now released for fancy indexing, `np.where`
and the `random`
module now
uses a per-state lock instead of the GIL.

### MaskedArray support for more complicated base classes[#](#maskedarray-support-for-more-complicated-base-classes)
Built-in assumptions that the baseclass behaved like a plain array are being
removed. In particular, `repr`
and `str`
should now work more reliably.

### C-API[#](#c-api)
## Deprecations[#](#deprecations)
### Non-integer scalars for sequence repetition[#](#non-integer-scalars-for-sequence-repetition)
Using non-integer numpy scalars to repeat python sequences is deprecated.
For example `np.float_(2) * [1]`
will be an error in the future.

`select`
input deprecations[#](#select-input-deprecations)
The integer and empty input to `select`
is deprecated. In the future only
boolean arrays will be valid conditions and an empty `condlist`
will be
considered an input error instead of returning the default.

`rank`
function[#](#rank-function)
The `rank`
function has been deprecated to avoid confusion with
`numpy.linalg.matrix_rank`
.

### Object array equality comparisons[#](#object-array-equality-comparisons)
In the future object array comparisons both *==* and *np.equal* will not
make use of identity checks anymore. For example:

```
>>> a = np.array([np.array([1, 2, 3]), 1])
>>> b = np.array([np.array([1, 2, 3]), 1])
>>> a == b
```
will consistently return False (and in the future an error) even if the array
in *a* and *b* was the same object.

The equality operator *==* will in the future raise errors like *np.equal*
if broadcasting or element comparisons, etc. fails.

Comparison with *arr == None* will in the future do an elementwise comparison
instead of just returning False. Code should be using *arr is None*.

All of these changes will give Deprecation- or FutureWarnings at this time.

### C-API[#](#id1)
The utility function npy_PyFile_Dup and npy_PyFile_DupClose are broken by the internal buffering python 3 applies to its file objects. To fix this two new functions npy_PyFile_Dup2 and npy_PyFile_DupClose2 are declared in npy_3kcompat.h and the old functions are deprecated. Due to the fragile nature of these functions it is recommended to instead use the python API when possible.

This change was already applied to the 1.8.1 release.# NumPy 1.15.2 Release Notes[#](#numpy-1-15-2-release-notes)
This is a bugfix release for bugs and regressions reported following the 1.15.1 release.

The matrix PendingDeprecationWarning is now suppressed in pytest 3.8.

The new cached allocations machinery has been fixed to be thread safe.

The boolean indexing of subclasses now works correctly.

A small memory leak in PyArray_AdaptFlexibleDType has been fixed.

The Python versions supported by this release are 2.7, 3.4-3.7. The wheels are linked with OpenBLAS v0.3.0, which should fix some of the linalg problems reported for NumPy 1.14.

## Compatibility Note[#](#compatibility-note)
The NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit
binaries. That will also be the case in future releases. See
[#11625](https://github.com/numpy/numpy/issues/11625) for the related
discussion. Those needing 32-bit support should look elsewhere or build
from source.

## Contributors[#](#contributors)
A total of 4 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Julian Taylor

Marten van Kerkwijk

Matti Picus

## Pull requests merged[#](#pull-requests-merged)
A total of 4 pull requests were merged for this release.# NumPy 1.18.1 Release Notes[#](#numpy-1-18-1-release-notes)
This release contains fixes for bugs reported against NumPy 1.18.0. Two bugs in particular that caused widespread problems downstream were:

The cython random extension test was not using a temporary directory for building, resulting in a permission violation. Fixed.

Numpy distutils was appending

*-std=c99*to all C compiler runs, leading to changed behavior and compile problems downstream. That flag is now only applied when building numpy C code.
The Python versions supported in this release are 3.5-3.8. Downstream developers should use Cython >= 0.29.14 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Matti Picus

Maxwell Aladago

Pauli Virtanen

Ralf Gommers

Tyler Reddy

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 13 pull requests were merged for this release.

[#15158](https://github.com/numpy/numpy/pull/15158): MAINT: Update pavement.py for towncrier.
[#15159](https://github.com/numpy/numpy/pull/15159): DOC: add moved modules to 1.18 release note
[#15161](https://github.com/numpy/numpy/pull/15161): MAINT, DOC: Minor backports and updates for 1.18.x
[#15176](https://github.com/numpy/numpy/pull/15176): TST: Add assert_array_equal test for big integer arrays
[#15184](https://github.com/numpy/numpy/pull/15184): BUG: use tmp dir and check version for cython test (#15170)
[#15220](https://github.com/numpy/numpy/pull/15220): BUG: distutils: fix msvc+gfortran openblas handling corner case
[#15221](https://github.com/numpy/numpy/pull/15221): BUG: remove -std=c99 for c++ compilation (#15194)
[#15222](https://github.com/numpy/numpy/pull/15222): MAINT: unskip test on win32
[#15223](https://github.com/numpy/numpy/pull/15223): TST: add BLAS ILP64 run in Travis & Azure
[#15245](https://github.com/numpy/numpy/pull/15245): MAINT: only add –std=c99 where needed
[#15246](https://github.com/numpy/numpy/pull/15246): BUG: lib: Fix handling of integer arrays by gradient.
[#15247](https://github.com/numpy/numpy/pull/15247): MAINT: Do not use private Python function in testing
[#15250](https://github.com/numpy/numpy/pull/15250): REL: Prepare for the NumPy 1.18.1 release.# NumPy 1.21.2 Release Notes[#](#numpy-1-21-2-release-notes)
The NumPy 1.21.2 is a maintenance release that fixes bugs discovered after 1.21.1. It also provides 64 bit manylinux Python 3.10.0rc1 wheels for downstream testing. Note that Python 3.10 is not yet final. It also has preliminary support for Windows on ARM64, but there is no OpenBLAS for that platform and no wheels are available.

The Python versions supported for this release are 3.7-3.9. The 1.21.x series is compatible with Python 3.10.0rc1 and Python 3.10 will be officially supported after it is released. The previous problems with gcc-11.1 have been fixed by gcc-11.2, check your version if you are using gcc-11.

## Contributors[#](#contributors)
A total of 10 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Bas van Beek

Carl Johnsen +

Charles Harris

Gwyn Ciesla +

Matthieu Dartiailh

Matti Picus

Niyas Sait +

Ralf Gommers

Sayed Adel

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 18 pull requests were merged for this release.

[#19497](https://github.com/numpy/numpy/pull/19497): MAINT: set Python version for 1.21.x to`<3.11`
[#19533](https://github.com/numpy/numpy/pull/19533): BUG: Fix an issue wherein importing`numpy.typing`
could raise
[#19646](https://github.com/numpy/numpy/pull/19646): MAINT: Update Cython version for Python 3.10.
[#19648](https://github.com/numpy/numpy/pull/19648): TST: Bump the python 3.10 test version from beta4 to rc1
[#19651](https://github.com/numpy/numpy/pull/19651): TST: avoid distutils.sysconfig in runtests.py
[#19652](https://github.com/numpy/numpy/pull/19652): MAINT: add missing dunder method to nditer type hints
[#19656](https://github.com/numpy/numpy/pull/19656): BLD, SIMD: Fix testing extra checks when`-Werror`
isn’t applicable…
[#19657](https://github.com/numpy/numpy/pull/19657): BUG: Remove logical object ufuncs with bool output
[#19658](https://github.com/numpy/numpy/pull/19658): MAINT: Include .coveragerc in source distributions to support…
[#19659](https://github.com/numpy/numpy/pull/19659): BUG: Fix bad write in masked iterator output copy paths
[#19660](https://github.com/numpy/numpy/pull/19660): ENH: Add support for windows on arm targets
[#19661](https://github.com/numpy/numpy/pull/19661): BUG: add base to templated arguments for platlib
[#19662](https://github.com/numpy/numpy/pull/19662): BUG,DEP: Non-default UFunc signature/dtype usage should be deprecated
[#19666](https://github.com/numpy/numpy/pull/19666): MAINT: Add Python 3.10 to supported versions.
[#19668](https://github.com/numpy/numpy/pull/19668): TST,BUG: Sanitize path-separators when running`runtest.py`
[#19671](https://github.com/numpy/numpy/pull/19671): BLD: load extra flags when checking for libflame
[#19676](https://github.com/numpy/numpy/pull/19676): BLD: update circleCI docker image
[#19677](https://github.com/numpy/numpy/pull/19677): REL: Prepare for 1.21.2 release.# NumPy 1.17.4 Release Notes[#](#numpy-1-17-4-release-notes)
This release contains fixes for bugs reported against NumPy 1.17.3 along with some build improvements. The Python versions supported in this release are 3.5-3.8.

Downstream developers should use Cython >= 0.29.13 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

## Highlights[#](#highlights)
Fixed

biased generation of 8 and 16 bit integers.`random.random_integers`
Fixed

*np.einsum*regression on Power9 and z/Linux.
Fixed histogram problem with signed integer arrays.

## Contributors[#](#contributors)
A total of 5 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Chris Burr +

Matti Picus

Qiming Sun +

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 8 pull requests were merged for this release.

[#14758](https://github.com/numpy/numpy/pull/14758): BLD: declare support for python 3.8
[#14781](https://github.com/numpy/numpy/pull/14781): BUG: random: biased samples from integers() with 8 or 16 bit…
[#14851](https://github.com/numpy/numpy/pull/14851): BUG: Fix _ctypes class circular reference. (#13808)
[#14852](https://github.com/numpy/numpy/pull/14852): BLD: add ‘apt update’ to shippable
[#14855](https://github.com/numpy/numpy/pull/14855): BUG: Fix*np.einsum*errors on Power9 Linux and z/Linux
[#14857](https://github.com/numpy/numpy/pull/14857): BUG: lib: Fix histogram problem with signed integer arrays.
[#14858](https://github.com/numpy/numpy/pull/14858): BLD: Prevent -flto from optimising long double representation…
[#14866](https://github.com/numpy/numpy/pull/14866): MAINT: move buffer.h -> npy_buffer.h to avoid conflicts# NumPy 1.14.5 Release Notes[#](#numpy-1-14-5-release-notes)
This is a bugfix release for bugs reported following the 1.14.4 release. The most significant fixes are:

fixes for compilation errors on alpine and NetBSD

The Python versions supported in this release are 2.7 and 3.4 - 3.6. The Python 3.6 wheels available from PIP are built with Python 3.6.2 and should be compatible with all previous versions of Python 3.6. The source releases were cythonized with Cython 0.28.2 and should work for the upcoming Python 3.7.

## Contributors[#](#contributors)
A total of 1 person contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

## Pull requests merged[#](#pull-requests-merged)
A total of 2 pull requests were merged for this release.# NumPy 1.18.3 Release Notes[#](#numpy-1-18-3-release-notes)
This release contains various bug/regression fixes.

The Python versions supported in this release are 3.5-3.8. Downstream developers should use Cython >= 0.29.15 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

## Highlights[#](#highlights)
Fix for the

*method=’eigh’*and*method=’cholesky’*methods in. Those were producing samples from the wrong distribution.`numpy.random.multivariate_normal`
## Contributors[#](#contributors)
A total of 6 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Max Balandat +

@Mibu287 +

Pan Jan +

Sebastian Berg

@panpiort8 +

## Pull requests merged[#](#pull-requests-merged)
A total of 5 pull requests were merged for this release.

[#15916](https://github.com/numpy/numpy/pull/15916): BUG: Fix eigh and cholesky methods of numpy.random.multivariate_normal
[#15929](https://github.com/numpy/numpy/pull/15929): BUG,MAINT: Remove incorrect special case in string to number…
[#15930](https://github.com/numpy/numpy/pull/15930): BUG: Guarantee array is in valid state after memory error occurs…
[#15954](https://github.com/numpy/numpy/pull/15954): BUG: Check that*pvals*is 1D in*_generator.multinomial*.
[#16017](https://github.com/numpy/numpy/pull/16017): BUG: Alpha parameter must be 1D in*generator.dirichlet*# NumPy 1.23.1 Release Notes[#](#numpy-1-23-1-release-notes)
NumPy 1.23.1 is a maintenance release that fixes bugs discovered after the 1.23.0 release. Notable fixes are:

Fix searchsorted for float16 NaNs

Fix compilation on Apple M1

Fix KeyError in crackfortran operator support (Slycot)

The Python version supported for this release are 3.8-3.10.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Matthias Koeppe +

Pranab Das +

Rohit Goswami

Sebastian Berg

Serge Guelton

Srimukh Sripada +

## Pull requests merged[#](#pull-requests-merged)
A total of 8 pull requests were merged for this release.

[#21866](https://github.com/numpy/numpy/pull/21866): BUG: Fix discovered MachAr (still used within valgrind)
[#21867](https://github.com/numpy/numpy/pull/21867): BUG: Handle NaNs correctly for float16 during sorting
[#21868](https://github.com/numpy/numpy/pull/21868): BUG: Use`keepdims`
during normalization in`np.average`
and…
[#21869](https://github.com/numpy/numpy/pull/21869): DOC: mention changes to`max_rows`
behaviour in`np.loadtxt`
[#21870](https://github.com/numpy/numpy/pull/21870): BUG: Reject non integer array-likes with size 1 in delete
[#21949](https://github.com/numpy/numpy/pull/21949): BLD: Make can_link_svml return False for 32bit builds on x86_64
[#21951](https://github.com/numpy/numpy/pull/21951): BUG: Reorder extern “C” to only apply to function declarations…
[#21952](https://github.com/numpy/numpy/pull/21952): BUG: Fix KeyError in crackfortran operator support# NumPy 1.11.3 Release Notes[#](#numpy-1-11-3-release-notes)
Numpy 1.11.3 fixes a bug that leads to file corruption when very large files
opened in append mode are used in `ndarray.tofile`
. It supports Python
versions 2.6 - 2.7 and 3.2 - 3.5. Wheels for Linux, Windows, and OS X can be
found on PyPI.

## Contributors to maintenance/1.11.3[#](#contributors-to-maintenance-1-11-3)
A total of 2 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Pavel Potocek +# NumPy 1.23.5 Release Notes[#](#numpy-1-23-5-release-notes)
NumPy 1.23.5 is a maintenance release that fixes bugs discovered after the 1.23.4 release and keeps the build infrastructure current. The Python versions supported for this release are 3.8-3.11.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

@DWesl

Aayush Agrawal +

Adam Knapp +

Charles Harris

Navpreet Singh +

Sebastian Berg

Tania Allard

## Pull requests merged[#](#pull-requests-merged)
A total of 10 pull requests were merged for this release.

[#22489](https://github.com/numpy/numpy/pull/22489): TST, MAINT: Replace most setup with setup_method (also teardown)
[#22490](https://github.com/numpy/numpy/pull/22490): MAINT, CI: Switch to[cygwin/cygwin-install-action@v2](/cdn-cgi/l/email-protection#4a29332d3d23246529332d3d2324672324393e2b2626672b293e2325246c69797d716c697f78716c697e72713c78)
[#22494](https://github.com/numpy/numpy/pull/22494): TST: Make test_partial_iteration_cleanup robust but require leak…
[#22592](https://github.com/numpy/numpy/pull/22592): MAINT: Ensure graceful handling of large header sizes
[#22593](https://github.com/numpy/numpy/pull/22593): TYP: Spelling alignment for array flag literal
[#22594](https://github.com/numpy/numpy/pull/22594): BUG: Fix bounds checking for`random.logseries`
[#22595](https://github.com/numpy/numpy/pull/22595): DEV: Update GH actions and Dockerfile for Gitpod
[#22596](https://github.com/numpy/numpy/pull/22596): CI: Only fetch in actions/checkout
[#22597](https://github.com/numpy/numpy/pull/22597): BUG: Decrement ref count in gentype_reduce if allocated memory…
[#22625](https://github.com/numpy/numpy/pull/22625): BUG: Histogramdd breaks on big arrays in Windows# NumPy 1.19.2 Release Notes[#](#numpy-1-19-2-release-notes)
NumPy 1.19.2 fixes several bugs, prepares for the upcoming Cython 3.x release. and pins setuptools to keep distutils working while upstream modifications are ongoing. The aarch64 wheels are built with the latest manylinux2014 release that fixes the problem of differing page sizes used by different linux distros.

This release supports Python 3.6-3.8. Cython >= 0.29.21 needs to be used when building with Python 3.9 for testing purposes.

There is a known problem with Windows 10 version=2004 and OpenBLAS svd that we are trying to debug. If you are running that Windows version you should use a NumPy version that links to the MKL library, earlier Windows versions are fine.

## Improvements[#](#improvements)
### Add NumPy declarations for Cython 3.0 and later[#](#add-numpy-declarations-for-cython-3-0-and-later)
The pxd declarations for Cython 3.0 were improved to avoid using deprecated
NumPy C-API features. Extension modules built with Cython 3.0+ that use NumPy
can now set the C macro `NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION`
to avoid
C compiler warnings about deprecated API usage.

## Contributors[#](#contributors)
A total of 8 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Matti Picus

Pauli Virtanen

Philippe Ombredanne +

Sebastian Berg

Stefan Behnel +

Stephan Loyd +

Zac Hatfield-Dodds

## Pull requests merged[#](#pull-requests-merged)
A total of 9 pull requests were merged for this release.

[#16959](https://github.com/numpy/numpy/pull/16959): TST: Change aarch64 to arm64 in travis.yml.
[#16998](https://github.com/numpy/numpy/pull/16998): MAINT: Configure hypothesis in`np.test()`
for determinism,…
[#17000](https://github.com/numpy/numpy/pull/17000): BLD: pin setuptools < 49.2.0
[#17015](https://github.com/numpy/numpy/pull/17015): ENH: Add NumPy declarations to be used by Cython 3.0+
[#17125](https://github.com/numpy/numpy/pull/17125): BUG: Remove non-threadsafe sigint handling from fft calculation
[#17243](https://github.com/numpy/numpy/pull/17243): BUG: core: fix ilp64 blas dot/vdot/… for strides > int32 max
[#17244](https://github.com/numpy/numpy/pull/17244): DOC: Use SPDX license expressions with correct license
[#17245](https://github.com/numpy/numpy/pull/17245): DOC: Fix the link to the quick-start in the old API functions
[#17272](https://github.com/numpy/numpy/pull/17272): BUG: fix pickling of arrays larger than 2GiB# NumPy 1.18.4 Release Notes[#](#numpy-1-18-4-release-notes)
This is the last planned release in the 1.18.x series. It reverts the
`bool("0")`
behavior introduced in 1.18.3 and fixes a bug in
`Generator.integers`
. There is also a link to a new troubleshooting section
in the documentation included in the error message emitted when numpy import
fails.

The Python versions supported in this release are 3.5-3.8. Downstream developers should use Cython >= 0.29.15 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

## Contributors[#](#contributors)
A total of 4 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Matti Picus

Sebastian Berg

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 6 pull requests were merged for this release.

[#16055](https://github.com/numpy/numpy/pull/16055): BLD: add i686 for 1.18 builds
[#16090](https://github.com/numpy/numpy/pull/16090): BUG: random:`Generator.integers(2**32)`
always returned 0.
[#16091](https://github.com/numpy/numpy/pull/16091): BLD: fix path to libgfortran on macOS
[#16109](https://github.com/numpy/numpy/pull/16109): REV: Reverts side-effect changes to casting
[#16114](https://github.com/numpy/numpy/pull/16114): BLD: put openblas library in local directory on windows
[#16132](https://github.com/numpy/numpy/pull/16132): DOC: Change import error “howto” to link to new troubleshooting…# NumPy 1.12.1 Release Notes[#](#numpy-1-12-1-release-notes)
NumPy 1.12.1 supports Python 2.7 and 3.4 - 3.6 and fixes bugs and regressions found in NumPy 1.12.0. In particular, the regression in f2py constant parsing is fixed. Wheels for Linux, Windows, and OSX can be found on PyPI,

## Bugs Fixed[#](#bugs-fixed)
BUG: Fix wrong future nat warning and equiv type logic error…

BUG: Fix wrong masked median for some special cases

DOC: Place np.average in inline code

TST: Work around isfinite inconsistency on i386

BUG: Guard against replacing constants without ‘_’ spec in f2py.

BUG: Fix mean for float 16 non-array inputs for 1.12

BUG: Fix calling python api with error set and minor leaks for…

BUG: Make iscomplexobj compatible with custom dtypes again

BUG: Fix undefined behaviour induced by bad __array_wrap__

BUG: Fix MaskedArray.__setitem__

BUG: PPC64el machines are POWER for Fortran in f2py

BUG: Look up methods on MaskedArray in

*_frommethod*
BUG: Remove extra digit in binary_repr at limit

BUG: Fix deepcopy regression for empty arrays.

BUG: Fix ma.median for empty ndarrays# NumPy 1.16.5 Release Notes[#](#numpy-1-16-5-release-notes)
The NumPy 1.16.5 release fixes bugs reported against the 1.16.4 release, and also backports several enhancements from master that seem appropriate for a release series that is the last to support Python 2.7. The wheels on PyPI are linked with OpenBLAS v0.3.7-dev, which should fix errors on Skylake series cpus.

Downstream developers building this release should use Cython >= 0.29.2 and, if using OpenBLAS, OpenBLAS >= v0.3.7. The supported Python versions are 2.7 and 3.5-3.7.

## Contributors[#](#contributors)
A total of 18 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Alexander Shadchin

Allan Haldane

Bruce Merry +

Charles Harris

Colin Snyder +

Dan Allan +

Emile +

Eric Wieser

Grey Baker +

Maksim Shabunin +

Marten van Kerkwijk

Matti Picus

Peter Andreas Entschev +

Ralf Gommers

Richard Harris +

Sebastian Berg

Sergei Lebedev +

Stephan Hoyer

## Pull requests merged[#](#pull-requests-merged)
A total of 23 pull requests were merged for this release.

[#13742](https://github.com/numpy/numpy/pull/13742): ENH: Add project URLs to setup.py
[#13823](https://github.com/numpy/numpy/pull/13823): TEST, ENH: fix tests and ctypes code for PyPy
[#13845](https://github.com/numpy/numpy/pull/13845): BUG: use npy_intp instead of int for indexing array
[#13867](https://github.com/numpy/numpy/pull/13867): TST: Ignore DeprecationWarning during nose imports
[#13905](https://github.com/numpy/numpy/pull/13905): BUG: Fix use-after-free in boolean indexing
[#13933](https://github.com/numpy/numpy/pull/13933): MAINT/BUG/DOC: Fix errors in _add_newdocs
[#13984](https://github.com/numpy/numpy/pull/13984): BUG: fix byte order reversal for datetime64[ns]
[#13994](https://github.com/numpy/numpy/pull/13994): MAINT,BUG: Use nbytes to also catch empty descr during allocation
[#14042](https://github.com/numpy/numpy/pull/14042): BUG: np.array cleared errors occurred in PyMemoryView_FromObject
[#14043](https://github.com/numpy/numpy/pull/14043): BUG: Fixes for Undefined Behavior Sanitizer (UBSan) errors.
[#14044](https://github.com/numpy/numpy/pull/14044): BUG: ensure that casting to/from structured is properly checked.
[#14045](https://github.com/numpy/numpy/pull/14045): MAINT: fix histogram*d dispatchers
[#14046](https://github.com/numpy/numpy/pull/14046): BUG: further fixup to histogram2d dispatcher.
[#14052](https://github.com/numpy/numpy/pull/14052): BUG: Replace contextlib.suppress for Python 2.7
[#14056](https://github.com/numpy/numpy/pull/14056): BUG: fix compilation of 3rd party modules with Py_LIMITED_API…
[#14057](https://github.com/numpy/numpy/pull/14057): BUG: Fix memory leak in dtype from dict constructor
[#14058](https://github.com/numpy/numpy/pull/14058): DOC: Document array_function at a higher level.
[#14084](https://github.com/numpy/numpy/pull/14084): BUG, DOC: add new recfunctions to*__all__*
[#14162](https://github.com/numpy/numpy/pull/14162): BUG: Remove stray print that causes a SystemError on python 3.7
[#14297](https://github.com/numpy/numpy/pull/14297): TST: Pin pytest version to 5.0.1.
[#14322](https://github.com/numpy/numpy/pull/14322): ENH: Enable huge pages in all Linux builds
[#14346](https://github.com/numpy/numpy/pull/14346): BUG: fix behavior of structured_to_unstructured on non-trivial…
[#14382](https://github.com/numpy/numpy/pull/14382): REL: Prepare for the NumPy 1.16.5 release.# NumPy 1.10.1 Release Notes[#](#numpy-1-10-1-release-notes)
This release deals with a few build problems that showed up in 1.10.0. Most users would not have seen these problems. The differences are:

Compiling with msvc9 or msvc10 for 32 bit Windows now requires SSE2. This was the easiest fix for what looked to be some miscompiled code when SSE2 was not used. If you need to compile for 32 bit Windows systems without SSE2 support, mingw32 should still work.

Make compiling with VS2008 python2.7 SDK easier

Change Intel compiler options so that code will also be generated to support systems without SSE4.2.

Some _config test functions needed an explicit integer return in order to avoid the openSUSE rpmlinter erring out.

We ran into a problem with pipy not allowing reuse of filenames and a resulting proliferation of

*.*.*.postN releases. Not only were the names getting out of hand, some packages were unable to work with the postN suffix.
Numpy 1.10.1 supports Python 2.6 - 2.7 and 3.2 - 3.5.

Commits:

45a3d84 DEP: Remove warning for *full* when dtype is set.
0c1a5df BLD: import setuptools to allow compile with VS2008 python2.7 sdk
04211c6 BUG: mask nan to 1 in ordered compare
826716f DOC: Document the reason msvc requires SSE2 on 32 bit platforms.
49fa187 BLD: enable SSE2 for 32-bit msvc 9 and 10 compilers
dcbc4cc MAINT: remove Wreturn-type warnings from config checks
d6564cb BLD: do not build exclusively for SSE4.2 processors
15cb66f BLD: do not build exclusively for SSE4.2 processors
c38bc08 DOC: fix var. reference in percentile docstring
78497f4 DOC: Sync 1.10.0-notes.rst in 1.10.x branch with master.# C API for random
Access to various distributions below is available via Cython or C-wrapper
libraries like CFFI. All the functions accept a `bitgen_t`
as their
first argument. To access these from Cython or C, you must link with the
`npyrandom`
static library which is part of the NumPy distribution, located
in `numpy/random/lib`
. Note that you must *also* link with `npymath`
,
see [Linking against the core math library in an extension](../c-api/coremath.html#linking-npymath).

type bitgen_t
-
The `bitgen_t`
holds the current state of the BitGenerator and
pointers to functions that return standard C types while advancing the
state.

struct bitgen:
void *state
npy_uint64 (*next_uint64)(void *st) nogil
uint32_t (*next_uint32)(void *st) nogil
double (*next_double)(void *st) nogil
npy_uint64 (*next_raw)(void *st) nogil
ctypedef bitgen bitgen_t
See [Extending](extending.html) for examples of using these functions.

The functions are named with the following conventions:

“standard” refers to the reference values for any parameters. For instance
“standard_uniform” means a uniform distribution on the interval `0.0`
to
`1.0`

-
“fill” functions will fill the provided `out`
with `cnt`
values.

-
The functions without “standard” in their name require additional parameters
to describe the distributions.

-
Functions with `inv`
in their name are based on the slower inverse method
instead of a ziggurat lookup algorithm, which is significantly faster. The
non-ziggurat variants are used in corner cases and for legacy compatibility.

-
double random_standard_uniform([bitgen_t](#c.bitgen_t) *bitgen_state)
-
void random_standard_uniform_fill([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) cnt, double *out)
-
double random_standard_exponential([bitgen_t](#c.bitgen_t) *bitgen_state)
-
void random_standard_exponential_fill([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) cnt, double *out)
-
void random_standard_exponential_inv_fill([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) cnt, double *out)
-
double random_standard_normal([bitgen_t](#c.bitgen_t) *bitgen_state)
-
void random_standard_normal_fill([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) count, double *out)
-
void random_standard_normal_fill_f([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) count, float *out)
-
double random_standard_gamma([bitgen_t](#c.bitgen_t) *bitgen_state, double shape)
-
float random_standard_uniform_f([bitgen_t](#c.bitgen_t) *bitgen_state)
-
void random_standard_uniform_fill_f([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) cnt, float *out)
-
float random_standard_exponential_f([bitgen_t](#c.bitgen_t) *bitgen_state)
-
void random_standard_exponential_fill_f([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) cnt, float *out)
-
void random_standard_exponential_inv_fill_f([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_intp](../c-api/dtype.html#c.npy_intp) cnt, float *out)
-
float random_standard_normal_f([bitgen_t](#c.bitgen_t) *bitgen_state)
-
float random_standard_gamma_f([bitgen_t](#c.bitgen_t) *bitgen_state, float shape)
-
double random_normal([bitgen_t](#c.bitgen_t) *bitgen_state, double loc, double scale)
-
double random_gamma([bitgen_t](#c.bitgen_t) *bitgen_state, double shape, double scale)
-
float random_gamma_f([bitgen_t](#c.bitgen_t) *bitgen_state, float shape, float scale)
-
double random_exponential([bitgen_t](#c.bitgen_t) *bitgen_state, double scale)
-
double random_uniform([bitgen_t](#c.bitgen_t) *bitgen_state, double lower, double range)
-
double random_beta([bitgen_t](#c.bitgen_t) *bitgen_state, double a, double b)
-
double random_chisquare([bitgen_t](#c.bitgen_t) *bitgen_state, double df)
-
double random_f([bitgen_t](#c.bitgen_t) *bitgen_state, double dfnum, double dfden)
-
double random_standard_cauchy([bitgen_t](#c.bitgen_t) *bitgen_state)
-
double random_pareto([bitgen_t](#c.bitgen_t) *bitgen_state, double a)
-
double random_weibull([bitgen_t](#c.bitgen_t) *bitgen_state, double a)
-
double random_power([bitgen_t](#c.bitgen_t) *bitgen_state, double a)
-
double random_laplace([bitgen_t](#c.bitgen_t) *bitgen_state, double loc, double scale)
-
double random_gumbel([bitgen_t](#c.bitgen_t) *bitgen_state, double loc, double scale)
-
double random_logistic([bitgen_t](#c.bitgen_t) *bitgen_state, double loc, double scale)
-
double random_lognormal([bitgen_t](#c.bitgen_t) *bitgen_state, double mean, double sigma)
-
double random_rayleigh([bitgen_t](#c.bitgen_t) *bitgen_state, double mode)
-
double random_standard_t([bitgen_t](#c.bitgen_t) *bitgen_state, double df)
-
double random_noncentral_chisquare([bitgen_t](#c.bitgen_t) *bitgen_state, double df, double nonc)
-
double random_noncentral_f([bitgen_t](#c.bitgen_t) *bitgen_state, double dfnum, double dfden, double nonc)
-
double random_wald([bitgen_t](#c.bitgen_t) *bitgen_state, double mean, double scale)
-
double random_vonmises([bitgen_t](#c.bitgen_t) *bitgen_state, double mu, double kappa)
-
double random_triangular([bitgen_t](#c.bitgen_t) *bitgen_state, double left, double mode, double right)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_poisson([bitgen_t](#c.bitgen_t) *bitgen_state, double lam)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_negative_binomial([bitgen_t](#c.bitgen_t) *bitgen_state, double n, double p)
-
type binomial_t
-
typedef struct s_binomial_t {
int has_binomial; /* !=0: following parameters initialized for binomial */
double psave;
RAND_INT_TYPE nsave;
double r;
double q;
double fm;
RAND_INT_TYPE m;
double p1;
double xm;
double xl;
double xr;
double c;
double laml;
double lamr;
double p2;
double p3;
double p4;
} binomial_t;
[npy_int64](../c-api/dtype.html#c.npy_int64) random_binomial([bitgen_t](#c.bitgen_t) *bitgen_state, double p, [npy_int64](../c-api/dtype.html#c.npy_int64) n, [binomial_t](#c.binomial_t) *binomial)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_logseries([bitgen_t](#c.bitgen_t) *bitgen_state, double p)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_geometric_search([bitgen_t](#c.bitgen_t) *bitgen_state, double p)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_geometric_inversion([bitgen_t](#c.bitgen_t) *bitgen_state, double p)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_geometric([bitgen_t](#c.bitgen_t) *bitgen_state, double p)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_zipf([bitgen_t](#c.bitgen_t) *bitgen_state, double a)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_hypergeometric([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_int64](../c-api/dtype.html#c.npy_int64) good, [npy_int64](../c-api/dtype.html#c.npy_int64) bad, [npy_int64](../c-api/dtype.html#c.npy_int64) sample)
-
[npy_uint64](../c-api/dtype.html#c.npy_uint64) random_interval([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_uint64](../c-api/dtype.html#c.npy_uint64) max)
-
void random_multinomial([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_int64](../c-api/dtype.html#c.npy_int64) n, [npy_int64](../c-api/dtype.html#c.npy_int64) *mnix, double *pix, [npy_intp](../c-api/dtype.html#c.npy_intp) d, [binomial_t](#c.binomial_t) *binomial)
-
int random_multivariate_hypergeometric_count([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_int64](../c-api/dtype.html#c.npy_int64) total, size_t num_colors, [npy_int64](../c-api/dtype.html#c.npy_int64) *colors, [npy_int64](../c-api/dtype.html#c.npy_int64) nsample, size_t num_variates, [npy_int64](../c-api/dtype.html#c.npy_int64) *variates)
-
void random_multivariate_hypergeometric_marginals([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_int64](../c-api/dtype.html#c.npy_int64) total, size_t num_colors, [npy_int64](../c-api/dtype.html#c.npy_int64) *colors, [npy_int64](../c-api/dtype.html#c.npy_int64) nsample, size_t num_variates, [npy_int64](../c-api/dtype.html#c.npy_int64) *variates)
-
Generate a single integer

[npy_int64](../c-api/dtype.html#c.npy_int64) random_positive_int64([bitgen_t](#c.bitgen_t) *bitgen_state)
-
[npy_int32](../c-api/dtype.html#c.npy_int32) random_positive_int32([bitgen_t](#c.bitgen_t) *bitgen_state)
-
[npy_int64](../c-api/dtype.html#c.npy_int64) random_positive_int([bitgen_t](#c.bitgen_t) *bitgen_state)
-
[npy_uint64](../c-api/dtype.html#c.npy_uint64) random_uint([bitgen_t](#c.bitgen_t) *bitgen_state)
-
Generate random uint64 numbers in closed interval [off, off + rng].

[npy_uint64](../c-api/dtype.html#c.npy_uint64) random_bounded_uint64([bitgen_t](#c.bitgen_t) *bitgen_state, [npy_uint64](../c-api/dtype.html#c.npy_uint64) off, [npy_uint64](../c-api/dtype.html#c.npy_uint64) rng, [npy_uint64](../c-api/dtype.html#c.npy_uint64) mask, bool use_masked)
-# numpy.memmap.view[#](#numpy-memmap-view)
method

memmap.view(*[dtype][, type]*)[#](#numpy.memmap.view)
-
New view of array with the same data.

Note

Passing None for

`dtype`
is different from omitting the parameter, since the former invokes`dtype(None)`
which is an alias for`dtype('float_')`
.Parameters:
-
**dtype**data-type or ndarray sub-class, optional
Data-type descriptor of the returned view, e.g., float32 or int16. Omitting it results in the view having the same data-type as

*a*. This argument can also be specified as an ndarray sub-class, which then specifies the type of the returned object (this is equivalent to setting the`type`
parameter).
**type**Python type, optional
Type of the returned view, e.g., ndarray or matrix. Again, omission of the parameter results in type preservation.

Notes

`a.view()`
is used two different ways:`a.view(some_dtype)`
or`a.view(dtype=some_dtype)`
constructs a view of the array’s memory with a different data-type. This can cause a reinterpretation of the bytes of memory.`a.view(ndarray_subclass)`
or`a.view(type=ndarray_subclass)`
just returns an instance of*ndarray_subclass*that looks at the same array (same shape, dtype, etc.) This does not cause a reinterpretation of the memory.For

`a.view(some_dtype)`
, if`some_dtype`
has a different number of bytes per entry than the previous dtype (for example, converting a regular array to a structured array), then the last axis of`a`
must be contiguous. This axis will be resized in the result.Changed in version 1.23.0: Only the last axis needs to be contiguous. Previously, the entire array had to be C-contiguous.

Examples

>>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])
Viewing array data using a different type and dtype:

>>> y = x.view(dtype=np.int16, type=np.matrix) >>> y matrix([[513]], dtype=int16) >>> print(type(y)) <class 'numpy.matrix'>
Creating a view on a structured array so it can be used in calculations

>>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)]) >>> xv = x.view(dtype=np.int8).reshape(-1,2) >>> xv array([[1, 2], [3, 4]], dtype=int8) >>> xv.mean(0) array([2., 3.])
Making changes to the view changes the underlying array

>>> xv[0,1] = 20 >>> x array([(1, 20), (3, 4)], dtype=[('a', 'i1'), ('b', 'i1')])
Using a view to convert an array to a recarray:

>>> z = x.view(np.recarray) >>> z.a array([1, 3], dtype=int8)
Views share data:

>>> x[0] = (9, 10) >>> z[0] (9, 10)
Views that change the dtype size (bytes per entry) should normally be avoided on arrays defined by slices, transposes, fortran-ordering, etc.:

>>> x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int16) >>> y = x[:, ::2] >>> y array([[1, 3], [4, 6]], dtype=int16) >>> y.view(dtype=[('width', np.int16), ('length', np.int16)]) Traceback (most recent call last): ... ValueError: To change to a dtype of a different size, the last axis must be contiguous >>> z = y.copy() >>> z.view(dtype=[('width', np.int16), ('length', np.int16)]) array([[(1, 3)], [(4, 6)]], dtype=[('width', '<i2'), ('length', '<i2')])
However, views that change dtype are totally fine for arrays with a contiguous last axis, even if the rest of the axes are not C-contiguous:

>>> x = np.arange(2 * 3 * 4, dtype=np.int8).reshape(2, 3, 4) >>> x.transpose(1, 0, 2).view(np.int16) array([[[ 256, 770], [3340, 3854]], [[1284, 1798], [4368, 4882]], [[2312, 2826], [5396, 5910]]], dtype=int16)# numpy.linalg.pinv[#](#numpy-linalg-pinv)
linalg.pinv(*a*,*rcond=1e-15*,*hermitian=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L1936-L2031)[#](#numpy.linalg.pinv)
-
Compute the (Moore-Penrose) pseudo-inverse of a matrix.

Calculate the generalized inverse of a matrix using its singular-value decomposition (SVD) and including all

*large*singular values.Changed in version 1.14: Can now operate on stacks of matrices

Parameters:
-
**a**(…, M, N) array_like
Matrix or stack of matrices to be pseudo-inverted.

**rcond**(…) array_like of float
Cutoff for small singular values. Singular values less than or equal to

`rcond * largest_singular_value`
are set to zero. Broadcasts against the stack of matrices.
**hermitian**bool, optional
If True,

*a*is assumed to be Hermitian (symmetric if real-valued), enabling a more efficient method for finding singular values. Defaults to False.New in version 1.17.0.

Returns:
-
**B**(…, N, M) ndarray
The pseudo-inverse of

*a*. If*a*is ainstance, then so is`matrix`
*B*.
Raises:
-
LinAlgError
-
If the SVD computation does not converge.

See also

`scipy.linalg.pinv`
Similar function in SciPy.

`scipy.linalg.pinvh`
Compute the (Moore-Penrose) pseudo-inverse of a Hermitian matrix.

Notes

The pseudo-inverse of a matrix A, denoted \(A^+\), is defined as: “the matrix that ‘solves’ [the least-squares problem] \(Ax = b\),” i.e., if \(\bar{x}\) is said solution, then \(A^+\) is that matrix such that \(\bar{x} = A^+b\).

It can be shown that if \(Q_1 \Sigma Q_2^T = A\) is the singular value decomposition of A, then \(A^+ = Q_2 \Sigma^+ Q_1^T\), where \(Q_{1,2}\) are orthogonal matrices, \(\Sigma\) is a diagonal matrix consisting of A’s so-called singular values, (followed, typically, by zeros), and then \(\Sigma^+\) is simply the diagonal matrix consisting of the reciprocals of A’s singular values (again, followed by zeros).

[[1]](#rec505eafac9d-1)References

[[1](#id1)]G. Strang,

*Linear Algebra and Its Applications*, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pp. 139-142.Examples

The following example checks that

`a * a+ * a == a`
and`a+ * a * a+ == a+`
:>>> a = np.random.randn(9, 6) >>> B = np.linalg.pinv(a) >>> np.allclose(a, np.dot(a, np.dot(B, a))) True >>> np.allclose(B, np.dot(B, np.dot(a, B))) True# numpy.cbrt[#](#numpy-cbrt)
numpy.cbrt(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'cbrt'>*[#](#numpy.cbrt)
-
Return the cube-root of an array, element-wise.

New in version 1.10.0.

Parameters:
-
**x**array_like
The values whose cube-roots are required.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray
An array of the same shape as

*x*, containing the cube cube-root of each element in*x*. If*out*was provided,*y*is a reference to it. This is a scalar if*x*is a scalar.
Examples

>>> np.cbrt([1,8,27]) array([ 1., 2., 3.])# numpy.polynomial.polyutils.trimcoef[#](#numpy-polynomial-polyutils-trimcoef)
polynomial.polyutils.trimcoef(*c*,*tol=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polyutils.py#L160-L212)[#](#numpy.polynomial.polyutils.trimcoef)
-
Remove “small” “trailing” coefficients from a polynomial.

“Small” means “small in absolute value” and is controlled by the parameter

*tol*; “trailing” means highest order coefficient(s), e.g., in`[0, 1, 1, 0, 0]`
(which represents`0 + x + x**2 + 0*x**3 + 0*x**4`
) both the 3-rd and 4-th order coefficients would be “trimmed.”Parameters:
-
**c**array_like
1-d array of coefficients, ordered from lowest order to highest.

**tol**number, optional
Trailing (i.e., highest order) elements with absolute value less than or equal to

*tol*(default value is zero) are removed.
Returns:
-
**trimmed**ndarray
1-d array with trailing zeros removed. If the resulting series would be empty, a series containing a single zero is returned.

Raises:
-
ValueError
-
If

*tol*< 0
See also

Examples

>>> from numpy.polynomial import polyutils as pu >>> pu.trimcoef((0,0,3,0,5,0,0)) array([0., 0., 3., 0., 5.]) >>> pu.trimcoef((0,0,1e-3,0,1e-5,0,0),1e-3) # item == tol is trimmed array([0.]) >>> i = complex(0,1) # works for complex >>> pu.trimcoef((3e-4,1e-3*(1-i),5e-4,2e-5*(1+i)), 1e-3) array([0.0003+0.j , 0.001 -0.001j])numpy.polynomial.legendre.Legendre.has_samewindow# method polynomial.legendre.Legendre.has_samewindow(other)[source]# Check if windows match. New in version 1.6.0. Parameters: otherclass instanceThe other class must have the window attribute. Returns: boolbooleanTrue if the windows are the same, False otherwise.# numpy.polynomial.legendre.legx[#](#numpy-polynomial-legendre-legx)
polynomial.legendre.legx*= array([0, 1])*[#](#numpy.polynomial.legendre.legx)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.polynomial.chebyshev.poly2cheb[#](#numpy-polynomial-chebyshev-poly2cheb)
polynomial.chebyshev.poly2cheb(*pol*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L347-L394)[#](#numpy.polynomial.chebyshev.poly2cheb)
-
Convert a polynomial to a Chebyshev series.

Convert an array representing the coefficients of a polynomial (relative to the “standard” basis) ordered from lowest degree to highest, to an array of the coefficients of the equivalent Chebyshev series, ordered from lowest to highest degree.

Parameters:
-
**pol**array_like
1-D array containing the polynomial coefficients

Returns:
-
**c**ndarray
1-D array containing the coefficients of the equivalent Chebyshev series.

See also

Notes

The easy way to do conversions between polynomial basis sets is to use the convert method of a class instance.

Examples

>>> from numpy import polynomial as P >>> p = P.Polynomial(range(4)) >>> p Polynomial([0., 1., 2., 3.], domain=[-1, 1], window=[-1, 1]) >>> c = p.convert(kind=P.Chebyshev) >>> c Chebyshev([1. , 3.25, 1. , 0.75], domain=[-1., 1.], window=[-1., 1.]) >>> P.chebyshev.poly2cheb(range(4)) array([1. , 3.25, 1. , 0.75])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
random.SeedSequence.entropy
numpy.random.SeedSequence.entropy
#
attribute
random.SeedSequence.
entropy
#numpy.distutils.system_info.get_info# distutils.system_info.get_info(name, notfound_action=0)[source]# notfound_action:0 - do nothing 1 - display warning message 2 - raise error# numpy.flatnonzero[#](#numpy-flatnonzero)
numpy.flatnonzero(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L615-L653)[#](#numpy.flatnonzero)
-
Return indices that are non-zero in the flattened version of a.

This is equivalent to

`np.nonzero(np.ravel(a))[0]`
.Parameters:
-
**a**array_like
Input data.

Returns:
-
**res**ndarray
Output array, containing the indices of the elements of

`a.ravel()`
that are non-zero.
See also

Examples

>>> x = np.arange(-2, 3) >>> x array([-2, -1, 0, 1, 2]) >>> np.flatnonzero(x) array([0, 1, 3, 4])
Use the indices of the non-zero elements as an index array to extract these elements:

>>> x.ravel()[np.flatnonzero(x)] array([-2, -1, 1, 2])# numpy.ma.ediff1d[#](#numpy-ma-ediff1d)
ma.ediff1d(*arr*,*to_end=None*,*to_begin=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L1151-L1177)[#](#numpy.ma.ediff1d)
-
Compute the differences between consecutive elements of an array.

This function is the equivalent of

that takes masked values into account, see`numpy.ediff1d`
for details.`numpy.ediff1d`
See also

`numpy.ediff1d`
Equivalent function for ndarrays.# numpy.ma.MaskedArray.cumsum[#](#numpy-ma-maskedarray-cumsum)
method

ma.MaskedArray.cumsum(*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5192-L5231)[#](#numpy.ma.MaskedArray.cumsum)
-
Return the cumulative sum of the array elements over the given axis.

Masked values are set to 0 internally during the computation. However, their position is saved, and the result will be masked at the same locations.

Refer to

for full documentation.`numpy.cumsum`
See also

`numpy.ndarray.cumsum`
corresponding function for ndarrays

`numpy.cumsum`
equivalent function

Notes

The mask is lost if

*out*is not a valid!`ma.MaskedArray`
Arithmetic is modular when using integer types, and no error is raised on overflow.

Examples

>>> marr = np.ma.array(np.arange(10), mask=[0,0,0,1,1,1,0,0,0,0]) >>> marr.cumsum() masked_array(data=[0, 1, 3, --, --, --, 9, 16, 24, 33], mask=[False, False, False, True, True, True, False, False, False, False], fill_value=999999)# numpy.put_along_axis[#](#numpy-put-along-axis)
numpy.put_along_axis(*arr*,*indices*,*values*,*axis*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L177-L260)[#](#numpy.put_along_axis)
-
Put values into the destination array by matching 1d index and data slices.

This iterates over matching 1d slices oriented along the specified axis in the index and data arrays, and uses the former to place values into the latter. These slices can be different lengths.

Functions returning an index along an axis, like

and`argsort`
, produce suitable indices for this function.`argpartition`
New in version 1.15.0.

Parameters:
-
**arr**ndarray (Ni…, M, Nk…)
Destination array.

**indices**ndarray (Ni…, J, Nk…)
Indices to change along each 1d slice of

*arr*. This must match the dimension of arr, but dimensions in Ni and Nj may be 1 to broadcast against*arr*.
**values**array_like (Ni…, J, Nk…)
values to insert at those indices. Its shape and dimension are broadcast to match that of

.`indices`
**axis**int
The axis to take 1d slices along. If axis is None, the destination array is treated as if a flattened 1d view had been created of it.

See also

`take_along_axis`
Take values from the input array by matching 1d index and data slices

Notes

This is equivalent to (but faster than) the following use of

and`ndindex`
, which sets each of`s_`
`ii`
and`kk`
to a tuple of indices:Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:] J = indices.shape[axis] # Need not equal M for ii in ndindex(Ni): for kk in ndindex(Nk): a_1d = a [ii + s_[:,] + kk] indices_1d = indices[ii + s_[:,] + kk] values_1d = values [ii + s_[:,] + kk] for j in range(J): a_1d[indices_1d[j]] = values_1d[j]
Equivalently, eliminating the inner loop, the last two lines would be:

a_1d[indices_1d] = values_1d
Examples

For this sample array

>>> a = np.array([[10, 30, 20], [60, 40, 50]])
We can replace the maximum values with:

>>> ai = np.argmax(a, axis=1, keepdims=True) >>> ai array([[1], [0]]) >>> np.put_along_axis(a, ai, 99, axis=1) >>> a array([[10, 99, 20], [99, 40, 50]])numpy.ma.MaskedArray.__setitem__# method ma.MaskedArray.__setitem__(indx, value)[source]# x.__setitem__(i, y) <==> x[i]=y Set item described by index. If value is masked, masks those locations.numpy.busdaycalendar.weekmask# attribute busdaycalendar.weekmask# A copy of the seven-element boolean mask indicating valid days.# numpy.matrix.itemset[#](#numpy-matrix-itemset)
method

matrix.itemset(**args*)[#](#numpy.matrix.itemset)
-
Insert scalar into an array (scalar is cast to array’s dtype, if possible)

There must be at least 1 argument, and define the last argument as

*item*. Then,`a.itemset(*args)`
is equivalent to but faster than`a[args] = item`
. The item should be a scalar value and*args*must select a single item in the array*a*.Parameters:
-
***args**Arguments
If one argument: a scalar, only used in case

*a*is of size 1. If two arguments: the last argument is the value to be set and must be a scalar, the first argument specifies a single array element location. It is either an int or a tuple.
Notes

Compared to indexing syntax,

provides some speed increase for placing a scalar into a particular location in an`itemset`
, if you must do this. However, generally this is discouraged: among other problems, it complicates the appearance of the code. Also, when using`ndarray`
(and`itemset`
) inside a loop, be sure to assign the methods to a local variable to avoid the attribute look-up at each loop iteration.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.itemset(4, 0) >>> x.itemset((2, 2), 9) >>> x array([[2, 2, 6], [1, 0, 6], [1, 0, 9]])ufunc

numpy.ctypeslib

numpy.fft

numpy.linalg

numpy.matlib

numpy.random

numpy.testing

numpy.testing.overrides

numpy.typing

numpy.distutils

masked_array

alias of MaskedArray

MaskedArray# numpy.polynomial.hermite.herm2poly[#](#numpy-polynomial-hermite-herm2poly)
polynomial.hermite.herm2poly(*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L142-L197)[#](#numpy.polynomial.hermite.herm2poly)
-
Convert a Hermite series to a polynomial.

Convert an array representing the coefficients of a Hermite series, ordered from lowest degree to highest, to an array of the coefficients of the equivalent polynomial (relative to the “standard” basis) ordered from lowest to highest degree.

Parameters:
-
**c**array_like
1-D array containing the Hermite series coefficients, ordered from lowest order term to highest.

Returns:
-
**pol**ndarray
1-D array containing the coefficients of the equivalent polynomial (relative to the “standard” basis) ordered from lowest order term to highest.

See also

Notes

The easy way to do conversions between polynomial basis sets is to use the convert method of a class instance.

Examples

>>> from numpy.polynomial.hermite import herm2poly >>> herm2poly([ 1. , 2.75 , 0.5 , 0.375]) array([0., 1., 2., 3.])numpy.char.chararray.any# method char.chararray.any(axis=None, out=None, keepdims=False, *, where=True)# Returns True if any of the elements of a evaluate to True. Refer to numpy.any for full documentation. See also numpy.anyequivalent function# numpy.recarray.round[#](#numpy-recarray-round)
method

recarray.round(*decimals=0*,*out=None*)[#](#numpy.recarray.round)
-
Return

*a*with each element rounded to the given number of decimals.Refer to

for full documentation.`numpy.around`
See also

`numpy.around`
equivalent function

method

Return *a* with each element rounded to the given number of decimals.

Refer to [ numpy.around](numpy.around.html#numpy.around) for full documentation.

See also

`numpy.around`
equivalent functionnumpy.distutils.ccompiler_opt.CCompilerOpt.dist_log# method static distutils.ccompiler_opt.CCompilerOpt.dist_log(*args, stderr=False)[source]# Print a console messagenumpy.distutils.ccompiler.new_compiler# distutils.ccompiler.new_compiler(plat=None, compiler=None, verbose=None, dry_run=0, force=0)[source]## numpy.lib.format.descr_to_dtype[#](#numpy-lib-format-descr-to-dtype)
lib.format.descr_to_dtype(*descr*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/format.py#L282-L336)[#](#numpy.lib.format.descr_to_dtype)
-
Returns a dtype based off the given description.

This is essentially the reverse of

*dtype_to_descr()*. It will remove the valueless padding fields created by, i.e. simple fields like dtype(‘float32’), and then convert the description to its corresponding dtype.Parameters:
-
**descr**object
The object retrieved by dtype.descr. Can be passed to

*numpy.dtype()*in order to replicate the input dtype.
Returns:
-
**dtype**dtype
The dtype constructed by the description.# numpy.linalg.eigvalsh[#](#numpy-linalg-eigvalsh)
linalg.eigvalsh(*a*,*UPLO='L'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L1090-L1182)[#](#numpy.linalg.eigvalsh)
-
Compute the eigenvalues of a complex Hermitian or real symmetric matrix.

Main difference from eigh: the eigenvectors are not computed.

Parameters:
-
**a**(…, M, M) array_like
A complex- or real-valued matrix whose eigenvalues are to be computed.

**UPLO**{‘L’, ‘U’}, optional
Specifies whether the calculation is done with the lower triangular part of

*a*(‘L’, default) or the upper triangular part (‘U’). Irrespective of this value only the real parts of the diagonal will be considered in the computation to preserve the notion of a Hermitian matrix. It therefore follows that the imaginary part of the diagonal will always be treated as zero.
Returns:
-
**w**(…, M,) ndarray
The eigenvalues in ascending order, each repeated according to its multiplicity.

Raises:
-
LinAlgError
-
If the eigenvalue computation does not converge.

See also

`eigh`
eigenvalues and eigenvectors of real symmetric or complex Hermitian (conjugate symmetric) arrays.

`eigvals`
eigenvalues of general real or complex arrays.

`eig`
eigenvalues and right eigenvectors of general real or complex arrays.

`scipy.linalg.eigvalsh`
Similar function in SciPy.

Notes

New in version 1.8.0.

Broadcasting rules apply, see the

documentation for details.`numpy.linalg`
The eigenvalues are computed using LAPACK routines

`_syevd`
,`_heevd`
.Examples

>>> from numpy import linalg as LA >>> a = np.array([[1, -2j], [2j, 5]]) >>> LA.eigvalsh(a) array([ 0.17157288, 5.82842712]) # may vary
>>> # demonstrate the treatment of the imaginary part of the diagonal >>> a = np.array([[5+2j, 9-2j], [0+2j, 2-1j]]) >>> a array([[5.+2.j, 9.-2.j], [0.+2.j, 2.-1.j]]) >>> # with UPLO='L' this is numerically equivalent to using LA.eigvals() >>> # with: >>> b = np.array([[5.+0.j, 0.-2.j], [0.+2.j, 2.-0.j]]) >>> b array([[5.+0.j, 0.-2.j], [0.+2.j, 2.+0.j]]) >>> wa = LA.eigvalsh(a) >>> wb = LA.eigvals(b) >>> wa; wb array([1., 6.]) array([6.+0.j, 1.+0.j])# numpy.polynomial.polyutils.mapparms[#](#numpy-polynomial-polyutils-mapparms)
polynomial.polyutils.mapparms(*old*,*new*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polyutils.py#L260-L305)[#](#numpy.polynomial.polyutils.mapparms)
-
Linear map parameters between domains.

Return the parameters of the linear map

`offset + scale*x`
that maps*old*to*new*such that`old[i] -> new[i]`
,`i = 0, 1`
.Parameters:
-
**old, new**array_like
Domains. Each domain must (successfully) convert to a 1-d array containing precisely two values.

Returns:
-
**offset, scale**scalars
The map

`L(x) = offset + scale*x`
maps the first domain to the second.
Notes

Also works for complex numbers, and thus can be used to calculate the parameters required to map any line in the complex plane to any other line therein.

Examples

>>> from numpy.polynomial import polyutils as pu >>> pu.mapparms((-1,1),(-1,1)) (0.0, 1.0) >>> pu.mapparms((1,-1),(-1,1)) (-0.0, -1.0) >>> i = complex(0,1) >>> pu.mapparms((-i,-1),(1,i)) ((1+1j), (1-0j))numpy.ndarray.data# attribute ndarray.data# Python buffer object pointing to the start of the array’s data.numpy.distutils.ccompiler_opt.CCompilerOpt.feature_test# method distutils.ccompiler_opt.CCompilerOpt.feature_test(*args, **kwargs)[source]#numpy.ma.MaskedArray.flat# property property ma.MaskedArray.flat# Return a flat iterator, or set a flattened version of self to value.# numpy.char.chararray[#](#numpy-char-chararray)
*class*numpy.char.chararray(*shape*,*itemsize=1*,*unicode=False*,*buffer=None*,*offset=0*,*strides=None*,*order=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/__init__.py)[#](#numpy.char.chararray)
-
Provides a convenient view on arrays of string and unicode values.

Note

The

class exists for backwards compatibility with Numarray, it is not recommended for new development. Starting from numpy 1.4, if one needs arrays of strings, it is recommended to use arrays of`chararray`
`dtype`
`object_`
,`bytes_`
or`str_`
, and use the free functions in themodule for fast vectorized string operations.`numpy.char`
Versus a regular NumPy array of type

*str*or*unicode*, this class adds the following functionality:values automatically have whitespace removed from the end when indexed

comparison operators automatically remove whitespace from the end when comparing values

vectorized string operations are provided as methods (e.g.

) and infix operators (e.g.`endswith`
`"+", "*", "%"`
)
chararrays should be created using

or`numpy.char.array`
, rather than this constructor directly.`numpy.char.asarray`
This constructor creates the array, using

*buffer*(with*offset*and) if it is not`strides`
`None`
. If*buffer*is`None`
, then constructs a new array within “C order”, unless both`strides`
`len(shape) >= 2`
and`order='F'`
, in which caseis in “Fortran order”.`strides`
Parameters:
-
**shape**tuple
Shape of the array.

**itemsize**int, optional
Length of each array element, in number of characters. Default is 1.

**unicode**bool, optional
Are the array elements of type unicode (True) or string (False). Default is False.

**buffer**object exposing the buffer interface or str, optional
Memory address of the start of the array data. Default is None, in which case a new array is created.

**offset**int, optional
Fixed stride displacement from the beginning of an axis? Default is 0. Needs to be >=0.

**strides**array_like of ints, optional
Strides for the array (see

`ndarray.strides`
for full description). Default is None.
**order**{‘C’, ‘F’}, optional
The order in which the array data is stored in memory: ‘C’ -> “row major” order (the default), ‘F’ -> “column major” (Fortran) order.

Examples

>>> charar = np.chararray((3, 3)) >>> charar[:] = 'a' >>> charar chararray([[b'a', b'a', b'a'], [b'a', b'a', b'a'], [b'a', b'a', b'a']], dtype='|S1')
>>> charar = np.chararray(charar.shape, itemsize=5) >>> charar[:] = 'abc' >>> charar chararray([[b'abc', b'abc', b'abc'], [b'abc', b'abc', b'abc'], [b'abc', b'abc', b'abc']], dtype='|S5')
Attributes:
-
`T`
View of the transposed array.

`base`
Base object if memory is from some other object.

`ctypes`
An object to simplify the interaction of the array with the ctypes module.

`data`
Python buffer object pointing to the start of the array’s data.

`dtype`
Data-type of the array’s elements.

`flags`
Information about the memory layout of the array.

`flat`
A 1-D iterator over the array.

`imag`
The imaginary part of the array.

`itemsize`
Length of one array element in bytes.

`nbytes`
Total bytes consumed by the elements of the array.

`ndim`
Number of array dimensions.

`real`
The real part of the array.

`shape`
Tuple of array dimensions.

`size`
Number of elements in the array.

`strides`
Tuple of bytes to step in each dimension when traversing an array.

Methods

(dtype[, order, casting, subok, copy])`astype`
Copy of the array, cast to a specified type.

([axis, kind, order])`argsort`
Returns the indices that would sort this array.

([order])`copy`
Return a copy of the array.

(sub[, start, end])`count`
Returns an array with the number of non-overlapping occurrences of substring

*sub*in the range [*start*,*end*].([encoding, errors])`decode`
Calls

`bytes.decode`
element-wise.(file)`dump`
Dump a pickle of the array to the specified file.

()`dumps`
Returns the pickle of the array as a string.

([encoding, errors])`encode`
Calls

*str.encode*element-wise.(suffix[, start, end])`endswith`
Returns a boolean array which is

*True*where the string element in*self*ends with*suffix*, otherwise*False*.([tabsize])`expandtabs`
Return a copy of each string element where all tab characters are replaced by one or more spaces.

(value)`fill`
Fill the array with a scalar value.

(sub[, start, end])`find`
For each element, return the lowest index in the string where substring

*sub*is found.([order])`flatten`
Return a copy of the array collapsed into one dimension.

(dtype[, offset])`getfield`
Returns a field of the given array as a certain type.

(sub[, start, end])`index`
Like

, but raises`find`
*ValueError*when the substring is not found.()`isalnum`
Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.

()`isalpha`
Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise.

For each element in

*self*, return True if there are only decimal characters in the element.()`isdigit`
Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.

()`islower`
Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise.

For each element in

*self*, return True if there are only numeric characters in the element.()`isspace`
Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise.

()`istitle`
Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise.

()`isupper`
Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise.

(*args)`item`
Copy an element of an array to a standard Python scalar and return it.

(seq)`join`
Return a string which is the concatenation of the strings in the sequence

*seq*.(width[, fillchar])`ljust`
Return an array with the elements of

*self*left-justified in a string of length*width*.()`lower`
Return an array with the elements of

*self*converted to lowercase.([chars])`lstrip`
For each element in

*self*, return a copy with the leading characters removed.()`nonzero`
Return the indices of the elements that are non-zero.

(indices, values[, mode])`put`
Set

`a.flat[n] = values[n]`
for all*n*in indices.([order])`ravel`
Return a flattened array.

(repeats[, axis])`repeat`
Repeat elements of an array.

(old, new[, count])`replace`
For each element in

*self*, return a copy of the string with all occurrences of substring*old*replaced by*new*.(shape[, order])`reshape`
Returns an array containing the same data with a new shape.

(new_shape[, refcheck])`resize`
Change shape and size of array in-place.

(sub[, start, end])`rfind`
For each element in

*self*, return the highest index in the string where substring*sub*is found, such that*sub*is contained within [*start*,*end*].(sub[, start, end])`rindex`
Like

, but raises`rfind`
*ValueError*when the substring*sub*is not found.(width[, fillchar])`rjust`
Return an array with the elements of

*self*right-justified in a string of length*width*.([sep, maxsplit])`rsplit`
For each element in

*self*, return a list of the words in the string, using*sep*as the delimiter string.([chars])`rstrip`
For each element in

*self*, return a copy with the trailing characters removed.(v[, side, sorter])`searchsorted`
Find indices where elements of v should be inserted in a to maintain order.

(val, dtype[, offset])`setfield`
Put a value into a specified place in a field defined by a data-type.

([write, align, uic])`setflags`
Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY, respectively.

([axis, kind, order])`sort`
Sort an array in-place.

([sep, maxsplit])`split`
For each element in

*self*, return a list of the words in the string, using*sep*as the delimiter string.([keepends])`splitlines`
For each element in

*self*, return a list of the lines in the element, breaking at line boundaries.([axis])`squeeze`
Remove axes of length one from

*a*.(prefix[, start, end])`startswith`
Returns a boolean array which is

*True*where the string element in*self*starts with*prefix*, otherwise*False*.([chars])`strip`
For each element in

*self*, return a copy with the leading and trailing characters removed.(axis1, axis2)`swapaxes`
Return a view of the array with

*axis1*and*axis2*interchanged.()`swapcase`
For each element in

*self*, return a copy of the string with uppercase characters converted to lowercase and vice versa.(indices[, axis, out, mode])`take`
Return an array formed from the elements of

*a*at the given indices.()`title`
For each element in

*self*, return a titlecased version of the string: words start with uppercase characters, all remaining cased characters are lowercase.(fid[, sep, format])`tofile`
Write array to a file as text or binary (default).

()`tolist`
Return the array as an

`a.ndim`
-levels deep nested list of Python scalars.([order])`tostring`
A compatibility alias for

, with exactly the same behavior.`tobytes`
(table[, deletechars])`translate`
For each element in

*self*, return a copy of the string where all characters occurring in the optional argument*deletechars*are removed, and the remaining characters have been mapped through the given translation table.(*axes)`transpose`
Returns a view of the array with axes transposed.

()`upper`
Return an array with the elements of

*self*converted to uppercase.([dtype][, type])`view`
New view of array with the same data.

(width)`zfill`
Return the numeric string left-filled with zeros in a string of length

*width*.# numpy.char.chararray.min[#](#numpy-char-chararray-min)
method

char.chararray.min(*axis=None*,*out=None*,*keepdims=False*,*initial=<no value>*,*where=True*)[#](#numpy.char.chararray.min)
-
Return the minimum along a given axis.

Refer to

for full documentation.`numpy.amin`
See also

`numpy.amin`
equivalent function# numpy.random.Generator.shuffle[#](#numpy-random-generator-shuffle)
method

random.Generator.shuffle(*x*,*axis=0*)[#](#numpy.random.Generator.shuffle)
-
Modify an array or sequence in-place by shuffling its contents.

The order of sub-arrays is changed but their contents remains the same.

Parameters:
-
**x**ndarray or MutableSequence
The array, list or mutable sequence to be shuffled.

**axis**int, optional
The axis which

*x*is shuffled along. Default is 0. It is only supported onobjects.`ndarray`
Returns:
-
None
-
See also

Notes

An important distinction between methods

`shuffle`
and`permuted`
is how they both treat the`axis`
parameter which can be found at[Handling the axis parameter](../generator.html#generator-handling-axis-parameter).Examples

>>> rng = np.random.default_rng() >>> arr = np.arange(10) >>> arr array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) >>> rng.shuffle(arr) >>> arr array([2, 0, 7, 5, 1, 4, 8, 9, 3, 6]) # random
>>> arr = np.arange(9).reshape((3, 3)) >>> arr array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) >>> rng.shuffle(arr) >>> arr array([[3, 4, 5], # random [6, 7, 8], [0, 1, 2]])
>>> arr = np.arange(9).reshape((3, 3)) >>> arr array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) >>> rng.shuffle(arr, axis=1) >>> arr array([[2, 0, 1], # random [5, 3, 4], [8, 6, 7]])numpy.broadcast.size# attribute broadcast.size# Total size of broadcasted result. Examples >>> x = np.array([1, 2, 3]) >>> y = np.array([[4], [5], [6]]) >>> b = np.broadcast(x, y) >>> b.size 9numpy.broadcast.numiter# attribute broadcast.numiter# Number of iterators possessed by the broadcasted result. Examples >>> x = np.array([1, 2, 3]) >>> y = np.array([[4], [5], [6]]) >>> b = np.broadcast(x, y) >>> b.numiter 2# numpy.random.RandomState.random_sample[#](#numpy-random-randomstate-random-sample)
method

random.RandomState.random_sample(*size=None*)[#](#numpy.random.RandomState.random_sample)
-
Return random floats in the half-open interval [0.0, 1.0).

Results are from the “continuous uniform” distribution over the stated interval. To sample \(Unif[a, b), b > a\) multiply the output of

by`random_sample`
*(b-a)*and add*a*:(b - a) * random_sample() + a
Note

New code should use the

method of a`random`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**out**float or ndarray of floats
Array of random floats of shape

`size`
(unless`size=None`
, in which case a single float is returned).
See also

`random.Generator.random`
which should be used for new code.

Examples

>>> np.random.random_sample() 0.47108547995356098 # random >>> type(np.random.random_sample()) <class 'float'> >>> np.random.random_sample((5,)) array([ 0.30220482, 0.86820401, 0.1654503 , 0.11659149, 0.54323428]) # random
Three-by-two array of random numbers from [-5, 0):

>>> 5 * np.random.random_sample((3, 2)) - 5 array([[-3.99149989, -0.52338984], # random [-2.99091858, -0.79479508], [-1.23204345, -1.75224494]])numpy.distutils.system_info.get_standard_file# distutils.system_info.get_standard_file(fname)[source]# Returns a list of files named ‘fname’ from 1) System-wide directory (directory-location of this module) 2) Users HOME directory (os.environ[‘HOME’]) 3) Local directory# numpy.memmap.round[#](#numpy-memmap-round)
method

memmap.round(*decimals=0*,*out=None*)[#](#numpy.memmap.round)
-
Return

*a*with each element rounded to the given number of decimals.Refer to

for full documentation.`numpy.around`
See also

`numpy.around`
equivalent function

method

Return *a* with each element rounded to the given number of decimals.

Refer to [ numpy.around](numpy.around.html#numpy.around) for full documentation.

See also

`numpy.around`
equivalent function# numpy.recarray.conjugate[#](#numpy-recarray-conjugate)
method

recarray.conjugate()[#](#numpy.recarray.conjugate)
-
Return the complex conjugate, element-wise.

Refer to

for full documentation.`numpy.conjugate`
See also

`numpy.conjugate`
equivalent function

method

Return the complex conjugate, element-wise.

Refer to [ numpy.conjugate](numpy.conjugate.html#numpy.conjugate) for full documentation.

See also

`numpy.conjugate`
equivalent function# numpy.nanargmax[#](#numpy-nanargmax)
numpy.nanargmax(*a*,*axis=None*,*out=None*,***,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L561-L615)[#](#numpy.nanargmax)
-
Return the indices of the maximum values in the specified axis ignoring NaNs. For all-NaN slices

`ValueError`
is raised. Warning: the results cannot be trusted if a slice contains only NaNs and -Infs.Parameters:
-
**a**array_like
Input data.

**axis**int, optional
Axis along which to operate. By default flattened input is used.

**out**array, optional
If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.

New in version 1.22.0.

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.

New in version 1.22.0.

Returns:
-
**index_array**ndarray
An array of indices or a single index value.

Examples

>>> a = np.array([[np.nan, 4], [2, 3]]) >>> np.argmax(a) 0 >>> np.nanargmax(a) 1 >>> np.nanargmax(a, axis=0) array([1, 0]) >>> np.nanargmax(a, axis=1) array([1, 1])# numpy.ufunc.ntypes[#](#numpy-ufunc-ntypes)
attribute

ufunc.ntypes[#](#numpy.ufunc.ntypes)
-
The number of types.

The number of numerical NumPy types - of which there are 18 total - on which the ufunc can operate.

See also

Examples

>>> np.add.ntypes 18 >>> np.multiply.ntypes 18 >>> np.power.ntypes 17 >>> np.exp.ntypes 7 >>> np.remainder.ntypes 14# numpy.char.chararray.compress[#](#numpy-char-chararray-compress)
method

char.chararray.compress(*condition*,*axis=None*,*out=None*)[#](#numpy.char.chararray.compress)
-
Return selected slices of this array along given axis.

Refer to

for full documentation.`numpy.compress`
See also

`numpy.compress`
equivalent functionUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
Scalars
Data type objects (
dtype
)
numpy.dtype
numpy.dtype.type
numpy.dtype.kind
numpy.dtype.char
numpy.dtype.num
numpy.dtype.str
numpy.dtype.name
numpy.dtype.itemsize
numpy.dtype.byteorder
numpy.dtype.fields
numpy.dtype.names
numpy.dtype.subdtype
numpy.dtype.shape
numpy.dtype.hasobject
numpy.dtype.flags
numpy.dtype.isbuiltin
numpy.dtype.isnative
numpy.dtype.descr
numpy.dtype.alignment
numpy.dtype.base
numpy.dtype.metadata
numpy.dtype.newbyteorder
numpy.dtype.__reduce__
numpy.dtype.__setstate__
numpy.dtype.__class_getitem__
numpy.dtype.__ge__
numpy.dtype.__gt__
numpy.dtype.__le__
numpy.dtype.__lt__
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
dtype.type
numpy.dtype.type
#
attribute
dtype.
type
=
None
## numpy.generic.setflags[#](#numpy-generic-setflags)
method

generic.setflags()[#](#numpy.generic.setflags)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.setflags`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.setflags](numpy.ndarray.setflags.html#numpy.ndarray.setflags).# numpy.require[#](#numpy-require)
numpy.require(*a*,*dtype=None*,*requirements=None*,***,*like=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_asarray.py#L27-L131)[#](#numpy.require)
-
Return an ndarray of the provided type that satisfies requirements.

This function is useful to be sure that an array with the correct flags is returned for passing to compiled code (perhaps through ctypes).

Parameters:
-
**a**array_like
The object to be converted to a type-and-requirement-satisfying array.

**dtype**data-type
The required data-type. If None preserve the current dtype. If your application requires the data to be in native byteorder, include a byteorder specification as a part of the dtype specification.

**requirements**str or sequence of str
The requirements list can be any of the following

‘F_CONTIGUOUS’ (‘F’) - ensure a Fortran-contiguous array

‘C_CONTIGUOUS’ (‘C’) - ensure a C-contiguous array

‘ALIGNED’ (‘A’) - ensure a data-type aligned array

‘WRITEABLE’ (‘W’) - ensure a writable array

‘OWNDATA’ (‘O’) - ensure an array that owns its own data

‘ENSUREARRAY’, (‘E’) - ensure a base array, instead of a subclass

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**out**ndarray
Array with specified requirements and type if given.

See also

`asarray`
Convert input to an ndarray.

`asanyarray`
Convert to an ndarray, but pass through ndarray subclasses.

`ascontiguousarray`
Convert input to a contiguous array.

`asfortranarray`
Convert input to an ndarray with column-major memory order.

`ndarray.flags`
Information about the memory layout of the array.

Notes

The returned array will be guaranteed to have the listed requirements by making a copy if needed.

Examples

>>> x = np.arange(6).reshape(2,3) >>> x.flags C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : False WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False
>>> y = np.require(x, dtype=np.float32, requirements=['A', 'O', 'W', 'F']) >>> y.flags C_CONTIGUOUS : False F_CONTIGUOUS : True OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False# numpy.chararray.ctypes[#](#numpy-chararray-ctypes)
attribute

chararray.ctypes[#](#numpy.chararray.ctypes)
-
An object to simplify the interaction of the array with the ctypes module.

This attribute creates an object that makes it easier to use arrays when calling shared libraries with the ctypes module. The returned object has, among others, data, shape, and strides attributes (see Notes below) which themselves return ctypes objects that can be used as arguments to a shared library.

Parameters:
-
**None**
Returns:
-
**c**Python object
Possessing attributes data, shape, strides, etc.

See also

Notes

Below are the public attributes of this object which were documented in “Guide to NumPy” (we have omitted undocumented public attributes, as well as documented private attributes):

_ctypes.data
-
A pointer to the memory area of the array as a Python integer. This memory area may contain data that is not aligned, or not in correct byte-order. The memory area may not even be writeable. The array flags and data-type of this array should be respected when passing this attribute to arbitrary C-code to avoid trouble that can include Python crashing. User Beware! The value of this attribute is exactly the same as

`self._array_interface_['data'][0]`
.Note that unlike

`data_as`
, a reference will not be kept to the array: code like`ctypes.c_void_p((a + b).ctypes.data)`
will result in a pointer to a deallocated array, and should be spelt`(a + b).ctypes.data_as(ctypes.c_void_p)`
_ctypes.shape
-
(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the C-integer corresponding to

`dtype('p')`
on this platform (see). This base-type could be`c_intp`
,`ctypes.c_int`
, or`ctypes.c_long`
depending on the platform. The ctypes array contains the shape of the underlying array.`ctypes.c_longlong`
_ctypes.strides
-
(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the same as for the shape attribute. This ctypes array contains the strides information from the underlying array. This strides information is important for showing how many bytes must be jumped to get to the next element in the array.

_ctypes.data_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L267-L284)
-
Return the data pointer cast to a particular c-types object. For example, calling

`self._as_parameter_`
is equivalent to`self.data_as(ctypes.c_void_p)`
. Perhaps you want to use the data as a pointer to a ctypes array of floating-point data:`self.data_as(ctypes.POINTER(ctypes.c_double))`
.The returned pointer will keep a reference to the array.

_ctypes.shape_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L286-L293)
-
Return the shape tuple as an array of some other c-types type. For example:

`self.shape_as(ctypes.c_short)`
.
_ctypes.strides_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L295-L302)
-
Return the strides tuple as an array of some other c-types type. For example:

`self.strides_as(ctypes.c_longlong)`
.
If the ctypes module is not available, then the ctypes attribute of array objects still returns something useful, but ctypes objects are not returned and errors may be raised instead. In particular, the object will still have the

`as_parameter`
attribute which will return an integer equal to the data attribute.Examples

>>> import ctypes >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32) >>> x array([[0, 1], [2, 3]], dtype=int32) >>> x.ctypes.data 31962608 # may vary >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)) <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents c_uint(0) >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents c_ulong(4294967296) >>> x.ctypes.shape <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary >>> x.ctypes.strides <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary# numpy.arcsin[#](#numpy-arcsin)
numpy.arcsin(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'arcsin'>*[#](#numpy.arcsin)
-
Inverse sine, element-wise.

Parameters:
-
**x**array_like
*y*-coordinate on the unit circle.
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**angle**ndarray
The inverse sine of each element in

*x*, in radians and in the closed interval`[-pi/2, pi/2]`
. This is a scalar if*x*is a scalar.
Notes

is a multivalued function: for each`arcsin`
*x*there are infinitely many numbers*z*such that \(sin(z) = x\). The convention is to return the angle*z*whose real part lies in [-pi/2, pi/2].For real-valued input data types,

*arcsin*always returns real output. For each value that cannot be expressed as a real number or infinity, it yields`nan`
and sets the*invalid*floating point error flag.For complex-valued input,

is a complex analytic function that has, by convention, the branch cuts [-inf, -1] and [1, inf] and is continuous from above on the former and from below on the latter.`arcsin`
The inverse sine is also known as

*asin*or sin^{-1}.References

Abramowitz, M. and Stegun, I. A.,

*Handbook of Mathematical Functions*, 10th printing, New York: Dover, 1964, pp. 79ff.[https://personal.math.ubc.ca/~cbm/aands/page_79.htm](https://personal.math.ubc.ca/~cbm/aands/page_79.htm)Examples

>>> np.arcsin(1) # pi/2 1.5707963267948966 >>> np.arcsin(-1) # -pi/2 -1.5707963267948966 >>> np.arcsin(0) 0.0# numpy.matrix.item[#](#numpy-matrix-item)
method

matrix.item(**args*)[#](#numpy.matrix.item)
-
Copy an element of an array to a standard Python scalar and return it.

Parameters:
-
***args**Arguments (variable number and type)
none: in this case, the method only works for arrays with one element (

*a.size == 1*), which element is copied into a standard Python scalar object and returned.
int_type: this argument is interpreted as a flat index into the array, specifying which element to copy and return.

tuple of int_types: functions as does a single int_type argument, except that the argument is interpreted as an nd-index into the array.

Returns:
-
**z**Standard Python scalar object
A copy of the specified element of the array as a suitable Python scalar

Notes

When the data type of

*a*is longdouble or clongdouble, item() returns a scalar array object because there is no available Python scalar that would not lose information. Void arrays return a buffer object for item(), unless fields are defined, in which case a tuple is returned.is very similar to a[args], except, instead of an array scalar, a standard Python scalar is returned. This can be useful for speeding up access to elements of the array and doing arithmetic on elements of the array using Python’s optimized math.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.item(3) 1 >>> x.item(7) 0 >>> x.item((0, 1)) 2 >>> x.item((2, 2)) 1numpy.matrix.data# attribute matrix.data# Python buffer object pointing to the start of the array’s data.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
ma.MaskType.flags
numpy.ma.MaskType.flags
#
attribute
ma.MaskType.
flags
#
The integer value of flags.# numpy.tensordot[#](#numpy-tensordot)
numpy.tensordot(*a*,*b*,*axes=2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L932-L1122)[#](#numpy.tensordot)
-
Compute tensor dot product along specified axes.

Given two tensors,

*a*and*b*, and an array_like object containing two array_like objects,`(a_axes, b_axes)`
, sum the products of*a*’s and*b*’s elements (components) over the axes specified by`a_axes`
and`b_axes`
. The third argument can be a single non-negative integer_like scalar,`N`
; if it is such, then the last`N`
dimensions of*a*and the first`N`
dimensions of*b*are summed over.Parameters:
-
**a, b**array_like
Tensors to “dot”.

**axes**int or (2,) array_like
integer_like If an int N, sum over the last N axes of

*a*and the first N axes of*b*in order. The sizes of the corresponding axes must match.
(2,) array_like Or, a list of axes to be summed over, first sequence applying to

*a*, second to*b*. Both elements array_like must be of the same length.
Returns:
-
**output**ndarray
The tensor dot product of the input.

Notes

Three common use cases are:
-
`axes = 0`
: tensor product \(a\otimes b\)
`axes = 1`
: tensor dot product \(a\cdot b\)
`axes = 2`
: (default) tensor double contraction \(a:b\)
When

*axes*is integer_like, the sequence for evaluation will be: first the -Nth axis in*a*and 0th axis in*b*, and the -1th axis in*a*and Nth axis in*b*last.When there is more than one axis to sum over - and they are not the last (first) axes of

*a*(*b*) - the argument*axes*should consist of two sequences of the same length, with the first axis to sum over given first in both sequences, the second axis second, and so forth.The shape of the result consists of the non-contracted axes of the first tensor, followed by the non-contracted axes of the second.

Examples

A “traditional” example:

>>> a = np.arange(60.).reshape(3,4,5) >>> b = np.arange(24.).reshape(4,3,2) >>> c = np.tensordot(a,b, axes=([1,0],[0,1])) >>> c.shape (5, 2) >>> c array([[4400., 4730.], [4532., 4874.], [4664., 5018.], [4796., 5162.], [4928., 5306.]]) >>> # A slower but equivalent way of computing the same... >>> d = np.zeros((5,2)) >>> for i in range(5): ... for j in range(2): ... for k in range(3): ... for n in range(4): ... d[i,j] += a[k,n,i] * b[n,k,j] >>> c == d array([[ True, True], [ True, True], [ True, True], [ True, True], [ True, True]])
An extended example taking advantage of the overloading of + and *:

>>> a = np.array(range(1, 9)) >>> a.shape = (2, 2, 2) >>> A = np.array(('a', 'b', 'c', 'd'), dtype=object) >>> A.shape = (2, 2) >>> a; A array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]) array([['a', 'b'], ['c', 'd']], dtype=object)
>>> np.tensordot(a, A) # third argument default is 2 for double-contraction array(['abbcccdddd', 'aaaaabbbbbbcccccccdddddddd'], dtype=object)
>>> np.tensordot(a, A, 1) array([[['acc', 'bdd'], ['aaacccc', 'bbbdddd']], [['aaaaacccccc', 'bbbbbdddddd'], ['aaaaaaacccccccc', 'bbbbbbbdddddddd']]], dtype=object)
>>> np.tensordot(a, A, 0) # tensor product (result too long to incl.) array([[[[['a', 'b'], ['c', 'd']], ...
>>> np.tensordot(a, A, (0, 1)) array([[['abbbbb', 'cddddd'], ['aabbbbbb', 'ccdddddd']], [['aaabbbbbbb', 'cccddddddd'], ['aaaabbbbbbbb', 'ccccdddddddd']]], dtype=object)
>>> np.tensordot(a, A, (2, 1)) array([[['abb', 'cdd'], ['aaabbbb', 'cccdddd']], [['aaaaabbbbbb', 'cccccdddddd'], ['aaaaaaabbbbbbbb', 'cccccccdddddddd']]], dtype=object)
>>> np.tensordot(a, A, ((0, 1), (0, 1))) array(['abbbcccccddddddd', 'aabbbbccccccdddddddd'], dtype=object)
>>> np.tensordot(a, A, ((2, 1), (1, 0))) array(['acccbbdddd', 'aaaaacccccccbbbbbbdddddddd'], dtype=object)# numpy.nested_iters[#](#numpy-nested-iters)
numpy.nested_iters(*op*,*axes*,*flags=None*,*op_flags=None*,*op_dtypes=None*,*order='K'*,*casting='safe'*,*buffersize=0*)[#](#numpy.nested_iters)
-
Create nditers for use in nested loops

Create a tuple of

objects which iterate in nested loops over different axes of the op argument. The first iterator is used in the outermost loop, the last in the innermost loop. Advancing one will change the subsequent iterators to point at its new element.`nditer`
Parameters:
-
**op**ndarray or sequence of array_like
The array(s) to iterate over.

**axes**list of list of int
Each item is used as an “op_axes” argument to an nditer

**flags, op_flags, op_dtypes, order, casting, buffersize (optional)**
See

parameters of the same name`nditer`
Returns:
-
**iters**tuple of nditer
An nditer for each item in

*axes*, outermost first
See also

Examples

Basic usage. Note how y is the “flattened” version of [a[:, 0, :], a[:, 1, 0], a[:, 2, :]] since we specified the first iter’s axes as [1]

>>> a = np.arange(12).reshape(2, 3, 2) >>> i, j = np.nested_iters(a, [[1], [0, 2]], flags=["multi_index"]) >>> for x in i: ... print(i.multi_index) ... for y in j: ... print('', j.multi_index, y) (0,) (0, 0) 0 (0, 1) 1 (1, 0) 6 (1, 1) 7 (1,) (0, 0) 2 (0, 1) 3 (1, 0) 8 (1, 1) 9 (2,) (0, 0) 4 (0, 1) 5 (1, 0) 10 (1, 1) 11# numpy.minimum[#](#numpy-minimum)
numpy.minimum(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'minimum'>*[#](#numpy.minimum)
-
Element-wise minimum of array elements.

Compare two arrays and return a new array containing the element-wise minima. If one of the elements being compared is a NaN, then that element is returned. If both elements are NaNs then the first is returned. The latter distinction is important for complex NaNs, which are defined as at least one of the real or imaginary parts being a NaN. The net effect is that NaNs are propagated.

Parameters:
-
**x1, x2**array_like
The arrays holding the elements to be compared. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray or scalar
The minimum of

*x1*and*x2*, element-wise. This is a scalar if both*x1*and*x2*are scalars.
See also

Notes

The minimum is equivalent to

`np.where(x1 <= x2, x1, x2)`
when neither x1 nor x2 are NaNs, but it is faster and does proper broadcasting.Examples

>>> np.minimum([2, 3, 4], [1, 5, 2]) array([1, 3, 2])
>>> np.minimum(np.eye(2), [0.5, 2]) # broadcasting array([[ 0.5, 0. ], [ 0. , 1. ]])
>>> np.minimum([np.nan, 0, np.nan],[0, np.nan, np.nan]) array([nan, nan, nan]) >>> np.minimum(-np.Inf, 1) -inf# numpy.typename[#](#numpy-typename)
numpy.typename(*char*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/type_check.py#L612-L662)[#](#numpy.typename)
-
Return a description for the given data type code.

Parameters:
-
**char**str
Data type code.

Returns:
-
**out**str
Description of the input data type code.

See also

,`dtype`
`typecodes`
Examples

>>> typechars = ['S1', '?', 'B', 'D', 'G', 'F', 'I', 'H', 'L', 'O', 'Q', ... 'S', 'U', 'V', 'b', 'd', 'g', 'f', 'i', 'h', 'l', 'q'] >>> for typechar in typechars: ... print(typechar, ' : ', np.typename(typechar)) ... S1 : character ? : bool B : unsigned char D : complex double precision G : complex long double precision F : complex single precision I : unsigned integer H : unsigned short L : unsigned long integer O : object Q : unsigned long long integer S : string U : unicode V : void b : signed char d : double precision g : long precision f : single precision i : integer h : short l : long integer q : long long integer# numpy.polynomial.hermite_e.hermeint[#](#numpy-polynomial-hermite-e-hermeint)
polynomial.hermite_e.hermeint(*c*,*m=1*,*k=[]*,*lbnd=0*,*scl=1*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L673-L792)[#](#numpy.polynomial.hermite_e.hermeint)
-
Integrate a Hermite_e series.

Returns the Hermite_e series coefficients

*c*integrated*m*times from*lbnd*along*axis*. At each iteration the resulting series is**multiplied**by*scl*and an integration constant,*k*, is added. The scaling factor is for use in a linear change of variable. (“Buyer beware”: note that, depending on what one is doing, one may want*scl*to be the reciprocal of what one might expect; for more information, see the Notes section below.) The argument*c*is an array of coefficients from low to high degree along each axis, e.g., [1,2,3] represents the series`H_0 + 2*H_1 + 3*H_2`
while [[1,2],[1,2]] represents`1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) + 2*H_0(x)*H_1(y) + 2*H_1(x)*H_1(y)`
if axis=0 is`x`
and axis=1 is`y`
.Parameters:
-
**c**array_like
Array of Hermite_e series coefficients. If c is multidimensional the different axis correspond to different variables with the degree in each axis given by the corresponding index.

**m**int, optional
Order of integration, must be positive. (Default: 1)

**k**{[], list, scalar}, optional
Integration constant(s). The value of the first integral at

`lbnd`
is the first value in the list, the value of the second integral at`lbnd`
is the second value, etc. If`k == []`
(the default), all constants are set to zero. If`m == 1`
, a single scalar can be given instead of a list.
**lbnd**scalar, optional
The lower bound of the integral. (Default: 0)

**scl**scalar, optional
Following each integration the result is

*multiplied*by*scl*before the integration constant is added. (Default: 1)
**axis**int, optional
Axis over which the integral is taken. (Default: 0).

New in version 1.7.0.

Returns:
-
**S**ndarray
Hermite_e series coefficients of the integral.

Raises:
-
ValueError
-
If

`m < 0`
,`len(k) > m`
,`np.ndim(lbnd) != 0`
, or`np.ndim(scl) != 0`
.
See also

Notes

Note that the result of each integration is

*multiplied*by*scl*. Why is this important to note? Say one is making a linear change of variable \(u = ax + b\) in an integral relative to*x*. Then \(dx = du/a\), so one will need to set*scl*equal to \(1/a\) - perhaps not what one would have first thought.Also note that, in general, the result of integrating a C-series needs to be “reprojected” onto the C-series basis set. Thus, typically, the result of this function is “unintuitive,” albeit correct; see Examples section below.

Examples

>>> from numpy.polynomial.hermite_e import hermeint >>> hermeint([1, 2, 3]) # integrate once, value 0 at 0. array([1., 1., 1., 1.]) >>> hermeint([1, 2, 3], m=2) # integrate twice, value & deriv 0 at 0 array([-0.25 , 1. , 0.5 , 0.33333333, 0.25 ]) # may vary >>> hermeint([1, 2, 3], k=1) # integrate once, value 1 at 0. array([2., 1., 1., 1.]) >>> hermeint([1, 2, 3], lbnd=-1) # integrate once, value 0 at -1 array([-1., 1., 1., 1.]) >>> hermeint([1, 2, 3], m=2, k=[1, 2], lbnd=-1) array([ 1.83333333, 0. , 0.5 , 0.33333333, 0.25 ]) # may vary# numpy.ma.hsplit[#](#numpy-ma-hsplit)
ma.hsplit*= <numpy.ma.extras._fromnxfunction_single object>*[#](#numpy.ma.hsplit)
-
hsplit

Split an array into multiple sub-arrays horizontally (column-wise).

Please refer to the

documentation.`split`
is equivalent to`hsplit`
with`split`
`axis=1`
, the array is always split along the second axis except for 1-D arrays, where it is split at`axis=0`
.See also

`split`
Split an array into multiple sub-arrays of equal size.

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> x = np.arange(16.0).reshape(4, 4) >>> x array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]]) >>> np.hsplit(x, 2) [array([[ 0., 1.], [ 4., 5.], [ 8., 9.], [12., 13.]]), array([[ 2., 3.], [ 6., 7.], [10., 11.], [14., 15.]])] >>> np.hsplit(x, np.array([3, 6])) [array([[ 0., 1., 2.], [ 4., 5., 6.], [ 8., 9., 10.], [12., 13., 14.]]), array([[ 3.], [ 7.], [11.], [15.]]), array([], shape=(4, 0), dtype=float64)]
With a higher dimensional array the split is still along the second axis.

>>> x = np.arange(8.0).reshape(2, 2, 2) >>> x array([[[0., 1.], [2., 3.]], [[4., 5.], [6., 7.]]]) >>> np.hsplit(x, 2) [array([[[0., 1.]], [[4., 5.]]]), array([[[2., 3.]], [[6., 7.]]])]
With a 1-D array, the split is along axis 0.

>>> x = np.array([0, 1, 2, 3, 4, 5]) >>> np.hsplit(x, 2) [array([0, 1, 2]), array([3, 4, 5])]numpy.flatiter.copy# method flatiter.copy()# Get a copy of the iterator as a 1-D array. Examples >>> x = np.arange(6).reshape(2, 3) >>> x array([[0, 1, 2], [3, 4, 5]]) >>> fl = x.flat >>> fl.copy() array([0, 1, 2, 3, 4, 5])ufunc

numpy.ctypeslib

numpy.fft

numpy.linalg

numpy.matlib

numpy.random

numpy.testing

numpy.testing.overrides

numpy.typing

numpy.distutils

MaskType

alias of bool_

bool_numpy.distutils.ccompiler_opt.CCompilerOpt.report# method distutils.ccompiler_opt.CCompilerOpt.report(full=False)[source]## numpy.char.chararray.split[#](#numpy-char-chararray-split)
method

char.chararray.split(*sep=None*,*maxsplit=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2594-L2604)[#](#numpy.char.chararray.split)
-
For each element in

*self*, return a list of the words in the string, using*sep*as the delimiter string.See also

method

For each element in *self*, return a list of the words in the
string, using *sep* as the delimiter string.

See also# numpy.less_equal[#](#numpy-less-equal)
numpy.less_equal(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'less_equal'>*[#](#numpy.less_equal)
-
Return the truth value of (x1 <= x2) element-wise.

Parameters:
-
**x1, x2**array_like
Input arrays. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray or scalar
Output array, element-wise comparison of

*x1*and*x2*. Typically of type bool, unless`dtype=object`
is passed. This is a scalar if both*x1*and*x2*are scalars.
See also

Examples

>>> np.less_equal([4, 2, 1], [2, 2, 2]) array([False, True, True])
The

`<=`
operator can be used as a shorthand for`np.less_equal`
on ndarrays.>>> a = np.array([4, 2, 1]) >>> b = np.array([2, 2, 2]) >>> a <= b array([False, True, True])# numpy.polynomial.legendre.legzero[#](#numpy-polynomial-legendre-legzero)
polynomial.legendre.legzero*= array([0])*[#](#numpy.polynomial.legendre.legzero)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.ma.sum[#](#numpy-ma-sum)
ma.sum(*self*,*axis=None*,*dtype=None*,*out=None*,*keepdims=<no value>*)*= <numpy.ma.core._frommethod object>*[#](#numpy.ma.sum)
-
Return the sum of the array elements over the given axis.

Masked elements are set to 0 internally.

Refer to

for full documentation.`numpy.sum`
See also

`numpy.ndarray.sum`
corresponding function for ndarrays

`numpy.sum`
equivalent function

Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.sum() 25 >>> x.sum(axis=1) masked_array(data=[4, 5, 16], mask=[False, False, False], fill_value=999999) >>> x.sum(axis=0) masked_array(data=[8, 5, 12], mask=[False, False, False], fill_value=999999) >>> print(type(x.sum(axis=0, dtype=np.int64)[0])) <class 'numpy.int64'># numpy.chararray.real[#](#numpy-chararray-real)
attribute

chararray.real[#](#numpy.chararray.real)
-
The real part of the array.

See also

`numpy.real`
equivalent function

Examples

>>> x = np.sqrt([1+0j, 0+1j]) >>> x.real array([ 1. , 0.70710678]) >>> x.real.dtype dtype('float64')
attribute

The real part of the array.

See also

`numpy.real`
equivalent function

Examples

```
>>> x = np.sqrt([1+0j, 0+1j])
>>> x.real
array([ 1. , 0.70710678])
>>> x.real.dtype
dtype('float64')
```# numpy.memmap.mean[#](#numpy-memmap-mean)
method

memmap.mean(*axis=None*,*dtype=None*,*out=None*,*keepdims=False*,***,*where=True*)[#](#numpy.memmap.mean)
-
Returns the average of the array elements along given axis.

Refer to

for full documentation.`numpy.mean`
See also

`numpy.mean`
equivalent function# numpy.chararray.conjugate[#](#numpy-chararray-conjugate)
method

chararray.conjugate()[#](#numpy.chararray.conjugate)
-
Return the complex conjugate, element-wise.

Refer to

for full documentation.`numpy.conjugate`
See also

`numpy.conjugate`
equivalent function

method

Return the complex conjugate, element-wise.

Refer to [ numpy.conjugate](numpy.conjugate.html#numpy.conjugate) for full documentation.

See also

`numpy.conjugate`
equivalent function# numpy.ma.clump_unmasked[#](#numpy-ma-clump-unmasked)
ma.clump_unmasked(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L2002-L2038)[#](#numpy.ma.clump_unmasked)
-
Return list of slices corresponding to the unmasked clumps of a 1-D array. (A “clump” is defined as a contiguous region of the array).

Parameters:
-
**a**ndarray
A one-dimensional masked array.

Returns:
-
**slices**list of slice
The list of slices, one for each continuous region of unmasked elements in

*a*.
See also

Notes

New in version 1.4.0.

Examples

>>> a = np.ma.masked_array(np.arange(10)) >>> a[[0, 1, 2, 6, 8, 9]] = np.ma.masked >>> np.ma.clump_unmasked(a) [slice(3, 6, None), slice(7, 8, None)]# numpy.recarray.cumsum[#](#numpy-recarray-cumsum)
method

recarray.cumsum(*axis=None*,*dtype=None*,*out=None*)[#](#numpy.recarray.cumsum)
-
Return the cumulative sum of the elements along the given axis.

Refer to

for full documentation.`numpy.cumsum`
See also

`numpy.cumsum`
equivalent function

method

Return the cumulative sum of the elements along the given axis.

Refer to [ numpy.cumsum](numpy.cumsum.html#numpy.cumsum) for full documentation.

See also

`numpy.cumsum`
equivalent function# numpy.emath.logn[#](#numpy-emath-logn)
emath.logn(*n*,*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/scimath.py#L353-L386)[#](#numpy.emath.logn)
-
Take log base n of x.

If

*x*contains negative inputs, the answer is computed and returned in the complex domain.Parameters:
-
**n**array_like
The integer base(s) in which the log is taken.

**x**array_like
The value(s) whose log base

*n*is (are) required.
Returns:
-
**out**ndarray or scalar
The log base

*n*of the*x*value(s). If*x*was a scalar, so is*out*, otherwise an array is returned.
Examples

>>> np.set_printoptions(precision=4)
>>> np.emath.logn(2, [4, 8]) array([2., 3.]) >>> np.emath.logn(2, [-4, -8, 8]) array([2.+4.5324j, 3.+4.5324j, 3.+0.j ])# numpy.matrix.squeeze[#](#numpy-matrix-squeeze)
method

matrix.squeeze(*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L324-L373)[#](#numpy.matrix.squeeze)
-
Return a possibly reshaped matrix.

Refer to

for more documentation.`numpy.squeeze`
Parameters:
-
**axis**None or int or tuple of ints, optional
Selects a subset of the axes of length one in the shape. If an axis is selected with shape entry greater than one, an error is raised.

Returns:
-
**squeezed**matrix
The matrix, but as a (1, N) matrix if it had shape (N, 1).

See also

`numpy.squeeze`
related function

Notes

If

*m*has a single column then that column is returned as the single row of a matrix. Otherwise*m*is returned. The returned matrix is always either*m*itself or a view into*m*. Supplying an axis keyword argument will not affect the returned matrix but it may cause an error to be raised.Examples

>>> c = np.matrix([[1], [2]]) >>> c matrix([[1], [2]]) >>> c.squeeze() matrix([[1, 2]]) >>> r = c.T >>> r matrix([[1, 2]]) >>> r.squeeze() matrix([[1, 2]]) >>> m = np.matrix([[1, 2], [3, 4]]) >>> m.squeeze() matrix([[1, 2], [3, 4]])# numpy.recarray[#](#numpy-recarray)
*class*numpy.recarray(*shape*,*dtype=None*,*buf=None*,*offset=0*,*strides=None*,*formats=None*,*names=None*,*titles=None*,*byteorder=None*,*aligned=False*,*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/__init__.py)[#](#numpy.recarray)
-
Construct an ndarray that allows field access using attributes.

Arrays may have a data-types containing fields, analogous to columns in a spread sheet. An example is

`[(x, int), (y, float)]`
, where each entry in the array is a pair of`(int, float)`
. Normally, these attributes are accessed using dictionary lookups such as`arr['x']`
and`arr['y']`
. Record arrays allow the fields to be accessed as members of the array, using`arr.x`
and`arr.y`
.Parameters:
-
**shape**tuple
Shape of output array.

**dtype**data-type, optional
The desired data-type. By default, the data-type is determined from

*formats*,*names*,*titles*,*aligned*and*byteorder*.
**formats**list of data-types, optional
A list containing the data-types for the different columns, e.g.

`['i4', 'f8', 'i4']`
.*formats*does*not*support the new convention of using types directly, i.e.`(int, float, int)`
. Note that*formats*must be a list, not a tuple. Given that*formats*is somewhat limited, we recommend specifyinginstead.`dtype`
**names**tuple of str, optional
The name of each column, e.g.

`('x', 'y', 'z')`
.
**buf**buffer, optional
By default, a new array is created of the given shape and data-type. If

*buf*is specified and is an object exposing the buffer interface, the array will use the memory from the existing buffer. In this case, the*offset*andkeywords are available.`strides`
Returns:
-
**rec**recarray
Empty array of the given shape and type.

Other Parameters:
-
**titles**tuple of str, optional
Aliases for column names. For example, if

*names*were`('x', 'y', 'z')`
and*titles*is`('x_coordinate', 'y_coordinate', 'z_coordinate')`
, then`arr['x']`
is equivalent to both`arr.x`
and`arr.x_coordinate`
.
**byteorder**{‘<’, ‘>’, ‘=’}, optional
Byte-order for all fields.

**aligned**bool, optional
Align the fields in memory as the C-compiler would.

**strides**tuple of ints, optional
Buffer (

*buf*) is interpreted according to these strides (strides define how many bytes each array element, row, column, etc. occupy in memory).
**offset**int, optional
Start reading buffer (

*buf*) from this offset onwards.
**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`core.records.fromrecords`
Construct a record array from data.

`record`
fundamental data-type for

.`recarray`
`format_parser`
determine a data-type from formats, names, titles.

Notes

This constructor can be compared to

`empty`
: it creates a new record array but does not fill it with data. To create a record array from data, use one of the following methods:Create a standard ndarray and convert it to a record array, using

`arr.view(np.recarray)`
Use the

*buf*keyword.
Use

*np.rec.fromrecords*.
Examples

Create an array with two fields,

`x`
and`y`
:>>> x = np.array([(1.0, 2), (3.0, 4)], dtype=[('x', '<f8'), ('y', '<i8')]) >>> x array([(1., 2), (3., 4)], dtype=[('x', '<f8'), ('y', '<i8')])
>>> x['x'] array([1., 3.])
View the array as a record array:

>>> x = x.view(np.recarray)
>>> x.x array([1., 3.])
>>> x.y array([2, 4])
Create a new, empty record array:

>>> np.recarray((2,), ... dtype=[('x', int), ('y', float), ('z', int)]) rec.array([(-1073741821, 1.2249118382103472e-301, 24547520), (3471280, 1.2134086255804012e-316, 0)], dtype=[('x', '<i4'), ('y', '<f8'), ('z', '<i4')])
Attributes:
-
`T`
View of the transposed array.

`base`
Base object if memory is from some other object.

`ctypes`
An object to simplify the interaction of the array with the ctypes module.

`data`
Python buffer object pointing to the start of the array’s data.

`dtype`
Data-type of the array’s elements.

`flags`
Information about the memory layout of the array.

`flat`
A 1-D iterator over the array.

`imag`
The imaginary part of the array.

`itemsize`
Length of one array element in bytes.

`nbytes`
Total bytes consumed by the elements of the array.

`ndim`
Number of array dimensions.

`real`
The real part of the array.

`shape`
Tuple of array dimensions.

`size`
Number of elements in the array.

`strides`
Tuple of bytes to step in each dimension when traversing an array.

Methods

([axis, out, keepdims, where])`all`
Returns True if all elements evaluate to True.

([axis, out, keepdims, where])`any`
Returns True if any of the elements of

*a*evaluate to True.([axis, out, keepdims])`argmax`
Return indices of the maximum values along the given axis.

([axis, out, keepdims])`argmin`
Return indices of the minimum values along the given axis.

(kth[, axis, kind, order])`argpartition`
Returns the indices that would partition this array.

([axis, kind, order])`argsort`
Returns the indices that would sort this array.

(dtype[, order, casting, subok, copy])`astype`
Copy of the array, cast to a specified type.

([inplace])`byteswap`
Swap the bytes of the array elements

(choices[, out, mode])`choose`
Use an index array to construct a new array from a set of choices.

([min, max, out])`clip`
Return an array whose values are limited to

`[min, max]`
.(condition[, axis, out])`compress`
Return selected slices of this array along given axis.

()`conj`
Complex-conjugate all elements.

Return the complex conjugate, element-wise.

([order])`copy`
Return a copy of the array.

([axis, dtype, out])`cumprod`
Return the cumulative product of the elements along the given axis.

([axis, dtype, out])`cumsum`
Return the cumulative sum of the elements along the given axis.

([offset, axis1, axis2])`diagonal`
Return specified diagonals.

(file)`dump`
Dump a pickle of the array to the specified file.

()`dumps`
Returns the pickle of the array as a string.

(value)`fill`
Fill the array with a scalar value.

([order])`flatten`
Return a copy of the array collapsed into one dimension.

(dtype[, offset])`getfield`
Returns a field of the given array as a certain type.

(*args)`item`
Copy an element of an array to a standard Python scalar and return it.

(*args)`itemset`
Insert scalar into an array (scalar is cast to array's dtype, if possible)

([axis, out, keepdims, initial, where])`max`
Return the maximum along a given axis.

([axis, dtype, out, keepdims, where])`mean`
Returns the average of the array elements along given axis.

([axis, out, keepdims, initial, where])`min`
Return the minimum along a given axis.

([new_order])`newbyteorder`
Return the array with the same data viewed with a different byte order.

()`nonzero`
Return the indices of the elements that are non-zero.

(kth[, axis, kind, order])`partition`
Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array.

([axis, dtype, out, keepdims, initial, ...])`prod`
Return the product of the array elements over the given axis

([axis, out, keepdims])`ptp`
Peak to peak (maximum - minimum) value along a given axis.

(indices, values[, mode])`put`
Set

`a.flat[n] = values[n]`
for all*n*in indices.([order])`ravel`
Return a flattened array.

(repeats[, axis])`repeat`
Repeat elements of an array.

(shape[, order])`reshape`
Returns an array containing the same data with a new shape.

(new_shape[, refcheck])`resize`
Change shape and size of array in-place.

([decimals, out])`round`
Return

*a*with each element rounded to the given number of decimals.(v[, side, sorter])`searchsorted`
Find indices where elements of v should be inserted in a to maintain order.

(val, dtype[, offset])`setfield`
Put a value into a specified place in a field defined by a data-type.

([write, align, uic])`setflags`
Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY, respectively.

([axis, kind, order])`sort`
Sort an array in-place.

([axis])`squeeze`
Remove axes of length one from

*a*.([axis, dtype, out, ddof, keepdims, where])`std`
Returns the standard deviation of the array elements along given axis.

([axis, dtype, out, keepdims, initial, where])`sum`
Return the sum of the array elements over the given axis.

(axis1, axis2)`swapaxes`
Return a view of the array with

*axis1*and*axis2*interchanged.(indices[, axis, out, mode])`take`
Return an array formed from the elements of

*a*at the given indices.([order])`tobytes`
Construct Python bytes containing the raw data bytes in the array.

(fid[, sep, format])`tofile`
Write array to a file as text or binary (default).

()`tolist`
Return the array as an

`a.ndim`
-levels deep nested list of Python scalars.([order])`tostring`
A compatibility alias for

, with exactly the same behavior.`tobytes`
([offset, axis1, axis2, dtype, out])`trace`
Return the sum along diagonals of the array.

(*axes)`transpose`
Returns a view of the array with axes transposed.

([axis, dtype, out, ddof, keepdims, where])`var`
Returns the variance of the array elements, along given axis.

([dtype][, type])`view`
New view of array with the same data.

**dot****field**# numpy.ma.filled[#](#numpy-ma-filled)
ma.filled(*a*,*fill_value=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L587-L641)[#](#numpy.ma.filled)
-
Return input as an array with masked data replaced by a fill value.

If

*a*is not a,`MaskedArray`
*a*itself is returned. If*a*is aand`MaskedArray`
*fill_value*is None,*fill_value*is set to`a.fill_value`
.Parameters:
-
**a**MaskedArray or array_like
An input object.

**fill_value**array_like, optional.
Can be scalar or non-scalar. If non-scalar, the resulting filled array should be broadcastable over input array. Default is None.

Returns:
-
**a**ndarray
The filled array.

See also

Examples

>>> x = np.ma.array(np.arange(9).reshape(3, 3), mask=[[1, 0, 0], ... [1, 0, 0], ... [0, 0, 0]]) >>> x.filled() array([[999999, 1, 2], [999999, 4, 5], [ 6, 7, 8]]) >>> x.filled(fill_value=333) array([[333, 1, 2], [333, 4, 5], [ 6, 7, 8]]) >>> x.filled(fill_value=np.arange(3)) array([[0, 1, 2], [0, 4, 5], [6, 7, 8]])# numpy.ma.masked_array.transpose[#](#numpy-ma-masked-array-transpose)
method

ma.masked_array.transpose(**axes*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2571-L2581)[#](#numpy.ma.masked_array.transpose)
-
Returns a view of the array with axes transposed.

Refer to

for full documentation.`numpy.transpose`
Parameters:
-
**axes**None, tuple of ints, or*n*ints
None or no argument: reverses the order of the axes.

tuple of ints:

*i*in the*j*-th place in the tuple means that the array’s*i*-th axis becomes the transposed array’s*j*-th axis.
*n*ints: same as an n-tuple of the same ints (this form is intended simply as a “convenience” alternative to the tuple form).
Returns:
-
**p**ndarray
View of the array with its axes suitably permuted.

See also

`transpose`
Equivalent function.

`ndarray.T`
Array property returning the array transposed.

`ndarray.reshape`
Give a new shape to an array without changing its data.

Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> a array([[1, 2], [3, 4]]) >>> a.transpose() array([[1, 3], [2, 4]]) >>> a.transpose((1, 0)) array([[1, 3], [2, 4]]) >>> a.transpose(1, 0) array([[1, 3], [2, 4]])
>>> a = np.array([1, 2, 3, 4]) >>> a array([1, 2, 3, 4]) >>> a.transpose() array([1, 2, 3, 4])# numpy.ma.MaskedArray.compress[#](#numpy-ma-maskedarray-compress)
method

ma.MaskedArray.compress(*condition*,*axis=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L3893-L3963)[#](#numpy.ma.MaskedArray.compress)
-
Return

*a*where condition is`True`
.If condition is a

, missing values are considered as`MaskedArray`
`False`
.Parameters:
-
**condition**var
Boolean 1-d array selecting which entries to return. If len(condition) is less than the size of a along the axis, then output is truncated to length of condition array.

**axis**{None, int}, optional
Axis along which the operation must be performed.

**out**{None, ndarray}, optional
Alternative output array in which to place the result. It must have the same shape as the expected output but the type will be cast if necessary.

Returns:
-
**result**MaskedArray
A

object.`MaskedArray`
Notes

Please note the difference with

! The output of`compressed`
has a mask, the output of`compress`
does not.`compressed`
Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.compress([1, 0, 1]) masked_array(data=[1, 3], mask=[False, False], fill_value=999999)
>>> x.compress([1, 0, 1], axis=1) masked_array( data=[[1, 3], [--, --], [7, 9]], mask=[[False, False], [ True, True], [False, False]], fill_value=999999)# numpy.radians[#](#numpy-radians)
numpy.radians(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'radians'>*[#](#numpy.radians)
-
Convert angles from degrees to radians.

Parameters:
-
**x**array_like
Input array in degrees.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray
The corresponding radian values. This is a scalar if

*x*is a scalar.
See also

`deg2rad`
equivalent function

Examples

Convert a degree array to radians

>>> deg = np.arange(12.) * 30. >>> np.radians(deg) array([ 0. , 0.52359878, 1.04719755, 1.57079633, 2.0943951 , 2.61799388, 3.14159265, 3.66519143, 4.1887902 , 4.71238898, 5.23598776, 5.75958653])
>>> out = np.zeros((deg.shape)) >>> ret = np.radians(deg, out) >>> ret is out Truenumpy.distutils.ccompiler_opt.CCompilerOpt.dist_error# method static distutils.ccompiler_opt.CCompilerOpt.dist_error(*args)[source]# Raise a compiler error# numpy.chararray.flags[#](#numpy-chararray-flags)
attribute

chararray.flags[#](#numpy.chararray.flags)
-
Information about the memory layout of the array.

Notes

The

object can be accessed dictionary-like (as in`flags`
`a.flags['WRITEABLE']`
), or by using lowercased attribute names (as in`a.flags.writeable`
). Short flag names are only supported in dictionary access.Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED flags can be changed by the user, via direct assignment to the attribute or dictionary entry, or by calling

.`ndarray.setflags`
The array flags cannot be set arbitrarily:

WRITEBACKIFCOPY can only be set

`False`
.
ALIGNED can only be set

`True`
if the data is truly aligned.
WRITEABLE can only be set

`True`
if the array owns its own memory or the ultimate owner of the memory exposes a writeable buffer interface or is a string.
Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.

Even for contiguous arrays a stride for a given dimension

`arr.strides[dim]`
may be*arbitrary*if`arr.shape[dim] == 1`
or the array has no elements. It does*not*generally hold that`self.strides[-1] == self.itemsize`
for C-style contiguous arrays or`self.strides[0] == self.itemsize`
for Fortran-style contiguous arrays is true.Attributes:
-
**C_CONTIGUOUS (C)**
The data is in a single, C-style contiguous segment.

**F_CONTIGUOUS (F)**
The data is in a single, Fortran-style contiguous segment.

**OWNDATA (O)**
The array owns the memory it uses or borrows it from another object.

**WRITEABLE (W)**
The data area can be written to. Setting this to False locks the data, making it read-only. A view (slice, etc.) inherits WRITEABLE from its base array at creation time, but a view of a writeable array may be subsequently locked while the base array remains writeable. (The opposite is not true, in that a view of a locked array may not be made writeable. However, currently, locking a base object does not lock any views that already reference it, so under that circumstance it is possible to alter the contents of a locked array via a previously created writeable view onto it.) Attempting to change a non-writeable array raises a RuntimeError exception.

**ALIGNED (A)**
The data and all elements are aligned appropriately for the hardware.

**WRITEBACKIFCOPY (X)**
This array is a copy of some other array. The C-API function PyArray_ResolveWritebackIfCopy must be called before deallocating to the base array will be updated with the contents of this array.

**FNC**
F_CONTIGUOUS and not C_CONTIGUOUS.

**FORC**
F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).

**BEHAVED (B)**
ALIGNED and WRITEABLE.

**CARRAY (CA)**
BEHAVED and C_CONTIGUOUS.

**FARRAY (FA)**
BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.# numpy.random.power[#](#numpy-random-power)
random.power(*a*,*size=None*)[#](#numpy.random.power)
-
Draws samples in [0, 1] from a power distribution with positive exponent a - 1.

Also known as the power function distribution.

Note

New code should use the

method of a`power`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**a**float or array_like of floats
Parameter of the distribution. Must be non-negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`a`
is a scalar. Otherwise,`np.array(a).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized power distribution.

Raises:
-
ValueError
-
If a <= 0.

See also

`random.Generator.power`
which should be used for new code.

Notes

The probability density function is

\[P(x; a) = ax^{a-1}, 0 \le x \le 1, a>0.\]The power function distribution is just the inverse of the Pareto distribution. It may also be seen as a special case of the Beta distribution.

It is used, for example, in modeling the over-reporting of insurance claims.

References

[1]Christian Kleiber, Samuel Kotz, “Statistical size distributions in economics and actuarial sciences”, Wiley, 2003.

[2]Heckert, N. A. and Filliben, James J. “NIST Handbook 148: Dataplot Reference Manual, Volume 2: Let Subcommands and Library Functions”, National Institute of Standards and Technology Handbook Series, June 2003.

[https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf](https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf)Examples

Draw samples from the distribution:

>>> a = 5. # shape >>> samples = 1000 >>> s = np.random.power(a, samples)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, bins=30) >>> x = np.linspace(0, 1, 100) >>> y = a*x**(a-1.) >>> normed_y = samples*np.diff(bins)[0]*y >>> plt.plot(x, normed_y) >>> plt.show()
Compare the power function distribution to the inverse of the Pareto.

>>> from scipy import stats >>> rvs = np.random.power(5, 1000000) >>> rvsp = np.random.pareto(5, 1000000) >>> xx = np.linspace(0,1,100) >>> powpdf = stats.powerlaw.pdf(xx,5)
>>> plt.figure() >>> plt.hist(rvs, bins=50, density=True) >>> plt.plot(xx,powpdf,'r-') >>> plt.title('np.random.power(5)')
>>> plt.figure() >>> plt.hist(1./(1.+rvsp), bins=50, density=True) >>> plt.plot(xx,powpdf,'r-') >>> plt.title('inverse of 1 + np.random.pareto(5)')
>>> plt.figure() >>> plt.hist(1./(1.+rvsp), bins=50, density=True) >>> plt.plot(xx,powpdf,'r-') >>> plt.title('inverse of stats.pareto(5)')# numpy.matrix.nonzero[#](#numpy-matrix-nonzero)
method

matrix.nonzero()[#](#numpy.matrix.nonzero)
-
Return the indices of the elements that are non-zero.

Refer to

for full documentation.`numpy.nonzero`
See also

`numpy.nonzero`
equivalent function

method

Return the indices of the elements that are non-zero.

Refer to [ numpy.nonzero](numpy.nonzero.html#numpy.nonzero) for full documentation.

See also

`numpy.nonzero`
equivalent function# numpy.random.Generator.multivariate_hypergeometric[#](#numpy-random-generator-multivariate-hypergeometric)
method

random.Generator.multivariate_hypergeometric(*colors*,*nsample*,*size=None*,*method='marginals'*)[#](#numpy.random.Generator.multivariate_hypergeometric)
-
Generate variates from a multivariate hypergeometric distribution.

The multivariate hypergeometric distribution is a generalization of the hypergeometric distribution.

Choose

`nsample`
items at random without replacement from a collection with`N`
distinct types.`N`
is the length of`colors`
, and the values in`colors`
are the number of occurrences of that type in the collection. The total number of items in the collection is`sum(colors)`
. Each random variate generated by this function is a vector of length`N`
holding the counts of the different types that occurred in the`nsample`
items.The name

`colors`
comes from a common description of the distribution: it is the probability distribution of the number of marbles of each color selected without replacement from an urn containing marbles of different colors;`colors[i]`
is the number of marbles in the urn with color`i`
.Parameters:
-
**colors**sequence of integers
The number of each type of item in the collection from which a sample is drawn. The values in

`colors`
must be nonnegative. To avoid loss of precision in the algorithm,`sum(colors)`
must be less than`10**9`
when*method*is “marginals”.
**nsample**int
The number of items selected.

`nsample`
must not be greater than`sum(colors)`
.
**size**int or tuple of ints, optional
The number of variates to generate, either an integer or a tuple holding the shape of the array of variates. If the given size is, e.g.,

`(k, m)`
, then`k * m`
variates are drawn, where one variate is a vector of length`len(colors)`
, and the return value has shape`(k, m, len(colors))`
. If`size`
is an integer, the output has shape`(size, len(colors))`
. Default is None, in which case a single variate is returned as an array with shape`(len(colors),)`
.
**method**string, optional
Specify the algorithm that is used to generate the variates. Must be ‘count’ or ‘marginals’ (the default). See the Notes for a description of the methods.

Returns:
-
**variates**ndarray
Array of variates drawn from the multivariate hypergeometric distribution.

See also

`hypergeometric`
Draw samples from the (univariate) hypergeometric distribution.

Notes

The two methods do not return the same sequence of variates.

The “count” algorithm is roughly equivalent to the following numpy code:

choices = np.repeat(np.arange(len(colors)), colors) selection = np.random.choice(choices, nsample, replace=False) variate = np.bincount(selection, minlength=len(colors))
The “count” algorithm uses a temporary array of integers with length

`sum(colors)`
.The “marginals” algorithm generates a variate by using repeated calls to the univariate hypergeometric sampler. It is roughly equivalent to:

variate = np.zeros(len(colors), dtype=np.int64) # `remaining` is the cumulative sum of `colors` from the last # element to the first; e.g. if `colors` is [3, 1, 5], then # `remaining` is [9, 6, 5]. remaining = np.cumsum(colors[::-1])[::-1] for i in range(len(colors)-1): if nsample < 1: break variate[i] = hypergeometric(colors[i], remaining[i+1], nsample) nsample -= variate[i] variate[-1] = nsample
The default method is “marginals”. For some cases (e.g. when

*colors*contains relatively small integers), the “count” method can be significantly faster than the “marginals” method. If performance of the algorithm is important, test the two methods with typical inputs to decide which works best.New in version 1.18.0.

Examples

>>> colors = [16, 8, 4] >>> seed = 4861946401452 >>> gen = np.random.Generator(np.random.PCG64(seed)) >>> gen.multivariate_hypergeometric(colors, 6) array([5, 0, 1]) >>> gen.multivariate_hypergeometric(colors, 6, size=3) array([[5, 0, 1], [2, 2, 2], [3, 3, 0]]) >>> gen.multivariate_hypergeometric(colors, 6, size=(2, 2)) array([[[3, 2, 1], [3, 2, 1]], [[4, 1, 1], [3, 2, 1]]])ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__str__

method

Return str(self).# numpy.polynomial.laguerre.lagmul[#](#numpy-polynomial-laguerre-lagmul)
polynomial.laguerre.lagmul(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L442-L505)[#](#numpy.polynomial.laguerre.lagmul)
-
Multiply one Laguerre series by another.

Returns the product of two Laguerre series

*c1***c2*. The arguments are sequences of coefficients, from lowest order “term” to highest, e.g., [1,2,3] represents the series`P_0 + 2*P_1 + 3*P_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Laguerre series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Of Laguerre series coefficients representing their product.

Notes

In general, the (polynomial) product of two C-series results in terms that are not in the Laguerre polynomial basis set. Thus, to express the product as a Laguerre series, it is necessary to “reproject” the product onto said basis set, which may produce “unintuitive” (but correct) results; see Examples section below.

Examples

>>> from numpy.polynomial.laguerre import lagmul >>> lagmul([1, 2, 3], [0, 1, 2]) array([ 8., -13., 38., -51., 36.])ndarray

dtype

ufunc

numpy.typing

numpy.distutils

generic.size

attribute

The number of elements in the gentype.numpy.ma.MaskType.all# method ma.MaskType.all()# Scalar method identical to the corresponding array attribute. Please see ndarray.all.# numpy.fft.fft[#](#numpy-fft-fft)
fft.fft(*a*,*n=None*,*axis=-1*,*norm=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/fft/_pocketfft.py#L122-L216)[#](#numpy.fft.fft)
-
Compute the one-dimensional discrete Fourier Transform.

This function computes the one-dimensional

*n*-point discrete Fourier Transform (DFT) with the efficient Fast Fourier Transform (FFT) algorithm [CT].Parameters:
-
**a**array_like
Input array, can be complex.

**n**int, optional
Length of the transformed axis of the output. If

*n*is smaller than the length of the input, the input is cropped. If it is larger, the input is padded with zeros. If*n*is not given, the length of the input along the axis specified by*axis*is used.
**axis**int, optional
Axis over which to compute the FFT. If not given, the last axis is used.

**norm**{“backward”, “ortho”, “forward”}, optional
New in version 1.10.0.

Normalization mode (see

). Default is “backward”. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.`numpy.fft`
New in version 1.20.0: The “backward”, “forward” values were added.

Returns:
-
**out**complex ndarray
The truncated or zero-padded input, transformed along the axis indicated by

*axis*, or the last one if*axis*is not specified.
Raises:
-
IndexError
-
If

*axis*is not a valid axis of*a*.
See also

Notes

FFT (Fast Fourier Transform) refers to a way the discrete Fourier Transform (DFT) can be calculated efficiently, by using symmetries in the calculated terms. The symmetry is highest when

*n*is a power of 2, and the transform is therefore most efficient for these sizes.The DFT is defined, with the conventions used in this implementation, in the documentation for the

module.`numpy.fft`
References

[CT]Cooley, James W., and John W. Tukey, 1965, “An algorithm for the machine calculation of complex Fourier series,”

*Math. Comput.*19: 297-301.Examples

>>> np.fft.fft(np.exp(2j * np.pi * np.arange(8) / 8)) array([-2.33486982e-16+1.14423775e-17j, 8.00000000e+00-1.25557246e-15j, 2.33486982e-16+2.33486982e-16j, 0.00000000e+00+1.22464680e-16j, -1.14423775e-17+2.33486982e-16j, 0.00000000e+00+5.20784380e-16j, 1.14423775e-17+1.14423775e-17j, 0.00000000e+00+1.22464680e-16j])
In this example, real input has an FFT which is Hermitian, i.e., symmetric in the real part and anti-symmetric in the imaginary part, as described in the

documentation:`numpy.fft`
>>> import matplotlib.pyplot as plt >>> t = np.arange(256) >>> sp = np.fft.fft(np.sin(t)) >>> freq = np.fft.fftfreq(t.shape[-1]) >>> plt.plot(freq, sp.real, freq, sp.imag) [<matplotlib.lines.Line2D object at 0x...>, <matplotlib.lines.Line2D object at 0x...>] >>> plt.show()# numpy.get_printoptions[#](#numpy-get-printoptions)
numpy.get_printoptions()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/arrayprint.py#L295-L326)[#](#numpy.get_printoptions)
-
Return the current print options.

Returns:
-
**print_opts**dict
Dictionary of current print options with keys

precision : int

threshold : int

edgeitems : int

linewidth : int

suppress : bool

nanstr : str

infstr : str

formatter : dict of callables

sign : str

For a full description of these options, see

.`set_printoptions`
See alsonumpy.record.prod# method record.prod()# Scalar method identical to the corresponding array attribute. Please see ndarray.prod.# numpy.polynomial.polynomial.polyx[#](#numpy-polynomial-polynomial-polyx)
polynomial.polynomial.polyx*= array([0, 1])*[#](#numpy.polynomial.polynomial.polyx)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.ma.masked_array.count[#](#numpy-ma-masked-array-count)
method

ma.masked_array.count(*axis=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4525-L4622)[#](#numpy.ma.masked_array.count)
-
Count the non-masked elements of the array along the given axis.

Parameters:
-
**axis**None or int or tuple of ints, optional
Axis or axes along which the count is performed. The default, None, performs the count over all the dimensions of the input array.

*axis*may be negative, in which case it counts from the last to the first axis.New in version 1.10.0.

If this is a tuple of ints, the count is performed on multiple axes, instead of a single axis or all the axes as before.

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.

Returns:
-
**result**ndarray or scalar
An array with the same shape as the input array, with the specified axis removed. If the array is a 0-d array, or if

*axis*is None, a scalar is returned.
See also

`ma.count_masked`
Count masked elements in array or along a given axis.

Examples

>>> import numpy.ma as ma >>> a = ma.arange(6).reshape((2, 3)) >>> a[1, :] = ma.masked >>> a masked_array( data=[[0, 1, 2], [--, --, --]], mask=[[False, False, False], [ True, True, True]], fill_value=999999) >>> a.count() 3
When the

*axis*keyword is specified an array of appropriate size is returned.>>> a.count(axis=0) array([1, 1, 1]) >>> a.count(axis=1) array([3, 0])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__repr__
numpy.ndarray.__repr__
#
method
ndarray.
__repr__
(
/
)
#
Return repr(self).# numpy.random.Generator.power[#](#numpy-random-generator-power)
method

random.Generator.power(*a*,*size=None*)[#](#numpy.random.Generator.power)
-
Draws samples in [0, 1] from a power distribution with positive exponent a - 1.

Also known as the power function distribution.

Parameters:
-
**a**float or array_like of floats
Parameter of the distribution. Must be non-negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`a`
is a scalar. Otherwise,`np.array(a).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized power distribution.

Raises:
-
ValueError
-
If a <= 0.

Notes

The probability density function is

\[P(x; a) = ax^{a-1}, 0 \le x \le 1, a>0.\]The power function distribution is just the inverse of the Pareto distribution. It may also be seen as a special case of the Beta distribution.

It is used, for example, in modeling the over-reporting of insurance claims.

References

[1]Christian Kleiber, Samuel Kotz, “Statistical size distributions in economics and actuarial sciences”, Wiley, 2003.

[2]Heckert, N. A. and Filliben, James J. “NIST Handbook 148: Dataplot Reference Manual, Volume 2: Let Subcommands and Library Functions”, National Institute of Standards and Technology Handbook Series, June 2003.

[https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf](https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf)Examples

Draw samples from the distribution:

>>> rng = np.random.default_rng() >>> a = 5. # shape >>> samples = 1000 >>> s = rng.power(a, samples)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, bins=30) >>> x = np.linspace(0, 1, 100) >>> y = a*x**(a-1.) >>> normed_y = samples*np.diff(bins)[0]*y >>> plt.plot(x, normed_y) >>> plt.show()
Compare the power function distribution to the inverse of the Pareto.

>>> from scipy import stats >>> rvs = rng.power(5, 1000000) >>> rvsp = rng.pareto(5, 1000000) >>> xx = np.linspace(0,1,100) >>> powpdf = stats.powerlaw.pdf(xx,5)
>>> plt.figure() >>> plt.hist(rvs, bins=50, density=True) >>> plt.plot(xx,powpdf,'r-') >>> plt.title('power(5)')
>>> plt.figure() >>> plt.hist(1./(1.+rvsp), bins=50, density=True) >>> plt.plot(xx,powpdf,'r-') >>> plt.title('inverse of 1 + Generator.pareto(5)')
>>> plt.figure() >>> plt.hist(1./(1.+rvsp), bins=50, density=True) >>> plt.plot(xx,powpdf,'r-') >>> plt.title('inverse of stats.pareto(5)')# numpy.polynomial.polynomial.Polynomial.linspace[#](#numpy-polynomial-polynomial-polynomial-linspace)
method

polynomial.polynomial.Polynomial.linspace(*n=100*,*domain=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L923-L953)[#](#numpy.polynomial.polynomial.Polynomial.linspace)
-
Return x, y values at equally spaced points in domain.

Returns the x, y values at

*n*linearly spaced points across the domain. Here y is the value of the polynomial at the points x. By default the domain is the same as that of the series instance. This method is intended mostly as a plotting aid.New in version 1.5.0.

Parameters:
-
**n**int, optional
Number of point pairs to return. The default value is 100.

**domain**{None, array_like}, optional
If not None, the specified domain is used instead of that of the calling instance. It should be of the form

`[beg,end]`
. The default is None which case the class domain is used.
Returns:
-
**x, y**ndarray
x is equal to linspace(self.domain[0], self.domain[1], n) and y is the series evaluated at element of x.# numpy.polynomial.chebyshev.chebgrid3d[#](#numpy-polynomial-chebyshev-chebgrid3d)
polynomial.chebyshev.chebgrid3d(*x*,*y*,*z*,*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L1331-L1384)[#](#numpy.polynomial.chebyshev.chebgrid3d)
-
Evaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.

This function returns the values:

\[p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * T_i(a) * T_j(b) * T_k(c)\]where the points

*(a, b, c)*consist of all triples formed by taking*a*from*x*,*b*from*y*, and*c*from*z*. The resulting points form a grid with*x*in the first dimension,*y*in the second, and*z*in the third.The parameters

*x*,*y*, and*z*are converted to arrays only if they are tuples or a lists, otherwise they are treated as a scalars. In either case, either*x*,*y*, and*z*or their elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*has fewer than three dimensions, ones are implicitly appended to its shape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape + y.shape + z.shape.Parameters:
-
**x, y, z**array_like, compatible objects
The three dimensional series is evaluated at the points in the Cartesian product of

*x*,*y*, and*z*. If*x*,`y`, or*z*is a list or tuple, it is first converted to an ndarray, otherwise it is left unchanged and, if it isn’t an ndarray, it is treated as a scalar.
**c**array_like
Array of coefficients ordered so that the coefficients for terms of degree i,j are contained in

`c[i,j]`
. If*c*has dimension greater than two the remaining indices enumerate multiple sets of coefficients.
Returns:
-
**values**ndarray, compatible object
The values of the two dimensional polynomial at points in the Cartesian product of

*x*and*y*.
See also

Notes

New in version 1.7.0.# numpy.from_dlpack[#](#numpy-from-dlpack)
numpy.from_dlpack(*x*,*/*)[#](#numpy.from_dlpack)
-
Create a NumPy array from an object implementing the

`__dlpack__`
protocol. Generally, the returned NumPy array is a read-only view of the input object. See[[1]](#re9eadf7a166b-1)and[[2]](#re9eadf7a166b-2)for more details.Parameters:
-
**x**object
A Python object that implements the

`__dlpack__`
and`__dlpack_device__`
methods.
Returns:
-
**out**ndarray
References

[[1](#id1)]Array API documentation,

[https://data-apis.org/array-api/latest/design_topics/data_interchange.html#syntax-for-data-interchange-with-dlpack](https://data-apis.org/array-api/latest/design_topics/data_interchange.html#syntax-for-data-interchange-with-dlpack)[[2](#id2)]Python specification for DLPack,

[https://dmlc.github.io/dlpack/latest/python_spec.html](https://dmlc.github.io/dlpack/latest/python_spec.html)Examples

>>> import torch >>> x = torch.arange(10) >>> # create a view of the torch tensor "x" in NumPy >>> y = np.from_dlpack(x)# numpy.memmap.flags[#](#numpy-memmap-flags)
attribute

memmap.flags[#](#numpy.memmap.flags)
-
Information about the memory layout of the array.

Notes

The

object can be accessed dictionary-like (as in`flags`
`a.flags['WRITEABLE']`
), or by using lowercased attribute names (as in`a.flags.writeable`
). Short flag names are only supported in dictionary access.Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED flags can be changed by the user, via direct assignment to the attribute or dictionary entry, or by calling

.`ndarray.setflags`
The array flags cannot be set arbitrarily:

WRITEBACKIFCOPY can only be set

`False`
.
ALIGNED can only be set

`True`
if the data is truly aligned.
WRITEABLE can only be set

`True`
if the array owns its own memory or the ultimate owner of the memory exposes a writeable buffer interface or is a string.
Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.

Even for contiguous arrays a stride for a given dimension

`arr.strides[dim]`
may be*arbitrary*if`arr.shape[dim] == 1`
or the array has no elements. It does*not*generally hold that`self.strides[-1] == self.itemsize`
for C-style contiguous arrays or`self.strides[0] == self.itemsize`
for Fortran-style contiguous arrays is true.Attributes:
-
**C_CONTIGUOUS (C)**
The data is in a single, C-style contiguous segment.

**F_CONTIGUOUS (F)**
The data is in a single, Fortran-style contiguous segment.

**OWNDATA (O)**
The array owns the memory it uses or borrows it from another object.

**WRITEABLE (W)**
The data area can be written to. Setting this to False locks the data, making it read-only. A view (slice, etc.) inherits WRITEABLE from its base array at creation time, but a view of a writeable array may be subsequently locked while the base array remains writeable. (The opposite is not true, in that a view of a locked array may not be made writeable. However, currently, locking a base object does not lock any views that already reference it, so under that circumstance it is possible to alter the contents of a locked array via a previously created writeable view onto it.) Attempting to change a non-writeable array raises a RuntimeError exception.

**ALIGNED (A)**
The data and all elements are aligned appropriately for the hardware.

**WRITEBACKIFCOPY (X)**
This array is a copy of some other array. The C-API function PyArray_ResolveWritebackIfCopy must be called before deallocating to the base array will be updated with the contents of this array.

**FNC**
F_CONTIGUOUS and not C_CONTIGUOUS.

**FORC**
F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).

**BEHAVED (B)**
ALIGNED and WRITEABLE.

**CARRAY (CA)**
BEHAVED and C_CONTIGUOUS.

**FARRAY (FA)**
BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.# numpy.dtype.newbyteorder[#](#numpy-dtype-newbyteorder)
method

dtype.newbyteorder(*new_order='S'*,*/*)[#](#numpy.dtype.newbyteorder)
-
Return a new dtype with a different byte order.

Changes are also made in all fields and sub-arrays of the data type.

Parameters:
-
**new_order**string, optional
Byte order to force; a value from the byte order specifications below. The default value (‘S’) results in swapping the current byte order.

*new_order*codes can be any of:‘S’ - swap dtype from current to opposite endian

{‘<’, ‘little’} - little endian

{‘>’, ‘big’} - big endian

{‘=’, ‘native’} - native order

{‘|’, ‘I’} - ignore (no change to byte order)

Returns:
-
**new_dtype**dtype
New dtype object with the given change to the byte order.

Notes

Changes are also made in all fields and sub-arrays of the data type.

Examples

>>> import sys >>> sys_is_le = sys.byteorder == 'little' >>> native_code = '<' if sys_is_le else '>' >>> swapped_code = '>' if sys_is_le else '<' >>> native_dt = np.dtype(native_code+'i2') >>> swapped_dt = np.dtype(swapped_code+'i2') >>> native_dt.newbyteorder('S') == swapped_dt True >>> native_dt.newbyteorder() == swapped_dt True >>> native_dt == swapped_dt.newbyteorder('S') True >>> native_dt == swapped_dt.newbyteorder('=') True >>> native_dt == swapped_dt.newbyteorder('N') True >>> native_dt == native_dt.newbyteorder('|') True >>> np.dtype('<i2') == native_dt.newbyteorder('<') True >>> np.dtype('<i2') == native_dt.newbyteorder('L') True >>> np.dtype('>i2') == native_dt.newbyteorder('>') True >>> np.dtype('>i2') == native_dt.newbyteorder('B') Truenumpy.dtype.isnative# attribute dtype.isnative# Boolean indicating whether the byte order of this dtype is native to the platform.# numpy.polynomial.legendre.Legendre.linspace[#](#numpy-polynomial-legendre-legendre-linspace)
method

polynomial.legendre.Legendre.linspace(*n=100*,*domain=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L923-L953)[#](#numpy.polynomial.legendre.Legendre.linspace)
-
Return x, y values at equally spaced points in domain.

Returns the x, y values at

*n*linearly spaced points across the domain. Here y is the value of the polynomial at the points x. By default the domain is the same as that of the series instance. This method is intended mostly as a plotting aid.New in version 1.5.0.

Parameters:
-
**n**int, optional
Number of point pairs to return. The default value is 100.

**domain**{None, array_like}, optional
If not None, the specified domain is used instead of that of the calling instance. It should be of the form

`[beg,end]`
. The default is None which case the class domain is used.
Returns:
-
**x, y**ndarray
x is equal to linspace(self.domain[0], self.domain[1], n) and y is the series evaluated at element of x.# numpy.issubsctype[#](#numpy-issubsctype)
numpy.issubsctype(*arg1*,*arg2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numerictypes.py#L325-L354)[#](#numpy.issubsctype)
-
Determine if the first argument is a subclass of the second argument.

Parameters:
-
**arg1, arg2**dtype or dtype specifier
Data-types.

Returns:
-
**out**bool
The result.

See also

Examples

>>> np.issubsctype('S8', str) False >>> np.issubsctype(np.array([1]), int) True >>> np.issubsctype(np.array([1]), float) Falsenumpy.ndarray.__array__# method ndarray.__array__([dtype, ]/)# Returns either a new reference to self if dtype is not given or a new array of provided data type if dtype is different from the current dtype of the array.numpy.distutils.ccompiler_opt.CCompilerOpt.feature_is_exist# method distutils.ccompiler_opt.CCompilerOpt.feature_is_exist(name)[source]# Returns True if a certain feature is exist and covered within _Config.conf_features. Parameters: ‘name’: strfeature name in uppercase.# numpy.ma.MaskedArray.filled[#](#numpy-ma-maskedarray-filled)
method

ma.MaskedArray.filled(*fill_value=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L3786-L3864)[#](#numpy.ma.MaskedArray.filled)
-
Return a copy of self, with masked values filled with a given value.

**However**, if there are no masked values to fill, self will be returned instead as an ndarray.Parameters:
-
**fill_value**array_like, optional
The value to use for invalid entries. Can be scalar or non-scalar. If non-scalar, the resulting ndarray must be broadcastable over input array. Default is None, in which case, the

attribute of the array is used instead.`fill_value`
Returns:
-
**filled_array**ndarray
A copy of

`self`
with invalid entries replaced by*fill_value*(be it the function argument or the attribute of`self`
), or`self`
itself as an ndarray if there are no invalid entries to be replaced.
Notes

The result is

**not**a MaskedArray!Examples

>>> x = np.ma.array([1,2,3,4,5], mask=[0,0,1,0,1], fill_value=-999) >>> x.filled() array([ 1, 2, -999, 4, -999]) >>> x.filled(fill_value=1000) array([ 1, 2, 1000, 4, 1000]) >>> type(x.filled()) <class 'numpy.ndarray'>
Subclassing is preserved. This means that if, e.g., the data part of the masked array is a recarray,

returns a recarray:`filled`
>>> x = np.array([(-1, 2), (-3, 4)], dtype='i8,i8').view(np.recarray) >>> m = np.ma.array(x, mask=[(True, False), (False, True)]) >>> m.filled() rec.array([(999999, 2), ( -3, 999999)], dtype=[('f0', '<i8'), ('f1', '<i8')])numpy.polynomial.hermite_e.HermiteE.window# attribute polynomial.hermite_e.HermiteE.window = array([-1, 1])#ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__irshift__

method

Return self>>=value.# numpy.polynomial.legendre.Legendre.integ[#](#numpy-polynomial-legendre-legendre-integ)
method

polynomial.legendre.Legendre.integ(*m=1*,*k=[]*,*lbnd=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L853-L884)[#](#numpy.polynomial.legendre.Legendre.integ)
-
Integrate.

Return a series instance that is the definite integral of the current series.

Parameters:
-
**m**non-negative int
The number of integrations to perform.

**k**array_like
Integration constants. The first constant is applied to the first integration, the second to the second, and so on. The list of values must less than or equal to

*m*in length and any missing values are set to zero.
**lbnd**Scalar
The lower bound of the definite integral.

Returns:
-
**new_series**series
A new series representing the integral. The domain is the same as the domain of the integrated series.# numpy.lcm[#](#numpy-lcm)
numpy.lcm(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'lcm'>*[#](#numpy.lcm)
-
Returns the lowest common multiple of

`|x1|`
and`|x2|`
Parameters:
-
**x1, x2**array_like, int
Arrays of values. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
Returns:
-
**y**ndarray or scalar
The lowest common multiple of the absolute value of the inputs This is a scalar if both

*x1*and*x2*are scalars.
See also

`gcd`
The greatest common divisor

Examples

>>> np.lcm(12, 20) 60 >>> np.lcm.reduce([3, 12, 20]) 60 >>> np.lcm.reduce([40, 12, 20]) 120 >>> np.lcm(np.arange(6), 20) array([ 0, 20, 20, 60, 20, 20])# numpy.polynomial.chebyshev.chebvander2d[#](#numpy-polynomial-chebyshev-chebvander2d)
polynomial.chebyshev.chebvander2d(*x*,*y*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L1440-L1490)[#](#numpy.polynomial.chebyshev.chebvander2d)
-
Pseudo-Vandermonde matrix of given degrees.

Returns the pseudo-Vandermonde matrix of degrees

*deg*and sample points*(x, y)*. The pseudo-Vandermonde matrix is defined by\[V[..., (deg[1] + 1)*i + j] = T_i(x) * T_j(y),\]where

*0 <= i <= deg[0]*and*0 <= j <= deg[1]*. The leading indices of*V*index the points*(x, y)*and the last index encodes the degrees of the Chebyshev polynomials.If

`V = chebvander2d(x, y, [xdeg, ydeg])`
, then the columns of*V*correspond to the elements of a 2-D coefficient array*c*of shape (xdeg + 1, ydeg + 1) in the order\[c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...\]and

`np.dot(V, c.flat)`
and`chebval2d(x, y, c)`
will be the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of 2-D Chebyshev series of the same degrees and sample points.Parameters:
-
**x, y**array_like
Arrays of point coordinates, all of the same shape. The dtypes will be converted to either float64 or complex128 depending on whether any of the elements are complex. Scalars are converted to 1-D arrays.

**deg**list of ints
List of maximum degrees of the form [x_deg, y_deg].

Returns:
-
**vander2d**ndarray
The shape of the returned matrix is

`x.shape + (order,)`
, where \(order = (deg[0]+1)*(deg[1]+1)\). The dtype will be the same as the converted*x*and*y*.
See also

Notes

New in version 1.7.0.numpy.matrix.itemsize# attribute matrix.itemsize# Length of one array element in bytes. Examples >>> x = np.array([1,2,3], dtype=np.float64) >>> x.itemsize 8 >>> x = np.array([1,2,3], dtype=np.complex128) >>> x.itemsize 16# numpy.polynomial.hermite_e.hermetrim[#](#numpy-polynomial-hermite-e-hermetrim)
polynomial.hermite_e.hermetrim(*c*,*tol=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polyutils.py#L160-L212)[#](#numpy.polynomial.hermite_e.hermetrim)
-
Remove “small” “trailing” coefficients from a polynomial.

“Small” means “small in absolute value” and is controlled by the parameter

*tol*; “trailing” means highest order coefficient(s), e.g., in`[0, 1, 1, 0, 0]`
(which represents`0 + x + x**2 + 0*x**3 + 0*x**4`
) both the 3-rd and 4-th order coefficients would be “trimmed.”Parameters:
-
**c**array_like
1-d array of coefficients, ordered from lowest order to highest.

**tol**number, optional
Trailing (i.e., highest order) elements with absolute value less than or equal to

*tol*(default value is zero) are removed.
Returns:
-
**trimmed**ndarray
1-d array with trailing zeros removed. If the resulting series would be empty, a series containing a single zero is returned.

Raises:
-
ValueError
-
If

*tol*< 0
See also

`trimseq`
Examples

>>> from numpy.polynomial import polyutils as pu >>> pu.trimcoef((0,0,3,0,5,0,0)) array([0., 0., 3., 0., 5.]) >>> pu.trimcoef((0,0,1e-3,0,1e-5,0,0),1e-3) # item == tol is trimmed array([0.]) >>> i = complex(0,1) # works for complex >>> pu.trimcoef((3e-4,1e-3*(1-i),5e-4,2e-5*(1+i)), 1e-3) array([0.0003+0.j , 0.001 -0.001j])# numpy.bitwise_xor[#](#numpy-bitwise-xor)
numpy.bitwise_xor(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'bitwise_xor'>*[#](#numpy.bitwise_xor)
-
Compute the bit-wise XOR of two arrays element-wise.

Computes the bit-wise XOR of the underlying binary representation of the integers in the input arrays. This ufunc implements the C/Python operator

`^`
.Parameters:
-
**x1, x2**array_like
Only integer and boolean types are handled. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray or scalar
Result. This is a scalar if both

*x1*and*x2*are scalars.
See also

`logical_xor`
`bitwise_and`
`bitwise_or`
`binary_repr`
Return the binary representation of the input number as a string.

Examples

The number 13 is represented by

`00001101`
. Likewise, 17 is represented by`00010001`
. The bit-wise XOR of 13 and 17 is therefore`00011100`
, or 28:>>> np.bitwise_xor(13, 17) 28 >>> np.binary_repr(28) '11100'
>>> np.bitwise_xor(31, 5) 26 >>> np.bitwise_xor([31,3], 5) array([26, 6])
>>> np.bitwise_xor([31,3], [5,6]) array([26, 5]) >>> np.bitwise_xor([True, True], [False, True]) array([ True, False])
The

`^`
operator can be used as a shorthand for`np.bitwise_xor`
on ndarrays.>>> x1 = np.array([True, True]) >>> x2 = np.array([False, True]) >>> x1 ^ x2 array([ True, False])# numpy.memmap.trace[#](#numpy-memmap-trace)
method

memmap.trace(*offset=0*,*axis1=0*,*axis2=1*,*dtype=None*,*out=None*)[#](#numpy.memmap.trace)
-
Return the sum along diagonals of the array.

Refer to

for full documentation.`numpy.trace`
See also

`numpy.trace`
equivalent function

method

Return the sum along diagonals of the array.

Refer to [ numpy.trace](numpy.trace.html#numpy.trace) for full documentation.

See also

`numpy.trace`
equivalent function# numpy.char.chararray.byteswap[#](#numpy-char-chararray-byteswap)
method

char.chararray.byteswap(*inplace=False*)[#](#numpy.char.chararray.byteswap)
-
Swap the bytes of the array elements

Toggle between low-endian and big-endian data representation by returning a byteswapped array, optionally swapped in-place. Arrays of byte-strings are not swapped. The real and imaginary parts of a complex number are swapped individually.

Parameters:
-
**inplace**bool, optional
If

`True`
, swap bytes in-place, default is`False`
.
Returns:
-
**out**ndarray
The byteswapped array. If

*inplace*is`True`
, this is a view to self.
Examples

>>> A = np.array([1, 256, 8755], dtype=np.int16) >>> list(map(hex, A)) ['0x1', '0x100', '0x2233'] >>> A.byteswap(inplace=True) array([ 256, 1, 13090], dtype=int16) >>> list(map(hex, A)) ['0x100', '0x1', '0x3322']
Arrays of byte-strings are not swapped

>>> A = np.array([b'ceg', b'fac']) >>> A.byteswap() array([b'ceg', b'fac'], dtype='|S3')
`A.newbyteorder().byteswap()`
produces an array with the same values
but different representation in memory

>>> A = np.array([1, 2, 3]) >>> A.view(np.uint8) array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0], dtype=uint8) >>> A.newbyteorder().byteswap(inplace=True) array([1, 2, 3]) >>> A.view(np.uint8) array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3], dtype=uint8)# numpy.polynomial.hermite_e.hermepow[#](#numpy-polynomial-hermite-e-hermepow)
polynomial.hermite_e.hermepow(*c*,*pow*,*maxpower=16*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L553-L587)[#](#numpy.polynomial.hermite_e.hermepow)
-
Raise a Hermite series to a power.

Returns the Hermite series

*c*raised to the power*pow*. The argument*c*is a sequence of coefficients ordered from low to high. i.e., [1,2,3] is the series`P_0 + 2*P_1 + 3*P_2.`
Parameters:
-
**c**array_like
1-D array of Hermite series coefficients ordered from low to high.

**pow**integer
Power to which the series will be raised

**maxpower**integer, optional
Maximum power allowed. This is mainly to limit growth of the series to unmanageable size. Default is 16

Returns:
-
**coef**ndarray
Hermite series of power.

Examples

>>> from numpy.polynomial.hermite_e import hermepow >>> hermepow([1, 2, 3], 2) array([23., 28., 46., 12., 9.])# numpy.polynomial.laguerre.Laguerre.integ[#](#numpy-polynomial-laguerre-laguerre-integ)
method

polynomial.laguerre.Laguerre.integ(*m=1*,*k=[]*,*lbnd=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L853-L884)[#](#numpy.polynomial.laguerre.Laguerre.integ)
-
Integrate.

Return a series instance that is the definite integral of the current series.

Parameters:
-
**m**non-negative int
The number of integrations to perform.

**k**array_like
Integration constants. The first constant is applied to the first integration, the second to the second, and so on. The list of values must less than or equal to

*m*in length and any missing values are set to zero.
**lbnd**Scalar
The lower bound of the definite integral.

Returns:
-
**new_series**series
A new series representing the integral. The domain is the same as the domain of the integrated series.# numpy.random.RandomState.standard_cauchy[#](#numpy-random-randomstate-standard-cauchy)
method

random.RandomState.standard_cauchy(*size=None*)[#](#numpy.random.RandomState.standard_cauchy)
-
Draw samples from a standard Cauchy distribution with mode = 0.

Also known as the Lorentz distribution.

Note

New code should use the

method of a`standard_cauchy`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**samples**ndarray or scalar
The drawn samples.

See also

`random.Generator.standard_cauchy`
which should be used for new code.

Notes

The probability density function for the full Cauchy distribution is

\[P(x; x_0, \gamma) = \frac{1}{\pi \gamma \bigl[ 1+ (\frac{x-x_0}{\gamma})^2 \bigr] }\]and the Standard Cauchy distribution just sets \(x_0=0\) and \(\gamma=1\)

The Cauchy distribution arises in the solution to the driven harmonic oscillator problem, and also describes spectral line broadening. It also describes the distribution of values at which a line tilted at a random angle will cut the x axis.

When studying hypothesis tests that assume normality, seeing how the tests perform on data from a Cauchy distribution is a good indicator of their sensitivity to a heavy-tailed distribution, since the Cauchy looks very much like a Gaussian distribution, but with heavier tails.

References

[1]NIST/SEMATECH e-Handbook of Statistical Methods, “Cauchy Distribution”,

[https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm)[2]Weisstein, Eric W. “Cauchy Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/CauchyDistribution.html](http://mathworld.wolfram.com/CauchyDistribution.html)[3]Wikipedia, “Cauchy distribution”

[https://en.wikipedia.org/wiki/Cauchy_distribution](https://en.wikipedia.org/wiki/Cauchy_distribution)Examples

Draw samples and plot the distribution:

>>> import matplotlib.pyplot as plt >>> s = np.random.standard_cauchy(1000000) >>> s = s[(s>-25) & (s<25)] # truncate distribution so it plots well >>> plt.hist(s, bins=100) >>> plt.show()# numpy.char.chararray.strip[#](#numpy-char-chararray-strip)
method

char.chararray.strip(*chars=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2630-L2640)[#](#numpy.char.chararray.strip)
-
For each element in

*self*, return a copy with the leading and trailing characters removed.See also

method

For each element in *self*, return a copy with the leading and
trailing characters removed.

See also# numpy.linspace[#](#numpy-linspace)
numpy.linspace(*start*,*stop*,*num=50*,*endpoint=True*,*retstep=False*,*dtype=None*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/function_base.py#L24-L182)[#](#numpy.linspace)
-
Return evenly spaced numbers over a specified interval.

Returns

*num*evenly spaced samples, calculated over the interval [*start*,*stop*].The endpoint of the interval can optionally be excluded.

Changed in version 1.16.0: Non-scalar

*start*and*stop*are now supported.Changed in version 1.20.0: Values are rounded towards

`-inf`
instead of`0`
when an integer`dtype`
is specified. The old behavior can still be obtained with`np.linspace(start, stop, num).astype(int)`
Parameters:
-
**start**array_like
The starting value of the sequence.

**stop**array_like
The end value of the sequence, unless

*endpoint*is set to False. In that case, the sequence consists of all but the last of`num + 1`
evenly spaced samples, so that*stop*is excluded. Note that the step size changes when*endpoint*is False.
**num**int, optional
Number of samples to generate. Default is 50. Must be non-negative.

**endpoint**bool, optional
If True,

*stop*is the last sample. Otherwise, it is not included. Default is True.
**retstep**bool, optional
If True, return (

*samples*,*step*), where*step*is the spacing between samples.
**dtype**dtype, optional
The type of the output array. If

is not given, the data type is inferred from`dtype`
*start*and*stop*. The inferred dtype will never be an integer;*float*is chosen even if the arguments would produce an array of integers.New in version 1.9.0.

**axis**int, optional
The axis in the result to store the samples. Relevant only if start or stop are array-like. By default (0), the samples will be along a new axis inserted at the beginning. Use -1 to get an axis at the end.

New in version 1.16.0.

Returns:
-
**samples**ndarray
There are

*num*equally spaced samples in the closed interval`[start, stop]`
or the half-open interval`[start, stop)`
(depending on whether*endpoint*is True or False).
**step**float, optional
Only returned if

*retstep*is TrueSize of spacing between samples.

See also

`arange`
Similar to

, but uses a step size (instead of the number of samples).`linspace`
`geomspace`
Similar to

, but with numbers spaced evenly on a log scale (a geometric progression).`linspace`
`logspace`
Similar to

, but with the end points specified as logarithms.`geomspace`
[How to create arrays with regularly-spaced values](../../user/how-to-partition.html#how-to-partition)
Examples

>>> np.linspace(2.0, 3.0, num=5) array([2. , 2.25, 2.5 , 2.75, 3. ]) >>> np.linspace(2.0, 3.0, num=5, endpoint=False) array([2. , 2.2, 2.4, 2.6, 2.8]) >>> np.linspace(2.0, 3.0, num=5, retstep=True) (array([2. , 2.25, 2.5 , 2.75, 3. ]), 0.25)
Graphical illustration:

>>> import matplotlib.pyplot as plt >>> N = 8 >>> y = np.zeros(N) >>> x1 = np.linspace(0, 10, N, endpoint=True) >>> x2 = np.linspace(0, 10, N, endpoint=False) >>> plt.plot(x1, y, 'o') [<matplotlib.lines.Line2D object at 0x...>] >>> plt.plot(x2, y + 0.5, 'o') [<matplotlib.lines.Line2D object at 0x...>] >>> plt.ylim([-0.5, 1]) (-0.5, 1) >>> plt.show()# numpy.polynomial.legendre.Legendre.convert[#](#numpy-polynomial-legendre-legendre-convert)
method

polynomial.legendre.Legendre.convert(*domain=None*,*kind=None*,*window=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L787-L822)[#](#numpy.polynomial.legendre.Legendre.convert)
-
Convert series to a different kind and/or domain and/or window.

Parameters:
-
**domain**array_like, optional
The domain of the converted series. If the value is None, the default domain of

*kind*is used.
**kind**class, optional
The polynomial series type class to which the current instance should be converted. If kind is None, then the class of the current instance is used.

**window**array_like, optional
The window of the converted series. If the value is None, the default window of

*kind*is used.
Returns:
-
**new_series**series
The returned class can be of different type than the current instance and/or have a different domain and/or different window.

Notes

Conversion between domains and class types can result in numerically ill defined series.numpy.record.var# method record.var()# Scalar method identical to the corresponding array attribute. Please see ndarray.var.# numpy.matrix.I[#](#numpy-matrix-i)
property

*property*matrix.I[#](#numpy.matrix.I)
-
Returns the (multiplicative) inverse of invertible

*self*.Parameters:
-
**None**
Returns:
-
**ret**matrix object
If

*self*is non-singular,*ret*is such that`ret * self`
==`self * ret`
==`np.matrix(np.eye(self[0,:].size))`
all return`True`
.
Raises:
-
numpy.linalg.LinAlgError: Singular matrix
-
If

*self*is singular.
See also

Examples

>>> m = np.matrix('[1, 2; 3, 4]'); m matrix([[1, 2], [3, 4]]) >>> m.getI() matrix([[-2. , 1. ], [ 1.5, -0.5]]) >>> m.getI() * m matrix([[ 1., 0.], # may vary [ 0., 1.]])# numpy.ma.MaskedArray.sum[#](#numpy-ma-maskedarray-sum)
method

ma.MaskedArray.sum(*axis=None*,*dtype=None*,*out=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5130-L5190)[#](#numpy.ma.MaskedArray.sum)
-
Return the sum of the array elements over the given axis.

Masked elements are set to 0 internally.

Refer to

for full documentation.`numpy.sum`
See also

`numpy.ndarray.sum`
corresponding function for ndarrays

`numpy.sum`
equivalent function

Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.sum() 25 >>> x.sum(axis=1) masked_array(data=[4, 5, 16], mask=[False, False, False], fill_value=999999) >>> x.sum(axis=0) masked_array(data=[8, 5, 12], mask=[False, False, False], fill_value=999999) >>> print(type(x.sum(axis=0, dtype=np.int64)[0])) <class 'numpy.int64'># numpy.polynomial.chebyshev.Chebyshev.fromroots[#](#numpy-polynomial-chebyshev-chebyshev-fromroots)
method

*classmethod*polynomial.chebyshev.Chebyshev.fromroots(*roots*,*domain=[]*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1047-L1088)[#](#numpy.polynomial.chebyshev.Chebyshev.fromroots)
-
Return series instance that has the specified roots.

Returns a series representing the product

`(x - r[0])*(x - r[1])*...*(x - r[n-1])`
, where`r`
is a list of roots.Parameters:
-
**roots**array_like
List of roots.

**domain**{[], None, array_like}, optional
Domain for the resulting series. If None the domain is the interval from the smallest root to the largest. If [] the domain is the class domain. The default is [].

**window**{None, array_like}, optional
Window for the returned series. If None the class window is used. The default is None.

**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
Series with the specified roots.numpy.record.ptp# method record.ptp()# Scalar method identical to the corresponding array attribute. Please see ndarray.ptp.# numpy.ma.ones[#](#numpy-ma-ones)
ma.ones(*shape*,*dtype=None*,*order='C'*)*= <numpy.ma.core._convert2ma object>*[#](#numpy.ma.ones)
-
Return a new array of given shape and type, filled with ones.

Parameters:
-
**shape**int or sequence of ints
Shape of the new array, e.g.,

`(2, 3)`
or`2`
.
**dtype**data-type, optional
The desired data-type for the array, e.g.,

. Default is`numpy.int8`
.`numpy.float64`
**order**{‘C’, ‘F’}, optional, default: C
Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**out**MaskedArray
Array of ones with the given shape, dtype, and order.

See also

Examples

>>> np.ones(5) array([1., 1., 1., 1., 1.])
>>> np.ones((5,), dtype=int) array([1, 1, 1, 1, 1])
>>> np.ones((2, 1)) array([[1.], [1.]])
>>> s = (2,2) >>> np.ones(s) array([[1., 1.], [1., 1.]])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__irshift__
numpy.ndarray.__irshift__
#
method
ndarray.
__irshift__
(
value
,
/
)
#
Return self>>=value.numpy.ma.MaskedArray.tostring# method ma.MaskedArray.tostring(fill_value=None, order='C')[source]# A compatibility alias for tobytes, with exactly the same behavior. Despite its name, it returns bytes not strs. Deprecated since version 1.19.0.# numpy.random.RandomState.f[#](#numpy-random-randomstate-f)
method

random.RandomState.f(*dfnum*,*dfden*,*size=None*)[#](#numpy.random.RandomState.f)
-
Draw samples from an F distribution.

Samples are drawn from an F distribution with specified parameters,

*dfnum*(degrees of freedom in numerator) and*dfden*(degrees of freedom in denominator), where both parameters must be greater than zero.The random variate of the F distribution (also known as the Fisher distribution) is a continuous probability distribution that arises in ANOVA tests, and is the ratio of two chi-square variates.

Note

New code should use the

method of a`f`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**dfnum**float or array_like of floats
Degrees of freedom in numerator, must be > 0.

**dfden**float or array_like of float
Degrees of freedom in denominator, must be > 0.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`dfnum`
and`dfden`
are both scalars. Otherwise,`np.broadcast(dfnum, dfden).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Fisher distribution.

See also

`scipy.stats.f`
probability density function, distribution or cumulative density function, etc.

`random.Generator.f`
which should be used for new code.

Notes

The F statistic is used to compare in-group variances to between-group variances. Calculating the distribution depends on the sampling, and so it is a function of the respective degrees of freedom in the problem. The variable

*dfnum*is the number of samples minus one, the between-groups degrees of freedom, while*dfden*is the within-groups degrees of freedom, the sum of the number of samples in each group minus the number of groups.References

[1]Glantz, Stanton A. “Primer of Biostatistics.”, McGraw-Hill, Fifth Edition, 2002.

[2]Wikipedia, “F-distribution”,

[https://en.wikipedia.org/wiki/F-distribution](https://en.wikipedia.org/wiki/F-distribution)Examples

An example from Glantz[1], pp 47-40:

Two groups, children of diabetics (25 people) and children from people without diabetes (25 controls). Fasting blood glucose was measured, case group had a mean value of 86.1, controls had a mean value of 82.2. Standard deviations were 2.09 and 2.49 respectively. Are these data consistent with the null hypothesis that the parents diabetic status does not affect their children’s blood glucose levels? Calculating the F statistic from the data gives a value of 36.01.

Draw samples from the distribution:

>>> dfnum = 1. # between group degrees of freedom >>> dfden = 48. # within groups degrees of freedom >>> s = np.random.f(dfnum, dfden, 1000)
The lower bound for the top 1% of the samples is :

>>> np.sort(s)[-10] 7.61988120985 # random
So there is about a 1% chance that the F statistic will exceed 7.62, the measured value is 36, so the null hypothesis is rejected at the 1% level.# numpy.random.Generator.dirichlet[#](#numpy-random-generator-dirichlet)
method

random.Generator.dirichlet(*alpha*,*size=None*)[#](#numpy.random.Generator.dirichlet)
-
Draw samples from the Dirichlet distribution.

Draw

`size`
samples of dimension k from a Dirichlet distribution. A Dirichlet-distributed random variable can be seen as a multivariate generalization of a Beta distribution. The Dirichlet distribution is a conjugate prior of a multinomial distribution in Bayesian inference.Parameters:
-
**alpha**sequence of floats, length k
Parameter of the distribution (length

`k`
for sample of length`k`
).
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n)`
, then`m * n * k`
samples are drawn. Default is None, in which case a vector of length`k`
is returned.
Returns:
-
**samples**ndarray,
The drawn samples, of shape

`(size, k)`
.
Raises:
-
ValueError
-
If any value in

`alpha`
is less than zero
Notes

The Dirichlet distribution is a distribution over vectors \(x\) that fulfil the conditions \(x_i>0\) and \(\sum_{i=1}^k x_i = 1\).

The probability density function \(p\) of a Dirichlet-distributed random vector \(X\) is proportional to

\[p(x) \propto \prod_{i=1}^{k}{x^{\alpha_i-1}_i},\]where \(\alpha\) is a vector containing the positive concentration parameters.

The method uses the following property for computation: let \(Y\) be a random vector which has components that follow a standard gamma distribution, then \(X = \frac{1}{\sum_{i=1}^k{Y_i}} Y\) is Dirichlet-distributed

References

[1]David McKay, “Information Theory, Inference and Learning Algorithms,” chapter 23,

[http://www.inference.org.uk/mackay/itila/](http://www.inference.org.uk/mackay/itila/)[2]Wikipedia, “Dirichlet distribution”,

[https://en.wikipedia.org/wiki/Dirichlet_distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution)Examples

Taking an example cited in Wikipedia, this distribution can be used if one wanted to cut strings (each of initial length 1.0) into K pieces with different lengths, where each piece had, on average, a designated average length, but allowing some variation in the relative sizes of the pieces.

>>> s = np.random.default_rng().dirichlet((10, 5, 3), 20).transpose()
>>> import matplotlib.pyplot as plt >>> plt.barh(range(20), s[0]) >>> plt.barh(range(20), s[1], left=s[0], color='g') >>> plt.barh(range(20), s[2], left=s[0]+s[1], color='r') >>> plt.title("Lengths of Strings")# numpy.char.isspace[#](#numpy-char-isspace)
char.isspace(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L933-L957)[#](#numpy.char.isspace)
-
Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise.

Calls

*str.isspace*element-wise.For 8-bit strings, this method is locale-dependent.

Parameters:
-
**a**array_like of str or unicode
Returns:
-
**out**ndarray
Output array of bools

See also# numpy.char.chararray.trace[#](#numpy-char-chararray-trace)
method

char.chararray.trace(*offset=0*,*axis1=0*,*axis2=1*,*dtype=None*,*out=None*)[#](#numpy.char.chararray.trace)
-
Return the sum along diagonals of the array.

Refer to

for full documentation.`numpy.trace`
See also

`numpy.trace`
equivalent function# numpy.polynomial.laguerre.lagval2d[#](#numpy-polynomial-laguerre-lagval2d)
polynomial.laguerre.lagval2d(*x*,*y*,*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L896-L942)[#](#numpy.polynomial.laguerre.lagval2d)
-
Evaluate a 2-D Laguerre series at points (x, y).

This function returns the values:

\[p(x,y) = \sum_{i,j} c_{i,j} * L_i(x) * L_j(y)\]The parameters

*x*and*y*are converted to arrays only if they are tuples or a lists, otherwise they are treated as a scalars and they must have the same shape after conversion. In either case, either*x*and*y*or their elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*is a 1-D array a one is implicitly appended to its shape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape.Parameters:
-
**x, y**array_like, compatible objects
The two dimensional series is evaluated at the points

*(x, y)*, where*x*and*y*must have the same shape. If*x*or*y*is a list or tuple, it is first converted to an ndarray, otherwise it is left unchanged and if it isn’t an ndarray it is treated as a scalar.
**c**array_like
Array of coefficients ordered so that the coefficient of the term of multi-degree i,j is contained in

`c[i,j]`
. If*c*has dimension greater than two the remaining indices enumerate multiple sets of coefficients.
Returns:
-
**values**ndarray, compatible object
The values of the two dimensional polynomial at points formed with pairs of corresponding values from

*x*and*y*.
Notes

New in version 1.7.0.# numpy.random.RandomState.randn[#](#numpy-random-randomstate-randn)
method

random.RandomState.randn(*d0*,*d1*,*...*,*dn*)[#](#numpy.random.RandomState.randn)
-
Return a sample (or samples) from the “standard normal” distribution.

Note

This is a convenience function for users porting code from Matlab, and wraps

. That function takes a tuple to specify the size of the output, which is consistent with other NumPy functions like`standard_normal`
and`numpy.zeros`
.`numpy.ones`
Note

New code should use the

method of a`standard_normal`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).If positive int_like arguments are provided,

generates an array of shape`randn`
`(d0, d1, ..., dn)`
, filled with random floats sampled from a univariate “normal” (Gaussian) distribution of mean 0 and variance 1. A single float randomly sampled from the distribution is returned if no argument is provided.Parameters:
-
**d0, d1, …, dn**int, optional
The dimensions of the returned array, must be non-negative. If no argument is given a single Python float is returned.

Returns:
-
**Z**ndarray or float
A

`(d0, d1, ..., dn)`
-shaped array of floating-point samples from the standard normal distribution, or a single such float if no parameters were supplied.
See also

`standard_normal`
Similar, but takes a tuple as its argument.

`normal`
Also accepts mu and sigma arguments.

`random.Generator.standard_normal`
which should be used for new code.

Notes

For random samples from the normal distribution with mean

`mu`
and standard deviation`sigma`
, use:sigma * np.random.randn(...) + mu
Examples

>>> np.random.randn() 2.1923875335537315 # random
Two-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:

>>> 3 + 2.5 * np.random.randn(2, 4) array([[-4.49401501, 4.00950034, -1.81814867, 7.29718677], # random [ 0.39924804, 4.68456316, 4.99394529, 4.84057254]]) # random# numpy.ma.masked_array.reshape[#](#numpy-ma-masked-array-reshape)
method

ma.masked_array.reshape(**s*,***kwargs*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4686-L4750)[#](#numpy.ma.masked_array.reshape)
-
Give a new shape to the array without changing its data.

Returns a masked array containing the same data, but with a new shape. The result is a view on the original array; if this is not possible, a ValueError is raised.

Parameters:
-
**shape**int or tuple of ints
The new shape should be compatible with the original shape. If an integer is supplied, then the result will be a 1-D array of that length.

**order**{‘C’, ‘F’}, optional
Determines whether the array data should be viewed as in C (row-major) or FORTRAN (column-major) order.

Returns:
-
**reshaped_array**array
A new view on the array.

See also

`reshape`
Equivalent function in the masked array module.

`numpy.ndarray.reshape`
Equivalent method on ndarray object.

`numpy.reshape`
Equivalent function in the NumPy module.

Notes

The reshaping operation cannot guarantee that a copy will not be made, to modify the shape in place, use

`a.shape = s`
Examples

>>> x = np.ma.array([[1,2],[3,4]], mask=[1,0,0,1]) >>> x masked_array( data=[[--, 2], [3, --]], mask=[[ True, False], [False, True]], fill_value=999999) >>> x = x.reshape((4,1)) >>> x masked_array( data=[[--], [2], [3], [--]], mask=[[ True], [False], [False], [ True]], fill_value=999999)# numpy.polynomial.legendre.Legendre.truncate[#](#numpy-polynomial-legendre-legendre-truncate)
method

polynomial.legendre.Legendre.truncate(*size*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L758-L785)[#](#numpy.polynomial.legendre.Legendre.truncate)
-
Truncate series to length

`size`
.Reduce the series to length

`size`
by discarding the high degree terms. The value of`size`
must be a positive integer. This can be useful in least squares where the coefficients of the high degree terms may be very small.Parameters:
-
**size**positive int
The series is reduced to length

`size`
by discarding the high degree terms. The value of`size`
must be a positive integer.
Returns:
-
**new_series**series
New instance of series with truncated coefficients.numpy.char.chararray.data# attribute char.chararray.data# Python buffer object pointing to the start of the array’s data.# numpy.hanning[#](#numpy-hanning)
numpy.hanning(*M*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L3128-L3234)[#](#numpy.hanning)
-
Return the Hanning window.

The Hanning window is a taper formed by using a weighted cosine.

Parameters:
-
**M**int
Number of points in the output window. If zero or less, an empty array is returned.

Returns:
-
**out**ndarray, shape(M,)
The window, with the maximum value normalized to one (the value one appears only if

*M*is odd).
Notes

The Hanning window is defined as

\[w(n) = 0.5 - 0.5\cos\left(\frac{2\pi{n}}{M-1}\right) \qquad 0 \leq n \leq M-1\]The Hanning was named for Julius von Hann, an Austrian meteorologist. It is also known as the Cosine Bell. Some authors prefer that it be called a Hann window, to help avoid confusion with the very similar Hamming window.

Most references to the Hanning window come from the signal processing literature, where it is used as one of many windowing functions for smoothing values. It is also known as an apodization (which means “removing the foot”, i.e. smoothing discontinuities at the beginning and end of the sampled signal) or tapering function.

References

[1]Blackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra, Dover Publications, New York.

[2]E.R. Kanasewich, “Time Sequence Analysis in Geophysics”, The University of Alberta Press, 1975, pp. 106-108.

[3]Wikipedia, “Window function”,

[https://en.wikipedia.org/wiki/Window_function](https://en.wikipedia.org/wiki/Window_function)[4]W.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, “Numerical Recipes”, Cambridge University Press, 1986, page 425.

Examples

>>> np.hanning(12) array([0. , 0.07937323, 0.29229249, 0.57115742, 0.82743037, 0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249, 0.07937323, 0. ])
Plot the window and its frequency response:

>>> import matplotlib.pyplot as plt >>> from numpy.fft import fft, fftshift >>> window = np.hanning(51) >>> plt.plot(window) [<matplotlib.lines.Line2D object at 0x...>] >>> plt.title("Hann window") Text(0.5, 1.0, 'Hann window') >>> plt.ylabel("Amplitude") Text(0, 0.5, 'Amplitude') >>> plt.xlabel("Sample") Text(0.5, 0, 'Sample') >>> plt.show()
>>> plt.figure() <Figure size 640x480 with 0 Axes> >>> A = fft(window, 2048) / 25.5 >>> mag = np.abs(fftshift(A)) >>> freq = np.linspace(-0.5, 0.5, len(A)) >>> with np.errstate(divide='ignore', invalid='ignore'): ... response = 20 * np.log10(mag) ... >>> response = np.clip(response, -100, 100) >>> plt.plot(freq, response) [<matplotlib.lines.Line2D object at 0x...>] >>> plt.title("Frequency response of the Hann window") Text(0.5, 1.0, 'Frequency response of the Hann window') >>> plt.ylabel("Magnitude [dB]") Text(0, 0.5, 'Magnitude [dB]') >>> plt.xlabel("Normalized frequency [cycles per sample]") Text(0.5, 0, 'Normalized frequency [cycles per sample]') >>> plt.axis('tight') ... >>> plt.show()numpy.ma.MaskType.fill# method ma.MaskType.fill()# Scalar method identical to the corresponding array attribute. Please see ndarray.fill.# numpy.remainder[#](#numpy-remainder)
numpy.remainder(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'remainder'>*[#](#numpy.remainder)
-
Returns the element-wise remainder of division.

Computes the remainder complementary to the

function. It is equivalent to the Python modulus operator``x1 % x2`` and has the same sign as the divisor`floor_divide`
*x2*. The MATLAB function equivalent to`np.remainder`
is`mod`
.Warning

This should not be confused with:

Python 3.7’s

and C’s`math.remainder`
`remainder`
, which computes the IEEE remainder, which are the complement to`round(x1 / x2)`
.
The MATLAB

`rem`
function and or the C`%`
operator which is the complement to`int(x1 / x2)`
.
Parameters:
-
**x1**array_like
Dividend array.

**x2**array_like
Divisor array. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray
The element-wise remainder of the quotient

`floor_divide(x1, x2)`
. This is a scalar if both*x1*and*x2*are scalars.
See also

`floor_divide`
Equivalent of Python

`//`
operator.
`divmod`
Simultaneous floor division and remainder.

`fmod`
Equivalent of the MATLAB

`rem`
function.
,`divide`
`floor`
Notes

Returns 0 when

*x2*is 0 and both*x1*and*x2*are (arrays of) integers.`mod`
is an alias of`remainder`
.Examples

>>> np.remainder([4, 7], [2, 3]) array([0, 1]) >>> np.remainder(np.arange(7), 5) array([0, 1, 2, 3, 4, 0, 1])
The

`%`
operator can be used as a shorthand for`np.remainder`
on ndarrays.>>> x1 = np.arange(7) >>> x1 % 5 array([0, 1, 2, 3, 4, 0, 1])# numpy.recarray.partition[#](#numpy-recarray-partition)
method

recarray.partition(*kth*,*axis=-1*,*kind='introselect'*,*order=None*)[#](#numpy.recarray.partition)
-
Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array. All elements smaller than the kth element are moved before this element and all equal or greater are moved behind it. The ordering of the elements in the two partitions is undefined.

New in version 1.8.0.

Parameters:
-
**kth**int or sequence of ints
Element index to partition by. The kth element value will be in its final sorted position and all smaller elements will be moved before it and all equal or greater elements behind it. The order of all elements in the partitions is undefined. If provided with a sequence of kth it will partition all elements indexed by kth of them into their sorted position at once.

Deprecated since version 1.22.0: Passing booleans as index is deprecated.

**axis**int, optional
Axis along which to sort. Default is -1, which means sort along the last axis.

**kind**{‘introselect’}, optional
Selection algorithm. Default is ‘introselect’.

**order**str or list of str, optional
When

*a*is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need to be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.
See also

`numpy.partition`
Return a partitioned copy of an array.

`argpartition`
Indirect partition.

`sort`
Full sort.

Notes

See

`np.partition`
for notes on the different algorithms.Examples

>>> a = np.array([3, 4, 2, 1]) >>> a.partition(3) >>> a array([2, 1, 3, 4])
>>> a.partition((1, 3)) >>> a array([1, 2, 3, 4])# numpy.memmap.argmax[#](#numpy-memmap-argmax)
method

memmap.argmax(*axis=None*,*out=None*,***,*keepdims=False*)[#](#numpy.memmap.argmax)
-
Return indices of the maximum values along the given axis.

Refer to

for full documentation.`numpy.argmax`
See also

`numpy.argmax`
equivalent function

method

Return indices of the maximum values along the given axis.

Refer to [ numpy.argmax](numpy.argmax.html#numpy.argmax) for full documentation.

See also

`numpy.argmax`
equivalent function# numpy.polynomial.chebyshev.Chebyshev.trim[#](#numpy-polynomial-chebyshev-chebyshev-trim)
method

polynomial.chebyshev.Chebyshev.trim(*tol=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L735-L756)[#](#numpy.polynomial.chebyshev.Chebyshev.trim)
-
Remove trailing coefficients

Remove trailing coefficients until a coefficient is reached whose absolute value greater than

*tol*or the beginning of the series is reached. If all the coefficients would be removed the series is set to`[0]`
. A new series instance is returned with the new coefficients. The current instance remains unchanged.Parameters:
-
**tol**non-negative number.
All trailing coefficients less than

*tol*will be removed.
Returns:
-
**new_series**series
New instance of series with trimmed coefficients.# numpy.char.chararray.newbyteorder[#](#numpy-char-chararray-newbyteorder)
method

char.chararray.newbyteorder(*new_order='S'*,*/*)[#](#numpy.char.chararray.newbyteorder)
-
Return the array with the same data viewed with a different byte order.

Equivalent to:

arr.view(arr.dtype.newbytorder(new_order))
Changes are also made in all fields and sub-arrays of the array data type.

Parameters:
-
**new_order**string, optional
Byte order to force; a value from the byte order specifications below.

*new_order*codes can be any of:‘S’ - swap dtype from current to opposite endian

{‘<’, ‘little’} - little endian

{‘>’, ‘big’} - big endian

{‘=’, ‘native’} - native order, equivalent to

`sys.byteorder`
{‘|’, ‘I’} - ignore (no change to byte order)

The default value (‘S’) results in swapping the current byte order.

Returns:
-
**new_arr**array
New array object with the dtype reflecting given change to the byte order.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
ma.MaskType.strides
numpy.ma.MaskType.strides
#
attribute
ma.MaskType.
strides
#
Tuple of bytes steps in each dimension.# numpy.broadcast[#](#numpy-broadcast)
*class*numpy.broadcast[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/__init__.py)[#](#numpy.broadcast)
-
Produce an object that mimics broadcasting.

Parameters:
-
**in1, in2, …**array_like
Input parameters.

Returns:
-
**b**broadcast object
Broadcast the input parameters against one another, and return an object that encapsulates the result. Amongst others, it has

`shape`
and`nd`
properties, and may be used as an iterator.
See also

Examples

Manually adding two vectors, using broadcasting:

>>> x = np.array([[1], [2], [3]]) >>> y = np.array([4, 5, 6]) >>> b = np.broadcast(x, y)
>>> out = np.empty(b.shape) >>> out.flat = [u+v for (u,v) in b] >>> out array([[5., 6., 7.], [6., 7., 8.], [7., 8., 9.]])
Compare against built-in broadcasting:

>>> x + y array([[5, 6, 7], [6, 7, 8], [7, 8, 9]])
Attributes:
-
`index`
current index in broadcasted result

`iters`
tuple of iterators along

`self`
’s “components.”
`nd`
Number of dimensions of broadcasted result.

`ndim`
Number of dimensions of broadcasted result.

`numiter`
Number of iterators possessed by the broadcasted result.

`shape`
Shape of broadcasted result.

`size`
Total size of broadcasted result.

Methods

()`reset`
Reset the broadcasted result's iterator(s).# numpy.char.upper[#](#numpy-char-upper)
char.upper(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1777-L1809)[#](#numpy.char.upper)
-
Return an array with the elements converted to uppercase.

Calls

*str.upper*element-wise.For 8-bit strings, this method is locale-dependent.

Parameters:
-
**a**array_like, {str, unicode}
Input array.

Returns:
-
**out**ndarray, {str, unicode}
Output array of str or unicode, depending on input type

See also

Examples

>>> c = np.array(['a1b c', '1bca', 'bca1']); c array(['a1b c', '1bca', 'bca1'], dtype='<U5') >>> np.char.upper(c) array(['A1B C', '1BCA', 'BCA1'], dtype='<U5')# numpy.matrix.getA[#](#numpy-matrix-geta)
method

matrix.getA()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L838-L866)[#](#numpy.matrix.getA)
-
Return

*self*as anobject.`ndarray`
Equivalent to

`np.asarray(self)`
.Parameters:
-
**None**
Returns:
-
**ret**ndarray
*self*as an`ndarray`
Examples

>>> x = np.matrix(np.arange(12).reshape((3,4))); x matrix([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) >>> x.getA() array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])# numpy.matlib.randn[#](#numpy-matlib-randn)
matlib.randn(**args*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matlib.py#L277-L328)[#](#numpy.matlib.randn)
-
Return a random matrix with data from the “standard normal” distribution.

generates a matrix filled with random floats sampled from a univariate “normal” (Gaussian) distribution of mean 0 and variance 1.`randn`
Parameters:
-
***args**Arguments
Shape of the output. If given as N integers, each integer specifies the size of one dimension. If given as a tuple, this tuple gives the complete shape.

Returns:
-
**Z**matrix of floats
A matrix of floating-point samples drawn from the standard normal distribution.

See also

Notes

For random samples from the normal distribution with mean

`mu`
and standard deviation`sigma`
, use:sigma * np.matlib.randn(...) + mu
Examples

>>> np.random.seed(123) >>> import numpy.matlib >>> np.matlib.randn(1) matrix([[-1.0856306]]) >>> np.matlib.randn(1, 2, 3) matrix([[ 0.99734545, 0.2829785 , -1.50629471], [-0.57860025, 1.65143654, -2.42667924]])
Two-by-four matrix of samples from the normal distribution with mean 3 and standard deviation 2.5:

>>> 2.5 * np.matlib.randn((2, 4)) + 3 matrix([[1.92771843, 6.16484065, 0.83314899, 1.30278462], [2.76322758, 6.72847407, 1.40274501, 1.8900451 ]])# numpy.argwhere[#](#numpy-argwhere)
numpy.argwhere(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L561-L608)[#](#numpy.argwhere)
-
Find the indices of array elements that are non-zero, grouped by element.

Parameters:
-
**a**array_like
Input data.

Returns:
-
**index_array**(N, a.ndim) ndarray
Indices of elements that are non-zero. Indices are grouped by element. This array will have shape

`(N, a.ndim)`
where`N`
is the number of non-zero items.
Notes

`np.argwhere(a)`
is almost the same as`np.transpose(np.nonzero(a))`
, but produces a result of the correct shape for a 0D array.The output of

`argwhere`
is not suitable for indexing arrays. For this purpose use`nonzero(a)`
instead.Examples

>>> x = np.arange(6).reshape(2,3) >>> x array([[0, 1, 2], [3, 4, 5]]) >>> np.argwhere(x>1) array([[0, 2], [1, 0], [1, 1], [1, 2]])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__mul__
numpy.ndarray.__mul__
#
method
ndarray.
__mul__
(
value
,
/
)
#
Return self*value.# numpy.tri[#](#numpy-tri)
numpy.tri(*N*,*M=None*,*k=0*,*dtype=<class 'float'>*,***,*like=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/twodim_base.py#L366-L420)[#](#numpy.tri)
-
An array with ones at and below the given diagonal and zeros elsewhere.

Parameters:
-
**N**int
Number of rows in the array.

**M**int, optional
Number of columns in the array. By default,

*M*is taken equal to*N*.
**k**int, optional
The sub-diagonal at and below which the array is filled.

*k*= 0 is the main diagonal, while*k*< 0 is below it, and*k*> 0 is above. The default is 0.
**dtype**dtype, optional
Data type of the returned array. The default is float.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**tri**ndarray of shape (N, M)
Array with its lower triangle filled with ones and zero elsewhere; in other words

`T[i,j] == 1`
for`j <= i + k`
, 0 otherwise.
Examples

>>> np.tri(3, 5, 2, dtype=int) array([[1, 1, 1, 0, 0], [1, 1, 1, 1, 0], [1, 1, 1, 1, 1]])
>>> np.tri(3, 5, -1) array([[0., 0., 0., 0., 0.], [1., 0., 0., 0., 0.], [1., 1., 0., 0., 0.]])# numpy.ma.ones_like[#](#numpy-ma-ones-like)
ma.ones_like*= <numpy.ma.core._convert2ma object>*[#](#numpy.ma.ones_like)
-
Return an array of ones with the same shape and type as a given array.

Parameters:
-
**a**array_like
The shape and data-type of

*a*define these same attributes of the returned array.
**dtype**data-type, optional
Overrides the data type of the result.

New in version 1.6.0.

**order**{‘C’, ‘F’, ‘A’, or ‘K’}, optional
Overrides the memory layout of the result. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*a*as closely as possible.New in version 1.6.0.

**subok**bool, optional.
If True, then the newly created array will use the sub-class type of

*a*, otherwise it will be a base-class array. Defaults to True.
**shape**int or sequence of ints, optional.
Overrides the shape of the result. If order=’K’ and the number of dimensions is unchanged, will try to keep order, otherwise, order=’C’ is implied.

New in version 1.17.0.

Returns:
-
**out**MaskedArray
Array of ones with the same shape and type as

*a*.
See also

`empty_like`
Return an empty array with shape and type of input.

`zeros_like`
Return an array of zeros with shape and type of input.

`full_like`
Return a new array with shape of input filled with value.

`ones`
Return a new array setting values to one.

Examples

>>> x = np.arange(6) >>> x = x.reshape((2, 3)) >>> x array([[0, 1, 2], [3, 4, 5]]) >>> np.ones_like(x) array([[1, 1, 1], [1, 1, 1]])
>>> y = np.arange(3, dtype=float) >>> y array([0., 1., 2.]) >>> np.ones_like(y) array([1., 1., 1.])numpy.distutils.exec_command.forward_bytes_to_stdout# distutils.exec_command.forward_bytes_to_stdout(val)[source]# Forward bytes from a subprocess call to the console, without attempting to decode them. The assumption is that the subprocess call already returned bytes in a suitable encoding.# numpy.ndarray.argsort[#](#numpy-ndarray-argsort)
method

ndarray.argsort(*axis=-1*,*kind=None*,*order=None*)[#](#numpy.ndarray.argsort)
-
Returns the indices that would sort this array.

Refer to

for full documentation.`numpy.argsort`
See also

`numpy.argsort`
equivalent function

method

Returns the indices that would sort this array.

Refer to [ numpy.argsort](numpy.argsort.html#numpy.argsort) for full documentation.

See also

`numpy.argsort`
equivalent functionndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__int__

method

Convert to int.# numpy.polynomial.hermite.poly2herm[#](#numpy-polynomial-hermite-poly2herm)
polynomial.hermite.poly2herm(*pol*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L96-L139)[#](#numpy.polynomial.hermite.poly2herm)
-
Convert a polynomial to a Hermite series.

Convert an array representing the coefficients of a polynomial (relative to the “standard” basis) ordered from lowest degree to highest, to an array of the coefficients of the equivalent Hermite series, ordered from lowest to highest degree.

Parameters:
-
**pol**array_like
1-D array containing the polynomial coefficients

Returns:
-
**c**ndarray
1-D array containing the coefficients of the equivalent Hermite series.

See also

Notes

The easy way to do conversions between polynomial basis sets is to use the convert method of a class instance.

Examples

>>> from numpy.polynomial.hermite import poly2herm >>> poly2herm(np.arange(4)) array([1. , 2.75 , 0.5 , 0.375])# Mersenne Twister (MT19937)[#](#mersenne-twister-mt19937)
*class*numpy.random.MT19937(*seed=None*)[#](#numpy.random.MT19937)
-
Container for the Mersenne Twister pseudo-random number generator.

Parameters:
-
**seed**{None, int, array_like[ints], SeedSequence}, optional
A seed to initialize the

. If None, then fresh, unpredictable entropy will be pulled from the OS. If an`BitGenerator`
`int`
or`array_like[ints]`
is passed, then it will be passed toto derive the initial`SeedSequence`
state. One may also pass in a`BitGenerator`
instance.`SeedSequence`
Notes

`MT19937`
provides a capsule containing function pointers that produce doubles, and unsigned 32 and 64- bit integers[[1]](#r312276d80bfa-1). These are not directly consumable in Python and must be consumed by a`Generator`
or similar object that supports low-level access.The Python stdlib module “random” also contains a Mersenne Twister pseudo-random number generator.

**State and Seeding**The

`MT19937`
state vector consists of a 624-element array of 32-bit unsigned integers plus a single integer value between 0 and 624 that indexes the current position within the main array.The input seed is processed by

to fill the whole state. The first element is reset such that only its most significant bit is set.`SeedSequence`
**Parallel Features**The preferred way to use a BitGenerator in parallel applications is to use the

method to obtain entropy values, and to use these to generate new BitGenerators:`SeedSequence.spawn`
>>> from numpy.random import Generator, MT19937, SeedSequence >>> sg = SeedSequence(1234) >>> rg = [Generator(MT19937(s)) for s in sg.spawn(10)]
Another method is to use

which advances the state as-if \(2^{128}\) random numbers have been generated (`MT19937.jumped`
[[1]](#r312276d80bfa-1),[[2]](#r312276d80bfa-2)). This allows the original sequence to be split so that distinct segments can be used in each worker process. All generators should be chained to ensure that the segments come from the same sequence.>>> from numpy.random import Generator, MT19937, SeedSequence >>> sg = SeedSequence(1234) >>> bit_generator = MT19937(sg) >>> rg = [] >>> for _ in range(10): ... rg.append(Generator(bit_generator)) ... # Chain the BitGenerators ... bit_generator = bit_generator.jumped()
**Compatibility Guarantee**`MT19937`
makes a guarantee that a fixed seed will always produce the same random integer stream.References

[1] ([1](#id1),[2](#id2))Hiroshi Haramoto, Makoto Matsumoto, and Pierre L’Ecuyer, “A Fast Jump Ahead Algorithm for Linear Recurrences in a Polynomial Space”, Sequences and Their Applications - SETA, 290–298, 2008.

[[2](#id3)]Hiroshi Haramoto, Makoto Matsumoto, Takuji Nishimura, François Panneton, Pierre L’Ecuyer, “Efficient Jump Ahead for F2-Linear Random Number Generators”, INFORMS JOURNAL ON COMPUTING, Vol. 20, No. 3, Summer 2008, pp. 385-390.

Attributes:
-
**lock: threading.Lock**
Lock instance that is shared so that the same bit git generator can be used in multiple Generators without corrupting the state. Code that generates values from a bit generator should hold the bit generator’s lock.

## State[#](#state)
Get or set the PRNG state

|
## Parallel generation[#](#parallel-generation)
|
Returns a new bit generator with the state jumped

|
## Extending[#](#extending)
CFFI interface

|
ctypes interface

|# numpy.ma.MaskType.resize[#](#numpy-ma-masktype-resize)
method

ma.MaskType.resize()[#](#numpy.ma.MaskType.resize)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.resize`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.resize](numpy.ndarray.resize.html#numpy.ndarray.resize).# numpy.polynomial.laguerre.lagvander2d[#](#numpy-polynomial-laguerre-lagvander2d)
polynomial.laguerre.lagvander2d(*x*,*y*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L1165-L1215)[#](#numpy.polynomial.laguerre.lagvander2d)
-
Pseudo-Vandermonde matrix of given degrees.

Returns the pseudo-Vandermonde matrix of degrees

*deg*and sample points*(x, y)*. The pseudo-Vandermonde matrix is defined by\[V[..., (deg[1] + 1)*i + j] = L_i(x) * L_j(y),\]where

*0 <= i <= deg[0]*and*0 <= j <= deg[1]*. The leading indices of*V*index the points*(x, y)*and the last index encodes the degrees of the Laguerre polynomials.If

`V = lagvander2d(x, y, [xdeg, ydeg])`
, then the columns of*V*correspond to the elements of a 2-D coefficient array*c*of shape (xdeg + 1, ydeg + 1) in the order\[c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...\]and

`np.dot(V, c.flat)`
and`lagval2d(x, y, c)`
will be the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of 2-D Laguerre series of the same degrees and sample points.Parameters:
-
**x, y**array_like
Arrays of point coordinates, all of the same shape. The dtypes will be converted to either float64 or complex128 depending on whether any of the elements are complex. Scalars are converted to 1-D arrays.

**deg**list of ints
List of maximum degrees of the form [x_deg, y_deg].

Returns:
-
**vander2d**ndarray
The shape of the returned matrix is

`x.shape + (order,)`
, where \(order = (deg[0]+1)*(deg[1]+1)\). The dtype will be the same as the converted*x*and*y*.
See also

Notes

New in version 1.7.0.numpy.record.argsort# method record.argsort()# Scalar method identical to the corresponding array attribute. Please see ndarray.argsort.# numpy.ma.masked_array.byteswap[#](#numpy-ma-masked-array-byteswap)
method

ma.masked_array.byteswap(*inplace=False*)[#](#numpy.ma.masked_array.byteswap)
-
Swap the bytes of the array elements

Toggle between low-endian and big-endian data representation by returning a byteswapped array, optionally swapped in-place. Arrays of byte-strings are not swapped. The real and imaginary parts of a complex number are swapped individually.

Parameters:
-
**inplace**bool, optional
If

`True`
, swap bytes in-place, default is`False`
.
Returns:
-
**out**ndarray
The byteswapped array. If

*inplace*is`True`
, this is a view to self.
Examples

>>> A = np.array([1, 256, 8755], dtype=np.int16) >>> list(map(hex, A)) ['0x1', '0x100', '0x2233'] >>> A.byteswap(inplace=True) array([ 256, 1, 13090], dtype=int16) >>> list(map(hex, A)) ['0x100', '0x1', '0x3322']
Arrays of byte-strings are not swapped

>>> A = np.array([b'ceg', b'fac']) >>> A.byteswap() array([b'ceg', b'fac'], dtype='|S3')
`A.newbyteorder().byteswap()`
produces an array with the same values
but different representation in memory

>>> A = np.array([1, 2, 3]) >>> A.view(np.uint8) array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0], dtype=uint8) >>> A.newbyteorder().byteswap(inplace=True) array([1, 2, 3]) >>> A.view(np.uint8) array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3], dtype=uint8)# numpy.logical_not[#](#numpy-logical-not)
numpy.logical_not(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'logical_not'>*[#](#numpy.logical_not)
-
Compute the truth value of NOT x element-wise.

Parameters:
-
**x**array_like
Logical NOT is applied to the elements of

*x*.
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**bool or ndarray of bool
Boolean result with the same shape as

*x*of the NOT operation on elements of*x*. This is a scalar if*x*is a scalar.
See also

Examples

>>> np.logical_not(3) False >>> np.logical_not([True, False, 0, 1]) array([False, True, True, False])
>>> x = np.arange(5) >>> np.logical_not(x<3) array([False, False, False, True, True])# numpy.ndarray.__setstate__[#](#numpy-ndarray-setstate)
method

ndarray.__setstate__(*state*,*/*)[#](#numpy.ndarray.__setstate__)
-
For unpickling.

The

*state*argument must be a sequence that contains the following elements:Parameters:
-
**version**int
optional pickle version. If omitted defaults to 0.

**shape**tuple
**dtype**data-type
**isFortran**bool
**rawdata**string or list
a binary string with the data (or a list if ‘a’ is an object array)# numpy.nansum[#](#numpy-nansum)
numpy.nansum(*a*,*axis=None*,*dtype=None*,*out=None*,*keepdims=<no value>*,*initial=<no value>*,*where=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L623-L724)[#](#numpy.nansum)
-
Return the sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.

In NumPy versions <= 1.9.0 Nan is returned for slices that are all-NaN or empty. In later versions zero is returned.

Parameters:
-
**a**array_like
Array containing numbers whose sum is desired. If

*a*is not an array, a conversion is attempted.
**axis**{int, tuple of int, None}, optional
Axis or axes along which the sum is computed. The default is to compute the sum of the flattened array.

**dtype**data-type, optional
The type of the returned array and of the accumulator in which the elements are summed. By default, the dtype of

*a*is used. An exception is when*a*has an integer type with less precision than the platform (u)intp. In that case, the default will be either (u)int32 or (u)int64 depending on whether the platform is 32 or 64 bits. For inexact inputs, dtype must be inexact.New in version 1.8.0.

**out**ndarray, optional
Alternate output array in which to place the result. The default is

`None`
. If provided, it must have the same shape as the expected output, but the type will be cast if necessary. See[Output type determination](../../user/basics.ufuncs.html#ufuncs-output-type)for more details. The casting of NaN to integer can yield unexpected results.New in version 1.8.0.

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original

*a*.If the value is anything but the default, then

*keepdims*will be passed through to theor`mean`
methods of sub-classes of`sum`
. If the sub-classes methods does not implement`ndarray`
*keepdims*any exceptions will be raised.New in version 1.8.0.

**initial**scalar, optional
Starting value for the sum. See

for details.`reduce`
New in version 1.22.0.

**where**array_like of bool, optional
Elements to include in the sum. See

for details.`reduce`
New in version 1.22.0.

Returns:
-
**nansum**ndarray.
A new array holding the result is returned unless

*out*is specified, in which it is returned. The result has the same size as*a*, and the same shape as*a*if*axis*is not None or*a*is a 1-d array.
See also

Notes

If both positive and negative infinity are present, the sum will be Not A Number (NaN).

Examples

>>> np.nansum(1) 1 >>> np.nansum([1]) 1 >>> np.nansum([1, np.nan]) 1.0 >>> a = np.array([[1, 1], [1, np.nan]]) >>> np.nansum(a) 3.0 >>> np.nansum(a, axis=0) array([2., 1.]) >>> np.nansum([1, np.nan, np.inf]) inf >>> np.nansum([1, np.nan, np.NINF]) -inf >>> from numpy.testing import suppress_warnings >>> with suppress_warnings() as sup: ... sup.filter(RuntimeWarning) ... np.nansum([1, np.nan, np.inf, -np.inf]) # both +/- infinity present nannumpy.distutils.ccompiler.CCompiler_show_customization# distutils.ccompiler.CCompiler_show_customization(self)[source]# Print the compiler customizations to stdout. Parameters: None Returns: None Notes Printing is only done if the distutils log threshold is < 2.# numpy.distutils.exec_command[#](#module-numpy.distutils.exec_command)
exec_command

Implements exec_command function that is (almost) equivalent to commands.getstatusoutput function but on NT, DOS systems the returned status is actually correct (though, the returned status values may be different by a factor). In addition, exec_command takes keyword arguments for (re-)defining environment variables.

Provides functions:

exec_command — execute command in a specified directory and
-
-
in the modified environment.

find_executable — locate a command using info from environment
-
-
variable PATH. Equivalent to posix

whichcommand.
Author: Pearu Peterson <[pearu@cens.ioc.ee](/cdn-cgi/l/email-protection#82f2e7e3f0f7a4a1b1b5b9a4a1b7b0b9a4a1b6bab9e1e7ecf1a4a1b6b4b9ebede1a4a1b6b4b9e7e7)>
Created: 11 January 2003

Requires: Python 2.x

Successfully tested on:

os.name

|
sys.platform

|
comments

|
---|---|---|
posix

|
linux2

|
Debian (sid) Linux, Python 2.1.3+, 2.2.3+, 2.3.3 PyCrust 0.9.3, Idle 1.0.2

|
posix

|
linux2

|
Red Hat 9 Linux, Python 2.1.3, 2.2.2, 2.3.2

|
posix

|
sunos5

|
SunOS 5.9, Python 2.2, 2.3.2

|
posix

|
darwin

|
Darwin 7.2.0, Python 2.3

|
nt

|
win32

|
Windows Me Python 2.3(EE), Idle 1.0, PyCrust 0.7.2 Python 2.1.1 Idle 0.8

|
nt

|
win32

|
Windows 98, Python 2.1.1. Idle 0.8

|
nt

|
win32

|
Cygwin 98-4.10, Python 2.1.1(MSC) - echo tests
fail i.e. redefining environment variables may
not work. FIXED: don’t use cygwin echo!
Comment: also

|
posix

|
cygwin

|
Cygwin 98-4.10, Python 2.3.3(cygming special)

|
nt

|
win32

|
Windows XP, Python 2.3.3

|
Known bugs:

Tests, that send messages to stderr, fail when executed from MSYS prompt because the messages are lost at some point.

Functions

|
Return (status,output) of executed command.

|
|
Convert

|
|
Return full path of a executable or None.

|
Forward bytes from a subprocess call to the console, without attempting to decode them.

|# numpy.polynomial.legendre.Legendre.identity[#](#numpy-polynomial-legendre-legendre-identity)
method

*classmethod*polynomial.legendre.Legendre.identity(*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1090-L1123)[#](#numpy.polynomial.legendre.Legendre.identity)
-
Identity function.

If

`p`
is the returned series, then`p(x) == x`
for all values of x.Parameters:
-
**domain**{None, array_like}, optional
If given, the array must be of the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the domain. If None is given then the class domain is used. The default is None.
**window**{None, array_like}, optional
If given, the resulting array must be if the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the window. If None is given then the class window is used. The default is None.
**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
Series of representing the identity.# numpy.char.chararray.flags[#](#numpy-char-chararray-flags)
attribute

char.chararray.flags[#](#numpy.char.chararray.flags)
-
Information about the memory layout of the array.

Notes

The

object can be accessed dictionary-like (as in`flags`
`a.flags['WRITEABLE']`
), or by using lowercased attribute names (as in`a.flags.writeable`
). Short flag names are only supported in dictionary access.Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED flags can be changed by the user, via direct assignment to the attribute or dictionary entry, or by calling

.`ndarray.setflags`
The array flags cannot be set arbitrarily:

WRITEBACKIFCOPY can only be set

`False`
.
ALIGNED can only be set

`True`
if the data is truly aligned.
WRITEABLE can only be set

`True`
if the array owns its own memory or the ultimate owner of the memory exposes a writeable buffer interface or is a string.
Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.

Even for contiguous arrays a stride for a given dimension

`arr.strides[dim]`
may be*arbitrary*if`arr.shape[dim] == 1`
or the array has no elements. It does*not*generally hold that`self.strides[-1] == self.itemsize`
for C-style contiguous arrays or`self.strides[0] == self.itemsize`
for Fortran-style contiguous arrays is true.Attributes:
-
**C_CONTIGUOUS (C)**
The data is in a single, C-style contiguous segment.

**F_CONTIGUOUS (F)**
The data is in a single, Fortran-style contiguous segment.

**OWNDATA (O)**
The array owns the memory it uses or borrows it from another object.

**WRITEABLE (W)**
The data area can be written to. Setting this to False locks the data, making it read-only. A view (slice, etc.) inherits WRITEABLE from its base array at creation time, but a view of a writeable array may be subsequently locked while the base array remains writeable. (The opposite is not true, in that a view of a locked array may not be made writeable. However, currently, locking a base object does not lock any views that already reference it, so under that circumstance it is possible to alter the contents of a locked array via a previously created writeable view onto it.) Attempting to change a non-writeable array raises a RuntimeError exception.

**ALIGNED (A)**
The data and all elements are aligned appropriately for the hardware.

**WRITEBACKIFCOPY (X)**
This array is a copy of some other array. The C-API function PyArray_ResolveWritebackIfCopy must be called before deallocating to the base array will be updated with the contents of this array.

**FNC**
F_CONTIGUOUS and not C_CONTIGUOUS.

**FORC**
F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).

**BEHAVED (B)**
ALIGNED and WRITEABLE.

**CARRAY (CA)**
BEHAVED and C_CONTIGUOUS.

**FARRAY (FA)**
BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.# numpy.ma.MaskedArray.strides[#](#numpy-ma-maskedarray-strides)
attribute

ma.MaskedArray.strides[#](#numpy.ma.MaskedArray.strides)
-
Tuple of bytes to step in each dimension when traversing an array.

The byte offset of element

`(i[0], i[1], ..., i[n])`
in an array*a*is:offset = sum(np.array(i) * a.strides)
A more detailed explanation of strides can be found in the “ndarray.rst” file in the NumPy reference guide.

Warning

Setting

`arr.strides`
is discouraged and may be deprecated in the future.should be preferred to create a new view of the same data in a safer way.`numpy.lib.stride_tricks.as_strided`
See also

Notes

Imagine an array of 32-bit integers (each 4 bytes):

x = np.array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], dtype=np.int32)
This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array

*x*will be`(20, 4)`
.Examples

>>> y = np.reshape(np.arange(2*3*4), (2,3,4)) >>> y array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) >>> y.strides (48, 16, 4) >>> y[1,1,1] 17 >>> offset=sum(y.strides * np.array((1,1,1))) >>> offset/y.itemsize 17
>>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0) >>> x.strides (32, 4, 224, 1344) >>> i = np.array([3,5,2,2]) >>> offset = sum(i * x.strides) >>> x[3,5,2,2] 813 >>> offset / x.itemsize 813User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
record.strides
numpy.record.strides
#
attribute
record.
strides
#
Tuple of bytes steps in each dimension.ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__rand__

method

Return value&self.# numpy.ma.where[#](#numpy-ma-where)
ma.where(*condition*,*x=<no value>*,*y=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7603-L7691)[#](#numpy.ma.where)
-
Return a masked array with elements from

*x*or*y*, depending on condition.Note

When only

*condition*is provided, this function is identical to. The rest of this documentation covers only the case where all three arguments are provided.`nonzero`
Parameters:
-
**condition**array_like, bool
Where True, yield

*x*, otherwise yield*y*.
**x, y**array_like, optional
Values from which to choose.

*x*,*y*and*condition*need to be broadcastable to some shape.
Returns:
-
**out**MaskedArray
An masked array with

elements where the condition is masked, elements from`masked`
*x*where*condition*is True, and elements from*y*elsewhere.
See also

`numpy.where`
Equivalent function in the top-level NumPy module.

`nonzero`
The function that is called when x and y are omitted

Examples

>>> x = np.ma.array(np.arange(9.).reshape(3, 3), mask=[[0, 1, 0], ... [1, 0, 1], ... [0, 1, 0]]) >>> x masked_array( data=[[0.0, --, 2.0], [--, 4.0, --], [6.0, --, 8.0]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=1e+20) >>> np.ma.where(x > 5, x, -3.1416) masked_array( data=[[-3.1416, --, -3.1416], [--, -3.1416, --], [6.0, --, 8.0]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=1e+20)# numpy.matrix.tofile[#](#numpy-matrix-tofile)
method

matrix.tofile(*fid*,*sep=''*,*format='%s'*)[#](#numpy.matrix.tofile)
-
Write array to a file as text or binary (default).

Data is always written in ‘C’ order, independent of the order of

*a*. The data produced by this method can be recovered using the function fromfile().Parameters:
-
**fid**file or str or Path
An open file object, or a string containing a filename.

Changed in version 1.17.0:

objects are now accepted.`pathlib.Path`
**sep**str
Separator between array items for text output. If “” (empty), a binary file is written, equivalent to

`file.write(a.tobytes())`
.
**format**str
Format string for text file output. Each entry in the array is formatted to text by first converting it to the closest Python type, and then using “format” % item.

Notes

This is a convenience function for quick storage of array data. Information on endianness and precision is lost, so this method is not a good choice for files intended to archive data or transport data between machines with different endianness. Some of these problems can be overcome by outputting the data as text files, at the expense of speed and file size.

When fid is a file object, array contents are directly written to the file, bypassing the file object’s

`write`
method. As a result, tofile cannot be used with files objects supporting compression (e.g., GzipFile) or file-like objects that do not support`fileno()`
(e.g., BytesIO).# numpy.polynomial.legendre.legval[#](#numpy-polynomial-legendre-legval)
polynomial.legendre.legval(*x*,*c*,*tensor=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L832-L914)[#](#numpy.polynomial.legendre.legval)
-
Evaluate a Legendre series at points x.

If

*c*is of length*n + 1*, this function returns the value:\[p(x) = c_0 * L_0(x) + c_1 * L_1(x) + ... + c_n * L_n(x)\]The parameter

*x*is converted to an array only if it is a tuple or a list, otherwise it is treated as a scalar. In either case, either*x*or its elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*is a 1-D array, then*p(x)*will have the same shape as*x*. If*c*is multidimensional, then the shape of the result depends on the value of*tensor*. If*tensor*is true the shape will be c.shape[1:] + x.shape. If*tensor*is false the shape will be c.shape[1:]. Note that scalars have shape (,).Trailing zeros in the coefficients will be used in the evaluation, so they should be avoided if efficiency is a concern.

Parameters:
-
**x**array_like, compatible object
If

*x*is a list or tuple, it is converted to an ndarray, otherwise it is left unchanged and treated as a scalar. In either case,*x*or its elements must support addition and multiplication with themselves and with the elements of*c*.
**c**array_like
Array of coefficients ordered so that the coefficients for terms of degree n are contained in c[n]. If

*c*is multidimensional the remaining indices enumerate multiple polynomials. In the two dimensional case the coefficients may be thought of as stored in the columns of*c*.
**tensor**boolean, optional
If True, the shape of the coefficient array is extended with ones on the right, one for each dimension of

*x*. Scalars have dimension 0 for this action. The result is that every column of coefficients in*c*is evaluated for every element of*x*. If False,*x*is broadcast over the columns of*c*for the evaluation. This keyword is useful when*c*is multidimensional. The default value is True.New in version 1.7.0.

Returns:
-
**values**ndarray, algebra_like
The shape of the return value is described above.

Notes

The evaluation uses Clenshaw recursion, aka synthetic division.# numpy.matrix.getH[#](#numpy-matrix-geth)
method

matrix.getH()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L969-L1002)[#](#numpy.matrix.getH)
-
Returns the (complex) conjugate transpose of

*self*.Equivalent to

`np.transpose(self)`
if*self*is real-valued.Parameters:
-
**None**
Returns:
-
**ret**matrix object
complex conjugate transpose of

*self*
Examples

>>> x = np.matrix(np.arange(12).reshape((3,4))) >>> z = x - 1j*x; z matrix([[ 0. +0.j, 1. -1.j, 2. -2.j, 3. -3.j], [ 4. -4.j, 5. -5.j, 6. -6.j, 7. -7.j], [ 8. -8.j, 9. -9.j, 10.-10.j, 11.-11.j]]) >>> z.getH() matrix([[ 0. -0.j, 4. +4.j, 8. +8.j], [ 1. +1.j, 5. +5.j, 9. +9.j], [ 2. +2.j, 6. +6.j, 10.+10.j], [ 3. +3.j, 7. +7.j, 11.+11.j]])# numpy.chararray.clip[#](#numpy-chararray-clip)
method

chararray.clip(*min=None*,*max=None*,*out=None*,***kwargs*)[#](#numpy.chararray.clip)
-
Return an array whose values are limited to

`[min, max]`
. One of max or min must be given.Refer to

for full documentation.`numpy.clip`
See also

`numpy.clip`
equivalent function# numpy.dtype.descr[#](#numpy-dtype-descr)
attribute

dtype.descr[#](#numpy.dtype.descr)
-
*__array_interface__*description of the data-type.The format is that required by the ‘descr’ key in the

*__array_interface__*attribute.Warning: This attribute exists specifically for

*__array_interface__*, and passing it directly to*np.dtype*will not accurately reconstruct some dtypes (e.g., scalar and subarray dtypes).Examples

>>> x = np.dtype(float) >>> x.descr [('', '<f8')]
>>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))]) >>> dt.descr [('name', '<U16'), ('grades', '<f8', (2,))]# numpy.diff[#](#numpy-diff)
numpy.diff(*a*,*n=1*,*axis=-1*,*prepend=<no value>*,*append=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L1324-L1454)[#](#numpy.diff)
-
Calculate the n-th discrete difference along the given axis.

The first difference is given by

`out[i] = a[i+1] - a[i]`
along the given axis, higher differences are calculated by usingrecursively.`diff`
Parameters:
-
**a**array_like
Input array

**n**int, optional
The number of times values are differenced. If zero, the input is returned as-is.

**axis**int, optional
The axis along which the difference is taken, default is the last axis.

**prepend, append**array_like, optional
Values to prepend or append to

*a*along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match*a*except along axis.New in version 1.16.0.

Returns:
-
**diff**ndarray
The n-th differences. The shape of the output is the same as

*a*except along*axis*where the dimension is smaller by*n*. The type of the output is the same as the type of the difference between any two elements of*a*. This is the same as the type of*a*in most cases. A notable exception is, which results in a`datetime64`
output array.`timedelta64`
Notes

Type is preserved for boolean arrays, so the result will contain

*False*when consecutive elements are the same and*True*when they differ.For unsigned integer arrays, the results will also be unsigned. This should not be surprising, as the result is consistent with calculating the difference directly:

>>> u8_arr = np.array([1, 0], dtype=np.uint8) >>> np.diff(u8_arr) array([255], dtype=uint8) >>> u8_arr[1,...] - u8_arr[0,...] 255
If this is not desirable, then the array should be cast to a larger integer type first:

>>> i16_arr = u8_arr.astype(np.int16) >>> np.diff(i16_arr) array([-1], dtype=int16)
Examples

>>> x = np.array([1, 2, 4, 7, 0]) >>> np.diff(x) array([ 1, 2, 3, -7]) >>> np.diff(x, n=2) array([ 1, 1, -10])
>>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]]) >>> np.diff(x) array([[2, 3, 4], [5, 1, 2]]) >>> np.diff(x, axis=0) array([[-1, 2, 0, -2]])
>>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64) >>> np.diff(x) array([1, 1], dtype='timedelta64[D]')numpy.record.put# method record.put()# Scalar method identical to the corresponding array attribute. Please see ndarray.put.# numpy.polynomial.chebyshev.Chebyshev.fit[#](#numpy-polynomial-chebyshev-chebyshev-fit)
method

*classmethod*polynomial.chebyshev.Chebyshev.fit(*x*,*y*,*deg*,*domain=None*,*rcond=None*,*full=False*,*w=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L955-L1045)[#](#numpy.polynomial.chebyshev.Chebyshev.fit)
-
Least squares fit to data.

Return a series instance that is the least squares fit to the data

*y*sampled at*x*. The domain of the returned instance can be specified and this will often result in a superior fit with less chance of ill conditioning.Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,)
y-coordinates of the M sample points

`(x[i], y[i])`
.
**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**domain**{None, [beg, end], []}, optional
Domain to use for the returned series. If

`None`
, then a minimal domain that covers the points*x*is chosen. If`[]`
the class domain is used. The default value was the class domain in NumPy 1.4 and`None`
in later versions. The`[]`
option was added in numpy 1.5.0.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (M,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.New in version 1.5.0.

**window**{[beg, end]}, optional
Window to use for the returned series. The default value is the default class domain

New in version 1.6.0.

**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
A series that represents the least squares fit to the data and has the domain and window specified in the call. If the coefficients for the unscaled and unshifted basis polynomials are of interest, do

`new_series.convert().coef`
.
**[resid, rank, sv, rcond]**list
These values are only returned if

`full == True`
resid – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

sv – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`linalg.lstsq`# numpy.memmap.searchsorted[#](#numpy-memmap-searchsorted)
method

memmap.searchsorted(*v*,*side='left'*,*sorter=None*)[#](#numpy.memmap.searchsorted)
-
Find indices where elements of v should be inserted in a to maintain order.

For full documentation, see

`numpy.searchsorted`
See also

`numpy.searchsorted`
equivalent function# numpy.linalg.eig[#](#numpy-linalg-eig)
linalg.eig(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L1193-L1345)[#](#numpy.linalg.eig)
-
Compute the eigenvalues and right eigenvectors of a square array.

Parameters:
-
**a**(…, M, M) array
Matrices for which the eigenvalues and right eigenvectors will be computed

Returns:
-
A namedtuple with the following attributes:
-
**eigenvalues**(…, M) array
The eigenvalues, each repeated according to its multiplicity. The eigenvalues are not necessarily ordered. The resulting array will be of complex type, unless the imaginary part is zero in which case it will be cast to a real type. When

*a*is real the resulting eigenvalues will be real (0 imaginary part) or occur in conjugate pairs
**eigenvectors**(…, M, M) array
The normalized (unit “length”) eigenvectors, such that the column

`eigenvectors[:,i]`
is the eigenvector corresponding to the eigenvalue`eigenvalues[i]`
.
Raises:
-
LinAlgError
-
If the eigenvalue computation does not converge.

See also

`eigvals`
eigenvalues of a non-symmetric array.

`eigh`
eigenvalues and eigenvectors of a real symmetric or complex Hermitian (conjugate symmetric) array.

`eigvalsh`
eigenvalues of a real symmetric or complex Hermitian (conjugate symmetric) array.

`scipy.linalg.eig`
Similar function in SciPy that also solves the generalized eigenvalue problem.

`scipy.linalg.schur`
Best choice for unitary and other non-Hermitian normal matrices.

Notes

New in version 1.8.0.

Broadcasting rules apply, see the

documentation for details.`numpy.linalg`
This is implemented using the

`_geev`
LAPACK routines which compute the eigenvalues and eigenvectors of general square arrays.The number

*w*is an eigenvalue of*a*if there exists a vector*v*such that`a @ v = w * v`
. Thus, the arrays*a*,*eigenvalues*, and*eigenvectors*satisfy the equations`a @ eigenvectors[:,i] = eigenvalues[i] * eigenvalues[:,i]`
for \(i \in \{0,...,M-1\}\).The array

*eigenvectors*may not be of maximum rank, that is, some of the columns may be linearly dependent, although round-off error may obscure that fact. If the eigenvalues are all different, then theoretically the eigenvectors are linearly independent and*a*can be diagonalized by a similarity transformation using*eigenvectors*, i.e,`inv(eigenvectors) @ a @ eigenvectors`
is diagonal.For non-Hermitian normal matrices the SciPy function

is preferred because the matrix`scipy.linalg.schur`
*eigenvectors*is guaranteed to be unitary, which is not the case when using. The Schur factorization produces an upper triangular matrix rather than a diagonal matrix, but for normal matrices only the diagonal of the upper triangular matrix is needed, the rest is roundoff error.`eig`
Finally, it is emphasized that

*eigenvectors*consists of the*right*(as in right-hand side) eigenvectors of*a*. A vector*y*satisfying`y.T @ a = z * y.T`
for some number*z*is called a*left*eigenvector of*a*, and, in general, the left and right eigenvectors of a matrix are not necessarily the (perhaps conjugate) transposes of each other.References

G. Strang,

*Linear Algebra and Its Applications*, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, Various pp.Examples

>>> from numpy import linalg as LA
(Almost) trivial example with real eigenvalues and eigenvectors.

>>> eigenvalues, eigenvectors = LA.eig(np.diag((1, 2, 3))) >>> eigenvalues array([1., 2., 3.]) >>> eigenvectors array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])
Real matrix possessing complex eigenvalues and eigenvectors; note that the eigenvalues are complex conjugates of each other.

>>> eigenvalues, eigenvectors = LA.eig(np.array([[1, -1], [1, 1]])) >>> eigenvalues array([1.+1.j, 1.-1.j]) >>> eigenvectors array([[0.70710678+0.j , 0.70710678-0.j ], [0. -0.70710678j, 0. +0.70710678j]])
Complex-valued matrix with real eigenvalues (but complex-valued eigenvectors); note that

`a.conj().T == a`
, i.e.,*a*is Hermitian.>>> a = np.array([[1, 1j], [-1j, 1]]) >>> eigenvalues, eigenvectors = LA.eig(a) >>> eigenvalues array([2.+0.j, 0.+0.j]) >>> eigenvectors array([[ 0. +0.70710678j, 0.70710678+0.j ], # may vary [ 0.70710678+0.j , -0. +0.70710678j]])
Be careful about round-off error!

>>> a = np.array([[1 + 1e-9, 0], [0, 1 - 1e-9]]) >>> # Theor. eigenvalues are 1 +/- 1e-9 >>> eigenvalues, eigenvectors = LA.eig(a) >>> eigenvalues array([1., 1.]) >>> eigenvectors array([[1., 0.], [0., 1.]])# numpy.ma.masked_array.soften_mask[#](#numpy-ma-masked-array-soften-mask)
method

ma.masked_array.soften_mask()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L3571-L3587)[#](#numpy.ma.masked_array.soften_mask)
-
Force the mask to soft (default), allowing unmasking by assignment.

Whether the mask of a masked array is hard or soft is determined by its

property.`hardmask`
sets`soften_mask`
to`hardmask`
`False`
(and returns the modified self).# numpy.fft.fftshift[#](#numpy-fft-fftshift)
fft.fftshift(*x*,*axes=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/fft/helper.py#L19-L73)[#](#numpy.fft.fftshift)
-
Shift the zero-frequency component to the center of the spectrum.

This function swaps half-spaces for all axes listed (defaults to all). Note that

`y[0]`
is the Nyquist component only if`len(x)`
is even.Parameters:
-
**x**array_like
Input array.

**axes**int or shape tuple, optional
Axes over which to shift. Default is None, which shifts all axes.

Returns:
-
**y**ndarray
The shifted array.

Examples

>>> freqs = np.fft.fftfreq(10, 0.1) >>> freqs array([ 0., 1., 2., ..., -3., -2., -1.]) >>> np.fft.fftshift(freqs) array([-5., -4., -3., -2., -1., 0., 1., 2., 3., 4.])
Shift the zero-frequency component only along the second axis:

>>> freqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3) >>> freqs array([[ 0., 1., 2.], [ 3., 4., -4.], [-3., -2., -1.]]) >>> np.fft.fftshift(freqs, axes=(1,)) array([[ 2., 0., 1.], [-4., 3., 4.], [-1., -3., -2.]])# numpy.recarray.tolist[#](#numpy-recarray-tolist)
method

recarray.tolist()[#](#numpy.recarray.tolist)
-
Return the array as an

`a.ndim`
-levels deep nested list of Python scalars.Return a copy of the array data as a (nested) Python list. Data items are converted to the nearest compatible builtin Python type, via the

function.`item`
If

`a.ndim`
is 0, then since the depth of the nested list is 0, it will not be a list at all, but a simple Python scalar.Parameters:
-
**none**
Returns:
-
**y**object, or list of object, or list of list of object, or …
The possibly nested list of array elements.

Notes

The array may be recreated via

`a = np.array(a.tolist())`
, although this may sometimes lose precision.Examples

For a 1D array,

`a.tolist()`
is almost the same as`list(a)`
, except that`tolist`
changes numpy scalars to Python scalars:>>> a = np.uint32([1, 2]) >>> a_list = list(a) >>> a_list [1, 2] >>> type(a_list[0]) <class 'numpy.uint32'> >>> a_tolist = a.tolist() >>> a_tolist [1, 2] >>> type(a_tolist[0]) <class 'int'>
Additionally, for a 2D array,

`tolist`
applies recursively:>>> a = np.array([[1, 2], [3, 4]]) >>> list(a) [array([1, 2]), array([3, 4])] >>> a.tolist() [[1, 2], [3, 4]]
The base case for this recursion is a 0D array:

>>> a = np.array(1) >>> list(a) Traceback (most recent call last): ... TypeError: iteration over a 0-d array >>> a.tolist() 1# numpy.byte_bounds[#](#numpy-byte-bounds)
numpy.byte_bounds(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/utils.py#L270-L319)[#](#numpy.byte_bounds)
-
Returns pointers to the end-points of an array.

Parameters:
-
**a**ndarray
Input array. It must conform to the Python-side of the array interface.

Returns:
-
**(low, high)**tuple of 2 integers
The first integer is the first byte of the array, the second integer is just past the last byte of the array. If

*a*is not contiguous it will not use every byte between the (*low*,*high*) values.
Examples

>>> I = np.eye(2, dtype='f'); I.dtype dtype('float32') >>> low, high = np.byte_bounds(I) >>> high - low == I.size*I.itemsize True >>> I = np.eye(2); I.dtype dtype('float64') >>> low, high = np.byte_bounds(I) >>> high - low == I.size*I.itemsize True# numpy.ma.MaskedArray.view[#](#numpy-ma-maskedarray-view)
method

ma.MaskedArray.view(*dtype=None*,*type=None*,*fill_value=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L3127-L3215)[#](#numpy.ma.MaskedArray.view)
-
Return a view of the MaskedArray data.

Parameters:
-
**dtype**data-type or ndarray sub-class, optional
Data-type descriptor of the returned view, e.g., float32 or int16. The default, None, results in the view having the same data-type as

*a*. As with`ndarray.view`
, dtype can also be specified as an ndarray sub-class, which then specifies the type of the returned object (this is equivalent to setting the`type`
parameter).
**type**Python type, optional
Type of the returned view, either ndarray or a subclass. The default None results in type preservation.

**fill_value**scalar, optional
The value to use for invalid entries (None by default). If None, then this argument is inferred from the passed

, or in its absence the original array, as discussed in the notes below.`dtype`
See also

`numpy.ndarray.view`
Equivalent method on ndarray object.

Notes

`a.view()`
is used two different ways:`a.view(some_dtype)`
or`a.view(dtype=some_dtype)`
constructs a view of the array’s memory with a different data-type. This can cause a reinterpretation of the bytes of memory.`a.view(ndarray_subclass)`
or`a.view(type=ndarray_subclass)`
just returns an instance of*ndarray_subclass*that looks at the same array (same shape, dtype, etc.) This does not cause a reinterpretation of the memory.If

is not specified, but`fill_value`
is specified (and is not an ndarray sub-class), the`dtype`
of the MaskedArray will be reset. If neither`fill_value`
nor`fill_value`
are specified (or if`dtype`
is an ndarray sub-class), then the fill value is preserved. Finally, if`dtype`
is specified, but`fill_value`
is not, the fill value is set to the specified value.`dtype`
For

`a.view(some_dtype)`
, if`some_dtype`
has a different number of bytes per entry than the previous dtype (for example, converting a regular array to a structured array), then the behavior of the view cannot be predicted just from the superficial appearance of`a`
(shown by`print(a)`
). It also depends on exactly how`a`
is stored in memory. Therefore if`a`
is C-ordered versus fortran-ordered, versus defined as a slice or transpose, etc., the view may give different results.# numpy.min_scalar_type[#](#numpy-min-scalar-type)
numpy.min_scalar_type(*a*,*/*)[#](#numpy.min_scalar_type)
-
For scalar

`a`
, returns the data type with the smallest size and smallest scalar kind which can hold its value. For non-scalar array`a`
, returns the vector’s dtype unmodified.Floating point values are not demoted to integers, and complex values are not demoted to floats.

Parameters:
-
**a**scalar or array_like
The value whose minimal data type is to be found.

Returns:
-
**out**dtype
The minimal data type.

See also

Notes

New in version 1.6.0.

Examples

>>> np.min_scalar_type(10) dtype('uint8')
>>> np.min_scalar_type(-260) dtype('int16')
>>> np.min_scalar_type(3.1) dtype('float16')
>>> np.min_scalar_type(1e50) dtype('float64')
>>> np.min_scalar_type(np.arange(4,dtype='f8')) dtype('float64')# numpy.chararray.diagonal[#](#numpy-chararray-diagonal)
method

chararray.diagonal(*offset=0*,*axis1=0*,*axis2=1*)[#](#numpy.chararray.diagonal)
-
Return specified diagonals. In NumPy 1.9 the returned array is a read-only view instead of a copy as in previous NumPy versions. In a future version the read-only restriction will be removed.

Refer to

for full documentation.`numpy.diagonal`
See also

`numpy.diagonal`
equivalent function# numpy.zeros[#](#numpy-zeros)
numpy.zeros(*shape*,*dtype=float*,*order='C'*,***,*like=None*)[#](#numpy.zeros)
-
Return a new array of given shape and type, filled with zeros.

Parameters:
-
**shape**int or tuple of ints
Shape of the new array, e.g.,

`(2, 3)`
or`2`
.
**dtype**data-type, optional
The desired data-type for the array, e.g.,

. Default is`numpy.int8`
.`numpy.float64`
**order**{‘C’, ‘F’}, optional, default: ‘C’
Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**out**ndarray
Array of zeros with the given shape, dtype, and order.

See also

`zeros_like`
Return an array of zeros with shape and type of input.

`empty`
Return a new uninitialized array.

`ones`
Return a new array setting values to one.

`full`
Return a new array of given shape filled with value.

Examples

>>> np.zeros(5) array([ 0., 0., 0., 0., 0.])
>>> np.zeros((5,), dtype=int) array([0, 0, 0, 0, 0])
>>> np.zeros((2, 1)) array([[ 0.], [ 0.]])
>>> s = (2,2) >>> np.zeros(s) array([[ 0., 0.], [ 0., 0.]])
>>> np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype array([(0, 0), (0, 0)], dtype=[('x', '<i4'), ('y', '<i4')])# numpy.memmap.tolist[#](#numpy-memmap-tolist)
method

memmap.tolist()[#](#numpy.memmap.tolist)
-
Return the array as an

`a.ndim`
-levels deep nested list of Python scalars.Return a copy of the array data as a (nested) Python list. Data items are converted to the nearest compatible builtin Python type, via the

function.`item`
If

`a.ndim`
is 0, then since the depth of the nested list is 0, it will not be a list at all, but a simple Python scalar.Parameters:
-
**none**
Returns:
-
**y**object, or list of object, or list of list of object, or …
The possibly nested list of array elements.

Notes

The array may be recreated via

`a = np.array(a.tolist())`
, although this may sometimes lose precision.Examples

For a 1D array,

`a.tolist()`
is almost the same as`list(a)`
, except that`tolist`
changes numpy scalars to Python scalars:>>> a = np.uint32([1, 2]) >>> a_list = list(a) >>> a_list [1, 2] >>> type(a_list[0]) <class 'numpy.uint32'> >>> a_tolist = a.tolist() >>> a_tolist [1, 2] >>> type(a_tolist[0]) <class 'int'>
Additionally, for a 2D array,

`tolist`
applies recursively:>>> a = np.array([[1, 2], [3, 4]]) >>> list(a) [array([1, 2]), array([3, 4])] >>> a.tolist() [[1, 2], [3, 4]]
The base case for this recursion is a 0D array:

>>> a = np.array(1) >>> list(a) Traceback (most recent call last): ... TypeError: iteration over a 0-d array >>> a.tolist() 1User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
lib.user_array.container.byteswap
numpy.lib.user_array.container.byteswap
#
method
lib.user_array.container.
byteswap
(
)
[source]
#ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__ior__

method

Return self|=value.# numpy.cumsum[#](#numpy-cumsum)
numpy.cumsum(*a*,*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L2512-L2586)[#](#numpy.cumsum)
-
Return the cumulative sum of the elements along a given axis.

Parameters:
-
**a**array_like
Input array.

**axis**int, optional
Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.

**dtype**dtype, optional
Type of the returned array and of the accumulator in which the elements are summed. If

is not specified, it defaults to the dtype of`dtype`
*a*, unless*a*has an integer dtype with a precision less than that of the default platform integer. In that case, the default platform integer is used.
**out**ndarray, optional
Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary. See

[Output type determination](../../user/basics.ufuncs.html#ufuncs-output-type)for more details.
Returns:
-
**cumsum_along_axis**ndarray.
A new array holding the result is returned unless

*out*is specified, in which case a reference to*out*is returned. The result has the same size as*a*, and the same shape as*a*if*axis*is not None or*a*is a 1-d array.
See also

Notes

Arithmetic is modular when using integer types, and no error is raised on overflow.

`cumsum(a)[-1]`
may not be equal to`sum(a)`
for floating-point values since`sum`
may use a pairwise summation routine, reducing the roundoff-error. Seefor more information.`sum`
Examples

>>> a = np.array([[1,2,3], [4,5,6]]) >>> a array([[1, 2, 3], [4, 5, 6]]) >>> np.cumsum(a) array([ 1, 3, 6, 10, 15, 21]) >>> np.cumsum(a, dtype=float) # specifies type of output value(s) array([ 1., 3., 6., 10., 15., 21.])
>>> np.cumsum(a,axis=0) # sum over rows for each of the 3 columns array([[1, 2, 3], [5, 7, 9]]) >>> np.cumsum(a,axis=1) # sum over columns for each of the 2 rows array([[ 1, 3, 6], [ 4, 9, 15]])
`cumsum(b)[-1]`
may not be equal to`sum(b)`
>>> b = np.array([1, 2e-9, 3e-9] * 1000000) >>> b.cumsum()[-1] 1000000.0050045159 >>> b.sum() 1000000.0050000029User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
lib.user_array.container.copy
numpy.lib.user_array.container.copy
#
method
lib.user_array.container.
copy
(
)
[source]
#numpy.generic.base# attribute generic.base# Scalar attribute identical to the corresponding array attribute. Please see ndarray.base.# numpy.mgrid[#](#numpy-mgrid)
numpy.mgrid*= <numpy.lib.index_tricks.MGridClass object>*[#](#numpy.mgrid)
-
An instance which returns a dense multi-dimensional “meshgrid”.

An instance which returns a dense (or fleshed out) mesh-grid when indexed, so that each returned argument has the same shape. The dimensions and number of the output arrays are equal to the number of indexing dimensions. If the step length is not a complex number, then the stop is not inclusive.

However, if the step length is a

**complex number**(e.g. 5j), then the integer part of its magnitude is interpreted as specifying the number of points to create between the start and stop values, where the stop value**is inclusive**.Returns:
-
mesh-grid *ndarrays*all of the same dimensions
-
mesh-grid
-
See also

`ogrid`
like

but returns open (not fleshed out) mesh grids`mgrid`
`meshgrid`
return coordinate matrices from coordinate vectors

`r_`
array concatenator

[How to create arrays with regularly-spaced values](../../user/how-to-partition.html#how-to-partition)
Examples

>>> np.mgrid[0:5, 0:5] array([[[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3], [4, 4, 4, 4, 4]], [[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]]) >>> np.mgrid[-1:1:5j] array([-1. , -0.5, 0. , 0.5, 1. ])# numpy.polynomial.legendre.Legendre.degree[#](#numpy-polynomial-legendre-legendre-degree)
method

polynomial.legendre.Legendre.degree()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L675-L708)[#](#numpy.polynomial.legendre.Legendre.degree)
-
The degree of the series.

New in version 1.5.0.

Returns:
-
**degree**int
Degree of the series, one less than the number of coefficients.

Examples

Create a polynomial object for

`1 + 7*x + 4*x**2`
:>>> poly = np.polynomial.Polynomial([1, 7, 4]) >>> print(poly) 1.0 + 7.0·x + 4.0·x² >>> poly.degree() 2
Note that this method does not check for non-zero coefficients. You must trim the polynomial to remove any trailing zeroes:

>>> poly = np.polynomial.Polynomial([1, 7, 0]) >>> print(poly) 1.0 + 7.0·x + 0.0·x² >>> poly.degree() 2 >>> poly.trim().degree() 1# numpy.char.chararray.count[#](#numpy-char-chararray-count)
method

char.chararray.count(*sub*,*start=0*,*end=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2283-L2293)[#](#numpy.char.chararray.count)
-
Returns an array with the number of non-overlapping occurrences of substring

*sub*in the range [*start*,*end*].See also

method

Returns an array with the number of non-overlapping occurrences of
substring *sub* in the range [*start*, *end*].

See alsoUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
iinfo.min
numpy.iinfo.min
#
property
property
iinfo.
min
#
Minimum value of given dtype.# numpy.dtype.itemsize[#](#numpy-dtype-itemsize)
attribute

dtype.itemsize[#](#numpy.dtype.itemsize)
-
The element size of this data-type object.

For 18 of the 21 types this number is fixed by the data-type. For the flexible data-types, this number can be anything.

Examples

>>> arr = np.array([[1, 2], [3, 4]]) >>> arr.dtype dtype('int64') >>> arr.itemsize 8
>>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))]) >>> dt.itemsize 80# numpy.floor[#](#numpy-floor)
numpy.floor(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'floor'>*[#](#numpy.floor)
-
Return the floor of the input, element-wise.

The floor of the scalar

*x*is the largest integer*i*, such that*i <= x*. It is often denoted as \(\lfloor x \rfloor\).Parameters:
-
**x**array_like
Input data.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray or scalar
The floor of each element in

*x*. This is a scalar if*x*is a scalar.
Notes

Some spreadsheet programs calculate the “floor-towards-zero”, where

`floor(-2.5) == -2`
. NumPy instead uses the definition ofwhere`floor`
*floor(-2.5) == -3*. The “floor-towards-zero” function is called`fix`
in NumPy.Examples

>>> a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) >>> np.floor(a) array([-2., -2., -1., 0., 1., 1., 2.])# numpy.ma.masked_array.recordmask[#](#numpy-ma-masked-array-recordmask)
property

*property*ma.masked_array.recordmask[#](#numpy.ma.masked_array.recordmask)
-
Get or set the mask of the array if it has no named fields. For structured arrays, returns a ndarray of booleans where entries are

`True`
if**all**the fields are masked,`False`
otherwise:>>> x = np.ma.array([(1, 1), (2, 2), (3, 3), (4, 4), (5, 5)], ... mask=[(0, 0), (1, 0), (1, 1), (0, 1), (0, 0)], ... dtype=[('a', int), ('b', int)]) >>> x.recordmask array([False, False, True, False, False])# numpy.char.chararray.astype[#](#numpy-char-chararray-astype)
method

char.chararray.astype(*dtype*,*order='K'*,*casting='unsafe'*,*subok=True*,*copy=True*)[#](#numpy.char.chararray.astype)
-
Copy of the array, cast to a specified type.

Parameters:
-
**dtype**str or dtype
Typecode or data-type to which the array is cast.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout order of the result. ‘C’ means C order, ‘F’ means Fortran order, ‘A’ means ‘F’ order if all the arrays are Fortran contiguous, ‘C’ order otherwise, and ‘K’ means as close to the order the array elements appear in memory as possible. Default is ‘K’.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘unsafe’ for backwards compatibility.

‘no’ means the data types should not be cast at all.

‘equiv’ means only byte-order changes are allowed.

‘safe’ means only casts which can preserve values are allowed.

‘same_kind’ means only safe casts or casts within a kind, like float64 to float32, are allowed.

‘unsafe’ means any data conversions may be done.

**subok**bool, optional
If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.

**copy**bool, optional
By default, astype always returns a newly allocated array. If this is set to false, and the

,`dtype`
*order*, and*subok*requirements are satisfied, the input array is returned instead of a copy.
Returns:
-
Raises:
-
ComplexWarning
-
When casting from complex to float or int. To avoid this, one should use

`a.real.astype(t)`
.
Notes

Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for “unsafe” casting. Casting to multiple fields is allowed, but casting from multiple fields is not.

Changed in version 1.9.0: Casting from numeric to string types in ‘safe’ casting mode requires that the string dtype length is long enough to store the max integer/float value converted.

Examples

>>> x = np.array([1, 2, 2.5]) >>> x array([1. , 2. , 2.5])
>>> x.astype(int) array([1, 2, 2])numpy.random.PCG64.state# attribute random.PCG64.state# Get or set the PRNG state Returns: statedictDictionary containing the information required to describe the state of the PRNG# numpy.ldexp[#](#numpy-ldexp)
numpy.ldexp(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'ldexp'>*[#](#numpy.ldexp)
-
Returns x1 * 2**x2, element-wise.

The mantissas

*x1*and twos exponents*x2*are used to construct floating point numbers`x1 * 2**x2`
.Parameters:
-
**x1**array_like
Array of multipliers.

**x2**array_like, int
Array of twos exponents. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray or scalar
The result of

`x1 * 2**x2`
. This is a scalar if both*x1*and*x2*are scalars.
Notes

Complex dtypes are not supported, they will raise a TypeError.

is useful as the inverse of`ldexp`
, if used by itself it is more clear to simply use the expression`frexp`
`x1 * 2**x2`
.Examples

>>> np.ldexp(5, np.arange(4)) array([ 5., 10., 20., 40.], dtype=float16)
>>> x = np.arange(6) >>> np.ldexp(*np.frexp(x)) array([ 0., 1., 2., 3., 4., 5.])# numpy.frompyfunc[#](#numpy-frompyfunc)
numpy.frompyfunc(*func*,*/*,*nin*,*nout*,***[,*identity*])[#](#numpy.frompyfunc)
-
Takes an arbitrary Python function and returns a NumPy ufunc.

Can be used, for example, to add broadcasting to a built-in Python function (see Examples section).

Parameters:
-
**func**Python function object
An arbitrary Python function.

**nin**int
The number of input arguments.

**nout**int
The number of objects returned by

*func*.
**identity**object, optional
The value to use for the

attribute of the resulting object. If specified, this is equivalent to setting the underlying C`identity`
`identity`
field to`PyUFunc_IdentityValue`
. If omitted, the identity is set to`PyUFunc_None`
. Note that this is _not_ equivalent to setting the identity to`None`
, which implies the operation is reorderable.
Returns:
-
**out**ufunc
Returns a NumPy universal function (

`ufunc`
) object.
See also

`vectorize`
Evaluates pyfunc over input arrays using broadcasting rules of numpy.

Notes

The returned ufunc always returns PyObject arrays.

Examples

Use frompyfunc to add broadcasting to the Python function

`oct`
:>>> oct_array = np.frompyfunc(oct, 1, 1) >>> oct_array(np.array((10, 30, 100))) array(['0o12', '0o36', '0o144'], dtype=object) >>> np.array((oct(10), oct(30), oct(100))) # for comparison array(['0o12', '0o36', '0o144'], dtype='<U5')# numpy.ma.masked_array.base[#](#numpy-ma-masked-array-base)
attribute

ma.masked_array.base[#](#numpy.ma.masked_array.base)
-
Base object if memory is from some other object.

Examples

The base of an array that owns its memory is None:

>>> x = np.array([1,2,3,4]) >>> x.base is None True
Slicing creates a view, whose memory is shared with x:

>>> y = x[2:] >>> y.base is x True# numpy.ma.masked_array.cumprod[#](#numpy-ma-masked-array-cumprod)
method

ma.masked_array.cumprod(*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5275-L5304)[#](#numpy.ma.masked_array.cumprod)
-
Return the cumulative product of the array elements over the given axis.

Masked values are set to 1 internally during the computation. However, their position is saved, and the result will be masked at the same locations.

Refer to

for full documentation.`numpy.cumprod`
See also

`numpy.ndarray.cumprod`
corresponding function for ndarrays

`numpy.cumprod`
equivalent function

Notes

The mask is lost if

*out*is not a valid MaskedArray !Arithmetic is modular when using integer types, and no error is raised on overflow.# numpy.polynomial.hermite.hermint[#](#numpy-polynomial-hermite-hermint)
polynomial.hermite.hermint(*c*,*m=1*,*k=[]*,*lbnd=0*,*scl=1*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L680-L799)[#](#numpy.polynomial.hermite.hermint)
-
Integrate a Hermite series.

Returns the Hermite series coefficients

*c*integrated*m*times from*lbnd*along*axis*. At each iteration the resulting series is**multiplied**by*scl*and an integration constant,*k*, is added. The scaling factor is for use in a linear change of variable. (“Buyer beware”: note that, depending on what one is doing, one may want*scl*to be the reciprocal of what one might expect; for more information, see the Notes section below.) The argument*c*is an array of coefficients from low to high degree along each axis, e.g., [1,2,3] represents the series`H_0 + 2*H_1 + 3*H_2`
while [[1,2],[1,2]] represents`1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) + 2*H_0(x)*H_1(y) + 2*H_1(x)*H_1(y)`
if axis=0 is`x`
and axis=1 is`y`
.Parameters:
-
**c**array_like
Array of Hermite series coefficients. If c is multidimensional the different axis correspond to different variables with the degree in each axis given by the corresponding index.

**m**int, optional
Order of integration, must be positive. (Default: 1)

**k**{[], list, scalar}, optional
Integration constant(s). The value of the first integral at

`lbnd`
is the first value in the list, the value of the second integral at`lbnd`
is the second value, etc. If`k == []`
(the default), all constants are set to zero. If`m == 1`
, a single scalar can be given instead of a list.
**lbnd**scalar, optional
The lower bound of the integral. (Default: 0)

**scl**scalar, optional
Following each integration the result is

*multiplied*by*scl*before the integration constant is added. (Default: 1)
**axis**int, optional
Axis over which the integral is taken. (Default: 0).

New in version 1.7.0.

Returns:
-
**S**ndarray
Hermite series coefficients of the integral.

Raises:
-
ValueError
-
If

`m < 0`
,`len(k) > m`
,`np.ndim(lbnd) != 0`
, or`np.ndim(scl) != 0`
.
See also

Notes

Note that the result of each integration is

*multiplied*by*scl*. Why is this important to note? Say one is making a linear change of variable \(u = ax + b\) in an integral relative to*x*. Then \(dx = du/a\), so one will need to set*scl*equal to \(1/a\) - perhaps not what one would have first thought.Also note that, in general, the result of integrating a C-series needs to be “reprojected” onto the C-series basis set. Thus, typically, the result of this function is “unintuitive,” albeit correct; see Examples section below.

Examples

>>> from numpy.polynomial.hermite import hermint >>> hermint([1,2,3]) # integrate once, value 0 at 0. array([1. , 0.5, 0.5, 0.5]) >>> hermint([1,2,3], m=2) # integrate twice, value & deriv 0 at 0 array([-0.5 , 0.5 , 0.125 , 0.08333333, 0.0625 ]) # may vary >>> hermint([1,2,3], k=1) # integrate once, value 1 at 0. array([2. , 0.5, 0.5, 0.5]) >>> hermint([1,2,3], lbnd=-1) # integrate once, value 0 at -1 array([-2. , 0.5, 0.5, 0.5]) >>> hermint([1,2,3], m=2, k=[1,2], lbnd=-1) array([ 1.66666667, -0.5 , 0.125 , 0.08333333, 0.0625 ]) # may vary# numpy.ma.is_masked[#](#numpy-ma-is-masked)
ma.is_masked(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L6677-L6727)[#](#numpy.ma.is_masked)
-
Determine whether input has masked values.

Accepts any object as input, but always returns False unless the input is a MaskedArray containing masked values.

Parameters:
-
**x**array_like
Array to check for masked values.

Returns:
-
**result**bool
True if

*x*is a MaskedArray with masked values, False otherwise.
Examples

>>> import numpy.ma as ma >>> x = ma.masked_equal([0, 1, 0, 2, 3], 0) >>> x masked_array(data=[--, 1, --, 2, 3], mask=[ True, False, True, False, False], fill_value=0) >>> ma.is_masked(x) True >>> x = ma.masked_equal([0, 1, 0, 2, 3], 42) >>> x masked_array(data=[0, 1, 0, 2, 3], mask=False, fill_value=42) >>> ma.is_masked(x) False
Always returns False if

*x*isn’t a MaskedArray.>>> x = [False, True, False] >>> ma.is_masked(x) False >>> x = 'a string' >>> ma.is_masked(x) False# numpy.polynomial.legendre.Legendre.trim[#](#numpy-polynomial-legendre-legendre-trim)
method

polynomial.legendre.Legendre.trim(*tol=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L735-L756)[#](#numpy.polynomial.legendre.Legendre.trim)
-
Remove trailing coefficients

Remove trailing coefficients until a coefficient is reached whose absolute value greater than

*tol*or the beginning of the series is reached. If all the coefficients would be removed the series is set to`[0]`
. A new series instance is returned with the new coefficients. The current instance remains unchanged.Parameters:
-
**tol**non-negative number.
All trailing coefficients less than

*tol*will be removed.
Returns:
-
**new_series**series
New instance of series with trimmed coefficients.# numpy.random.random_sample[#](#numpy-random-random-sample)
random.random_sample(*size=None*)[#](#numpy.random.random_sample)
-
Return random floats in the half-open interval [0.0, 1.0).

Results are from the “continuous uniform” distribution over the stated interval. To sample \(Unif[a, b), b > a\) multiply the output of

by`random_sample`
*(b-a)*and add*a*:(b - a) * random_sample() + a
Note

New code should use the

method of a`random`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**out**float or ndarray of floats
Array of random floats of shape

`size`
(unless`size=None`
, in which case a single float is returned).
See also

`random.Generator.random`
which should be used for new code.

Examples

>>> np.random.random_sample() 0.47108547995356098 # random >>> type(np.random.random_sample()) <class 'float'> >>> np.random.random_sample((5,)) array([ 0.30220482, 0.86820401, 0.1654503 , 0.11659149, 0.54323428]) # random
Three-by-two array of random numbers from [-5, 0):

>>> 5 * np.random.random_sample((3, 2)) - 5 array([[-3.99149989, -0.52338984], # random [-2.99091858, -0.79479508], [-1.23204345, -1.75224494]])# numpy.ma.MaskType.argmax[#](#numpy-ma-masktype-argmax)
method

ma.MaskType.argmax()[#](#numpy.ma.MaskType.argmax)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.argmax`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.argmax](numpy.ndarray.argmax.html#numpy.ndarray.argmax).# numpy.gcd[#](#numpy-gcd)
numpy.gcd(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'gcd'>*[#](#numpy.gcd)
-
Returns the greatest common divisor of

`|x1|`
and`|x2|`
Parameters:
-
**x1, x2**array_like, int
Arrays of values. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
Returns:
-
**y**ndarray or scalar
The greatest common divisor of the absolute value of the inputs This is a scalar if both

*x1*and*x2*are scalars.
See also

`lcm`
The lowest common multiple

Examples

>>> np.gcd(12, 20) 4 >>> np.gcd.reduce([15, 25, 35]) 5 >>> np.gcd(np.arange(6), 20) array([20, 1, 2, 1, 4, 5])# numpy.recarray.shape[#](#numpy-recarray-shape)
attribute

recarray.shape[#](#numpy.recarray.shape)
-
Tuple of array dimensions.

The shape property is usually used to get the current shape of an array, but may also be used to reshape the array in-place by assigning a tuple of array dimensions to it. As with

, one of the new shape dimensions can be -1, in which case its value is inferred from the size of the array and the remaining dimensions. Reshaping an array in-place will fail if a copy is required.`numpy.reshape`
Warning

Setting

`arr.shape`
is discouraged and may be deprecated in the future. Usingis the preferred approach.`ndarray.reshape`
See also

`numpy.shape`
Equivalent getter function.

`numpy.reshape`
Function similar to setting

`shape`
.
`ndarray.reshape`
Method similar to setting

`shape`
.
Examples

>>> x = np.array([1, 2, 3, 4]) >>> x.shape (4,) >>> y = np.zeros((2, 3, 4)) >>> y.shape (2, 3, 4) >>> y.shape = (3, 8) >>> y array([[ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.]]) >>> y.shape = (3, 6) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: total size of new array must be unchanged >>> np.zeros((4,2))[::2].shape = (-1,) Traceback (most recent call last): File "<stdin>", line 1, in <module> AttributeError: Incompatible shape for in-place modification. Use `.reshape()` to make a copy with the desired shape.# numpy.random.MT19937.ctypes[#](#numpy-random-mt19937-ctypes)
attribute

random.MT19937.ctypes[#](#numpy.random.MT19937.ctypes)
-
ctypes interface

Returns:
-
**interface**namedtuple
Named tuple containing ctypes wrapper

state_address - Memory address of the state struct

state - pointer to the state struct

next_uint64 - function pointer to produce 64 bit integers

next_uint32 - function pointer to produce 32 bit integers

next_double - function pointer to produce doubles

bitgen - pointer to the bit generator structnumpy.ma.MaskType.max# method ma.MaskType.max()# Scalar method identical to the corresponding array attribute. Please see ndarray.max.# numpy.chararray.isdecimal[#](#numpy-chararray-isdecimal)
method

chararray.isdecimal()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2717-L2727)[#](#numpy.chararray.isdecimal)
-
For each element in

*self*, return True if there are only decimal characters in the element.See also

method

For each element in *self*, return True if there are only
decimal characters in the element.

See also# numpy.polynomial.hermite_e.hermedomain[#](#numpy-polynomial-hermite-e-hermedomain)
polynomial.hermite_e.hermedomain*= array([-1, 1])*[#](#numpy.polynomial.hermite_e.hermedomain)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.polynomial.polynomial.Polynomial.truncate[#](#numpy-polynomial-polynomial-polynomial-truncate)
method

polynomial.polynomial.Polynomial.truncate(*size*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L758-L785)[#](#numpy.polynomial.polynomial.Polynomial.truncate)
-
Truncate series to length

`size`
.Reduce the series to length

`size`
by discarding the high degree terms. The value of`size`
must be a positive integer. This can be useful in least squares where the coefficients of the high degree terms may be very small.Parameters:
-
**size**positive int
The series is reduced to length

`size`
by discarding the high degree terms. The value of`size`
must be a positive integer.
Returns:
-
**new_series**series
New instance of series with truncated coefficients.# numpy.ma.diagflat[#](#numpy-ma-diagflat)
ma.diagflat*= <numpy.ma.extras._fromnxfunction_single object>*[#](#numpy.ma.diagflat)
-
diagflat

Create a two-dimensional array with the flattened input as a diagonal.

Parameters:
-
**v**array_like
Input data, which is flattened and set as the

*k*-th diagonal of the output.
**k**int, optional
Diagonal to set; 0, the default, corresponds to the “main” diagonal, a positive (negative)

*k*giving the number of the diagonal above (below) the main.
Returns:
-
**out**ndarray
The 2-D output array.

See also

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> np.diagflat([[1,2], [3,4]]) array([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 0], [0, 0, 0, 4]])
>>> np.diagflat([1,2], 1) array([[0, 1, 0], [0, 0, 2], [0, 0, 0]])# numpy.polynomial.hermite.hermvander3d[#](#numpy-polynomial-hermite-hermvander3d)
polynomial.hermite.hermvander3d(*x*,*y*,*z*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L1221-L1272)[#](#numpy.polynomial.hermite.hermvander3d)
-
Pseudo-Vandermonde matrix of given degrees.

Returns the pseudo-Vandermonde matrix of degrees

*deg*and sample points*(x, y, z)*. If*l, m, n*are the given degrees in*x, y, z*, then The pseudo-Vandermonde matrix is defined by\[V[..., (m+1)(n+1)i + (n+1)j + k] = H_i(x)*H_j(y)*H_k(z),\]where

*0 <= i <= l*,*0 <= j <= m*, and*0 <= j <= n*. The leading indices of*V*index the points*(x, y, z)*and the last index encodes the degrees of the Hermite polynomials.If

`V = hermvander3d(x, y, z, [xdeg, ydeg, zdeg])`
, then the columns of*V*correspond to the elements of a 3-D coefficient array*c*of shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order\[c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...\]and

`np.dot(V, c.flat)`
and`hermval3d(x, y, z, c)`
will be the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of 3-D Hermite series of the same degrees and sample points.Parameters:
-
**x, y, z**array_like
Arrays of point coordinates, all of the same shape. The dtypes will be converted to either float64 or complex128 depending on whether any of the elements are complex. Scalars are converted to 1-D arrays.

**deg**list of ints
List of maximum degrees of the form [x_deg, y_deg, z_deg].

Returns:
-
**vander3d**ndarray
The shape of the returned matrix is

`x.shape + (order,)`
, where \(order = (deg[0]+1)*(deg[1]+1)*(deg[2]+1)\). The dtype will be the same as the converted*x*,*y*, and*z*.
See also

Notes

New in version 1.7.0.# numpy.polynomial.laguerre.lagweight[#](#numpy-polynomial-laguerre-lagweight)
polynomial.laguerre.lagweight(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L1576-L1600)[#](#numpy.polynomial.laguerre.lagweight)
-
Weight function of the Laguerre polynomials.

The weight function is \(exp(-x)\) and the interval of integration is \([0, \inf]\). The Laguerre polynomials are orthogonal, but not normalized, with respect to this weight function.

Parameters:
-
**x**array_like
Values at which the weight function will be computed.

Returns:
-
**w**ndarray
The weight function at

*x*.
Notes

New in version 1.7.0.# numpy.polynomial.chebyshev.Chebyshev.integ[#](#numpy-polynomial-chebyshev-chebyshev-integ)
method

polynomial.chebyshev.Chebyshev.integ(*m=1*,*k=[]*,*lbnd=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L853-L884)[#](#numpy.polynomial.chebyshev.Chebyshev.integ)
-
Integrate.

Return a series instance that is the definite integral of the current series.

Parameters:
-
**m**non-negative int
The number of integrations to perform.

**k**array_like
Integration constants. The first constant is applied to the first integration, the second to the second, and so on. The list of values must less than or equal to

*m*in length and any missing values are set to zero.
**lbnd**Scalar
The lower bound of the definite integral.

Returns:
-
**new_series**series
A new series representing the integral. The domain is the same as the domain of the integrated series.# numpy.random.RandomState.wald[#](#numpy-random-randomstate-wald)
method

random.RandomState.wald(*mean*,*scale*,*size=None*)[#](#numpy.random.RandomState.wald)
-
Draw samples from a Wald, or inverse Gaussian, distribution.

As the scale approaches infinity, the distribution becomes more like a Gaussian. Some references claim that the Wald is an inverse Gaussian with mean equal to 1, but this is by no means universal.

The inverse Gaussian distribution was first studied in relationship to Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian because there is an inverse relationship between the time to cover a unit distance and distance covered in unit time.

Note

New code should use the

method of a`wald`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**mean**float or array_like of floats
Distribution mean, must be > 0.

**scale**float or array_like of floats
Scale parameter, must be > 0.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`mean`
and`scale`
are both scalars. Otherwise,`np.broadcast(mean, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Wald distribution.

See also

`random.Generator.wald`
which should be used for new code.

Notes

The probability density function for the Wald distribution is

\[P(x;mean,scale) = \sqrt{\frac{scale}{2\pi x^3}}e^ \frac{-scale(x-mean)^2}{2\cdotp mean^2x}\]As noted above the inverse Gaussian distribution first arise from attempts to model Brownian motion. It is also a competitor to the Weibull for use in reliability modeling and modeling stock returns and interest rate processes.

References

[1]Brighton Webs Ltd., Wald Distribution,

[https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp](https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp)[2]Chhikara, Raj S., and Folks, J. Leroy, “The Inverse Gaussian Distribution: Theory : Methodology, and Applications”, CRC Press, 1988.

[3]Wikipedia, “Inverse Gaussian distribution”

[https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution](https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution)Examples

Draw values from the distribution and plot the histogram:

>>> import matplotlib.pyplot as plt >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True) >>> plt.show()# numpy.random.RandomState.set_state[#](#numpy-random-randomstate-set-state)
method

random.RandomState.set_state(*state*)[#](#numpy.random.RandomState.set_state)
-
Set the internal state of the generator from a tuple.

For use if one has reason to manually (re-)set the internal state of the bit generator used by the RandomState instance. By default, RandomState uses the “Mersenne Twister”

[[1]](#rd62dfb5ffa26-1)pseudo-random number generating algorithm.Parameters:
-
**state**{tuple(str, ndarray of 624 uints, int, int, float), dict}
The

*state*tuple has the following items:the string ‘MT19937’, specifying the Mersenne Twister algorithm.

a 1-D array of 624 unsigned integers

`keys`
.
an integer

`pos`
.
an integer

`has_gauss`
.
a float

`cached_gaussian`
.
If state is a dictionary, it is directly set using the BitGenerators

*state*property.
Returns:
-
**out**None
Returns ‘None’ on success.

See also

Notes

and`set_state`
are not needed to work with any of the random distributions in NumPy. If the internal state is manually altered, the user should know exactly what he/she is doing.`get_state`
For backwards compatibility, the form (str, array of 624 uints, int) is also accepted although it is missing some information about the cached Gaussian value:

`state = ('MT19937', keys, pos)`
.References

[[1](#id1)]M. Matsumoto and T. Nishimura, “Mersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator,”

*ACM Trans. on Modeling and Computer Simulation*, Vol. 8, No. 1, pp. 3-30, Jan. 1998.numpy.chararray.sum# method chararray.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)# Return the sum of the array elements over the given axis. Refer to numpy.sum for full documentation. See also numpy.sumequivalent functionnumpy.chararray.rindex# method chararray.rindex(sub, start=0, end=None)[source]# Like rfind, but raises ValueError when the substring sub is not found. See also char.rindex# numpy.random.Generator.pareto[#](#numpy-random-generator-pareto)
method

random.Generator.pareto(*a*,*size=None*)[#](#numpy.random.Generator.pareto)
-
Draw samples from a Pareto II or Lomax distribution with specified shape.

The Lomax or Pareto II distribution is a shifted Pareto distribution. The classical Pareto distribution can be obtained from the Lomax distribution by adding 1 and multiplying by the scale parameter

`m`
(see Notes). The smallest value of the Lomax distribution is zero while for the classical Pareto distribution it is`mu`
, where the standard Pareto distribution has location`mu = 1`
. Lomax can also be considered as a simplified version of the Generalized Pareto distribution (available in SciPy), with the scale set to one and the location set to zero.The Pareto distribution must be greater than zero, and is unbounded above. It is also known as the “80-20 rule”. In this distribution, 80 percent of the weights are in the lowest 20 percent of the range, while the other 20 percent fill the remaining 80 percent of the range.

Parameters:
-
**a**float or array_like of floats
Shape of the distribution. Must be positive.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`a`
is a scalar. Otherwise,`np.array(a).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Pareto distribution.

See also

`scipy.stats.lomax`
probability density function, distribution or cumulative density function, etc.

`scipy.stats.genpareto`
probability density function, distribution or cumulative density function, etc.

Notes

The probability density for the Pareto distribution is

\[p(x) = \frac{am^a}{x^{a+1}}\]where \(a\) is the shape and \(m\) the scale.

The Pareto distribution, named after the Italian economist Vilfredo Pareto, is a power law probability distribution useful in many real world problems. Outside the field of economics it is generally referred to as the Bradford distribution. Pareto developed the distribution to describe the distribution of wealth in an economy. It has also found use in insurance, web page access statistics, oil field sizes, and many other problems, including the download frequency for projects in Sourceforge

[[1]](#rc338d9f74bfc-1). It is one of the so-called “fat-tailed” distributions.References

[[1](#id1)]Francis Hunt and Paul Johnson, On the Pareto Distribution of Sourceforge projects.

[2]Pareto, V. (1896). Course of Political Economy. Lausanne.

[3]Reiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme Values, Birkhauser Verlag, Basel, pp 23-30.

[4]Wikipedia, “Pareto distribution”,

[https://en.wikipedia.org/wiki/Pareto_distribution](https://en.wikipedia.org/wiki/Pareto_distribution)Examples

Draw samples from the distribution:

>>> a, m = 3., 2. # shape and mode >>> s = (np.random.default_rng().pareto(a, 1000) + 1) * m
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, _ = plt.hist(s, 100, density=True) >>> fit = a*m**a / bins**(a+1) >>> plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r') >>> plt.show()# numpy.negative[#](#numpy-negative)
numpy.negative(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'negative'>*[#](#numpy.negative)
-
Numerical negative, element-wise.

Parameters:
-
**x**array_like or scalar
Input array.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray or scalar
Returned array or scalar:

*y = -x*. This is a scalar if*x*is a scalar.
Examples

>>> np.negative([1.,-1.]) array([-1., 1.])
The unary

`-`
operator can be used as a shorthand for`np.negative`
on ndarrays.>>> x1 = np.array(([1., -1.])) >>> -x1 array([-1., 1.])# numpy.char.chararray.istitle[#](#numpy-char-chararray-istitle)
method

char.chararray.istitle()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2428-L2438)[#](#numpy.char.chararray.istitle)
-
Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise.

See also

method

Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise.

See also# numpy.polynomial.laguerre.lagpow[#](#numpy-polynomial-laguerre-lagpow)
polynomial.laguerre.lagpow(*c*,*pow*,*maxpower=16*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L554-L588)[#](#numpy.polynomial.laguerre.lagpow)
-
Raise a Laguerre series to a power.

Returns the Laguerre series

*c*raised to the power*pow*. The argument*c*is a sequence of coefficients ordered from low to high. i.e., [1,2,3] is the series`P_0 + 2*P_1 + 3*P_2.`
Parameters:
-
**c**array_like
1-D array of Laguerre series coefficients ordered from low to high.

**pow**integer
Power to which the series will be raised

**maxpower**integer, optional
Maximum power allowed. This is mainly to limit growth of the series to unmanageable size. Default is 16

Returns:
-
**coef**ndarray
Laguerre series of power.

Examples

>>> from numpy.polynomial.laguerre import lagpow >>> lagpow([1, 2, 3], 2) array([ 14., -16., 56., -72., 54.])# numpy.ma.MaskType.newbyteorder[#](#numpy-ma-masktype-newbyteorder)
method

ma.MaskType.newbyteorder(*new_order='S'*,*/*)[#](#numpy.ma.MaskType.newbyteorder)
-
Return a new

with a different byte order.`dtype`
Changes are also made in all fields and sub-arrays of the data type.

The

*new_order*code can be any from the following:‘S’ - swap dtype from current to opposite endian

{‘<’, ‘little’} - little endian

{‘>’, ‘big’} - big endian

{‘=’, ‘native’} - native order

{‘|’, ‘I’} - ignore (no change to byte order)

Parameters:
-
**new_order**str, optional
Byte order to force; a value from the byte order specifications above. The default value (‘S’) results in swapping the current byte order.

Returns:
-
**new_dtype**dtype
New

object with the given change to the byte order.`dtype`# numpy.random.RandomState.chisquare[#](#numpy-random-randomstate-chisquare)
method

random.RandomState.chisquare(*df*,*size=None*)[#](#numpy.random.RandomState.chisquare)
-
Draw samples from a chi-square distribution.

When

*df*independent random variables, each with standard normal distributions (mean 0, variance 1), are squared and summed, the resulting distribution is chi-square (see Notes). This distribution is often used in hypothesis testing.Note

New code should use the

method of a`chisquare`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**df**float or array_like of floats
Number of degrees of freedom, must be > 0.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`df`
is a scalar. Otherwise,`np.array(df).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized chi-square distribution.

Raises:
-
ValueError
-
When

*df*<= 0 or when an inappropriate`size`
(e.g.`size=-1`
) is given.
See also

`random.Generator.chisquare`
which should be used for new code.

Notes

The variable obtained by summing the squares of

*df*independent, standard normally distributed random variables:\[Q = \sum_{i=0}^{\mathtt{df}} X^2_i\]is chi-square distributed, denoted

\[Q \sim \chi^2_k.\]The probability density function of the chi-squared distribution is

\[p(x) = \frac{(1/2)^{k/2}}{\Gamma(k/2)} x^{k/2 - 1} e^{-x/2},\]where \(\Gamma\) is the gamma function,

\[\Gamma(x) = \int_0^{-\infty} t^{x - 1} e^{-t} dt.\]References

[1]NIST “Engineering Statistics Handbook”

[https://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm)Examples

>>> np.random.chisquare(2,4) array([ 1.89920014, 9.00867716, 3.13710533, 5.62318272]) # random# numpy.deprecate_with_doc[#](#numpy-deprecate-with-doc)
numpy.deprecate_with_doc(*msg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/utils.py#L239-L263)[#](#numpy.deprecate_with_doc)
-
Deprecates a function and includes the deprecation in its docstring.

This function is used as a decorator. It returns an object that can be used to issue a DeprecationWarning, by passing the to-be decorated function as argument, this adds warning to the to-be decorated function’s docstring and returns the new function object.

Parameters:
-
**msg**str
Additional explanation of the deprecation. Displayed in the docstring after the warning.

Returns:
-
**obj**object
See also

`deprecate`
Decorate a function such that it issues a

*DeprecationWarning*# numpy.chararray.trace[#](#numpy-chararray-trace)
method

chararray.trace(*offset=0*,*axis1=0*,*axis2=1*,*dtype=None*,*out=None*)[#](#numpy.chararray.trace)
-
Return the sum along diagonals of the array.

Refer to

for full documentation.`numpy.trace`
See also

`numpy.trace`
equivalent function

method

Return the sum along diagonals of the array.

Refer to [ numpy.trace](numpy.trace.html#numpy.trace) for full documentation.

See also

`numpy.trace`
equivalent functionnumpy.char.chararray.center# method char.chararray.center(width, fillchar=' ')[source]# Return a copy of self with its elements centered in a string of length width. See also center# numpy.polynomial.legendre.Legendre.fromroots[#](#numpy-polynomial-legendre-legendre-fromroots)
method

*classmethod*polynomial.legendre.Legendre.fromroots(*roots*,*domain=[]*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1047-L1088)[#](#numpy.polynomial.legendre.Legendre.fromroots)
-
Return series instance that has the specified roots.

Returns a series representing the product

`(x - r[0])*(x - r[1])*...*(x - r[n-1])`
, where`r`
is a list of roots.Parameters:
-
**roots**array_like
List of roots.

**domain**{[], None, array_like}, optional
Domain for the resulting series. If None the domain is the interval from the smallest root to the largest. If [] the domain is the class domain. The default is [].

**window**{None, array_like}, optional
Window for the returned series. If None the class window is used. The default is None.

**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
Series with the specified roots.# numpy.ma.MaskedArray.all[#](#numpy-ma-maskedarray-all)
method

ma.MaskedArray.all(*axis=None*,*out=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4908-L4946)[#](#numpy.ma.MaskedArray.all)
-
Returns True if all elements evaluate to True.

The output array is masked where all the values along the given axis are masked: if the output would have been a scalar and that all the values are masked, then the output is

*masked*.Refer to

for full documentation.`numpy.all`
See also

`numpy.ndarray.all`
corresponding function for ndarrays

`numpy.all`
equivalent function

Examples

>>> np.ma.array([1,2,3]).all() True >>> a = np.ma.array([1,2,3], mask=True) >>> (a.all() is np.ma.masked) True# numpy.polynomial.legendre.Legendre.mapparms[#](#numpy-polynomial-legendre-legendre-mapparms)
method

polynomial.legendre.Legendre.mapparms()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L824-L851)[#](#numpy.polynomial.legendre.Legendre.mapparms)
-
Return the mapping parameters.

The returned values define a linear map

`off + scl*x`
that is applied to the input arguments before the series is evaluated. The map depends on the`domain`
and`window`
; if the current`domain`
is equal to the`window`
the resulting map is the identity. If the coefficients of the series instance are to be used by themselves outside this class, then the linear function must be substituted for the`x`
in the standard representation of the base polynomials.Returns:
-
**off, scl**float or complex
The mapping function is defined by

`off + scl*x`
.
Notes

If the current domain is the interval

`[l1, r1]`
and the window is`[l2, r2]`
, then the linear mapping function`L`
is defined by the equations:L(l1) = l2 L(r1) = r2numpy.distutils.ccompiler_opt.CCompilerOpt.dist_test# method distutils.ccompiler_opt.CCompilerOpt.dist_test(source, flags, macros=[])[source]# Return True if ‘CCompiler.compile()’ able to compile a source file with certain flags.# numpy.recarray.strides[#](#numpy-recarray-strides)
attribute

recarray.strides[#](#numpy.recarray.strides)
-
Tuple of bytes to step in each dimension when traversing an array.

The byte offset of element

`(i[0], i[1], ..., i[n])`
in an array*a*is:offset = sum(np.array(i) * a.strides)
A more detailed explanation of strides can be found in the “ndarray.rst” file in the NumPy reference guide.

Warning

Setting

`arr.strides`
is discouraged and may be deprecated in the future.should be preferred to create a new view of the same data in a safer way.`numpy.lib.stride_tricks.as_strided`
See also

Notes

Imagine an array of 32-bit integers (each 4 bytes):

x = np.array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], dtype=np.int32)
This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array

*x*will be`(20, 4)`
.Examples

>>> y = np.reshape(np.arange(2*3*4), (2,3,4)) >>> y array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) >>> y.strides (48, 16, 4) >>> y[1,1,1] 17 >>> offset=sum(y.strides * np.array((1,1,1))) >>> offset/y.itemsize 17
>>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0) >>> x.strides (32, 4, 224, 1344) >>> i = np.array([3,5,2,2]) >>> offset = sum(i * x.strides) >>> x[3,5,2,2] 813 >>> offset / x.itemsize 813# numpy.ma.MaskedArray.reshape[#](#numpy-ma-maskedarray-reshape)
method

ma.MaskedArray.reshape(**s*,***kwargs*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4686-L4750)[#](#numpy.ma.MaskedArray.reshape)
-
Give a new shape to the array without changing its data.

Returns a masked array containing the same data, but with a new shape. The result is a view on the original array; if this is not possible, a ValueError is raised.

Parameters:
-
**shape**int or tuple of ints
The new shape should be compatible with the original shape. If an integer is supplied, then the result will be a 1-D array of that length.

**order**{‘C’, ‘F’}, optional
Determines whether the array data should be viewed as in C (row-major) or FORTRAN (column-major) order.

Returns:
-
**reshaped_array**array
A new view on the array.

See also

`reshape`
Equivalent function in the masked array module.

`numpy.ndarray.reshape`
Equivalent method on ndarray object.

`numpy.reshape`
Equivalent function in the NumPy module.

Notes

The reshaping operation cannot guarantee that a copy will not be made, to modify the shape in place, use

`a.shape = s`
Examples

>>> x = np.ma.array([[1,2],[3,4]], mask=[1,0,0,1]) >>> x masked_array( data=[[--, 2], [3, --]], mask=[[ True, False], [False, True]], fill_value=999999) >>> x = x.reshape((4,1)) >>> x masked_array( data=[[--], [2], [3], [--]], mask=[[ True], [False], [False], [ True]], fill_value=999999)numpy.record.copy# method record.copy()# Scalar method identical to the corresponding array attribute. Please see ndarray.copy.numpy.polynomial.polynomial.Polynomial.__call__# method polynomial.polynomial.Polynomial.__call__(arg)[source]# Call self as a function.# numpy.ascontiguousarray[#](#numpy-ascontiguousarray)
numpy.ascontiguousarray(*a*,*dtype=None*,***,*like=None*)[#](#numpy.ascontiguousarray)
-
Return a contiguous array (ndim >= 1) in memory (C order).

Parameters:
-
**a**array_like
Input array.

**dtype**str or dtype object, optional
Data-type of returned array.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**out**ndarray
Contiguous array of same shape and content as

*a*, with typeif specified.`dtype`
See also

`asfortranarray`
Convert input to an ndarray with column-major memory order.

`require`
Return an ndarray that satisfies requirements.

`ndarray.flags`
Information about the memory layout of the array.

Examples

Starting with a Fortran-contiguous array:

>>> x = np.ones((2, 3), order='F') >>> x.flags['F_CONTIGUOUS'] True
Calling

`ascontiguousarray`
makes a C-contiguous copy:>>> y = np.ascontiguousarray(x) >>> y.flags['C_CONTIGUOUS'] True >>> np.may_share_memory(x, y) False
Now, starting with a C-contiguous array:

>>> x = np.ones((2, 3), order='C') >>> x.flags['C_CONTIGUOUS'] True
Then, calling

`ascontiguousarray`
returns the same object:>>> y = np.ascontiguousarray(x) >>> x is y True
Note: This function returns an array with at least one-dimension (1-d) so it will not preserve 0-d arrays.# numpy.ma.MaskType.compress[#](#numpy-ma-masktype-compress)
method

ma.MaskType.compress()[#](#numpy.ma.MaskType.compress)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.compress`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.compress](numpy.ndarray.compress.html#numpy.ndarray.compress).ndarray

dtype

ufunc

numpy.typing

numpy.distutils

nditer.reset

method

Reset the iterator to its initial state.# numpy.polynomial.hermite.hermroots[#](#numpy-polynomial-hermite-hermroots)
polynomial.hermite.hermroots(*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L1452-L1513)[#](#numpy.polynomial.hermite.hermroots)
-
Compute the roots of a Hermite series.

Return the roots (a.k.a. “zeros”) of the polynomial

\[p(x) = \sum_i c[i] * H_i(x).\]Parameters:
-
**c**1-D array_like
1-D array of coefficients.

Returns:
-
**out**ndarray
Array of the roots of the series. If all the roots are real, then

*out*is also real, otherwise it is complex.
See also

Notes

The root estimates are obtained as the eigenvalues of the companion matrix, Roots far from the origin of the complex plane may have large errors due to the numerical instability of the series for such values. Roots with multiplicity greater than 1 will also show larger errors as the value of the series near such points is relatively insensitive to errors in the roots. Isolated roots near the origin can be improved by a few iterations of Newton’s method.

The Hermite series basis polynomials aren’t powers of

*x*so the results of this function may seem unintuitive.Examples

>>> from numpy.polynomial.hermite import hermroots, hermfromroots >>> coef = hermfromroots([-1, 0, 1]) >>> coef array([0. , 0.25 , 0. , 0.125]) >>> hermroots(coef) array([-1.00000000e+00, -1.38777878e-17, 1.00000000e+00])# numpy.matrix.repeat[#](#numpy-matrix-repeat)
method

matrix.repeat(*repeats*,*axis=None*)[#](#numpy.matrix.repeat)
-
Repeat elements of an array.

Refer to

for full documentation.`numpy.repeat`
See also

`numpy.repeat`
equivalent function

method

Repeat elements of an array.

Refer to [ numpy.repeat](numpy.repeat.html#numpy.repeat) for full documentation.

See also

`numpy.repeat`
equivalent function# numpy.matrix.round[#](#numpy-matrix-round)
method

matrix.round(*decimals=0*,*out=None*)[#](#numpy.matrix.round)
-
Return

*a*with each element rounded to the given number of decimals.Refer to

for full documentation.`numpy.around`
See also

`numpy.around`
equivalent function

method

Return *a* with each element rounded to the given number of decimals.

Refer to [ numpy.around](numpy.around.html#numpy.around) for full documentation.

See also

`numpy.around`
equivalent function# numpy.ma.outer[#](#numpy-ma-outer)
ma.outer(*a*,*b*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7945-L7957)[#](#numpy.ma.outer)
-
Compute the outer product of two vectors.

Given two vectors

*a*and*b*of length`M`
and`N`
, repsectively, the outer product[[1]](#r863504129d6e-1)is:[[a_0*b_0 a_0*b_1 ... a_0*b_{N-1} ] [a_1*b_0 . [ ... . [a_{M-1}*b_0 a_{M-1}*b_{N-1} ]]
Parameters:
-
**a**(M,) array_like
First input vector. Input is flattened if not already 1-dimensional.

**b**(N,) array_like
Second input vector. Input is flattened if not already 1-dimensional.

**out**(M, N) ndarray, optional
A location where the result is stored

New in version 1.9.0.

Returns:
-
**out**(M, N) ndarray
`out[i, j] = a[i] * b[j]`
See also

`inner`
`einsum`
`einsum('i,j->ij', a.ravel(), b.ravel())`
is the equivalent.
`ufunc.outer`
A generalization to dimensions other than 1D and other operations.

`np.multiply.outer(a.ravel(), b.ravel())`
is the equivalent.
`tensordot`
`np.tensordot(a.ravel(), b.ravel(), axes=((), ()))`
is the equivalent.
Notes

Masked values are replaced by 0.

References

[[1](#id1)]G. H. Golub and C. F. Van Loan,

*Matrix Computations*, 3rd ed., Baltimore, MD, Johns Hopkins University Press, 1996, pg. 8.Examples

Make a (

*very*coarse) grid for computing a Mandelbrot set:>>> rl = np.outer(np.ones((5,)), np.linspace(-2, 2, 5)) >>> rl array([[-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.], [-2., -1., 0., 1., 2.]]) >>> im = np.outer(1j*np.linspace(2, -2, 5), np.ones((5,))) >>> im array([[0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j], [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j], [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], [0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j], [0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j]]) >>> grid = rl + im >>> grid array([[-2.+2.j, -1.+2.j, 0.+2.j, 1.+2.j, 2.+2.j], [-2.+1.j, -1.+1.j, 0.+1.j, 1.+1.j, 2.+1.j], [-2.+0.j, -1.+0.j, 0.+0.j, 1.+0.j, 2.+0.j], [-2.-1.j, -1.-1.j, 0.-1.j, 1.-1.j, 2.-1.j], [-2.-2.j, -1.-2.j, 0.-2.j, 1.-2.j, 2.-2.j]])
An example using a “vector” of letters:

>>> x = np.array(['a', 'b', 'c'], dtype=object) >>> np.outer(x, [1, 2, 3]) array([['a', 'aa', 'aaa'], ['b', 'bb', 'bbb'], ['c', 'cc', 'ccc']], dtype=object)# numpy.random.Generator.normal[#](#numpy-random-generator-normal)
method

random.Generator.normal(*loc=0.0*,*scale=1.0*,*size=None*)[#](#numpy.random.Generator.normal)
-
Draw random samples from a normal (Gaussian) distribution.

The probability density function of the normal distribution, first derived by De Moivre and 200 years later by both Gauss and Laplace independently

[[2]](#r1536f9c044a3-2), is often called the bell curve because of its characteristic shape (see the example below).The normal distributions occurs often in nature. For example, it describes the commonly occurring distribution of samples influenced by a large number of tiny, random disturbances, each with its own unique distribution

[[2]](#r1536f9c044a3-2).Parameters:
-
**loc**float or array_like of floats
Mean (“centre”) of the distribution.

**scale**float or array_like of floats
Standard deviation (spread or “width”) of the distribution. Must be non-negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`loc`
and`scale`
are both scalars. Otherwise,`np.broadcast(loc, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized normal distribution.

See also

`scipy.stats.norm`
probability density function, distribution or cumulative density function, etc.

Notes

The probability density for the Gaussian distribution is

\[p(x) = \frac{1}{\sqrt{ 2 \pi \sigma^2 }} e^{ - \frac{ (x - \mu)^2 } {2 \sigma^2} },\]where \(\mu\) is the mean and \(\sigma\) the standard deviation. The square of the standard deviation, \(\sigma^2\), is called the variance.

The function has its peak at the mean, and its “spread” increases with the standard deviation (the function reaches 0.607 times its maximum at \(x + \sigma\) and \(x - \sigma\)

[[2]](#r1536f9c044a3-2)). This implies thatis more likely to return samples lying close to the mean, rather than those far away.`normal`
References

[1]Wikipedia, “Normal distribution”,

[https://en.wikipedia.org/wiki/Normal_distribution](https://en.wikipedia.org/wiki/Normal_distribution)Examples

Draw samples from the distribution:

>>> mu, sigma = 0, 0.1 # mean and standard deviation >>> s = np.random.default_rng().normal(mu, sigma, 1000)
Verify the mean and the variance:

>>> abs(mu - np.mean(s)) 0.0 # may vary
>>> abs(sigma - np.std(s, ddof=1)) 0.0 # may vary
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 30, density=True) >>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * ... np.exp( - (bins - mu)**2 / (2 * sigma**2) ), ... linewidth=2, color='r') >>> plt.show()
Two-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:

>>> np.random.default_rng().normal(3, 2.5, size=(2, 4)) array([[-4.49401501, 4.00950034, -1.81814867, 7.29718677], # random [ 0.39924804, 4.68456316, 4.99394529, 4.84057254]]) # randomnumpy.ma.MaskedArray.__add__# method ma.MaskedArray.__add__(other)[source]# Add self to other, and return a new masked array.# numpy.matmul[#](#numpy-matmul)
numpy.matmul(*x1*,*x2*,*/*,*out=None*,***,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*,*axes*,*axis*])*= <ufunc 'matmul'>*[#](#numpy.matmul)
-
Matrix product of two arrays.

Parameters:
-
**x1, x2**array_like
Input arrays, scalars not allowed.

**out**ndarray, optional
A location into which the result is stored. If provided, it must have a shape that matches the signature

*(n,k),(k,m)->(n,m)*. If not provided or None, a freshly-allocated array is returned.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).New in version 1.16: Now handles ufunc kwargs

Returns:
-
**y**ndarray
The matrix product of the inputs. This is a scalar only when both x1, x2 are 1-d vectors.

Raises:
-
ValueError
-
If the last dimension of

*x1*is not the same size as the second-to-last dimension of*x2*.If a scalar value is passed in.

See also

Notes

The behavior depends on the arguments in the following way.

If both arguments are 2-D they are multiplied like conventional matrices.

If either argument is N-D, N > 2, it is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.

If the first argument is 1-D, it is promoted to a matrix by prepending a 1 to its dimensions. After matrix multiplication the prepended 1 is removed.

If the second argument is 1-D, it is promoted to a matrix by appending a 1 to its dimensions. After matrix multiplication the appended 1 is removed.

`matmul`
differs from`dot`
in two important ways:Multiplication by scalars is not allowed, use

`*`
instead.
Stacks of matrices are broadcast together as if the matrices were elements, respecting the signature

`(n,k),(k,m)->(n,m)`
:>>> a = np.ones([9, 5, 7, 4]) >>> c = np.ones([9, 5, 4, 3]) >>> np.dot(a, c).shape (9, 5, 7, 9, 5, 3) >>> np.matmul(a, c).shape (9, 5, 7, 3) >>> # n is 7, k is 4, m is 3
The matmul function implements the semantics of the

`@`
operator introduced in Python 3.5 following.**PEP 465**It uses an optimized BLAS library when possible (see

).`numpy.linalg`
Examples

For 2-D arrays it is the matrix product:

>>> a = np.array([[1, 0], ... [0, 1]]) >>> b = np.array([[4, 1], ... [2, 2]]) >>> np.matmul(a, b) array([[4, 1], [2, 2]])
For 2-D mixed with 1-D, the result is the usual.

>>> a = np.array([[1, 0], ... [0, 1]]) >>> b = np.array([1, 2]) >>> np.matmul(a, b) array([1, 2]) >>> np.matmul(b, a) array([1, 2])
Broadcasting is conventional for stacks of arrays

>>> a = np.arange(2 * 2 * 4).reshape((2, 2, 4)) >>> b = np.arange(2 * 2 * 4).reshape((2, 4, 2)) >>> np.matmul(a,b).shape (2, 2, 2) >>> np.matmul(a, b)[0, 1, 1] 98 >>> sum(a[0, 1, :] * b[0 , :, 1]) 98
Vector, vector returns the scalar inner product, but neither argument is complex-conjugated:

>>> np.matmul([2j, 3j], [2j, 3j]) (-13+0j)
Scalar multiplication raises an error.

>>> np.matmul([1,2], 3) Traceback (most recent call last): ... ValueError: matmul: Input operand 1 does not have enough dimensions ...
The

`@`
operator can be used as a shorthand for`np.matmul`
on ndarrays.>>> x1 = np.array([2j, 3j]) >>> x2 = np.array([2j, 3j]) >>> x1 @ x2 (-13+0j)
New in version 1.10.0.# numpy.true_divide[#](#numpy-true-divide)
numpy.true_divide(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'divide'>*[#](#numpy.true_divide)
-
Divide arguments element-wise.

Parameters:
-
**x1**array_like
Dividend array.

**x2**array_like
Divisor array. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray or scalar
The quotient

`x1/x2`
, element-wise. This is a scalar if both*x1*and*x2*are scalars.
See also

`seterr`
Set whether to raise or warn on overflow, underflow and division by zero.

Notes

Equivalent to

`x1`
/`x2`
in terms of array-broadcasting.The

`true_divide(x1, x2)`
function is an alias for`divide(x1, x2)`
.Examples

>>> np.divide(2.0, 4.0) 0.5 >>> x1 = np.arange(9.0).reshape((3, 3)) >>> x2 = np.arange(3.0) >>> np.divide(x1, x2) array([[nan, 1. , 1. ], [inf, 4. , 2.5], [inf, 7. , 4. ]])
The

`/`
operator can be used as a shorthand for`np.divide`
on ndarrays.>>> x1 = np.arange(9.0).reshape((3, 3)) >>> x2 = 2 * np.ones(3) >>> x1 / x2 array([[0. , 0.5, 1. ], [1.5, 2. , 2.5], [3. , 3.5, 4. ]])# numpy.full_like[#](#numpy-full-like)
numpy.full_like(*a*,*fill_value*,*dtype=None*,*order='K'*,*subok=True*,*shape=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L341-L408)[#](#numpy.full_like)
-
Return a full array with the same shape and type as a given array.

Parameters:
-
**a**array_like
The shape and data-type of

*a*define these same attributes of the returned array.
**fill_value**array_like
Fill value.

**dtype**data-type, optional
Overrides the data type of the result.

**order**{‘C’, ‘F’, ‘A’, or ‘K’}, optional
Overrides the memory layout of the result. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*a*as closely as possible.
**subok**bool, optional.
If True, then the newly created array will use the sub-class type of

*a*, otherwise it will be a base-class array. Defaults to True.
**shape**int or sequence of ints, optional.
Overrides the shape of the result. If order=’K’ and the number of dimensions is unchanged, will try to keep order, otherwise, order=’C’ is implied.

New in version 1.17.0.

Returns:
-
**out**ndarray
Array of

*fill_value*with the same shape and type as*a*.
See also

`empty_like`
Return an empty array with shape and type of input.

`ones_like`
Return an array of ones with shape and type of input.

`zeros_like`
Return an array of zeros with shape and type of input.

`full`
Return a new array of given shape filled with value.

Examples

>>> x = np.arange(6, dtype=int) >>> np.full_like(x, 1) array([1, 1, 1, 1, 1, 1]) >>> np.full_like(x, 0.1) array([0, 0, 0, 0, 0, 0]) >>> np.full_like(x, 0.1, dtype=np.double) array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) >>> np.full_like(x, np.nan, dtype=np.double) array([nan, nan, nan, nan, nan, nan])
>>> y = np.arange(6, dtype=np.double) >>> np.full_like(y, 0.1) array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
>>> y = np.zeros([2, 2, 3], dtype=int) >>> np.full_like(y, [0, 0, 255]) array([[[ 0, 0, 255], [ 0, 0, 255]], [[ 0, 0, 255], [ 0, 0, 255]]])# numpy.ma.isin[#](#numpy-ma-isin)
ma.isin(*element*,*test_elements*,*assume_unique=False*,*invert=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L1331-L1351)[#](#numpy.ma.isin)
-
Calculates

*element in test_elements*, broadcasting over*element*only.The output is always a masked array of the same shape as

*element*. Seefor more details.`numpy.isin`
See also

`in1d`
Flattened version of this function.

`numpy.isin`
Equivalent function for ndarrays.

Notes

New in version 1.13.0.# numpy.char.find[#](#numpy-char-find)
char.find(*a*,*sub*,*start=0*,*end=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L742-L781)[#](#numpy.char.find)
-
For each element, return the lowest index in the string where substring

*sub*is found.Calls

*str.find*element-wise.For each element, return the lowest index in the string where substring

*sub*is found, such that*sub*is contained in the range [*start*,*end*].Parameters:
-
**a**array_like of str or unicode
**sub**str or unicode
**start, end**int, optional
Optional arguments

*start*and*end*are interpreted as in slice notation.
Returns:
-
**out**ndarray or int
Output array of ints. Returns -1 if

*sub*is not found.
See also

Examples

>>> a = np.array(["NumPy is a Python library"]) >>> np.char.find(a, "Python", start=0, end=None) array([11])# numpy.polynomial.hermite.hermval2d[#](#numpy-polynomial-hermite-hermval2d)
polynomial.hermite.hermval2d(*x*,*y*,*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L898-L944)[#](#numpy.polynomial.hermite.hermval2d)
-
Evaluate a 2-D Hermite series at points (x, y).

This function returns the values:

\[p(x,y) = \sum_{i,j} c_{i,j} * H_i(x) * H_j(y)\]The parameters

*x*and*y*are converted to arrays only if they are tuples or a lists, otherwise they are treated as a scalars and they must have the same shape after conversion. In either case, either*x*and*y*or their elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*is a 1-D array a one is implicitly appended to its shape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape.Parameters:
-
**x, y**array_like, compatible objects
The two dimensional series is evaluated at the points

*(x, y)*, where*x*and*y*must have the same shape. If*x*or*y*is a list or tuple, it is first converted to an ndarray, otherwise it is left unchanged and if it isn’t an ndarray it is treated as a scalar.
**c**array_like
Array of coefficients ordered so that the coefficient of the term of multi-degree i,j is contained in

`c[i,j]`
. If*c*has dimension greater than two the remaining indices enumerate multiple sets of coefficients.
Returns:
-
**values**ndarray, compatible object
The values of the two dimensional polynomial at points formed with pairs of corresponding values from

*x*and*y*.
See also

Notes

New in version 1.7.0.# numpy.recarray.resize[#](#numpy-recarray-resize)
method

recarray.resize(*new_shape*,*refcheck=True*)[#](#numpy.recarray.resize)
-
Change shape and size of array in-place.

Parameters:
-
**new_shape**tuple of ints, or*n*ints
Shape of resized array.

**refcheck**bool, optional
If False, reference count will not be checked. Default is True.

Returns:
-
None
-
Raises:
-
ValueError
-
If

*a*does not own its own data or references or views to it exist, and the data memory must be changed. PyPy only: will always raise if the data memory must be changed, since there is no reliable way to determine if references or views to it exist.
SystemError
-
If the

*order*keyword argument is specified. This behaviour is a bug in NumPy.
See also

`resize`
Return a new array with the specified shape.

Notes

This reallocates space for the data area if necessary.

Only contiguous arrays (data elements consecutive in memory) can be resized.

The purpose of the reference count check is to make sure you do not use this array as a buffer for another Python object and then reallocate the memory. However, reference counts can increase in other ways so if you are sure that you have not shared the memory for this array with another Python object, then you may safely set

*refcheck*to False.Examples

Shrinking an array: array is flattened (in the order that the data are stored in memory), resized, and reshaped:

>>> a = np.array([[0, 1], [2, 3]], order='C') >>> a.resize((2, 1)) >>> a array([[0], [1]])
>>> a = np.array([[0, 1], [2, 3]], order='F') >>> a.resize((2, 1)) >>> a array([[0], [2]])
Enlarging an array: as above, but missing entries are filled with zeros:

>>> b = np.array([[0, 1], [2, 3]]) >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple >>> b array([[0, 1, 2], [3, 0, 0]])
Referencing an array prevents resizing…

>>> c = a >>> a.resize((1, 1)) Traceback (most recent call last): ... ValueError: cannot resize an array that references or is referenced ...
Unless

*refcheck*is False:>>> a.resize((1, 1), refcheck=False) >>> a array([[0]]) >>> c array([[0]])# numpy.memmap.conjugate[#](#numpy-memmap-conjugate)
method

memmap.conjugate()[#](#numpy.memmap.conjugate)
-
Return the complex conjugate, element-wise.

Refer to

for full documentation.`numpy.conjugate`
See also

`numpy.conjugate`
equivalent function

method

Return the complex conjugate, element-wise.

Refer to [ numpy.conjugate](numpy.conjugate.html#numpy.conjugate) for full documentation.

See also

`numpy.conjugate`
equivalent function# numpy.matrix.newbyteorder[#](#numpy-matrix-newbyteorder)
method

matrix.newbyteorder(*new_order='S'*,*/*)[#](#numpy.matrix.newbyteorder)
-
Return the array with the same data viewed with a different byte order.

Equivalent to:

arr.view(arr.dtype.newbytorder(new_order))
Changes are also made in all fields and sub-arrays of the array data type.

Parameters:
-
**new_order**string, optional
Byte order to force; a value from the byte order specifications below.

*new_order*codes can be any of:‘S’ - swap dtype from current to opposite endian

{‘<’, ‘little’} - little endian

{‘>’, ‘big’} - big endian

{‘=’, ‘native’} - native order, equivalent to

`sys.byteorder`
{‘|’, ‘I’} - ignore (no change to byte order)

The default value (‘S’) results in swapping the current byte order.

Returns:
-
**new_arr**array
New array object with the dtype reflecting given change to the byte order.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
numpy.matrix.T
numpy.matrix.H
numpy.matrix.I
numpy.matrix.A
numpy.matrix
numpy.asmatrix
numpy.bmat
numpy.memmap
numpy.memmap.flush
numpy.chararray
numpy.core.defchararray.array
numpy.recarray
numpy.record
numpy.record.all
numpy.record.any
numpy.record.argmax
numpy.record.argmin
numpy.record.argsort
numpy.record.astype
numpy.record.byteswap
numpy.record.choose
numpy.record.clip
numpy.record.compress
numpy.record.conjugate
numpy.record.copy
numpy.record.cumprod
numpy.record.cumsum
numpy.record.diagonal
numpy.record.dump
numpy.record.dumps
numpy.record.fill
numpy.record.flatten
numpy.record.getfield
numpy.record.item
numpy.record.itemset
numpy.record.max
numpy.record.mean
numpy.record.min
numpy.record.newbyteorder
numpy.record.nonzero
numpy.record.pprint
numpy.record.prod
numpy.record.ptp
numpy.record.put
numpy.record.ravel
numpy.record.repeat
numpy.record.reshape
numpy.record.resize
numpy.record.round
numpy.record.searchsorted
numpy.record.setfield
numpy.record.setflags
numpy.record.sort
numpy.record.squeeze
numpy.record.std
numpy.record.sum
numpy.record.swapaxes
numpy.record.take
numpy.record.tofile
numpy.record.tolist
numpy.record.tostring
numpy.record.trace
numpy.record.transpose
numpy.record.var
numpy.record.view
numpy.lib.user_array.container
numpy.ndarray.flat
numpy.ndenumerate
numpy.broadcast
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
record.pprint
numpy.record.pprint
#
method
record.
pprint
(
)
[source]
#
Pretty-print all fields.# numpy.ma.masked_array.get_real[#](#numpy-ma-masked-array-get-real)
method

ma.masked_array.get_real()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4498-L4520)[#](#numpy.ma.masked_array.get_real)
-
The real part of the masked array.

This property is a view on the real part of this

*MaskedArray*.See also

Examples

>>> x = np.ma.array([1+1.j, -2j, 3.45+1.6j], mask=[False, True, False]) >>> x.real masked_array(data=[1.0, --, 3.45], mask=[False, True, False], fill_value=1e+20)ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__or__

method

Return self|value.# numpy.hypot[#](#numpy-hypot)
numpy.hypot(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'hypot'>*[#](#numpy.hypot)
-
Given the “legs” of a right triangle, return its hypotenuse.

Equivalent to

`sqrt(x1**2 + x2**2)`
, element-wise. If*x1*or*x2*is scalar_like (i.e., unambiguously cast-able to a scalar type), it is broadcast for use with each element of the other argument. (See Examples)Parameters:
-
**x1, x2**array_like
Leg of the triangle(s). If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**z**ndarray
The hypotenuse of the triangle(s). This is a scalar if both

*x1*and*x2*are scalars.
Examples

>>> np.hypot(3*np.ones((3, 3)), 4*np.ones((3, 3))) array([[ 5., 5., 5.], [ 5., 5., 5.], [ 5., 5., 5.]])
Example showing broadcast of scalar_like argument:

>>> np.hypot(3*np.ones((3, 3)), [4]) array([[ 5., 5., 5.], [ 5., 5., 5.], [ 5., 5., 5.]])numpy.ma.MaskType.sum# method ma.MaskType.sum()# Scalar method identical to the corresponding array attribute. Please see ndarray.sum.# numpy.polynomial.polynomial.polyadd[#](#numpy-polynomial-polynomial-polyadd)
polynomial.polynomial.polyadd(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L215-L248)[#](#numpy.polynomial.polynomial.polyadd)
-
Add one polynomial to another.

Returns the sum of two polynomials

*c1*+*c2*. The arguments are sequences of coefficients from lowest order term to highest, i.e., [1,2,3] represents the polynomial`1 + 2*x + 3*x**2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of polynomial coefficients ordered from low to high.

Returns:
-
**out**ndarray
The coefficient array representing their sum.

Examples

>>> from numpy.polynomial import polynomial as P >>> c1 = (1,2,3) >>> c2 = (3,2,1) >>> sum = P.polyadd(c1,c2); sum array([4., 4., 4.]) >>> P.polyval(2, sum) # 4 + 4(2) + 4(2**2) 28.0# numpy.polynomial.legendre.legtrim[#](#numpy-polynomial-legendre-legtrim)
polynomial.legendre.legtrim(*c*,*tol=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polyutils.py#L160-L212)[#](#numpy.polynomial.legendre.legtrim)
-
Remove “small” “trailing” coefficients from a polynomial.

“Small” means “small in absolute value” and is controlled by the parameter

*tol*; “trailing” means highest order coefficient(s), e.g., in`[0, 1, 1, 0, 0]`
(which represents`0 + x + x**2 + 0*x**3 + 0*x**4`
) both the 3-rd and 4-th order coefficients would be “trimmed.”Parameters:
-
**c**array_like
1-d array of coefficients, ordered from lowest order to highest.

**tol**number, optional
Trailing (i.e., highest order) elements with absolute value less than or equal to

*tol*(default value is zero) are removed.
Returns:
-
**trimmed**ndarray
1-d array with trailing zeros removed. If the resulting series would be empty, a series containing a single zero is returned.

Raises:
-
ValueError
-
If

*tol*< 0
See also

`trimseq`
Examples

>>> from numpy.polynomial import polyutils as pu >>> pu.trimcoef((0,0,3,0,5,0,0)) array([0., 0., 3., 0., 5.]) >>> pu.trimcoef((0,0,1e-3,0,1e-5,0,0),1e-3) # item == tol is trimmed array([0.]) >>> i = complex(0,1) # works for complex >>> pu.trimcoef((3e-4,1e-3*(1-i),5e-4,2e-5*(1+i)), 1e-3) array([0.0003+0.j , 0.001 -0.001j])# numpy.testing.decorate_methods[#](#numpy-testing-decorate-methods)
testing.decorate_methods(*cls*,*decorator*,*testmatch=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/_private/utils.py#L1319-L1363)[#](#numpy.testing.decorate_methods)
-
Apply a decorator to all methods in a class matching a regular expression.

The given decorator is applied to all public methods of

*cls*that are matched by the regular expression*testmatch*(`testmatch.search(methodname)`
). Methods that are private, i.e. start with an underscore, are ignored.Parameters:
-
**cls**class
Class whose methods to decorate.

**decorator**function
Decorator to apply to methods

**testmatch**compiled regexp or str, optional
The regular expression. Default value is None, in which case the nose default (

`re.compile(r'(?:^|[\b_\.%s-])[Tt]est' % os.sep)`
) is used. If*testmatch*is a string, it is compiled to a regular expression first.# numpy.chararray.isdigit[#](#numpy-chararray-isdigit)
method

chararray.isdigit()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2390-L2400)[#](#numpy.chararray.isdigit)
-
Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.

See also

method

Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.

See also# numpy.random.Generator.gumbel[#](#numpy-random-generator-gumbel)
method

random.Generator.gumbel(*loc=0.0*,*scale=1.0*,*size=None*)[#](#numpy.random.Generator.gumbel)
-
Draw samples from a Gumbel distribution.

Draw samples from a Gumbel distribution with specified location and scale. For more information on the Gumbel distribution, see Notes and References below.

Parameters:
-
**loc**float or array_like of floats, optional
The location of the mode of the distribution. Default is 0.

**scale**float or array_like of floats, optional
The scale parameter of the distribution. Default is 1. Must be non- negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`loc`
and`scale`
are both scalars. Otherwise,`np.broadcast(loc, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Gumbel distribution.

Notes

The Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme Value Type I) distribution is one of a class of Generalized Extreme Value (GEV) distributions used in modeling extreme value problems. The Gumbel is a special case of the Extreme Value Type I distribution for maximums from distributions with “exponential-like” tails.

The probability density for the Gumbel distribution is

\[p(x) = \frac{e^{-(x - \mu)/ \beta}}{\beta} e^{ -e^{-(x - \mu)/ \beta}},\]where \(\mu\) is the mode, a location parameter, and \(\beta\) is the scale parameter.

The Gumbel (named for German mathematician Emil Julius Gumbel) was used very early in the hydrology literature, for modeling the occurrence of flood events. It is also used for modeling maximum wind speed and rainfall rates. It is a “fat-tailed” distribution - the probability of an event in the tail of the distribution is larger than if one used a Gaussian, hence the surprisingly frequent occurrence of 100-year floods. Floods were initially modeled as a Gaussian process, which underestimated the frequency of extreme events.

It is one of a class of extreme value distributions, the Generalized Extreme Value (GEV) distributions, which also includes the Weibull and Frechet.

The function has a mean of \(\mu + 0.57721\beta\) and a variance of \(\frac{\pi^2}{6}\beta^2\).

References

[1]Gumbel, E. J., “Statistics of Extremes,” New York: Columbia University Press, 1958.

[2]Reiss, R.-D. and Thomas, M., “Statistical Analysis of Extreme Values from Insurance, Finance, Hydrology and Other Fields,” Basel: Birkhauser Verlag, 2001.

Examples

Draw samples from the distribution:

>>> rng = np.random.default_rng() >>> mu, beta = 0, 0.1 # location and scale >>> s = rng.gumbel(mu, beta, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 30, density=True) >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta) ... * np.exp( -np.exp( -(bins - mu) /beta) ), ... linewidth=2, color='r') >>> plt.show()
Show how an extreme value distribution can arise from a Gaussian process and compare to a Gaussian:

>>> means = [] >>> maxima = [] >>> for i in range(0,1000) : ... a = rng.normal(mu, beta, 1000) ... means.append(a.mean()) ... maxima.append(a.max()) >>> count, bins, ignored = plt.hist(maxima, 30, density=True) >>> beta = np.std(maxima) * np.sqrt(6) / np.pi >>> mu = np.mean(maxima) - 0.57721*beta >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta) ... * np.exp(-np.exp(-(bins - mu)/beta)), ... linewidth=2, color='r') >>> plt.plot(bins, 1/(beta * np.sqrt(2 * np.pi)) ... * np.exp(-(bins - mu)**2 / (2 * beta**2)), ... linewidth=2, color='g') >>> plt.show()# numpy.random.poisson[#](#numpy-random-poisson)
random.poisson(*lam=1.0*,*size=None*)[#](#numpy.random.poisson)
-
Draw samples from a Poisson distribution.

The Poisson distribution is the limit of the binomial distribution for large N.

Note

New code should use the

method of a`poisson`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**lam**float or array_like of floats
Expected number of events occurring in a fixed-time interval, must be >= 0. A sequence must be broadcastable over the requested size.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`lam`
is a scalar. Otherwise,`np.array(lam).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Poisson distribution.

See also

`random.Generator.poisson`
which should be used for new code.

Notes

The Poisson distribution

\[f(k; \lambda)=\frac{\lambda^k e^{-\lambda}}{k!}\]For events with an expected separation \(\lambda\) the Poisson distribution \(f(k; \lambda)\) describes the probability of \(k\) events occurring within the observed interval \(\lambda\).

Because the output is limited to the range of the C int64 type, a ValueError is raised when

*lam*is within 10 sigma of the maximum representable value.References

[1]Weisstein, Eric W. “Poisson Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/PoissonDistribution.html](http://mathworld.wolfram.com/PoissonDistribution.html)[2]Wikipedia, “Poisson distribution”,

[https://en.wikipedia.org/wiki/Poisson_distribution](https://en.wikipedia.org/wiki/Poisson_distribution)Examples

Draw samples from the distribution:

>>> import numpy as np >>> s = np.random.poisson(5, 10000)
Display histogram of the sample:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 14, density=True) >>> plt.show()
Draw each 100 values for lambda 100 and 500:

>>> s = np.random.poisson(lam=(100., 500.), size=(100, 2))User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
record.data
numpy.record.data
#
attribute
record.
data
#
Pointer to start of data.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
nditer.finished
numpy.nditer.finished
#
attribute
nditer.
finished
#numpy.polynomial.chebyshev.Chebyshev.has_sametype# method polynomial.chebyshev.Chebyshev.has_sametype(other)[source]# Check if types match. New in version 1.7.0. Parameters: otherobjectClass instance. Returns: boolbooleanTrue if other is same class as self# numpy.nditer[#](#numpy-nditer)
*class*numpy.nditer(*op*,*flags=None*,*op_flags=None*,*op_dtypes=None*,*order='K'*,*casting='safe'*,*op_axes=None*,*itershape=None*,*buffersize=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/__init__.py)[#](#numpy.nditer)
-
Efficient multi-dimensional iterator object to iterate over arrays. To get started using this object, see the

[introductory guide to array iteration](../arrays.nditer.html#arrays-nditer).Parameters:
-
**op**ndarray or sequence of array_like
The array(s) to iterate over.

**flags**sequence of str, optional
Flags to control the behavior of the iterator.

`buffered`
enables buffering when required.
`c_index`
causes a C-order index to be tracked.
`f_index`
causes a Fortran-order index to be tracked.
`multi_index`
causes a multi-index, or a tuple of indices with one per iteration dimension, to be tracked.
`common_dtype`
causes all the operands to be converted to a common data type, with copying or buffering as necessary.
`copy_if_overlap`
causes the iterator to determine if read operands have overlap with write operands, and make temporary copies as necessary to avoid overlap. False positives (needless copying) are possible in some cases.
`delay_bufalloc`
delays allocation of the buffers until a reset() call is made. Allows`allocate`
operands to be initialized before their values are copied into the buffers.
`external_loop`
causes the`values`
given to be one-dimensional arrays with multiple values instead of zero-dimensional arrays.
`grow_inner`
allows the`value`
array sizes to be made larger than the buffer size when both`buffered`
and`external_loop`
is used.
`ranged`
allows the iterator to be restricted to a sub-range of the iterindex values.
`refs_ok`
enables iteration of reference types, such as object arrays.
`reduce_ok`
enables iteration of`readwrite`
operands which are broadcasted, also known as reduction operands.
`zerosize_ok`
allowsto be zero.`itersize`
**op_flags**list of list of str, optional
This is a list of flags for each operand. At minimum, one of

`readonly`
,`readwrite`
, or`writeonly`
must be specified.`readonly`
indicates the operand will only be read from.
`readwrite`
indicates the operand will be read from and written to.
`writeonly`
indicates the operand will only be written to.
`no_broadcast`
prevents the operand from being broadcasted.
`contig`
forces the operand data to be contiguous.
`aligned`
forces the operand data to be aligned.
`nbo`
forces the operand data to be in native byte order.
`copy`
allows a temporary read-only copy if required.
`updateifcopy`
allows a temporary read-write copy if required.
`allocate`
causes the array to be allocated if it is None in the`op`
parameter.
`no_subtype`
prevents an`allocate`
operand from using a subtype.
`arraymask`
indicates that this operand is the mask to use for selecting elements when writing to operands with the ‘writemasked’ flag set. The iterator does not enforce this, but when writing from a buffer back to the array, it only copies those elements indicated by this mask.
`writemasked`
indicates that only elements where the chosen`arraymask`
operand is True will be written to.
`overlap_assume_elementwise`
can be used to mark operands that are accessed only in the iterator order, to allow less conservative copying when`copy_if_overlap`
is present.
**op_dtypes**dtype or tuple of dtype(s), optional
The required data type(s) of the operands. If copying or buffering is enabled, the data will be converted to/from their original types.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the iteration order. ‘C’ means C order, ‘F’ means Fortran order, ‘A’ means ‘F’ order if all the arrays are Fortran contiguous, ‘C’ order otherwise, and ‘K’ means as close to the order the array elements appear in memory as possible. This also affects the element memory order of

`allocate`
operands, as they are allocated to be compatible with iteration order. Default is ‘K’.
**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur when making a copy or buffering. Setting this to ‘unsafe’ is not recommended, as it can adversely affect accumulations.

‘no’ means the data types should not be cast at all.

‘equiv’ means only byte-order changes are allowed.

‘safe’ means only casts which can preserve values are allowed.

‘same_kind’ means only safe casts or casts within a kind, like float64 to float32, are allowed.

‘unsafe’ means any data conversions may be done.

**op_axes**list of list of ints, optional
If provided, is a list of ints or None for each operands. The list of axes for an operand is a mapping from the dimensions of the iterator to the dimensions of the operand. A value of -1 can be placed for entries, causing that dimension to be treated as

.`newaxis`
**itershape**tuple of ints, optional
The desired shape of the iterator. This allows

`allocate`
operands with a dimension mapped by op_axes not corresponding to a dimension of a different operand to get a value not equal to 1 for that dimension.
**buffersize**int, optional
When buffering is enabled, controls the size of the temporary buffers. Set to 0 for the default value.

Notes

supersedes`nditer`
. The iterator implementation behind`flatiter`
is also exposed by the NumPy C API.`nditer`
The Python exposure supplies two iteration interfaces, one which follows the Python iterator protocol, and another which mirrors the C-style do-while pattern. The native Python approach is better in most cases, but if you need the coordinates or index of an iterator, use the C-style pattern.

Examples

Here is how we might write an

`iter_add`
function, using the Python iterator protocol:>>> def iter_add_py(x, y, out=None): ... addop = np.add ... it = np.nditer([x, y, out], [], ... [['readonly'], ['readonly'], ['writeonly','allocate']]) ... with it: ... for (a, b, c) in it: ... addop(a, b, out=c) ... return it.operands[2]
Here is the same function, but following the C-style pattern:

>>> def iter_add(x, y, out=None): ... addop = np.add ... it = np.nditer([x, y, out], [], ... [['readonly'], ['readonly'], ['writeonly','allocate']]) ... with it: ... while not it.finished: ... addop(it[0], it[1], out=it[2]) ... it.iternext() ... return it.operands[2]
Here is an example outer product function:

>>> def outer_it(x, y, out=None): ... mulop = np.multiply ... it = np.nditer([x, y, out], ['external_loop'], ... [['readonly'], ['readonly'], ['writeonly', 'allocate']], ... op_axes=[list(range(x.ndim)) + [-1] * y.ndim, ... [-1] * x.ndim + list(range(y.ndim)), ... None]) ... with it: ... for (a, b, c) in it: ... mulop(a, b, out=c) ... return it.operands[2]
>>> a = np.arange(2)+1 >>> b = np.arange(3)+1 >>> outer_it(a,b) array([[1, 2, 3], [2, 4, 6]])
Here is an example function which operates like a “lambda” ufunc:

>>> def luf(lamdaexpr, *args, **kwargs): ... '''luf(lambdaexpr, op1, ..., opn, out=None, order='K', casting='safe', buffersize=0)''' ... nargs = len(args) ... op = (kwargs.get('out',None),) + args ... it = np.nditer(op, ['buffered','external_loop'], ... [['writeonly','allocate','no_broadcast']] + ... [['readonly','nbo','aligned']]*nargs, ... order=kwargs.get('order','K'), ... casting=kwargs.get('casting','safe'), ... buffersize=kwargs.get('buffersize',0)) ... while not it.finished: ... it[0] = lamdaexpr(*it[1:]) ... it.iternext() ... return it.operands[0]
>>> a = np.arange(5) >>> b = np.ones(5) >>> luf(lambda i,j:i*i + j/2, a, b) array([ 0.5, 1.5, 4.5, 9.5, 16.5])
If operand flags

`"writeonly"`
or`"readwrite"`
are used the operands may be views into the original data with the*WRITEBACKIFCOPY*flag. In this casemust be used as a context manager or the`nditer`
method must be called before using the result. The temporary data will be written back to the original data when the`nditer.close`
`__exit__`
function is called but not before:>>> a = np.arange(6, dtype='i4')[::-2] >>> with np.nditer(a, [], ... [['writeonly', 'updateifcopy']], ... casting='unsafe', ... op_dtypes=[np.dtype('f4')]) as i: ... x = i.operands[0] ... x[:] = [-1, -2, -3] ... # a still unchanged here >>> a, x (array([-1, -2, -3], dtype=int32), array([-1., -2., -3.], dtype=float32))
It is important to note that once the iterator is exited, dangling references (like

*x*in the example) may or may not share data with the original data*a*. If writeback semantics were active, i.e. if*x.base.flags.writebackifcopy*is*True*, then exiting the iterator will sever the connection between*x*and*a*, writing to*x*will no longer write to*a*. If writeback semantics are not active, then*x.data*will still point at some part of*a.data*, and writing to one will affect the other.Context management and the

method appeared in version 1.15.0.`close`
Attributes:
-
**dtypes**tuple of dtype(s)
The data types of the values provided in

. This may be different from the operand data types if buffering is enabled. Valid only before the iterator is closed.`value`
**finished**bool
Whether the iteration over the operands is finished or not.

**has_delayed_bufalloc**bool
If True, the iterator was created with the

`delay_bufalloc`
flag, and no reset() function was called on it yet.
**has_index**bool
If True, the iterator was created with either the

`c_index`
or the`f_index`
flag, and the propertycan be used to retrieve it.`index`
**has_multi_index**bool
If True, the iterator was created with the

`multi_index`
flag, and the propertycan be used to retrieve it.`multi_index`
**index**
When the

`c_index`
or`f_index`
flag was used, this property provides access to the index. Raises a ValueError if accessed and`has_index`
is False.
**iterationneedsapi**bool
Whether iteration requires access to the Python API, for example if one of the operands is an object array.

**iterindex**int
An index which matches the order of iteration.

**itersize**int
Size of the iterator.

**itviews**
Structured view(s) of

in memory, matching the reordered and optimized iterator access pattern. Valid only before the iterator is closed.`operands`
**multi_index**
When the

`multi_index`
flag was used, this property provides access to the index. Raises a ValueError if accessed accessed and`has_multi_index`
is False.
**ndim**int
The dimensions of the iterator.

**nop**int
The number of iterator operands.

tuple of operand(s)`operands`
operands[

*Slice*]
**shape**tuple of ints
Shape tuple, the shape of the iterator.

**value**
Value of

`operands`
at current iteration. Normally, this is a tuple of array scalars, but if the flag`external_loop`
is used, it is a tuple of one dimensional arrays.
Methods

()`close`
Resolve all writeback semantics in writeable operands.

()`copy`
Get a copy of the iterator in its current state.

Print the current state of the

instance and debug info to stdout.`nditer`
When the "external_loop" was not used during construction, but is desired, this modifies the iterator to behave as if the flag was specified.

()`iternext`
Check whether iterations are left, and perform a single internal iteration without returning the result.

(i, /)`remove_axis`
Removes axis

*i*from the iterator.When the "multi_index" flag was specified, this removes it, allowing the internal iteration structure to be optimized further.

()`reset`
Reset the iterator to its initial state.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__new__
numpy.ndarray.__new__
#
method
ndarray.
__new__
(
*
args
,
**
kwargs
)
## numpy.polydiv[#](#numpy-polydiv)
numpy.polydiv(*u*,*v*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/polynomial.py#L977-L1047)[#](#numpy.polydiv)
-
Returns the quotient and remainder of polynomial division.

Note

This forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in

is preferred. A summary of the differences can be found in the`numpy.polynomial`
[transition guide](../routines.polynomials.html).The input arrays are the coefficients (including any coefficients equal to zero) of the “numerator” (dividend) and “denominator” (divisor) polynomials, respectively.

Parameters:
-
**u**array_like or poly1d
Dividend polynomial’s coefficients.

**v**array_like or poly1d
Divisor polynomial’s coefficients.

Returns:
-
**q**ndarray
Coefficients, including those equal to zero, of the quotient.

**r**ndarray
Coefficients, including those equal to zero, of the remainder.

Notes

Both

*u*and*v*must be 0-d or 1-d (ndim = 0 or 1), but*u.ndim*need not equal*v.ndim*. In other words, all four possible combinations -`u.ndim = v.ndim = 0`
,`u.ndim = v.ndim = 1`
,`u.ndim = 1, v.ndim = 0`
, and`u.ndim = 0, v.ndim = 1`
- work.Examples

\[\frac{3x^2 + 5x + 2}{2x + 1} = 1.5x + 1.75, remainder 0.25\]>>> x = np.array([3.0, 5.0, 2.0]) >>> y = np.array([2.0, 1.0]) >>> np.polydiv(x, y) (array([1.5 , 1.75]), array([0.25]))# numpy.chararray.squeeze[#](#numpy-chararray-squeeze)
method

chararray.squeeze(*axis=None*)[#](#numpy.chararray.squeeze)
-
Remove axes of length one from

*a*.Refer to

for full documentation.`numpy.squeeze`
See also

`numpy.squeeze`
equivalent function

method

Remove axes of length one from *a*.

Refer to [ numpy.squeeze](numpy.squeeze.html#numpy.squeeze) for full documentation.

See also

`numpy.squeeze`
equivalent function# numpy.polynomial.polynomial.polyone[#](#numpy-polynomial-polynomial-polyone)
polynomial.polynomial.polyone*= array([1])*[#](#numpy.polynomial.polynomial.polyone)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.recarray.dtype[#](#numpy-recarray-dtype)
attribute

recarray.dtype[#](#numpy.recarray.dtype)
-
Data-type of the array’s elements.

Warning

Setting

`arr.dtype`
is discouraged and may be deprecated in the future. Setting will replace the`dtype`
without modifying the memory (see alsoand`ndarray.view`
).`ndarray.astype`
Parameters:
-
**None**
Returns:
-
**d**numpy dtype object
See also

`ndarray.astype`
Cast the values contained in the array to a new data-type.

`ndarray.view`
Create a view of the same data but a different data-type.

`numpy.dtype`
Examples

>>> x array([[0, 1], [2, 3]]) >>> x.dtype dtype('int32') >>> type(x.dtype) <type 'numpy.dtype'># numpy.testing.assert_warns[#](#numpy-testing-assert-warns)
testing.assert_warns(*warning_class*,**args*,***kwargs*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/_private/utils.py#L1726-L1777)[#](#numpy.testing.assert_warns)
-
Fail unless the given callable throws the specified warning.

A warning of class warning_class should be thrown by the callable when invoked with arguments args and keyword arguments kwargs. If a different type of warning is thrown, it will not be caught.

If called with all arguments other than the warning class omitted, may be used as a context manager:

with assert_warns(SomeWarning):
-
do_something()

The ability to be used as a context manager is new in NumPy v1.11.0.

New in version 1.4.0.

Parameters:
-
**warning_class**class
The class defining the warning that

*func*is expected to throw.
**func**callable, optional
Callable to test

***args**Arguments
Arguments for

*func*.
****kwargs**Kwargs
Keyword arguments for

*func*.
Returns:
-
The value returned by *func*.
-
The value returned by
-
Examples

>>> import warnings >>> def deprecated_func(num): ... warnings.warn("Please upgrade", DeprecationWarning) ... return num*num >>> with np.testing.assert_warns(DeprecationWarning): ... assert deprecated_func(4) == 16 >>> # or passing a func >>> ret = np.testing.assert_warns(DeprecationWarning, deprecated_func, 4) >>> assert ret == 16# numpy.get_include[#](#numpy-get-include)
numpy.get_include()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/utils.py#L75-L101)[#](#numpy.get_include)
-
Return the directory that contains the NumPy *.h header files.

Extension modules that need to compile against NumPy should use this function to locate the appropriate include directory.

Notes

When using

`distutils`
, for example in`setup.py`
:import numpy as np ... Extension('extension_name', ... include_dirs=[np.get_include()]) ...# numpy.char.isalnum[#](#numpy-char-isalnum)
char.isalnum(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L819-L842)[#](#numpy.char.isalnum)
-
Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.

Calls

*str.isalnum*element-wise.For 8-bit strings, this method is locale-dependent.

Parameters:
-
**a**array_like of str or unicode
Returns:
-
**out**ndarray
Output array of str or unicode, depending on input type

See alsonumpy.random.Philox.state# attribute random.Philox.state# Get or set the PRNG state Returns: statedictDictionary containing the information required to describe the state of the PRNG# numpy.random.RandomState.laplace[#](#numpy-random-randomstate-laplace)
method

random.RandomState.laplace(*loc=0.0*,*scale=1.0*,*size=None*)[#](#numpy.random.RandomState.laplace)
-
Draw samples from the Laplace or double exponential distribution with specified location (or mean) and scale (decay).

The Laplace distribution is similar to the Gaussian/normal distribution, but is sharper at the peak and has fatter tails. It represents the difference between two independent, identically distributed exponential random variables.

Note

New code should use the

method of a`laplace`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**loc**float or array_like of floats, optional
The position, \(\mu\), of the distribution peak. Default is 0.

**scale**float or array_like of floats, optional
\(\lambda\), the exponential decay. Default is 1. Must be non- negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`loc`
and`scale`
are both scalars. Otherwise,`np.broadcast(loc, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Laplace distribution.

See also

`random.Generator.laplace`
which should be used for new code.

Notes

It has the probability density function

\[f(x; \mu, \lambda) = \frac{1}{2\lambda} \exp\left(-\frac{|x - \mu|}{\lambda}\right).\]The first law of Laplace, from 1774, states that the frequency of an error can be expressed as an exponential function of the absolute magnitude of the error, which leads to the Laplace distribution. For many problems in economics and health sciences, this distribution seems to model the data better than the standard Gaussian distribution.

References

[1]Abramowitz, M. and Stegun, I. A. (Eds.). “Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables, 9th printing,” New York: Dover, 1972.

[2]Kotz, Samuel, et. al. “The Laplace Distribution and Generalizations, “ Birkhauser, 2001.

[3]Weisstein, Eric W. “Laplace Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/LaplaceDistribution.html](http://mathworld.wolfram.com/LaplaceDistribution.html)[4]Wikipedia, “Laplace distribution”,

[https://en.wikipedia.org/wiki/Laplace_distribution](https://en.wikipedia.org/wiki/Laplace_distribution)Examples

Draw samples from the distribution

>>> loc, scale = 0., 1. >>> s = np.random.laplace(loc, scale, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 30, density=True) >>> x = np.arange(-8., 8., .01) >>> pdf = np.exp(-abs(x-loc)/scale)/(2.*scale) >>> plt.plot(x, pdf)
Plot Gaussian for comparison:

>>> g = (1/(scale * np.sqrt(2 * np.pi)) * ... np.exp(-(x - loc)**2 / (2 * scale**2))) >>> plt.plot(x,g)# numpy.seterr[#](#numpy-seterr)
numpy.seterr(*all=None*,*divide=None*,*over=None*,*under=None*,*invalid=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_ufunc_config.py#L33-L129)[#](#numpy.seterr)
-
Set how floating-point errors are handled.

Note that operations on integer scalar types (such as

) are handled like floating point, and are affected by these settings.`int16`
Parameters:
-
**all**{‘ignore’, ‘warn’, ‘raise’, ‘call’, ‘print’, ‘log’}, optional
Set treatment for all types of floating-point errors at once:

ignore: Take no action when the exception occurs.

warn: Print a

*RuntimeWarning*(via the Pythonmodule).`warnings`
raise: Raise a

*FloatingPointError*.
call: Call a function specified using the

function.`seterrcall`
print: Print a warning directly to

`stdout`
.
log: Record error in a Log object specified by

.`seterrcall`
The default is not to change the current behavior.

**divide**{‘ignore’, ‘warn’, ‘raise’, ‘call’, ‘print’, ‘log’}, optional
Treatment for division by zero.

**over**{‘ignore’, ‘warn’, ‘raise’, ‘call’, ‘print’, ‘log’}, optional
Treatment for floating-point overflow.

**under**{‘ignore’, ‘warn’, ‘raise’, ‘call’, ‘print’, ‘log’}, optional
Treatment for floating-point underflow.

**invalid**{‘ignore’, ‘warn’, ‘raise’, ‘call’, ‘print’, ‘log’}, optional
Treatment for invalid floating-point operation.

Returns:
-
**old_settings**dict
Dictionary containing the old settings.

See also

`seterrcall`
Set a callback function for the ‘call’ mode.

,`geterr`
,`geterrcall`
`errstate`
Notes

The floating-point exceptions are defined in the IEEE 754 standard

[[1]](#r4cab4292821f-1):Division by zero: infinite result obtained from finite numbers.

Overflow: result too large to be expressed.

Underflow: result so close to zero that some precision was lost.

Invalid operation: result is not an expressible number, typically indicates that a NaN was produced.

Examples

>>> old_settings = np.seterr(all='ignore') #seterr to known value >>> np.seterr(over='raise') {'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'} >>> np.seterr(**old_settings) # reset to default {'divide': 'ignore', 'over': 'raise', 'under': 'ignore', 'invalid': 'ignore'}
>>> np.int16(32000) * np.int16(3) 30464 >>> old_settings = np.seterr(all='warn', over='raise') >>> np.int16(32000) * np.int16(3) Traceback (most recent call last): File "<stdin>", line 1, in <module> FloatingPointError: overflow encountered in scalar multiply
>>> old_settings = np.seterr(all='print') >>> np.geterr() {'divide': 'print', 'over': 'print', 'under': 'print', 'invalid': 'print'} >>> np.int16(32000) * np.int16(3) 30464# numpy.choose[#](#numpy-choose)
numpy.choose(*a*,*choices*,*out=None*,*mode='raise'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L294-L416)[#](#numpy.choose)
-
Construct an array from an index array and a list of arrays to choose from.

First of all, if confused or uncertain, definitely look at the Examples - in its full generality, this function is less simple than it might seem from the following code description (below ndi =

`numpy.lib.index_tricks`
):`np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])`
.But this omits some subtleties. Here is a fully general summary:

Given an “index” array (

*a*) of integers and a sequence of`n`
arrays (*choices*),*a*and each choice array are first broadcast, as necessary, to arrays of a common shape; calling these*Ba*and*Bchoices[i], i = 0,…,n-1*we have that, necessarily,`Ba.shape == Bchoices[i].shape`
for each`i`
. Then, a new array with shape`Ba.shape`
is created as follows:if

`mode='raise'`
(the default), then, first of all, each element of`a`
(and thus`Ba`
) must be in the range`[0, n-1]`
; now, suppose that`i`
(in that range) is the value at the`(j0, j1, ..., jm)`
position in`Ba`
- then the value at the same position in the new array is the value in`Bchoices[i]`
at that same position;
if

`mode='wrap'`
, values in*a*(and thus*Ba*) may be any (signed) integer; modular arithmetic is used to map integers outside the range*[0, n-1]*back into that range; and then the new array is constructed as above;
if

`mode='clip'`
, values in*a*(and thus`Ba`
) may be any (signed) integer; negative integers are mapped to 0; values greater than`n-1`
are mapped to`n-1`
; and then the new array is constructed as above.
Parameters:
-
**a**int array
This array must contain integers in

`[0, n-1]`
, where`n`
is the number of choices, unless`mode=wrap`
or`mode=clip`
, in which cases any integers are permissible.
**choices**sequence of arrays
Choice arrays.

*a*and all of the choices must be broadcastable to the same shape. If*choices*is itself an array (not recommended), then its outermost dimension (i.e., the one corresponding to`choices.shape[0]`
) is taken as defining the “sequence”.
**out**array, optional
If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype. Note that

*out*is always buffered if`mode='raise'`
; use other modes for better performance.
**mode**{‘raise’ (default), ‘wrap’, ‘clip’}, optional
Specifies how indices outside

`[0, n-1]`
will be treated:‘raise’ : an exception is raised

‘wrap’ : value becomes value mod

`n`
‘clip’ : values < 0 are mapped to 0, values > n-1 are mapped to n-1

Returns:
-
**merged_array**array
The merged result.

Raises:
-
ValueError: shape mismatch
-
If

*a*and each choice array are not all broadcastable to the same shape.
See also

`ndarray.choose`
equivalent method

`numpy.take_along_axis`
Preferable if

*choices*is an array
Notes

To reduce the chance of misinterpretation, even though the following “abuse” is nominally supported,

*choices*should neither be, nor be thought of as, a single array, i.e., the outermost sequence-like container should be either a list or a tuple.Examples

>>> choices = [[0, 1, 2, 3], [10, 11, 12, 13], ... [20, 21, 22, 23], [30, 31, 32, 33]] >>> np.choose([2, 3, 1, 0], choices ... # the first element of the result will be the first element of the ... # third (2+1) "array" in choices, namely, 20; the second element ... # will be the second element of the fourth (3+1) choice array, i.e., ... # 31, etc. ... ) array([20, 31, 12, 3]) >>> np.choose([2, 4, 1, 0], choices, mode='clip') # 4 goes to 3 (4-1) array([20, 31, 12, 3]) >>> # because there are 4 choice arrays >>> np.choose([2, 4, 1, 0], choices, mode='wrap') # 4 goes to (4 mod 4) array([20, 1, 12, 3]) >>> # i.e., 0
A couple examples illustrating how choose broadcasts:

>>> a = [[1, 0, 1], [0, 1, 0], [1, 0, 1]] >>> choices = [-10, 10] >>> np.choose(a, choices) array([[ 10, -10, 10], [-10, 10, -10], [ 10, -10, 10]])
>>> # With thanks to Anne Archibald >>> a = np.array([0, 1]).reshape((2,1,1)) >>> c1 = np.array([1, 2, 3]).reshape((1,3,1)) >>> c2 = np.array([-1, -2, -3, -4, -5]).reshape((1,1,5)) >>> np.choose(a, (c1, c2)) # result is 2x3x5, res[0,:,:]=c1, res[1,:,:]=c2 array([[[ 1, 1, 1, 1, 1], [ 2, 2, 2, 2, 2], [ 3, 3, 3, 3, 3]], [[-1, -2, -3, -4, -5], [-1, -2, -3, -4, -5], [-1, -2, -3, -4, -5]]])# numpy.polynomial.legendre.Legendre.fit[#](#numpy-polynomial-legendre-legendre-fit)
method

*classmethod*polynomial.legendre.Legendre.fit(*x*,*y*,*deg*,*domain=None*,*rcond=None*,*full=False*,*w=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L955-L1045)[#](#numpy.polynomial.legendre.Legendre.fit)
-
Least squares fit to data.

Return a series instance that is the least squares fit to the data

*y*sampled at*x*. The domain of the returned instance can be specified and this will often result in a superior fit with less chance of ill conditioning.Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,)
y-coordinates of the M sample points

`(x[i], y[i])`
.
**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**domain**{None, [beg, end], []}, optional
Domain to use for the returned series. If

`None`
, then a minimal domain that covers the points*x*is chosen. If`[]`
the class domain is used. The default value was the class domain in NumPy 1.4 and`None`
in later versions. The`[]`
option was added in numpy 1.5.0.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (M,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.New in version 1.5.0.

**window**{[beg, end]}, optional
Window to use for the returned series. The default value is the default class domain

New in version 1.6.0.

**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
A series that represents the least squares fit to the data and has the domain and window specified in the call. If the coefficients for the unscaled and unshifted basis polynomials are of interest, do

`new_series.convert().coef`
.
**[resid, rank, sv, rcond]**list
These values are only returned if

`full == True`
resid – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

sv – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`linalg.lstsq`# numpy.chararray.argmax[#](#numpy-chararray-argmax)
method

chararray.argmax(*axis=None*,*out=None*,***,*keepdims=False*)[#](#numpy.chararray.argmax)
-
Return indices of the maximum values along the given axis.

Refer to

for full documentation.`numpy.argmax`
See also

`numpy.argmax`
equivalent function# numpy.squeeze[#](#numpy-squeeze)
numpy.squeeze(*a*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L1491-L1558)[#](#numpy.squeeze)
-
Remove axes of length one from

*a*.Parameters:
-
**a**array_like
Input data.

**axis**None or int or tuple of ints, optional
New in version 1.7.0.

Selects a subset of the entries of length one in the shape. If an axis is selected with shape entry greater than one, an error is raised.

Returns:
-
**squeezed**ndarray
The input array, but with all or a subset of the dimensions of length 1 removed. This is always

*a*itself or a view into*a*. Note that if all axes are squeezed, the result is a 0d array and not a scalar.
Raises:
-
ValueError
-
If

*axis*is not None, and an axis being squeezed is not of length 1
See also

`expand_dims`
The inverse operation, adding entries of length one

`reshape`
Insert, remove, and combine dimensions, and resize existing ones

Examples

>>> x = np.array([[[0], [1], [2]]]) >>> x.shape (1, 3, 1) >>> np.squeeze(x).shape (3,) >>> np.squeeze(x, axis=0).shape (3, 1) >>> np.squeeze(x, axis=1).shape Traceback (most recent call last): ... ValueError: cannot select an axis to squeeze out which has size not equal to one >>> np.squeeze(x, axis=2).shape (1, 3) >>> x = np.array([[1234]]) >>> x.shape (1, 1) >>> np.squeeze(x) array(1234) # 0d array >>> np.squeeze(x).shape () >>> np.squeeze(x)[()] 1234# numpy.polynomial.legendre.legfromroots[#](#numpy-polynomial-legendre-legfromroots)
polynomial.legendre.legfromroots(*roots*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L267-L319)[#](#numpy.polynomial.legendre.legfromroots)
-
Generate a Legendre series with given roots.

The function returns the coefficients of the polynomial

\[p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),\]in Legendre form, where the

*r_n*are the roots specified in. If a zero has multiplicity n, then it must appear in`roots`
n times. For instance, if 2 is a root of multiplicity three and 3 is a root of multiplicity 2, then`roots`
looks something like [2, 2, 2, 3, 3]. The roots can appear in any order.`roots`
If the returned coefficients are

*c*, then\[p(x) = c_0 + c_1 * L_1(x) + ... + c_n * L_n(x)\]The coefficient of the last term is not generally 1 for monic polynomials in Legendre form.

Parameters:
-
**roots**array_like
Sequence containing the roots.

Returns:
-
**out**ndarray
1-D array of coefficients. If all roots are real then

*out*is a real array, if some of the roots are complex, then*out*is complex even if all the coefficients in the result are real (see Examples below).
See also

Examples

>>> import numpy.polynomial.legendre as L >>> L.legfromroots((-1,0,1)) # x^3 - x relative to the standard basis array([ 0. , -0.4, 0. , 0.4]) >>> j = complex(0,1) >>> L.legfromroots((-j,j)) # x^2 + 1 relative to the standard basis array([ 1.33333333+0.j, 0.00000000+0.j, 0.66666667+0.j]) # may varynumpy.ma.masked_array.baseclass# property property ma.masked_array.baseclass# Class of the underlying data (read-only).# numpy.median[#](#numpy-median)
numpy.median(*a*,*axis=None*,*out=None*,*overwrite_input=False*,*keepdims=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L3845-L3928)[#](#numpy.median)
-
Compute the median along the specified axis.

Returns the median of the array elements.

Parameters:
-
**a**array_like
Input array or object that can be converted to an array.

**axis**{int, sequence of int, None}, optional
Axis or axes along which the medians are computed. The default is to compute the median along a flattened version of the array. A sequence of axes is supported since version 1.9.0.

**out**ndarray, optional
Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output, but the type (of the output) will be cast if necessary.

**overwrite_input**bool, optional
If True, then allow use of memory of input array

*a*for calculations. The input array will be modified by the call to. This will save memory when you do not need to preserve the contents of the input array. Treat the input as undefined, but it will probably be fully or partially sorted. Default is False. If`median`
*overwrite_input*is`True`
and*a*is not already an, an error will be raised.`ndarray`
**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original

*arr*.New in version 1.9.0.

Returns:
-
**median**ndarray
A new array holding the result. If the input contains integers or floats smaller than

`float64`
, then the output data-type is`np.float64`
. Otherwise, the data-type of the output is the same as that of the input. If*out*is specified, that array is returned instead.
See also

Notes

Given a vector

`V`
of length`N`
, the median of`V`
is the middle value of a sorted copy of`V`
,`V_sorted`
- i e.,`V_sorted[(N-1)/2]`
, when`N`
is odd, and the average of the two middle values of`V_sorted`
when`N`
is even.Examples

>>> a = np.array([[10, 7, 4], [3, 2, 1]]) >>> a array([[10, 7, 4], [ 3, 2, 1]]) >>> np.median(a) 3.5 >>> np.median(a, axis=0) array([6.5, 4.5, 2.5]) >>> np.median(a, axis=1) array([7., 2.]) >>> m = np.median(a, axis=0) >>> out = np.zeros_like(m) >>> np.median(a, axis=0, out=m) array([6.5, 4.5, 2.5]) >>> m array([6.5, 4.5, 2.5]) >>> b = a.copy() >>> np.median(b, axis=1, overwrite_input=True) array([7., 2.]) >>> assert not np.all(a==b) >>> b = a.copy() >>> np.median(b, axis=None, overwrite_input=True) 3.5 >>> assert not np.all(a==b)# numpy.polynomial.hermite.Hermite.basis[#](#numpy-polynomial-hermite-hermite-basis)
method

*classmethod*polynomial.hermite.Hermite.basis(*deg*,*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1125-L1164)[#](#numpy.polynomial.hermite.Hermite.basis)
-
Series basis polynomial of degree

*deg*.Returns the series representing the basis polynomial of degree

*deg*.New in version 1.7.0.

Parameters:
-
**deg**int
Degree of the basis polynomial for the series. Must be >= 0.

**domain**{None, array_like}, optional
If given, the array must be of the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the domain. If None is given then the class domain is used. The default is None.
**window**{None, array_like}, optional
If given, the resulting array must be if the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the window. If None is given then the class window is used. The default is None.
**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
A series with the coefficient of the

*deg*term set to one and all others zero.# numpy.gradient[#](#numpy-gradient)
numpy.gradient(*f*,**varargs*,*axis=None*,*edge_order=1*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L972-L1317)[#](#numpy.gradient)
-
Return the gradient of an N-dimensional array.

The gradient is computed using second order accurate central differences in the interior points and either first or second order accurate one-sides (forward or backwards) differences at the boundaries. The returned gradient hence has the same shape as the input array.

Parameters:
-
**f**array_like
An N-dimensional array containing samples of a scalar function.

**varargs**list of scalar or array, optional
Spacing between f values. Default unitary spacing for all dimensions. Spacing can be specified using:

single scalar to specify a sample distance for all dimensions.

N scalars to specify a constant sample distance for each dimension. i.e.

*dx*,*dy*,*dz*, …
N arrays to specify the coordinates of the values along each dimension of F. The length of the array must match the size of the corresponding dimension

Any combination of N scalars/arrays with the meaning of 2. and 3.

If

*axis*is given, the number of varargs must equal the number of axes. Default: 1.
**edge_order**{1, 2}, optional
Gradient is calculated using N-th order accurate differences at the boundaries. Default: 1.

New in version 1.9.1.

**axis**None or int or tuple of ints, optional
Gradient is calculated only along the given axis or axes The default (axis = None) is to calculate the gradient for all the axes of the input array. axis may be negative, in which case it counts from the last to the first axis.

New in version 1.11.0.

Returns:
-
**gradient**ndarray or list of ndarray
A list of ndarrays (or a single ndarray if there is only one dimension) corresponding to the derivatives of f with respect to each dimension. Each derivative has the same shape as f.

Notes

Assuming that \(f\in C^{3}\) (i.e., \(f\) has at least 3 continuous derivatives) and let \(h_{*}\) be a non-homogeneous stepsize, we minimize the “consistency error” \(\eta_{i}\) between the true gradient and its estimate from a linear combination of the neighboring grid-points:

\[\eta_{i} = f_{i}^{\left(1\right)} - \left[ \alpha f\left(x_{i}\right) + \beta f\left(x_{i} + h_{d}\right) + \gamma f\left(x_{i}-h_{s}\right) \right]\]By substituting \(f(x_{i} + h_{d})\) and \(f(x_{i} - h_{s})\) with their Taylor series expansion, this translates into solving the following the linear system:

\[\begin{split}\left\{ \begin{array}{r} \alpha+\beta+\gamma=0 \\ \beta h_{d}-\gamma h_{s}=1 \\ \beta h_{d}^{2}+\gamma h_{s}^{2}=0 \end{array} \right.\end{split}\]The resulting approximation of \(f_{i}^{(1)}\) is the following:

\[\hat f_{i}^{(1)} = \frac{ h_{s}^{2}f\left(x_{i} + h_{d}\right) + \left(h_{d}^{2} - h_{s}^{2}\right)f\left(x_{i}\right) - h_{d}^{2}f\left(x_{i}-h_{s}\right)} { h_{s}h_{d}\left(h_{d} + h_{s}\right)} + \mathcal{O}\left(\frac{h_{d}h_{s}^{2} + h_{s}h_{d}^{2}}{h_{d} + h_{s}}\right)\]It is worth noting that if \(h_{s}=h_{d}\) (i.e., data are evenly spaced) we find the standard second order approximation:

\[\hat f_{i}^{(1)}= \frac{f\left(x_{i+1}\right) - f\left(x_{i-1}\right)}{2h} + \mathcal{O}\left(h^{2}\right)\]With a similar procedure the forward/backward approximations used for boundaries can be derived.

References

[1]Quarteroni A., Sacco R., Saleri F. (2007) Numerical Mathematics (Texts in Applied Mathematics). New York: Springer.

[2]Durran D. R. (1999) Numerical Methods for Wave Equations in Geophysical Fluid Dynamics. New York: Springer.

[3]Fornberg B. (1988) Generation of Finite Difference Formulas on Arbitrarily Spaced Grids, Mathematics of Computation 51, no. 184 : 699-706.

[PDF](http://www.ams.org/journals/mcom/1988-51-184/S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf).Examples

>>> f = np.array([1, 2, 4, 7, 11, 16], dtype=float) >>> np.gradient(f) array([1. , 1.5, 2.5, 3.5, 4.5, 5. ]) >>> np.gradient(f, 2) array([0.5 , 0.75, 1.25, 1.75, 2.25, 2.5 ])
Spacing can be also specified with an array that represents the coordinates of the values F along the dimensions. For instance a uniform spacing:

>>> x = np.arange(f.size) >>> np.gradient(f, x) array([1. , 1.5, 2.5, 3.5, 4.5, 5. ])
Or a non uniform one:

>>> x = np.array([0., 1., 1.5, 3.5, 4., 6.], dtype=float) >>> np.gradient(f, x) array([1. , 3. , 3.5, 6.7, 6.9, 2.5])
For two dimensional arrays, the return will be two arrays ordered by axis. In this example the first array stands for the gradient in rows and the second one in columns direction:

>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float)) [array([[ 2., 2., -1.], [ 2., 2., -1.]]), array([[1. , 2.5, 4. ], [1. , 1. , 1. ]])]
In this example the spacing is also specified: uniform for axis=0 and non uniform for axis=1

>>> dx = 2. >>> y = [1., 1.5, 3.5] >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), dx, y) [array([[ 1. , 1. , -0.5], [ 1. , 1. , -0.5]]), array([[2. , 2. , 2. ], [2. , 1.7, 0.5]])]
It is possible to specify how boundaries are treated using

*edge_order*>>> x = np.array([0, 1, 2, 3, 4]) >>> f = x**2 >>> np.gradient(f, edge_order=1) array([1., 2., 4., 6., 7.]) >>> np.gradient(f, edge_order=2) array([0., 2., 4., 6., 8.])
The

*axis*keyword can be used to specify a subset of axes of which the gradient is calculated>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), axis=0) array([[ 2., 2., -1.], [ 2., 2., -1.]])# numpy.signbit[#](#numpy-signbit)
numpy.signbit(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'signbit'>*[#](#numpy.signbit)
-
Returns element-wise True where signbit is set (less than zero).

Parameters:
-
**x**array_like
The input value(s).

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**result**ndarray of bool
Output array, or reference to

*out*if that was supplied. This is a scalar if*x*is a scalar.
Examples

>>> np.signbit(-1.2) True >>> np.signbit(np.array([1, -2.3, 2.1])) array([False, True, False])numpy.polynomial.legendre.Legendre.has_samecoef# method polynomial.legendre.Legendre.has_samecoef(other)[source]# Check if coefficients match. New in version 1.6.0. Parameters: otherclass instanceThe other class must have the coef attribute. Returns: boolbooleanTrue if the coefficients are the same, False otherwise.# numpy.char.rpartition[#](#numpy-char-rpartition)
char.rpartition(*a*,*sep*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1381-L1414)[#](#numpy.char.rpartition)
-
Partition (split) each element around the right-most separator.

Calls

*str.rpartition*element-wise.For each element in

*a*, split the element as the last occurrence of*sep*, and return 3 strings containing the part before the separator, the separator itself, and the part after the separator. If the separator is not found, return 3 strings containing the string itself, followed by two empty strings.Parameters:
-
**a**array_like of str or unicode
Input array

**sep**str or unicode
Right-most separator to split each element in array.

Returns:
-
**out**ndarray
Output array of string or unicode, depending on input type. The output array will have an extra dimension with 3 elements per input element.

See alsondarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__mod__

method

Return self%value.numpy.around# numpy.around(a, decimals=0, out=None)[source]# Round an array to the given number of decimals. around is an alias of round. See also ndarray.roundequivalent method roundalias for this function ceil, fix, floor, rint, truncnumpy.polynomial.laguerre.Laguerre.domain# attribute polynomial.laguerre.Laguerre.domain = array([0, 1])## numpy.memmap.newbyteorder[#](#numpy-memmap-newbyteorder)
method

memmap.newbyteorder(*new_order='S'*,*/*)[#](#numpy.memmap.newbyteorder)
-
Return the array with the same data viewed with a different byte order.

Equivalent to:

arr.view(arr.dtype.newbytorder(new_order))
Changes are also made in all fields and sub-arrays of the array data type.

Parameters:
-
**new_order**string, optional
Byte order to force; a value from the byte order specifications below.

*new_order*codes can be any of:‘S’ - swap dtype from current to opposite endian

{‘<’, ‘little’} - little endian

{‘>’, ‘big’} - big endian

{‘=’, ‘native’} - native order, equivalent to

`sys.byteorder`
{‘|’, ‘I’} - ignore (no change to byte order)

The default value (‘S’) results in swapping the current byte order.

Returns:
-
**new_arr**array
New array object with the dtype reflecting given change to the byte order.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
nditer.itersize
numpy.nditer.itersize
#
attribute
nditer.
itersize
## numpy.random.Generator.geometric[#](#numpy-random-generator-geometric)
method

random.Generator.geometric(*p*,*size=None*)[#](#numpy.random.Generator.geometric)
-
Draw samples from the geometric distribution.

Bernoulli trials are experiments with one of two outcomes: success or failure (an example of such an experiment is flipping a coin). The geometric distribution models the number of trials that must be run in order to achieve success. It is therefore supported on the positive integers,

`k = 1, 2, ...`
.The probability mass function of the geometric distribution is

\[f(k) = (1 - p)^{k - 1} p\]where

*p*is the probability of success of an individual trial.Parameters:
-
**p**float or array_like of floats
The probability of success of an individual trial.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`p`
is a scalar. Otherwise,`np.array(p).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized geometric distribution.

Examples

Draw ten thousand values from the geometric distribution, with the probability of an individual success equal to 0.35:

>>> z = np.random.default_rng().geometric(p=0.35, size=10000)
How many trials succeeded after a single run?

>>> (z == 1).sum() / 10000. 0.34889999999999999 # random# numpy.random.randn[#](#numpy-random-randn)
random.randn(*d0*,*d1*,*...*,*dn*)[#](#numpy.random.randn)
-
Return a sample (or samples) from the “standard normal” distribution.

Note

This is a convenience function for users porting code from Matlab, and wraps

. That function takes a tuple to specify the size of the output, which is consistent with other NumPy functions like`standard_normal`
and`numpy.zeros`
.`numpy.ones`
Note

New code should use the

method of a`standard_normal`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).If positive int_like arguments are provided,

generates an array of shape`randn`
`(d0, d1, ..., dn)`
, filled with random floats sampled from a univariate “normal” (Gaussian) distribution of mean 0 and variance 1. A single float randomly sampled from the distribution is returned if no argument is provided.Parameters:
-
**d0, d1, …, dn**int, optional
The dimensions of the returned array, must be non-negative. If no argument is given a single Python float is returned.

Returns:
-
**Z**ndarray or float
A

`(d0, d1, ..., dn)`
-shaped array of floating-point samples from the standard normal distribution, or a single such float if no parameters were supplied.
See also

`standard_normal`
Similar, but takes a tuple as its argument.

`normal`
Also accepts mu and sigma arguments.

`random.Generator.standard_normal`
which should be used for new code.

Notes

For random samples from the normal distribution with mean

`mu`
and standard deviation`sigma`
, use:sigma * np.random.randn(...) + mu
Examples

>>> np.random.randn() 2.1923875335537315 # random
Two-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:

>>> 3 + 2.5 * np.random.randn(2, 4) array([[-4.49401501, 4.00950034, -1.81814867, 7.29718677], # random [ 0.39924804, 4.68456316, 4.99394529, 4.84057254]]) # randomnumpy.ma.MaskType.copy# method ma.MaskType.copy()# Scalar method identical to the corresponding array attribute. Please see ndarray.copy.# numpy.ma.MaskType.base[#](#numpy-ma-masktype-base)
attribute

ma.MaskType.base[#](#numpy.ma.MaskType.base)
-
Scalar attribute identical to the corresponding array attribute.

Please see

.`ndarray.base`
attribute

Scalar attribute identical to the corresponding array attribute.

Please see [ ndarray.base](numpy.ndarray.base.html#numpy.ndarray.base).# numpy.chararray.argmin[#](#numpy-chararray-argmin)
method

chararray.argmin(*axis=None*,*out=None*,***,*keepdims=False*)[#](#numpy.chararray.argmin)
-
Return indices of the minimum values along the given axis.

Refer to

for detailed documentation.`numpy.argmin`
See also

`numpy.argmin`
equivalent function# numpy.chararray.isalpha[#](#numpy-chararray-isalpha)
method

chararray.isalpha()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2377-L2388)[#](#numpy.chararray.isalpha)
-
Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise.

See also

method

Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise.

See also# numpy.core.records.array[#](#numpy-core-records-array)
core.records.array(*obj*,*dtype=None*,*shape=None*,*offset=0*,*strides=None*,*formats=None*,*names=None*,*titles=None*,*aligned=False*,*byteorder=None*,*copy=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/records.py#L953-L1099)[#](#numpy.core.records.array)
-
Construct a record array from a wide-variety of objects.

A general-purpose record array constructor that dispatches to the appropriate

creation function based on the inputs (see Notes).`recarray`
Parameters:
-
**obj**any
Input object. See Notes for details on how various input types are treated.

**dtype**data-type, optional
Valid dtype for array.

**shape**int or tuple of ints, optional
Shape of each array.

**offset**int, optional
Position in the file or buffer to start reading from.

**strides**tuple of ints, optional
Buffer (

*buf*) is interpreted according to these strides (strides define how many bytes each array element, row, column, etc. occupy in memory).
**formats, names, titles, aligned, byteorder**
If

is`dtype`
`None`
, these arguments are passed toto construct a dtype. See that function for detailed documentation.`numpy.format_parser`
**copy**bool, optional
Whether to copy the input object (True), or to use a reference instead. This option only applies when the input is an ndarray or recarray. Defaults to True.

Returns:
-
np.recarray
-
Record array created from the specified object.

Notes

If

*obj*is`None`
, then call theconstructor. If`recarray`
*obj*is a string, then call theconstructor. If`fromstring`
*obj*is a list or a tuple, then if the first object is an, call`ndarray`
, otherwise call`fromarrays`
. If`fromrecords`
*obj*is a, then make a copy of the data in the recarray (if`recarray`
`copy=True`
) and use the new formats, names, and titles. If*obj*is a file, then call. Finally, if obj is an`fromfile`
, then return`ndarray`
`obj.view(recarray)`
, making a copy of the data if`copy=True`
.Examples

>>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
>>> np.core.records.array(a) rec.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=int32)
>>> b = [(1, 1), (2, 4), (3, 9)] >>> c = np.core.records.array(b, formats = ['i2', 'f2'], names = ('x', 'y')) >>> c rec.array([(1, 1.0), (2, 4.0), (3, 9.0)], dtype=[('x', '<i2'), ('y', '<f2')])
>>> c.x rec.array([1, 2, 3], dtype=int16)
>>> c.y rec.array([ 1.0, 4.0, 9.0], dtype=float16)
>>> r = np.rec.array(['abc','def'], names=['col1','col2']) >>> print(r.col1) abc
>>> r.col1 array('abc', dtype='<U3')
>>> r.col2 array('def', dtype='<U3')numpy.ma.MaskType.put# method ma.MaskType.put()# Scalar method identical to the corresponding array attribute. Please see ndarray.put.# numpy.polynomial.legendre.legmulx[#](#numpy-polynomial-legendre-legmulx)
polynomial.legendre.legmulx(*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L408-L461)[#](#numpy.polynomial.legendre.legmulx)
-
Multiply a Legendre series by x.

Multiply the Legendre series

*c*by x, where x is the independent variable.Parameters:
-
**c**array_like
1-D array of Legendre series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Array representing the result of the multiplication.

Notes

The multiplication uses the recursion relationship for Legendre polynomials in the form

\[xP_i(x) = ((i + 1)*P_{i + 1}(x) + i*P_{i - 1}(x))/(2i + 1)\]Examples

>>> from numpy.polynomial import legendre as L >>> L.legmulx([1,2,3]) array([ 0.66666667, 2.2, 1.33333333, 1.8]) # may vary# numpy.char.chararray.isdigit[#](#numpy-char-chararray-isdigit)
method

char.chararray.isdigit()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2390-L2400)[#](#numpy.char.chararray.isdigit)
-
Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.

See also

method

Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.

See also# numpy.ma.atleast_3d[#](#numpy-ma-atleast-3d)
ma.atleast_3d*= <numpy.ma.extras._fromnxfunction_allargs object>*[#](#numpy.ma.atleast_3d)
-
atleast_3d

View inputs as arrays with at least three dimensions.

Parameters:
-
**arys1, arys2, …**array_like
One or more array-like sequences. Non-array inputs are converted to arrays. Arrays that already have three or more dimensions are preserved.

Returns:
-
**res1, res2, …**ndarray
An array, or list of arrays, each with

`a.ndim >= 3`
. Copies are avoided where possible, and views with three or more dimensions are returned. For example, a 1-D array of shape`(N,)`
becomes a view of shape`(1, N, 1)`
, and a 2-D array of shape`(M, N)`
becomes a view of shape`(M, N, 1)`
.
See also

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> np.atleast_3d(3.0) array([[[3.]]])
>>> x = np.arange(3.0) >>> np.atleast_3d(x).shape (1, 3, 1)
>>> x = np.arange(12.0).reshape(4,3) >>> np.atleast_3d(x).shape (4, 3, 1) >>> np.atleast_3d(x).base is x.base # x is a reshape, so not base itself True
>>> for arr in np.atleast_3d([1, 2], [[1, 2]], [[[1, 2]]]): ... print(arr, arr.shape) ... [[[1] [2]]] (1, 2, 1) [[[1] [2]]] (1, 2, 1) [[[1 2]]] (1, 1, 2)# numpy.memmap.item[#](#numpy-memmap-item)
method

memmap.item(**args*)[#](#numpy.memmap.item)
-
Copy an element of an array to a standard Python scalar and return it.

Parameters:
-
***args**Arguments (variable number and type)
none: in this case, the method only works for arrays with one element (

*a.size == 1*), which element is copied into a standard Python scalar object and returned.
int_type: this argument is interpreted as a flat index into the array, specifying which element to copy and return.

tuple of int_types: functions as does a single int_type argument, except that the argument is interpreted as an nd-index into the array.

Returns:
-
**z**Standard Python scalar object
A copy of the specified element of the array as a suitable Python scalar

Notes

When the data type of

*a*is longdouble or clongdouble, item() returns a scalar array object because there is no available Python scalar that would not lose information. Void arrays return a buffer object for item(), unless fields are defined, in which case a tuple is returned.is very similar to a[args], except, instead of an array scalar, a standard Python scalar is returned. This can be useful for speeding up access to elements of the array and doing arithmetic on elements of the array using Python’s optimized math.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.item(3) 1 >>> x.item(7) 0 >>> x.item((0, 1)) 2 >>> x.item((2, 2)) 1# numpy.char.chararray.tobytes[#](#numpy-char-chararray-tobytes)
method

char.chararray.tobytes(*order='C'*)[#](#numpy.char.chararray.tobytes)
-
Construct Python bytes containing the raw data bytes in the array.

Constructs Python bytes showing a copy of the raw contents of data memory. The bytes object is produced in C-order by default. This behavior is controlled by the

`order`
parameter.New in version 1.9.0.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’}, optional
Controls the memory layout of the bytes object. ‘C’ means C-order, ‘F’ means F-order, ‘A’ (short for

*Any*) means ‘F’ if*a*is Fortran contiguous, ‘C’ otherwise. Default is ‘C’.
Returns:
-
**s**bytes
Python bytes exhibiting a copy of

*a*’s raw data.
See also

`frombuffer`
Inverse of this operation, construct a 1-dimensional array from Python bytes.

Examples

>>> x = np.array([[0, 1], [2, 3]], dtype='<u2') >>> x.tobytes() b'\x00\x00\x01\x00\x02\x00\x03\x00' >>> x.tobytes('C') == x.tobytes() True >>> x.tobytes('F') b'\x00\x00\x02\x00\x01\x00\x03\x00'User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
ndarray.dot
numpy.ndarray.dot
#
method
ndarray.
dot
(
)
## numpy.char.chararray.itemset[#](#numpy-char-chararray-itemset)
method

char.chararray.itemset(**args*)[#](#numpy.char.chararray.itemset)
-
Insert scalar into an array (scalar is cast to array’s dtype, if possible)

There must be at least 1 argument, and define the last argument as

*item*. Then,`a.itemset(*args)`
is equivalent to but faster than`a[args] = item`
. The item should be a scalar value and*args*must select a single item in the array*a*.Parameters:
-
***args**Arguments
If one argument: a scalar, only used in case

*a*is of size 1. If two arguments: the last argument is the value to be set and must be a scalar, the first argument specifies a single array element location. It is either an int or a tuple.
Notes

Compared to indexing syntax,

provides some speed increase for placing a scalar into a particular location in an`itemset`
, if you must do this. However, generally this is discouraged: among other problems, it complicates the appearance of the code. Also, when using`ndarray`
(and`itemset`
) inside a loop, be sure to assign the methods to a local variable to avoid the attribute look-up at each loop iteration.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.itemset(4, 0) >>> x.itemset((2, 2), 9) >>> x array([[2, 2, 6], [1, 0, 6], [1, 0, 9]])# numpy.ma.allclose[#](#numpy-ma-allclose)
ma.allclose(*a*,*b*,*masked_equal=True*,*rtol=1e-05*,*atol=1e-08*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L8096-L8201)[#](#numpy.ma.allclose)
-
Returns True if two arrays are element-wise equal within a tolerance.

This function is equivalent to

except that masked values are treated as equal (default) or unequal, depending on the`allclose`
argument.`masked_equal`
Parameters:
-
**a, b**array_like
Input arrays to compare.

**masked_equal**bool, optional
Whether masked values in

*a*and*b*are considered equal (True) or not (False). They are considered equal by default.
**rtol**float, optional
Relative tolerance. The relative difference is equal to

`rtol * b`
. Default is 1e-5.
**atol**float, optional
Absolute tolerance. The absolute difference is equal to

*atol*. Default is 1e-8.
Returns:
-
**y**bool
Returns True if the two arrays are equal within the given tolerance, False otherwise. If either array contains NaN, then False is returned.

See also

,`all`
`any`
`numpy.allclose`
the non-masked

.`allclose`
Notes

If the following equation is element-wise True, then

returns True:`allclose`
absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))
Return True if all elements of

*a*and*b*are equal subject to given tolerances.Examples

>>> a = np.ma.array([1e10, 1e-7, 42.0], mask=[0, 0, 1]) >>> a masked_array(data=[10000000000.0, 1e-07, --], mask=[False, False, True], fill_value=1e+20) >>> b = np.ma.array([1e10, 1e-8, -42.0], mask=[0, 0, 1]) >>> np.ma.allclose(a, b) False
>>> a = np.ma.array([1e10, 1e-8, 42.0], mask=[0, 0, 1]) >>> b = np.ma.array([1.00001e10, 1e-9, -42.0], mask=[0, 0, 1]) >>> np.ma.allclose(a, b) True >>> np.ma.allclose(a, b, masked_equal=False) False
Masked values are not compared directly.

>>> a = np.ma.array([1e10, 1e-8, 42.0], mask=[0, 0, 1]) >>> b = np.ma.array([1.00001e10, 1e-9, 42.0], mask=[0, 0, 1]) >>> np.ma.allclose(a, b) True >>> np.ma.allclose(a, b, masked_equal=False) False# numpy.matrix.setflags[#](#numpy-matrix-setflags)
method

matrix.setflags(*write=None*,*align=None*,*uic=None*)[#](#numpy.matrix.setflags)
-
Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY, respectively.

These Boolean-valued flags affect how numpy interprets the memory area used by

*a*(see Notes below). The ALIGNED flag can only be set to True if the data is actually aligned according to the type. The WRITEBACKIFCOPY and flag can never be set to True. The flag WRITEABLE can only be set to True if the array owns its own memory, or the ultimate owner of the memory exposes a writeable buffer interface, or is a string. (The exception for string is made so that unpickling can be done without copying memory.)Parameters:
-
**write**bool, optional
Describes whether or not

*a*can be written to.
**align**bool, optional
Describes whether or not

*a*is aligned properly for its type.
**uic**bool, optional
Describes whether or not

*a*is a copy of another “base” array.
Notes

Array flags provide information about how the memory area used for the array is to be interpreted. There are 7 Boolean flags in use, only four of which can be changed by the user: WRITEBACKIFCOPY, WRITEABLE, and ALIGNED.

WRITEABLE (W) the data area can be written to;

ALIGNED (A) the data and strides are aligned appropriately for the hardware (as determined by the compiler);

WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by .base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the base array will be updated with the contents of this array.

All flags can be accessed using the single (upper case) letter as well as the full name.

Examples

>>> y = np.array([[3, 1, 7], ... [2, 0, 0], ... [8, 5, 9]]) >>> y array([[3, 1, 7], [2, 0, 0], [8, 5, 9]]) >>> y.flags C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False >>> y.setflags(write=0, align=0) >>> y.flags C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : False ALIGNED : False WRITEBACKIFCOPY : False >>> y.setflags(uic=1) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: cannot set WRITEBACKIFCOPY flag to Truenumpy.ma.MaskType.var# method ma.MaskType.var()# Scalar method identical to the corresponding array attribute. Please see ndarray.var.numpy.random.Generator.bit_generator# attribute random.Generator.bit_generator# Gets the bit generator instance used by the generator Returns: bit_generatorBitGeneratorThe bit generator instance used by the generatorndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__rrshift__

method

Return value>>self.# numpy.find_common_type[#](#numpy-find-common-type)
numpy.find_common_type(*array_types*,*scalar_types*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numerictypes.py#L598-L689)[#](#numpy.find_common_type)
-
Determine common type following standard coercion rules.

Deprecated since version NumPy: 1.25

This function is deprecated, use

or`numpy.promote_types`
instead. To achieve semantics for the`numpy.result_type`
*scalar_types*argument, useand pass the Python values`numpy.result_type`
*0*,*0.0*, or*0j*. This will give the same results in almost all cases. More information and rare exception can be found in the[NumPy 1.25 release notes](https://numpy.org/devdocs/release/1.25.0-notes.html).Parameters:
-
**array_types**sequence
A list of dtypes or dtype convertible objects representing arrays.

**scalar_types**sequence
A list of dtypes or dtype convertible objects representing scalars.

Returns:
-
**datatype**dtype
The common data type, which is the maximum of

*array_types*ignoring*scalar_types*, unless the maximum of*scalar_types*is of a different kind (). If the kind is not understood, then None is returned.`dtype.kind`
See also

Examples

>>> np.find_common_type([], [np.int64, np.float32, complex]) dtype('complex128') >>> np.find_common_type([np.int64, np.float32], []) dtype('float64')
The standard casting rules ensure that a scalar cannot up-cast an array unless the scalar is of a fundamentally different kind of data (i.e. under a different hierarchy in the data type hierarchy) then the array:

>>> np.find_common_type([np.float32], [np.int64, np.float64]) dtype('float32')
Complex is of a different type, so it up-casts the float in the

*array_types*argument:>>> np.find_common_type([np.float32], [complex]) dtype('complex128')
Type specifier strings are convertible to dtypes and can therefore be used instead of dtypes:

>>> np.find_common_type(['f4', 'f4', 'i4'], ['c8']) dtype('complex128')# numpy.ma.masked_array.var[#](#numpy-ma-masked-array-var)
method

ma.masked_array.var(*axis=None*,*dtype=None*,*out=None*,*ddof=0*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5398-L5459)[#](#numpy.ma.masked_array.var)
-
Compute the variance along the specified axis.

Returns the variance of the array elements, a measure of the spread of a distribution. The variance is computed for the flattened array by default, otherwise over the specified axis.

Parameters:
-
**a**array_like
Array containing numbers whose variance is desired. If

*a*is not an array, a conversion is attempted.
**axis**None or int or tuple of ints, optional
Axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.

New in version 1.7.0.

If this is a tuple of ints, a variance is performed over multiple axes, instead of a single axis or all the axes as before.

**dtype**data-type, optional
Type to use in computing the variance. For arrays of integer type the default is

; for arrays of float types it is the same as the array type.`float64`
**out**ndarray, optional
Alternate output array in which to place the result. It must have the same shape as the expected output, but the type is cast if necessary.

**ddof**int, optional
“Delta Degrees of Freedom”: the divisor used in the calculation is

`N - ddof`
, where`N`
represents the number of elements. By default*ddof*is zero.
**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.

If the default value is passed, then

*keepdims*will not be passed through to themethod of sub-classes of`var`
, however any non-default value will be. If the sub-class’ method does not implement`ndarray`
*keepdims*any exceptions will be raised.
**where**array_like of bool, optional
Elements to include in the variance. See

for details.`reduce`
New in version 1.20.0.

Returns:
-
**variance**ndarray, see dtype parameter above
If

`out=None`
, returns a new array containing the variance; otherwise, a reference to the output array is returned.
Notes

The variance is the average of the squared deviations from the mean, i.e.,

`var = mean(x)`
, where`x = abs(a - a.mean())**2`
.The mean is typically calculated as

`x.sum() / N`
, where`N = len(x)`
. If, however,*ddof*is specified, the divisor`N - ddof`
is used instead. In standard statistical practice,`ddof=1`
provides an unbiased estimator of the variance of a hypothetical infinite population.`ddof=0`
provides a maximum likelihood estimate of the variance for normally distributed variables.Note that for complex numbers, the absolute value is taken before squaring, so that the result is always real and nonnegative.

For floating-point input, the variance is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for

(see example below). Specifying a higher-accuracy accumulator using the`float32`
`dtype`
keyword can alleviate this issue.Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> np.var(a) 1.25 >>> np.var(a, axis=0) array([1., 1.]) >>> np.var(a, axis=1) array([0.25, 0.25])
In single precision, var() can be inaccurate:

>>> a = np.zeros((2, 512*512), dtype=np.float32) >>> a[0, :] = 1.0 >>> a[1, :] = 0.1 >>> np.var(a) 0.20250003
Computing the variance in float64 is more accurate:

>>> np.var(a, dtype=np.float64) 0.20249999932944759 # may vary >>> ((1-0.55)**2 + (0.1-0.55)**2)/2 0.2025
Specifying a where argument:

>>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]]) >>> np.var(a) 6.833333333333333 # may vary >>> np.var(a, where=[[True], [True], [False]]) 4.0# numpy.dtype.num[#](#numpy-dtype-num)
attribute

dtype.num[#](#numpy.dtype.num)
-
A unique number for each of the 21 different built-in types.

These are roughly ordered from least-to-most precision.

Examples

>>> dt = np.dtype(str) >>> dt.num 19
>>> dt = np.dtype(float) >>> dt.num 12# numpy.chararray.transpose[#](#numpy-chararray-transpose)
method

chararray.transpose(**axes*)[#](#numpy.chararray.transpose)
-
Returns a view of the array with axes transposed.

Refer to

for full documentation.`numpy.transpose`
Parameters:
-
**axes**None, tuple of ints, or*n*ints
None or no argument: reverses the order of the axes.

tuple of ints:

*i*in the*j*-th place in the tuple means that the array’s*i*-th axis becomes the transposed array’s*j*-th axis.
*n*ints: same as an n-tuple of the same ints (this form is intended simply as a “convenience” alternative to the tuple form).
Returns:
-
**p**ndarray
View of the array with its axes suitably permuted.

See also

`transpose`
Equivalent function.

`ndarray.T`
Array property returning the array transposed.

`ndarray.reshape`
Give a new shape to an array without changing its data.

Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> a array([[1, 2], [3, 4]]) >>> a.transpose() array([[1, 3], [2, 4]]) >>> a.transpose((1, 0)) array([[1, 3], [2, 4]]) >>> a.transpose(1, 0) array([[1, 3], [2, 4]])
>>> a = np.array([1, 2, 3, 4]) >>> a array([1, 2, 3, 4]) >>> a.transpose() array([1, 2, 3, 4])# numpy.ma.MaskType.dumps[#](#numpy-ma-masktype-dumps)
method

ma.MaskType.dumps()[#](#numpy.ma.MaskType.dumps)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.dumps`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.dumps](numpy.ndarray.dumps.html#numpy.ndarray.dumps).Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# numpy.ma.indices[#](#numpy-ma-indices)
ma.indices(*dimensions*,*dtype=<class 'int'>*,*sparse=False*)*= <numpy.ma.core._convert2ma object>*[#](#numpy.ma.indices)
-
Return an array representing the indices of a grid.

Compute an array where the subarrays contain index values 0, 1, … varying only along the corresponding axis.

Parameters:
-
**dimensions**sequence of ints
The shape of the grid.

**dtype**dtype, optional
Data type of the result.

**sparse**boolean, optional
Return a sparse representation of the grid instead of a dense representation. Default is False.

New in version 1.17.

Returns:
-
**grid**one MaskedArray or tuple of MaskedArrays
If sparse is False:
-
Returns one array of grid indices,

`grid.shape = (len(dimensions),) + tuple(dimensions)`
.
If sparse is True:
-
Returns a tuple of arrays, with

`grid[i].shape = (1, ..., 1, dimensions[i], 1, ..., 1)`
with dimensions[i] in the ith place
Notes

The output shape in the dense case is obtained by prepending the number of dimensions in front of the tuple of dimensions, i.e. if

*dimensions*is a tuple`(r0, ..., rN-1)`
of length`N`
, the output shape is`(N, r0, ..., rN-1)`
.The subarrays

`grid[k]`
contains the N-D array of indices along the`k-th`
axis. Explicitly:grid[k, i0, i1, ..., iN-1] = ik
Examples

>>> grid = np.indices((2, 3)) >>> grid.shape (2, 2, 3) >>> grid[0] # row indices array([[0, 0, 0], [1, 1, 1]]) >>> grid[1] # column indices array([[0, 1, 2], [0, 1, 2]])
The indices can be used as an index into an array.

>>> x = np.arange(20).reshape(5, 4) >>> row, col = np.indices((2, 3)) >>> x[row, col] array([[0, 1, 2], [4, 5, 6]])
Note that it would be more straightforward in the above example to extract the required elements directly with

`x[:2, :3]`
.If sparse is set to true, the grid will be returned in a sparse representation.

>>> i, j = np.indices((2, 3), sparse=True) >>> i.shape (2, 1) >>> j.shape (1, 3) >>> i # row indices array([[0], [1]]) >>> j # column indices array([[0, 1, 2]])Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Using via `meson`
[#](#using-via-meson)
The key advantage gained by leveraging `meson`
over the techniques described
in [Using via numpy.distutils](distutils.html#f2py-distutils) is that this feeds into existing systems and larger
projects with ease. `meson`
has a rather pythonic syntax which makes it more
comfortable and amenable to extension for `python`
users.

Note

Meson needs to be at-least `0.46.0`
in order to resolve the `python`
include directories.

## Fibonacci Walkthrough (F77)[#](#fibonacci-walkthrough-f77)
We will need the generated `C`
wrapper before we can use a general purpose
build system like `meson`
. We will acquire this by:

```
python -m numpy.f2py fib1.f -m fib2
```
Now, consider the following `meson.build`
file for the `fib`
and `scalar`
examples from [Three ways to wrap - getting started](../f2py.getting-started.html#f2py-getting-started) section:

```
project('f2py_examples', 'c',
version : '0.1',
license: 'BSD-3',
meson_version: '>=0.64.0',
default_options : ['warning_level=2'],
)
add_languages('fortran')
py_mod = import('python')
py = py_mod.find_installation(pure: false)
py_dep = py.dependency()
incdir_numpy = run_command(py,
['-c', 'import os; os.chdir(".."); import numpy; print(numpy.get_include())'],
check : true
).stdout().strip()
incdir_f2py = run_command(py,
['-c', 'import os; os.chdir(".."); import numpy.f2py; print(numpy.f2py.get_include())'],
check : true
).stdout().strip()
inc_np = include_directories(incdir_numpy, incdir_f2py)
py.extension_module('fib2',
[
'fib1.f',
'fib2module.c', # note: this assumes f2py was manually run before!
],
incdir_f2py / 'fortranobject.c',
include_directories: inc_np,
dependencies : py_dep,
install : true
)
```
At this point the build will complete, but the import will fail:

```
meson setup builddir
meson compile -C builddir
cd builddir
python -c 'import fib2'
Traceback (most recent call last):
File "<string>", line 1, in <module>
ImportError: fib2.cpython-39-x86_64-linux-gnu.so: undefined symbol: FIB_
# Check this isn't a false positive
nm -A fib2.cpython-39-x86_64-linux-gnu.so | grep FIB_
fib2.cpython-39-x86_64-linux-gnu.so: U FIB_
```
Recall that the original example, as reproduced below, was in SCREAMCASE:

```
C FILE: FIB1.F
SUBROUTINE FIB(A,N)
C
C CALCULATE FIRST N FIBONACCI NUMBERS
C
INTEGER N
REAL*8 A(N)
DO I=1,N
IF (I.EQ.1) THEN
A(I) = 0.0D0
ELSEIF (I.EQ.2) THEN
A(I) = 1.0D0
ELSE
A(I) = A(I-1) + A(I-2)
ENDIF
ENDDO
END
C END FILE FIB1.F
```
With the standard approach, the subroutine exposed to `python`
is `fib`
and
not `FIB`
. This means we have a few options. One approach (where possible) is
to lowercase the original Fortran file with say:

```
tr "[:upper:]" "[:lower:]" < fib1.f > fib1.f
python -m numpy.f2py fib1.f -m fib2
meson --wipe builddir
meson compile -C builddir
cd builddir
python -c 'import fib2'
```
However this requires the ability to modify the source which is not always
possible. The easiest way to solve this is to let `f2py`
deal with it:

```
python -m numpy.f2py fib1.f -m fib2 --lower
meson --wipe builddir
meson compile -C builddir
cd builddir
python -c 'import fib2'
```
### Automating wrapper generation[#](#automating-wrapper-generation)
A major pain point in the workflow defined above, is the manual tracking of
inputs. Although it would require more effort to figure out the actual outputs
for reasons discussed in [F2PY and Build Systems](index.html#f2py-bldsys).

Note

From NumPy `1.22.4`
onwards, `f2py`
will deterministically generate
wrapper files based on the input file Fortran standard (F77 or greater).
`--skip-empty-wrappers`
can be passed to `f2py`
to restore the previous
behaviour of only generating wrappers when needed by the input .

However, we can augment our workflow in a straightforward to take into account files for which the outputs are known when the build system is set up.

```
project('f2py_examples', 'c',
version : '0.1',
license: 'BSD-3',
meson_version: '>=0.64.0',
default_options : ['warning_level=2'],
)
add_languages('fortran')
py_mod = import('python')
py = py_mod.find_installation(pure: false)
py_dep = py.dependency()
incdir_numpy = run_command(py,
['-c', 'import os; os.chdir(".."); import numpy; print(numpy.get_include())'],
check : true
).stdout().strip()
incdir_f2py = run_command(py,
['-c', 'import os; os.chdir(".."); import numpy.f2py; print(numpy.f2py.get_include())'],
check : true
).stdout().strip()
fibby_source = custom_target('fibbymodule.c',
input : ['fib1.f'], # .f so no F90 wrappers
output : ['fibbymodule.c', 'fibby-f2pywrappers.f'],
command : [py, '-m', 'numpy.f2py', '@INPUT@', '-m', 'fibby', '--lower']
)
inc_np = include_directories(incdir_numpy, incdir_f2py)
py.extension_module('fibby',
['fib1.f', fibby_source],
incdir_f2py / 'fortranobject.c',
include_directories: inc_np,
dependencies : py_dep,
install : true
)
```
This can be compiled and run as before.

```
rm -rf builddir
meson setup builddir
meson compile -C builddir
cd builddir
python -c "import numpy as np; import fibby; a = np.zeros(9); fibby.fib(a); print (a)"
# [ 0. 1. 1. 2. 3. 5. 8. 13. 21.]
```
## Salient points[#](#salient-points)
It is worth keeping in mind the following:

`meson`
will default to passing`-fimplicit-none`
under`gfortran`
by default, which differs from that of the standard`np.distutils`
behaviour
It is not possible to use SCREAMCASE in this context, so either the contents of the

`.f`
file or the generated wrapper`.c`
needs to be lowered to regular letters; which can be facilitated by the`--lower`
option of`F2PY`F2PY reference manual# Signature file Signature files syntax Using F2PY bindings in Python Fortran type objects Scalar arguments String arguments Array arguments Call-back arguments Common blocks Fortran 90 module data Allocatable arrays F2PY and Build Systems Basic Concepts Build Systems Advanced F2PY use cases Adding user-defined functions to F2PY generated modules Adding user-defined variables Dealing with KIND specifiers Character strings F2PY test suite Adding a testSearch Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# F2PY and Conda on Windows[#](#f2py-and-conda-on-windows)
As a convenience measure, we will additionally assume the
existence of `scoop`
, which can be used to install tools without
administrative access.

```
Invoke-Expression (New-Object System.Net.WebClient).DownloadString('https://get.scoop.sh')
```
Now we will setup a `conda`
environment.

```
scoop install miniconda3
# For conda activate / deactivate in powershell
conda install -n root -c pscondaenvs pscondaenvs
Powershell -c Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
conda init powershell
# Open a new shell for the rest
```
`conda`
pulls packages from `msys2`
, however, the UX is sufficiently different enough to warrant a separate discussion.
Warning

As of 30-01-2022, the [MSYS2 binaries](https://github.com/conda-forge/conda-forge.github.io/issues/1044) shipped with `conda`
are **outdated** and this approach is **not preferred**.# Using via `scikit-build`
[#](#using-via-scikit-build)
`scikit-build`
provides two separate concepts geared towards the users of Python extension modules.
A

`setuptools`
replacement (legacy behaviour)
A series of

`cmake`
modules with definitions which help building Python extensions
Note

It is possible to use `scikit-build`
’s `cmake`
modules to [bypass the
cmake setup mechanism](https://scikit-build.readthedocs.io/en/latest/cmake-modules/F2PY.html) completely, and to write targets which call ```
f2py
-c
```
. This usage is **not recommended** since the point of these build system
documents are to move away from the internal `numpy.distutils`
methods.

For situations where no `setuptools`
replacements are required or wanted (i.e.
if `wheels`
are not needed), it is recommended to instead use the vanilla
`cmake`
setup described in [Using via cmake](cmake.html#f2py-cmake).

## Fibonacci Walkthrough (F77)[#](#fibonacci-walkthrough-f77)
We will consider the `fib`
example from [Three ways to wrap - getting started](../f2py.getting-started.html#f2py-getting-started) section.

```
C FILE: FIB1.F
SUBROUTINE FIB(A,N)
C
C CALCULATE FIRST N FIBONACCI NUMBERS
C
INTEGER N
REAL*8 A(N)
DO I=1,N
IF (I.EQ.1) THEN
A(I) = 0.0D0
ELSEIF (I.EQ.2) THEN
A(I) = 1.0D0
ELSE
A(I) = A(I-1) + A(I-2)
ENDIF
ENDDO
END
C END FILE FIB1.F
```
`CMake`
modules only[#](#cmake-modules-only)
Consider using the following `CMakeLists.txt`
.

```
### setup project ###
cmake_minimum_required(VERSION 3.9)
project(fibby
VERSION 1.0
DESCRIPTION "FIB module"
LANGUAGES C Fortran
)
# Safety net
if(PROJECT_SOURCE_DIR STREQUAL PROJECT_BINARY_DIR)
message(
FATAL_ERROR
"In-source builds not allowed. Please make a new directory (called a build directory) and run CMake from there.\n"
)
endif()
# Ensure scikit-build modules
if (NOT SKBUILD)
find_package(PythonInterp 3.8 REQUIRED)
# Kanged --> https://github.com/Kitware/torch_liberator/blob/master/CMakeLists.txt
# If skbuild is not the driver; include its utilities in CMAKE_MODULE_PATH
execute_process(
COMMAND "${PYTHON_EXECUTABLE}"
-c "import os, skbuild; print(os.path.dirname(skbuild.__file__))"
OUTPUT_VARIABLE SKBLD_DIR
OUTPUT_STRIP_TRAILING_WHITESPACE
)
list(APPEND CMAKE_MODULE_PATH "${SKBLD_DIR}/resources/cmake")
message(STATUS "Looking in ${SKBLD_DIR}/resources/cmake for CMake modules")
endif()
# scikit-build style includes
find_package(PythonExtensions REQUIRED) # for ${PYTHON_EXTENSION_MODULE_SUFFIX}
# Grab the variables from a local Python installation
# NumPy headers
execute_process(
COMMAND "${PYTHON_EXECUTABLE}"
-c "import numpy; print(numpy.get_include())"
OUTPUT_VARIABLE NumPy_INCLUDE_DIRS
OUTPUT_STRIP_TRAILING_WHITESPACE
)
# F2PY headers
execute_process(
COMMAND "${PYTHON_EXECUTABLE}"
-c "import numpy.f2py; print(numpy.f2py.get_include())"
OUTPUT_VARIABLE F2PY_INCLUDE_DIR
OUTPUT_STRIP_TRAILING_WHITESPACE
)
# Prepping the module
set(f2py_module_name "fibby")
set(fortran_src_file "${CMAKE_SOURCE_DIR}/fib1.f")
set(f2py_module_c "${f2py_module_name}module.c")
# Target for enforcing dependencies
add_custom_target(genpyf
DEPENDS "${fortran_src_file}"
)
add_custom_command(
OUTPUT "${CMAKE_CURRENT_BINARY_DIR}/${f2py_module_c}"
COMMAND ${PYTHON_EXECUTABLE} -m "numpy.f2py"
"${fortran_src_file}"
-m "fibby"
--lower # Important
DEPENDS fib1.f # Fortran source
)
add_library(${CMAKE_PROJECT_NAME} MODULE
"${f2py_module_name}module.c"
"${F2PY_INCLUDE_DIR}/fortranobject.c"
"${fortran_src_file}")
target_include_directories(${CMAKE_PROJECT_NAME} PUBLIC
${F2PY_INCLUDE_DIR}
${NumPy_INCLUDE_DIRS}
${PYTHON_INCLUDE_DIRS})
set_target_properties(${CMAKE_PROJECT_NAME} PROPERTIES SUFFIX "${PYTHON_EXTENSION_MODULE_SUFFIX}")
set_target_properties(${CMAKE_PROJECT_NAME} PROPERTIES PREFIX "")
# Linker fixes
if (UNIX)
if (APPLE)
set_target_properties(${CMAKE_PROJECT_NAME} PROPERTIES
LINK_FLAGS '-Wl,-dylib,-undefined,dynamic_lookup')
else()
set_target_properties(${CMAKE_PROJECT_NAME} PROPERTIES
LINK_FLAGS '-Wl,--allow-shlib-undefined')
endif()
endif()
add_dependencies(${CMAKE_PROJECT_NAME} genpyf)
install(TARGETS ${CMAKE_PROJECT_NAME} DESTINATION fibby)
```
Much of the logic is the same as in [Using via cmake](cmake.html#f2py-cmake), however notably here the
appropriate module suffix is generated via `sysconfig.get_config_var("SO")`
.
The resulting extension can be built and loaded in the standard workflow.

```
ls .
# CMakeLists.txt fib1.f
cmake -S . -B build
cmake --build build
cd build
python -c "import numpy as np; import fibby; a = np.zeros(9); fibby.fib(a); print (a)"
# [ 0. 1. 1. 2. 3. 5. 8. 13. 21.]
```
`setuptools`
replacement[#](#setuptools-replacement)
Note

**As of November 2021**
The behavior described here of driving the `cmake`
build of a module is
considered to be legacy behaviour and should not be depended on.

The utility of `scikit-build`
lies in being able to drive the generation of
more than extension modules, in particular a common usage pattern is the
generation of Python distributables (for example for PyPI).

The workflow with `scikit-build`
straightforwardly supports such packaging requirements. Consider augmenting the project with a `setup.py`
as defined:

```
from skbuild import setup
setup(
name="fibby",
version="0.0.1",
description="a minimal example package (fortran version)",
license="MIT",
packages=['fibby'],
python_requires=">=3.7",
)
```
Along with a commensurate `pyproject.toml`

```
[build-system]
requires = ["setuptools>=42", "wheel", "scikit-build", "cmake>=3.9", "numpy>=1.21"]
build-backend = "setuptools.build_meta"
```
Together these can build the extension using `cmake`
in tandem with other
standard `setuptools`
outputs. Running `cmake`
through `setup.py`
is
mostly used when it is necessary to integrate with extension modules not built
with `cmake`
.

```
ls .
# CMakeLists.txt fib1.f pyproject.toml setup.py
python setup.py build_ext --inplace
python -c "import numpy as np; import fibby.fibby; a = np.zeros(9); fibby.fibby.fib(a); print (a)"
# [ 0. 1. 1. 2. 3. 5. 8. 13. 21.]
```
Where we have modified the path to the module as `--inplace`
places the
extension module in a subfolder.# Using via `cmake`
[#](#using-via-cmake)
In terms of complexity, `cmake`
falls between `make`
and `meson`
. The
learning curve is steeper since CMake syntax is not pythonic and is closer to
`make`
with environment variables.

However, the trade-off is enhanced flexibility and support for most architectures
and compilers. An introduction to the syntax is out of scope for this document,
but this [extensive CMake collection](https://cliutils.gitlab.io/modern-cmake/) of resources is great.

Note

`cmake`
is very popular for mixed-language systems, however support for
`f2py`
is not particularly native or pleasant; and a more natural approach
is to consider [Using via scikit-build](skbuild.html#f2py-skbuild)
## Fibonacci walkthrough (F77)[#](#fibonacci-walkthrough-f77)
Returning to the `fib`
example from [Three ways to wrap - getting started](../f2py.getting-started.html#f2py-getting-started) section.

```
C FILE: FIB1.F
SUBROUTINE FIB(A,N)
C
C CALCULATE FIRST N FIBONACCI NUMBERS
C
INTEGER N
REAL*8 A(N)
DO I=1,N
IF (I.EQ.1) THEN
A(I) = 0.0D0
ELSEIF (I.EQ.2) THEN
A(I) = 1.0D0
ELSE
A(I) = A(I-1) + A(I-2)
ENDIF
ENDDO
END
C END FILE FIB1.F
```
We do not need to explicitly generate the `python -m numpy.f2py fib1.f`
output, which is `fib1module.c`
, which is beneficial. With this; we can now
initialize a `CMakeLists.txt`
file as follows:

```
cmake_minimum_required(VERSION 3.18) # Needed to avoid requiring embedded Python libs too
project(fibby
VERSION 1.0
DESCRIPTION "FIB module"
LANGUAGES C Fortran
)
# Safety net
if(PROJECT_SOURCE_DIR STREQUAL PROJECT_BINARY_DIR)
message(
FATAL_ERROR
"In-source builds not allowed. Please make a new directory (called a build directory) and run CMake from there.\n"
)
endif()
# Grab Python, 3.8 or newer
find_package(Python 3.8 REQUIRED
COMPONENTS Interpreter Development.Module NumPy)
# Grab the variables from a local Python installation
# F2PY headers
execute_process(
COMMAND "${Python_EXECUTABLE}"
-c "import numpy.f2py; print(numpy.f2py.get_include())"
OUTPUT_VARIABLE F2PY_INCLUDE_DIR
OUTPUT_STRIP_TRAILING_WHITESPACE
)
# Print out the discovered paths
include(CMakePrintHelpers)
cmake_print_variables(Python_INCLUDE_DIRS)
cmake_print_variables(F2PY_INCLUDE_DIR)
cmake_print_variables(Python_NumPy_INCLUDE_DIRS)
# Common variables
set(f2py_module_name "fibby")
set(fortran_src_file "${CMAKE_SOURCE_DIR}/fib1.f")
set(f2py_module_c "${f2py_module_name}module.c")
# Generate sources
add_custom_target(
genpyf
DEPENDS "${CMAKE_CURRENT_BINARY_DIR}/${f2py_module_c}"
)
add_custom_command(
OUTPUT "${CMAKE_CURRENT_BINARY_DIR}/${f2py_module_c}"
COMMAND ${Python_EXECUTABLE} -m "numpy.f2py"
"${fortran_src_file}"
-m "fibby"
--lower # Important
DEPENDS fib1.f # Fortran source
)
# Set up target
Python_add_library(${CMAKE_PROJECT_NAME} MODULE WITH_SOABI
"${CMAKE_CURRENT_BINARY_DIR}/${f2py_module_c}" # Generated
"${F2PY_INCLUDE_DIR}/fortranobject.c" # From NumPy
"${fortran_src_file}" # Fortran source(s)
)
# Depend on sources
target_link_libraries(${CMAKE_PROJECT_NAME} PRIVATE Python::NumPy)
add_dependencies(${CMAKE_PROJECT_NAME} genpyf)
target_include_directories(${CMAKE_PROJECT_NAME} PRIVATE "${F2PY_INCLUDE_DIR}")
```
A key element of the `CMakeLists.txt`
file defined above is that the
`add_custom_command`
is used to generate the wrapper `C`
files and then
added as a dependency of the actual shared library target via a
`add_custom_target`
directive which prevents the command from running every
time. Additionally, the method used for obtaining the `fortranobject.c`
file
can also be used to grab the `numpy`
headers on older `cmake`
versions.

This then works in the same manner as the other modules, although the naming
conventions are different and the output library is not automatically prefixed
with the `cython`
information.

```
ls .
# CMakeLists.txt fib1.f
cmake -S . -B build
cmake --build build
cd build
python -c "import numpy as np; import fibby; a = np.zeros(9); fibby.fib(a); print (a)"
# [ 0. 1. 1. 2. 3. 5. 8. 13. 21.]
```
This is particularly useful where an existing toolchain already exists and
`scikit-build`
or other additional `python`
dependencies are discouraged.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Verifying bugs and bug fixes in NumPy[#](#verifying-bugs-and-bug-fixes-in-numpy)
In this how-to you will learn how to:

Verify the existence of a bug in NumPy

Verify the fix, if any, made for the bug

While you walk through the verification process, you will learn how to:

Set up a Python virtual environment (using

`virtualenv`
)
Install appropriate versions of NumPy, first to see the bug in action, then to verify its fix

[Issue 16354](https://github.com/numpy/numpy/issues/16354) is used as an
example.
This issue was:


Title:np.polymul return type is np.float64 or np.complex128 when given an all-zero argument

np.polymul returns an object with type np.float64 when one argument is all zero, and both arguments have type np.int64 or np.float32. Something similar happens with all zero np.complex64 giving result type np.complex128.

This doesn’t happen with non-zero arguments; there the result is as expected.

This bug isn’t present in np.convolve.

Reproducing code example:>>> import numpy as np >>> np.__version__ '1.18.4' >>> a = np.array([1,2,3]) >>> z = np.array([0,0,0]) >>> np.polymul(a.astype(np.int64), a.astype(np.int64)).dtype dtype('int64') >>> np.polymul(a.astype(np.int64), z.astype(np.int64)).dtype dtype('float64') >>> np.polymul(a.astype(np.float32), z.astype(np.float32)).dtype dtype('float64') >>> np.polymul(a.astype(np.complex64), z.astype(np.complex64)).dtype dtype('complex128') Numpy/Python version information: >>> import sys, numpy; print(numpy.__version__, sys.version) 1.18.4 3.7.5 (default, Nov 7 2019, 10:50:52) [GCC 8.3.0]
## 1. Set up a virtual environment[#](#set-up-a-virtual-environment)
Create a new directory, enter into it, and set up a virtual environment using
your preferred method. For example, this is how to do it using
`virtualenv`
on linux or macOS:

```
virtualenv venv_np_bug
source venv_np_bug/bin/activate
```
This ensures the system/global/default Python/NumPy installation will not be altered.

## 2. Install the NumPy version in which the bug was reported[#](#install-the-numpy-version-in-which-the-bug-was-reported)
The report references NumPy version 1.18.4, so that is the version you need to install in this case.

Since this bug is tied to a release and not a specific commit, a pre-built wheel
installed in your virtual environment via `pip`
will suffice:

```
pip install numpy==1.18.4
```
Some bugs may require you to build the NumPy version referenced in the issue
report. To learn how to do that, visit
[Building from source](building.html#building-from-source).

## 1. Reproduce the bug[#](#reproduce-the-bug)
The issue reported in [#16354](https://github.com/numpy/numpy/issues/16354) is
that the wrong `dtype`
is returned if one of the inputs of the method
[ numpy.polymul](../reference/generated/numpy.polymul.html#numpy.polymul) is a zero array.

To reproduce the bug, start a Python terminal, enter the code snippet shown in the bug report, and ensure that the results match those in the issue:

```
>>> import numpy as np
>>> np.__version__
'...' # 1.18.4
>>> a = np.array([1,2,3])
>>> z = np.array([0,0,0])
>>> np.polymul(a.astype(np.int64), a.astype(np.int64)).dtype
dtype('int64')
>>> np.polymul(a.astype(np.int64), z.astype(np.int64)).dtype
dtype('...') # float64
>>> np.polymul(a.astype(np.float32), z.astype(np.float32)).dtype
dtype('...') # float64
>>> np.polymul(a.astype(np.complex64), z.astype(np.complex64)).dtype
dtype('...') # complex128
```
As reported, whenever the zero array, `z`
in the example above, is one of the
arguments to [ numpy.polymul](../reference/generated/numpy.polymul.html#numpy.polymul), an incorrect

`dtype`
is returned.## 4. Check for fixes in the latest version of NumPy[#](#check-for-fixes-in-the-latest-version-of-numpy)
If the issue report for your bug has not yet been resolved, further action or patches need to be submitted.

In this case, however, the issue was resolved by
[PR 17577](https://github.com/numpy/numpy/pull/17577) and is now closed. So
you can try to verify the fix.

To verify the fix:

Uninstall the version of NumPy in which the bug still exists:

pip uninstall numpy
Install the latest version of NumPy:

pip install numpy
In your Python terminal, run the reported code snippet you used to verify the existence of the bug and confirm that the issue has been resolved:

>>> import numpy as np >>> np.__version__ '...' # 1.18.4 >>> a = np.array([1,2,3]) >>> z = np.array([0,0,0]) >>> np.polymul(a.astype(np.int64), a.astype(np.int64)).dtype dtype('int64') >>> np.polymul(a.astype(np.int64), z.astype(np.int64)).dtype dtype('int64') >>> np.polymul(a.astype(np.float32), z.astype(np.float32)).dtype dtype('float32') >>> np.polymul(a.astype(np.complex64), z.astype(np.complex64)).dtype dtype('complex64')
Note that the correct `dtype`
is now returned even when a zero array is one of
the arguments to [ numpy.polymul](../reference/generated/numpy.polymul.html#numpy.polymul).

## 5. Support NumPy development by verifying and fixing bugs[#](#support-numpy-development-by-verifying-and-fixing-bugs)
Go to the [NumPy GitHub issues page](https://github.com/numpy/numpy/issues)
and see if you can confirm the existence of any other bugs which have not been
confirmed yet. In particular, it is useful for the developers to know if a bug
can be reproduced on a newer version of NumPy.

Comments verifying the existence of bugs alert the NumPy developers that more than one user can reproduce the issue.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Memory Alignment
#
This document has been moved to
Memory alignment
.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Writing custom array containers[#](#writing-custom-array-containers)
Numpy’s dispatch mechanism, introduced in numpy version v1.16 is the
recommended approach for writing custom N-dimensional array containers that are
compatible with the numpy API and provide custom implementations of numpy
functionality. Applications include [dask](http://dask.pydata.org) arrays, an
N-dimensional array distributed across multiple nodes, and [cupy](https://docs-cupy.chainer.org/en/stable/) arrays, an N-dimensional array on
a GPU.

To get a feel for writing custom array containers, we’ll begin with a simple example that has rather narrow utility but illustrates the concepts involved.

```
>>> import numpy as np
>>> class DiagonalArray:
... def __init__(self, N, value):
... self._N = N
... self._i = value
... def __repr__(self):
... return f"{self.__class__.__name__}(N={self._N}, value={self._i})"
... def __array__(self, dtype=None):
... return self._i * np.eye(self._N, dtype=dtype)
```
Our custom array can be instantiated like:

```
>>> arr = DiagonalArray(5, 1)
>>> arr
DiagonalArray(N=5, value=1)
```
We can convert to a numpy array using [ numpy.array](../reference/generated/numpy.array.html#numpy.array) or

[, which will call its](../reference/generated/numpy.asarray.html#numpy.asarray)
`numpy.asarray`
`__array__`
method to obtain a
standard `numpy.ndarray`
.```
>>> np.asarray(arr)
array([[1., 0., 0., 0., 0.],
[0., 1., 0., 0., 0.],
[0., 0., 1., 0., 0.],
[0., 0., 0., 1., 0.],
[0., 0., 0., 0., 1.]])
```
If we operate on `arr`
with a numpy function, numpy will again use the
`__array__`
interface to convert it to an array and then apply the function
in the usual way.

```
>>> np.multiply(arr, 2)
array([[2., 0., 0., 0., 0.],
[0., 2., 0., 0., 0.],
[0., 0., 2., 0., 0.],
[0., 0., 0., 2., 0.],
[0., 0., 0., 0., 2.]])
```
Notice that the return type is a standard `numpy.ndarray`
.

```
>>> type(np.multiply(arr, 2))
<class 'numpy.ndarray'>
```
How can we pass our custom array type through this function? Numpy allows a
class to indicate that it would like to handle computations in a custom-defined
way through the interfaces `__array_ufunc__`
and `__array_function__`
. Let’s
take one at a time, starting with `__array_ufunc__`
. This method covers
[Universal functions (ufunc)](../reference/ufuncs.html#ufuncs), a class of functions that includes, for example,
[ numpy.multiply](../reference/generated/numpy.multiply.html#numpy.multiply) and

[.](../reference/generated/numpy.sin.html#numpy.sin)
`numpy.sin`
The `__array_ufunc__`
receives:

`ufunc`
, a function like`numpy.multiply`
`method`
, a string, differentiating between`numpy.multiply(...)`
and variants like`numpy.multiply.outer`
,`numpy.multiply.accumulate`
, and so on. For the common case,`numpy.multiply(...)`
,`method == '__call__'`
.
`inputs`
, which could be a mixture of different types
`kwargs`
, keyword arguments passed to the function
For this example we will only handle the method `__call__`

```
>>> from numbers import Number
>>> class DiagonalArray:
... def __init__(self, N, value):
... self._N = N
... self._i = value
... def __repr__(self):
... return f"{self.__class__.__name__}(N={self._N}, value={self._i})"
... def __array__(self, dtype=None):
... return self._i * np.eye(self._N, dtype=dtype)
... def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):
... if method == '__call__':
... N = None
... scalars = []
... for input in inputs:
... if isinstance(input, Number):
... scalars.append(input)
... elif isinstance(input, self.__class__):
... scalars.append(input._i)
... if N is not None:
... if N != self._N:
... raise TypeError("inconsistent sizes")
... else:
... N = self._N
... else:
... return NotImplemented
... return self.__class__(N, ufunc(*scalars, **kwargs))
... else:
... return NotImplemented
```
Now our custom array type passes through numpy functions.

```
>>> arr = DiagonalArray(5, 1)
>>> np.multiply(arr, 3)
DiagonalArray(N=5, value=3)
>>> np.add(arr, 3)
DiagonalArray(N=5, value=4)
>>> np.sin(arr)
DiagonalArray(N=5, value=0.8414709848078965)
```
At this point `arr + 3`
does not work.

```
>>> arr + 3
Traceback (most recent call last):
...
TypeError: unsupported operand type(s) for +: 'DiagonalArray' and 'int'
```
To support it, we need to define the Python interfaces `__add__`
, `__lt__`
,
and so on to dispatch to the corresponding ufunc. We can achieve this
conveniently by inheriting from the mixin
[ NDArrayOperatorsMixin](../reference/generated/numpy.lib.mixins.NDArrayOperatorsMixin.html#numpy.lib.mixins.NDArrayOperatorsMixin).

```
>>> import numpy.lib.mixins
>>> class DiagonalArray(numpy.lib.mixins.NDArrayOperatorsMixin):
... def __init__(self, N, value):
... self._N = N
... self._i = value
... def __repr__(self):
... return f"{self.__class__.__name__}(N={self._N}, value={self._i})"
... def __array__(self, dtype=None):
... return self._i * np.eye(self._N, dtype=dtype)
... def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):
... if method == '__call__':
... N = None
... scalars = []
... for input in inputs:
... if isinstance(input, Number):
... scalars.append(input)
... elif isinstance(input, self.__class__):
... scalars.append(input._i)
... if N is not None:
... if N != self._N:
... raise TypeError("inconsistent sizes")
... else:
... N = self._N
... else:
... return NotImplemented
... return self.__class__(N, ufunc(*scalars, **kwargs))
... else:
... return NotImplemented
```
```
>>> arr = DiagonalArray(5, 1)
>>> arr + 3
DiagonalArray(N=5, value=4)
>>> arr > 0
DiagonalArray(N=5, value=True)
```
Now let’s tackle `__array_function__`
. We’ll create dict that maps numpy
functions to our custom variants.

```
>>> HANDLED_FUNCTIONS = {}
>>> class DiagonalArray(numpy.lib.mixins.NDArrayOperatorsMixin):
... def __init__(self, N, value):
... self._N = N
... self._i = value
... def __repr__(self):
... return f"{self.__class__.__name__}(N={self._N}, value={self._i})"
... def __array__(self, dtype=None):
... return self._i * np.eye(self._N, dtype=dtype)
... def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):
... if method == '__call__':
... N = None
... scalars = []
... for input in inputs:
... # In this case we accept only scalar numbers or DiagonalArrays.
... if isinstance(input, Number):
... scalars.append(input)
... elif isinstance(input, self.__class__):
... scalars.append(input._i)
... if N is not None:
... if N != self._N:
... raise TypeError("inconsistent sizes")
... else:
... N = self._N
... else:
... return NotImplemented
... return self.__class__(N, ufunc(*scalars, **kwargs))
... else:
... return NotImplemented
... def __array_function__(self, func, types, args, kwargs):
... if func not in HANDLED_FUNCTIONS:
... return NotImplemented
... # Note: this allows subclasses that don't override
... # __array_function__ to handle DiagonalArray objects.
... if not all(issubclass(t, self.__class__) for t in types):
... return NotImplemented
... return HANDLED_FUNCTIONS[func](*args, **kwargs)
...
```
A convenient pattern is to define a decorator `implements`
that can be used
to add functions to `HANDLED_FUNCTIONS`
.

```
>>> def implements(np_function):
... "Register an __array_function__ implementation for DiagonalArray objects."
... def decorator(func):
... HANDLED_FUNCTIONS[np_function] = func
... return func
... return decorator
...
```
Now we write implementations of numpy functions for `DiagonalArray`
.
For completeness, to support the usage `arr.sum()`
add a method `sum`
that
calls `numpy.sum(self)`
, and the same for `mean`
.

```
>>> @implements(np.sum)
... def sum(arr):
... "Implementation of np.sum for DiagonalArray objects"
... return arr._i * arr._N
...
>>> @implements(np.mean)
... def mean(arr):
... "Implementation of np.mean for DiagonalArray objects"
... return arr._i / arr._N
...
>>> arr = DiagonalArray(5, 1)
>>> np.sum(arr)
5
>>> np.mean(arr)
0.2
```
If the user tries to use any numpy functions not included in
`HANDLED_FUNCTIONS`
, a `TypeError`
will be raised by numpy, indicating that
this operation is not supported. For example, concatenating two
`DiagonalArrays`
does not produce another diagonal array, so it is not
supported.

```
>>> np.concatenate([arr, arr])
Traceback (most recent call last):
...
TypeError: no implementation found for 'numpy.concatenate' on types that implement __array_function__: [<class '__main__.DiagonalArray'>]
```
Additionally, our implementations of `sum`
and `mean`
do not accept the
optional arguments that numpy’s implementation does.

```
>>> np.sum(arr, axis=0)
Traceback (most recent call last):
...
TypeError: sum() got an unexpected keyword argument 'axis'
```
The user always has the option of converting to a normal `numpy.ndarray`
with
[ numpy.asarray](../reference/generated/numpy.asarray.html#numpy.asarray) and using standard numpy from there.

```
>>> np.concatenate([np.asarray(arr), np.asarray(arr)])
array([[1., 0., 0., 0., 0.],
[0., 1., 0., 0., 0.],
[0., 0., 1., 0., 0.],
[0., 0., 0., 1., 0.],
[0., 0., 0., 0., 1.],
[1., 0., 0., 0., 0.],
[0., 1., 0., 0., 0.],
[0., 0., 1., 0., 0.],
[0., 0., 0., 1., 0.],
[0., 0., 0., 0., 1.]])
```
The implementation of `DiagonalArray`
in this example only handles the
`np.sum`
and `np.mean`
functions for brevity. Many other functions in the
Numpy API are also available to wrap and a full-fledged custom array container
can explicitly support all functions that Numpy makes available to wrap.

Numpy provides some utilities to aid testing of custom array containers that
implement the `__array_ufunc__`
and `__array_function__`
protocols in the
`numpy.testing.overrides`
namespace.

To check if a Numpy function can be overridden via `__array_ufunc__`
, you can
use [ allows_array_ufunc_override](../reference/generated/numpy.testing.overrides.allows_array_ufunc_override.html#numpy.testing.overrides.allows_array_ufunc_override):

```
>>> from np.testing.overrides import allows_array_ufunc_override
>>> allows_array_ufunc_override(np.add)
True
```
Similarly, you can check if a function can be overridden via
`__array_function__`
using
[ allows_array_function_override](../reference/generated/numpy.testing.overrides.allows_array_function_override.html#numpy.testing.overrides.allows_array_function_override).

Lists of every overridable function in the Numpy API are also available via
[ get_overridable_numpy_array_functions](../reference/generated/numpy.testing.overrides.get_overridable_numpy_array_functions.html#numpy.testing.overrides.get_overridable_numpy_array_functions) for
functions that support the

`__array_function__`
protocol and
[for functions that support the](../reference/generated/numpy.testing.overrides.get_overridable_numpy_ufuncs.html#numpy.testing.overrides.get_overridable_numpy_ufuncs)
`get_overridable_numpy_ufuncs`
`__array_ufunc__`
protocol. Both functions return sets of
functions that are present in the Numpy public API. User-defined ufuncs or
ufuncs defined in other libraries that depend on Numpy are not present in
these sets.Refer to the [dask source code](https://github.com/dask/dask) and
[cupy source code](https://github.com/cupy/cupy) for more fully-worked
examples of custom array containers.

See also [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html).Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Troubleshooting[#](#troubleshooting)
Note

Since this information may be updated regularly, please ensure you are
viewing the most [up-to-date version](https://numpy.org/devdocs/user/troubleshooting-importerror.html).

## ImportError[#](#importerror)
In certain cases a failed installation or setup issue can cause you to see the following error message:

```
IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!
Importing the numpy c-extensions failed. This error can happen for
different reasons, often due to issues with your setup.
```
The error also has additional information to help you troubleshoot:

Your Python version

Your NumPy version

Please check both of these carefully to see if they are what you expect.
You may need to check your `PATH`
or `PYTHONPATH`
environment variables
(see [Check Environment Variables](#check-environment-variables) below).

The following sections list commonly reported issues depending on your setup. If you have an issue/solution that you think should appear please open a NumPy issue so that it will be added.

There are a few commonly reported issues depending on your system/setup. If none of the following tips help you, please be sure to note the following:

how you installed Python

how you installed NumPy

your operating system

whether or not you have multiple versions of Python installed

if you built from source, your compiler versions and ideally a build log

when investigating further and asking for support.

### Using Python from `conda`
(Anaconda)[#](#using-python-from-conda-anaconda)
Please make sure that you have activated your conda environment.
See also the [conda user-guide](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#activating-an-environment).
If you use an external editor/development environment it will have to be set
up correctly. See below for solutions for some common setups.

### Using PyCharm with Anaconda/conda Python[#](#using-pycharm-with-anaconda-conda-python)
There are fairly common issues when using PyCharm together with Anaconda,
please see the [PyCharm support](https://www.jetbrains.com/help/pycharm/conda-support-creating-conda-virtual-environment.html)

### Using VSCode with Anaconda/conda Python (or environments)[#](#using-vscode-with-anaconda-conda-python-or-environments)
A commonly reported issue is related to the environment activation within
VSCode. Please see the [VSCode support](https://code.visualstudio.com/docs/python/environments)
for information on how to correctly set up VSCode with virtual environments
or conda.

### Using Eclipse/PyDev with Anaconda/conda Python (or environments)[#](#using-eclipse-pydev-with-anaconda-conda-python-or-environments)
Please see the
[Anaconda Documentation](https://docs.anaconda.com/anaconda/user-guide/tasks/integration/eclipse-pydev/)
on how to properly configure Eclipse/PyDev to use Anaconda Python with specific
conda environments.

### Raspberry Pi[#](#raspberry-pi)
There are sometimes issues reported on Raspberry Pi setups when installing
using `pip3 install`
(or `pip`
install). These will typically mention:

```
libf77blas.so.3: cannot open shared object file: No such file or directory
```
The solution will be to either:

```
sudo apt-get install libatlas-base-dev
```
to install the missing libraries expected by the self-compiled NumPy (ATLAS is a possible provider of linear algebra).

*Alternatively* use the NumPy provided by Raspbian. In which case run:
```
pip3 uninstall numpy # remove previously installed version
apt install python3-numpy
```
### Debug build on Windows[#](#debug-build-on-windows)
Rather than building your project in `DEBUG`
mode on windows, try
building in `RELEASE`
mode with debug symbols and no optimization.
Full `DEBUG`
mode on windows changes the names of the DLLs python
expects to find, so if you wish to truly work in `DEBUG`
mode you will
need to recompile the entire stack of python modules you work with
including NumPy

### All Setups[#](#all-setups)
Occasionally there may be simple issues with old or bad installations of NumPy. In this case you may just try to uninstall and reinstall NumPy. Make sure that NumPy is not found after uninstalling.

### Development Setup[#](#development-setup)
If you are using a development setup, make sure to run `git clean -xdf`
to delete all files not under version control (be careful not to lose
any modifications you made, e.g. `site.cfg`
).
In many cases files from old builds may lead to incorrect builds.

### Check Environment Variables[#](#check-environment-variables)
In general how to set and check your environment variables depends on your system. If you can open a correct python shell, you can also run the following in python:

```
import os
print("PYTHONPATH:", os.environ.get('PYTHONPATH'))
print("PATH:", os.environ.get('PATH'))
```
This may mainly help you if you are not running the python and/or NumPy version you are expecting to run.

### C-API incompatibility[#](#c-api-incompatibility)
If you see an error like:

RuntimeError: module compiled against API version v1 but this version of numpy is v2

You may have:

A bad extension “wheel” (binary install) that should use

[oldest-support-numpy](https://pypi.org/project/oldest-supported-numpy/)( with manual constraints if necessary) to build their binary packages.
An environment issue messing with package versions.

Incompatible package versions somehow enforced manually.

An extension module compiled locally against a very recent version followed by a NumPy downgrade.

A compiled extension copied to a different computer with an older NumPy version.

The best thing to do if you see this error is to contact the maintainers of the package that is causing problem so that they can solve the problem properly.

However, while you wait for a solution, a work around that usually works is to upgrade the NumPy version:

```
pip install numpy --upgrade
```
## Segfaults or crashes[#](#segfaults-or-crashes)
NumPy tries to use advanced CPU features (SIMD) to speed up operations. If you are getting an “illegal instruction” error or a segfault, one cause could be that the environment claims it can support one or more of these features but actually cannot. This can happen inside a docker image or a VM (qemu, VMWare, …)

You can use the output of `np.show_runtime()`
to show which SIMD features are
detected. For instance:

```
>>> np.show_runtime()
WARNING: `threadpoolctl` not found in system! Install it by `pip install \
threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed
build information
[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
'found': ['SSSE3',
'SSE41',
'POPCNT',
'SSE42',
'AVX',
'F16C',
'FMA3',
'AVX2'],
'not_found': ['AVX512F',
'AVX512CD',
'AVX512_KNL',
'AVX512_KNM',
'AVX512_SKX',
'AVX512_CLX',
'AVX512_CNL',
'AVX512_ICL']}}]
```
In this case, it shows AVX2 and FMA3 under the `found`
section, so you can
try disabling them by setting `NPY_DISABLE_CPU_FEATURES="AVX2,FMA3"`
in your
environment before running python (for cmd.exe on windows):

```
>SET NPY_DISABLE_CPU_FEATURES="AVX2,FMA3"
>python <myprogram.py>
```
By installing threadpoolctl `np.show_runtime()`
will show additional information:

```
...
{'architecture': 'Zen',
'filepath': '/tmp/venv3/lib/python3.9/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',
'internal_api': 'openblas',
'num_threads': 24,
'prefix': 'libopenblas',
'threading_layer': 'pthreads',
'user_api': 'blas',
'version': '0.3.21'}]
```
If you use the wheel from PyPI, it contains code from the OpenBLAS project to
speed up matrix operations. This code too can try to use SIMD instructions. It
has a different mechanism for choosing which to use, based on a CPU
architecture, You can override this architecture by setting
`OPENBLAS_CORETYPE`
: a minimal value for `x86_64`
is
`OPENBLAS_CORETYPE=Haswell`
. This too needs to be set before running your
python (this time for posix):

```
$ OPENBLAS_CORETYPE=Haswell python <myprogram.py>
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Memory alignment[#](#memory-alignment)
## NumPy alignment goals[#](#numpy-alignment-goals)
There are three use-cases related to memory alignment in NumPy (as of 1.14):

-
Creating

[structured datatypes]with[fields]aligned like in a C-struct.
-
Speeding up copy operations by using

[assignment in instead of]`uint`
`memcpy`
.
-
Guaranteeing safe aligned access for ufuncs/setitem/casting code.

NumPy uses two different forms of alignment to achieve these goals: “True alignment” and “Uint alignment”.

“True” alignment refers to the architecture-dependent alignment of an
equivalent C-type in C. For example, in x64 systems [ float64](../reference/arrays.scalars.html#numpy.float64) is
equivalent to

`double`
in C. On most systems, this has either an alignment of
4 or 8 bytes (and this can be controlled in GCC by the option
`malign-double`
). A variable is aligned in memory if its memory offset is a
multiple of its alignment. On some systems (eg. sparc) memory alignment is
required; on others, it gives a speedup.“Uint” alignment depends on the size of a datatype. It is defined to be the
“True alignment” of the uint used by NumPy’s copy-code to copy the datatype, or
undefined/unaligned if there is no equivalent uint. Currently, NumPy uses
`uint8`
, `uint16`
, `uint32`
, `uint64`
, and `uint64`
to copy data of
size 1, 2, 4, 8, 16 bytes respectively, and all other sized datatypes cannot
be uint-aligned.

For example, on a (typical Linux x64 GCC) system, the NumPy [ complex64](../reference/arrays.scalars.html#numpy.complex64)
datatype is implemented as

`struct { float real, imag; }`
. This has “true”
alignment of 4 and “uint” alignment of 8 (equal to the true alignment of
`uint64`
).Some cases where uint and true alignment are different (default GCC Linux):
-
arch

type

true-aln

uint-aln

x86_64

complex64

4

8

x86_64

float128

16

8

x86

float96

4

-

## Variables in NumPy which control and describe alignment[#](#variables-in-numpy-which-control-and-describe-alignment)
There are 4 relevant uses of the word `align`
used in NumPy:

-
The

[attribute (]`dtype.alignment`
`descr->alignment`
in C). This is meant to reflect the “true alignment” of the type. It has arch-dependent default values for all datatypes, except for the structured types created with`align=True`
as described below.
-
The

`ALIGNED`
flag of an ndarray, computed in`IsAligned`
and checked by[. This is computed from]`PyArray_ISALIGNED`
[. It is set to]`dtype.alignment`
`True`
if every item in the array is at a memory location consistent with[, which is the case if the]`dtype.alignment`
`data ptr`
and all strides of the array are multiples of that alignment.
-
The

`align`
keyword of the dtype constructor, which only affects[Structured arrays]. If the structure’s field offsets are not manually provided, NumPy determines offsets automatically. In that case,`align=True`
pads the structure so that each field is “true” aligned in memory and sets[to be the largest of the field “true” alignments. This is like what C-structs usually do. Otherwise if offsets or itemsize were manually provided]`dtype.alignment`
`align=True`
simply checks that all the fields are “true” aligned and that the total itemsize is a multiple of the largest field alignment. In either case[is also set to True.]`dtype.isalignedstruct`
-
`IsUintAligned`
is used to determine if an ndarray is “uint aligned” in an analogous way to how`IsAligned`
checks for true alignment.
## Consequences of alignment[#](#consequences-of-alignment)
Here is how the variables above are used:

-
Creating aligned structs: To know how to offset a field when

`align=True`
, NumPy looks up`field.dtype.alignment`
. This includes fields that are nested structured arrays.
-
Ufuncs: If the

`ALIGNED`
flag of an array is False, ufuncs will buffer/cast the array before evaluation. This is needed since ufunc inner loops access raw elements directly, which might fail on some archs if the elements are not true-aligned.
-
Getitem/setitem/copyswap function: Similar to ufuncs, these functions generally have two code paths. If

`ALIGNED`
is False they will use a code path that buffers the arguments so they are true-aligned.
-
Strided copy code: Here, “uint alignment” is used instead. If the itemsize of an array is equal to 1, 2, 4, 8 or 16 bytes and the array is uint aligned then instead NumPy will do

`*(uintN*)dst) = *(uintN*)src)`
for appropriate N. Otherwise, NumPy copies by doing`memcpy(dst, src, N)`
.
-
Nditer code: Since this often calls the strided copy code, it must check for “uint alignment”.

-
Cast code: This checks for “true” alignment, as it does

`*dst = CASTFUNC(*src)`
if aligned. Otherwise, it does`memmove(srcval, src); dstval = CASTFUNC(srcval); memmove(dst, dstval)`
where dstval/srcval are aligned.
Note that the strided-copy and strided-cast code are deeply intertwined and so any arrays being processed by them must be both uint and true aligned, even though the copy-code only needs uint alignment and the cast code only true alignment. If there is ever a big rewrite of this code it would be good to allow them to use different alignments.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Performance[#](#performance)
## Recommendation[#](#recommendation)
The recommended generator for general use is [ PCG64](bit_generators/pcg64.html#numpy.random.PCG64) or its upgraded variant

[for heavily-parallel use cases. They are statistically high quality, full-featured, and fast on most platforms, but somewhat slow when compiled for 32-bit processes. See](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM)
`PCG64DXSM`
[Upgrading PCG64 with PCG64DXSM](upgrading-pcg64.html#upgrading-pcg64)for details on when heavy parallelism would indicate using
[.](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM)
`PCG64DXSM`
[ Philox](bit_generators/philox.html#numpy.random.Philox) is fairly slow, but its statistical properties have
very high quality, and it is easy to get an assuredly-independent stream by using
unique keys. If that is the style you wish to use for parallel streams, or you
are porting from another system that uses that style, then
[is your choice.](bit_generators/philox.html#numpy.random.Philox)
`Philox`
[ SFC64](bit_generators/sfc64.html#numpy.random.SFC64) is statistically high quality and very fast. However, it
lacks jumpability. If you are not using that capability and want lots of speed,
even on 32-bit processes, this is your choice.
`MT19937`
[fails some statistical tests](https://www.iro.umontreal.ca/~lecuyer/myftp/papers/testu01.pdf) and is not especially
fast compared to modern PRNGs. For these reasons, we mostly do not recommend
using it on its own, only through the legacy [ RandomState](legacy.html#numpy.random.RandomState) for
reproducing old results. That said, it has a very long history as a default in
many systems.
## Timings[#](#timings)
The timings below are the time in ns to produce 1 random value from a
specific distribution. The original [ MT19937](bit_generators/mt19937.html#numpy.random.MT19937) generator is
much slower since it requires 2 32-bit values to equal the output of the
faster generators.

Integer performance has a similar ordering.

The pattern is similar for other, more complex generators. The normal
performance of the legacy [ RandomState](legacy.html#numpy.random.RandomState) generator is much
lower than the other since it uses the Box-Muller transform rather
than the Ziggurat method. The performance gap for Exponentials is also
large due to the cost of computing the log function to invert the CDF.
The column labeled MT19973 uses the same 32-bit generator as

[but produces random variates using](legacy.html#numpy.random.RandomState)
`RandomState`
[.](generator.html#numpy.random.Generator)
`Generator`
MT19937

|
PCG64

|
PCG64DXSM

|
Philox

|
SFC64

|
RandomState

|
---|---|---|---|---|---|
32-bit Unsigned Ints

|
3.3

|
1.9

|
2.0

|
3.3

|
1.8

|
3.1

|
64-bit Unsigned Ints

|
5.6

|
3.2

|
2.9

|
4.9

|
2.5

|
5.5

|
Uniforms

|
5.9

|
3.1

|
2.9

|
5.0

|
2.6

|
6.0

|
Normals

|
13.9

|
10.8

|
10.5

|
12.0

|
8.3

|
56.8

|
Exponentials

|
9.1

|
6.0

|
5.8

|
8.1

|
5.4

|
63.9

|
Gammas

|
37.2

|
30.8

|
28.9

|
34.0

|
27.5

|
77.0

|
Binomials

|
21.3

|
17.4

|
17.6

|
19.3

|
15.6

|
21.4

|
Laplaces

|
73.2

|
72.3

|
76.1

|
73.0

|
72.3

|
82.5

|
Poissons

|
111.7

|
103.4

|
100.5

|
109.4

|
90.7

|
115.2

|
The next table presents the performance in percentage relative to values
generated by the legacy generator, `RandomState(MT19937())`
. The overall
performance was computed using a geometric mean.

MT19937

|
PCG64

|
PCG64DXSM

|
Philox

|
SFC64

|
---|---|---|---|---|
32-bit Unsigned Ints

|
96

|
162

|
160

|
96

|
175

|
64-bit Unsigned Ints

|
97

|
171

|
188

|
113

|
218

|
Uniforms

|
102

|
192

|
206

|
121

|
233

|
Normals

|
409

|
526

|
541

|
471

|
684

|
Exponentials

|
701

|
1071

|
1101

|
784

|
1179

|
Gammas

|
207

|
250

|
266

|
227

|
281

|
Binomials

|
100

|
123

|
122

|
111

|
138

|
Laplaces

|
113

|
114

|
108

|
113

|
114

|
Poissons

|
103

|
111

|
115

|
105

|
127

|
Overall

|
159

|
219

|
225

|
174

|
251

|
Note

All timings were taken using Linux on an AMD Ryzen 9 3900X processor.

## Performance on different Operating Systems[#](#performance-on-different-operating-systems)
Performance differs across platforms due to compiler and hardware availability (e.g., register width) differences. The default bit generator has been chosen to perform well on 64-bit platforms. Performance on 32-bit operating systems is very different.

The values reported are normalized relative to the speed of MT19937 in each table. A value of 100 indicates that the performance matches the MT19937. Higher values indicate improved performance. These values cannot be compared across tables.

### 64-bit Linux[#](#bit-linux)
Distribution

|
MT19937

|
PCG64

|
PCG64DXSM

|
Philox

|
SFC64

|
---|---|---|---|---|---|
32-bit Unsigned Ints

|
100

|
168

|
166

|
100

|
182

|
64-bit Unsigned Ints

|
100

|
176

|
193

|
116

|
224

|
Uniforms

|
100

|
188

|
202

|
118

|
228

|
Normals

|
100

|
128

|
132

|
115

|
167

|
Exponentials

|
100

|
152

|
157

|
111

|
168

|
Overall

|
100

|
161

|
168

|
112

|
192

|
### 64-bit Windows[#](#bit-windows)
The relative performance on 64-bit Linux and 64-bit Windows is broadly similar with the notable exception of the Philox generator.

Distribution

|
MT19937

|
PCG64

|
PCG64DXSM

|
Philox

|
SFC64

|
---|---|---|---|---|---|
32-bit Unsigned Ints

|
100

|
155

|
131

|
29

|
150

|
64-bit Unsigned Ints

|
100

|
157

|
143

|
25

|
154

|
Uniforms

|
100

|
151

|
144

|
24

|
155

|
Normals

|
100

|
129

|
128

|
37

|
150

|
Exponentials

|
100

|
150

|
145

|
28

|
159

|
|
100

|
148

|
138

|
28

|
154

|
### 32-bit Windows[#](#id1)
The performance of 64-bit generators on 32-bit Windows is much lower than on 64-bit operating systems due to register width. MT19937, the generator that has been in NumPy since 2005, operates on 32-bit integers.

Distribution

|
MT19937

|
PCG64

|
PCG64DXSM

|
Philox

|
SFC64

|
---|---|---|---|---|---|
32-bit Unsigned Ints

|
100

|
24

|
34

|
14

|
57

|
64-bit Unsigned Ints

|
100

|
21

|
32

|
14

|
74

|
Uniforms

|
100

|
21

|
34

|
16

|
73

|
Normals

|
100

|
36

|
57

|
28

|
101

|
Exponentials

|
100

|
28

|
44

|
20

|
88

|
|
100

|
25

|
39

|
18

|
77

|
Note

Linux timings used Ubuntu 20.04 and GCC 9.3.0. Windows timings were made on Windows 10 using Microsoft C/C++ Optimizing Compiler Version 19 (Visual Studio 2019). All timings were produced on an AMD Ryzen 9 3900X processor.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Bit Generators[#](#bit-generators)
The random values produced by [ Generator](../generator.html#numpy.random.Generator)
originate in a BitGenerator. The BitGenerators do not directly provide
random numbers and only contains methods used for seeding, getting or
setting the state, jumping or advancing the state, and for accessing
low-level wrappers for consumption by code that can efficiently
access the functions provided, e.g.,

[numba](https://numba.pydata.org).
## Supported BitGenerators[#](#supported-bitgenerators)
The included BitGenerators are:

PCG-64 - The default. A fast generator that can be advanced by an arbitrary amount. See the documentation for

. PCG-64 has a period of \(2^{128}\). See the`advance`
[PCG author’s page](http://www.pcg-random.org/)for more details about this class of PRNG.
PCG-64 DXSM - An upgraded version of PCG-64 with better statistical properties in parallel contexts. See

[Upgrading PCG64 with PCG64DXSM](../upgrading-pcg64.html#upgrading-pcg64)for more information on these improvements.
MT19937 - The standard Python BitGenerator. Adds a

function that returns a new generator with state as-if \(2^{128}\) draws have been made.`MT19937.jumped`
Philox - A counter-based generator capable of being advanced an arbitrary number of steps or generating independent streams. See the

[Random123](https://www.deshawresearch.com/resources_random123.html)page for more details about this class of bit generators.
SFC64 - A fast generator based on random invertible mappings. Usually the fastest generator of the four. See the

[SFC author’s page](http://pracrand.sourceforge.net/RNG_engines.txt)for (a little) more detail.
|
Base Class for generic BitGenerators, which provide a stream of random bits based on different algorithms.

|
# Seeding and Entropy[#](#seeding-and-entropy)
A BitGenerator provides a stream of random values. In order to generate
reproducible streams, BitGenerators support setting their initial state via a
seed. All of the provided BitGenerators will take an arbitrary-sized
non-negative integer, or a list of such integers, as a seed. BitGenerators
need to take those inputs and process them into a high-quality internal state
for the BitGenerator. All of the BitGenerators in numpy delegate that task to
[ SeedSequence](generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence), which uses hashing techniques to ensure that even low-quality
seeds generate high-quality initial states.

```
from numpy.random import PCG64
bg = PCG64(12345678903141592653589793)
```
[ SeedSequence](generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) is designed to be convenient for implementing best practices.
We recommend that a stochastic program defaults to using entropy from the OS so
that each run is different. The program should print out or log that entropy.
In order to reproduce a past value, the program should allow the user to
provide that value through some mechanism, a command-line argument is common,
so that the user can then re-enter that entropy to reproduce the result.
[can take care of everything except for communicating with the user, which is up to you.](generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
```
from numpy.random import PCG64, SeedSequence
# Get the user's seed somehow, maybe through `argparse`.
# If the user did not provide a seed, it should return `None`.
seed = get_user_seed()
ss = SeedSequence(seed)
print('seed = {}'.format(ss.entropy))
bg = PCG64(ss)
```
We default to using a 128-bit integer using entropy gathered from the OS. This is a good amount of entropy to initialize all of the generators that we have in numpy. We do not recommend using small seeds below 32 bits for general use. Using just a small set of seeds to instantiate larger state spaces means that there are some initial states that are impossible to reach. This creates some biases if everyone uses such values.

There will not be anything *wrong* with the results, per se; even a seed of
0 is perfectly fine thanks to the processing that [ SeedSequence](generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) does. If you
just need

*some*fixed value for unit tests or debugging, feel free to use whatever seed you like. But if you want to make inferences from the results or publish them, drawing from a larger set of seeds is good practice.
If you need to generate a good seed “offline”, then `SeedSequence().entropy`
or using `secrets.randbits(128)`
from the standard library are both
convenient ways.

If you need to run several stochastic simulations in parallel, best practice
is to construct a random generator instance for each simulation.
To make sure that the random streams have distinct initial states, you can use
the *spawn* method of [ SeedSequence](generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence). For instance, here we construct a list
of 12 instances:

```
from numpy.random import PCG64, SeedSequence
# High quality initial entropy
entropy = 0x87351080e25cb0fad77a44a3be03b491
base_seq = SeedSequence(entropy)
child_seqs = base_seq.spawn(12) # a list of 12 SeedSequences
generators = [PCG64(seq) for seq in child_seqs]
```
If you already have an initial random generator instance, you can shorten
the above by using the [ spawn](generated/numpy.random.BitGenerator.spawn.html#numpy.random.BitGenerator.spawn) method:

```
from numpy.random import PCG64, SeedSequence
# High quality initial entropy
entropy = 0x87351080e25cb0fad77a44a3be03b491
base_bitgen = PCG64(entropy)
generators = base_bitgen.spawn(12)
```
An alternative way is to use the fact that a [ SeedSequence](generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) can be initialized
by a tuple of elements. Here we use a base entropy value and an integer

`worker_id`
```
from numpy.random import PCG64, SeedSequence
# High quality initial entropy
entropy = 0x87351080e25cb0fad77a44a3be03b491
sequences = [SeedSequence((entropy, worker_id)) for worker_id in range(12)]
generators = [PCG64(seq) for seq in sequences]
```
Note that the sequences produced by the latter method will be distinct from
those constructed via [ spawn](generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn).

|
SeedSequence mixes sources of entropy in a reproducible way to set the initial state for independent and very probably non-overlapping BitGenerators.

|Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# How to create arrays with regularly-spaced values[#](#how-to-create-arrays-with-regularly-spaced-values)
There are a few NumPy functions that are similar in application, but which provide slightly different results, which may cause confusion if one is not sure when and how to use them. The following guide aims to list these functions and describe their recommended usage.

The functions mentioned here are

## 1D domains (intervals)[#](#d-domains-intervals)
`linspace`
vs. `arange`
[#](#linspace-vs-arange)
Both [ numpy.linspace](../reference/generated/numpy.linspace.html#numpy.linspace) and

[provide ways to partition an interval (a 1D domain) into equal-length subintervals. These partitions will vary depending on the chosen starting and ending points, and the](../reference/generated/numpy.arange.html#numpy.arange)
`numpy.arange`
**step**(the length of the subintervals).
**Use**`numpy.arange`
**if you want integer steps.**relies on step size to determine how many elements are in the returned array, which excludes the endpoint. This is determined through the`numpy.arange`
`step`
argument to`arange`
.Example:

>>> np.arange(0, 10, 2) # np.arange(start, stop, step) array([0, 2, 4, 6, 8])
The arguments

`start`
and`stop`
should be integer or real, but not complex numbers.is similar to the Python built-in`numpy.arange`
.`range`
Floating-point inaccuracies can make

`arange`
results with floating-point numbers confusing. In this case, you should useinstead.`numpy.linspace`
**Use**`numpy.linspace`
**if you want the endpoint to be included in the result, or if you are using a non-integer step size.**`numpy.linspace`
*can*include the endpoint and determines step size from the*num*argument, which specifies the number of elements in the returned array.The inclusion of the endpoint is determined by an optional boolean argument

`endpoint`
, which defaults to`True`
. Note that selecting`endpoint=False`
will change the step size computation, and the subsequent output for the function.Example:

>>> np.linspace(0.1, 0.2, num=5) # np.linspace(start, stop, num) array([0.1 , 0.125, 0.15 , 0.175, 0.2 ]) >>> np.linspace(0.1, 0.2, num=5, endpoint=False) array([0.1, 0.12, 0.14, 0.16, 0.18])
can also be used with complex arguments:`numpy.linspace`
>>> np.linspace(1+1.j, 4, 5, dtype=np.complex64) array([1. +1.j , 1.75+0.75j, 2.5 +0.5j , 3.25+0.25j, 4. +0.j ], dtype=complex64)
### Other examples[#](#other-examples)
Unexpected results may happen if floating point values are used as

`step`
in`numpy.arange`
. To avoid this, make sure all floating point conversion happens after the computation of results. For example, replace>>> list(np.arange(0.1,0.4,0.1).round(1)) [0.1, 0.2, 0.3, 0.4] # endpoint should not be included!
with

>>> list(np.arange(1, 4, 1) / 10.0) [0.1, 0.2, 0.3] # expected result
Note that

>>> np.arange(0, 1.12, 0.04) array([0. , 0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 , 0.44, 0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84, 0.88, 0.92, 0.96, 1. , 1.04, 1.08, 1.12])
and

>>> np.arange(0, 1.08, 0.04) array([0. , 0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 , 0.44, 0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84, 0.88, 0.92, 0.96, 1. , 1.04])
These differ because of numeric noise. When using floating point values, it is possible that

`0 + 0.04 * 28 < 1.12`
, and so`1.12`
is in the interval. In fact, this is exactly the case:>>> 1.12/0.04 28.000000000000004
But

`0 + 0.04 * 27 >= 1.08`
so that 1.08 is excluded:>>> 1.08/0.04 27.0
Alternatively, you could use

`np.arange(0, 28)*0.04`
which would always give you precise control of the end point since it is integral:>>> np.arange(0, 28)*0.04 array([0. , 0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 , 0.44, 0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84, 0.88, 0.92, 0.96, 1. , 1.04, 1.08])
`geomspace`
and `logspace`
[#](#geomspace-and-logspace)
`numpy.geomspace`
is similar to `numpy.linspace`
, but with numbers spaced
evenly on a log scale (a geometric progression). The endpoint is included in the
result.
Example:

```
>>> np.geomspace(2, 3, num=5)
array([2. , 2.21336384, 2.44948974, 2.71080601, 3. ])
```
`numpy.logspace`
is similar to `numpy.geomspace`
, but with the start and end
points specified as logarithms (with base 10 as default):
```
>>> np.logspace(2, 3, num=5)
array([ 100. , 177.827941 , 316.22776602, 562.34132519, 1000. ])
```
In linear space, the sequence starts at `base ** start`
(`base`
to the power
of `start`
) and ends with `base ** stop`
:

```
>>> np.logspace(2, 3, num=5, base=2)
array([4. , 4.75682846, 5.65685425, 6.72717132, 8. ])
```
## nD domains[#](#nd-domains)
nD domains can be partitioned into *grids*. This can be done using one of the
following functions.

`meshgrid`
[#](#meshgrid)
The purpose of `numpy.meshgrid`
is to create a rectangular grid out of a set
of one-dimensional coordinate arrays.

Given arrays

>>> x = np.array([0, 1, 2, 3]) >>> y = np.array([0, 1, 2, 3, 4, 5])
`meshgrid`
will create two coordinate arrays, which can be used to generate
the coordinate pairs determining this grid.
>>> xx, yy = np.meshgrid(x, y) >>> xx array([[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]]) >>> yy array([[0, 0, 0, 0], [1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4], [5, 5, 5, 5]]) >>> import matplotlib.pyplot as plt >>> plt.plot(xx, yy, marker='.', color='k', linestyle='none')
`mgrid`
[#](#mgrid)
`numpy.mgrid`
can be used as a shortcut for creating meshgrids. It is not a
function, but when indexed, returns a multidimensional meshgrid.
```
>>> xx, yy = np.meshgrid(np.array([0, 1, 2, 3]), np.array([0, 1, 2, 3, 4, 5]))
>>> xx.T, yy.T
(array([[0, 0, 0, 0, 0, 0],
[1, 1, 1, 1, 1, 1],
[2, 2, 2, 2, 2, 2],
[3, 3, 3, 3, 3, 3]]),
array([[0, 1, 2, 3, 4, 5],
[0, 1, 2, 3, 4, 5],
[0, 1, 2, 3, 4, 5],
[0, 1, 2, 3, 4, 5]]))
>>> np.mgrid[0:4, 0:6]
array([[[0, 0, 0, 0, 0, 0],
[1, 1, 1, 1, 1, 1],
[2, 2, 2, 2, 2, 2],
[3, 3, 3, 3, 3, 3]],
[[0, 1, 2, 3, 4, 5],
[0, 1, 2, 3, 4, 5],
[0, 1, 2, 3, 4, 5],
[0, 1, 2, 3, 4, 5]]])
```
`ogrid`
[#](#ogrid)
Similar to `numpy.mgrid`
, `numpy.ogrid`
returns an *open* multidimensional
meshgrid. This means that when it is indexed, only one dimension of each
returned array is greater than 1. This avoids repeating the data and thus saves
memory, which is often desirable.

These sparse coordinate grids are intended to be use with [Broadcasting](https://scipy-lectures.org/intro/numpy/operations.html#broadcasting).
When all coordinates are used in an expression, broadcasting still leads to a
fully-dimensonal result array.

```
>>> np.ogrid[0:4, 0:6]
[array([[0],
[1],
[2],
[3]]), array([[0, 1, 2, 3, 4, 5]])]
```
All three methods described here can be used to evaluate function values on a grid.

```
>>> g = np.ogrid[0:4, 0:6]
>>> zg = np.sqrt(g[0]**2 + g[1]**2)
>>> g[0].shape, g[1].shape, zg.shape
((4, 1), (1, 6), (4, 6))
>>> m = np.mgrid[0:4, 0:6]
>>> zm = np.sqrt(m[0]**2 + m[1]**2)
>>> np.array_equal(zm, zg)
True
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Using the Convenience Classes[#](#using-the-convenience-classes)
The convenience classes provided by the polynomial package are:

Name

Provides

Polynomial

Power series

Chebyshev

Chebyshev series

Legendre

Legendre series

Laguerre

Laguerre series

Hermite

Hermite series

HermiteE

HermiteE series

The series in this context are finite sums of the corresponding polynomial basis functions multiplied by coefficients. For instance, a power series looks like

and has coefficients \([1, 2, 3]\). The Chebyshev series with the same coefficients looks like

and more generally

where in this case the \(T_n\) are the Chebyshev functions of degree \(n\), but could just as easily be the basis functions of any of the other classes. The convention for all the classes is that the coefficient \(c[i]\) goes with the basis function of degree i.

All of the classes are immutable and have the same methods, and especially they implement the Python numeric operators +, -, *, //, %, divmod, **, ==, and !=. The last two can be a bit problematic due to floating point roundoff errors. We now give a quick demonstration of the various operations using NumPy version 1.7.0.

## Basics[#](#basics)
First we need a polynomial class and a polynomial instance to play with. The classes can be imported directly from the polynomial package or from the module of the relevant type. Here we import from the package and use the conventional Polynomial class because of its familiarity:

```
>>> from numpy.polynomial import Polynomial as P
>>> p = P([1,2,3])
>>> p
Polynomial([1., 2., 3.], domain=[-1, 1], window=[-1, 1], symbol='x')
```
Note that there are three parts to the long version of the printout. The first is the coefficients, the second is the domain, and the third is the window:

```
>>> p.coef
array([1., 2., 3.])
>>> p.domain
array([-1, 1])
>>> p.window
array([-1, 1])
```
Printing a polynomial yields the polynomial expression in a more familiar format:

```
>>> print(p)
1.0 + 2.0·x + 3.0·x²
```
Note that the string representation of polynomials uses Unicode characters
by default (except on Windows) to express powers and subscripts. An ASCII-based
representation is also available (default on Windows). The polynomial string
format can be toggled at the package-level with the
[ set_default_printstyle](generated/numpy.polynomial.set_default_printstyle.html#numpy.polynomial.set_default_printstyle) function:

```
>>> np.polynomial.set_default_printstyle('ascii')
>>> print(p)
1.0 + 2.0 x + 3.0 x**2
```
or controlled for individual polynomial instances with string formatting:

```
>>> print(f"{p:unicode}")
1.0 + 2.0·x + 3.0·x²
```
We will deal with the domain and window when we get to fitting, for the moment we ignore them and run through the basic algebraic and arithmetic operations.

Addition and Subtraction:

```
>>> p + p
Polynomial([2., 4., 6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p - p
Polynomial([0.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Multiplication:

```
>>> p * p
Polynomial([ 1., 4., 10., 12., 9.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Powers:

```
>>> p**2
Polynomial([ 1., 4., 10., 12., 9.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Division:

Floor division, ‘//’, is the division operator for the polynomial classes, polynomials are treated like integers in this regard. For Python versions < 3.x the ‘/’ operator maps to ‘//’, as it does for Python, for later versions the ‘/’ will only work for division by scalars. At some point it will be deprecated:

```
>>> p // P([-1, 1])
Polynomial([5., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Remainder:

```
>>> p % P([-1, 1])
Polynomial([6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Divmod:

```
>>> quo, rem = divmod(p, P([-1, 1]))
>>> quo
Polynomial([5., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> rem
Polynomial([6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Evaluation:

```
>>> x = np.arange(5)
>>> p(x)
array([ 1., 6., 17., 34., 57.])
>>> x = np.arange(6).reshape(3,2)
>>> p(x)
array([[ 1., 6.],
[17., 34.],
[57., 86.]])
```
Substitution:

Substitute a polynomial for x and expand the result. Here we substitute p in itself leading to a new polynomial of degree 4 after expansion. If the polynomials are regarded as functions this is composition of functions:

```
>>> p(p)
Polynomial([ 6., 16., 36., 36., 27.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Roots:

```
>>> p.roots()
array([-0.33333333-0.47140452j, -0.33333333+0.47140452j])
```
It isn’t always convenient to explicitly use Polynomial instances, so tuples, lists, arrays, and scalars are automatically cast in the arithmetic operations:

```
>>> p + [1, 2, 3]
Polynomial([2., 4., 6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> [1, 2, 3] * p
Polynomial([ 1., 4., 10., 12., 9.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p / 2
Polynomial([0.5, 1. , 1.5], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Polynomials that differ in domain, window, or class can’t be mixed in arithmetic:

```
>>> from numpy.polynomial import Chebyshev as T
>>> p + P([1], domain=[0,1])
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "<string>", line 213, in __add__
TypeError: Domains differ
>>> p + P([1], window=[0,1])
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "<string>", line 215, in __add__
TypeError: Windows differ
>>> p + T([1])
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "<string>", line 211, in __add__
TypeError: Polynomial types differ
```
But different types can be used for substitution. In fact, this is how conversion of Polynomial classes among themselves is done for type, domain, and window casting:

```
>>> p(T([0, 1]))
Chebyshev([2.5, 2. , 1.5], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Which gives the polynomial *p* in Chebyshev form. This works because
\(T_1(x) = x\) and substituting \(x\) for \(x\) doesn’t change
the original polynomial. However, all the multiplications and divisions
will be done using Chebyshev series, hence the type of the result.

It is intended that all polynomial instances are immutable, therefore
augmented operations (`+=`
, `-=`
, etc.) and any other functionality that
would violate the immutablity of a polynomial instance are intentionally
unimplemented.

## Calculus[#](#calculus)
Polynomial instances can be integrated and differentiated.:

```
>>> from numpy.polynomial import Polynomial as P
>>> p = P([2, 6])
>>> p.integ()
Polynomial([0., 2., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.integ(2)
Polynomial([0., 0., 1., 1.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
The first example integrates *p* once, the second example integrates it
twice. By default, the lower bound of the integration and the integration
constant are 0, but both can be specified.:

```
>>> p.integ(lbnd=-1)
Polynomial([-1., 2., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.integ(lbnd=-1, k=1)
Polynomial([0., 2., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
In the first case the lower bound of the integration is set to -1 and the integration constant is 0. In the second the constant of integration is set to 1 as well. Differentiation is simpler since the only option is the number of times the polynomial is differentiated:

```
>>> p = P([1, 2, 3])
>>> p.deriv(1)
Polynomial([2., 6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.deriv(2)
Polynomial([6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
## Other Polynomial Constructors[#](#other-polynomial-constructors)
Constructing polynomials by specifying coefficients is just one way of obtaining a polynomial instance, they may also be created by specifying their roots, by conversion from other polynomial types, and by least squares fits. Fitting is discussed in its own section, the other methods are demonstrated below:

```
>>> from numpy.polynomial import Polynomial as P
>>> from numpy.polynomial import Chebyshev as T
>>> p = P.fromroots([1, 2, 3])
>>> p
Polynomial([-6., 11., -6., 1.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.convert(kind=T)
Chebyshev([-9. , 11.75, -3. , 0.25], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
The convert method can also convert domain and window:

```
>>> p.convert(kind=T, domain=[0, 1])
Chebyshev([-2.4375 , 2.96875, -0.5625 , 0.03125], domain=[0., 1.], window=[-1., 1.], symbol='x')
>>> p.convert(kind=P, domain=[0, 1])
Polynomial([-1.875, 2.875, -1.125, 0.125], domain=[0., 1.], window=[-1., 1.], symbol='x')
```
In numpy versions >= 1.7.0 the *basis* and *cast* class methods are also
available. The cast method works like the convert method while the basis
method returns the basis polynomial of given degree:

```
>>> P.basis(3)
Polynomial([0., 0., 0., 1.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> T.cast(p)
Chebyshev([-9. , 11.75, -3. , 0.25], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Conversions between types can be useful, but it is *not* recommended
for routine use. The loss of numerical precision in passing from a
Chebyshev series of degree 50 to a Polynomial series of the same degree
can make the results of numerical evaluation essentially random.

## Fitting[#](#fitting)
Fitting is the reason that the *domain* and *window* attributes are part of
the convenience classes. To illustrate the problem, the values of the Chebyshev
polynomials up to degree 5 are plotted below.

```
>>> import matplotlib.pyplot as plt
>>> from numpy.polynomial import Chebyshev as T
>>> x = np.linspace(-1, 1, 100)
>>> for i in range(6):
... ax = plt.plot(x, T.basis(i)(x), lw=2, label=f"$T_{i}$")
...
>>> plt.legend(loc="upper left")
>>> plt.show()
```
In the range -1 <= *x* <= 1 they are nice, equiripple functions lying between +/- 1.
The same plots over the range -2 <= *x* <= 2 look very different:

```
>>> import matplotlib.pyplot as plt
>>> from numpy.polynomial import Chebyshev as T
>>> x = np.linspace(-2, 2, 100)
>>> for i in range(6):
... ax = plt.plot(x, T.basis(i)(x), lw=2, label=f"$T_{i}$")
...
>>> plt.legend(loc="lower right")
>>> plt.show()
```
As can be seen, the “good” parts have shrunk to insignificance. In using
Chebyshev polynomials for fitting we want to use the region where *x* is
between -1 and 1 and that is what the *window* specifies. However, it is
unlikely that the data to be fit has all its data points in that interval,
so we use *domain* to specify the interval where the data points lie. When
the fit is done, the domain is first mapped to the window by a linear
transformation and the usual least squares fit is done using the mapped
data points. The window and domain of the fit are part of the returned series
and are automatically used when computing values, derivatives, and such. If
they aren’t specified in the call the fitting routine will use the default
window and the smallest domain that holds all the data points. This is
illustrated below for a fit to a noisy sine curve.

```
>>> import numpy as np
>>> import matplotlib.pyplot as plt
>>> from numpy.polynomial import Chebyshev as T
>>> np.random.seed(11)
>>> x = np.linspace(0, 2*np.pi, 20)
>>> y = np.sin(x) + np.random.normal(scale=.1, size=x.shape)
>>> p = T.fit(x, y, 5)
>>> plt.plot(x, y, 'o')
>>> xx, yy = p.linspace()
>>> plt.plot(xx, yy, lw=2)
>>> p.domain
array([0. , 6.28318531])
>>> p.window
array([-1., 1.])
>>> plt.show()
```r"""
Building the required library in this example requires a source distribution
of NumPy or clone of the NumPy git repository since distributions.c is not
included in binary distributions.
On *nix, execute in numpy/random/src/distributions
export ${PYTHON_VERSION}=3.8 # Python version
export PYTHON_INCLUDE=#path to Python's include folder, usually \
${PYTHON_HOME}/include/python${PYTHON_VERSION}m
export NUMPY_INCLUDE=#path to numpy's include folder, usually \
${PYTHON_HOME}/lib/python${PYTHON_VERSION}/site-packages/numpy/core/include
gcc -shared -o libdistributions.so -fPIC distributions.c \
-I${NUMPY_INCLUDE} -I${PYTHON_INCLUDE}
mv libdistributions.so ../../_examples/numba/
On Windows
rem PYTHON_HOME and PYTHON_VERSION are setup dependent, this is an example
set PYTHON_HOME=c:\Anaconda
set PYTHON_VERSION=38
cl.exe /LD .\distributions.c -DDLL_EXPORT \
-I%PYTHON_HOME%\lib\site-packages\numpy\core\include \
-I%PYTHON_HOME%\include %PYTHON_HOME%\libs\python%PYTHON_VERSION%.lib
move distributions.dll ../../_examples/numba/
"""
import os
import numba as nb
import numpy as np
from cffi import FFI
from numpy.random import PCG64
ffi = FFI()
if os.path.exists('./distributions.dll'):
lib = ffi.dlopen('./distributions.dll')
elif os.path.exists('./libdistributions.so'):
lib = ffi.dlopen('./libdistributions.so')
else:
raise RuntimeError('Required DLL/so file was not found.')
ffi.cdef("""
double random_standard_normal(void *bitgen_state);
""")
x = PCG64()
xffi = x.cffi
bit_generator = xffi.bit_generator
random_standard_normal = lib.random_standard_normal
def normals(n, bit_generator):
out = np.empty(n)
for i in range(n):
out[i] = random_standard_normal(bit_generator)
return out
normalsj = nb.jit(normals, nopython=True)
# Numba requires a memory address for void *
# Can also get address from x.ctypes.bit_generator.value
bit_generator_address = int(ffi.cast('uintptr_t', bit_generator))
norm = normalsj(1000, bit_generator_address)
print(norm[:12])Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Putting the Inner Loop in Cython[#](#putting-the-inner-loop-in-cython)
Those who want really good performance out of their low level operations
should strongly consider directly using the iteration API provided
in C, but for those who are not comfortable with C or C++, Cython
is a good middle ground with reasonable performance tradeoffs. For
the [ nditer](generated/numpy.nditer.html#numpy.nditer) object, this means letting the iterator take care
of broadcasting, dtype conversion, and buffering, while giving the inner
loop to Cython.

For our example, we’ll create a sum of squares function. To start,
let’s implement this function in straightforward Python. We want to
support an ‘axis’ parameter similar to the numpy [ sum](https://docs.python.org/3/library/functions.html#sum) function,
so we will need to construct a list for the

*op_axes*parameter. Here’s how this looks.
Example

```
>>> def axis_to_axeslist(axis, ndim):
... if axis is None:
... return [-1] * ndim
... else:
... if type(axis) is not tuple:
... axis = (axis,)
... axeslist = [1] * ndim
... for i in axis:
... axeslist[i] = -1
... ax = 0
... for i in range(ndim):
... if axeslist[i] != -1:
... axeslist[i] = ax
... ax += 1
... return axeslist
...
>>> def sum_squares_py(arr, axis=None, out=None):
... axeslist = axis_to_axeslist(axis, arr.ndim)
... it = np.nditer([arr, out], flags=['reduce_ok',
... 'buffered', 'delay_bufalloc'],
... op_flags=[['readonly'], ['readwrite', 'allocate']],
... op_axes=[None, axeslist],
... op_dtypes=['float64', 'float64'])
... with it:
... it.operands[1][...] = 0
... it.reset()
... for x, y in it:
... y[...] += x*x
... return it.operands[1]
...
>>> a = np.arange(6).reshape(2,3)
>>> sum_squares_py(a)
array(55.)
>>> sum_squares_py(a, axis=-1)
array([ 5., 50.])
```
To Cython-ize this function, we replace the inner loop (y[…] += x*x) with Cython code that’s specialized for the float64 dtype. With the ‘external_loop’ flag enabled, the arrays provided to the inner loop will always be one-dimensional, so very little checking needs to be done.

Here’s the listing of sum_squares.pyx:

```
import numpy as np
cimport numpy as np
cimport cython
def axis_to_axeslist(axis, ndim):
if axis is None:
return [-1] * ndim
else:
if type(axis) is not tuple:
axis = (axis,)
axeslist = [1] * ndim
for i in axis:
axeslist[i] = -1
ax = 0
for i in range(ndim):
if axeslist[i] != -1:
axeslist[i] = ax
ax += 1
return axeslist
@cython.boundscheck(False)
def sum_squares_cy(arr, axis=None, out=None):
cdef np.ndarray[double] x
cdef np.ndarray[double] y
cdef int size
cdef double value
axeslist = axis_to_axeslist(axis, arr.ndim)
it = np.nditer([arr, out], flags=['reduce_ok', 'external_loop',
'buffered', 'delay_bufalloc'],
op_flags=[['readonly'], ['readwrite', 'allocate']],
op_axes=[None, axeslist],
op_dtypes=['float64', 'float64'])
with it:
it.operands[1][...] = 0
it.reset()
for xarr, yarr in it:
x = xarr
y = yarr
size = x.shape[0]
for i in range(size):
value = x[i]
y[i] = y[i] + value * value
return it.operands[1]
```
On this machine, building the .pyx file into a module looked like the following, but you may have to find some Cython tutorials to tell you the specifics for your system configuration.:

```
$ cython sum_squares.pyx
$ gcc -shared -pthread -fPIC -fwrapv -O2 -Wall -I/usr/include/python2.7 -fno-strict-aliasing -o sum_squares.so sum_squares.c
```
Running this from the Python interpreter produces the same answers as our native Python/NumPy code did.

Example

```
>>> from sum_squares import sum_squares_cy
>>> a = np.arange(6).reshape(2,3)
>>> sum_squares_cy(a)
array(55.0)
>>> sum_squares_cy(a, axis=-1)
array([ 5., 50.])
```
Doing a little timing in IPython shows that the reduced overhead and memory allocation of the Cython inner loop is providing a very nice speedup over both the straightforward Python code and an expression using NumPy’s built-in sum function.:

```
>>> a = np.random.rand(1000,1000)
>>> timeit sum_squares_py(a, axis=-1)
10 loops, best of 3: 37.1 ms per loop
>>> timeit np.sum(a*a, axis=-1)
10 loops, best of 3: 20.9 ms per loop
>>> timeit sum_squares_cy(a, axis=-1)
100 loops, best of 3: 11.8 ms per loop
>>> np.all(sum_squares_cy(a, axis=-1) == np.sum(a*a, axis=-1))
True
>>> np.all(sum_squares_py(a, axis=-1) == np.sum(a*a, axis=-1))
True
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.#!/usr/bin/env python3
#cython: language_level=3
from libc.stdint cimport uint32_t
from cpython.pycapsule cimport PyCapsule_IsValid, PyCapsule_GetPointer
import numpy as np
cimport numpy as np
cimport cython
from numpy.random cimport bitgen_t
from numpy.random import PCG64
np.import_array()
@cython.boundscheck(False)
@cython.wraparound(False)
def uniform_mean(Py_ssize_t n):
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef const char *capsule_name = "BitGenerator"
cdef double[::1] random_values
cdef np.ndarray randoms
x = PCG64()
capsule = x.capsule
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
rng = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)
random_values = np.empty(n)
# Best practice is to acquire the lock whenever generating random values.
# This prevents other threads from modifying the state. Acquiring the lock
# is only necessary if the GIL is also released, as in this example.
with x.lock, nogil:
for i in range(n):
random_values[i] = rng.next_double(rng.state)
randoms = np.asarray(random_values)
return randoms.mean()
# This function is declared nogil so it can be used without the GIL below
cdef uint32_t bounded_uint(uint32_t lb, uint32_t ub, bitgen_t *rng) nogil:
cdef uint32_t mask, delta, val
mask = delta = ub - lb
mask |= mask >> 1
mask |= mask >> 2
mask |= mask >> 4
mask |= mask >> 8
mask |= mask >> 16
val = rng.next_uint32(rng.state) & mask
while val > delta:
val = rng.next_uint32(rng.state) & mask
return lb + val
@cython.boundscheck(False)
@cython.wraparound(False)
def bounded_uints(uint32_t lb, uint32_t ub, Py_ssize_t n):
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef uint32_t[::1] out
cdef const char *capsule_name = "BitGenerator"
x = PCG64()
out = np.empty(n, dtype=np.uint32)
capsule = x.capsule
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
rng = <bitgen_t *>PyCapsule_GetPointer(capsule, capsule_name)
with x.lock, nogil:
for i in range(n):
out[i] = bounded_uint(lb, ub, rng)
return np.asarray(out)Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# NumPy documentation[#](#numpy-documentation)
**Version**: 1.26
**Download documentation**:
[Historical versions of documentation](https://numpy.org/doc/)
**Useful links**:
[Installation](https://numpy.org/install/) |
[Source Repository](https://github.com/numpy/numpy) |
[Issue Tracker](https://github.com/numpy/numpy/issues) |
[Q&A Support](https://numpy.org/gethelp/) |
[Mailing List](https://mail.python.org/mailman/listinfo/numpy-discussion)
NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.

Getting Started

New to NumPy? Check out the Absolute Beginner’s Guide. It contains an introduction to NumPy’s main concepts and links to additional tutorials.

User Guide

The user guide provides in-depth information on the key concepts of NumPy with useful background information and explanation.

API Reference

The reference guide contains a detailed description of the functions, modules, and objects included in NumPy. The reference describes how the methods work and which parameters can be used. It assumes that you have an understanding of the key concepts.

Contributor’s Guide

Want to add to the codebase? Can help add translation or a flowchart to the documentation? The contributing guidelines will guide you through the process of improving NumPy.# Releasing a version[#](#releasing-a-version)
The following guides include detailed information on how to prepare a NumPy release.

## How to prepare a release[#](#how-to-prepare-a-release)
These instructions give an overview of what is necessary to build binary releases for NumPy.

### Current build and release info[#](#current-build-and-release-info)
Useful info can be found in the following locations:

**Source tree**
**NumPy docs**
**Release scripts**
### Supported platforms and versions[#](#supported-platforms-and-versions)
[NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html#nep29) outlines which Python versions
are supported; For the first half of 2020, this will be Python >= 3.6. We test
NumPy against all these versions every time we merge code to main. Binary
installers may be available for a subset of these versions (see below).
**OS X**OS X versions >= 10.9 are supported, for Python version support see

[NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html#nep29). We build binary wheels for OSX that are compatible with Python.org Python, system Python, homebrew and macports - see this[OSX wheel building summary](https://github.com/MacPython/wiki/wiki/Spinning-wheels)for details.
**Windows**We build 32- and 64-bit wheels on Windows. Windows 7, 8 and 10 are supported. We build NumPy using the

[mingw-w64 toolchain](https://mingwpy.github.io),[cibuildwheels](https://cibuildwheel.readthedocs.io/en/stable/)and GitHub actions.
**Linux**We build and ship

[manylinux2014](https://www.python.org/dev/peps/pep-0513)wheels for NumPy. Many Linux distributions include their own binary builds of NumPy.
**BSD / Solaris**No binaries are provided, but successful builds on Solaris and BSD have been reported.

### Tool chain[#](#tool-chain)
We build all our wheels on cloud infrastructure - so this list of compilers is
for information and debugging builds locally. See the `.travis.yml`
script
in the [numpy wheels](https://github.com/MacPython/numpy-wheels) repo for an outdated source of the build recipes using
multibuild.

#### Compilers[#](#compilers)
The same gcc version is used as the one with which Python itself is built on each platform. At the moment this means:

OS X builds on travis currently use

*clang*. It appears that binary wheels for OSX >= 10.6 can be safely built from the travis-ci OSX 10.9 VMs when building against the Python from the Python.org installers;
Windows builds use the

[mingw-w64 toolchain](https://mingwpy.github.io);
Manylinux2014 wheels use the gcc provided on the Manylinux docker images.

You will need Cython for building the binaries. Cython compiles the `.pyx`
files in the NumPy distribution to `.c`
files.

#### OpenBLAS[#](#openblas)
All the wheels link to a version of [OpenBLAS](https://github.com/xianyi/OpenBLAS) supplied via the [openblas-libs](https://github.com/MacPython/openblas-libs) repo.
The shared object (or DLL) is shipped with in the wheel, renamed to prevent name
collisions with other OpenBLAS shared objects that may exist in the filesystem.

#### Building source archives and wheels[#](#building-source-archives-and-wheels)
The NumPy wheels and sdist are now built using cibuildwheel with github actions.

#### Building docs[#](#building-docs)
We are no longer building pdf files, only html docs. The `numpy-html.zip`
needed to upload to the doc server can be built with `spin docs dist`
.

To install the necessary doc build dependencies into your development
environment, run `pip install -r doc_requirements.txt`
.

#### Uploading to PyPI[#](#uploading-to-pypi)
The only application needed for uploading is

twine (pip).

You will also need a PyPI token, which is best kept on a keyring. See the
twine [keyring](https://twine.readthedocs.io/en/stable/#keyring-support) documentation for how to do that.

### What is released[#](#what-is-released)
**Wheels**We currently support Python 3.8-3.10 on Windows, OSX, and Linux.Windows: 32-bit and 64-bit wheels built using Github actions;

OSX: x64_86 and arm64 OSX wheels built using Github actions;

Linux: x64_86 and aarch64 Manylinux2014 wheels built using Github actions.

**Other**Release notes and changelog
**Source distribution**We build source releases in the .tar.gz format.
### Release process[#](#release-process)
#### Agree on a release schedule[#](#agree-on-a-release-schedule)
A typical release schedule is one beta, two release candidates and a final release. It’s best to discuss the timing on the mailing list first, in order for people to get their commits in on time, get doc wiki edits merged, etc. After a date is set, create a new maintenance/x.y.z branch, add new empty release notes for the next version in the main branch and update the Trac Milestones.

#### Make sure current branch builds a package correctly[#](#make-sure-current-branch-builds-a-package-correctly)
The CI builds wheels when a PR header begins with `REL`
. Your last
PR before releasing should be so marked and all the tests should pass.
You can also do:

```
git clean -fxdq
python setup.py bdist_wheel
python setup.py sdist
```
For details of the build process itself, it is best to read the Step-by-Step Directions below.

Note

The following steps are repeated for the beta(s), release candidates(s) and the final release.

#### Check deprecations[#](#check-deprecations)
Before [the release branch is made](#branching), it should be checked that
all deprecated code that should be removed is actually removed, and all new
deprecations say in the docstring or deprecation warning what version the code
will be removed.

#### Check the C API version number[#](#check-the-c-api-version-number)
The C API version needs to be tracked in three places

numpy/core/setup_common.py

numpy/core/code_generators/cversions.txt

numpy/core/include/numpy/numpyconfig.h

There are three steps to the process.

If the API has changed, increment the C_API_VERSION in setup_common.py. The API is unchanged only if any code compiled against the current API will be backward compatible with the last released NumPy version. Any changes to C structures or additions to the public interface will make the new API not backward compatible.

If the C_API_VERSION in the first step has changed, or if the hash of the API has changed, the cversions.txt file needs to be updated. To check the hash, run the script numpy/core/cversions.py and note the API hash that is printed. If that hash does not match the last hash in numpy/core/code_generators/cversions.txt the hash has changed. Using both the appropriate C_API_VERSION and hash, add a new entry to cversions.txt. If the API version was not changed, but the hash differs, you will need to comment out the previous entry for that API version. For instance, in NumPy 1.9 annotations were added, which changed the hash, but the API was the same as in 1.8. The hash serves as a check for API changes, but it is not definitive.

If steps 1 and 2 are done correctly, compiling the release should not give a warning “API mismatch detect at the beginning of the build”.

The numpy/core/include/numpy/numpyconfig.h will need a new NPY_X_Y_API_VERSION macro, where X and Y are the major and minor version numbers of the release. The value given to that macro only needs to be increased from the previous version if some of the functions or macros in the include files were deprecated.

The C ABI version number in numpy/core/setup_common.py should only be updated for a major release.

#### Check the release notes[#](#check-the-release-notes)
Use [towncrier](https://pypi.org/project/towncrier/) to build the release note and
commit the changes. This will remove all the fragments from
`doc/release/upcoming_changes`
and add `doc/release/<version>-note.rst`
.

towncrier build –version “<version>” git commit -m”Create release note”

Check that the release notes are up-to-date.

Update the release notes with a Highlights section. Mention some of the following:

major new features

deprecated and removed features

supported Python versions

for SciPy, supported NumPy version(s)

outlook for the near future

## Step-by-step directions[#](#step-by-step-directions)
This is a walkthrough of the NumPy 1.21.0 release on Linux, modified for
building with GitHub Actions and cibuildwheels and uploading to the
[anaconda.org staging repository for NumPy](https://anaconda.org/multibuild-wheels-staging/numpy).
The commands can be copied into the command line, but be sure to replace 1.21.0
by the correct version. This should be read together with the
[general release guide](#prepare-release).

### Facility preparation[#](#facility-preparation)
Before beginning to make a release, use the `*_requirements.txt`
files to
ensure that you have the needed software. Most software can be installed with
pip, but some will require apt-get, dnf, or whatever your system uses for
software. You will also need a GitHub personal access token (PAT) to push the
documentation. There are a few ways to streamline things:

Git can be set up to use a keyring to store your GitHub personal access token. Search online for the details.

You can use the

`keyring`
app to store the PyPI password for twine. See the online twine documentation for details.
### Release preparation[#](#release-preparation)
#### Add/drop Python versions[#](#add-drop-python-versions)
When adding or dropping Python versions, three files need to be edited:

.github/workflows/wheels.yml # for github cibuildwheel

.travis.yml # for cibuildwheel aarch64 builds

setup.py # for classifier and minimum version check.

Make these changes in an ordinary PR against main and backport if necessary.
Using the *BLD:* prefix (build label) for the commit summary will cause the
wheel builds to be run so that the changes will be tested, We currently release
wheels for new Python versions after the first Python rc once manylinux and
cibuildwheel support it. For Python 3.11 we were able to release within a week
of the rc1 announcement.

#### Backport Pull Requests[#](#backport-pull-requests)
Changes that have been marked for this release must be backported to the maintenance/1.21.x branch.

#### Update release documentation[#](#update-release-documentation)
Four documents usually need to be updated or created before making a release:

The changelog

The release-notes

The

`.mailmap`
file
The

`doc/source/release.rst`
file
These changes should be made as an ordinary PR against the maintenance branch.
After release all files except `doc/source/release.rst`
will need to be
forward ported to the main branch.

##### Generate the changelog[#](#generate-the-changelog)
The changelog is generated using the changelog tool:

```
$ python tools/changelog.py $GITHUB v1.20.0..maintenance/1.21.x > doc/changelog/1.21.0-changelog.rst
```
where `GITHUB`
contains your GitHub access token. The text will need to be
checked for non-standard contributor names and dependabot entries removed. It
is also a good idea to remove any links that may be present in the PR titles
as they don’t translate well to markdown, replace them with monospaced text. The
non-standard contributor names should be fixed by updating the `.mailmap`
file, which is a lot of work. It is best to make several trial runs before
reaching this point and ping the malefactors using a GitHub issue to get the
needed information.

##### Finish the release notes[#](#finish-the-release-notes)
If this is the first release in a series the release note is generated, see
the release note in `doc/release/upcoming_changes/README.rst`
to see how to
do this. Generating the release notes will also delete all the news
fragment files in `doc/release/upcoming_changes/`
.

The generated release note will always need some fixups, the introduction will
need to be written, and significant changes should be called out. For patch
releases the changelog text may also be appended, but not for the initial
release as it is too long. Check previous release notes to see how this is
done. Note that the `:orphan:`
markup at the top, if present, will need
changing to `.. currentmodule:: numpy`
and the `doc/source/release.rst`
index file will need updating.

##### Check the `pavement.py`
file[#](#check-the-pavement-py-file)
Check that the pavement.py file points to the correct release notes. It should have been updated after the last release, but if not, fix it now:

```
$ gvim pavement.py
```
### Release walkthrough[#](#release-walkthrough)
Note that in the code snippets below, `upstream`
refers to the root repository on
GitHub and `origin`
to its fork in your personal GitHub repositories. You may
need to make adjustments if you have not forked the repository but simply
cloned it locally. You can also edit `.git/config`
and add `upstream`
if it
isn’t already present.

#### 1. Prepare the release commit[#](#prepare-the-release-commit)
Checkout the branch for the release, make sure it is up to date, and clean the repository:

```
$ git checkout maintenance/1.21.x
$ git pull upstream maintenance/1.21.x
$ git submodule update
$ git clean -xdfq
```
Sanity check:

```
$ python3 -m spin test -m full
```
Tag the release and push the tag. This requires write permission for the numpy repository:

```
$ git tag -a -s v1.21.0 -m"NumPy 1.21.0 release"
$ git push upstream v1.21.0
```
If you need to delete the tag due to error:

```
$ git tag -d v1.21.0
$ git push --delete upstream v1.21.0
```
#### 2. Build wheels[#](#build-wheels)
##### Build wheels via cibuildwheel (preferred)[#](#build-wheels-via-cibuildwheel-preferred)
Tagging the build at the beginning of this process will trigger a wheel build
via cibuildwheel and upload wheels and an sdist to the staging repo. The CI run
on github actions (for all x86-based and macOS arm64 wheels) takes about 1 1/4
hours. The CI run on travis (for aarch64) takes less time. You can check for
uploaded files at the [staging repository](https://anaconda.org/multibuild-wheels-staging/numpy/files), but note that it is not closely
synched with what you see of the running jobs.

If you wish to manually trigger a wheel build, you can do so:

On github actions ->

[Wheel builder](https://github.com/numpy/numpy/actions/workflows/wheels.yml)there is a “Run workflow” button, click on it and choose the tag to build
On

[travis](https://app.travis-ci.com/github/numpy/numpy)there is a “More Options” button, click on it and choose a branch to build. There does not appear to be an option to build a tag.
If a wheel build fails for unrelated reasons, you can rerun it individually:

On github actions select

[Wheel builder](https://github.com/numpy/numpy/actions/workflows/wheels.yml)click on the commit that contains the build you want to rerun. On the left there is a list of wheel builds, select the one you want to rerun and on the resulting page hit the counterclockwise arrows button.
On

[travis](https://app.travis-ci.com/github/numpy/numpy)select the failing build, which will take you to the travis job for that build. Hit the restart job button.
Note that if you do need to rerun jobs, you will need to delete the uploaded
file, if any, in the anaconda [staging repository](https://anaconda.org/multibuild-wheels-staging/numpy/files), The old files will not be
overwritten.

#### 3. Download wheels[#](#download-wheels)
When the wheels have all been successfully built and staged, download them from the
Anaconda staging directory using the `tools/download-wheels.py`
script:

```
$ cd ../numpy
$ mkdir -p release/installers
$ python3 tools/download-wheels.py 1.21.0
```
#### 4. Generate the README files[#](#generate-the-readme-files)
This needs to be done after all installers are downloaded, but before the pavement file is updated for continued development:

```
$ paver write_release
```
#### 5. Reset the maintenance branch into a development state (skip for prereleases)[#](#reset-the-maintenance-branch-into-a-development-state-skip-for-prereleases)
Create release notes for next release and edit them to set the version. These notes will be a skeleton and have little content:

```
$ cp doc/source/release/template.rst doc/source/release/1.21.1-notes.rst
$ gvim doc/source/release/1.21.1-notes.rst
$ git add doc/source/release/1.21.1-notes.rst
```
Add new release notes to the documentation release list and update the
`RELEASE_NOTES`
variable in `pavement.py`
:

```
$ gvim doc/source/release.rst pavement.py
```
Commit the result:

```
$ git commit -a -m"REL: prepare 1.21.x for further development"
$ git push upstream HEAD
```
#### 6. Upload to PyPI[#](#upload-to-pypi)
Upload to PyPI using `twine`
. A recent version of `twine`
of is needed
after recent PyPI changes, version `3.4.1`
was used here:

```
$ cd ../numpy
$ twine upload release/installers/*.whl
$ twine upload release/installers/numpy-1.21.0.tar.gz # Upload last.
```
If one of the commands breaks in the middle, you may need to selectively upload the remaining files because PyPI does not allow the same file to be uploaded twice. The source file should be uploaded last to avoid synchronization problems that might occur if pip users access the files while this is in process, causing pip to build from source rather than downloading a binary wheel. PyPI only allows a single source distribution, here we have chosen the zip archive.

#### 7. Upload files to github[#](#upload-files-to-github)
Go to [https://github.com/numpy/numpy/releases](https://github.com/numpy/numpy/releases), there should be a ```
v1.21.0
tag
```
, click on it and hit the edit button for that tag. There are two ways to
add files, using an editable text window and as binary uploads. Start by
editing the `release/README.md`
that is translated from the rst version using
pandoc. Things that will need fixing: PR lines from the changelog, if included,
are wrapped and need unwrapping, links should be changed to monospaced text.
Then copy the contents to the clipboard and paste them into the text window. It
may take several tries to get it look right. Then

Upload

`release/installers/numpy-1.21.0.tar.gz`
as a binary file.
Upload

`release/README.rst`
as a binary file.
Upload

`doc/changelog/1.21.0-changelog.rst`
as a binary file.
Check the pre-release button if this is a pre-releases.

Hit the

`{Publish,Update} release`
button at the bottom.
#### 8. Upload documents to numpy.org (skip for prereleases)[#](#upload-documents-to-numpy-org-skip-for-prereleases)
Note

You will need a GitHub personal access token to push the update.

This step is only needed for final releases and can be skipped for pre-releases
and most patch releases. `make merge-doc`
clones the `numpy/doc`
repo into
`doc/build/merge`
and updates it with the new documentation:

```
$ git clean -xdfq
$ git co v1.21.0
$ pushd doc
$ make docenv && source docenv/bin/activate
$ make merge-doc
$ pushd build/merge
```
If the release series is a new one, you will need to add a new section to the
`doc/build/merge/index.html`
front page just after the “insert here” comment:

```
$ gvim index.html +/'insert here'
```
Further, update the version-switcher json file to add the new release and
update the version marked *(stable)*:

```
$ gvim _static/versions.json
```
Otherwise, only the `zip`
link should be updated with the new tag name. Since
we are no longer generating `pdf`
files, remove the line for the `pdf`
files if present:

```
$ gvim index.html +/'tag v1.21'
```
You can “test run” the new documentation in a browser to make sure the links work:

```
$ firefox index.html # or google-chrome, etc.
```
Update the stable link and update:

```
$ ln -sfn 1.21 stable
$ ls -l # check the link
```
Once everything seems satisfactory, update, commit and upload the changes:

```
$ python3 update.py
$ git commit -a -m"Add documentation for v1.21.0"
$ git push
$ deactivate
$ popd
$ popd
```
#### 9. Announce the release on numpy.org (skip for prereleases)[#](#announce-the-release-on-numpy-org-skip-for-prereleases)
This assumes that you have forked [https://github.com/numpy/numpy.org](https://github.com/numpy/numpy.org):

```
$ cd ../numpy.org
$ git checkout main
$ git pull upstream main
$ git checkout -b announce-numpy-1.21.0
$ gvim content/en/news.md
```
For all releases, go to the bottom of the page and add a one line link. Look to the previous links for example.

For the

`*.0`
release in a cycle, add a new section at the top with a short description of the new features and point the news link to it.
commit and push:

```
$ git commit -a -m"announce the NumPy 1.21.0 release"
$ git push origin HEAD
```
Go to your Github fork and make a pull request.

#### 10. Announce to mailing lists[#](#announce-to-mailing-lists)
The release should be announced on the numpy-discussion, scipy-devel, scipy-user, and python-announce-list mailing lists. Look at previous announcements for the basic template. The contributor and PR lists are the same as generated for the release notes above. If you crosspost, make sure that python-announce-list is BCC so that replies will not be sent to that list.

#### 11. Post-release tasks (skip for prereleases)[#](#post-release-tasks-skip-for-prereleases)
Checkout main and forward port the documentation changes:

```
$ git checkout -b post-1.21.0-release-update
$ git checkout maintenance/1.21.x doc/source/release/1.21.0-notes.rst
$ git checkout maintenance/1.21.x doc/changelog/1.21.0-changelog.rst
$ git checkout maintenance/1.21.x .mailmap # only if updated for release.
$ gvim doc/source/release.rst # Add link to new notes
$ git status # check status before commit
$ git commit -a -m"MAINT: Update main after 1.21.0 release."
$ git push origin HEAD
```
Go to GitHub and make a PR.

#### 12. Update oldest-supported-numpy[#](#update-oldest-supported-numpy)
If this release is the first one to support a new Python version, or the first
to provide wheels for a new platform or PyPy version, the version pinnings
in [https://github.com/scipy/oldest-supported-numpy](https://github.com/scipy/oldest-supported-numpy) should be updated.
Either submit a PR with changes to `setup.cfg`
there, or open an issue with
info on needed changes.

## Branch walkthrough[#](#branch-walkthrough)
This guide contains a walkthrough of branching NumPy 1.21.x on Linux. The
commands can be copied into the command line, but be sure to replace 1.21 and
1.22 by the correct versions. It is good practice to make `.mailmap`
as
current as possible before making the branch, that may take several weeks.

This should be read together with the
[general release guide](#prepare-release).

### Branching[#](#id2)
#### Make the branch[#](#make-the-branch)
This is only needed when starting a new maintenance branch. Because NumPy now depends on tags to determine the version, the start of a new development cycle in the main branch needs an annotated tag. That is done as follows:

```
$ git checkout main
$ git pull upstream main
$ git commit --allow-empty -m'REL: Begin NumPy 1.22.0 development'
$ git push upstream HEAD
```
If the push fails because new PRs have been merged, do:

```
$ git pull --rebase upstream
```
and repeat the push. Once the push succeeds, tag it:

```
$ git tag -a -s v1.22.0.dev0 -m'Begin NumPy 1.22.0 development'
$ git push upstream v1.22.0.dev0
```
then make the new branch and push it:

```
$ git branch maintenance/1.21.x HEAD^
$ git push upstream maintenance/1.21.x
```
#### Prepare the main branch for further development[#](#prepare-the-main-branch-for-further-development)
Make a PR branch to prepare main for further development:

```
$ git checkout -b 'prepare-main-for-1.22.0-development' v1.22.0.dev0
```
Delete the release note fragments:

```
$ git rm doc/release/upcoming_changes/[0-9]*.*.rst
```
Create the new release notes skeleton and add to index:

```
$ cp doc/source/release/template.rst doc/source/release/1.22.0-notes.rst
$ gvim doc/source/release/1.22.0-notes.rst # put the correct version
$ git add doc/source/release/1.22.0-notes.rst
$ gvim doc/source/release.rst # add new notes to notes index
$ git add doc/source/release.rst
```
Update `pavement.py`
and update the `RELEASE_NOTES`
variable to point to
the new notes:

```
$ gvim pavement.py
$ git add pavement.py
```
Update `cversions.txt`
to add current release. There should be no new hash
to worry about at this early point, just add a comment following previous
practice:

```
$ gvim numpy/core/code_generators/cversions.txt
$ git add numpy/core/code_generators/cversions.txt
```
Check your work, commit it, and push:

```
$ git status # check work
$ git commit -m'REL: Prepare main for NumPy 1.22.0 development'
$ git push origin HEAD
```
Now make a pull request.# NumPy C-API[#](#numpy-c-api)
*William Feather, Sr.*
*Chris Carter, The X Files*
NumPy provides a C-API to enable users to extend the system and get
access to the array object for use in other routines. The best way to
truly understand the C-API is to read the source code. If you are
unfamiliar with (C) source code, however, this can be a daunting
experience at first. Be assured that the task becomes easier with
practice, and you may be surprised at how simple the C-code can be to
understand. Even if you don’t think you can write C-code from scratch,
it is much easier to understand and modify already-written source code
than create it *de novo*.

Python extensions are especially straightforward to understand because they all have a very similar structure. Admittedly, NumPy is not a trivial extension to Python, and may take a little more snooping to grasp. This is especially true because of the code-generation techniques, which simplify maintenance of very similar code, but can make the code a little less readable to beginners. Still, with a little persistence, the code can be opened to your understanding. It is my hope, that this guide to the C-API can assist in the process of becoming familiar with the compiled-level work that can be done with NumPy in order to squeeze that last bit of necessary speed out of your code.

[Python Types and C-Structures](types-and-structures.html)
[System configuration](config.html)
[Data Type API](dtype.html)
[Array API](array.html)[Array structure and data access](array.html#array-structure-and-data-access)
[Creating arrays](array.html#creating-arrays)
[Dealing with types](array.html#dealing-with-types)
[Array flags](array.html#array-flags)
[Array method alternative API](array.html#array-method-alternative-api)
[Functions](array.html#functions)
[Auxiliary Data With Object Semantics](array.html#auxiliary-data-with-object-semantics)
[Array Iterators](array.html#array-iterators)
[Broadcasting (multi-iterators)](array.html#broadcasting-multi-iterators)
[Neighborhood iterator](array.html#neighborhood-iterator)
[Array mapping](array.html#array-mapping)
[Array Scalars](array.html#array-scalars)
[Data-type descriptors](array.html#data-type-descriptors)
[Conversion Utilities](array.html#conversion-utilities)
[Miscellaneous](array.html#miscellaneous)
[Array Iterator API](iterator.html)
[UFunc API](ufunc.html)
[Generalized Universal Function API](generalized-ufuncs.html)
[NumPy core libraries](coremath.html)
[C API Deprecations](deprecations.html)
[Memory management in NumPy](data_memory.html)# Typing (`numpy.typing`
)[#](#typing-numpy-typing)
`numpy.typing`
New in version 1.20.

Large parts of the NumPy API have [ PEP 484](https://peps.python.org/pep-0484/)-style type annotations. In
addition a number of type aliases are available to users, most prominently
the two below:

: objects that can be converted to arrays`ArrayLike`
: objects that can be converted to dtypes`DTypeLike`
## Mypy plugin[#](#mypy-plugin)
New in version 1.21.

A [mypy](http://mypy-lang.org/) plugin for managing a number of platform-specific annotations.
Its functionality can be split into three distinct parts:

Assigning the (platform-dependent) precisions of certain

subclasses, including the likes of`number`
,`int_`
and`intp`
. See the documentation on`longlong`
[scalar types](arrays.scalars.html#arrays-scalars-built-in)for a comprehensive overview of the affected classes. Without the plugin the precision of all relevant classes will be inferred as.`Any`
Removing all extended-precision

subclasses that are unavailable for the platform in question. Most notably this includes the likes of`number`
and`float128`
. Without the plugin`complex256`
*all*extended-precision types will, as far as mypy is concerned, be available to all platforms.
Assigning the (platform-dependent) precision of

. Without the plugin the type will default to`c_intp`
.`ctypes.c_int64`
New in version 1.22.

### Examples[#](#examples)
To enable the plugin, one must add it to their mypy [configuration file](https://mypy.readthedocs.io/en/stable/config_file.html):

```
[mypy]
plugins = numpy.typing.mypy_plugin
```
## Differences from the runtime NumPy API[#](#differences-from-the-runtime-numpy-api)
NumPy is very flexible. Trying to describe the full range of possibilities statically would result in types that are not very helpful. For that reason, the typed NumPy API is often stricter than the runtime NumPy API. This section describes some notable differences.

### ArrayLike[#](#arraylike)
The [ ArrayLike](#numpy.typing.ArrayLike) type tries to avoid creating object arrays. For
example,

```
>>> np.array(x**2 for x in range(10))
array(<generator object <genexpr> at ...>, dtype=object)
```
is valid NumPy code which will create a 0-dimensional object
array. Type checkers will complain about the above example when using
the NumPy types however. If you really intended to do the above, then
you can either use a `# type: ignore`
comment:

```
>>> np.array(x**2 for x in range(10)) # type: ignore
```
or explicitly type the array like object as [ Any](https://docs.python.org/3/library/typing.html#typing.Any):

```
>>> from typing import Any
>>> array_like: Any = (x**2 for x in range(10))
>>> np.array(array_like)
array(<generator object <genexpr> at ...>, dtype=object)
```
### ndarray[#](#ndarray)
It’s possible to mutate the dtype of an array at runtime. For example, the following code is valid:

```
>>> x = np.array([1, 2])
>>> x.dtype = np.bool_
```
This sort of mutation is not allowed by the types. Users who want to
write statically typed code should instead use the [ numpy.ndarray.view](generated/numpy.ndarray.view.html#numpy.ndarray.view)
method to create a view of the array with a different dtype.

### DTypeLike[#](#dtypelike)
The [ DTypeLike](#numpy.typing.DTypeLike) type tries to avoid creation of dtype objects using
dictionary of fields like below:

```
>>> x = np.dtype({"field1": (float, 1), "field2": (int, 3)})
```
Although this is valid NumPy code, the type checker will complain about it,
since its usage is discouraged.
Please see : [Data type objects](arrays.dtypes.html#arrays-dtypes)

### Number precision[#](#number-precision)
The precision of [ numpy.number](arrays.scalars.html#numpy.number) subclasses is treated as a covariant generic
parameter (see

[), simplifying the annotating of processes involving precision-based casting.](#numpy.typing.NBitBase)
`NBitBase`
```
>>> from typing import TypeVar
>>> import numpy as np
>>> import numpy.typing as npt
>>> T = TypeVar("T", bound=npt.NBitBase)
>>> def func(a: "np.floating[T]", b: "np.floating[T]") -> "np.floating[T]":
... ...
```
Consequently, the likes of [ float16](arrays.scalars.html#numpy.float16),

[and](arrays.scalars.html#numpy.float32)
`float32`
[are still sub-types of](arrays.scalars.html#numpy.float64)
`float64`
[, but, contrary to runtime, they’re not necessarily considered as sub-classes.](arrays.scalars.html#numpy.floating)
`floating`
### Timedelta64[#](#timedelta64)
The [ timedelta64](arrays.scalars.html#numpy.timedelta64) class is not considered a subclass of

[, the former only inheriting from](arrays.scalars.html#numpy.signedinteger)
`signedinteger`
[while static type checking.](arrays.scalars.html#numpy.generic)
`generic`
### 0D arrays[#](#d-arrays)
During runtime numpy aggressively casts any passed 0D arrays into their
corresponding [ generic](arrays.scalars.html#numpy.generic) instance. Until the introduction of shape
typing (see

[) it is unfortunately not possible to make the necessary distinction between 0D and >0D arrays. While thus not strictly correct, all operations are that can potentially perform a 0D-array -> scalar cast are currently annotated as exclusively returning an](https://peps.python.org/pep-0646/)
**PEP 646***ndarray*.
If it is known in advance that an operation _will_ perform a
0D-array -> scalar cast, then one can consider manually remedying the
situation with either [ typing.cast](https://docs.python.org/3/library/typing.html#typing.cast) or a

`# type: ignore`
comment.### Record array dtypes[#](#record-array-dtypes)
The dtype of [ numpy.recarray](generated/numpy.recarray.html#numpy.recarray), and the

`numpy.rec`
functions in general,
can be specified in one of two ways:Directly via the

`dtype`
argument.
With up to five helper arguments that operate via

:`numpy.format_parser`
`formats`
,`names`
,`titles`
,`aligned`
and`byteorder`
.
These two approaches are currently typed as being mutually exclusive,
*i.e.* if `dtype`
is specified than one may not specify `formats`
.
While this mutual exclusivity is not (strictly) enforced during runtime,
combining both dtype specifiers can lead to unexpected or even downright
buggy behavior.

## API[#](#api)
numpy.typing.ArrayLike*= typing.Union[...]*[#](#numpy.typing.ArrayLike)
-
A

representing objects that can be coerced into an`Union`
.`ndarray`
Among others this includes the likes of:

Scalars.

(Nested) sequences.

Objects implementing the

*__array__*protocol.
New in version 1.20.

See Also

[array_like](../glossary.html#term-array_like):
Any scalar or sequence that can be interpreted as an ndarray.

Examples

>>> import numpy as np >>> import numpy.typing as npt >>> def as_array(a: npt.ArrayLike) -> np.ndarray: ... return np.array(a)
numpy.typing.DTypeLike*= typing.Union[...]*[#](#numpy.typing.DTypeLike)
-
A

representing objects that can be coerced into a`Union`
.`dtype`
Among others this includes the likes of:

New in version 1.20.

See Also

[Specifying and constructing data types](arrays.dtypes.html#arrays-dtypes-constructing)
A comprehensive overview of all objects that can be coerced into data types.

Examples

>>> import numpy as np >>> import numpy.typing as npt >>> def as_dtype(d: npt.DTypeLike) -> np.dtype: ... return np.dtype(d)
numpy.typing.NDArray*= numpy.ndarray[typing.Any, numpy.dtype[+_ScalarType_co]]*[#](#numpy.typing.NDArray)
-
A

[generic](https://docs.python.org/3/glossary.html#term-generic-type)version of.`np.ndarray[Any, np.dtype[+ScalarType]]`
Can be used during runtime for typing arrays with a given dtype and unspecified shape.

New in version 1.21.

Examples

>>> import numpy as np >>> import numpy.typing as npt >>> print(npt.NDArray) numpy.ndarray[typing.Any, numpy.dtype[+ScalarType]] >>> print(npt.NDArray[np.float64]) numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]] >>> NDArrayInt = npt.NDArray[np.int_] >>> a: NDArrayInt = np.arange(10) >>> def func(a: npt.ArrayLike) -> npt.NDArray[Any]: ... return np.array(a)
*class*numpy.typing.NBitBase[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/typing/__init__.py)[#](#numpy.typing.NBitBase)
-
A type representing

precision during static type checking.`numpy.number`
Used exclusively for the purpose static type checking,

represents the base of a hierarchical set of subclasses. Each subsequent subclass is herein used for representing a lower level of precision,`NBitBase`
*e.g.*`64Bit > 32Bit > 16Bit`
.New in version 1.20.

Examples

Below is a typical usage example:

is herein used for annotating a function that takes a float and integer of arbitrary precision as arguments and returns a new float of whichever precision is largest (`NBitBase`
*e.g.*`np.float16 + np.int64 -> np.float64`
).>>> from __future__ import annotations >>> from typing import TypeVar, TYPE_CHECKING >>> import numpy as np >>> import numpy.typing as npt >>> T1 = TypeVar("T1", bound=npt.NBitBase) >>> T2 = TypeVar("T2", bound=npt.NBitBase) >>> def add(a: np.floating[T1], b: np.integer[T2]) -> np.floating[T1 | T2]: ... return a + b >>> a = np.float16() >>> b = np.int64() >>> out = add(a, b) >>> if TYPE_CHECKING: ... reveal_locals() ... # note: Revealed local types are: ... # note: a: numpy.floating[numpy.typing._16Bit*] ... # note: b: numpy.signedinteger[numpy.typing._64Bit*] ... # note: out: numpy.floating[numpy.typing._64Bit*]Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# NumPy documentation[#](#numpy-documentation)
**Version**: 1.26
**Download documentation**:
[Historical versions of documentation](https://numpy.org/doc/)
**Useful links**:
[Installation](https://numpy.org/install/) |
[Source Repository](https://github.com/numpy/numpy) |
[Issue Tracker](https://github.com/numpy/numpy/issues) |
[Q&A Support](https://numpy.org/gethelp/) |
[Mailing List](https://mail.python.org/mailman/listinfo/numpy-discussion)
NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.

Getting Started

New to NumPy? Check out the Absolute Beginner’s Guide. It contains an introduction to NumPy’s main concepts and links to additional tutorials.

User Guide

The user guide provides in-depth information on the key concepts of NumPy with useful background information and explanation.

API Reference

The reference guide contains a detailed description of the functions, modules, and objects included in NumPy. The reference describes how the methods work and which parameters can be used. It assumes that you have an understanding of the key concepts.

Contributor’s Guide

Want to add to the codebase? Can help add translation or a flowchart to the documentation? The contributing guidelines will guide you through the process of improving NumPy.# NumPy: the absolute basics for beginners[#](#numpy-the-absolute-basics-for-beginners)
Welcome to the absolute beginner’s guide to NumPy! If you have comments or
suggestions, please don’t hesitate to [reach out](https://numpy.org/community/)!

## Welcome to NumPy![#](#welcome-to-numpy)
NumPy (**Numerical Python**) is an open source Python library that’s used in
almost every field of science and engineering. It’s the universal standard for
working with numerical data in Python, and it’s at the core of the scientific
Python and PyData ecosystems. NumPy users include everyone from beginning coders
to experienced researchers doing state-of-the-art scientific and industrial
research and development. The NumPy API is used extensively in Pandas, SciPy,
Matplotlib, scikit-learn, scikit-image and most other data science and
scientific Python packages.

The NumPy library contains multidimensional array and matrix data structures
(you’ll find more information about this in later sections). It provides
**ndarray**, a homogeneous n-dimensional array object, with methods to
efficiently operate on it. NumPy can be used to perform a wide variety of
mathematical operations on arrays. It adds powerful data structures to Python
that guarantee efficient calculations with arrays and matrices and it supplies
an enormous library of high-level mathematical functions that operate on these
arrays and matrices.

Learn more about [NumPy here](whatisnumpy.html#whatisnumpy)!

## Installing NumPy[#](#installing-numpy)
To install NumPy, we strongly recommend using a scientific Python distribution.
If you’re looking for the full instructions for installing NumPy on your
operating system, see [Installing NumPy](https://numpy.org/install/).

If you already have Python, you can install NumPy with:

```
conda install numpy
```
or

```
pip install numpy
```
If you don’t have Python yet, you might want to consider using [Anaconda](https://www.anaconda.com/). It’s the easiest way to get started. The good
thing about getting this distribution is the fact that you don’t need to worry
too much about separately installing NumPy or any of the major packages that
you’ll be using for your data analyses, like pandas, Scikit-Learn, etc.

## How to import NumPy[#](#how-to-import-numpy)
To access NumPy and its functions import it in your Python code like this:

```
import numpy as np
```
We shorten the imported name to `np`
for better readability of code using
NumPy. This is a widely adopted convention that makes your code more readable
for everyone working on it. We recommend to always use import numpy as `np`
.

## Reading the example code[#](#reading-the-example-code)
If you aren’t already comfortable with reading tutorials that contain a lot of code, you might not know how to interpret a code block that looks like this:

```
>>> a = np.arange(6)
>>> a2 = a[np.newaxis, :]
>>> a2.shape
(1, 6)
```
If you aren’t familiar with this style, it’s very easy to understand.
If you see `>>>`
, you’re looking at **input**, or the code that
you would enter. Everything that doesn’t have `>>>`
in front of it
is **output**, or the results of running your code. This is the style
you see when you run `python`
on the command line, but if you’re using
IPython, you might see a different style. Note that it is not part of the
code and will cause an error if typed or pasted into the Python
shell. It can be safely typed or pasted into the IPython shell; the `>>>`
is ignored.

## What’s the difference between a Python list and a NumPy array?[#](#whats-the-difference-between-a-python-list-and-a-numpy-array)
NumPy gives you an enormous range of fast and efficient ways of creating arrays and manipulating numerical data inside them. While a Python list can contain different data types within a single list, all of the elements in a NumPy array should be homogeneous. The mathematical operations that are meant to be performed on arrays would be extremely inefficient if the arrays weren’t homogeneous.

**Why use NumPy?**
NumPy arrays are faster and more compact than Python lists. An array consumes less memory and is convenient to use. NumPy uses much less memory to store data and it provides a mechanism of specifying the data types. This allows the code to be optimized even further.

## What is an array?[#](#what-is-an-array)
An array is a central data structure of the NumPy library. An array is a grid of
values and it contains information about the raw data, how to locate an element,
and how to interpret an element. It has a grid of elements that can be indexed
in [various ways](quickstart.html#quickstart-indexing-slicing-and-iterating).
The elements are all of the same type, referred to as the array `dtype`
.

An array can be indexed by a tuple of nonnegative integers, by booleans, by
another array, or by integers. The `rank`
of the array is the number of
dimensions. The `shape`
of the array is a tuple of integers giving the size of
the array along each dimension.

One way we can initialize NumPy arrays is from Python lists, using nested lists for two- or higher-dimensional data.

For example:

```
>>> a = np.array([1, 2, 3, 4, 5, 6])
```
or:

```
>>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
```
We can access the elements in the array using square brackets. When you’re accessing elements, remember that indexing in NumPy starts at 0. That means that if you want to access the first element in your array, you’ll be accessing element “0”.

```
>>> print(a[0])
[1 2 3 4]
```
## More information about arrays[#](#more-information-about-arrays)
*This section covers* `1D array`
, `2D array`
, `ndarray`
, `vector`
, `matrix`
You might occasionally hear an array referred to as a “ndarray,” which is
shorthand for “N-dimensional array.” An N-dimensional array is simply an array
with any number of dimensions. You might also hear **1-D**, or one-dimensional
array, **2-D**, or two-dimensional array, and so on. The NumPy `ndarray`
class
is used to represent both matrices and vectors. A **vector** is an array with a
single dimension (there’s no difference
between row and column vectors), while a **matrix** refers to an
array with two dimensions. For **3-D** or higher dimensional arrays, the term
**tensor** is also commonly used.

**What are the attributes of an array?**
An array is usually a fixed-size container of items of the same type and size. The number of dimensions and items in an array is defined by its shape. The shape of an array is a tuple of non-negative integers that specify the sizes of each dimension.

In NumPy, dimensions are called **axes**. This means that if you have a 2D array
that looks like this:

```
[[0., 0., 0.],
[1., 1., 1.]]
```
Your array has 2 axes. The first axis has a length of 2 and the second axis has a length of 3.

Just like in other Python container objects, the contents of an array can be accessed and modified by indexing or slicing the array. Unlike the typical container objects, different arrays can share the same data, so changes made on one array might be visible in another.

Array **attributes** reflect information intrinsic to the array itself. If you
need to get, or even set, properties of an array without creating a new array,
you can often access an array through its attributes.

[Read more about array attributes here](../reference/arrays.ndarray.html#arrays-ndarray) and learn about
[array objects here](../reference/arrays.html#arrays).
## How to create a basic array[#](#how-to-create-a-basic-array)
*This section covers* `np.array()`
, `np.zeros()`
, `np.ones()`
,
`np.empty()`
, `np.arange()`
, `np.linspace()`
, `dtype`
To create a NumPy array, you can use the function `np.array()`
.

All you need to do to create a simple array is pass a list to it. If you choose
to, you can also specify the type of data in your list.
[You can find more information about data types here](../reference/arrays.dtypes.html#arrays-dtypes).

```
>>> import numpy as np
>>> a = np.array([1, 2, 3])
```
You can visualize your array this way:

*Be aware that these visualizations are meant to simplify ideas and give you a basic understanding of NumPy concepts and mechanics. Arrays and array operations are much more complicated than are captured here!*
Besides creating an array from a sequence of elements, you can easily create an
array filled with `0`
’s:

```
>>> np.zeros(2)
array([0., 0.])
```
Or an array filled with `1`
’s:

```
>>> np.ones(2)
array([1., 1.])
```
Or even an empty array! The function `empty`
creates an array whose initial
content is random and depends on the state of the memory. The reason to use
`empty`
over `zeros`
(or something similar) is speed - just make sure to
fill every element afterwards!

```
>>> # Create an empty array with 2 elements
>>> np.empty(2)
array([3.14, 42. ]) # may vary
```
You can create an array with a range of elements:

```
>>> np.arange(4)
array([0, 1, 2, 3])
```
And even an array that contains a range of evenly spaced intervals. To do this,
you will specify the **first number**, **last number**, and the **step size**.

```
>>> np.arange(2, 9, 2)
array([2, 4, 6, 8])
```
You can also use `np.linspace()`
to create an array with values that are
spaced linearly in a specified interval:

```
>>> np.linspace(0, 10, num=5)
array([ 0. , 2.5, 5. , 7.5, 10. ])
```
**Specifying your data type**
While the default data type is floating point (`np.float64`
), you can explicitly
specify which data type you want using the `dtype`
keyword.

```
>>> x = np.ones(2, dtype=np.int64)
>>> x
array([1, 1])
```
## Adding, removing, and sorting elements[#](#adding-removing-and-sorting-elements)
*This section covers* `np.sort()`
, `np.concatenate()`
Sorting an element is simple with `np.sort()`
. You can specify the axis, kind,
and order when you call the function.

If you start with this array:

```
>>> arr = np.array([2, 1, 5, 3, 7, 4, 6, 8])
```
You can quickly sort the numbers in ascending order with:

```
>>> np.sort(arr)
array([1, 2, 3, 4, 5, 6, 7, 8])
```
In addition to sort, which returns a sorted copy of an array, you can use:

, which is an indirect sort along a specified axis,`argsort`
, which is an indirect stable sort on multiple keys,`lexsort`
, which will find elements in a sorted array, and`searchsorted`
, which is a partial sort.`partition`
To read more about sorting an array, see: [ sort](../reference/generated/numpy.sort.html#numpy.sort).

If you start with these arrays:

```
>>> a = np.array([1, 2, 3, 4])
>>> b = np.array([5, 6, 7, 8])
```
You can concatenate them with `np.concatenate()`
.

```
>>> np.concatenate((a, b))
array([1, 2, 3, 4, 5, 6, 7, 8])
```
Or, if you start with these arrays:

```
>>> x = np.array([[1, 2], [3, 4]])
>>> y = np.array([[5, 6]])
```
You can concatenate them with:

```
>>> np.concatenate((x, y), axis=0)
array([[1, 2],
[3, 4],
[5, 6]])
```
In order to remove elements from an array, it’s simple to use indexing to select the elements that you want to keep.

To read more about concatenate, see: [ concatenate](../reference/generated/numpy.concatenate.html#numpy.concatenate).

## How do you know the shape and size of an array?[#](#how-do-you-know-the-shape-and-size-of-an-array)
*This section covers* `ndarray.ndim`
, `ndarray.size`
, `ndarray.shape`
`ndarray.ndim`
will tell you the number of axes, or dimensions, of the array.
`ndarray.size`
will tell you the total number of elements of the array. This
is the *product* of the elements of the array’s shape.
`ndarray.shape`
will display a tuple of integers that indicate the number of
elements stored along each dimension of the array. If, for example, you have a
2-D array with 2 rows and 3 columns, the shape of your array is `(2, 3)`
.
For example, if you create this array:

```
>>> array_example = np.array([[[0, 1, 2, 3],
... [4, 5, 6, 7]],
...
... [[0, 1, 2, 3],
... [4, 5, 6, 7]],
...
... [[0 ,1 ,2, 3],
... [4, 5, 6, 7]]])
```
To find the number of dimensions of the array, run:

```
>>> array_example.ndim
3
```
To find the total number of elements in the array, run:

```
>>> array_example.size
24
```
And to find the shape of your array, run:

```
>>> array_example.shape
(3, 2, 4)
```
## Can you reshape an array?[#](#can-you-reshape-an-array)
*This section covers* `arr.reshape()`
**Yes!**
Using `arr.reshape()`
will give a new shape to an array without changing the
data. Just remember that when you use the reshape method, the array you want to
produce needs to have the same number of elements as the original array. If you
start with an array with 12 elements, you’ll need to make sure that your new
array also has a total of 12 elements.

If you start with this array:

```
>>> a = np.arange(6)
>>> print(a)
[0 1 2 3 4 5]
```
You can use `reshape()`
to reshape your array. For example, you can reshape
this array to an array with three rows and two columns:

```
>>> b = a.reshape(3, 2)
>>> print(b)
[[0 1]
[2 3]
[4 5]]
```
With `np.reshape`
, you can specify a few optional parameters:

```
>>> np.reshape(a, newshape=(1, 6), order='C')
array([[0, 1, 2, 3, 4, 5]])
```
`a`
is the array to be reshaped.
`newshape`
is the new shape you want. You can specify an integer or a tuple of
integers. If you specify an integer, the result will be an array of that length.
The shape should be compatible with the original shape.
`order:`
`C`
means to read/write the elements using C-like index order,
`F`
means to read/write the elements using Fortran-like index order, `A`
means to read/write the elements in Fortran-like index order if a is Fortran
contiguous in memory, C-like order otherwise. (This is an optional parameter and
doesn’t need to be specified.)
If you want to learn more about C and Fortran order, you can
[read more about the internal organization of NumPy arrays here](../dev/internals.html#numpy-internals).
Essentially, C and Fortran orders have to do with how indices correspond
to the order the array is stored in memory. In Fortran, when moving through
the elements of a two-dimensional array as it is stored in memory, the **first**
index is the most rapidly varying index. As the first index moves to the next
row as it changes, the matrix is stored one column at a time.
This is why Fortran is thought of as a **Column-major language**.
In C on the other hand, the **last** index changes
the most rapidly. The matrix is stored by rows, making it a **Row-major
language**. What you do for C or Fortran depends on whether it’s more important
to preserve the indexing convention or not reorder the data.

## How to convert a 1D array into a 2D array (how to add a new axis to an array)[#](#how-to-convert-a-1d-array-into-a-2d-array-how-to-add-a-new-axis-to-an-array)
*This section covers* `np.newaxis`
, `np.expand_dims`
You can use `np.newaxis`
and `np.expand_dims`
to increase the dimensions of
your existing array.

Using `np.newaxis`
will increase the dimensions of your array by one dimension
when used once. This means that a **1D** array will become a **2D** array, a
**2D** array will become a **3D** array, and so on.

For example, if you start with this array:

```
>>> a = np.array([1, 2, 3, 4, 5, 6])
>>> a.shape
(6,)
```
You can use `np.newaxis`
to add a new axis:

```
>>> a2 = a[np.newaxis, :]
>>> a2.shape
(1, 6)
```
You can explicitly convert a 1D array with either a row vector or a column
vector using `np.newaxis`
. For example, you can convert a 1D array to a row
vector by inserting an axis along the first dimension:

```
>>> row_vector = a[np.newaxis, :]
>>> row_vector.shape
(1, 6)
```
Or, for a column vector, you can insert an axis along the second dimension:

```
>>> col_vector = a[:, np.newaxis]
>>> col_vector.shape
(6, 1)
```
You can also expand an array by inserting a new axis at a specified position
with `np.expand_dims`
.

For example, if you start with this array:

```
>>> a = np.array([1, 2, 3, 4, 5, 6])
>>> a.shape
(6,)
```
You can use `np.expand_dims`
to add an axis at index position 1 with:

```
>>> b = np.expand_dims(a, axis=1)
>>> b.shape
(6, 1)
```
You can add an axis at index position 0 with:

```
>>> c = np.expand_dims(a, axis=0)
>>> c.shape
(1, 6)
```
Find more information about [newaxis here](../reference/arrays.indexing.html#arrays-indexing) and
`expand_dims`
at [ expand_dims](../reference/generated/numpy.expand_dims.html#numpy.expand_dims).

## Indexing and slicing[#](#indexing-and-slicing)
You can index and slice NumPy arrays in the same ways you can slice Python lists.

```
>>> data = np.array([1, 2, 3])
>>> data[1]
2
>>> data[0:2]
array([1, 2])
>>> data[1:]
array([2, 3])
>>> data[-2:]
array([2, 3])
```
You can visualize it this way:

You may want to take a section of your array or specific array elements to use in further analysis or additional operations. To do that, you’ll need to subset, slice, and/or index your arrays.

If you want to select values from your array that fulfill certain conditions, it’s straightforward with NumPy.

For example, if you start with this array:

```
>>> a = np.array([[1 , 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
```
You can easily print all of the values in the array that are less than 5.

```
>>> print(a[a < 5])
[1 2 3 4]
```
You can also select, for example, numbers that are equal to or greater than 5, and use that condition to index an array.

```
>>> five_up = (a >= 5)
>>> print(a[five_up])
[ 5 6 7 8 9 10 11 12]
```
You can select elements that are divisible by 2:

```
>>> divisible_by_2 = a[a%2==0]
>>> print(divisible_by_2)
[ 2 4 6 8 10 12]
```
Or you can select elements that satisfy two conditions using the `&`
and `|`
operators:

```
>>> c = a[(a > 2) & (a < 11)]
>>> print(c)
[ 3 4 5 6 7 8 9 10]
```
You can also make use of the logical operators **&** and **|** in order to
return boolean values that specify whether or not the values in an array fulfill
a certain condition. This can be useful with arrays that contain names or other
categorical values.

```
>>> five_up = (a > 5) | (a == 5)
>>> print(five_up)
[[False False False False]
[ True True True True]
[ True True True True]]
```
You can also use `np.nonzero()`
to select elements or indices from an array.

Starting with this array:

```
>>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
```
You can use `np.nonzero()`
to print the indices of elements that are, for
example, less than 5:

```
>>> b = np.nonzero(a < 5)
>>> print(b)
(array([0, 0, 0, 0]), array([0, 1, 2, 3]))
```
In this example, a tuple of arrays was returned: one for each dimension. The first array represents the row indices where these values are found, and the second array represents the column indices where the values are found.

If you want to generate a list of coordinates where the elements exist, you can zip the arrays, iterate over the list of coordinates, and print them. For example:

```
>>> list_of_coordinates= list(zip(b[0], b[1]))
>>> for coord in list_of_coordinates:
... print(coord)
(0, 0)
(0, 1)
(0, 2)
(0, 3)
```
You can also use `np.nonzero()`
to print the elements in an array that are less
than 5 with:

```
>>> print(a[b])
[1 2 3 4]
```
If the element you’re looking for doesn’t exist in the array, then the returned array of indices will be empty. For example:

```
>>> not_there = np.nonzero(a == 42)
>>> print(not_there)
(array([], dtype=int64), array([], dtype=int64))
```
Learn more about [indexing and slicing here](quickstart.html#quickstart-indexing-slicing-and-iterating)
and [here](basics.indexing.html#basics-indexing).

Read more about using the nonzero function at: [ nonzero](../reference/generated/numpy.nonzero.html#numpy.nonzero).

## How to create an array from existing data[#](#how-to-create-an-array-from-existing-data)
*This section covers* `slicing and indexing`
, `np.vstack()`
, `np.hstack()`
,
`np.hsplit()`
, `.view()`
, `copy()`
You can easily create a new array from a section of an existing array.

Let’s say you have this array:

```
>>> a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
```
You can create a new array from a section of your array any time by specifying where you want to slice your array.

```
>>> arr1 = a[3:8]
>>> arr1
array([4, 5, 6, 7, 8])
```
Here, you grabbed a section of your array from index position 3 through index position 8.

You can also stack two existing arrays, both vertically and horizontally. Let’s
say you have two arrays, `a1`
and `a2`
:

```
>>> a1 = np.array([[1, 1],
... [2, 2]])
>>> a2 = np.array([[3, 3],
... [4, 4]])
```
You can stack them vertically with `vstack`
:

```
>>> np.vstack((a1, a2))
array([[1, 1],
[2, 2],
[3, 3],
[4, 4]])
```
Or stack them horizontally with `hstack`
:

```
>>> np.hstack((a1, a2))
array([[1, 1, 3, 3],
[2, 2, 4, 4]])
```
You can split an array into several smaller arrays using `hsplit`
. You can
specify either the number of equally shaped arrays to return or the columns
*after* which the division should occur.

Let’s say you have this array:

```
>>> x = np.arange(1, 25).reshape(2, 12)
>>> x
array([[ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],
[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]])
```
If you wanted to split this array into three equally shaped arrays, you would run:

```
>>> np.hsplit(x, 3)
[array([[ 1, 2, 3, 4],
[13, 14, 15, 16]]), array([[ 5, 6, 7, 8],
[17, 18, 19, 20]]), array([[ 9, 10, 11, 12],
[21, 22, 23, 24]])]
```
If you wanted to split your array after the third and fourth column, you’d run:

```
>>> np.hsplit(x, (3, 4))
[array([[ 1, 2, 3],
[13, 14, 15]]), array([[ 4],
[16]]), array([[ 5, 6, 7, 8, 9, 10, 11, 12],
[17, 18, 19, 20, 21, 22, 23, 24]])]
```
[Learn more about stacking and splitting arrays here](quickstart.html#quickstart-stacking-arrays).
You can use the `view`
method to create a new array object that looks at the
same data as the original array (a *shallow copy*).

Views are an important NumPy concept! NumPy functions, as well as operations like indexing and slicing, will return views whenever possible. This saves memory and is faster (no copy of the data has to be made). However it’s important to be aware of this - modifying data in a view also modifies the original array!

Let’s say you create this array:

```
>>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
```
Now we create an array `b1`
by slicing `a`
and modify the first element of
`b1`
. This will modify the corresponding element in `a`
as well!

```
>>> b1 = a[0, :]
>>> b1
array([1, 2, 3, 4])
>>> b1[0] = 99
>>> b1
array([99, 2, 3, 4])
>>> a
array([[99, 2, 3, 4],
[ 5, 6, 7, 8],
[ 9, 10, 11, 12]])
```
Using the `copy`
method will make a complete copy of the array and its data (a
*deep copy*). To use this on your array, you could run:

```
>>> b2 = a.copy()
```
## Basic array operations[#](#basic-array-operations)
*This section covers addition, subtraction, multiplication, division, and more*
Once you’ve created your arrays, you can start to work with them. Let’s say, for example, that you’ve created two arrays, one called “data” and one called “ones”

You can add the arrays together with the plus sign.

```
>>> data = np.array([1, 2])
>>> ones = np.ones(2, dtype=int)
>>> data + ones
array([2, 3])
```
You can, of course, do more than just addition!

```
>>> data - ones
array([0, 1])
>>> data * data
array([1, 4])
>>> data / data
array([1., 1.])
```
Basic operations are simple with NumPy. If you want to find the sum of the
elements in an array, you’d use `sum()`
. This works for 1D arrays, 2D arrays,
and arrays in higher dimensions.

```
>>> a = np.array([1, 2, 3, 4])
>>> a.sum()
10
```
To add the rows or the columns in a 2D array, you would specify the axis.

If you start with this array:

```
>>> b = np.array([[1, 1], [2, 2]])
```
You can sum over the axis of rows with:

```
>>> b.sum(axis=0)
array([3, 3])
```
You can sum over the axis of columns with:

```
>>> b.sum(axis=1)
array([2, 4])
```
## Broadcasting[#](#broadcasting)
There are times when you might want to carry out an operation between an array
and a single number (also called *an operation between a vector and a scalar*)
or between arrays of two different sizes. For example, your array (we’ll call it
“data”) might contain information about distance in miles but you want to
convert the information to kilometers. You can perform this operation with:

```
>>> data = np.array([1.0, 2.0])
>>> data * 1.6
array([1.6, 3.2])
```
NumPy understands that the multiplication should happen with each cell. That
concept is called **broadcasting**. Broadcasting is a mechanism that allows
NumPy to perform operations on arrays of different shapes. The dimensions of
your array must be compatible, for example, when the dimensions of both arrays
are equal or when one of them is 1. If the dimensions are not compatible, you
will get a `ValueError`
.

## More useful array operations[#](#more-useful-array-operations)
*This section covers maximum, minimum, sum, mean, product, standard deviation, and more*
NumPy also performs aggregation functions. In addition to `min`
, `max`
, and
`sum`
, you can easily run `mean`
to get the average, `prod`
to get the
result of multiplying the elements together, `std`
to get the standard
deviation, and more.

```
>>> data.max()
2.0
>>> data.min()
1.0
>>> data.sum()
3.0
```
Let’s start with this array, called “a”

```
>>> a = np.array([[0.45053314, 0.17296777, 0.34376245, 0.5510652],
... [0.54627315, 0.05093587, 0.40067661, 0.55645993],
... [0.12697628, 0.82485143, 0.26590556, 0.56917101]])
```
It’s very common to want to aggregate along a row or column. By default, every NumPy aggregation function will return the aggregate of the entire array. To find the sum or the minimum of the elements in your array, run:

```
>>> a.sum()
4.8595784
```
Or:

```
>>> a.min()
0.05093587
```
You can specify on which axis you want the aggregation function to be computed.
For example, you can find the minimum value within each column by specifying
`axis=0`
.

```
>>> a.min(axis=0)
array([0.12697628, 0.05093587, 0.26590556, 0.5510652 ])
```
The four values listed above correspond to the number of columns in your array. With a four-column array, you will get four values as your result.

Read more about [array methods here](../reference/arrays.ndarray.html#array-ndarray-methods).

## Creating matrices[#](#creating-matrices)
You can pass Python lists of lists to create a 2-D array (or “matrix”) to represent them in NumPy.

```
>>> data = np.array([[1, 2], [3, 4], [5, 6]])
>>> data
array([[1, 2],
[3, 4],
[5, 6]])
```
Indexing and slicing operations are useful when you’re manipulating matrices:

```
>>> data[0, 1]
2
>>> data[1:3]
array([[3, 4],
[5, 6]])
>>> data[0:2, 0]
array([1, 3])
```
You can aggregate matrices the same way you aggregated vectors:

```
>>> data.max()
6
>>> data.min()
1
>>> data.sum()
21
```
You can aggregate all the values in a matrix and you can aggregate them across
columns or rows using the `axis`
parameter. To illustrate this point, let’s
look at a slightly modified dataset:

```
>>> data = np.array([[1, 2], [5, 3], [4, 6]])
>>> data
array([[1, 2],
[5, 3],
[4, 6]])
>>> data.max(axis=0)
array([5, 6])
>>> data.max(axis=1)
array([2, 5, 6])
```
Once you’ve created your matrices, you can add and multiply them using arithmetic operators if you have two matrices that are the same size.

```
>>> data = np.array([[1, 2], [3, 4]])
>>> ones = np.array([[1, 1], [1, 1]])
>>> data + ones
array([[2, 3],
[4, 5]])
```
You can do these arithmetic operations on matrices of different sizes, but only if one matrix has only one column or one row. In this case, NumPy will use its broadcast rules for the operation.

```
>>> data = np.array([[1, 2], [3, 4], [5, 6]])
>>> ones_row = np.array([[1, 1]])
>>> data + ones_row
array([[2, 3],
[4, 5],
[6, 7]])
```
Be aware that when NumPy prints N-dimensional arrays, the last axis is looped over the fastest while the first axis is the slowest. For instance:

```
>>> np.ones((4, 3, 2))
array([[[1., 1.],
[1., 1.],
[1., 1.]],
[[1., 1.],
[1., 1.],
[1., 1.]],
[[1., 1.],
[1., 1.],
[1., 1.]],
[[1., 1.],
[1., 1.],
[1., 1.]]])
```
There are often instances where we want NumPy to initialize the values of an
array. NumPy offers functions like `ones()`
and `zeros()`
, and the
`random.Generator`
class for random number generation for that.
All you need to do is pass in the number of elements you want it to generate:

```
>>> np.ones(3)
array([1., 1., 1.])
>>> np.zeros(3)
array([0., 0., 0.])
>>> rng = np.random.default_rng() # the simplest way to generate random numbers
>>> rng.random(3)
array([0.63696169, 0.26978671, 0.04097352])
```
You can also use `ones()`
, `zeros()`
, and `random()`
to create
a 2D array if you give them a tuple describing the dimensions of the matrix:

```
>>> np.ones((3, 2))
array([[1., 1.],
[1., 1.],
[1., 1.]])
>>> np.zeros((3, 2))
array([[0., 0.],
[0., 0.],
[0., 0.]])
>>> rng.random((3, 2))
array([[0.01652764, 0.81327024],
[0.91275558, 0.60663578],
[0.72949656, 0.54362499]]) # may vary
```
Read more about creating arrays, filled with `0`
’s, `1`
’s, other values or
uninitialized, at [array creation routines](../reference/routines.array-creation.html#routines-array-creation).

## Generating random numbers[#](#generating-random-numbers)
The use of random number generation is an important part of the configuration and evaluation of many numerical and machine learning algorithms. Whether you need to randomly initialize weights in an artificial neural network, split data into random sets, or randomly shuffle your dataset, being able to generate random numbers (actually, repeatable pseudo-random numbers) is essential.

With `Generator.integers`
, you can generate random integers from low (remember
that this is inclusive with NumPy) to high (exclusive). You can set
`endpoint=True`
to make the high number inclusive.

You can generate a 2 x 4 array of random integers between 0 and 4 with:

```
>>> rng.integers(5, size=(2, 4))
array([[2, 1, 1, 0],
[0, 0, 0, 4]]) # may vary
```
## How to get unique items and counts[#](#how-to-get-unique-items-and-counts)
*This section covers* `np.unique()`
You can find the unique elements in an array easily with `np.unique`
.

For example, if you start with this array:

```
>>> a = np.array([11, 11, 12, 13, 14, 15, 16, 17, 12, 13, 11, 14, 18, 19, 20])
```
you can use `np.unique`
to print the unique values in your array:

```
>>> unique_values = np.unique(a)
>>> print(unique_values)
[11 12 13 14 15 16 17 18 19 20]
```
To get the indices of unique values in a NumPy array (an array of first index
positions of unique values in the array), just pass the `return_index`
argument in `np.unique()`
as well as your array.

```
>>> unique_values, indices_list = np.unique(a, return_index=True)
>>> print(indices_list)
[ 0 2 3 4 5 6 7 12 13 14]
```
You can pass the `return_counts`
argument in `np.unique()`
along with your
array to get the frequency count of unique values in a NumPy array.

```
>>> unique_values, occurrence_count = np.unique(a, return_counts=True)
>>> print(occurrence_count)
[3 2 2 2 1 1 1 1 1 1]
```
This also works with 2D arrays! If you start with this array:

```
>>> a_2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [1, 2, 3, 4]])
```
You can find unique values with:

```
>>> unique_values = np.unique(a_2d)
>>> print(unique_values)
[ 1 2 3 4 5 6 7 8 9 10 11 12]
```
If the axis argument isn’t passed, your 2D array will be flattened.

If you want to get the unique rows or columns, make sure to pass the `axis`
argument. To find the unique rows, specify `axis=0`
and for columns, specify
`axis=1`
.

```
>>> unique_rows = np.unique(a_2d, axis=0)
>>> print(unique_rows)
[[ 1 2 3 4]
[ 5 6 7 8]
[ 9 10 11 12]]
```
To get the unique rows, index position, and occurrence count, you can use:

```
>>> unique_rows, indices, occurrence_count = np.unique(
... a_2d, axis=0, return_counts=True, return_index=True)
>>> print(unique_rows)
[[ 1 2 3 4]
[ 5 6 7 8]
[ 9 10 11 12]]
>>> print(indices)
[0 1 2]
>>> print(occurrence_count)
[2 1 1]
```
To learn more about finding the unique elements in an array, see [ unique](../reference/generated/numpy.unique.html#numpy.unique).

## Transposing and reshaping a matrix[#](#transposing-and-reshaping-a-matrix)
*This section covers* `arr.reshape()`
, `arr.transpose()`
, `arr.T`
It’s common to need to transpose your matrices. NumPy arrays have the property
`T`
that allows you to transpose a matrix.

You may also need to switch the dimensions of a matrix. This can happen when,
for example, you have a model that expects a certain input shape that is
different from your dataset. This is where the `reshape`
method can be useful.
You simply need to pass in the new dimensions that you want for the matrix.

```
>>> data.reshape(2, 3)
array([[1, 2, 3],
[4, 5, 6]])
>>> data.reshape(3, 2)
array([[1, 2],
[3, 4],
[5, 6]])
```
You can also use `.transpose()`
to reverse or change the axes of an array
according to the values you specify.

If you start with this array:

```
>>> arr = np.arange(6).reshape((2, 3))
>>> arr
array([[0, 1, 2],
[3, 4, 5]])
```
You can transpose your array with `arr.transpose()`
.

```
>>> arr.transpose()
array([[0, 3],
[1, 4],
[2, 5]])
```
You can also use `arr.T`
:

```
>>> arr.T
array([[0, 3],
[1, 4],
[2, 5]])
```
To learn more about transposing and reshaping arrays, see [ transpose](../reference/generated/numpy.transpose.html#numpy.transpose) and

[.](../reference/generated/numpy.reshape.html#numpy.reshape)
`reshape`
## How to reverse an array[#](#how-to-reverse-an-array)
*This section covers* `np.flip()`
NumPy’s `np.flip()`
function allows you to flip, or reverse, the contents of
an array along an axis. When using `np.flip()`
, specify the array you would like
to reverse and the axis. If you don’t specify the axis, NumPy will reverse the
contents along all of the axes of your input array.

**Reversing a 1D array**
If you begin with a 1D array like this one:

```
>>> arr = np.array([1, 2, 3, 4, 5, 6, 7, 8])
```
You can reverse it with:

```
>>> reversed_arr = np.flip(arr)
```
If you want to print your reversed array, you can run:

```
>>> print('Reversed Array: ', reversed_arr)
Reversed Array: [8 7 6 5 4 3 2 1]
```
**Reversing a 2D array**
A 2D array works much the same way.

If you start with this array:

```
>>> arr_2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
```
You can reverse the content in all of the rows and all of the columns with:

```
>>> reversed_arr = np.flip(arr_2d)
>>> print(reversed_arr)
[[12 11 10 9]
[ 8 7 6 5]
[ 4 3 2 1]]
```
You can easily reverse only the *rows* with:

```
>>> reversed_arr_rows = np.flip(arr_2d, axis=0)
>>> print(reversed_arr_rows)
[[ 9 10 11 12]
[ 5 6 7 8]
[ 1 2 3 4]]
```
Or reverse only the *columns* with:

```
>>> reversed_arr_columns = np.flip(arr_2d, axis=1)
>>> print(reversed_arr_columns)
[[ 4 3 2 1]
[ 8 7 6 5]
[12 11 10 9]]
```
You can also reverse the contents of only one column or row. For example, you can reverse the contents of the row at index position 1 (the second row):

```
>>> arr_2d[1] = np.flip(arr_2d[1])
>>> print(arr_2d)
[[ 1 2 3 4]
[ 8 7 6 5]
[ 9 10 11 12]]
```
You can also reverse the column at index position 1 (the second column):

```
>>> arr_2d[:,1] = np.flip(arr_2d[:,1])
>>> print(arr_2d)
[[ 1 10 3 4]
[ 8 7 6 5]
[ 9 2 11 12]]
```
Read more about reversing arrays at [ flip](../reference/generated/numpy.flip.html#numpy.flip).

## Reshaping and flattening multidimensional arrays[#](#reshaping-and-flattening-multidimensional-arrays)
*This section covers* `.flatten()`
, `ravel()`
There are two popular ways to flatten an array: `.flatten()`
and `.ravel()`
.
The primary difference between the two is that the new array created using
`ravel()`
is actually a reference to the parent array (i.e., a “view”). This
means that any changes to the new array will affect the parent array as well.
Since `ravel`
does not create a copy, it’s memory efficient.

If you start with this array:

```
>>> x = np.array([[1 , 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
```
You can use `flatten`
to flatten your array into a 1D array.

```
>>> x.flatten()
array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
```
When you use `flatten`
, changes to your new array won’t change the parent
array.

For example:

```
>>> a1 = x.flatten()
>>> a1[0] = 99
>>> print(x) # Original array
[[ 1 2 3 4]
[ 5 6 7 8]
[ 9 10 11 12]]
>>> print(a1) # New array
[99 2 3 4 5 6 7 8 9 10 11 12]
```
But when you use `ravel`
, the changes you make to the new array will affect
the parent array.

For example:

```
>>> a2 = x.ravel()
>>> a2[0] = 98
>>> print(x) # Original array
[[98 2 3 4]
[ 5 6 7 8]
[ 9 10 11 12]]
>>> print(a2) # New array
[98 2 3 4 5 6 7 8 9 10 11 12]
```
Read more about `flatten`
at [ ndarray.flatten](../reference/generated/numpy.ndarray.flatten.html#numpy.ndarray.flatten) and

`ravel`
at [.](../reference/generated/numpy.ravel.html#numpy.ravel)
`ravel`
## How to access the docstring for more information[#](#how-to-access-the-docstring-for-more-information)
*This section covers* `help()`
, `?`
, `??`
When it comes to the data science ecosystem, Python and NumPy are built with the
user in mind. One of the best examples of this is the built-in access to
documentation. Every object contains the reference to a string, which is known
as the **docstring**. In most cases, this docstring contains a quick and concise
summary of the object and how to use it. Python has a built-in `help()`
function that can help you access this information. This means that nearly any
time you need more information, you can use `help()`
to quickly find the
information that you need.

For example:

```
>>> help(max)
Help on built-in function max in module builtins:
max(...)
max(iterable, *[, default=obj, key=func]) -> value
max(arg1, arg2, *args, *[, key=func]) -> value
With a single iterable argument, return its biggest item. The
default keyword-only argument specifies an object to return if
the provided iterable is empty.
With two or more arguments, return the largest argument.
```
Because access to additional information is so useful, IPython uses the `?`
character as a shorthand for accessing this documentation along with other
relevant information. IPython is a command shell for interactive computing in
multiple languages.
[You can find more information about IPython here](https://ipython.org/).

For example:

```
In [0]: max?
max(iterable, *[, default=obj, key=func]) -> value
max(arg1, arg2, *args, *[, key=func]) -> value
With a single iterable argument, return its biggest item. The
default keyword-only argument specifies an object to return if
the provided iterable is empty.
With two or more arguments, return the largest argument.
Type: builtin_function_or_method
```
You can even use this notation for object methods and objects themselves.

Let’s say you create this array:

```
>>> a = np.array([1, 2, 3, 4, 5, 6])
```
Then you can obtain a lot of useful information (first details about `a`
itself,
followed by the docstring of `ndarray`
of which `a`
is an instance):

```
In [1]: a?
Type: ndarray
String form: [1 2 3 4 5 6]
Length: 6
File: ~/anaconda3/lib/python3.9/site-packages/numpy/__init__.py
Docstring: <no docstring>
Class docstring:
ndarray(shape, dtype=float, buffer=None, offset=0,
strides=None, order=None)
An array object represents a multidimensional, homogeneous array
of fixed-size items. An associated data-type object describes the
format of each element in the array (its byte-order, how many bytes it
occupies in memory, whether it is an integer, a floating point number,
or something else, etc.)
Arrays should be constructed using `array`, `zeros` or `empty` (refer
to the See Also section below). The parameters given here refer to
a low-level method (`ndarray(...)`) for instantiating an array.
For more information, refer to the `numpy` module and examine the
methods and attributes of an array.
Parameters
----------
(for the __new__ method; see Notes below)
shape : tuple of ints
Shape of created array.
...
```
This also works for functions and other objects that **you** create. Just
remember to include a docstring with your function using a string literal
(`""" """`
or `''' '''`
around your documentation).

For example, if you create this function:

```
>>> def double(a):
... '''Return a * 2'''
... return a * 2
```
You can obtain information about the function:

```
In [2]: double?
Signature: double(a)
Docstring: Return a * 2
File: ~/Desktop/<ipython-input-23-b5adf20be596>
Type: function
```
You can reach another level of information by reading the source code of the
object you’re interested in. Using a double question mark (`??`
) allows you to
access the source code.

For example:

```
In [3]: double??
Signature: double(a)
Source:
def double(a):
'''Return a * 2'''
return a * 2
File: ~/Desktop/<ipython-input-23-b5adf20be596>
Type: function
```
If the object in question is compiled in a language other than Python, using
`??`
will return the same information as `?`
. You’ll find this with a lot of
built-in objects and types, for example:

```
In [4]: len?
Signature: len(obj, /)
Docstring: Return the number of items in a container.
Type: builtin_function_or_method
```
and :

```
In [5]: len??
Signature: len(obj, /)
Docstring: Return the number of items in a container.
Type: builtin_function_or_method
```
have the same output because they were compiled in a programming language other than Python.

## Working with mathematical formulas[#](#working-with-mathematical-formulas)
The ease of implementing mathematical formulas that work on arrays is one of the things that make NumPy so widely used in the scientific Python community.

For example, this is the mean square error formula (a central formula used in supervised machine learning models that deal with regression):

Implementing this formula is simple and straightforward in NumPy:

What makes this work so well is that `predictions`
and `labels`
can contain
one or a thousand values. They only need to be the same size.

You can visualize it this way:

In this example, both the predictions and labels vectors contain three values,
meaning `n`
has a value of three. After we carry out subtractions the values
in the vector are squared. Then NumPy sums the values, and your result is the
error value for that prediction and a score for the quality of the model.

## How to save and load NumPy objects[#](#how-to-save-and-load-numpy-objects)
*This section covers* `np.save`
, `np.savez`
, `np.savetxt`
,
`np.load`
, `np.loadtxt`
You will, at some point, want to save your arrays to disk and load them back
without having to re-run the code. Fortunately, there are several ways to save
and load objects with NumPy. The ndarray objects can be saved to and loaded from
the disk files with `loadtxt`
and `savetxt`
functions that handle normal
text files, `load`
and `save`
functions that handle NumPy binary files with
a **.npy** file extension, and a `savez`
function that handles NumPy files
with a **.npz** file extension.

The **.npy** and **.npz** files store data, shape, dtype, and other information
required to reconstruct the ndarray in a way that allows the array to be
correctly retrieved, even when the file is on another machine with different
architecture.

If you want to store a single ndarray object, store it as a .npy file using
`np.save`
. If you want to store more than one ndarray object in a single file,
save it as a .npz file using `np.savez`
. You can also save several arrays
into a single file in compressed npz format with [ savez_compressed](../reference/generated/numpy.savez_compressed.html#numpy.savez_compressed).

It’s easy to save and load and array with `np.save()`
. Just make sure to
specify the array you want to save and a file name. For example, if you create
this array:

```
>>> a = np.array([1, 2, 3, 4, 5, 6])
```
You can save it as “filename.npy” with:

```
>>> np.save('filename', a)
```
You can use `np.load()`
to reconstruct your array.

```
>>> b = np.load('filename.npy')
```
If you want to check your array, you can run:

```
>>> print(b)
[1 2 3 4 5 6]
```
You can save a NumPy array as a plain text file like a **.csv** or **.txt** file
with `np.savetxt`
.

For example, if you create this array:

```
>>> csv_arr = np.array([1, 2, 3, 4, 5, 6, 7, 8])
```
You can easily save it as a .csv file with the name “new_file.csv” like this:

```
>>> np.savetxt('new_file.csv', csv_arr)
```
You can quickly and easily load your saved text file using `loadtxt()`
:

```
>>> np.loadtxt('new_file.csv')
array([1., 2., 3., 4., 5., 6., 7., 8.])
```
The `savetxt()`
and `loadtxt()`
functions accept additional optional
parameters such as header, footer, and delimiter. While text files can be easier
for sharing, .npy and .npz files are smaller and faster to read. If you need more
sophisticated handling of your text file (for example, if you need to work with
lines that contain missing values), you will want to use the [ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)
function.

With [ savetxt](../reference/generated/numpy.savetxt.html#numpy.savetxt), you can specify headers, footers, comments, and more.

Learn more about [input and output routines here](../reference/routines.io.html#routines-io).

## Importing and exporting a CSV[#](#importing-and-exporting-a-csv)
It’s simple to read in a CSV that contains existing information. The best and
easiest way to do this is to use
[Pandas](https://pandas.pydata.org).

```
>>> import pandas as pd
>>> # If all of your columns are the same type:
>>> x = pd.read_csv('music.csv', header=0).values
>>> print(x)
[['Billie Holiday' 'Jazz' 1300000 27000000]
['Jimmie Hendrix' 'Rock' 2700000 70000000]
['Miles Davis' 'Jazz' 1500000 48000000]
['SIA' 'Pop' 2000000 74000000]]
>>> # You can also simply select the columns you need:
>>> x = pd.read_csv('music.csv', usecols=['Artist', 'Plays']).values
>>> print(x)
[['Billie Holiday' 27000000]
['Jimmie Hendrix' 70000000]
['Miles Davis' 48000000]
['SIA' 74000000]]
```
It’s simple to use Pandas in order to export your array as well. If you are new to NumPy, you may want to create a Pandas dataframe from the values in your array and then write the data frame to a CSV file with Pandas.

If you created this array “a”

```
>>> a = np.array([[-2.58289208, 0.43014843, -1.24082018, 1.59572603],
... [ 0.99027828, 1.17150989, 0.94125714, -0.14692469],
... [ 0.76989341, 0.81299683, -0.95068423, 0.11769564],
... [ 0.20484034, 0.34784527, 1.96979195, 0.51992837]])
```
You could create a Pandas dataframe

```
>>> df = pd.DataFrame(a)
>>> print(df)
0 1 2 3
0 -2.582892 0.430148 -1.240820 1.595726
1 0.990278 1.171510 0.941257 -0.146925
2 0.769893 0.812997 -0.950684 0.117696
3 0.204840 0.347845 1.969792 0.519928
```
You can easily save your dataframe with:

```
>>> df.to_csv('pd.csv')
```
And read your CSV with:

```
>>> data = pd.read_csv('pd.csv')
```
You can also save your array with the NumPy `savetxt`
method.

```
>>> np.savetxt('np.csv', a, fmt='%.2f', delimiter=',', header='1, 2, 3, 4')
```
If you’re using the command line, you can read your saved CSV any time with a command such as:

```
$ cat np.csv
# 1, 2, 3, 4
-2.58,0.43,-1.24,1.60
0.99,1.17,0.94,-0.15
0.77,0.81,-0.95,0.12
0.20,0.35,1.97,0.52
```
Or you can open the file any time with a text editor!

If you’re interested in learning more about Pandas, take a look at the
[official Pandas documentation](https://pandas.pydata.org/index.html).
Learn how to install Pandas with the
[official Pandas installation information](https://pandas.pydata.org/pandas-docs/stable/install.html).

## Plotting arrays with Matplotlib[#](#plotting-arrays-with-matplotlib)
If you need to generate a plot for your values, it’s very simple with
[Matplotlib](https://matplotlib.org/).

For example, you may have an array like this one:

```
>>> a = np.array([2, 1, 5, 7, 4, 6, 8, 14, 10, 9, 18, 20, 22])
```
If you already have Matplotlib installed, you can import it with:

```
>>> import matplotlib.pyplot as plt
# If you're using Jupyter Notebook, you may also want to run the following
# line of code to display your code in the notebook:
%matplotlib inline
```
All you need to do to plot your values is run:

```
>>> plt.plot(a)
# If you are running from a command line, you may need to do this:
# >>> plt.show()
```
For example, you can plot a 1D array like this:

```
>>> x = np.linspace(0, 5, 20)
>>> y = np.linspace(0, 10, 20)
>>> plt.plot(x, y, 'purple') # line
>>> plt.plot(x, y, 'o') # dots
```
With Matplotlib, you have access to an enormous number of visualization options.

```
>>> fig = plt.figure()
>>> ax = fig.add_subplot(projection='3d')
>>> X = np.arange(-5, 5, 0.15)
>>> Y = np.arange(-5, 5, 0.15)
>>> X, Y = np.meshgrid(X, Y)
>>> R = np.sqrt(X**2 + Y**2)
>>> Z = np.sin(R)
>>> ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis')
```
To read more about Matplotlib and what it can do, take a look at
[the official documentation](https://matplotlib.org/).
For directions regarding installing Matplotlib, see the official
[installation section](https://matplotlib.org/users/installing.html).

*Image credits: Jay Alammar http://jalammar.github.io/*# NumPy reference[#](#numpy-reference)
Release:
-
1.26

Date:
-
September 16, 2023

This reference manual details functions, modules, and objects
included in NumPy, describing what they are and what they do.
For learning how to use NumPy, see the [complete documentation](../index.html#numpy-docs-mainpage).

[Array objects](arrays.html)
[Array API Standard Compatibility](array_api.html)
[Constants](constants.html)
[Universal functions (](ufuncs.html)`ufunc`
)
[Routines](routines.html)[Array creation routines](routines.array-creation.html)
[Array manipulation routines](routines.array-manipulation.html)
[Binary operations](routines.bitwise.html)
[String operations](routines.char.html)
[C-Types foreign function interface (](routines.ctypeslib.html)`numpy.ctypeslib`
)
[Datetime support functions](routines.datetime.html)
[Data type routines](routines.dtype.html)
[Mathematical functions with automatic domain](routines.emath.html)
[Floating point error handling](routines.err.html)
[Discrete Fourier Transform (](routines.fft.html)`numpy.fft`
)
[Functional programming](routines.functional.html)
[NumPy-specific help functions](routines.help.html)
[Input and output](routines.io.html)
[Linear algebra (](routines.linalg.html)`numpy.linalg`
)
[Logic functions](routines.logic.html)
[Masked array operations](routines.ma.html)
[Mathematical functions](routines.math.html)
[Matrix library (](routines.matlib.html)`numpy.matlib`
)
[Miscellaneous routines](routines.other.html)
[Padding Arrays](routines.padding.html)
[Polynomials](routines.polynomials.html)
[Random sampling (](random/index.html)`numpy.random`
)
[Set routines](routines.set.html)
[Sorting, searching, and counting](routines.sort.html)
[Statistics](routines.statistics.html)
[Test Support (](routines.testing.html)`numpy.testing`
)
[Support for testing overrides (](routines.testing.overrides.html)`numpy.testing.overrides`
)
[Window functions](routines.window.html)
[Typing (](typing.html)`numpy.typing`
)
[Global state](global_state.html)
[Packaging (](distutils.html)`numpy.distutils`
)
[NumPy distutils - users guide](distutils_guide.html)
[Status of](distutils_status_migration.html)`numpy.distutils`
and migration advice
[NumPy C-API](c-api/index.html)
[CPU/SIMD Optimizations](simd/index.html)
[NumPy security](security.html)
[NumPy and SWIG](swig.html)
## Acknowledgements[#](#acknowledgements)
Large parts of this manual originate from Travis E. Oliphant’s book
[Guide to NumPy](https://archive.org/details/NumPyBook) (which generously
entered Public Domain in August 2008). The reference documentation for many of
the functions are written by numerous contributors and developers of
NumPy.# Memory management in NumPy[#](#memory-management-in-numpy)
The [ numpy.ndarray](../generated/numpy.ndarray.html#numpy.ndarray) is a python class. It requires additional memory allocations
to hold

[,](../generated/numpy.ndarray.strides.html#numpy.ndarray.strides)
`numpy.ndarray.strides`
[and](../generated/numpy.ndarray.shape.html#numpy.ndarray.shape)
`numpy.ndarray.shape`
[attributes. These attributes are specially allocated after creating the python object in](../generated/numpy.ndarray.data.html#numpy.ndarray.data)
`numpy.ndarray.data`
*__new__*. The
`strides`
and
`shape`
are stored in a piece of memory allocated internally.The `data`
allocation used to store the actual array values (which could be
pointers in the case of `object`
arrays) can be very large, so NumPy has
provided interfaces to manage its allocation and release. This document details
how those interfaces work.

## Historical overview[#](#historical-overview)
Since version 1.7.0, NumPy has exposed a set of `PyDataMem_*`
functions
([ PyDataMem_NEW](array.html#c.PyDataMem_NEW),

[,](array.html#c.PyDataMem_FREE)
`PyDataMem_FREE`
[) which are backed by](array.html#c.PyDataMem_RENEW)
`PyDataMem_RENEW`
*alloc*,
*free*,
*realloc*respectively. In that version NumPy also exposed the
*PyDataMem_EventHook*function (now deprecated) described below, which wrap the OS-level calls.
Since those early days, Python also improved its memory management
capabilities, and began providing
various [management policies](https://docs.python.org/3/c-api/memory.html#memoryoverview) beginning in version
3.4. These routines are divided into a set of domains, each domain has a
[ PyMemAllocatorEx](https://docs.python.org/3/c-api/memory.html#c.PyMemAllocatorEx) structure of routines for memory management. Python also
added a

[module to trace calls to the various routines. These tracking hooks were added to the NumPy](https://docs.python.org/3/library/tracemalloc.html#module-tracemalloc)
`tracemalloc`
`PyDataMem_*`
routines.NumPy added a small cache of allocated memory in its internal
`npy_alloc_cache`
, `npy_alloc_cache_zero`
, and `npy_free_cache`
functions. These wrap `alloc`
, `alloc-and-memset(0)`
and `free`
respectively, but when `npy_free_cache`
is called, it adds the pointer to a
short list of available blocks marked by size. These blocks can be re-used by
subsequent calls to `npy_alloc*`
, avoiding memory thrashing.

## Configurable memory routines in NumPy (NEP 49)[#](#configurable-memory-routines-in-numpy-nep-49)
Users may wish to override the internal data memory routines with ones of their
own. Since NumPy does not use the Python domain strategy to manage data memory,
it provides an alternative set of C-APIs to change memory routines. There are
no Python domain-wide strategies for large chunks of object data, so those are
less suited to NumPy’s needs. User who wish to change the NumPy data memory
management routines can use [ PyDataMem_SetHandler](#c.PyDataMem_SetHandler), which uses a

[structure to hold pointers to functions used to manage the data memory. The calls are still wrapped by internal routines to call](#c.PyDataMem_Handler)
`PyDataMem_Handler`
[,](https://docs.python.org/3/c-api/memory.html#c.PyTraceMalloc_Track)
`PyTraceMalloc_Track`
[, and will use the deprecated](https://docs.python.org/3/c-api/memory.html#c.PyTraceMalloc_Untrack)
`PyTraceMalloc_Untrack`
[mechanism. Since the functions may change during the lifetime of the process, each](#c.PyDataMem_EventHookFunc)
`PyDataMem_EventHookFunc`
`ndarray`
carries with it the functions used at the time of its instantiation, and these
will be used to reallocate or free the data memory of the instance.
type PyDataMem_Handler[#](#c.PyDataMem_Handler)
-
A struct to hold function pointers used to manipulate memory

typedef struct { char name[127]; /* multiple of 64 to keep the struct aligned */ uint8_t version; /* currently 1 */ PyDataMemAllocator allocator; } PyDataMem_Handler;
where the allocator structure is

/* The declaration of free differs from PyMemAllocatorEx */ typedef struct { void *ctx; void* (*malloc) (void *ctx, size_t size); void* (*calloc) (void *ctx, size_t nelem, size_t elsize); void* (*realloc) (void *ctx, void *ptr, size_t new_size); void (*free) (void *ctx, void *ptr, size_t size); } PyDataMemAllocator;
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyDataMem_SetHandler([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*handler)[#](#c.PyDataMem_SetHandler)
-
Set a new allocation policy. If the input value is

`NULL`
, will reset the policy to the default. Return the previous policy, or return`NULL`
if an error has occurred. We wrap the user-provided functions so they will still call the python and numpy memory management callback hooks.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyDataMem_GetHandler()[#](#c.PyDataMem_GetHandler)
-
Return the current policy that will be used to allocate data for the next

`PyArrayObject`
. On failure, return`NULL`
.
For an example of setting up and using the PyDataMem_Handler, see the test in
`numpy/core/tests/test_mem_policy.py`

void PyDataMem_EventHookFunc(void *inp, void *outp, size_t size, void *user_data);[#](#c.PyDataMem_EventHookFunc)
-
This function will be called during data memory manipulation

[PyDataMem_EventHookFunc](#c.PyDataMem_EventHookFunc)*PyDataMem_SetEventHook([PyDataMem_EventHookFunc](#c.PyDataMem_EventHookFunc)*newhook, void *user_data, void **old_data)[#](#c.PyDataMem_SetEventHook)
-
Sets the allocation event hook for numpy array data.

Returns a pointer to the previous hook or

`NULL`
. If old_data is non-`NULL`
, the previous user_data pointer will be copied to it.If not

`NULL`
, hook will be called at the end of each`PyDataMem_NEW/FREE/RENEW`
:result = PyDataMem_NEW(size) -> (*hook)(NULL, result, size, user_data) PyDataMem_FREE(ptr) -> (*hook)(ptr, NULL, 0, user_data) result = PyDataMem_RENEW(ptr, size) -> (*hook)(ptr, result, size, user_data)
When the hook is called, the GIL will be held by the calling thread. The hook should be written to be reentrant, if it performs operations that might cause new allocation events (such as the creation/destruction numpy objects, or creating/destroying Python objects which might cause a gc).

Deprecated in v1.23

## What happens when deallocating if there is no policy set[#](#what-happens-when-deallocating-if-there-is-no-policy-set)
A rare but useful technique is to allocate a buffer outside NumPy, use
[ PyArray_NewFromDescr](array.html#c.PyArray_NewFromDescr) to wrap the buffer in a

`ndarray`
, then switch
the `OWNDATA`
flag to true. When the `ndarray`
is released, the
appropriate function from the `ndarray`
’s `PyDataMem_Handler`
should be
called to free the buffer. But the `PyDataMem_Handler`
field was never set,
it will be `NULL`
. For backward compatibility, NumPy will call `free()`
to
release the buffer. If `NUMPY_WARN_IF_NO_MEM_POLICY`
is set to `1`
, a
warning will be emitted. The current default is not to emit a warning, this may
change in a future version of NumPy.A better technique would be to use a `PyCapsule`
as a base object:

```
/* define a PyCapsule_Destructor, using the correct deallocator for buff */
void free_wrap(void *capsule){
void * obj = PyCapsule_GetPointer(capsule, PyCapsule_GetName(capsule));
free(obj);
};
/* then inside the function that creates arr from buff */
...
arr = PyArray_NewFromDescr(... buf, ...);
if (arr == NULL) {
return NULL;
}
capsule = PyCapsule_New(buf, "my_wrapped_buffer",
(PyCapsule_Destructor)&free_wrap);
if (PyArray_SetBaseObject(arr, capsule) == -1) {
Py_DECREF(arr);
return NULL;
}
...
```
## Example of memory tracing with `np.lib.tracemalloc_domain`
[#](#example-of-memory-tracing-with-np-lib-tracemalloc-domain)
Note that since Python 3.6 (or newer), the builtin `tracemalloc`
module can be used to
track allocations inside NumPy. NumPy places its CPU memory allocations into the
`np.lib.tracemalloc_domain`
domain.
For additional information, check: *https://docs.python.org/3/library/tracemalloc.html*.

Here is an example on how to use `np.lib.tracemalloc_domain`
:

```
"""
The goal of this example is to show how to trace memory
from an application that has NumPy and non-NumPy sections.
We only select the sections using NumPy related calls.
"""
import tracemalloc
import numpy as np
# Flag to determine if we select NumPy domain
use_np_domain = True
nx = 300
ny = 500
# Start to trace memory
tracemalloc.start()
# Section 1
# ---------
# NumPy related call
a = np.zeros((nx,ny))
# non-NumPy related call
b = [i**2 for i in range(nx*ny)]
snapshot1 = tracemalloc.take_snapshot()
# We filter the snapshot to only select NumPy related calls
np_domain = np.lib.tracemalloc_domain
dom_filter = tracemalloc.DomainFilter(inclusive=use_np_domain,
domain=np_domain)
snapshot1 = snapshot1.filter_traces([dom_filter])
top_stats1 = snapshot1.statistics('traceback')
print("================ SNAPSHOT 1 =================")
for stat in top_stats1:
print(f"{stat.count} memory blocks: {stat.size / 1024:.1f} KiB")
print(stat.traceback.format()[-1])
# Clear traces of memory blocks allocated by Python
# before moving to the next section.
tracemalloc.clear_traces()
# Section 2
#----------
# We are only using NumPy
c = np.sum(a*a)
snapshot2 = tracemalloc.take_snapshot()
top_stats2 = snapshot2.statistics('traceback')
print()
print("================ SNAPSHOT 2 =================")
for stat in top_stats2:
print(f"{stat.count} memory blocks: {stat.size / 1024:.1f} KiB")
print(stat.traceback.format()[-1])
tracemalloc.stop()
print()
print("============================================")
print("\nTracing Status : ", tracemalloc.is_tracing())
try:
print("\nTrying to Take Snapshot After Tracing is Stopped.")
snap = tracemalloc.take_snapshot()
except Exception as e:
print("Exception : ", e)
```# F2PY user guide and reference manual[#](#f2py-user-guide-and-reference-manual)
The purpose of the `F2PY`
–*Fortran to Python interface generator*– utility
is to provide a connection between Python and Fortran. F2PY is a part of [NumPy](https://www.numpy.org/)
(`numpy.f2py`
) and also available as a standalone command line tool.

F2PY facilitates creating/building Python C/API extension modules that make it possible

to call Fortran 77/90/95 external subroutines and Fortran 90/95 module subroutines as well as C functions;

to access Fortran 77

`COMMON`
blocks and Fortran 90/95 module data, including allocatable arrays
from Python.

F2PY can be used either as a command line tool `f2py`
or as a Python
module `numpy.f2py`
. While we try to provide the command line tool as part
of the numpy setup, some platforms like Windows make it difficult to
reliably put the executables on the `PATH`
. If the `f2py`
command is not
available in your system, you may have to run it as a module:

```
python -m numpy.f2py
```
If you run `f2py`
with no arguments, and the line `numpy Version`
at the
end matches the NumPy version printed from `python -m numpy.f2py`
, then you
can use the shorter version. If not, or if you cannot run `f2py`
, you should
replace all calls to `f2py`
mentioned in this guide with the longer version.

[Three ways to wrap - getting started](f2py.getting-started.html)
[F2PY user guide](f2py-user.html)[Three ways to wrap - getting started](f2py.getting-started.html)
[Using F2PY](usage.html)
[F2PY examples](f2py-examples.html)
[F2PY reference manual](f2py-reference.html)[Signature file](signature-file.html)
[Using F2PY bindings in Python](python-usage.html)
[F2PY and Build Systems](buildtools/index.html)
[Advanced F2PY use cases](advanced.html)
[F2PY test suite](f2py-testing.html)
[Using F2PY](usage.html)
[Using F2PY bindings in Python](python-usage.html)
[Signature file](signature-file.html)
[F2PY and Build Systems](buildtools/index.html)
[Advanced F2PY use cases](advanced.html)
[F2PY and Windows](windows/index.html)# NumPy quickstart[#](#numpy-quickstart)
## Prerequisites[#](#prerequisites)
You’ll need to know a bit of Python. For a refresher, see the [Python
tutorial](https://docs.python.org/tutorial/).

To work the examples, you’ll need `matplotlib`
installed
in addition to NumPy.

**Learner profile**
This is a quick overview of arrays in NumPy. It demonstrates how n-dimensional (\(n>=2\)) arrays are represented and can be manipulated. In particular, if you don’t know how to apply common functions to n-dimensional arrays (without using for-loops), or if you want to understand axis and shape properties for n-dimensional arrays, this article might be of help.

**Learning Objectives**
After reading, you should be able to:

Understand the difference between one-, two- and n-dimensional arrays in NumPy;

Understand how to apply some linear algebra operations to n-dimensional arrays without using for-loops;

Understand axis and shape properties for n-dimensional arrays.

## The Basics[#](#the-basics)
NumPy’s main object is the homogeneous multidimensional array. It is a
table of elements (usually numbers), all of the same type, indexed by a
tuple of non-negative integers. In NumPy dimensions are called *axes*.

For example, the array for the coordinates of a point in 3D space,
`[1, 2, 1]`
, has one axis. That axis has 3 elements in it, so we say
it has a length of 3. In the example pictured below, the array has 2
axes. The first axis has a length of 2, the second axis has a length of
3.

```
[[1., 0., 0.],
[0., 1., 2.]]
```
NumPy’s array class is called `ndarray`
. It is also known by the alias
`array`
. Note that `numpy.array`
is not the same as the Standard
Python Library class `array.array`
, which only handles one-dimensional
arrays and offers less functionality. The more important attributes of
an `ndarray`
object are:

ndarray.ndim
-
the number of axes (dimensions) of the array.

ndarray.shape
-
the dimensions of the array. This is a tuple of integers indicating the size of the array in each dimension. For a matrix with

*n*rows and*m*columns,`shape`
will be`(n,m)`
. The length of the`shape`
tuple is therefore the number of axes,`ndim`
.
ndarray.size
-
the total number of elements of the array. This is equal to the product of the elements of

`shape`
.
ndarray.dtype
-
an object describing the type of the elements in the array. One can create or specify dtype’s using standard Python types. Additionally NumPy provides types of its own. numpy.int32, numpy.int16, and numpy.float64 are some examples.

ndarray.itemsize
-
the size in bytes of each element of the array. For example, an array of elements of type

`float64`
has`itemsize`
8 (=64/8), while one of type`complex32`
has`itemsize`
4 (=32/8). It is equivalent to`ndarray.dtype.itemsize`
.
ndarray.data
-
the buffer containing the actual elements of the array. Normally, we won’t need to use this attribute because we will access the elements in an array using indexing facilities.

### An example[#](#an-example)
```
>>> import numpy as np
>>> a = np.arange(15).reshape(3, 5)
>>> a
array([[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9],
[10, 11, 12, 13, 14]])
>>> a.shape
(3, 5)
>>> a.ndim
2
>>> a.dtype.name
'int64'
>>> a.itemsize
8
>>> a.size
15
>>> type(a)
<class 'numpy.ndarray'>
>>> b = np.array([6, 7, 8])
>>> b
array([6, 7, 8])
>>> type(b)
<class 'numpy.ndarray'>
```
### Array Creation[#](#array-creation)
There are several ways to create arrays.

For example, you can create an array from a regular Python list or tuple
using the `array`
function. The type of the resulting array is deduced
from the type of the elements in the sequences.

```
>>> import numpy as np
>>> a = np.array([2, 3, 4])
>>> a
array([2, 3, 4])
>>> a.dtype
dtype('int64')
>>> b = np.array([1.2, 3.5, 5.1])
>>> b.dtype
dtype('float64')
```
A frequent error consists in calling `array`
with multiple arguments,
rather than providing a single sequence as an argument.

```
>>> a = np.array(1, 2, 3, 4) # WRONG
Traceback (most recent call last):
...
TypeError: array() takes from 1 to 2 positional arguments but 4 were given
>>> a = np.array([1, 2, 3, 4]) # RIGHT
```
`array`
transforms sequences of sequences into two-dimensional arrays,
sequences of sequences of sequences into three-dimensional arrays, and
so on.
```
>>> b = np.array([(1.5, 2, 3), (4, 5, 6)])
>>> b
array([[1.5, 2. , 3. ],
[4. , 5. , 6. ]])
```
The type of the array can also be explicitly specified at creation time:

```
>>> c = np.array([[1, 2], [3, 4]], dtype=complex)
>>> c
array([[1.+0.j, 2.+0.j],
[3.+0.j, 4.+0.j]])
```
Often, the elements of an array are originally unknown, but its size is known. Hence, NumPy offers several functions to create arrays with initial placeholder content. These minimize the necessity of growing arrays, an expensive operation.

The function `zeros`
creates an array full of zeros, the function
`ones`
creates an array full of ones, and the function `empty`
creates an array whose initial content is random and depends on the
state of the memory. By default, the dtype of the created array is
`float64`
, but it can be specified via the key word argument `dtype`
.

```
>>> np.zeros((3, 4))
array([[0., 0., 0., 0.],
[0., 0., 0., 0.],
[0., 0., 0., 0.]])
>>> np.ones((2, 3, 4), dtype=np.int16)
array([[[1, 1, 1, 1],
[1, 1, 1, 1],
[1, 1, 1, 1]],
[[1, 1, 1, 1],
[1, 1, 1, 1],
[1, 1, 1, 1]]], dtype=int16)
>>> np.empty((2, 3))
array([[3.73603959e-262, 6.02658058e-154, 6.55490914e-260], # may vary
[5.30498948e-313, 3.14673309e-307, 1.00000000e+000]])
```
To create sequences of numbers, NumPy provides the `arange`
function
which is analogous to the Python built-in `range`
, but returns an
array.

```
>>> np.arange(10, 30, 5)
array([10, 15, 20, 25])
>>> np.arange(0, 2, 0.3) # it accepts float arguments
array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8])
```
When `arange`
is used with floating point arguments, it is generally
not possible to predict the number of elements obtained, due to the
finite floating point precision. For this reason, it is usually better
to use the function `linspace`
that receives as an argument the number
of elements that we want, instead of the step:

```
>>> from numpy import pi
>>> np.linspace(0, 2, 9) # 9 numbers from 0 to 2
array([0. , 0.25, 0.5 , 0.75, 1. , 1.25, 1.5 , 1.75, 2. ])
>>> x = np.linspace(0, 2 * pi, 100) # useful to evaluate function at lots of points
>>> f = np.sin(x)
```
See also

[ array](../reference/generated/numpy.array.html#numpy.array),
[,](../reference/generated/numpy.zeros.html#numpy.zeros)
`zeros`
[,](../reference/generated/numpy.zeros_like.html#numpy.zeros_like)
`zeros_like`
[,](../reference/generated/numpy.ones.html#numpy.ones)
`ones`
[,](../reference/generated/numpy.ones_like.html#numpy.ones_like)
`ones_like`
[,](../reference/generated/numpy.empty.html#numpy.empty)
`empty`
[,](../reference/generated/numpy.empty_like.html#numpy.empty_like)
`empty_like`
[,](../reference/generated/numpy.arange.html#numpy.arange)
`arange`
[,](../reference/generated/numpy.linspace.html#numpy.linspace)
`linspace`
*numpy.random.Generator.rand*,
*numpy.random.Generator.randn*,
[,](../reference/generated/numpy.fromfunction.html#numpy.fromfunction)
`fromfunction`
`fromfile`
### Printing Arrays[#](#printing-arrays)
When you print an array, NumPy displays it in a similar way to nested lists, but with the following layout:

the last axis is printed from left to right,

the second-to-last is printed from top to bottom,

the rest are also printed from top to bottom, with each slice separated from the next by an empty line.

One-dimensional arrays are then printed as rows, bidimensionals as matrices and tridimensionals as lists of matrices.

```
>>> a = np.arange(6) # 1d array
>>> print(a)
[0 1 2 3 4 5]
>>>
>>> b = np.arange(12).reshape(4, 3) # 2d array
>>> print(b)
[[ 0 1 2]
[ 3 4 5]
[ 6 7 8]
[ 9 10 11]]
>>>
>>> c = np.arange(24).reshape(2, 3, 4) # 3d array
>>> print(c)
[[[ 0 1 2 3]
[ 4 5 6 7]
[ 8 9 10 11]]
[[12 13 14 15]
[16 17 18 19]
[20 21 22 23]]]
```
See [below](#quickstart-shape-manipulation) to get
more details on `reshape`
.

If an array is too large to be printed, NumPy automatically skips the central part of the array and only prints the corners:

```
>>> print(np.arange(10000))
[ 0 1 2 ... 9997 9998 9999]
>>>
>>> print(np.arange(10000).reshape(100, 100))
[[ 0 1 2 ... 97 98 99]
[ 100 101 102 ... 197 198 199]
[ 200 201 202 ... 297 298 299]
...
[9700 9701 9702 ... 9797 9798 9799]
[9800 9801 9802 ... 9897 9898 9899]
[9900 9901 9902 ... 9997 9998 9999]]
```
To disable this behaviour and force NumPy to print the entire array, you
can change the printing options using `set_printoptions`
.

```
>>> np.set_printoptions(threshold=sys.maxsize) # sys module should be imported
```
### Basic Operations[#](#basic-operations)
Arithmetic operators on arrays apply *elementwise*. A new array is
created and filled with the result.

```
>>> a = np.array([20, 30, 40, 50])
>>> b = np.arange(4)
>>> b
array([0, 1, 2, 3])
>>> c = a - b
>>> c
array([20, 29, 38, 47])
>>> b**2
array([0, 1, 4, 9])
>>> 10 * np.sin(a)
array([ 9.12945251, -9.88031624, 7.4511316 , -2.62374854])
>>> a < 35
array([ True, True, False, False])
```
Unlike in many matrix languages, the product operator `*`
operates
elementwise in NumPy arrays. The matrix product can be performed using
the `@`
operator (in python >=3.5) or the `dot`
function or method:

```
>>> A = np.array([[1, 1],
... [0, 1]])
>>> B = np.array([[2, 0],
... [3, 4]])
>>> A * B # elementwise product
array([[2, 0],
[0, 4]])
>>> A @ B # matrix product
array([[5, 4],
[3, 4]])
>>> A.dot(B) # another matrix product
array([[5, 4],
[3, 4]])
```
Some operations, such as `+=`
and `*=`
, act in place to modify an
existing array rather than create a new one.

```
>>> rg = np.random.default_rng(1) # create instance of default random number generator
>>> a = np.ones((2, 3), dtype=int)
>>> b = rg.random((2, 3))
>>> a *= 3
>>> a
array([[3, 3, 3],
[3, 3, 3]])
>>> b += a
>>> b
array([[3.51182162, 3.9504637 , 3.14415961],
[3.94864945, 3.31183145, 3.42332645]])
>>> a += b # b is not automatically converted to integer type
Traceback (most recent call last):
...
numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'
```
When operating with arrays of different types, the type of the resulting array corresponds to the more general or precise one (a behavior known as upcasting).

```
>>> a = np.ones(3, dtype=np.int32)
>>> b = np.linspace(0, pi, 3)
>>> b.dtype.name
'float64'
>>> c = a + b
>>> c
array([1. , 2.57079633, 4.14159265])
>>> c.dtype.name
'float64'
>>> d = np.exp(c * 1j)
>>> d
array([ 0.54030231+0.84147098j, -0.84147098+0.54030231j,
-0.54030231-0.84147098j])
>>> d.dtype.name
'complex128'
```
Many unary operations, such as computing the sum of all the elements in
the array, are implemented as methods of the `ndarray`
class.

```
>>> a = rg.random((2, 3))
>>> a
array([[0.82770259, 0.40919914, 0.54959369],
[0.02755911, 0.75351311, 0.53814331]])
>>> a.sum()
3.1057109529998157
>>> a.min()
0.027559113243068367
>>> a.max()
0.8277025938204418
```
By default, these operations apply to the array as though it were a list
of numbers, regardless of its shape. However, by specifying the `axis`
parameter you can apply an operation along the specified axis of an
array:

```
>>> b = np.arange(12).reshape(3, 4)
>>> b
array([[ 0, 1, 2, 3],
[ 4, 5, 6, 7],
[ 8, 9, 10, 11]])
>>>
>>> b.sum(axis=0) # sum of each column
array([12, 15, 18, 21])
>>>
>>> b.min(axis=1) # min of each row
array([0, 4, 8])
>>>
>>> b.cumsum(axis=1) # cumulative sum along each row
array([[ 0, 1, 3, 6],
[ 4, 9, 15, 22],
[ 8, 17, 27, 38]])
```
### Universal Functions[#](#universal-functions)
NumPy provides familiar mathematical functions such as sin, cos, and
exp. In NumPy, these are called “universal
functions” (`ufunc`
). Within NumPy, these functions
operate elementwise on an array, producing an array as output.

```
>>> B = np.arange(3)
>>> B
array([0, 1, 2])
>>> np.exp(B)
array([1. , 2.71828183, 7.3890561 ])
>>> np.sqrt(B)
array([0. , 1. , 1.41421356])
>>> C = np.array([2., -1., 4.])
>>> np.add(B, C)
array([2., 0., 6.])
```
See also

[ all](../reference/generated/numpy.all.html#numpy.all),
[,](../reference/generated/numpy.any.html#numpy.any)
`any`
[,](../reference/generated/numpy.apply_along_axis.html#numpy.apply_along_axis)
`apply_along_axis`
[,](../reference/generated/numpy.argmax.html#numpy.argmax)
`argmax`
[,](../reference/generated/numpy.argmin.html#numpy.argmin)
`argmin`
[,](../reference/generated/numpy.argsort.html#numpy.argsort)
`argsort`
[,](../reference/generated/numpy.average.html#numpy.average)
`average`
[,](../reference/generated/numpy.bincount.html#numpy.bincount)
`bincount`
[,](../reference/generated/numpy.ceil.html#numpy.ceil)
`ceil`
[,](../reference/generated/numpy.clip.html#numpy.clip)
`clip`
[,](../reference/generated/numpy.conj.html#numpy.conj)
`conj`
[,](../reference/generated/numpy.corrcoef.html#numpy.corrcoef)
`corrcoef`
[,](../reference/generated/numpy.cov.html#numpy.cov)
`cov`
[,](../reference/generated/numpy.cross.html#numpy.cross)
`cross`
[,](../reference/generated/numpy.cumprod.html#numpy.cumprod)
`cumprod`
[,](../reference/generated/numpy.cumsum.html#numpy.cumsum)
`cumsum`
[,](../reference/generated/numpy.diff.html#numpy.diff)
`diff`
[,](../reference/generated/numpy.dot.html#numpy.dot)
`dot`
[,](../reference/generated/numpy.floor.html#numpy.floor)
`floor`
[,](../reference/generated/numpy.inner.html#numpy.inner)
`inner`
[,](../reference/generated/numpy.invert.html#numpy.invert)
`invert`
[,](../reference/generated/numpy.lexsort.html#numpy.lexsort)
`lexsort`
[,](../reference/generated/numpy.max.html#numpy.max)
`max`
[,](../reference/generated/numpy.maximum.html#numpy.maximum)
`maximum`
[,](../reference/generated/numpy.mean.html#numpy.mean)
`mean`
[,](../reference/generated/numpy.median.html#numpy.median)
`median`
[,](../reference/generated/numpy.min.html#numpy.min)
`min`
[,](../reference/generated/numpy.minimum.html#numpy.minimum)
`minimum`
[,](../reference/generated/numpy.nonzero.html#numpy.nonzero)
`nonzero`
[,](../reference/generated/numpy.outer.html#numpy.outer)
`outer`
[,](../reference/generated/numpy.prod.html#numpy.prod)
`prod`
[,](https://docs.python.org/3/library/re.html#module-re)
`re`
[,](../reference/generated/numpy.round.html#numpy.round)
`round`
[,](../reference/generated/numpy.sort.html#numpy.sort)
`sort`
[,](../reference/generated/numpy.std.html#numpy.std)
`std`
[,](../reference/generated/numpy.sum.html#numpy.sum)
`sum`
[,](../reference/generated/numpy.trace.html#numpy.trace)
`trace`
[,](../reference/generated/numpy.transpose.html#numpy.transpose)
`transpose`
[,](../reference/generated/numpy.var.html#numpy.var)
`var`
[,](../reference/generated/numpy.vdot.html#numpy.vdot)
`vdot`
[,](../reference/generated/numpy.vectorize.html#numpy.vectorize)
`vectorize`
`where`
### Indexing, Slicing and Iterating[#](#indexing-slicing-and-iterating)
**One-dimensional** arrays can be indexed, sliced and iterated over,
much like
[lists](https://docs.python.org/tutorial/introduction.html#lists)
and other Python sequences.
```
>>> a = np.arange(10)**3
>>> a
array([ 0, 1, 8, 27, 64, 125, 216, 343, 512, 729])
>>> a[2]
8
>>> a[2:5]
array([ 8, 27, 64])
>>> # equivalent to a[0:6:2] = 1000;
>>> # from start to position 6, exclusive, set every 2nd element to 1000
>>> a[:6:2] = 1000
>>> a
array([1000, 1, 1000, 27, 1000, 125, 216, 343, 512, 729])
>>> a[::-1] # reversed a
array([ 729, 512, 343, 216, 125, 1000, 27, 1000, 1, 1000])
>>> for i in a:
... print(i**(1 / 3.))
...
9.999999999999998 # may vary
1.0
9.999999999999998
3.0
9.999999999999998
4.999999999999999
5.999999999999999
6.999999999999999
7.999999999999999
8.999999999999998
```
**Multidimensional** arrays can have one index per axis. These indices
are given in a tuple separated by commas:
```
>>> def f(x, y):
... return 10 * x + y
...
>>> b = np.fromfunction(f, (5, 4), dtype=int)
>>> b
array([[ 0, 1, 2, 3],
[10, 11, 12, 13],
[20, 21, 22, 23],
[30, 31, 32, 33],
[40, 41, 42, 43]])
>>> b[2, 3]
23
>>> b[0:5, 1] # each row in the second column of b
array([ 1, 11, 21, 31, 41])
>>> b[:, 1] # equivalent to the previous example
array([ 1, 11, 21, 31, 41])
>>> b[1:3, :] # each column in the second and third row of b
array([[10, 11, 12, 13],
[20, 21, 22, 23]])
```
When fewer indices are provided than the number of axes, the missing
indices are considered complete slices`:`

```
>>> b[-1] # the last row. Equivalent to b[-1, :]
array([40, 41, 42, 43])
```
The expression within brackets in `b[i]`
is treated as an `i`
followed by as many instances of `:`
as needed to represent the
remaining axes. NumPy also allows you to write this using dots as
`b[i, ...]`
.

The **dots** (`...`
) represent as many colons as needed to produce a
complete indexing tuple. For example, if `x`
is an array with 5
axes, then

`x[1, 2, ...]`
is equivalent to`x[1, 2, :, :, :]`
,
`x[..., 3]`
to`x[:, :, :, :, 3]`
and
`x[4, ..., 5, :]`
to`x[4, :, :, 5, :]`
.
```
>>> c = np.array([[[ 0, 1, 2], # a 3D array (two stacked 2D arrays)
... [ 10, 12, 13]],
... [[100, 101, 102],
... [110, 112, 113]]])
>>> c.shape
(2, 2, 3)
>>> c[1, ...] # same as c[1, :, :] or c[1]
array([[100, 101, 102],
[110, 112, 113]])
>>> c[..., 2] # same as c[:, :, 2]
array([[ 2, 13],
[102, 113]])
```
**Iterating** over multidimensional arrays is done with respect to the
first axis:
```
>>> for row in b:
... print(row)
...
[0 1 2 3]
[10 11 12 13]
[20 21 22 23]
[30 31 32 33]
[40 41 42 43]
```
However, if one wants to perform an operation on each element in the
array, one can use the `flat`
attribute which is an
[iterator](https://docs.python.org/tutorial/classes.html#iterators)
over all the elements of the array:

```
>>> for element in b.flat:
... print(element)
...
0
1
2
3
10
11
12
13
20
21
22
23
30
31
32
33
40
41
42
43
```
See also

[Indexing on ndarrays](basics.indexing.html#basics-indexing),
[Indexing routines](../reference/arrays.indexing.html#arrays-indexing) (reference),
[ newaxis](../reference/constants.html#numpy.newaxis),
[,](../reference/generated/numpy.ndenumerate.html#numpy.ndenumerate)
`ndenumerate`
`indices`
## Shape Manipulation[#](#shape-manipulation)
### Changing the shape of an array[#](#changing-the-shape-of-an-array)
An array has a shape given by the number of elements along each axis:

```
>>> a = np.floor(10 * rg.random((3, 4)))
>>> a
array([[3., 7., 3., 4.],
[1., 4., 2., 2.],
[7., 2., 4., 9.]])
>>> a.shape
(3, 4)
```
The shape of an array can be changed with various commands. Note that the following three commands all return a modified array, but do not change the original array:

```
>>> a.ravel() # returns the array, flattened
array([3., 7., 3., 4., 1., 4., 2., 2., 7., 2., 4., 9.])
>>> a.reshape(6, 2) # returns the array with a modified shape
array([[3., 7.],
[3., 4.],
[1., 4.],
[2., 2.],
[7., 2.],
[4., 9.]])
>>> a.T # returns the array, transposed
array([[3., 1., 7.],
[7., 4., 2.],
[3., 2., 4.],
[4., 2., 9.]])
>>> a.T.shape
(4, 3)
>>> a.shape
(3, 4)
```
The order of the elements in the array resulting from `ravel`
is
normally “C-style”, that is, the rightmost index “changes the fastest”,
so the element after `a[0, 0]`
is `a[0, 1]`
. If the array is reshaped to some
other shape, again the array is treated as “C-style”. NumPy normally
creates arrays stored in this order, so `ravel`
will usually not need to
copy its argument, but if the array was made by taking slices of another
array or created with unusual options, it may need to be copied. The
functions `ravel`
and `reshape`
can also be instructed, using an
optional argument, to use FORTRAN-style arrays, in which the leftmost
index changes the fastest.

The [ reshape](../reference/generated/numpy.reshape.html#numpy.reshape) function returns its
argument with a modified shape, whereas the

[method modifies the array itself:](../reference/generated/numpy.ndarray.resize.html#numpy.ndarray.resize)
`ndarray.resize`
```
>>> a
array([[3., 7., 3., 4.],
[1., 4., 2., 2.],
[7., 2., 4., 9.]])
>>> a.resize((2, 6))
>>> a
array([[3., 7., 3., 4., 1., 4.],
[2., 2., 7., 2., 4., 9.]])
```
If a dimension is given as `-1`
in a reshaping operation, the other
dimensions are automatically calculated:

```
>>> a.reshape(3, -1)
array([[3., 7., 3., 4.],
[1., 4., 2., 2.],
[7., 2., 4., 9.]])
```
See also

### Stacking together different arrays[#](#stacking-together-different-arrays)
Several arrays can be stacked together along different axes:

```
>>> a = np.floor(10 * rg.random((2, 2)))
>>> a
array([[9., 7.],
[5., 2.]])
>>> b = np.floor(10 * rg.random((2, 2)))
>>> b
array([[1., 9.],
[5., 1.]])
>>> np.vstack((a, b))
array([[9., 7.],
[5., 2.],
[1., 9.],
[5., 1.]])
>>> np.hstack((a, b))
array([[9., 7., 1., 9.],
[5., 2., 5., 1.]])
```
The function [ column_stack](../reference/generated/numpy.column_stack.html#numpy.column_stack) stacks 1D arrays as columns into a 2D array.
It is equivalent to

[only for 2D arrays:](../reference/generated/numpy.hstack.html#numpy.hstack)
`hstack`
```
>>> from numpy import newaxis
>>> np.column_stack((a, b)) # with 2D arrays
array([[9., 7., 1., 9.],
[5., 2., 5., 1.]])
>>> a = np.array([4., 2.])
>>> b = np.array([3., 8.])
>>> np.column_stack((a, b)) # returns a 2D array
array([[4., 3.],
[2., 8.]])
>>> np.hstack((a, b)) # the result is different
array([4., 2., 3., 8.])
>>> a[:, newaxis] # view `a` as a 2D column vector
array([[4.],
[2.]])
>>> np.column_stack((a[:, newaxis], b[:, newaxis]))
array([[4., 3.],
[2., 8.]])
>>> np.hstack((a[:, newaxis], b[:, newaxis])) # the result is the same
array([[4., 3.],
[2., 8.]])
```
On the other hand, the function [ row_stack](../reference/generated/numpy.row_stack.html#numpy.row_stack) is equivalent to

[for any input arrays. In fact,](../reference/generated/numpy.vstack.html#numpy.vstack)
`vstack`
[is an alias for](../reference/generated/numpy.row_stack.html#numpy.row_stack)
`row_stack`
[:](../reference/generated/numpy.vstack.html#numpy.vstack)
`vstack`
```
>>> np.column_stack is np.hstack
False
>>> np.row_stack is np.vstack
True
```
In general, for arrays with more than two dimensions,
[ hstack](../reference/generated/numpy.hstack.html#numpy.hstack) stacks along their second
axes,

[stacks along their first axes, and](../reference/generated/numpy.vstack.html#numpy.vstack)
`vstack`
[allows for an optional arguments giving the number of the axis along which the concatenation should happen.](../reference/generated/numpy.concatenate.html#numpy.concatenate)
`concatenate`
**Note**
In complex cases, [ r_](../reference/generated/numpy.r_.html#numpy.r_) and

[are useful for creating arrays by stacking numbers along one axis. They allow the use of range literals](../reference/generated/numpy.c_.html#numpy.c_)
`c_`
`:`
.```
>>> np.r_[1:4, 0, 4]
array([1, 2, 3, 0, 4])
```
When used with arrays as arguments,
[ r_](../reference/generated/numpy.r_.html#numpy.r_) and

[are similar to](../reference/generated/numpy.c_.html#numpy.c_)
`c_`
[and](../reference/generated/numpy.vstack.html#numpy.vstack)
`vstack`
[in their default behavior, but allow for an optional argument giving the number of the axis along which to concatenate.](../reference/generated/numpy.hstack.html#numpy.hstack)
`hstack`
See also

[ hstack](../reference/generated/numpy.hstack.html#numpy.hstack),
[,](../reference/generated/numpy.vstack.html#numpy.vstack)
`vstack`
[,](../reference/generated/numpy.column_stack.html#numpy.column_stack)
`column_stack`
[,](../reference/generated/numpy.concatenate.html#numpy.concatenate)
`concatenate`
[,](../reference/generated/numpy.c_.html#numpy.c_)
`c_`
`r_`
### Splitting one array into several smaller ones[#](#splitting-one-array-into-several-smaller-ones)
Using [ hsplit](../reference/generated/numpy.hsplit.html#numpy.hsplit), you can split an
array along its horizontal axis, either by specifying the number of
equally shaped arrays to return, or by specifying the columns after
which the division should occur:

```
>>> a = np.floor(10 * rg.random((2, 12)))
>>> a
array([[6., 7., 6., 9., 0., 5., 4., 0., 6., 8., 5., 2.],
[8., 5., 5., 7., 1., 8., 6., 7., 1., 8., 1., 0.]])
>>> # Split `a` into 3
>>> np.hsplit(a, 3)
[array([[6., 7., 6., 9.],
[8., 5., 5., 7.]]), array([[0., 5., 4., 0.],
[1., 8., 6., 7.]]), array([[6., 8., 5., 2.],
[1., 8., 1., 0.]])]
>>> # Split `a` after the third and the fourth column
>>> np.hsplit(a, (3, 4))
[array([[6., 7., 6.],
[8., 5., 5.]]), array([[9.],
[7.]]), array([[0., 5., 4., 0., 6., 8., 5., 2.],
[1., 8., 6., 7., 1., 8., 1., 0.]])]
```
[ vsplit](../reference/generated/numpy.vsplit.html#numpy.vsplit) splits along the vertical
axis, and
[allows one to specify along which axis to split.](../reference/generated/numpy.array_split.html#numpy.array_split)
`array_split`
## Copies and Views[#](#copies-and-views)
When operating and manipulating arrays, their data is sometimes copied into a new array and sometimes not. This is often a source of confusion for beginners. There are three cases:

### No Copy at All[#](#no-copy-at-all)
Simple assignments make no copy of objects or their data.

```
>>> a = np.array([[ 0, 1, 2, 3],
... [ 4, 5, 6, 7],
... [ 8, 9, 10, 11]])
>>> b = a # no new object is created
>>> b is a # a and b are two names for the same ndarray object
True
```
Python passes mutable objects as references, so function calls make no copy.

```
>>> def f(x):
... print(id(x))
...
>>> id(a) # id is a unique identifier of an object
148293216 # may vary
>>> f(a)
148293216 # may vary
```
### View or Shallow Copy[#](#view-or-shallow-copy)
Different array objects can share the same data. The `view`
method
creates a new array object that looks at the same data.

```
>>> c = a.view()
>>> c is a
False
>>> c.base is a # c is a view of the data owned by a
True
>>> c.flags.owndata
False
>>>
>>> c = c.reshape((2, 6)) # a's shape doesn't change
>>> a.shape
(3, 4)
>>> c[0, 4] = 1234 # a's data changes
>>> a
array([[ 0, 1, 2, 3],
[1234, 5, 6, 7],
[ 8, 9, 10, 11]])
```
Slicing an array returns a view of it:

```
>>> s = a[:, 1:3]
>>> s[:] = 10 # s[:] is a view of s. Note the difference between s = 10 and s[:] = 10
>>> a
array([[ 0, 10, 10, 3],
[1234, 10, 10, 7],
[ 8, 10, 10, 11]])
```
### Deep Copy[#](#deep-copy)
The `copy`
method makes a complete copy of the array and its data.

```
>>> d = a.copy() # a new array object with new data is created
>>> d is a
False
>>> d.base is a # d doesn't share anything with a
False
>>> d[0, 0] = 9999
>>> a
array([[ 0, 10, 10, 3],
[1234, 10, 10, 7],
[ 8, 10, 10, 11]])
```
Sometimes `copy`
should be called after slicing if the original array is not required anymore.
For example, suppose `a`
is a huge intermediate result and the final result `b`
only contains
a small fraction of `a`
, a deep copy should be made when constructing `b`
with slicing:

```
>>> a = np.arange(int(1e8))
>>> b = a[:100].copy()
>>> del a # the memory of ``a`` can be released.
```
If `b = a[:100]`
is used instead, `a`
is referenced by `b`
and will persist in memory
even if `del a`
is executed.

### Functions and Methods Overview[#](#functions-and-methods-overview)
Here is a list of some useful NumPy functions and methods names
ordered in categories. See [Routines](../reference/routines.html#routines) for the full list.

Array Creation
-
,`arange`
,`array`
,`copy`
,`empty`
,`empty_like`
,`eye`
,`fromfile`
,`fromfunction`
,`identity`
,`linspace`
,`logspace`
,`mgrid`
,`ogrid`
,`ones`
,`ones_like`
,`r_`
,`zeros`
`zeros_like`
Conversions
-
Manipulations
-
,`array_split`
,`column_stack`
,`concatenate`
,`diagonal`
,`dsplit`
,`dstack`
,`hsplit`
,`hstack`
,`ndarray.item`
,`newaxis`
,`ravel`
,`repeat`
,`reshape`
,`resize`
,`squeeze`
,`swapaxes`
,`take`
,`transpose`
,`vsplit`
`vstack`
Questions
-
Ordering
-
Operations
-
,`choose`
,`compress`
,`cumprod`
,`cumsum`
,`inner`
,`ndarray.fill`
,`imag`
,`prod`
,`put`
,`putmask`
,`real`
`sum`
Basic Statistics
-
Basic Linear Algebra
-
,`cross`
,`dot`
,`outer`
,`linalg.svd`
`vdot`
## Less Basic[#](#less-basic)
### Broadcasting rules[#](#broadcasting-rules)
Broadcasting allows universal functions to deal in a meaningful way with inputs that do not have exactly the same shape.

The first rule of broadcasting is that if all input arrays do not have the same number of dimensions, a “1” will be repeatedly prepended to the shapes of the smaller arrays until all the arrays have the same number of dimensions.

The second rule of broadcasting ensures that arrays with a size of 1 along a particular dimension act as if they had the size of the array with the largest shape along that dimension. The value of the array element is assumed to be the same along that dimension for the “broadcast” array.

After application of the broadcasting rules, the sizes of all arrays
must match. More details can be found in [Broadcasting](basics.broadcasting.html#basics-broadcasting).

## Advanced indexing and index tricks[#](#advanced-indexing-and-index-tricks)
NumPy offers more indexing facilities than regular Python sequences. In addition to indexing by integers and slices, as we saw before, arrays can be indexed by arrays of integers and arrays of booleans.

### Indexing with Arrays of Indices[#](#indexing-with-arrays-of-indices)
```
>>> a = np.arange(12)**2 # the first 12 square numbers
>>> i = np.array([1, 1, 3, 8, 5]) # an array of indices
>>> a[i] # the elements of `a` at the positions `i`
array([ 1, 1, 9, 64, 25])
>>>
>>> j = np.array([[3, 4], [9, 7]]) # a bidimensional array of indices
>>> a[j] # the same shape as `j`
array([[ 9, 16],
[81, 49]])
```
When the indexed array `a`
is multidimensional, a single array of
indices refers to the first dimension of `a`
. The following example
shows this behavior by converting an image of labels into a color image
using a palette.

```
>>> palette = np.array([[0, 0, 0], # black
... [255, 0, 0], # red
... [0, 255, 0], # green
... [0, 0, 255], # blue
... [255, 255, 255]]) # white
>>> image = np.array([[0, 1, 2, 0], # each value corresponds to a color in the palette
... [0, 3, 4, 0]])
>>> palette[image] # the (2, 4, 3) color image
array([[[ 0, 0, 0],
[255, 0, 0],
[ 0, 255, 0],
[ 0, 0, 0]],
[[ 0, 0, 0],
[ 0, 0, 255],
[255, 255, 255],
[ 0, 0, 0]]])
```
We can also give indexes for more than one dimension. The arrays of indices for each dimension must have the same shape.

```
>>> a = np.arange(12).reshape(3, 4)
>>> a
array([[ 0, 1, 2, 3],
[ 4, 5, 6, 7],
[ 8, 9, 10, 11]])
>>> i = np.array([[0, 1], # indices for the first dim of `a`
... [1, 2]])
>>> j = np.array([[2, 1], # indices for the second dim
... [3, 3]])
>>>
>>> a[i, j] # i and j must have equal shape
array([[ 2, 5],
[ 7, 11]])
>>>
>>> a[i, 2]
array([[ 2, 6],
[ 6, 10]])
>>>
>>> a[:, j]
array([[[ 2, 1],
[ 3, 3]],
[[ 6, 5],
[ 7, 7]],
[[10, 9],
[11, 11]]])
```
In Python, `arr[i, j]`
is exactly the same as `arr[(i, j)]`
—so we can
put `i`
and `j`
in a `tuple`
and then do the indexing with that.

```
>>> l = (i, j)
>>> # equivalent to a[i, j]
>>> a[l]
array([[ 2, 5],
[ 7, 11]])
```
However, we can not do this by putting `i`
and `j`
into an array,
because this array will be interpreted as indexing the first dimension
of `a`
.

```
>>> s = np.array([i, j])
>>> # not what we want
>>> a[s]
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
IndexError: index 3 is out of bounds for axis 0 with size 3
>>> # same as `a[i, j]`
>>> a[tuple(s)]
array([[ 2, 5],
[ 7, 11]])
```
Another common use of indexing with arrays is the search of the maximum value of time-dependent series:

```
>>> time = np.linspace(20, 145, 5) # time scale
>>> data = np.sin(np.arange(20)).reshape(5, 4) # 4 time-dependent series
>>> time
array([ 20. , 51.25, 82.5 , 113.75, 145. ])
>>> data
array([[ 0. , 0.84147098, 0.90929743, 0.14112001],
[-0.7568025 , -0.95892427, -0.2794155 , 0.6569866 ],
[ 0.98935825, 0.41211849, -0.54402111, -0.99999021],
[-0.53657292, 0.42016704, 0.99060736, 0.65028784],
[-0.28790332, -0.96139749, -0.75098725, 0.14987721]])
>>> # index of the maxima for each series
>>> ind = data.argmax(axis=0)
>>> ind
array([2, 0, 3, 1])
>>> # times corresponding to the maxima
>>> time_max = time[ind]
>>>
>>> data_max = data[ind, range(data.shape[1])] # => data[ind[0], 0], data[ind[1], 1]...
>>> time_max
array([ 82.5 , 20. , 113.75, 51.25])
>>> data_max
array([0.98935825, 0.84147098, 0.99060736, 0.6569866 ])
>>> np.all(data_max == data.max(axis=0))
True
```
You can also use indexing with arrays as a target to assign to:

```
>>> a = np.arange(5)
>>> a
array([0, 1, 2, 3, 4])
>>> a[[1, 3, 4]] = 0
>>> a
array([0, 0, 2, 0, 0])
```
However, when the list of indices contains repetitions, the assignment is done several times, leaving behind the last value:

```
>>> a = np.arange(5)
>>> a[[0, 0, 2]] = [1, 2, 3]
>>> a
array([2, 1, 3, 3, 4])
```
This is reasonable enough, but watch out if you want to use Python’s
`+=`
construct, as it may not do what you expect:

```
>>> a = np.arange(5)
>>> a[[0, 0, 2]] += 1
>>> a
array([1, 1, 3, 3, 4])
```
Even though 0 occurs twice in the list of indices, the 0th element is
only incremented once. This is because Python requires `a += 1`
to be
equivalent to `a = a + 1`
.

### Indexing with Boolean Arrays[#](#indexing-with-boolean-arrays)
When we index arrays with arrays of (integer) indices we are providing the list of indices to pick. With boolean indices the approach is different; we explicitly choose which items in the array we want and which ones we don’t.

The most natural way one can think of for boolean indexing is to use
boolean arrays that have *the same shape* as the original array:

```
>>> a = np.arange(12).reshape(3, 4)
>>> b = a > 4
>>> b # `b` is a boolean with `a`'s shape
array([[False, False, False, False],
[False, True, True, True],
[ True, True, True, True]])
>>> a[b] # 1d array with the selected elements
array([ 5, 6, 7, 8, 9, 10, 11])
```
This property can be very useful in assignments:

```
>>> a[b] = 0 # All elements of `a` higher than 4 become 0
>>> a
array([[0, 1, 2, 3],
[4, 0, 0, 0],
[0, 0, 0, 0]])
```
You can look at the following
example to see
how to use boolean indexing to generate an image of the [Mandelbrot
set](https://en.wikipedia.org/wiki/Mandelbrot_set):

```
>>> import numpy as np
>>> import matplotlib.pyplot as plt
>>> def mandelbrot(h, w, maxit=20, r=2):
... """Returns an image of the Mandelbrot fractal of size (h,w)."""
... x = np.linspace(-2.5, 1.5, 4*h+1)
... y = np.linspace(-1.5, 1.5, 3*w+1)
... A, B = np.meshgrid(x, y)
... C = A + B*1j
... z = np.zeros_like(C)
... divtime = maxit + np.zeros(z.shape, dtype=int)
...
... for i in range(maxit):
... z = z**2 + C
... diverge = abs(z) > r # who is diverging
... div_now = diverge & (divtime == maxit) # who is diverging now
... divtime[div_now] = i # note when
... z[diverge] = r # avoid diverging too much
...
... return divtime
>>> plt.clf()
>>> plt.imshow(mandelbrot(400, 400))
```
The second way of indexing with booleans is more similar to integer indexing; for each dimension of the array we give a 1D boolean array selecting the slices we want:

```
>>> a = np.arange(12).reshape(3, 4)
>>> b1 = np.array([False, True, True]) # first dim selection
>>> b2 = np.array([True, False, True, False]) # second dim selection
>>>
>>> a[b1, :] # selecting rows
array([[ 4, 5, 6, 7],
[ 8, 9, 10, 11]])
>>>
>>> a[b1] # same thing
array([[ 4, 5, 6, 7],
[ 8, 9, 10, 11]])
>>>
>>> a[:, b2] # selecting columns
array([[ 0, 2],
[ 4, 6],
[ 8, 10]])
>>>
>>> a[b1, b2] # a weird thing to do
array([ 4, 10])
```
Note that the length of the 1D boolean array must coincide with the
length of the dimension (or axis) you want to slice. In the previous
example, `b1`
has length 3 (the number of *rows* in `a`
), and
`b2`
(of length 4) is suitable to index the 2nd axis (columns) of
`a`
.

### The ix_() function[#](#the-ix-function)
The [ ix_](../reference/generated/numpy.ix_.html#numpy.ix_) function can be used to combine different vectors so as to
obtain the result for each n-uplet. For example, if you want to compute
all the a+b*c for all the triplets taken from each of the vectors a, b
and c:

```
>>> a = np.array([2, 3, 4, 5])
>>> b = np.array([8, 5, 4])
>>> c = np.array([5, 4, 6, 8, 3])
>>> ax, bx, cx = np.ix_(a, b, c)
>>> ax
array([[[2]],
[[3]],
[[4]],
[[5]]])
>>> bx
array([[[8],
[5],
[4]]])
>>> cx
array([[[5, 4, 6, 8, 3]]])
>>> ax.shape, bx.shape, cx.shape
((4, 1, 1), (1, 3, 1), (1, 1, 5))
>>> result = ax + bx * cx
>>> result
array([[[42, 34, 50, 66, 26],
[27, 22, 32, 42, 17],
[22, 18, 26, 34, 14]],
[[43, 35, 51, 67, 27],
[28, 23, 33, 43, 18],
[23, 19, 27, 35, 15]],
[[44, 36, 52, 68, 28],
[29, 24, 34, 44, 19],
[24, 20, 28, 36, 16]],
[[45, 37, 53, 69, 29],
[30, 25, 35, 45, 20],
[25, 21, 29, 37, 17]]])
>>> result[3, 2, 4]
17
>>> a[3] + b[2] * c[4]
17
```
You could also implement the reduce as follows:

```
>>> def ufunc_reduce(ufct, *vectors):
... vs = np.ix_(*vectors)
... r = ufct.identity
... for v in vs:
... r = ufct(r, v)
... return r
```
and then use it as:

```
>>> ufunc_reduce(np.add, a, b, c)
array([[[15, 14, 16, 18, 13],
[12, 11, 13, 15, 10],
[11, 10, 12, 14, 9]],
[[16, 15, 17, 19, 14],
[13, 12, 14, 16, 11],
[12, 11, 13, 15, 10]],
[[17, 16, 18, 20, 15],
[14, 13, 15, 17, 12],
[13, 12, 14, 16, 11]],
[[18, 17, 19, 21, 16],
[15, 14, 16, 18, 13],
[14, 13, 15, 17, 12]]])
```
The advantage of this version of reduce compared to the normal
ufunc.reduce is that it makes use of the
[broadcasting rules](#broadcasting-rules)
in order to avoid creating an argument array the size of the output
times the number of vectors.

### Indexing with strings[#](#indexing-with-strings)
See [Structured arrays](basics.rec.html#structured-arrays).

## Tricks and Tips[#](#tricks-and-tips)
Here we give a list of short and useful tips.

### “Automatic” Reshaping[#](#automatic-reshaping)
To change the dimensions of an array, you can omit one of the sizes which will then be deduced automatically:

```
>>> a = np.arange(30)
>>> b = a.reshape((2, -1, 3)) # -1 means "whatever is needed"
>>> b.shape
(2, 5, 3)
>>> b
array([[[ 0, 1, 2],
[ 3, 4, 5],
[ 6, 7, 8],
[ 9, 10, 11],
[12, 13, 14]],
[[15, 16, 17],
[18, 19, 20],
[21, 22, 23],
[24, 25, 26],
[27, 28, 29]]])
```
### Vector Stacking[#](#vector-stacking)
How do we construct a 2D array from a list of equally-sized row vectors?
In MATLAB this is quite easy: if `x`
and `y`
are two vectors of the
same length you only need do `m=[x;y]`
. In NumPy this works via the
functions `column_stack`
, `dstack`
, `hstack`
and `vstack`
,
depending on the dimension in which the stacking is to be done. For
example:

```
>>> x = np.arange(0, 10, 2)
>>> y = np.arange(5)
>>> m = np.vstack([x, y])
>>> m
array([[0, 2, 4, 6, 8],
[0, 1, 2, 3, 4]])
>>> xy = np.hstack([x, y])
>>> xy
array([0, 2, 4, 6, 8, 0, 1, 2, 3, 4])
```
The logic behind those functions in more than two dimensions can be strange.

See also

### Histograms[#](#histograms)
The NumPy `histogram`
function applied to an array returns a pair of
vectors: the histogram of the array and a vector of the bin edges. Beware:
`matplotlib`
also has a function to build histograms (called `hist`
,
as in Matlab) that differs from the one in NumPy. The main difference is
that `pylab.hist`
plots the histogram automatically, while
`numpy.histogram`
only generates the data.

```
>>> import numpy as np
>>> rg = np.random.default_rng(1)
>>> import matplotlib.pyplot as plt
>>> # Build a vector of 10000 normal deviates with variance 0.5^2 and mean 2
>>> mu, sigma = 2, 0.5
>>> v = rg.normal(mu, sigma, 10000)
>>> # Plot a normalized histogram with 50 bins
>>> plt.hist(v, bins=50, density=True) # matplotlib version (plot)
(array...)
>>> # Compute the histogram with numpy and then plot it
>>> (n, bins) = np.histogram(v, bins=50, density=True) # NumPy version (no plot)
>>> plt.plot(.5 * (bins[1:] + bins[:-1]), n)
```
With Matplotlib >=3.4 you can also use `plt.stairs(n, bins)`
.# NumPy 1.21.0 Release Notes[#](#numpy-1-21-0-release-notes)
The NumPy 1.21.0 release highlights are

continued SIMD work covering more functions and platforms,

initial work on the new dtype infrastructure and casting,

universal2 wheels for Python 3.8 and Python 3.9 on Mac,

improved documentation,

improved annotations,

new

`PCG64DXSM`
bitgenerator for random numbers.
In addition there are the usual large number of bug fixes and other improvements.

The Python versions supported for this release are 3.7-3.9. Official support for Python 3.10 will be added when it is released.

Warning

There are unresolved problems compiling NumPy 1.20.0 with gcc-11.1.

Optimization level

*-O3*results in many incorrect warnings when running the tests.
On some hardware NumPY will hang in an infinite loop.

## New functions[#](#new-functions)
### Add `PCG64DXSM`
`BitGenerator`
[#](#add-pcg64dxsm-bitgenerator)
`PCG64DXSM`
`BitGenerator`
Uses of the `PCG64`
`BitGenerator`
in a massively-parallel context have been
shown to have statistical weaknesses that were not apparent at the first
release in numpy 1.17. Most users will never observe this weakness and are
safe to continue to use `PCG64`
. We have introduced a new `PCG64DXSM`
`BitGenerator`
that will eventually become the new default `BitGenerator`
implementation used by `default_rng`
in future releases. `PCG64DXSM`
solves
the statistical weakness while preserving the performance and the features of
`PCG64`
.

See [Upgrading PCG64 with PCG64DXSM](../reference/random/upgrading-pcg64.html#upgrading-pcg64) for more details.

([gh-18906](https://github.com/numpy/numpy/pull/18906))

## Expired deprecations[#](#expired-deprecations)
The

`shape`
argumentcannot be passed as`unravel_index`
`dims`
keyword argument anymore. (Was deprecated in NumPy 1.16.)(

[gh-17900](https://github.com/numpy/numpy/pull/17900))
The function

`PyUFunc_GenericFunction`
has been disabled. It was deprecated in NumPy 1.19. Users should call the ufunc directly using the Python API.(

[gh-18697](https://github.com/numpy/numpy/pull/18697))
The function

`PyUFunc_SetUsesArraysAsData`
has been disabled. It was deprecated in NumPy 1.19.(

[gh-18697](https://github.com/numpy/numpy/pull/18697))
The class

`PolyBase`
has been removed (deprecated in numpy 1.9.0). Please use the abstract`ABCPolyBase`
class instead.(

[gh-18963](https://github.com/numpy/numpy/pull/18963))
The unused

`PolyError`
and`PolyDomainError`
exceptions are removed.(

[gh-18963](https://github.com/numpy/numpy/pull/18963))
## Deprecations[#](#deprecations)
### The `.dtype`
attribute must return a `dtype`
[#](#the-dtype-attribute-must-return-a-dtype)
A `DeprecationWarning`
is now given if the `.dtype`
attribute
of an object passed into `np.dtype`
or as a `dtype=obj`
argument
is not a dtype. NumPy will stop attempting to recursively coerce the
result of `.dtype`
.

([gh-13578](https://github.com/numpy/numpy/pull/13578))

### Inexact matches for `numpy.convolve`
and `numpy.correlate`
are deprecated[#](#inexact-matches-for-numpy-convolve-and-numpy-correlate-are-deprecated)
[ convolve](../reference/generated/numpy.convolve.html#numpy.convolve) and
[now emit a warning when there are case insensitive and/or inexact matches found for](../reference/generated/numpy.correlate.html#numpy.correlate)
`correlate`
`mode`
argument in the functions.
Pass full `"same"`
, `"valid"`
, `"full"`
strings instead of
`"s"`
, `"v"`
, `"f"`
for the `mode`
argument.([gh-17492](https://github.com/numpy/numpy/pull/17492))

`np.typeDict`
has been formally deprecated[#](#np-typedict-has-been-formally-deprecated)
`np.typeDict`
is a deprecated alias for `np.sctypeDict`
and
has been so for over 14 years ([6689502](https://github.com/numpy/numpy/commit/668950285c407593a368336ff2e737c5da84af7d)).
A deprecation warning will now be issued whenever getting `np.typeDict`
.
([gh-17586](https://github.com/numpy/numpy/pull/17586))

### Exceptions will be raised during array-like creation[#](#exceptions-will-be-raised-during-array-like-creation)
When an object raised an exception during access of the special
attributes `__array__`
or `__array_interface__`
, this exception
was usually ignored.
A warning is now given when the exception is anything but AttributeError.
To silence the warning, the type raising the exception has to be adapted
to raise an `AttributeError`
.

([gh-19001](https://github.com/numpy/numpy/pull/19001))

### Four `ndarray.ctypes`
methods have been deprecated[#](#four-ndarray-ctypes-methods-have-been-deprecated)
Four methods of the [ ndarray.ctypes](../reference/generated/numpy.ndarray.ctypes.html#numpy.ndarray.ctypes) object have been deprecated,
as they are (undocumentated) implementation artifacts of their respective
properties.

The methods in question are:

`_ctypes.get_data`
(use`_ctypes.data`
instead)
`_ctypes.get_shape`
(use`_ctypes.shape`
instead)
`_ctypes.get_strides`
(use`_ctypes.strides`
instead)
`_ctypes.get_as_parameter`
(use`_ctypes._as_parameter_`
instead)
([gh-19031](https://github.com/numpy/numpy/pull/19031))

## Expired deprecations[#](#id2)
The

`shape`
argumentcannot be passed as`numpy.unravel_index`
`dims`
keyword argument anymore. (Was deprecated in NumPy 1.16.)(

[gh-17900](https://github.com/numpy/numpy/pull/17900))
The function

`PyUFunc_GenericFunction`
has been disabled. It was deprecated in NumPy 1.19. Users should call the ufunc directly using the Python API.(

[gh-18697](https://github.com/numpy/numpy/pull/18697))
The function

`PyUFunc_SetUsesArraysAsData`
has been disabled. It was deprecated in NumPy 1.19.(

[gh-18697](https://github.com/numpy/numpy/pull/18697))
### Remove deprecated `PolyBase`
and unused `PolyError`
and `PolyDomainError`
[#](#remove-deprecated-polybase-and-unused-polyerror-and-polydomainerror)
The class `PolyBase`
has been removed (deprecated in numpy 1.9.0). Please use
the abstract `ABCPolyBase`
class instead.

Furthermore, the unused `PolyError`
and `PolyDomainError`
exceptions are
removed from the [ numpy.polynomial](../reference/routines.polynomials.package.html#module-numpy.polynomial).

([gh-18963](https://github.com/numpy/numpy/pull/18963))

## Compatibility notes[#](#compatibility-notes)
### Error type changes in universal functions[#](#error-type-changes-in-universal-functions)
The universal functions may now raise different errors on invalid input in some
cases. The main changes should be that a `RuntimeError`
was replaced with a
more fitting `TypeError`
. When multiple errors were present in the same
call, NumPy may now raise a different one.

([gh-15271](https://github.com/numpy/numpy/pull/15271))

`__array_ufunc__`
argument validation[#](#array-ufunc-argument-validation)
NumPy will now partially validate arguments before calling `__array_ufunc__`
.
Previously, it was possible to pass on invalid arguments (such as a
non-existing keyword argument) when dispatch was known to occur.

([gh-15271](https://github.com/numpy/numpy/pull/15271))

`__array_ufunc__`
and additional positional arguments[#](#array-ufunc-and-additional-positional-arguments)
Previously, all positionally passed arguments were checked for
`__array_ufunc__`
support. In the case of `reduce`
, `accumulate`
, and
`reduceat`
all arguments may be passed by position. This means that when
they were passed by position, they could previously have been asked to handle
the ufunc call via `__array_ufunc__`
. Since this depended on the way the
arguments were passed (by position or by keyword), NumPy will now only dispatch
on the input and output array. For example, NumPy will never dispatch on the
`where`
array in a reduction such as `np.add.reduce`
.

([gh-15271](https://github.com/numpy/numpy/pull/15271))

### Validate input values in `Generator.uniform`
[#](#validate-input-values-in-generator-uniform)
Checked that `high - low >= 0`
in `np.random.Generator.uniform`
. Raises
`ValueError`
if `low > high`
. Previously out-of-order inputs were accepted
and silently swapped, so that if `low > high`
, the value generated was
`high + (low - high) * random()`
.

([gh-17921](https://github.com/numpy/numpy/pull/17921))

`/usr/include`
removed from default include paths[#](#usr-include-removed-from-default-include-paths)
The default include paths when building a package with `numpy.distutils`
no
longer include `/usr/include`
. This path is normally added by the compiler,
and hardcoding it can be problematic. In case this causes a problem, please
open an issue. A workaround is documented in PR 18658.

([gh-18658](https://github.com/numpy/numpy/pull/18658))

### Changes to comparisons with `dtype=...`
[#](#changes-to-comparisons-with-dtype)
When the `dtype=`
(or `signature`
) arguments to comparison
ufuncs (`equal`
, `less`
, etc.) is used, this will denote
the desired output dtype in the future.
This means that:

np.equal(2, 3, dtype=object)

will give a `FutureWarning`
that it will return an `object`
array in the future, which currently happens for:

np.equal(None, None, dtype=object)

due to the fact that `np.array(None)`
is already an object
array. (This also happens for some other dtypes.)

Since comparisons normally only return boolean arrays, providing
any other dtype will always raise an error in the future and
give a `DeprecationWarning`
now.

([gh-18718](https://github.com/numpy/numpy/pull/18718))

### Changes to `dtype`
and `signature`
arguments in ufuncs[#](#changes-to-dtype-and-signature-arguments-in-ufuncs)
The universal function arguments `dtype`
and `signature`
which are also valid for reduction such as `np.add.reduce`
(which is the implementation for `np.sum`
) will now issue
a warning when the `dtype`
provided is not a “basic” dtype.

NumPy almost always ignored metadata, byteorder or time units on these inputs. NumPy will now always ignore it and raise an error if byteorder or time unit changed. The following are the most important examples of changes which will give the error. In some cases previously the information stored was not ignored, in all of these an error is now raised:

```
# Previously ignored the byte-order (affect if non-native)
np.add(3, 5, dtype=">i32")
# The biggest impact is for timedelta or datetimes:
arr = np.arange(10, dtype="m8[s]")
# The examples always ignored the time unit "ns":
np.add(arr, arr, dtype="m8[ns]")
np.maximum.reduce(arr, dtype="m8[ns]")
# The following previously did use "ns" (as opposed to `arr.dtype`)
np.add(3, 5, dtype="m8[ns]") # Now return generic time units
np.maximum(arr, arr, dtype="m8[ns]") # Now returns "s" (from `arr`)
```
The same applies for functions like `np.sum`
which use these internally.
This change is necessary to achieve consistent handling within NumPy.

If you run into these, in most cases pass for example `dtype=np.timedelta64`
which clearly denotes a general `timedelta64`
without any unit or byte-order
defined. If you need to specify the output dtype precisely, you may do so
by either casting the inputs or providing an output array using *out=*.

NumPy may choose to allow providing an exact output `dtype`
here in the
future, which would be preceded by a `FutureWarning`
.

([gh-18718](https://github.com/numpy/numpy/pull/18718))

### Ufunc `signature=...`
and `dtype=`
generalization and `casting`
[#](#ufunc-signature-and-dtype-generalization-and-casting)
The behaviour for `np.ufunc(1.0, 1.0, signature=...)`
or
`np.ufunc(1.0, 1.0, dtype=...)`
can now yield different loops in 1.21
compared to 1.20 because of changes in promotion.
When `signature`
was previously used, the casting check on inputs
was relaxed, which could lead to downcasting inputs unsafely especially
if combined with `casting="unsafe"`
.

Casting is now guaranteed to be safe. If a signature is only
partially provided, for example using `signature=("float64", None, None)`
,
this could lead to no loop being found (an error).
In that case, it is necessary to provide the complete signature
to enforce casting the inputs.
If `dtype="float64"`
is used or only outputs are set (e.g.
`signature=(None, None, "float64")`
the is unchanged.
We expect that very few users are affected by this change.

Further, the meaning of `dtype="float64"`
has been slightly modified and
now strictly enforces only the correct output (and not input) DTypes.
This means it is now always equivalent to:

```
signature=(None, None, "float64")
```
(If the ufunc has two inputs and one output). Since this could lead to no loop being found in some cases, NumPy will normally also search for the loop:

```
signature=("float64", "float64", "float64")
```
if the first search failed.
In the future, this behaviour may be customized to achieve the expected
results for more complex ufuncs. (For some universal functions such as
`np.ldexp`
inputs can have different DTypes.)

([gh-18880](https://github.com/numpy/numpy/pull/18880))

### Distutils forces strict floating point model on clang[#](#distutils-forces-strict-floating-point-model-on-clang)
NumPy distutils will now always add the `-ffp-exception-behavior=strict`
compiler flag when compiling with clang. Clang defaults to a non-strict
version, which allows the compiler to generate code that does not set
floating point warnings/errors correctly.

([gh-19049](https://github.com/numpy/numpy/pull/19049))

## C API changes[#](#c-api-changes)
### Use of `ufunc->type_resolver`
and “type tuple”[#](#use-of-ufunc-type-resolver-and-type-tuple)
NumPy now normalizes the “type tuple” argument to the type resolver functions
before calling it. Note that in the use of this type resolver is legacy
behaviour and NumPy will not do so when possible. Calling
`ufunc->type_resolver`
or `PyUFunc_DefaultTypeResolver`
is strongly
discouraged and will now enforce a normalized type tuple if done. Note that
this does not affect providing a type resolver, which is expected to keep
working in most circumstances. If you have an unexpected use-case for calling
the type resolver, please inform the NumPy developers so that a solution can be
found.

([gh-18718](https://github.com/numpy/numpy/pull/18718))

## New Features[#](#new-features)
### Added a mypy plugin for handling platform-specific `numpy.number`
precisions[#](#added-a-mypy-plugin-for-handling-platform-specific-numpy-number-precisions)
A [mypy](http://mypy-lang.org/) plugin is now available for automatically assigning the (platform-dependent)
precisions of certain [ number](../reference/arrays.scalars.html#numpy.number) subclasses, including the likes of

[,](../reference/arrays.scalars.html#numpy.int_)
`int_`
[and](../reference/arrays.scalars.html#numpy.intp)
`intp`
[. See the documentation on](../reference/arrays.scalars.html#numpy.longlong)
`longlong`
[scalar types](../reference/arrays.scalars.html#arrays-scalars-built-in)for a comprehensive overview of the affected classes.
Note that while usage of the plugin is completely optional, without it the
precision of above-mentioned classes will be inferred as [ Any](https://docs.python.org/3/library/typing.html#typing.Any).

To enable the plugin, one must add it to their mypy [configuration file](https://mypy.readthedocs.io/en/stable/config_file.html):

```
[mypy]
plugins = numpy.typing.mypy_plugin
```
([gh-17843](https://github.com/numpy/numpy/pull/17843))

### Let the mypy plugin manage extended-precision `numpy.number`
subclasses[#](#let-the-mypy-plugin-manage-extended-precision-numpy-number-subclasses)
The [mypy](http://mypy-lang.org/) plugin, introduced in [numpy/numpy#17843](https://github.com/numpy/numpy/pull/17843), has been expanded:
the plugin now removes annotations for platform-specific extended-precision
types that are not available to the platform in question.
For example, it will remove [ float128](../reference/arrays.scalars.html#numpy.float128) when not available.

Without the plugin *all* extended-precision types will, as far as mypy is concerned,
be available on all platforms.

To enable the plugin, one must add it to their mypy [configuration file](https://mypy.readthedocs.io/en/stable/config_file.html):

```
[mypy]
plugins = numpy.typing.mypy_plugin
```
([gh-18322](https://github.com/numpy/numpy/pull/18322))

### New `min_digits`
argument for printing float values[#](#new-min-digits-argument-for-printing-float-values)
A new `min_digits`
argument has been added to the dragon4 float printing
functions [ format_float_positional](../reference/generated/numpy.format_float_positional.html#numpy.format_float_positional) and

[. This kwd guarantees that at least the given number of digits will be printed when printing in unique=True mode, even if the extra digits are unnecessary to uniquely specify the value. It is the counterpart to the precision argument which sets the maximum number of digits to be printed. When unique=False in fixed precision mode, it has no effect and the precision argument fixes the number of digits.](../reference/generated/numpy.format_float_scientific.html#numpy.format_float_scientific)
`format_float_scientific`
([gh-18629](https://github.com/numpy/numpy/pull/18629))

### f2py now recognizes Fortran abstract interface blocks[#](#f2py-now-recognizes-fortran-abstract-interface-blocks)
[ f2py](../f2py/usage.html#module-numpy.f2py) can now parse abstract interface blocks.
([gh-18695](https://github.com/numpy/numpy/pull/18695))

### BLAS and LAPACK configuration via environment variables[#](#blas-and-lapack-configuration-via-environment-variables)
Autodetection of installed BLAS and LAPACK libraries can be bypassed by using
the `NPY_BLAS_LIBS`
and `NPY_LAPACK_LIBS`
environment variables. Instead,
the link flags in these environment variables will be used directly, and the
language is assumed to be F77. This is especially useful in automated builds
where the BLAS and LAPACK that are installed are known exactly. A use case is
replacing the actual implementation at runtime via stub library links.

If `NPY_CBLAS_LIBS`
is set (optional in addition to `NPY_BLAS_LIBS`
), this
will be used as well, by defining `HAVE_CBLAS`
and appending the environment
variable content to the link flags.

([gh-18737](https://github.com/numpy/numpy/pull/18737))

### A runtime-subcriptable alias has been added for `ndarray`
[#](#a-runtime-subcriptable-alias-has-been-added-for-ndarray)
`numpy.typing.NDArray`
has been added, a runtime-subscriptable alias for
`np.ndarray[Any, np.dtype[~Scalar]]`
. The new type alias can be used
for annotating arrays with a given dtype and unspecified shape. 1
1 NumPy does not support the annotating of array shapes as of 1.21,
this is expected to change in the future though (see [ PEP 646](https://peps.python.org/pep-0646/)).
#### Examples[#](#examples)
```
>>> import numpy as np
>>> import numpy.typing as npt
>>> print(npt.NDArray)
numpy.ndarray[typing.Any, numpy.dtype[~ScalarType]]
>>> print(npt.NDArray[np.float64])
numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]
>>> NDArrayInt = npt.NDArray[np.int_]
>>> a: NDArrayInt = np.arange(10)
>>> def func(a: npt.ArrayLike) -> npt.NDArray[Any]:
... return np.array(a)
```
([gh-18935](https://github.com/numpy/numpy/pull/18935))

## Improvements[#](#improvements)
### Arbitrary `period`
option for `numpy.unwrap`
[#](#arbitrary-period-option-for-numpy-unwrap)
The size of the interval over which phases are unwrapped is no longer restricted to `2 * pi`
.
This is especially useful for unwrapping degrees, but can also be used for other intervals.

```
>>> phase_deg = np.mod(np.linspace(0,720,19), 360) - 180
>>> phase_deg
array([-180., -140., -100., -60., -20., 20., 60., 100., 140.,
-180., -140., -100., -60., -20., 20., 60., 100., 140.,
-180.])
>>> unwrap(phase_deg, period=360)
array([-180., -140., -100., -60., -20., 20., 60., 100., 140.,
180., 220., 260., 300., 340., 380., 420., 460., 500.,
540.])
```
([gh-16987](https://github.com/numpy/numpy/pull/16987))

`np.unique`
now returns single `NaN`
[#](#np-unique-now-returns-single-nan)
When `np.unique`
operated on an array with multiple `NaN`
entries,
its return included a `NaN`
for each entry that was `NaN`
in the original array.
This is now improved such that the returned array contains just one `NaN`
as the
last element.

Also for complex arrays all `NaN`
values are considered equivalent
(no matter whether the `NaN`
is in the real or imaginary part). As the
representant for the returned array the smallest one in the
lexicographical order is chosen - see `np.sort`
for how the lexicographical
order is defined for complex arrays.

([gh-18070](https://github.com/numpy/numpy/pull/18070))

`Generator.rayleigh`
and `Generator.geometric`
performance improved[#](#generator-rayleigh-and-generator-geometric-performance-improved)
The performance of Rayleigh and geometric random variate generation
in `Generator`
has improved. These are both transformation of exponential
random variables and the slow log-based inverse cdf transformation has
been replaced with the Ziggurat-based exponential variate generator.

This change breaks the stream of variates generated when variates from either of these distributions are produced.

([gh-18666](https://github.com/numpy/numpy/pull/18666))

### Placeholder annotations have been improved[#](#placeholder-annotations-have-been-improved)
All placeholder annotations, that were previously annotated as `typing.Any`
,
have been improved. Where appropriate they have been replaced with explicit
function definitions, classes or other miscellaneous objects.

([gh-18934](https://github.com/numpy/numpy/pull/18934))

## Performance improvements[#](#performance-improvements)
### Improved performance in integer division of NumPy arrays[#](#improved-performance-in-integer-division-of-numpy-arrays)
Integer division of NumPy arrays now uses
[libdivide](https://libdivide.com/) when the divisor is a constant. With the
usage of libdivide and other minor optimizations, there is a large speedup.
The `//`
operator and `np.floor_divide`
makes use of the new changes.

([gh-17727](https://github.com/numpy/numpy/pull/17727))

### Improve performance of `np.save`
and `np.load`
for small arrays[#](#improve-performance-of-np-save-and-np-load-for-small-arrays)
`np.save`
is now a lot faster for small arrays.
`np.load`
is also faster for small arrays,
but only when serializing with a version >= `(3, 0)`
.
Both are done by removing checks that are only relevant for Python 2, while still maintaining compatibility with arrays which might have been created by Python 2.

([gh-18657](https://github.com/numpy/numpy/pull/18657))

## Changes[#](#changes)
`numpy.piecewise`
output class now matches the input class[#](#numpy-piecewise-output-class-now-matches-the-input-class)
`numpy.piecewise`
When [ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray) subclasses are used on input to

[, they are passed on to the functions. The output will now be of the same subclass as well.](../reference/generated/numpy.piecewise.html#numpy.piecewise)
`piecewise`
([gh-18110](https://github.com/numpy/numpy/pull/18110))

### Enable Accelerate Framework[#](#enable-accelerate-framework)
With the release of macOS 11.3, several different issues that numpy was
encountering when using Accelerate Framework’s implementation of BLAS and
LAPACK should be resolved. This change enables the Accelerate Framework as an
option on macOS. If additional issues are found, please file a bug report
against Accelerate using the developer feedback assistant tool
([https://developer.apple.com/bug-reporting/](https://developer.apple.com/bug-reporting/)). We intend to address issues
promptly and plan to continue supporting and updating our BLAS and LAPACK
libraries.

([gh-18874](https://github.com/numpy/numpy/pull/18874))# Development workflow[#](#development-workflow)
You already have your own forked copy of the [NumPy](https://www.numpy.org) repository, by
following [Create a NumPy fork](gitwash/development_setup.html#forking), [Make the local copy](gitwash/development_setup.html#set-up-fork), you have configured [git](https://git-scm.com/)
by following [Git configuration](gitwash/configure_git.html#configure-git), and have linked the upstream
repository as explained in [Linking your repository to the upstream repo](https://scikit-image.org/docs/stable/gitwash/set_up_fork.html#linking-to-upstream).

What is described below is a recommended workflow with Git.

## Basic workflow[#](#basic-workflow)
In short:

Start a new

*feature branch*for each set of edits that you do. See[below](#making-a-new-feature-branch).
Hack away! See

[below](#editing-workflow)
When finished:

*Contributors*: push your feature branch to your own Github repo, and[create a pull request](#asking-for-merging).
*Core developers*: If you want to push changes without further review, see the notes[below](#pushing-to-main).
This way of working helps to keep work well organized and the history as clear as possible.

See also

There are many online tutorials to help you [learn git](https://try.github.io/). For discussions
of specific git workflows, see these discussions on [linux git workflow](https://www.mail-archive.com/dri-devel@lists.sourceforge.net/msg39091.html),
and [ipython git workflow](https://mail.python.org/pipermail/ipython-dev/2010-October/005632.html).

### Making a new feature branch[#](#making-a-new-feature-branch)
First, fetch new commits from the `upstream`
repository:

```
git fetch upstream
```
Then, create a new branch based on the main branch of the upstream repository:

```
git checkout -b my-new-feature upstream/main
```
### The editing workflow[#](#the-editing-workflow)
#### Overview[#](#overview)
```
# hack hack
git status # Optional
git diff # Optional
git add modified_file
git commit
# push the branch to your own Github repo
git push origin my-new-feature
```
#### In more detail[#](#in-more-detail)
Make some changes. When you feel that you’ve made a complete, working set of related changes, move on to the next steps.

Optional: Check which files have changed with

`git status`
(see[git status](https://www.kernel.org/pub/software/scm/git/docs/git-status.html)). You’ll see a listing like this one:# On branch my-new-feature # Changed but not updated: # (use "git add <file>..." to update what will be committed) # (use "git checkout -- <file>..." to discard changes in working directory) # # modified: README # # Untracked files: # (use "git add <file>..." to include in what will be committed) # # INSTALL no changes added to commit (use "git add" and/or "git commit -a")
Optional: Compare the changes with the previous version using with

`git diff`
([git diff](https://www.kernel.org/pub/software/scm/git/docs/git-diff.html)). This brings up a simple text browser interface that highlights the difference between your files and the previous version.
Add any relevant modified or new files using

`git add modified_file`
(see[git add](https://www.kernel.org/pub/software/scm/git/docs/git-add.html)). This puts the files into a staging area, which is a queue of files that will be added to your next commit. Only add files that have related, complete changes. Leave files with unfinished changes for later commits.
To commit the staged files into the local copy of your repo, do

`git commit`
. At this point, a text editor will open up to allow you to write a commit message. Read the[commit message section](#writing-the-commit-message)to be sure that you are writing a properly formatted and sufficiently detailed commit message. After saving your message and closing the editor, your commit will be saved. For trivial commits, a short commit message can be passed in through the command line using the`-m`
flag. For example,`git commit -am "ENH: Some message"`
.In some cases, you will see this form of the commit command:

`git commit -a`
. The extra`-a`
flag automatically commits all modified files and removes all deleted files. This can save you some typing of numerous`git add`
commands; however, it can add unwanted changes to a commit if you’re not careful. For more information, see[why the -a flag?](http://www.gitready.com/beginner/2009/01/18/the-staging-area.html)- and the helpful use-case description in the[tangled working copy problem](https://tomayko.com/writings/the-thing-about-git).
Push the changes to your forked repo on

[github](https://github.com/numpy/numpy):git push origin my-new-feature
For more information, see

[git push](https://www.kernel.org/pub/software/scm/git/docs/git-push.html).
Note

Assuming you have followed the instructions in these pages, git will create
a default link to your [github](https://github.com/numpy/numpy) repo called `origin`
. In git >= 1.7 you
can ensure that the link to origin is permanently set by using the
`--set-upstream`
option:

```
git push --set-upstream origin my-new-feature
```
From now on [git](https://git-scm.com/) will know that `my-new-feature`
is related to the
`my-new-feature`
branch in your own [github](https://github.com/numpy/numpy) repo. Subsequent push calls
are then simplified to the following:

```
git push
```
You have to use `--set-upstream`
for each new branch that you create.

It may be the case that while you were working on your edits, new commits have
been added to `upstream`
that affect your work. In this case, follow the
[Rebasing on main](#rebasing-on-main) section of this document to apply those changes to
your branch.

#### Writing the commit message[#](#writing-the-commit-message)
Commit messages should be clear and follow a few basic rules. Example:

```
ENH: add functionality X to numpy.<submodule>.
The first line of the commit message starts with a capitalized acronym
(options listed below) indicating what type of commit this is. Then a blank
line, then more text if needed. Lines shouldn't be longer than 72
characters. If the commit is related to a ticket, indicate that with
"See #3456", "See ticket 3456", "Closes #3456" or similar.
```
Describing the motivation for a change, the nature of a bug for bug fixes or
some details on what an enhancement does are also good to include in a commit
message. Messages should be understandable without looking at the code
changes. A commit message like `MAINT: fixed another one`
is an example of
what not to do; the reader has to go look for context elsewhere.

Standard acronyms to start the commit message with are:

```
API: an (incompatible) API change
BENCH: changes to the benchmark suite
BLD: change related to building numpy
BUG: bug fix
DEP: deprecate something, or remove a deprecated object
DEV: development tool or utility
DOC: documentation
ENH: enhancement
MAINT: maintenance commit (refactoring, typos, etc.)
REV: revert an earlier commit
STY: style fix (whitespace, PEP8)
TST: addition or modification of tests
TYP: static typing
REL: related to releasing numpy
```
##### Commands to skip continuous integration[#](#commands-to-skip-continuous-integration)
By default a lot of continuous integration (CI) jobs are run for every PR, from running the test suite on different operating systems and hardware platforms to building the docs. In some cases you already know that CI isn’t needed (or not all of it), for example if you work on CI config files, text in the README, or other files that aren’t involved in regular build, test or docs sequences. In such cases you may explicitly skip CI by including one of these fragments in your commit message:

`[skip ci]`
: skip all CIOnly recommended if you are still not ready for the checks to run on your PR (for example, if this is only a draft.)

`[skip actions]`
: skip GitHub Actions jobs[GitHub Actions](https://docs.github.com/actions)is where most of the CI checks are run, including the linter, benchmarking, running basic tests for most architectures and OSs, and several compiler and CPU optimization settings.[See the configuration files for these checks.](https://github.com/numpy/numpy/tree/main/.github/workflows)
`[skip travis]`
: skip TravisCI jobs[TravisCI](https://www.travis-ci.com/)will test your changes against Python 3.9 on the PowerPC and s390x architectures.[See the configuration file for these checks.](https://github.com/numpy/numpy/blob/main/.travis.yml)
`[skip azp]`
: skip Azure jobs[Azure](https://azure.microsoft.com/en-us/products/devops/pipelines)is where all comprehensive tests are run. This is an expensive run, and one you could typically skip if you do documentation-only changes, for example.[See the main configuration file for these checks.](https://github.com/numpy/numpy/blob/main/azure-pipelines.yml)
`[skip circle]`
: skip CircleCI jobs[CircleCI](https://circleci.com/)is where we build the documentation and store the generated artifact for preview in each PR. This check will also run all the docstrings examples and verify their results. If you don’t make documentation changes, but you make changes to a function’s API, for example, you may need to run these tests to verify that the doctests are still valid.[See the configuration file for these checks.](https://github.com/numpy/numpy/blob/main/.circleci/config.yml)
`[skip cirrus]`
: skip Cirrus jobs[CirrusCI](https://cirrus-ci.org/)mostly triggers Linux aarch64 and MacOS Arm64 wheels uploads.[See the configuration file for these checks.](https://github.com/numpy/numpy/blob/main/.cirrus.star)
##### Test building wheels[#](#test-building-wheels)
Numpy currently uses [cibuildwheel](https://https://cibuildwheel.readthedocs.io/en/stable/)
in order to build wheels through continuous integration services. To save resources, the
cibuildwheel wheel builders are not run by default on every single PR or commit to main.

If you would like to test that your pull request do not break the wheel builders,
you may either append `[wheel build]`
to the end of the commit message of the commit
or add one of the following labels to the pull request(if you have the permissions to do so):

`36 - Build`
: for pull requests changing build processes/configurations
`03 - Maintenance`
: for pull requests upgrading dependencies
`14 - Release`
: for pull requests preparing for a release
The wheels built via github actions (including 64-bit linux, macOS, and
windows, arm64 macOS, and 32-bit windows) will be uploaded as artifacts in zip
files. You can access them from the Summary page of the “Wheel builder”
[Action](https://github.com/numpy/numpy/actions). The aarch64 wheels built via [travis](https://app.travis-ci.com/github/numpy/numpy/builds) CI are not available as artifacts.
Additionally, the wheels will be uploaded to
[https://anaconda.org/scientific-python-nightly-wheels/](https://anaconda.org/scientific-python-nightly-wheels/) on the following conditions:

by a weekly cron job or

if the github action or travis build has been manually triggered, which requires appropriate permissions

The wheels will be uploaded to [https://anaconda.org/multibuild-wheels-staging/](https://anaconda.org/multibuild-wheels-staging/)
if the build was triggered by a tag to the repo that begins with `v`

### Get the mailing list’s opinion[#](#get-the-mailing-list-s-opinion)
If you plan a new feature or API change, it’s wisest to first email the
NumPy [mailing list](https://mail.python.org/mailman/listinfo/numpy-discussion)
asking for comment. If you haven’t heard back in a week, it’s
OK to ping the list again.

### Asking for your changes to be merged with the main repo[#](#asking-for-your-changes-to-be-merged-with-the-main-repo)
When you feel your work is finished, you can create a pull request (PR). Github
has a nice help page that outlines the process for [filing pull requests](https://help.github.com/articles/using-pull-requests/#initiating-the-pull-request).

If your changes involve modifications to the API or addition/modification of a
function, add a release note to the `doc/release/upcoming_changes/`
directory, following the instructions and format in the
`doc/release/upcoming_changes/README.rst`
file.

### Getting your PR reviewed[#](#getting-your-pr-reviewed)
We review pull requests as soon as we can, typically within a week. If you get no review comments within two weeks, feel free to ask for feedback by adding a comment on your PR (this will notify maintainers).

If your PR is large or complicated, asking for input on the numpy-discussion mailing list may also be useful.

### Rebasing on main[#](#rebasing-on-main)
This updates your feature branch with changes from the upstream [NumPy
github](https://github.com/numpy/numpy) repo. If you do not absolutely need to do this, try to avoid doing
it, except perhaps when you are finished. The first step will be to update
the remote repository with new commits from upstream:

```
git fetch upstream
```
Next, you need to update the feature branch:

```
# go to the feature branch
git checkout my-new-feature
# make a backup in case you mess up
git branch tmp my-new-feature
# rebase on upstream main branch
git rebase upstream/main
```
If you have made changes to files that have changed also upstream,
this may generate merge conflicts that you need to resolve. See
[below](#recovering-from-mess-up) for help in this case.

Finally, remove the backup branch upon a successful rebase:

```
git branch -D tmp
```
Note

Rebasing on main is preferred over merging upstream back to your
branch. Using `git merge`
and `git pull`
is discouraged when
working on feature branches.

### Recovering from mess-ups[#](#recovering-from-mess-ups)
Sometimes, you mess up merges or rebases. Luckily, in Git it is relatively straightforward to recover from such mistakes.

If you mess up during a rebase:

```
git rebase --abort
```
If you notice you messed up after the rebase:

```
# reset branch back to the saved point
git reset --hard tmp
```
If you forgot to make a backup branch:

```
# look at the reflog of the branch
git reflog show my-feature-branch
8630830 my-feature-branch@{0}: commit: BUG: io: close file handles immediately
278dd2a my-feature-branch@{1}: rebase finished: refs/heads/my-feature-branch onto 11ee694744f2552d
26aa21a my-feature-branch@{2}: commit: BUG: lib: make seek_gzip_factory not leak gzip obj
...
# reset the branch to where it was before the botched rebase
git reset --hard my-feature-branch@{2}
```
If you didn’t actually mess up but there are merge conflicts, you need to
resolve those. This can be one of the trickier things to get right. For a
good description of how to do this, see [this article on merging conflicts](https://git-scm.com/book/en/Git-Branching-Basic-Branching-and-Merging#Basic-Merge-Conflicts).

## Additional things you might want to do[#](#additional-things-you-might-want-to-do)
### Rewriting commit history[#](#rewriting-commit-history)
Note

Do this only for your own feature branches.

There’s an embarrassing typo in a commit you made? Or perhaps you made several false starts you would like the posterity not to see.

This can be done via *interactive rebasing*.

Suppose that the commit history looks like this:

```
git log --oneline
eadc391 Fix some remaining bugs
a815645 Modify it so that it works
2dec1ac Fix a few bugs + disable
13d7934 First implementation
6ad92e5 * masked is now an instance of a new object, MaskedConstant
29001ed Add pre-nep for a couple of structured_array_extensions.
...
```
and `6ad92e5`
is the last commit in the `main`
branch. Suppose we
want to make the following changes:

Rewrite the commit message for

`13d7934`
to something more sensible.
Combine the commits

`2dec1ac`
,`a815645`
,`eadc391`
into a single one.
We do as follows:

```
# make a backup of the current state
git branch tmp HEAD
# interactive rebase
git rebase -i 6ad92e5
```
This will open an editor with the following text in it:

```
pick 13d7934 First implementation
pick 2dec1ac Fix a few bugs + disable
pick a815645 Modify it so that it works
pick eadc391 Fix some remaining bugs
# Rebase 6ad92e5..eadc391 onto 6ad92e5
#
# Commands:
# p, pick = use commit
# r, reword = use commit, but edit the commit message
# e, edit = use commit, but stop for amending
# s, squash = use commit, but meld into previous commit
# f, fixup = like "squash", but discard this commit's log message
#
# If you remove a line here THAT COMMIT WILL BE LOST.
# However, if you remove everything, the rebase will be aborted.
#
```
To achieve what we want, we will make the following changes to it:

```
r 13d7934 First implementation
pick 2dec1ac Fix a few bugs + disable
f a815645 Modify it so that it works
f eadc391 Fix some remaining bugs
```
This means that (i) we want to edit the commit message for
`13d7934`
, and (ii) collapse the last three commits into one. Now we
save and quit the editor.

Git will then immediately bring up an editor for editing the commit message. After revising it, we get the output:

```
[detached HEAD 721fc64] FOO: First implementation
2 files changed, 199 insertions(+), 66 deletions(-)
[detached HEAD 0f22701] Fix a few bugs + disable
1 files changed, 79 insertions(+), 61 deletions(-)
Successfully rebased and updated refs/heads/my-feature-branch.
```
and the history looks now like this:

```
0f22701 Fix a few bugs + disable
721fc64 ENH: Sophisticated feature
6ad92e5 * masked is now an instance of a new object, MaskedConstant
```
If it went wrong, recovery is again possible as explained [above](#recovering-from-mess-up).

### Deleting a branch on [github](https://github.com/numpy/numpy)[#](#deleting-a-branch-on-github)
```
git checkout main
# delete branch locally
git branch -D my-unwanted-branch
# delete branch on github
git push origin --delete my-unwanted-branch
```
See also:
[https://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-branch-locally-and-remotely](https://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-branch-locally-and-remotely)

### Several people sharing a single repository[#](#several-people-sharing-a-single-repository)
If you want to work on some stuff with other people, where you are all
committing into the same repository, or even the same branch, then just
share it via [github](https://github.com/numpy/numpy).

First fork NumPy into your account, as from [Create a NumPy fork](gitwash/development_setup.html#forking).

Then, go to your forked repository github page, say
`https://github.com/your-user-name/numpy`

Click on the ‘Admin’ button, and add anyone else to the repo as a collaborator:

Now all those people can do:

```
git clone git@github.com:your-user-name/numpy.git
```
Remember that links starting with `git@`
use the ssh protocol and are
read-write; links starting with `git://`
are read-only.

Your collaborators can then commit directly into that repo with the usual:

```
git commit -am 'ENH - much better code'
git push origin my-feature-branch # pushes directly into your repo
```
### Checkout changes from an existing pull request[#](#checkout-changes-from-an-existing-pull-request)
If you want to test the changes in a pull request or continue the work in a new pull request, the commits are to be cloned into a local branch in your forked repository

First ensure your upstream points to the main repo, as from [Linking your repository to the upstream repo](https://scikit-image.org/docs/stable/gitwash/set_up_fork.html#linking-to-upstream)

Then, fetch the changes and create a local branch. Assuming `$ID`
is the pull request number
and `$BRANCHNAME`
is the name of the *new local* branch you wish to create:

```
git fetch upstream pull/$ID/head:$BRANCHNAME
```
Checkout the newly created branch:

```
git checkout $BRANCHNAME
```
You now have the changes in the pull request.

### Exploring your repository[#](#exploring-your-repository)
To see a graphical representation of the repository branches and commits:

```
gitk --all
```
To see a linear list of commits for this branch:

```
git log
```
You can also look at the [network graph visualizer](https://github.blog/2008-04-10-say-hello-to-the-network-graph-visualizer/) for your [github](https://github.com/numpy/numpy)
repo.

### Backporting[#](#backporting)
Backporting is the process of copying new feature/fixes committed in
[numpy/main](https://github.com/numpy/numpy) back to stable release branches. To do this you make a branch
off the branch you are backporting to, cherry pick the commits you want from
`numpy/main`
, and then submit a pull request for the branch containing the
backport.

First, you need to make the branch you will work on. This needs to be based on the older version of NumPy (not main):

# Make a new branch based on numpy/maintenance/1.8.x, # backport-3324 is our new name for the branch. git checkout -b backport-3324 upstream/maintenance/1.8.x
Now you need to apply the changes from main to this branch using

[git cherry-pick](https://www.kernel.org/pub/software/scm/git/docs/git-cherry-pick.html):# Update remote git fetch upstream # Check the commit log for commits to cherry pick git log upstream/main # This pull request included commits aa7a047 to c098283 (inclusive) # so you use the .. syntax (for a range of commits), the ^ makes the # range inclusive. git cherry-pick aa7a047^..c098283 ... # Fix any conflicts, then if needed: git cherry-pick --continue
You might run into some conflicts cherry picking here. These are resolved the same way as merge/rebase conflicts. Except here you can use

[git blame](https://www.kernel.org/pub/software/scm/git/docs/git-blame.html)to see the difference between main and the backported branch to make sure nothing gets screwed up.
Push the new branch to your Github repository:

git push -u origin backport-3324
Finally make a pull request using Github. Make sure it is against the maintenance branch and not main, Github will usually suggest you make the pull request against main.

### Pushing changes to the main repo[#](#pushing-changes-to-the-main-repo)
*Requires commit rights to the main NumPy repo.*
When you have a set of “ready” changes in a feature branch ready for
NumPy’s `main`
or `maintenance`
branches, you can push
them to `upstream`
as follows:

First, merge or rebase on the target branch.

Only a few, unrelated commits then prefer rebasing:

git fetch upstream git rebase upstream/main
See

[Rebasing on main](#rebasing-on-main).
If all of the commits are related, create a merge commit:

git fetch upstream git merge --no-ff upstream/main
Check that what you are going to push looks sensible:

git log -p upstream/main.. git log --oneline --graph
Push to upstream:

git push upstream my-feature-branch:main
Note

It’s usually a good idea to use the `-n`
flag to `git push`
to check
first that you’re about to push the changes you want to the place you
want.# Contributing to NumPy[#](#contributing-to-numpy)
Not a coder? Not a problem! NumPy is multi-faceted, and we can use a lot of help. These are all activities we’d like to get help with (they’re all important, so we list them in alphabetical order):

Code maintenance and development

Community coordination

DevOps

Developing educational content & narrative documentation

Fundraising

Marketing

Project management

Translating content

Website design and development

Writing technical documentation

The rest of this document discusses working on the NumPy code base and documentation.
We’re in the process of updating our descriptions of other activities and roles.
If you are interested in these other activities, please contact us!
You can do this via
the [numpy-discussion mailing list](https://mail.python.org/mailman/listinfo/numpy-discussion),
or on [GitHub](https://github.com/numpy/numpy) (open an issue or comment on a
relevant issue). These are our preferred communication channels (open source is open
by nature!), however if you prefer to discuss in private first, please reach out to
our community coordinators at [numpy-team@googlegroups.com](/cdn-cgi/l/email-protection#3a1515544f574a43174e5f5b571c19090d011c190f08011c190e02015d55555d565f5d48554f4a491c190e0c01595557) or [numpy-team.slack.com](https://numpy-team.slack.com) (send an email to [numpy-team@googlegroups.com](/cdn-cgi/l/email-protection#341b1b5a4159444d1940515559121707030f121701060f1217000c0f535b5b53585153465b414447121700020f575b59) for an
invite the first time).

## Development process - summary[#](#development-process-summary)
Here’s the short summary, complete TOC links are below:

If you are a first-time contributor:

Go to

[https://github.com/numpy/numpy](https://github.com/numpy/numpy)and click the “fork” button to create your own copy of the project.
Clone the project to your local computer:

git clone --recurse-submodules https://github.com/your-username/numpy.git
Change the directory:

cd numpy
Add the upstream repository:

git remote add upstream https://github.com/numpy/numpy.git
Now,

`git remote -v`
will show two remote repositories named:`upstream`
, which refers to the`numpy`
repository
`origin`
, which refers to your personal fork
Pull the latest changes from upstream, including tags:

git checkout main git pull upstream main --tags
Initialize numpy’s submodules:

git submodule update --init
Develop your contribution:

Create a branch for the feature you want to work on. Since the branch name will appear in the merge message, use a sensible name such as ‘linspace-speedups’:

git checkout -b linspace-speedups
Commit locally as you progress (

`git add`
and`git commit`
) Use a[properly formatted](development_workflow.html#writing-the-commit-message)commit message, write tests that fail before your change and pass afterward, run all the[tests locally](development_environment.html#development-environment). Be sure to document any changed behavior in docstrings, keeping to the NumPy docstring[standard](howto-docs.html#howto-document).
To submit your contribution:

Push your changes back to your fork on GitHub:

git push origin linspace-speedups
Enter your GitHub username and password (repeat contributors or advanced users can remove this step by connecting to GitHub with

[SSH](gitwash/development_setup.html#set-up-and-configure-a-github-account)).
Go to GitHub. The new branch will show up with a green Pull Request button. Make sure the title and message are clear, concise, and self- explanatory. Then click the button to submit it.

If your commit introduces a new feature or changes functionality, post on the

[mailing list](https://mail.python.org/mailman/listinfo/numpy-discussion)to explain your changes. For bug fixes, documentation updates, etc., this is generally not necessary, though if you do not get any reaction, do feel free to ask for review.
Review process:

Reviewers (the other developers and interested community members) will write inline and/or general comments on your Pull Request (PR) to help you improve its implementation, documentation and style. Every single developer working on the project has their code reviewed, and we’ve come to see it as friendly conversation from which we all learn and the overall code quality benefits. Therefore, please don’t let the review discourage you from contributing: its only aim is to improve the quality of project, not to criticize (we are, after all, very grateful for the time you’re donating!). See our

[Reviewer Guidelines](reviewer_guidelines.html#reviewer-guidelines)for more information.
To update your PR, make your changes on your local repository, commit,

**run tests, and only if they succeed**push to your fork. As soon as those changes are pushed up (to the same branch as before) the PR will update automatically. If you have no idea how to fix the test failures, you may push your changes anyway and ask for help in a PR comment.
Various continuous integration (CI) services are triggered after each PR update to build the code, run unit tests, measure code coverage and check coding style of your branch. The CI tests must pass before your PR can be merged. If CI fails, you can find out why by clicking on the “failed” icon (red cross) and inspecting the build and test log. To avoid overuse and waste of this resource,

[test your work](development_environment.html#recommended-development-setup)locally before committing.
A PR must be

**approved**by at least one core team member before merging. Approval means the core team member has carefully reviewed the changes, and the PR is ready for merging.
Document changes

Beyond changes to a functions docstring and possible description in the general documentation, if your change introduces any user-facing modifications they may need to be mentioned in the release notes. To add your change to the release notes, you need to create a short file with a summary and place it in

`doc/release/upcoming_changes`
. The file`doc/release/upcoming_changes/README.rst`
details the format and filename conventions.If your change introduces a deprecation, make sure to discuss this first on GitHub or the mailing list first. If agreement on the deprecation is reached, follow

[NEP 23 deprecation policy](https://numpy.org/neps/nep-0023-backwards-compatibility.html#nep23)to add the deprecation.
Cross referencing issues

If the PR relates to any issues, you can add the text

`xref gh-xxxx`
where`xxxx`
is the number of the issue to github comments. Likewise, if the PR solves an issue, replace the`xref`
with`closes`
,`fixes`
or any of the other flavors[github accepts](https://help.github.com/en/articles/closing-issues-using-keywords).In the source code, be sure to preface any issue or PR reference with

`gh-xxxx`
.
For a more detailed discussion, read on and follow the links at the bottom of this page.

### Divergence between `upstream/main`
and your feature branch[#](#divergence-between-upstream-main-and-your-feature-branch)
If GitHub indicates that the branch of your Pull Request can no longer
be merged automatically, you have to incorporate changes that have been made
since you started into your branch. Our recommended way to do this is to
[rebase on main](development_workflow.html#rebasing-on-main).

### Guidelines[#](#guidelines)
All code should have tests (see

[test coverage](#test-coverage)below for more details).
All code should be

[documented](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard).
No changes are ever committed without review and approval by a core team member. Please ask politely on the PR or on the

[mailing list](https://mail.python.org/mailman/listinfo/numpy-discussion)if you get no response to your pull request within a week.
### Stylistic Guidelines[#](#stylistic-guidelines)
### Test coverage[#](#test-coverage)
Pull requests (PRs) that modify code should either have new tests, or modify existing
tests to fail before the PR and pass afterwards. You should [run the tests](development_environment.html#development-environment) before pushing a PR.

Running NumPy’s test suite locally requires some additional packages, such as
`pytest`
and `hypothesis`
. The additional testing dependencies are listed
in `test_requirements.txt`
in the top-level directory, and can conveniently
be installed with:

```
$ python -m pip install -r test_requirements.txt
```
Tests for a module should ideally cover all code in that module, i.e., statement coverage should be at 100%.

To measure the test coverage, run:

```
$ spin test --coverage
```
This will create a report in `html`
format at `build/coverage`
, which can be
viewed with your browser, e.g.:

```
$ firefox build/coverage/index.html
```
### Building docs[#](#building-docs)
To build the HTML documentation, use:

```
spin docs
```
You can also run `make`
from the `doc`
directory. `make help`
lists
all targets.

To get the appropriate dependencies and other requirements,
see [Building the NumPy API and reference docs](howto_build_docs.html#howto-build-docs).

#### Fixing Warnings[#](#fixing-warnings)
“citation not found: R###” There is probably an underscore after a reference in the first line of a docstring (e.g. [1]_). Use this method to find the source file: $ cd doc/build; grep -rin R####

“Duplicate citation R###, other instance in…”” There is probably a [2] without a [1] in one of the docstrings

## Development process - details[#](#development-process-details)
The rest of the story

[Git Basics](gitwash/index.html)
[Setting up and using your development environment](development_environment.html)
[Building the NumPy API and reference docs](howto_build_docs.html)
[Development workflow](development_workflow.html)
[Advanced debugging tools](development_advanced_debugging.html)
[Reviewer guidelines](reviewer_guidelines.html)
[NumPy benchmarks](../benchmarking.html)
[NumPy C style guide](https://numpy.org/neps/nep-0045-c_style_guide.html)
[For downstream package authors](depending_on_numpy.html)
[Releasing a version](releasing.html)
[NumPy governance](governance/index.html)
[How to contribute to the NumPy documentation](howto-docs.html)
NumPy-specific workflow is in [numpy-development-workflow](development_workflow.html#development-workflow).# F2PY and Windows[#](#f2py-and-windows)
Warning

F2PY support for Windows is not at par with Linux support, and
OS specific flags can be seen via `python -m numpy.f2py`

Broadly speaking, there are two issues working with F2PY on Windows:

the lack of actively developed FOSS Fortran compilers, and,

the linking issues related to the C runtime library for building Python-C extensions.

The focus of this section is to establish a guideline for developing and extending Fortran modules for Python natively, via F2PY on Windows.

## Overview[#](#overview)
From a user perspective, the most UNIX compatible Windows development environment is through emulation, either via the Windows Subsystem on Linux, or facilitated by Docker. In a similar vein, traditional virtualization methods like VirtualBox are also reasonable methods to develop UNIX tools on Windows.

Native Windows support is typically stunted beyond the usage of commercial compilers.
However, as of 2022, most commercial compilers have free plans which are sufficient for
general use. Additionally, the Fortran language features supported by `f2py`
(partial coverage of Fortran 2003), means that newer toolchains are often not
required. Briefly, then, for an end user, in order of use:

Classic Intel Compilers (commercial)
-
These are maintained actively, though licensing restrictions may apply as further detailed in

[F2PY and Windows Intel Fortran](intel.html#f2py-win-intel).Suitable for general use for those building native Windows programs by building off of MSVC.

MSYS2 (FOSS)
-
In conjunction with the

`mingw-w64`
project,`gfortran`
and`gcc`
toolchains can be used to natively build Windows programs.
Windows Subsystem for Linux
-
Assuming the usage of

`gfortran`
, this can be used for cross-compiling Windows applications, but is significantly more complicated.
Conda
-
Windows support for compilers in

`conda`
is facilitated by pulling MSYS2 binaries, however these[are outdated](https://github.com/conda-forge/conda-forge.github.io/issues/1044), and therefore not recommended (as of 30-01-2022).
PGI Compilers (commercial)
-
Unmaintained but sufficient if an existing license is present. Works natively, but has been superseded by the Nvidia HPC SDK, with no

[native Windows support](https://developer.nvidia.com/nvidia-hpc-sdk-downloads#collapseFour).
Cygwin (FOSS)
-
Can also be used for

`gfortran`
. However, the POSIX API compatibility layer provided by Cygwin is meant to compile UNIX software on Windows, instead of building native Windows programs. This means cross compilation is required.
The compilation suites described so far are compatible with the [now
deprecated](https://github.com/numpy/numpy/pull/20875) `np.distutils`
build backend which is exposed by the F2PY CLI.
Additional build system usage (`meson`
, `cmake`
) as described in
[F2PY and Build Systems](../buildtools/index.html#f2py-bldsys) allows for a more flexible set of compiler
backends including:

Intel oneAPI
-
The newer Intel compilers (

`ifx`
,`icx`
) are based on LLVM and can be used for native compilation. Licensing requirements can be onerous.
Classic Flang (FOSS)
-
The backbone of the PGI compilers were cannibalized to form the “classic” or

[legacy version of Flang](https://github.com/flang-compiler/flang). This may be compiled from source and used natively.[LLVM Flang](https://releases.llvm.org/11.0.0/tools/flang/docs/ReleaseNotes.html)does not support Windows yet (30-01-2022).
LFortran (FOSS)
-
One of two LLVM based compilers. Not all of F2PY supported Fortran can be compiled yet (30-01-2022) but uses MSVC for native linking.

## Baseline[#](#baseline)
For this document we will assume the following basic tools:

The IDE being considered is the community supported

[Microsoft Visual Studio Code](https://code.visualstudio.com/Download)
The terminal being used is the

[Windows Terminal](https://www.microsoft.com/en-us/p/windows-terminal/9n0dx20hk701?activetab=pivot:overviewtab)
The shell environment is assumed to be

[Powershell 7.x](https://docs.microsoft.com/en-us/powershell/scripting/install/installing-powershell-on-windows?view=powershell-7.1)
Python 3.10 from [the Microsoft Store](https://www.microsoft.com/en-us/p/python-310/9pjpw5ldxlz5)and this can be tested with
-
`Get-Command python.exe`
resolving to`C:\Users\$USERNAME\AppData\Local\Microsoft\WindowsApps\python.exe`
Python 3.10 from
-
The Microsoft Visual C++ (MSVC) toolset

With this baseline configuration, we will further consider a configuration matrix as follows:

|
|
|
---|---|---|
Intel Fortran

|
MSVC / ICC

|
exe

|
GFortran

|
MSVC

|
MSYS2/exe

|
GFortran

|
GCC

|
WSL

|
Classic Flang

|
MSVC

|
Source / Conda

|
Anaconda GFortran

|
Anaconda GCC

|
exe

|
For an understanding of the key issues motivating the need for such a matrix
[Pauli Virtanen’s in-depth post on wheels with Fortran for Windows](https://pav.iki.fi/blog/2017-10-08/pywingfortran.html#building-python-wheels-with-fortran-for-windows) is an
excellent resource. An entertaining explanation of an application binary
interface (ABI) can be found in this post by [JeanHeyd Meneide](https://thephd.dev/binary-banshees-digital-demons-abi-c-c++-help-me-god-please).

## Powershell and MSVC[#](#powershell-and-msvc)
MSVC is installed either via the Visual Studio Bundle or the lighter (preferred)
[Build Tools for Visual Studio](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2019) with the `Desktop development with C++`
setting.

Note

This can take a significant amount of time as it includes a download of around 2GB and requires a restart.

It is possible to use the resulting environment from a [standard command
prompt](https://docs.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-160#developer_command_file_locations). However, it is more pleasant to use a [developer powershell](https://docs.microsoft.com/en-us/visualstudio/ide/reference/command-prompt-powershell?view=vs-2019),
with a [profile in Windows Terminal](https://techcommunity.microsoft.com/t5/microsoft-365-pnp-blog/add-developer-powershell-and-developer-command-prompt-for-visual/ba-p/2243078). This can be achieved by adding the
following block to the `profiles->list`
section of the JSON file used to
configure Windows Terminal (see `Settings->Open JSON file`
):

```
{
"name": "Developer PowerShell for VS 2019",
"commandline": "powershell.exe -noe -c \"$vsPath = (Join-Path ${env:ProgramFiles(x86)} -ChildPath 'Microsoft Visual Studio\\2019\\BuildTools'); Import-Module (Join-Path $vsPath 'Common7\\Tools\\Microsoft.VisualStudio.DevShell.dll'); Enter-VsDevShell -VsInstallPath $vsPath -SkipAutomaticLocation\"",
"icon": "ms-appx:///ProfileIcons/{61c54bbd-c2c6-5271-96e7-009a87ff44bf}.png"
}
```
Now, testing the compiler toolchain could look like:

```
# New Windows Developer Powershell instance / tab
# or
$vsPath = (Join-Path ${env:ProgramFiles(x86)} -ChildPath 'Microsoft Visual Studio\\2019\\BuildTools');
Import-Module (Join-Path $vsPath 'Common7\\Tools\\Microsoft.VisualStudio.DevShell.dll');
Enter-VsDevShell -VsInstallPath $vsPath -SkipAutomaticLocation
**********************************************************************
** Visual Studio 2019 Developer PowerShell v16.11.9
** Copyright (c) 2021 Microsoft Corporation
**********************************************************************
cd $HOME
echo "#include<stdio.h>" > blah.cpp; echo 'int main(){printf("Hi");return 1;}' >> blah.cpp
cl blah.cpp
.\blah.exe
# Hi
rm blah.cpp
```
It is also possible to check that the environment has been updated correctly
with `$ENV:PATH`
.

## Windows Store Python Paths[#](#windows-store-python-paths)
The MS Windows version of Python discussed here installs to a non-deterministic
path using a hash. This needs to be added to the `PATH`
variable.

```
$Env:Path += ";$env:LOCALAPPDATA\packages\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\localcache\local-packages\python310\scripts"
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# NumPy benchmarks[#](#numpy-benchmarks)
Benchmarking NumPy with Airspeed Velocity.

## Usage[#](#usage)
Airspeed Velocity manages building and Python virtualenvs by itself, unless told otherwise. To run the benchmarks, you do not need to install a development version of NumPy to your current Python environment.

Before beginning, ensure that *airspeed velocity* is installed.
By default, *asv* ships with support for anaconda and virtualenv:

```
pip install asv
pip install virtualenv
```
After contributing new benchmarks, you should test them locally before submitting a pull request.

To run all benchmarks, navigate to the root NumPy directory at the command line and execute:

```
spin bench
```
This builds NumPy and runs all available benchmarks
defined in `benchmarks/`
. (Note: this could take a while. Each
benchmark is run multiple times to measure the distribution in
execution times.)

For **testing** benchmarks locally, it may be better to run these without
replications:

```
cd benchmarks/
export REGEXP="bench.*Ufunc"
asv run --dry-run --show-stderr --python=same --quick -b $REGEXP
```
Where the regular expression used to match benchmarks is stored in `$REGEXP`
,
and *–quick* is used to avoid repetitions.

To run benchmarks from a particular benchmark module, such as
`bench_core.py`
, simply append the filename without the extension:

```
spin bench -t bench_core
```
To run a benchmark defined in a class, such as `MeshGrid`
from `bench_creation.py`
:

```
spin bench -t bench_creation.MeshGrid
```
Compare changes in benchmark results to another version/commit/branch, use the
`--compare`
option (or the equivalent `-c`
):

```
spin bench --compare v1.6.2 -t bench_core
spin bench --compare 20d03bcfd -t bench_core
spin bench -c main -t bench_core
```
All of the commands above display the results in plain text in the console, and the results are not saved for comparison with future commits. For greater control, a graphical view, and to have results saved for future comparison you can run ASV commands (record results and generate HTML):

```
cd benchmarks
asv run -n -e --python=same
asv publish
asv preview
```
More on how to use `asv`
can be found in [ASV documentation](https://asv.readthedocs.io/)
Command-line help is available as usual via `asv --help`
and
`asv run --help`
.

## Benchmarking versions[#](#benchmarking-versions)
To benchmark or visualize only releases on different machines locally, the tags with their commits can be generated, before being run with `asv`
, that is:

```
cd benchmarks
# Get commits for tags
# delete tag_commits.txt before re-runs
for gtag in $(git tag --list --sort taggerdate | grep "^v"); do
git log $gtag --oneline -n1 --decorate=no | awk '{print $1;}' >> tag_commits.txt
done
# Use the last 20
tail --lines=20 tag_commits.txt > 20_vers.txt
asv run HASHFILE:20_vers.txt
# Publish and view
asv publish
asv preview
```
For details on contributing these, see the [benchmark results repository](https://github.com/HaoZeke/asv-numpy).

## Writing benchmarks[#](#writing-benchmarks)
See [ASV documentation](https://asv.readthedocs.io/) for basics on how to write benchmarks.

Some things to consider:

The benchmark suite should be importable with any NumPy version.

The benchmark parameters etc. should not depend on which NumPy version is installed.

Try to keep the runtime of the benchmark reasonable.

Prefer ASV’s

`time_`
methods for benchmarking times rather than cooking up time measurements via`time.clock`
, even if it requires some juggling when writing the benchmark.
Preparing arrays etc. should generally be put in the

`setup`
method rather than the`time_`
methods, to avoid counting preparation time together with the time of the benchmarked operation.
Be mindful that large arrays created with

`np.empty`
or`np.zeros`
might not be allocated in physical memory until the memory is accessed. If this is desired behaviour, make sure to comment it in your setup function. If you are benchmarking an algorithm, it is unlikely that a user will be executing said algorithm on a newly created empty/zero array. One can force pagefaults to occur in the setup phase either by calling`np.ones`
or`arr.fill(value)`
after creating the array,Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# What is NumPy?[#](#what-is-numpy)
NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.

At the core of the NumPy package, is the *ndarray* object. This
encapsulates *n*-dimensional arrays of homogeneous data types, with
many operations being performed in compiled code for performance.
There are several important differences between NumPy arrays and the
standard Python sequences:

NumPy arrays have a fixed size at creation, unlike Python lists (which can grow dynamically). Changing the size of an

*ndarray*will create a new array and delete the original.
The elements in a NumPy array are all required to be of the same data type, and thus will be the same size in memory. The exception: one can have arrays of (Python, including NumPy) objects, thereby allowing for arrays of different sized elements.

NumPy arrays facilitate advanced mathematical and other types of operations on large numbers of data. Typically, such operations are executed more efficiently and with less code than is possible using Python’s built-in sequences.

A growing plethora of scientific and mathematical Python-based packages are using NumPy arrays; though these typically support Python-sequence input, they convert such input to NumPy arrays prior to processing, and they often output NumPy arrays. In other words, in order to efficiently use much (perhaps even most) of today’s scientific/mathematical Python-based software, just knowing how to use Python’s built-in sequence types is insufficient - one also needs to know how to use NumPy arrays.

The points about sequence size and speed are particularly important in
scientific computing. As a simple example, consider the case of
multiplying each element in a 1-D sequence with the corresponding
element in another sequence of the same length. If the data are
stored in two Python lists, `a`
and `b`
, we could iterate over
each element:

```
c = []
for i in range(len(a)):
c.append(a[i]*b[i])
```
This produces the correct answer, but if `a`
and `b`
each contain
millions of numbers, we will pay the price for the inefficiencies of
looping in Python. We could accomplish the same task much more
quickly in C by writing (for clarity we neglect variable declarations
and initializations, memory allocation, etc.)

```
for (i = 0; i < rows; i++) {
c[i] = a[i]*b[i];
}
```
This saves all the overhead involved in interpreting the Python code and manipulating Python objects, but at the expense of the benefits gained from coding in Python. Furthermore, the coding work required increases with the dimensionality of our data. In the case of a 2-D array, for example, the C code (abridged as before) expands to

```
for (i = 0; i < rows; i++) {
for (j = 0; j < columns; j++) {
c[i][j] = a[i][j]*b[i][j];
}
}
```
NumPy gives us the best of both worlds: element-by-element operations
are the “default mode” when an *ndarray* is involved, but the
element-by-element operation is speedily executed by pre-compiled C
code. In NumPy

```
c = a * b
```
does what the earlier examples do, at near-C speeds, but with the code simplicity we expect from something based on Python. Indeed, the NumPy idiom is even simpler! This last example illustrates two of NumPy’s features which are the basis of much of its power: vectorization and broadcasting.

## Why is NumPy Fast?[#](#why-is-numpy-fast)
Vectorization describes the absence of any explicit looping, indexing, etc., in the code - these things are taking place, of course, just “behind the scenes” in optimized, pre-compiled C code. Vectorized code has many advantages, among which are:

vectorized code is more concise and easier to read

fewer lines of code generally means fewer bugs

the code more closely resembles standard mathematical notation (making it easier, typically, to correctly code mathematical constructs)

vectorization results in more “Pythonic” code. Without vectorization, our code would be littered with inefficient and difficult to read

`for`
loops.
Broadcasting is the term used to describe the implicit
element-by-element behavior of operations; generally speaking, in
NumPy all operations, not just arithmetic operations, but
logical, bit-wise, functional, etc., behave in this implicit
element-by-element fashion, i.e., they broadcast. Moreover, in the
example above, `a`
and `b`
could be multidimensional arrays of the
same shape, or a scalar and an array, or even two arrays of with
different shapes, provided that the smaller array is “expandable” to
the shape of the larger in such a way that the resulting broadcast is
unambiguous. For detailed “rules” of broadcasting see
[Broadcasting](basics.broadcasting.html#basics-broadcasting).

## Who Else Uses NumPy?[#](#who-else-uses-numpy)
NumPy fully supports an object-oriented approach, starting, once
again, with *ndarray*. For example, *ndarray* is a class, possessing
numerous methods and attributes. Many of its methods are mirrored by
functions in the outer-most NumPy namespace, allowing the programmer
to code in whichever paradigm they prefer. This flexibility has allowed the
NumPy array dialect and NumPy *ndarray* class to become the *de-facto* language
of multi-dimensional data interchange used in Python.# For downstream package authors[#](#for-downstream-package-authors)
This document aims to explain some best practices for authoring a package that depends on NumPy.

## Understanding NumPy’s versioning and API/ABI stability[#](#understanding-numpy-s-versioning-and-api-abi-stability)
NumPy uses a standard, [ PEP 440](https://peps.python.org/pep-0440/) compliant, versioning scheme:

`major.minor.bugfix`
. A *major*release is highly unusual (NumPy is still at version
`1.xx`
) and if it happens it will likely indicate an ABI break.
*Minor*versions are released regularly, typically every 6 months. Minor versions contain new features, deprecations, and removals of previously deprecated code.
*Bugfix*releases are made even more frequently; they do not contain any new features or deprecations.
It is important to know that NumPy, like Python itself and most other
well known scientific Python projects, does **not** use semantic versioning.
Instead, backwards incompatible API changes require deprecation warnings for at
least two releases. For more details, see [NEP 23 — Backwards compatibility and deprecation policy](https://numpy.org/neps/nep-0023-backwards-compatibility.html#nep23).

NumPy has both a Python API and a C API. The C API can be used directly or via Cython, f2py, or other such tools. If your package uses the C API, then ABI (application binary interface) stability of NumPy is important. NumPy’s ABI is forward but not backward compatible. This means: binaries compiled against a given version of NumPy will still run correctly with newer NumPy versions, but not with older versions.

## Testing against the NumPy main branch or pre-releases[#](#testing-against-the-numpy-main-branch-or-pre-releases)
For large, actively maintained packages that depend on NumPy, we recommend
testing against the development version of NumPy in CI. To make this easy,
nightly builds are provided as wheels at
[https://anaconda.org/scientific-python-nightly-wheels/](https://anaconda.org/scientific-python-nightly-wheels/). Example install command:

```
pip install -U --pre --only-binary :all: -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple numpy
```
This helps detect regressions in NumPy that need fixing before the next NumPy
release. Furthermore, we recommend to raise errors on warnings in CI for this
job, either all warnings or otherwise at least `DeprecationWarning`
and
`FutureWarning`
. This gives you an early warning about changes in NumPy to
adapt your code.

## Adding a dependency on NumPy[#](#adding-a-dependency-on-numpy)
### Build-time dependency[#](#build-time-dependency)
Note

Before NumPy 1.25, the NumPy C-API was *not* backwards compatible. This
means that when compiling with a NumPy version earlier than 1.25 you
have to compile with the oldest version you wish to support.
This can be done by using
[oldest-supported-numpy](https://github.com/scipy/oldest-supported-numpy/).
Please see the [NumPy 1.24 documentation](https://numpy.org/doc/1.24/dev/depending_on_numpy.html).

If a package either uses the NumPy C API directly or it uses some other tool
that depends on it like Cython or Pythran, NumPy is a *build-time* dependency
of the package.

By default, NumPy will expose an API that is backwards compatible with the oldest NumPy version that supports the currently oldest compatible Python version. NumPy 1.25.0 supports Python 3.9 and higher and NumPy 1.19 is the first version to support Python 3.9. Thus, we guarantee that, when using defaults, NumPy 1.25 will expose a C-API compatible with NumPy 1.19. (the exact version is set within NumPy-internal header files).

NumPy is also forward compatible for all minor releases, but a major release will require recompilation.

The default behavior can be customized for example by adding:

```
#define NPY_TARGET_VERSION NPY_1_22_API_VERSION
```
before including any NumPy headers (or the equivalent `-D`
compiler flag) in
every extension module that requires the NumPy C-API.
This is mainly useful if you need to use newly added API at the cost of not
being compatible with older versions.

If for some reason you wish to compile for the currently installed NumPy version by default you can add:

```
#ifndef NPY_TARGET_VERSION
#define NPY_TARGET_VERSION NPY_API_VERSION
#endif
```
Which allows a user to override the default via `-DNPY_TARGET_VERSION`
.
This define must be consistent for each extension module (use of
`import_array()`
) and also applies to the umath module.

When you compile against NumPy, you should add the proper version restrictions
to your `pyproject.toml`
(see PEP 517). Since your extension will not be
compatible with a new major release of NumPy and may not be compatible with
very old versions.

For conda-forge packages, please see
[here](https://conda-forge.org/docs/maintainer/knowledge_base.html#building-against-numpy).

as of now, it is usually as easy as including:

```
host:
- numpy
run:
- {{ pin_compatible('numpy') }}
```
Note

At the time of NumPy 1.25, NumPy 2.0 is expected to be the next release of NumPy. The NumPy 2.0 release is expected to require a different pin, since NumPy 2+ will be needed in order to be compatible with both NumPy 1.x and 2.x.

### Runtime dependency & version ranges[#](#runtime-dependency-version-ranges)
NumPy itself and many core scientific Python packages have agreed on a schedule
for dropping support for old Python and NumPy versions: [NEP 29 — Recommend Python and NumPy version support as a community policy standard](https://numpy.org/neps/nep-0029-deprecation_policy.html#nep29). We
recommend all packages depending on NumPy to follow the recommendations in NEP
29.

For *run-time dependencies*, specify version bounds using
`install_requires`
in `setup.py`
(assuming you use `numpy.distutils`
or
`setuptools`
to build).

Most libraries that rely on NumPy will not need to set an upper version bound: NumPy is careful to preserve backward-compatibility.

That said, if you are (a) a project that is guaranteed to release
frequently, (b) use a large part of NumPy’s API surface, and (c) is
worried that changes in NumPy may break your code, you can set an
upper bound of `<MAJOR.MINOR + N`
with N no less than 3, and
`MAJOR.MINOR`
being the current release of NumPy [[*]](#id3). If you use the NumPy
C API (directly or via Cython), you can also pin the current major
version to prevent ABI breakage. Note that setting an upper bound on
NumPy may [affect the ability of your library to be installed
alongside other, newer packages](https://iscinumpy.dev/post/bound-version-constraints/).

Note

SciPy has more documentation on how it builds wheels and deals with its
build-time and runtime dependencies
[here](https://scipy.github.io/devdocs/dev/core-dev/index.html#distributing).

NumPy and SciPy wheel build CI may also be useful as a reference, it can be
found [here for NumPy](https://github.com/MacPython/numpy-wheels) and
[here for SciPy](https://github.com/MacPython/scipy-wheels).# The N-dimensional array (`ndarray`
)[#](#the-n-dimensional-array-ndarray)
`ndarray`
An [ ndarray](generated/numpy.ndarray.html#numpy.ndarray) is a (usually fixed-size) multidimensional
container of items of the same type and size. The number of dimensions
and items in an array is defined by its

[, which is a](generated/numpy.ndarray.shape.html#numpy.ndarray.shape)
`shape`
[of](https://docs.python.org/3/library/stdtypes.html#tuple)
`tuple`
*N*non-negative integers that specify the sizes of each dimension. The type of items in the array is specified by a separate
[data-type object (dtype)](arrays.dtypes.html#arrays-dtypes), one of which is associated with each ndarray.
As with other container objects in Python, the contents of an
[ ndarray](generated/numpy.ndarray.html#numpy.ndarray) can be accessed and modified by

[indexing or slicing](arrays.indexing.html#arrays-indexing)the array (using, for example,
*N*integers), and via the methods and attributes of the
[.](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
Different [ ndarrays](generated/numpy.ndarray.html#numpy.ndarray) can share the same data, so that
changes made in one

[may be visible in another. That is, an ndarray can be a](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
*“view”*to another ndarray, and the data it is referring to is taken care of by the
*“base”*ndarray. ndarrays can also be views to memory owned by Python
[or objects implementing the](https://docs.python.org/3/library/stdtypes.html#str)
`strings`
`buffer`
or [array](arrays.interface.html#arrays-interface)interfaces.
Example

A 2-dimensional array of size 2 x 3, composed of 4-byte integer elements:

```
>>> x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)
>>> type(x)
<class 'numpy.ndarray'>
>>> x.shape
(2, 3)
>>> x.dtype
dtype('int32')
```
The array can be indexed using Python container-like syntax:

```
>>> # The element of x in the *second* row, *third* column, namely, 6.
>>> x[1, 2]
6
```
For example [slicing](arrays.indexing.html#arrays-indexing) can produce views of
the array:

```
>>> y = x[:,1]
>>> y
array([2, 5], dtype=int32)
>>> y[0] = 9 # this also changes the corresponding element in x
>>> y
array([9, 5], dtype=int32)
>>> x
array([[1, 9, 3],
[4, 5, 6]], dtype=int32)
```
## Constructing arrays[#](#constructing-arrays)
New arrays can be constructed using the routines detailed in
[Array creation routines](routines.array-creation.html#routines-array-creation), and also by using the low-level
[ ndarray](generated/numpy.ndarray.html#numpy.ndarray) constructor:

|
An array object represents a multidimensional, homogeneous array of fixed-size items.

|
## Indexing arrays[#](#indexing-arrays)
Arrays can be indexed using an extended Python slicing syntax,
`array[selection]`
. Similar syntax is also used for accessing
fields in a [structured data type](../glossary.html#term-structured-data-type).

See also

## Internal memory layout of an ndarray[#](#internal-memory-layout-of-an-ndarray)
An instance of class [ ndarray](generated/numpy.ndarray.html#numpy.ndarray) consists of a contiguous
one-dimensional segment of computer memory (owned by the array, or by
some other object), combined with an indexing scheme that maps

*N*integers into the location of an item in the block. The ranges in which the indices can vary is specified by the
[of the array. How many bytes each item takes and how the bytes are interpreted is defined by the](generated/numpy.ndarray.shape.html#numpy.ndarray.shape)
`shape`
[data-type object](arrays.dtypes.html#arrays-dtypes)associated with the array.
A segment of memory is inherently 1-dimensional, and there are many
different schemes for arranging the items of an *N*-dimensional array
in a 1-dimensional block. NumPy is flexible, and [ ndarray](generated/numpy.ndarray.html#numpy.ndarray)
objects can accommodate any

*strided indexing scheme*. In a strided scheme, the N-dimensional index \((n_0, n_1, ..., n_{N-1})\) corresponds to the offset (in bytes):
from the beginning of the memory block associated with the
array. Here, \(s_k\) are integers which specify the [ strides](generated/numpy.ndarray.strides.html#numpy.ndarray.strides) of the array. The

[column-major](../glossary.html#term-column-major)order (used, for example, in the Fortran language and in
*Matlab*) and
[row-major](../glossary.html#term-row-major)order (used in C) schemes are just specific kinds of strided scheme, and correspond to memory that can be
*addressed*by the strides:
where \(d_j\) *= self.shape[j]*.

Both the C and Fortran orders are [contiguous](../glossary.html#term-contiguous), *i.e.,*
single-segment, memory layouts, in which every part of the
memory block can be accessed by some combination of the indices.

Note

*Contiguous arrays* and *single-segment arrays* are synonymous
and are used interchangeably throughout the documentation.
While a C-style and Fortran-style contiguous array, which has the corresponding flags set, can be addressed with the above strides, the actual strides may be different. This can happen in two cases:

-
If

`self.shape[k] == 1`
then for any legal index`index[k] == 0`
. This means that in the formula for the offset \(n_k = 0\) and thus \(s_k n_k = 0\) and the value of \(s_k\)= self.strides[k]is arbitrary.
-
If an array has no elements (

`self.size == 0`
) there is no legal index and the strides are never used. Any array with no elements may be considered C-style and Fortran-style contiguous.
Point 1. means that `self`
and `self.squeeze()`
always have the same
contiguity and `aligned`
flags value. This also means
that even a high dimensional array could be C-style and Fortran-style
contiguous at the same time.

An array is considered aligned if the memory offsets for all elements and the
base offset itself is a multiple of *self.itemsize*. Understanding
*memory-alignment* leads to better performance on most hardware.

Warning

It does *not* generally hold that `self.strides[-1] == self.itemsize`
for C-style contiguous arrays or `self.strides[0] == self.itemsize`
for
Fortran-style contiguous arrays is true.

`NPY_RELAXED_STRIDES_DEBUG=1`
can be used to help find errors when
incorrectly relying on the strides in C-extension code (see below warning).
Data in new [ ndarrays](generated/numpy.ndarray.html#numpy.ndarray) is in the

[row-major](../glossary.html#term-row-major)(C) order, unless otherwise specified, but, for example,
[basic array slicing](arrays.indexing.html#arrays-indexing)often produces
[views](../glossary.html#term-view)in a different scheme.
Note

Several algorithms in NumPy work on arbitrarily strided arrays. However, some algorithms require single-segment arrays. When an irregularly strided array is passed in to such algorithms, a copy is automatically made.

## Array attributes[#](#array-attributes)
Array attributes reflect information that is intrinsic to the array itself. Generally, accessing an array through its attributes allows you to get and sometimes set intrinsic properties of the array without creating a new array. The exposed attributes are the core parts of an array and only some of them can be reset meaningfully without creating a new array. Information on each attribute is given below.

### Memory layout[#](#id1)
The following attributes contain information about the memory layout of the array:

Information about the memory layout of the array.

|
Tuple of array dimensions.

|
Tuple of bytes to step in each dimension when traversing an array.

|
Number of array dimensions.

|
Python buffer object pointing to the start of the array's data.

|
Number of elements in the array.

|
Length of one array element in bytes.

|
Total bytes consumed by the elements of the array.

|
Base object if memory is from some other object.

|
### Data type[#](#data-type)
See also

The data type object associated with the array can be found in the
[ dtype](generated/numpy.ndarray.dtype.html#numpy.ndarray.dtype) attribute:

Data-type of the array's elements.

|
### Other attributes[#](#other-attributes)
View of the transposed array.

|
The real part of the array.

|
The imaginary part of the array.

|
A 1-D iterator over the array.

|
### Array interface[#](#array-interface)
See also

Python-side of the array interface

|
C-side of the array interface

|
`ctypes`
foreign function interface[#](#ctypes-foreign-function-interface)
`ctypes`
An object to simplify the interaction of the array with the ctypes module.

|
## Array methods[#](#array-methods)
An [ ndarray](generated/numpy.ndarray.html#numpy.ndarray) object has many methods which operate on or with
the array in some fashion, typically returning an array result. These
methods are briefly explained below. (Each method’s docstring has a
more complete description.)

For the following methods there are also corresponding functions in
[ numpy](index.html#module-numpy):

[,](generated/numpy.all.html#numpy.all)
`all`
[,](generated/numpy.any.html#numpy.any)
`any`
[,](generated/numpy.argmax.html#numpy.argmax)
`argmax`
[,](generated/numpy.argmin.html#numpy.argmin)
`argmin`
[,](generated/numpy.argpartition.html#numpy.argpartition)
`argpartition`
[,](generated/numpy.argsort.html#numpy.argsort)
`argsort`
[,](generated/numpy.choose.html#numpy.choose)
`choose`
[,](generated/numpy.clip.html#numpy.clip)
`clip`
[,](generated/numpy.compress.html#numpy.compress)
`compress`
[,](generated/numpy.copy.html#numpy.copy)
`copy`
[,](generated/numpy.cumprod.html#numpy.cumprod)
`cumprod`
[,](generated/numpy.cumsum.html#numpy.cumsum)
`cumsum`
[,](generated/numpy.diagonal.html#numpy.diagonal)
`diagonal`
[,](generated/numpy.imag.html#numpy.imag)
`imag`
[,](generated/numpy.amax.html#numpy.amax)
`max`
[,](generated/numpy.mean.html#numpy.mean)
`mean`
[,](generated/numpy.amin.html#numpy.amin)
`min`
[,](generated/numpy.nonzero.html#numpy.nonzero)
`nonzero`
[,](generated/numpy.partition.html#numpy.partition)
`partition`
[,](generated/numpy.prod.html#numpy.prod)
`prod`
[,](generated/numpy.ptp.html#numpy.ptp)
`ptp`
[,](generated/numpy.put.html#numpy.put)
`put`
[,](generated/numpy.ravel.html#numpy.ravel)
`ravel`
[,](generated/numpy.real.html#numpy.real)
`real`
[,](generated/numpy.repeat.html#numpy.repeat)
`repeat`
[,](generated/numpy.reshape.html#numpy.reshape)
`reshape`
[,](generated/numpy.around.html#numpy.around)
`round`
[,](generated/numpy.searchsorted.html#numpy.searchsorted)
`searchsorted`
[,](generated/numpy.sort.html#numpy.sort)
`sort`
[,](generated/numpy.squeeze.html#numpy.squeeze)
`squeeze`
[,](generated/numpy.std.html#numpy.std)
`std`
[,](generated/numpy.sum.html#numpy.sum)
`sum`
[,](generated/numpy.swapaxes.html#numpy.swapaxes)
`swapaxes`
[,](generated/numpy.take.html#numpy.take)
`take`
[,](generated/numpy.trace.html#numpy.trace)
`trace`
[,](generated/numpy.transpose.html#numpy.transpose)
`transpose`
[.](generated/numpy.var.html#numpy.var)
`var`
### Array conversion[#](#array-conversion)
|
Copy an element of an array to a standard Python scalar and return it.

|
Return the array as an

|
|
Insert scalar into an array (scalar is cast to array's dtype, if possible)

|
|
A compatibility alias for

|
|
Construct Python bytes containing the raw data bytes in the array.

|
|
Write array to a file as text or binary (default).

|
|
Dump a pickle of the array to the specified file.

|
Returns the pickle of the array as a string.

|
|
Copy of the array, cast to a specified type.

|
|
Swap the bytes of the array elements

|
|
Return a copy of the array.

|
|
New view of array with the same data.

|
|
Returns a field of the given array as a certain type.

|
|
Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY, respectively.

|
|
Fill the array with a scalar value.

|
### Shape manipulation[#](#shape-manipulation)
For reshape, resize, and transpose, the single tuple argument may be
replaced with `n`
integers which will be interpreted as an n-tuple.

|
Returns an array containing the same data with a new shape.

|
|
Change shape and size of array in-place.

|
|
Returns a view of the array with axes transposed.

|
|
Return a view of the array with

|
|
Return a copy of the array collapsed into one dimension.

|
|
Return a flattened array.

|
|
Remove axes of length one from

|
### Item selection and manipulation[#](#item-selection-and-manipulation)
For array methods that take an *axis* keyword, it defaults to
*None*. If axis is *None*, then the array is treated as a 1-D
array. Any other value for *axis* represents the dimension along which
the operation should proceed.

|
Return an array formed from the elements of

|
|
Set

|
|
Repeat elements of an array.

|
|
Use an index array to construct a new array from a set of choices.

|
|
Sort an array in-place.

|
|
Returns the indices that would sort this array.

|
|
Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array.

|
|
Returns the indices that would partition this array.

|
|
Find indices where elements of v should be inserted in a to maintain order.

|
Return the indices of the elements that are non-zero.

|
|
Return selected slices of this array along given axis.

|
|
Return specified diagonals.

|
### Calculation[#](#calculation)
Many of these methods take an argument named *axis*. In such cases,

If

*axis*is*None*(the default), the array is treated as a 1-D array and the operation is performed over the entire array. This behavior is also the default if self is a 0-dimensional array or array scalar. (An array scalar is an instance of the types/classes float32, float64, etc., whereas a 0-dimensional array is an ndarray instance containing precisely one array scalar.)
If

*axis*is an integer, then the operation is done over the given axis (for each 1-D subarray that can be created along the given axis).
Example of the *axis* argument

A 3-dimensional array of size 3 x 3 x 3, summed over each of its three axes

```
>>> x = np.arange(27).reshape((3,3,3))
>>> x
array([[[ 0, 1, 2],
[ 3, 4, 5],
[ 6, 7, 8]],
[[ 9, 10, 11],
[12, 13, 14],
[15, 16, 17]],
[[18, 19, 20],
[21, 22, 23],
[24, 25, 26]]])
>>> x.sum(axis=0)
array([[27, 30, 33],
[36, 39, 42],
[45, 48, 51]])
>>> # for sum, axis is the first keyword, so we may omit it,
>>> # specifying only its value
>>> x.sum(0), x.sum(1), x.sum(2)
(array([[27, 30, 33],
[36, 39, 42],
[45, 48, 51]]),
array([[ 9, 12, 15],
[36, 39, 42],
[63, 66, 69]]),
array([[ 3, 12, 21],
[30, 39, 48],
[57, 66, 75]]))
```
The parameter *dtype* specifies the data type over which a reduction
operation (like summing) should take place. The default reduce data
type is the same as the data type of *self*. To avoid overflow, it can
be useful to perform the reduction using a larger data type.

For several methods, an optional *out* argument can also be provided
and the result will be placed into the output array given. The *out*
argument must be an [ ndarray](generated/numpy.ndarray.html#numpy.ndarray) and have the same number of
elements. It can have a different data type in which case casting will
be performed.

|
Return the maximum along a given axis.

|
|
Return indices of the maximum values along the given axis.

|
|
Return the minimum along a given axis.

|
|
Return indices of the minimum values along the given axis.

|
|
Peak to peak (maximum - minimum) value along a given axis.

|
|
Return an array whose values are limited to

|
Complex-conjugate all elements.

|
|
Return

|
|
Return the sum along diagonals of the array.

|
|
Return the sum of the array elements over the given axis.

|
|
Return the cumulative sum of the elements along the given axis.

|
|
Returns the average of the array elements along given axis.

|
|
Returns the variance of the array elements, along given axis.

|
|
Returns the standard deviation of the array elements along given axis.

|
|
Return the product of the array elements over the given axis

|
|
Return the cumulative product of the elements along the given axis.

|
|
Returns True if all elements evaluate to True.

|
|
Returns True if any of the elements of

|
## Arithmetic, matrix multiplication, and comparison operations[#](#arithmetic-matrix-multiplication-and-comparison-operations)
Arithmetic and comparison operations on [ ndarrays](generated/numpy.ndarray.html#numpy.ndarray)
are defined as element-wise operations, and generally yield

[objects as results.](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
Each of the arithmetic operations (`+`
, `-`
, `*`
, `/`
, `//`
,
`%`
, `divmod()`
, `**`
or `pow()`
, `<<`
, `>>`
, `&`
,
`^`
, `|`
, `~`
) and the comparisons (`==`
, `<`
, `>`
,
`<=`
, `>=`
, `!=`
) is equivalent to the corresponding
universal function (or [ufunc](../glossary.html#term-ufunc) for short) in NumPy. For
more information, see the section on [Universal Functions](ufuncs.html#ufuncs).

Comparison operators:

|
Return self<value.

|
|
Return self<=value.

|
|
Return self>value.

|
|
Return self>=value.

|
|
Return self==value.

|
|
Return self!=value.

|
Truth value of an array ([ bool()](https://docs.python.org/3/library/functions.html#bool)):

True if self else False

|
Note

Truth-value testing of an array invokes
[ ndarray.__bool__](generated/numpy.ndarray.__bool__.html#numpy.ndarray.__bool__), which raises an error if the number of
elements in the array is larger than 1, because the truth value
of such arrays is ambiguous. Use

[and](generated/numpy.ndarray.any.html#numpy.ndarray.any)
`.any()`
[instead to be clear about what is meant in such cases. (If the number of elements is 0, the array evaluates to](generated/numpy.ndarray.all.html#numpy.ndarray.all)
`.all()`
`False`
.)Unary operations:

-self

|
+self

|
|
~self

|
Arithmetic:

|
Return self+value.

|
|
Return self-value.

|
|
Return self*value.

|
|
Return self/value.

|
|
Return self//value.

|
|
Return self%value.

|
|
Return divmod(self, value).

|
|
Return pow(self, value, mod).

|
|
Return self<<value.

|
|
Return self>>value.

|
|
Return self&value.

|
|
Return self|value.

|
|
Return self^value.

|
Note

Any third argument to

is silently ignored, as the underlying`pow`
takes only two arguments.`ufunc`
Because

is a built-in type (written in C), the`ndarray`
`__r{op}__`
special methods are not directly defined.
The functions called to implement many arithmetic special methods for arrays can be modified using

.`__array_ufunc__`
Arithmetic, in-place:

|
Return self+=value.

|
|
Return self-=value.

|
|
Return self*=value.

|
|
Return self/=value.

|
|
Return self//=value.

|
|
Return self%=value.

|
|
Return self**=value.

|
|
Return self<<=value.

|
|
Return self>>=value.

|
|
Return self&=value.

|
|
Return self|=value.

|
|
Return self^=value.

|
Warning

In place operations will perform the calculation using the
precision decided by the data type of the two operands, but will
silently downcast the result (if necessary) so it can fit back into
the array. Therefore, for mixed precision calculations, ```
A {op}=
B
```
can be different than `A = A {op} B`
. For example, suppose
`a = ones((3,3))`
. Then, `a += 3j`
is different than ```
a = a +
3j
```
: while they both perform the same computation, `a += 3`
casts the result to fit back in `a`
, whereas `a = a + 3j`
re-binds the name `a`
to the result.

Matrix Multiplication:

|
Return

|
## Special methods[#](#special-methods)
For standard library functions:

Used if

|
|
Used if

|
For pickling.

|
|
For unpickling.

|
Basic customization:

|
|
Returns either a new reference to self if dtype is not given or a new array of provided data type if dtype is different from the current dtype of the array.

|
|
Returns a view of

|
Container customization: (see [Indexing](arrays.indexing.html#arrays-indexing))

Return len(self).

|
|
Return self[key].

|
|
Set self[key] to value.

|
|
Return key in self.

|
Conversion; the operations [ int()](https://docs.python.org/3/library/functions.html#int),

[and](https://docs.python.org/3/library/functions.html#float)
`float()`
[. They work only on arrays that have one element in them and return the appropriate scalar.](https://docs.python.org/3/library/functions.html#complex)
`complex()`
|
|
String representations:

Return str(self).

|
Return repr(self).

|
Utility method for typing:

|
Return a parametrized wrapper around the

|# Reviewer guidelines[#](#reviewer-guidelines)
Reviewing open pull requests (PRs) helps move the project forward. We encourage people outside the project to get involved as well; it’s a great way to get familiar with the codebase.

## Who can be a reviewer?[#](#who-can-be-a-reviewer)
Reviews can come from outside the NumPy team – we welcome contributions from
domain experts (for instance, *linalg* or *fft*) or maintainers of other
projects. You do not need to be a NumPy maintainer (a NumPy team member with
permission to merge a PR) to review.

If we do not know you yet, consider introducing yourself in [the mailing list or
Slack](https://numpy.org/community/) before you start reviewing pull requests.

## Communication Guidelines[#](#communication-guidelines)
Every PR, good or bad, is an act of generosity. Opening with a positive comment will help the author feel rewarded, and your subsequent remarks may be heard more clearly. You may feel good also.

Begin if possible with the large issues, so the author knows they’ve been understood. Resist the temptation to immediately go line by line, or to open with small pervasive issues.

You are the face of the project, and NumPy some time ago decided

[the kind of project it will be](https://numpy.org/code-of-conduct/): open, empathetic, welcoming, friendly and patient. Be[kind](https://youtu.be/tzFWz5fiVKU?t=49m30s)to contributors.
Do not let perfect be the enemy of the good, particularly for documentation. If you find yourself making many small suggestions, or being too nitpicky on style or grammar, consider merging the current PR when all important concerns are addressed. Then, either push a commit directly (if you are a maintainer) or open a follow-up PR yourself.

If you need help writing replies in reviews, check out some

[standard replies for reviewing](#saved-replies).
## Reviewer Checklist[#](#reviewer-checklist)
Is the intended behavior clear under all conditions? Some things to watch:
-
What happens with unexpected inputs like empty arrays or nan/inf values?

Are axis or shape arguments tested to be

*int*or*tuples*?
Are unusual

*dtypes*tested if a function supports those?
Should variable names be improved for clarity or consistency?

Should comments be added, or rather removed as unhelpful or extraneous?

Does the documentation follow the

[NumPy guidelines](howto-docs.html#howto-document)? Are the docstrings properly formatted?
Does the code follow NumPy’s

[Stylistic Guidelines](index.html#stylistic-guidelines)?
If you are a maintainer, and it is not obvious from the PR description, add a short explanation of what a branch did to the merge message and, if closing an issue, also add “Closes gh-123” where 123 is the issue number.

For code changes, at least one maintainer (i.e. someone with commit rights) should review and approve a pull request. If you are the first to review a PR and approve of the changes use the GitHub

[approve review](https://help.github.com/articles/reviewing-changes-in-pull-requests/)tool to mark it as such. If a PR is straightforward, for example it’s a clearly correct bug fix, it can be merged straight away. If it’s more complex or changes public API, please leave it open for at least a couple of days so other maintainers get a chance to review.
If you are a subsequent reviewer on an already approved PR, please use the same review method as for a new PR (focus on the larger issues, resist the temptation to add only a few nitpicks). If you have commit rights and think no more review is needed, merge the PR.

### For maintainers[#](#for-maintainers)
Make sure all automated CI tests pass before merging a PR, and that the

[documentation builds](index.html#building-docs)without any errors.
In case of merge conflicts, ask the PR submitter to

[rebase on main](development_workflow.html#rebasing-on-main).
For PRs that add new features or are in some way complex, wait at least a day or two before merging it. That way, others get a chance to comment before the code goes in. Consider adding it to the release notes.

When merging contributions, a committer is responsible for ensuring that those meet the requirements outlined in the

[Development process guidelines](index.html#guidelines)for NumPy. Also, check that new features and backwards compatibility breaks were discussed on the[numpy-discussion mailing list](https://mail.python.org/mailman/listinfo/numpy-discussion).
Squashing commits or cleaning up commit messages of a PR that you consider too messy is OK. Remember to retain the original author’s name when doing this. Make sure commit messages follow the

[rules for NumPy](development_workflow.html#writing-the-commit-message).
When you want to reject a PR: if it’s very obvious, you can just close it and explain why. If it’s not, then it’s a good idea to first explain why you think the PR is not suitable for inclusion in NumPy and then let a second committer comment or close.

If the PR submitter doesn’t respond to your comments for 6 months, move the PR in question to the inactive category with the “inactive” tag attached. At this point, the PR can be closed by a maintainer. If there is any interest in finalizing the PR under consideration, this can be indicated at any time, without waiting 6 months, by a comment.

Maintainers are encouraged to finalize PRs when only small changes are necessary before merging (e.g., fixing code style or grammatical errors). If a PR becomes inactive, maintainers may make larger changes. Remember, a PR is a collaboration between a contributor and a reviewer/s, sometimes a direct push is the best way to finish it.

### API Changes[#](#api-changes)
As mentioned most public API changes should be discussed ahead of time and often with a wider audience (on the mailing list, or even through a NEP).

For changes in the public C-API be aware that the NumPy C-API is backwards compatible so that any addition must be ABI compatible with previous versions. When it is not the case, you must add a guard.

For example `PyUnicodeScalarObject`
struct contains the following:

```
#if NPY_FEATURE_VERSION >= NPY_1_20_API_VERSION
char *buffer_fmt;
#endif
```
Because the `buffer_fmt`
field was added to its end in NumPy 1.20 (all
previous fields remained ABI compatible).
Similarly, any function added to the API table in
`numpy/core/code_generators/numpy_api.py`
must use the `MinVersion`
annotation.
For example:

```
'PyDataMem_SetHandler': (304, MinVersion("1.22")),
```
Header only functionality (such as a new macro) typically does not need to be guarded.

### GitHub Workflow[#](#github-workflow)
When reviewing pull requests, please use workflow tracking features on GitHub as appropriate:

After you have finished reviewing, if you want to ask for the submitter to make changes, change your review status to “Changes requested.” This can be done on GitHub, PR page, Files changed tab, Review changes (button on the top right).

If you’re happy about the current status, mark the pull request as Approved (same way as Changes requested). Alternatively (for maintainers): merge the pull request, if you think it is ready to be merged.

It may be helpful to have a copy of the pull request code checked out on your
own machine so that you can play with it locally. You can use the [GitHub CLI](https://docs.github.com/en/github/getting-started-with-github/github-cli) to
do this by clicking the `Open with`
button in the upper right-hand corner of
the PR page.

Assuming you have your [development environment](development_environment.html#development-environment)
set up, you can now build the code and test it.

## Standard replies for reviewing[#](#standard-replies-for-reviewing)
It may be helpful to store some of these in GitHub’s [saved
replies](https://github.com/settings/replies/) for reviewing:

**Usage question**
You are asking a usage question. The issue tracker is for bugs and new features. I'm going to close this issue, feel free to ask for help via our [help channels](https://numpy.org/gethelp/).
**You’re welcome to update the docs**
Please feel free to offer a pull request updating the documentation if you feel it could be improved.
**Self-contained example for bug**
Please provide a [self-contained example code](https://stackoverflow.com/help/mcve), including imports and data (if possible), so that other contributors can just run it and reproduce your issue. Ideally your example code should be minimal.
**Software versions**
To help diagnose your issue, please paste the output of: ``` python -c 'import numpy; print(numpy.version.version)' ``` Thanks.
**Code blocks**
Readability can be greatly improved if you [format](https://help.github.com/articles/creating-and-highlighting-code-blocks/) your code snippets and complete error messages appropriately. You can edit your issue descriptions and comments at any time to improve readability. This helps maintainers a lot. Thanks!
**Linking to code**
For clarity's sake, you can link to code like [this](https://help.github.com/articles/creating-a-permanent-link-to-a-code-snippet/).
**Better description and title**
Please make the title of the PR more descriptive. The title will become the commit message when this is merged. You should state what issue (or PR) it fixes/resolves in the description using the syntax described [here](https://docs.github.com/en/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword).
**Regression test needed**
Please add a [non-regression test](https://en.wikipedia.org/wiki/Non-regression_testing) that would fail at main but pass in this PR.
**Don’t change unrelated**
Please do not change unrelated lines. It makes your contribution harder to review and may introduce merge conflicts to other pull requests.# Additional [Git](https://git-scm.com/) resources[#](#additional-git-resources)
## Tutorials and summaries[#](#tutorials-and-summaries)
[github help](https://help.github.com)has an excellent series of how-to guides.
[learn.github](https://learn.github.com/)has an excellent series of tutorials
The

[pro git book](https://git-scm.com/book/)is a good in-depth book on git.
A

[git cheat sheet](http://cheat.errtheblog.com/s/git)is a page giving summaries of common commands.
The

[git user manual](https://www.kernel.org/pub/software/scm/git/docs/user-manual.html)
The

[git tutorial](https://www.kernel.org/pub/software/scm/git/docs/gittutorial.html)
[git ready](http://www.gitready.com/)- a nice series of tutorials
[git casts](http://www.gitcasts.com/)- video snippets giving git how-tos.
[git magic](http://www-cs-students.stanford.edu/~blynn/gitmagic/index.html)- extended introduction with intermediate detail
The

[git parable](http://tom.preston-werner.com/2009/05/19/the-git-parable.html)is an easy read explaining the concepts behind git.
Our own

[git foundation](https://matthew-brett.github.com/pydagogue/foundation.html)expands on the[git parable](http://tom.preston-werner.com/2009/05/19/the-git-parable.html).
Fernando Perez’ git page -

[Fernando’s git page](http://www.fperez.org/py4science/git.html)- many links and tips
A good but technical page on

[git concepts](http://www.eecs.harvard.edu/~cduan/technical/git/)
[git svn crash course](https://git.wiki.kernel.org/index.php/GitSvnCrashCourse):[git](https://git-scm.com/)for those of us used to[subversion](http://subversion.tigris.org/)
## Advanced git workflow[#](#advanced-git-workflow)
There are many ways of working with [git](https://git-scm.com/); here are some posts on the
rules of thumb that other projects have come up with:

Linus Torvalds on

[git management](https://web.archive.org/web/20090328043540/http://kerneltrap.org/Linux/Git_Management)
Linus Torvalds on

[linux git workflow](https://www.mail-archive.com/dri-devel@lists.sourceforge.net/msg39091.html). Summary; use the git tools to make the history of your edits as clean as possible; merge from upstream edits as little as possible in branches where you are doing active development.
## Manual pages online[#](#manual-pages-online)
You can get these on your own machine with (e.g) `git help push`
or
(same thing) `git push --help`
, but, for convenience, here are the
online manual pages for some common commands:# Data type objects (`dtype`
)[#](#data-type-objects-dtype)
`dtype`
A data type object (an instance of [ numpy.dtype](generated/numpy.dtype.html#numpy.dtype) class)
describes how the bytes in the fixed-size block of memory
corresponding to an array item should be interpreted. It describes the
following aspects of the data:

Type of the data (integer, float, Python object, etc.)

Size of the data (how many bytes is in

*e.g.*the integer)
Byte order of the data (

[little-endian](../glossary.html#term-little-endian)or[big-endian](../glossary.html#term-big-endian))
If the data type is

[structured data type](../glossary.html#term-structured-data-type), an aggregate of other data types, (*e.g.*, describing an array item consisting of an integer and a float),
If the data type is a sub-array, what is its shape and data type.

To describe the type of scalar data, there are several [built-in
scalar types](arrays.scalars.html#arrays-scalars-built-in) in NumPy for various precision
of integers, floating-point numbers, *etc*. An item extracted from an
array, *e.g.*, by indexing, will be a Python object whose type is the
scalar type associated with the data type of the array.

Note that the scalar types are not [ dtype](generated/numpy.dtype.html#numpy.dtype) objects, even though
they can be used in place of one whenever a data type specification is
needed in NumPy.

Structured data types are formed by creating a data type whose
[field](../glossary.html#term-field) contain other data types. Each field has a name by
which it can be [accessed](../user/basics.indexing.html#arrays-indexing-fields). The parent data
type should be of sufficient size to contain all its fields; the
parent is nearly always based on the [ void](arrays.scalars.html#numpy.void) type which allows
an arbitrary item size. Structured data types may also contain nested
structured sub-array data types in their fields.

Finally, a data type can describe items that are themselves arrays of items of another data type. These sub-arrays must, however, be of a fixed size.

If an array is created using a data-type describing a sub-array,
the dimensions of the sub-array are appended to the shape
of the array when the array is created. Sub-arrays in a field of a
structured type behave differently, see [Field access](../user/basics.indexing.html#arrays-indexing-fields).

Sub-arrays always have a C-contiguous memory layout.

Example

A simple data type containing a 32-bit big-endian integer:
(see [Specifying and constructing data types](#arrays-dtypes-constructing) for details on construction)

```
>>> dt = np.dtype('>i4')
>>> dt.byteorder
'>'
>>> dt.itemsize
4
>>> dt.name
'int32'
>>> dt.type is np.int32
True
```
The corresponding array scalar type is [ int32](arrays.scalars.html#numpy.int32).

Example

A structured data type containing a 16-character string (in field ‘name’) and a sub-array of two 64-bit floating-point number (in field ‘grades’):

```
>>> dt = np.dtype([('name', np.unicode_, 16), ('grades', np.float64, (2,))])
>>> dt['name']
dtype('<U16')
>>> dt['grades']
dtype(('<f8', (2,)))
```
Items of an array of this data type are wrapped in an [array
scalar](arrays.scalars.html#arrays-scalars) type that also has two fields:

```
>>> x = np.array([('Sarah', (8.0, 7.0)), ('John', (6.0, 7.0))], dtype=dt)
>>> x[1]
('John', [6., 7.])
>>> x[1]['grades']
array([6., 7.])
>>> type(x[1])
<class 'numpy.void'>
>>> type(x[1]['grades'])
<class 'numpy.ndarray'>
```
## Specifying and constructing data types[#](#specifying-and-constructing-data-types)
Whenever a data-type is required in a NumPy function or method, either
a [ dtype](generated/numpy.dtype.html#numpy.dtype) object or something that can be converted to one can
be supplied. Such conversions are done by the

[constructor:](generated/numpy.dtype.html#numpy.dtype)
`dtype`
|
Create a data type object.

|
What can be converted to a data-type object is described below:

Array-scalar types
-
The 24 built-in

[array scalar type objects](arrays.scalars.html#arrays-scalars-built-in)all convert to an associated data-type object. This is true for their sub-classes as well.Note that not all data-type information can be supplied with a type-object: for example,

data-types have a default`flexible`
*itemsize*of 0, and require an explicitly given size to be useful.Example

>>> dt = np.dtype(np.int32) # 32-bit integer >>> dt = np.dtype(np.complex128) # 128-bit complex floating-point number
Generic types
-
The generic hierarchical type objects convert to corresponding type objects according to the associations:

`string`
Deprecated since version 1.19: This conversion of generic scalar types is deprecated. This is because it can be unexpected in a context such as

`arr.astype(dtype=np.floating)`
, which casts an array of`float32`
to an array of`float64`
, even though`float32`
is a subdtype of`np.floating`
.
Built-in Python types
-
Several python types are equivalent to a corresponding array scalar when used to generate a

object:`dtype`
`buffer`
(all others)

Note that

`str`
corresponds to UCS4 encoded unicode strings, while`string`
is an alias to`bytes_`
. The name`np.unicode_`
is also available as an alias to`np.str_`
, see[Note on string types](#string-dtype-note).Example

>>> dt = np.dtype(float) # Python-compatible floating-point number >>> dt = np.dtype(int) # Python-compatible integer >>> dt = np.dtype(object) # Python object
Note

All other types map to

`object_`
for convenience. Code should expect that such types may map to a specific (new) dtype in the future.
Types with `.dtype`
-
Any type object with a

`dtype`
attribute: The attribute will be accessed and used directly. The attribute must return something that is convertible into a dtype object.
Several kinds of strings can be converted. Recognized strings can be
prepended with `'>'`
([big-endian](../glossary.html#term-big-endian)), `'<'`
([little-endian](../glossary.html#term-little-endian)), or `'='`
(hardware-native, the default), to
specify the byte order.

One-character strings
-
Each built-in data-type has a character code (the updated Numeric typecodes), that uniquely identifies it.

Example

>>> dt = np.dtype('b') # byte, native byte order >>> dt = np.dtype('>H') # big-endian unsigned short >>> dt = np.dtype('<f') # little-endian single-precision float >>> dt = np.dtype('d') # double-precision floating-point number
Array-protocol type strings (see [The array interface protocol](arrays.interface.html#arrays-interface))
-
The first character specifies the kind of data and the remaining characters specify the number of bytes per item, except for Unicode, where it is interpreted as the number of characters. The item size must correspond to an existing type, or an error will be raised. The supported kinds are

`'?'`
boolean

`'b'`
(signed) byte

`'B'`
unsigned byte

`'i'`
(signed) integer

`'u'`
unsigned integer

`'f'`
floating-point

`'c'`
complex-floating point

`'m'`
timedelta

`'M'`
datetime

`'O'`
(Python) objects

`'S'`
,`'a'`
zero-terminated bytes (not recommended)

`'U'`
Unicode string

`'V'`
raw data (

)`void`
Example

>>> dt = np.dtype('i4') # 32-bit signed integer >>> dt = np.dtype('f8') # 64-bit floating-point number >>> dt = np.dtype('c16') # 128-bit complex floating-point number >>> dt = np.dtype('a25') # 25-length zero-terminated bytes >>> dt = np.dtype('U25') # 25-character string
Note on string types

For backward compatibility with existing code originally written to support Python 2,

`S`
and`a`
typestrings are zero-terminated bytes andcontinues to alias`numpy.string_`
. For unicode strings, use`numpy.bytes_`
`U`
,, or`numpy.str_`
. For signed bytes that do not need zero-termination`numpy.unicode_`
`b`
or`i1`
can be used.
String with comma-separated fields
-
A short-hand notation for specifying the format of a structured data type is a comma-separated string of basic formats.

A basic format in this context is an optional shape specifier followed by an array-protocol type string. Parenthesis are required on the shape if it has more than one dimension. NumPy allows a modification on the format in that any string that can uniquely identify the type can be used to specify the data-type in a field. The generated data-type fields are named

`'f0'`
,`'f1'`
, …,`'f<N-1>'`
where N (>1) is the number of comma-separated basic formats in the string. If the optional shape specifier is provided, then the data-type for the corresponding field describes a sub-array.Example

field named

`f0`
containing a 32-bit integer
field named

`f1`
containing a 2 x 3 sub-array of 64-bit floating-point numbers
field named

`f2`
containing a 32-bit floating-point number
>>> dt = np.dtype("i4, (2,3)f8, f4")
field named

`f0`
containing a 3-character string
field named

`f1`
containing a sub-array of shape (3,) containing 64-bit unsigned integers
field named

`f2`
containing a 3 x 4 sub-array containing 10-character strings
>>> dt = np.dtype("a3, 3u8, (3,4)a10")
Type strings
-
Any string in

`numpy.sctypeDict`
.keys():Example

>>> dt = np.dtype('uint32') # 32-bit unsigned integer >>> dt = np.dtype('float64') # 64-bit floating-point number
`(flexible_dtype, itemsize)`
The first argument must be an object that is converted to a zero-sized flexible data-type object, the second argument is an integer providing the desired itemsize.

Example

>>> dt = np.dtype((np.void, 10)) # 10-byte wide data block >>> dt = np.dtype(('U', 10)) # 10-character unicode string
`(fixed_dtype, shape)`
The first argument is any object that can be converted into a fixed-size data-type object. The second argument is the desired shape of this type. If the shape parameter is 1, then the data-type object used to be equivalent to fixed dtype. This behaviour is deprecated since NumPy 1.17 and will raise an error in the future. If

*shape*is a tuple, then the new dtype defines a sub-array of the given shape.Example

>>> dt = np.dtype((np.int32, (2,2))) # 2 x 2 integer sub-array >>> dt = np.dtype(('i4, (2,3)f8, f4', (2,3))) # 2 x 3 structured sub-array
`[(field_name, field_dtype, field_shape), ...]`
*obj*should be a list of fields where each field is described by a tuple of length 2 or 3. (Equivalent to the`descr`
item in theattribute.)`__array_interface__`
The first element,

*field_name*, is the field name (if this is`''`
then a standard field name,`'f#'`
, is assigned). The field name may also be a 2-tuple of strings where the first string is either a “title” (which may be any string or unicode string) or meta-data for the field which can be any object, and the second string is the “name” which must be a valid Python identifier.The second element,

*field_dtype*, can be anything that can be interpreted as a data-type.The optional third element

*field_shape*contains the shape if this field represents an array of the data-type in the second element. Note that a 3-tuple with a third argument equal to 1 is equivalent to a 2-tuple.This style does not accept

*align*in theconstructor as it is assumed that all of the memory is accounted for by the array interface description.`dtype`
Example

Data-type with fields

`big`
(big-endian 32-bit integer) and`little`
(little-endian 32-bit integer):>>> dt = np.dtype([('big', '>i4'), ('little', '<i4')])
Data-type with fields

`R`
,`G`
,`B`
,`A`
, each being an unsigned 8-bit integer:>>> dt = np.dtype([('R','u1'), ('G','u1'), ('B','u1'), ('A','u1')])
`{'names': ..., 'formats': ..., 'offsets': ..., 'titles': ..., 'itemsize': ...}`
This style has two required and three optional keys. The

*names*and*formats*keys are required. Their respective values are equal-length lists with the field names and the field formats. The field names must be strings and the field formats can be any object accepted byconstructor.`dtype`
When the optional keys

*offsets*and*titles*are provided, their values must each be lists of the same length as the*names*and*formats*lists. The*offsets*value is a list of byte offsets (limited to) for each field, while the`ctypes.c_int`
*titles*value is a list of titles for each field (`None`
can be used if no title is desired for that field). The*titles*can be any object, but when aobject will add another entry to the fields dictionary keyed by the title and referencing the same field tuple which will contain the title as an additional tuple member.`str`
The

*itemsize*key allows the total size of the dtype to be set, and must be an integer large enough so all the fields are within the dtype. If the dtype being constructed is aligned, the*itemsize*must also be divisible by the struct alignment. Total dtype*itemsize*is limited to.`ctypes.c_int`
Example

Data type with fields

`r`
,`g`
,`b`
,`a`
, each being an 8-bit unsigned integer:>>> dt = np.dtype({'names': ['r','g','b','a'], ... 'formats': [np.uint8, np.uint8, np.uint8, np.uint8]})
Data type with fields

`r`
and`b`
(with the given titles), both being 8-bit unsigned integers, the first at byte position 0 from the start of the field and the second at position 2:>>> dt = np.dtype({'names': ['r','b'], 'formats': ['u1', 'u1'], ... 'offsets': [0, 2], ... 'titles': ['Red pixel', 'Blue pixel']})
`{'field1': ..., 'field2': ..., ...}`
This usage is discouraged, because it is ambiguous with the other dict-based construction method. If you have a field called ‘names’ and a field called ‘formats’ there will be a conflict.

This style allows passing in the

attribute of a data-type object.`fields`
*obj*should contain string or unicode keys that refer to`(data-type, offset)`
or`(data-type, offset, title)`
tuples.Example

Data type containing field

`col1`
(10-character string at byte position 0),`col2`
(32-bit float at byte position 10), and`col3`
(integers at byte position 14):>>> dt = np.dtype({'col1': ('U10', 0), 'col2': (np.float32, 10), ... 'col3': (int, 14)})
`(base_dtype, new_dtype)`
In NumPy 1.7 and later, this form allows

*base_dtype*to be interpreted as a structured dtype. Arrays created with this dtype will have underlying dtype*base_dtype*but will have fields and flags taken from*new_dtype*. This is useful for creating custom structured dtypes, as done in[record arrays](arrays.classes.html#arrays-classes-rec).This form also makes it possible to specify struct dtypes with overlapping fields, functioning like the ‘union’ type in C. This usage is discouraged, however, and the union mechanism is preferred.

Both arguments must be convertible to data-type objects with the same total size.

Example

32-bit integer, whose first two bytes are interpreted as an integer via field

`real`
, and the following two bytes via field`imag`
.>>> dt = np.dtype((np.int32,{'real':(np.int16, 0),'imag':(np.int16, 2)}))
32-bit integer, which is interpreted as consisting of a sub-array of shape

`(4,)`
containing 8-bit integers:>>> dt = np.dtype((np.int32, (np.int8, 4)))
32-bit integer, containing fields

`r`
,`g`
,`b`
,`a`
that interpret the 4 bytes in the integer as four unsigned integers:>>> dt = np.dtype(('i4', [('r','u1'),('g','u1'),('b','u1'),('a','u1')]))
`dtype`
[#](#dtype)
`dtype`
NumPy data type descriptions are instances of the [ dtype](generated/numpy.dtype.html#numpy.dtype) class.

### Attributes[#](#attributes)
The type of the data is described by the following [ dtype](generated/numpy.dtype.html#numpy.dtype) attributes:

A character code (one of 'biufcmMOSUV') identifying the general kind of data.

|
A unique character code for each of the 21 different built-in types.

|
A unique number for each of the 21 different built-in types.

|
The array-protocol typestring of this data-type object.

|
Size of the data is in turn described by:

A bit-width name for this data-type.

|
The element size of this data-type object.

|
Endianness of this data:

A character indicating the byte-order of this data-type object.

|
Information about sub-data-types in a [structured data type](../glossary.html#term-structured-data-type):

Dictionary of named fields defined for this data type, or

|
Ordered list of field names, or

|
For data types that describe sub-arrays:

Tuple

|
Shape tuple of the sub-array if this data type describes a sub-array, and

|
Attributes providing additional information:

Boolean indicating whether this dtype contains any reference-counted objects in any fields or sub-dtypes.

|
Bit-flags describing how this data type is to be interpreted.

|
Integer indicating how this dtype relates to the built-in dtypes.

|
Boolean indicating whether the byte order of this dtype is native to the platform.

|
|
The required alignment (bytes) of this data-type according to the compiler.

|
Returns dtype for the base element of the subarrays, regardless of their dimension or shape.

|
Metadata attached by the user:

Either

|
### Methods[#](#methods)
Data types have the following method for changing the byte order:

|
Return a new dtype with a different byte order.

|
The following methods implement the pickle protocol:

Helper for pickle.

|
Utility method for typing:

|
Return a parametrized wrapper around the

|
Comparison operations:

|
Return self>=value.

|
|
Return self>value.

|
|
Return self<=value.

|
|
Return self<value.

|# numpy.lexsort[#](#numpy-lexsort)
numpy.lexsort(*keys*,*axis=-1*)[#](#numpy.lexsort)
-
Perform an indirect stable sort using a sequence of keys.

Given multiple sorting keys, which can be interpreted as columns in a spreadsheet, lexsort returns an array of integer indices that describes the sort order by multiple columns. The last key in the sequence is used for the primary sort order, the second-to-last key for the secondary sort order, and so on. The keys argument must be a sequence of objects that can be converted to arrays of the same shape. If a 2D array is provided for the keys argument, its rows are interpreted as the sorting keys and sorting is according to the last row, second last row etc.

Parameters:
-
**keys**(k, N) array or tuple containing k (N,)-shaped sequences
The

*k*different “columns” to be sorted. The last column (or row if*keys*is a 2D array) is the primary sort key.
**axis**int, optional
Axis to be indirectly sorted. By default, sort over the last axis.

Returns:
-
**indices**(N,) ndarray of ints
Array of indices that sort the keys along the specified axis.

See also

`argsort`
Indirect sort.

`ndarray.sort`
In-place sort.

`sort`
Return a sorted copy of an array.

Examples

Sort names: first by surname, then by name.

>>> surnames = ('Hertz', 'Galilei', 'Hertz') >>> first_names = ('Heinrich', 'Galileo', 'Gustav') >>> ind = np.lexsort((first_names, surnames)) >>> ind array([1, 2, 0])
>>> [surnames[i] + ", " + first_names[i] for i in ind] ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']
Sort two columns of numbers:

>>> a = [1,5,1,4,3,4,4] # First column >>> b = [9,4,0,4,0,2,1] # Second column >>> ind = np.lexsort((b,a)) # Sort by a, then by b >>> ind array([2, 0, 4, 6, 5, 3, 1])
>>> [(a[i],b[i]) for i in ind] [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]
Note that sorting is first according to the elements of

`a`
. Secondary sorting is according to the elements of`b`
.A normal

`argsort`
would have yielded:>>> [(a[i],b[i]) for i in np.argsort(a)] [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]
Structured arrays are sorted lexically by

`argsort`
:>>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)], ... dtype=np.dtype([('x', int), ('y', int)]))
>>> np.argsort(x) # or np.argsort(x, order=('x', 'y')) array([2, 0, 4, 6, 5, 3, 1])# numpy.savez_compressed[#](#numpy-savez-compressed)
numpy.savez_compressed(*file*,**args*,***kwds*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/npyio.py#L647-L710)[#](#numpy.savez_compressed)
-
Save several arrays into a single file in compressed

`.npz`
format.Provide arrays as keyword arguments to store them under the corresponding name in the output file:

`savez(fn, x=x, y=y)`
.If arrays are specified as positional arguments, i.e.,

`savez(fn, x, y)`
, their names will be*arr_0*,*arr_1*, etc.Parameters:
-
**file**str or file
Either the filename (string) or an open file (file-like object) where the data will be saved. If file is a string or a Path, the

`.npz`
extension will be appended to the filename if it is not already there.
**args**Arguments, optional
Arrays to save to the file. Please use keyword arguments (see

*kwds*below) to assign names to arrays. Arrays specified as args will be named “arr_0”, “arr_1”, and so on.
**kwds**Keyword arguments, optional
Arrays to save to the file. Each array will be saved to the output file with its corresponding keyword name.

Returns:
-
None
-
See also

`numpy.save`
Save a single array to a binary file in NumPy format.

`numpy.savetxt`
Save an array to a file as plain text.

`numpy.savez`
Save several arrays into an uncompressed

`.npz`
file format
`numpy.load`
Load the files created by savez_compressed.

Notes

The

`.npz`
file format is a zipped archive of files named after the variables they contain. The archive is compressed with`zipfile.ZIP_DEFLATED`
and each file in the archive contains one variable in`.npy`
format. For a description of the`.npy`
format, see.`numpy.lib.format`
When opening the saved

`.npz`
file witha`load`
*NpzFile*object is returned. This is a dictionary-like object which can be queried for its list of arrays (with the`.files`
attribute), and for the arrays themselves.Examples

>>> test_array = np.random.rand(3, 2) >>> test_vector = np.random.rand(4) >>> np.savez_compressed('/tmp/123', a=test_array, b=test_vector) >>> loaded = np.load('/tmp/123.npz') >>> print(np.array_equal(test_array, loaded['a'])) True >>> print(np.array_equal(test_vector, loaded['b'])) True# numpy.sort[#](#numpy-sort)
numpy.sort(*a*,*axis=-1*,*kind=None*,*order=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L865-L1018)[#](#numpy.sort)
-
Return a sorted copy of an array.

Parameters:
-
**a**array_like
Array to be sorted.

**axis**int or None, optional
Axis along which to sort. If None, the array is flattened before sorting. The default is -1, which sorts along the last axis.

**kind**{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, optional
Sorting algorithm. The default is ‘quicksort’. Note that both ‘stable’ and ‘mergesort’ use timsort or radix sort under the covers and, in general, the actual implementation will vary with data type. The ‘mergesort’ option is retained for backwards compatibility.

Changed in version 1.15.0.: The ‘stable’ option was added.

**order**str or list of str, optional
When

*a*is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.
Returns:
-
**sorted_array**ndarray
Array of the same type and shape as

*a*.
See also

`ndarray.sort`
Method to sort an array in-place.

`argsort`
Indirect sort.

`lexsort`
Indirect stable sort on multiple keys.

`searchsorted`
Find elements in a sorted array.

`partition`
Partial sort.

Notes

The various sorting algorithms are characterized by their average speed, worst case performance, work space size, and whether they are stable. A stable sort keeps items with the same key in the same relative order. The four algorithms implemented in NumPy have the following properties:

kind

speed

worst case

work space

stable

‘quicksort’

1

O(n^2)

0

no

‘heapsort’

3

O(n*log(n))

0

no

‘mergesort’

2

O(n*log(n))

~n/2

yes

‘timsort’

2

O(n*log(n))

~n/2

yes

Note

The datatype determines which of ‘mergesort’ or ‘timsort’ is actually used, even if ‘mergesort’ is specified. User selection at a finer scale is not currently available.

All the sort algorithms make temporary copies of the data when sorting along any but the last axis. Consequently, sorting along the last axis is faster and uses less space than sorting along any other axis.

The sort order for complex numbers is lexicographic. If both the real and imaginary parts are non-nan then the order is determined by the real parts except when they are equal, in which case the order is determined by the imaginary parts.

Previous to numpy 1.4.0 sorting real and complex arrays containing nan values led to undefined behaviour. In numpy versions >= 1.4.0 nan values are sorted to the end. The extended sort order is:

Real: [R, nan]

Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]

where R is a non-nan real value. Complex values with the same nan placements are sorted according to the non-nan part if it exists. Non-nan values are sorted as before.

New in version 1.12.0.

quicksort has been changed to

[introsort](https://en.wikipedia.org/wiki/Introsort). When sorting does not make enough progress it switches to[heapsort](https://en.wikipedia.org/wiki/Heapsort). This implementation makes quicksort O(n*log(n)) in the worst case.‘stable’ automatically chooses the best stable sorting algorithm for the data type being sorted. It, along with ‘mergesort’ is currently mapped to

[timsort](https://en.wikipedia.org/wiki/Timsort)or[radix sort](https://en.wikipedia.org/wiki/Radix_sort)depending on the data type. API forward compatibility currently limits the ability to select the implementation and it is hardwired for the different data types.New in version 1.17.0.

Timsort is added for better performance on already or nearly sorted data. On random data timsort is almost identical to mergesort. It is now used for stable sort while quicksort is still the default sort if none is chosen. For timsort details, refer to

[CPython listsort.txt](https://github.com/python/cpython/blob/3.7/Objects/listsort.txt). ‘mergesort’ and ‘stable’ are mapped to radix sort for integer data types. Radix sort is an O(n) sort instead of O(n log n).Changed in version 1.18.0.

NaT now sorts to the end of arrays for consistency with NaN.

Examples

>>> a = np.array([[1,4],[3,1]]) >>> np.sort(a) # sort along the last axis array([[1, 4], [1, 3]]) >>> np.sort(a, axis=None) # sort the flattened array array([1, 1, 3, 4]) >>> np.sort(a, axis=0) # sort along the first axis array([[1, 1], [3, 4]])
Use the

*order*keyword to specify a field to use when sorting a structured array:>>> dtype = [('name', 'S10'), ('height', float), ('age', int)] >>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38), ... ('Galahad', 1.7, 38)] >>> a = np.array(values, dtype=dtype) # create a structured array >>> np.sort(a, order='height') array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41), ('Lancelot', 1.8999999999999999, 38)], dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])
Sort by age, then height if ages are equal:

>>> np.sort(a, order=['age', 'height']) array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38), ('Arthur', 1.8, 41)], dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])# numpy.reshape[#](#numpy-reshape)
numpy.reshape(*a*,*newshape*,*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L200-L285)[#](#numpy.reshape)
-
Gives a new shape to an array without changing its data.

Parameters:
-
**a**array_like
Array to be reshaped.

**newshape**int or tuple of ints
The new shape should be compatible with the original shape. If an integer, then the result will be a 1-D array of that length. One shape dimension can be -1. In this case, the value is inferred from the length of the array and remaining dimensions.

**order**{‘C’, ‘F’, ‘A’}, optional
Read the elements of

*a*using this index order, and place the elements into the reshaped array using this index order. ‘C’ means to read / write the elements using C-like index order, with the last axis index changing fastest, back to the first axis index changing slowest. ‘F’ means to read / write the elements using Fortran-like index order, with the first index changing fastest, and the last index changing slowest. Note that the ‘C’ and ‘F’ options take no account of the memory layout of the underlying array, and only refer to the order of indexing. ‘A’ means to read / write the elements in Fortran-like index order if*a*is Fortran*contiguous*in memory, C-like order otherwise.
Returns:
-
**reshaped_array**ndarray
This will be a new view object if possible; otherwise, it will be a copy. Note there is no guarantee of the

*memory layout*(C- or Fortran- contiguous) of the returned array.
See also

`ndarray.reshape`
Equivalent method.

Notes

It is not always possible to change the shape of an array without copying the data.

The

*order*keyword gives the index ordering both for*fetching*the values from*a*, and then*placing*the values into the output array. For example, let’s say you have an array:>>> a = np.arange(6).reshape((3, 2)) >>> a array([[0, 1], [2, 3], [4, 5]])
You can think of reshaping as first raveling the array (using the given index order), then inserting the elements from the raveled array into the new array using the same kind of index ordering as was used for the raveling.

>>> np.reshape(a, (2, 3)) # C-like index ordering array([[0, 1, 2], [3, 4, 5]]) >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape array([[0, 1, 2], [3, 4, 5]]) >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering array([[0, 4, 3], [2, 1, 5]]) >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F') array([[0, 4, 3], [2, 1, 5]])
Examples

>>> a = np.array([[1,2,3], [4,5,6]]) >>> np.reshape(a, 6) array([1, 2, 3, 4, 5, 6]) >>> np.reshape(a, 6, order='F') array([1, 4, 2, 5, 3, 6])
>>> np.reshape(a, (3,-1)) # the unspecified value is inferred to be 2 array([[1, 2], [3, 4], [5, 6]])# Random sampling (`numpy.random`
)[#](#random-sampling-numpy-random)
`numpy.random`
## Quick Start[#](#quick-start)
The [ numpy.random](#module-numpy.random) module implements pseudo-random number generators
(PRNGs or RNGs, for short) with the ability to draw samples from a variety of
probability distributions. In general, users will create a

[instance with](generator.html#numpy.random.Generator)
`Generator`
[and call the various methods on it to obtain samples from different distributions.](generator.html#numpy.random.default_rng)
`default_rng`
```
>>> import numpy as np
>>> rng = np.random.default_rng()
# Generate one random float uniformly distributed over the range [0, 1)
>>> rng.random()
0.06369197489564249 # may vary
# Generate an array of 10 numbers according to a unit Gaussian distribution.
>>> rng.standard_normal(10)
array([-0.31018314, -1.8922078 , -0.3628523 , -0.63526532, 0.43181166, # may vary
0.51640373, 1.25693945, 0.07779185, 0.84090247, -2.13406828])
# Generate an array of 5 integers uniformly over the range [0, 10).
>>> rng.integers(low=0, high=10, size=5)
array([8, 7, 6, 2, 0]) # may vary
```
Our RNGs are deterministic sequences and can be reproduced by specifying a seed integer to
derive its initial state. By default, with no seed provided, [ default_rng](generator.html#numpy.random.default_rng) will create
seed the RNG from nondeterministic data from the operating system and therefore
generate different numbers each time. The pseudo-random sequences will be
independent for all practical purposes, at least those purposes for which our
pseudo-randomness was good for in the first place.

```
>>> rng1 = np.random.default_rng()
>>> rng1.random()
0.6596288841243357 # may vary
>>> rng2 = np.random.default_rng()
>>> rng2.random()
0.11885628817151628 # may vary
```
Warning

The pseudo-random number generators implemented in this module are designed
for statistical modeling and simulation. They are not suitable for security
or cryptographic purposes. See the [ secrets](https://docs.python.org/3/library/secrets.html#module-secrets) module from the
standard library for such use cases.

Seeds should be large positive integers. [ default_rng](generator.html#numpy.random.default_rng) can take positive
integers of any size. We recommend using very large, unique numbers to ensure
that your seed is different from anyone else’s. This is good practice to ensure
that your results are statistically independent from theirs unless you are
intentionally

*trying*to reproduce their result. A convenient way to get such a seed number is to use
[to get an arbitrary 128-bit integer.](https://docs.python.org/3/library/secrets.html#secrets.randbits)
`secrets.randbits`
```
>>> import secrets
>>> import numpy as np
>>> secrets.randbits(128)
122807528840384100672342137672332424406 # may vary
>>> rng1 = np.random.default_rng(122807528840384100672342137672332424406)
>>> rng1.random()
0.5363922081269535
>>> rng2 = np.random.default_rng(122807528840384100672342137672332424406)
>>> rng2.random()
0.5363922081269535
```
See the documentation on [ default_rng](generator.html#numpy.random.default_rng) and

[for more advanced options for controlling the seed in specialized scenarios.](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
[ Generator](generator.html#numpy.random.Generator) and its associated infrastructure was introduced in NumPy version
1.17.0. There is still a lot of code that uses the older
[and the functions in](legacy.html#numpy.random.RandomState)
`RandomState`
[. While there are no plans to remove them at this time, we do recommend transitioning to](#module-numpy.random)
`numpy.random`
[as you can. The algorithms are faster, more flexible, and will receive more improvements in the future. For the most part,](generator.html#numpy.random.Generator)
`Generator`
[can be used as a replacement for](generator.html#numpy.random.Generator)
`Generator`
[. See](legacy.html#numpy.random.RandomState)
`RandomState`
[Legacy Random Generation](legacy.html#legacy)for information on the legacy infrastructure,
[What’s New or Different](new-or-different.html#new-or-different)for information on transitioning, and
[NEP 19](https://numpy.org/neps/nep-0019-rng-policy.html#nep19)for some of the reasoning for the transition.
## Design[#](#design)
Users primarily interact with [ Generator](generator.html#numpy.random.Generator) instances. Each

[instance owns a](generator.html#numpy.random.Generator)
`Generator`
[instance that implements the core RNG algorithm. The](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
[has a limited set of responsibilities. It manages state and provides functions to produce random doubles and random unsigned 32- and 64-bit values.](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
The [ Generator](generator.html#numpy.random.Generator) takes the bit generator-provided stream and transforms them
into more useful distributions, e.g., simulated normal random values. This
structure allows alternative bit generators to be used with little code
duplication.

NumPy implements several different [ BitGenerator](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator) classes implementing
different RNG algorithms.

[currently uses](generator.html#numpy.random.default_rng)
`default_rng`
[as the default](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
[. It has better statistical properties and performance than the](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
[algorithm used in the legacy](bit_generators/mt19937.html#numpy.random.MT19937)
`MT19937`
[. See](legacy.html#numpy.random.RandomState)
`RandomState`
[Bit Generators](bit_generators/index.html#random-bit-generators)for more details on the supported BitGenerators.
[ default_rng](generator.html#numpy.random.default_rng) and BitGenerators delegate the conversion of seeds into RNG
states to
[internally.](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
[implements a sophisticated algorithm that intermediates between the user’s input and the internal implementation details of each](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
[algorithm, each of which can require different amounts of bits for its state. Importantly, it lets you use arbitrary-sized integers and arbitrary sequences of such integers to mix together into the RNG state. This is a useful primitive for constructing a](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
[flexible pattern for parallel RNG streams](parallel.html#seedsequence-spawn).
For backward compatibility, we still maintain the legacy [ RandomState](legacy.html#numpy.random.RandomState) class.
It continues to use the

[algorithm by default, and old seeds continue to reproduce the same results. The convenience](bit_generators/mt19937.html#numpy.random.MT19937)
`MT19937`
[Functions in numpy.random](legacy.html#functions-in-numpy-random)are still aliases to the methods on a single global
[instance. See](legacy.html#numpy.random.RandomState)
`RandomState`
[Legacy Random Generation](legacy.html#legacy)for the complete details. See
[What’s New or Different](new-or-different.html#new-or-different)for a detailed comparison between
[and](generator.html#numpy.random.Generator)
`Generator`
[.](legacy.html#numpy.random.RandomState)
`RandomState`
### Parallel Generation[#](#parallel-generation)
The included generators can be used in parallel, distributed applications in a number of ways:

Users with a very large amount of parallelism will want to consult
[Upgrading PCG64 with PCG64DXSM](upgrading-pcg64.html#upgrading-pcg64).

## Concepts[#](#concepts)
## Features[#](#features)
[Parallel Applications](parallel.html)
[Multithreaded Generation](multithreading.html)
[What’s New or Different](new-or-different.html)
[Comparing Performance](performance.html)
[C API for random](c-api.html)
[Examples of using Numba, Cython, CFFI](extending.html)
### Original Source of the Generator and BitGenerators[#](#original-source-of-the-generator-and-bitgenerators)
This package was developed independently of NumPy and was integrated in version
1.17.0. The original repo is at [https://github.com/bashtage/randomgen](https://github.com/bashtage/randomgen).# numpy.concatenate[#](#numpy-concatenate)
numpy.concatenate(*(a1*,*a2*,*...)*,*axis=0*,*out=None*,*dtype=None*,*casting="same_kind"*)[#](#numpy.concatenate)
-
Join a sequence of arrays along an existing axis.

Parameters:
-
**a1, a2, …**sequence of array_like
The arrays must have the same shape, except in the dimension corresponding to

*axis*(the first, by default).
**axis**int, optional
The axis along which the arrays will be joined. If axis is None, arrays are flattened before use. Default is 0.

**out**ndarray, optional
If provided, the destination to place the result. The shape must be correct, matching that of what concatenate would have returned if no out argument were specified.

**dtype**str or dtype
If provided, the destination array will have this dtype. Cannot be provided together with

*out*.New in version 1.20.0.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘same_kind’.

New in version 1.20.0.

Returns:
-
**res**ndarray
The concatenated array.

See also

`ma.concatenate`
Concatenate function that preserves input masks.

`array_split`
Split an array into multiple sub-arrays of equal or near-equal size.

`split`
Split array into a list of multiple sub-arrays of equal size.

`hsplit`
Split array into multiple sub-arrays horizontally (column wise).

`vsplit`
Split array into multiple sub-arrays vertically (row wise).

`dsplit`
Split array into multiple sub-arrays along the 3rd axis (depth).

`stack`
Stack a sequence of arrays along a new axis.

`block`
Assemble arrays from blocks.

`hstack`
Stack arrays in sequence horizontally (column wise).

`vstack`
Stack arrays in sequence vertically (row wise).

`dstack`
Stack arrays in sequence depth wise (along third dimension).

`column_stack`
Stack 1-D arrays as columns into a 2-D array.

Notes

When one or more of the arrays to be concatenated is a MaskedArray, this function will return a MaskedArray object instead of an ndarray, but the input masks are

*not*preserved. In cases where a MaskedArray is expected as input, use the ma.concatenate function from the masked array module instead.Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> b = np.array([[5, 6]]) >>> np.concatenate((a, b), axis=0) array([[1, 2], [3, 4], [5, 6]]) >>> np.concatenate((a, b.T), axis=1) array([[1, 2, 5], [3, 4, 6]]) >>> np.concatenate((a, b), axis=None) array([1, 2, 3, 4, 5, 6])
This function will not preserve masking of MaskedArray inputs.

>>> a = np.ma.arange(3) >>> a[1] = np.ma.masked >>> b = np.arange(2, 5) >>> a masked_array(data=[0, --, 2], mask=[False, True, False], fill_value=999999) >>> b array([2, 3, 4]) >>> np.concatenate([a, b]) masked_array(data=[0, 1, 2, 2, 3, 4], mask=False, fill_value=999999) >>> np.ma.concatenate([a, b]) masked_array(data=[0, --, 2, 2, 3, 4], mask=[False, True, False, False, False, False], fill_value=999999)# numpy.unique[#](#numpy-unique)
numpy.unique(*ar*,*return_index=False*,*return_inverse=False*,*return_counts=False*,*axis=None*,***,*equal_nan=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/arraysetops.py#L138-L320)[#](#numpy.unique)
-
Find the unique elements of an array.

Returns the sorted unique elements of an array. There are three optional outputs in addition to the unique elements:

the indices of the input array that give the unique values

the indices of the unique array that reconstruct the input array

the number of times each unique value comes up in the input array

Parameters:
-
**ar**array_like
Input array. Unless

*axis*is specified, this will be flattened if it is not already 1-D.
**return_index**bool, optional
If True, also return the indices of

*ar*(along the specified axis, if provided, or in the flattened array) that result in the unique array.
**return_inverse**bool, optional
If True, also return the indices of the unique array (for the specified axis, if provided) that can be used to reconstruct

*ar*.
**return_counts**bool, optional
If True, also return the number of times each unique item appears in

*ar*.
**axis**int or None, optional
The axis to operate on. If None,

*ar*will be flattened. If an integer, the subarrays indexed by the given axis will be flattened and treated as the elements of a 1-D array with the dimension of the given axis, see the notes for more details. Object arrays or structured arrays that contain objects are not supported if the*axis*kwarg is used. The default is None.New in version 1.13.0.

**equal_nan**bool, optional
If True, collapses multiple NaN values in the return array into one.

New in version 1.24.

Returns:
-
**unique**ndarray
The sorted unique values.

**unique_indices**ndarray, optional
The indices of the first occurrences of the unique values in the original array. Only provided if

*return_index*is True.
**unique_inverse**ndarray, optional
The indices to reconstruct the original array from the unique array. Only provided if

*return_inverse*is True.
**unique_counts**ndarray, optional
The number of times each of the unique values comes up in the original array. Only provided if

*return_counts*is True.New in version 1.9.0.

See also

`numpy.lib.arraysetops`
Module with a number of other functions for performing set operations on arrays.

`repeat`
Repeat elements of an array.

Notes

When an axis is specified the subarrays indexed by the axis are sorted. This is done by making the specified axis the first dimension of the array (move the axis to the first dimension to keep the order of the other axes) and then flattening the subarrays in C order. The flattened subarrays are then viewed as a structured type with each element given a label, with the effect that we end up with a 1-D array of structured types that can be treated in the same way as any other 1-D array. The result is that the flattened subarrays are sorted in lexicographic order starting with the first element.

Examples

>>> np.unique([1, 1, 2, 2, 3, 3]) array([1, 2, 3]) >>> a = np.array([[1, 1], [2, 3]]) >>> np.unique(a) array([1, 2, 3])
Return the unique rows of a 2D array

>>> a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]]) >>> np.unique(a, axis=0) array([[1, 0, 0], [2, 3, 4]])
Return the indices of the original array that give the unique values:

>>> a = np.array(['a', 'b', 'b', 'c', 'a']) >>> u, indices = np.unique(a, return_index=True) >>> u array(['a', 'b', 'c'], dtype='<U1') >>> indices array([0, 1, 3]) >>> a[indices] array(['a', 'b', 'c'], dtype='<U1')
Reconstruct the input array from the unique values and inverse:

>>> a = np.array([1, 2, 6, 4, 2, 3, 2]) >>> u, indices = np.unique(a, return_inverse=True) >>> u array([1, 2, 3, 4, 6]) >>> indices array([0, 1, 4, 3, 1, 2, 1]) >>> u[indices] array([1, 2, 6, 4, 2, 3, 2])
Reconstruct the input values from the unique values and counts:

>>> a = np.array([1, 2, 6, 4, 2, 3, 2]) >>> values, counts = np.unique(a, return_counts=True) >>> values array([1, 2, 3, 4, 6]) >>> counts array([1, 3, 1, 1, 1]) >>> np.repeat(values, counts) array([1, 2, 2, 2, 3, 4, 6]) # original order not preserved# Scalars[#](#scalars)
Python defines only one type of a particular data class (there is only one integer type, one floating-point type, etc.). This can be convenient in applications that don’t need to be concerned with all the ways data can be represented in a computer. For scientific computing, however, more control is often needed.

In NumPy, there are 24 new fundamental Python types to describe different types of scalars. These type descriptors are mostly based on the types available in the C language that CPython is written in, with several additional types compatible with Python’s types.

Array scalars have the same attributes and methods as [ ndarrays](generated/numpy.ndarray.html#numpy.ndarray).

[[1]](#id2)This allows one to treat items of an array partly on the same footing as arrays, smoothing out rough edges that result when mixing scalar and array operations.
Array scalars live in a hierarchy (see the Figure below) of data
types. They can be detected using the hierarchy: For example,
`isinstance(val, np.generic)`
will return [ True](https://docs.python.org/3/library/constants.html#True) if

*val*is an array scalar object. Alternatively, what kind of array scalar is present can be determined using other members of the data type hierarchy. Thus, for example
`isinstance(val, np.complexfloating)`
will return [if](https://docs.python.org/3/library/constants.html#True)
`True`
*val*is a complex valued type, while
`isinstance(val, np.flexible)`
will return true if *val*is one of the flexible itemsize array types (
[,](#numpy.str_)
`str_`
[,](#numpy.bytes_)
`bytes_`
[).](#numpy.void)
`void`
## Built-in scalar types[#](#built-in-scalar-types)
The built-in scalar types are shown below. The C-like names are associated with character codes, which are shown in their descriptions. Use of the character codes, however, is discouraged.

Some of the scalar types are essentially equivalent to fundamental Python types and therefore inherit from them as well as from the generic array scalar type:

Array scalar type

|
Related Python type

|
Inherits?

|
---|---|---|
Python 2 only

|
yes

|
yes

|
yes

|
yes

|
no

|
no

|
no

|
The [ bool_](#numpy.bool_) data type is very similar to the Python

[but does not inherit from it because Python’s](https://docs.python.org/3/library/functions.html#bool)
`bool`
[does not allow itself to be inherited from, and on the C-level the size of the actual bool data is not the same as a Python Boolean scalar.](https://docs.python.org/3/library/functions.html#bool)
`bool`
Warning

The [ int_](#numpy.int_) type does

**not**inherit from the
[built-in under Python 3, because type](https://docs.python.org/3/library/functions.html#int)
`int`
[is no longer a fixed-width integer type.](https://docs.python.org/3/library/functions.html#int)
`int`
Tip

The default data type in NumPy is [ float_](#numpy.float_).

*class*numpy.generic[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.generic)
-
Base class for numpy scalar types.

Class from which most (all?) numpy scalar types are derived. For consistency, exposes the same API as

, despite many consequent attributes being either “get-only,” or completely irrelevant. This is the class from which it is strongly suggested users should derive custom scalar types.`ndarray`
### Integer types[#](#integer-types)
Note

The numpy integer types mirror the behavior of C integers, and can therefore
be subject to [Overflow Errors](../user/basics.types.html#overflow-errors).

#### Signed integer types[#](#signed-integer-types)
*class*numpy.byte[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.byte)
-
Signed integer type, compatible with C

`char`
.Character code:
-
`'b'`
Alias on this platform (Linux x86_64):
-
: 8-bit signed integer (`numpy.int8`
`-128`
to`127`
).
*class*numpy.short[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.short)
-
Signed integer type, compatible with C

`short`
.Character code:
-
`'h'`
Alias on this platform (Linux x86_64):
-
: 16-bit signed integer (`numpy.int16`
`-32_768`
to`32_767`
).
*class*numpy.intc[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.intc)
-
Signed integer type, compatible with C

`int`
.Character code:
-
`'i'`
Alias on this platform (Linux x86_64):
-
: 32-bit signed integer (`numpy.int32`
`-2_147_483_648`
to`2_147_483_647`
).
*class*numpy.int_[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.int_)
-
Signed integer type, compatible with Python

*int*and C`long`
.Character code:
-
`'l'`
Alias on this platform (Linux x86_64):
-
: 64-bit signed integer (`numpy.int64`
`-9_223_372_036_854_775_808`
to`9_223_372_036_854_775_807`
).
Alias on this platform (Linux x86_64):
-
: Signed integer large enough to fit pointer, compatible with C`numpy.intp`
`intptr_t`
.
#### Unsigned integer types[#](#unsigned-integer-types)
*class*numpy.ubyte[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.ubyte)
-
Unsigned integer type, compatible with C

`unsigned char`
.Character code:
-
`'B'`
Alias on this platform (Linux x86_64):
-
: 8-bit unsigned integer (`numpy.uint8`
`0`
to`255`
).
*class*numpy.ushort[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.ushort)
-
Unsigned integer type, compatible with C

`unsigned short`
.Character code:
-
`'H'`
Alias on this platform (Linux x86_64):
-
: 16-bit unsigned integer (`numpy.uint16`
`0`
to`65_535`
).
*class*numpy.uintc[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.uintc)
-
Unsigned integer type, compatible with C

`unsigned int`
.Character code:
-
`'I'`
Alias on this platform (Linux x86_64):
-
: 32-bit unsigned integer (`numpy.uint32`
`0`
to`4_294_967_295`
).
*class*numpy.uint[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.uint)
-
Unsigned integer type, compatible with C

`unsigned long`
.Character code:
-
`'L'`
Alias on this platform (Linux x86_64):
-
: 64-bit unsigned integer (`numpy.uint64`
`0`
to`18_446_744_073_709_551_615`
).
Alias on this platform (Linux x86_64):
-
: Unsigned integer large enough to fit pointer, compatible with C`numpy.uintp`
`uintptr_t`
.
### Inexact types[#](#inexact-types)
*class*numpy.inexact[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.inexact)
-
Abstract base class of all numeric scalar types with a (potentially) inexact representation of the values in its range, such as floating-point numbers.

Note

Inexact scalars are printed using the fewest decimal digits needed to
distinguish their value from other values of the same datatype,
by judicious rounding. See the `unique`
parameter of
[ format_float_positional](generated/numpy.format_float_positional.html#numpy.format_float_positional) and

[.](generated/numpy.format_float_scientific.html#numpy.format_float_scientific)
`format_float_scientific`
This means that variables with equal binary values but whose datatypes are of different precisions may display differently:

```
>>> f16 = np.float16("0.1")
>>> f32 = np.float32(f16)
>>> f64 = np.float64(f32)
>>> f16 == f32 == f64
True
>>> f16, f32, f64
(0.1, 0.099975586, 0.0999755859375)
```
Note that none of these floats hold the exact value \(\frac{1}{10}\);
`f16`
prints as `0.1`
because it is as close to that value as possible,
whereas the other types do not as they have more precision and therefore have
closer values.

Conversely, floating-point scalars of different precisions which approximate the same decimal value may compare unequal despite printing identically:

```
>>> f16 = np.float16("0.1")
>>> f32 = np.float32("0.1")
>>> f64 = np.float64("0.1")
>>> f16 == f32 == f64
False
>>> f16, f32, f64
(0.1, 0.1, 0.1)
```
#### Floating-point types[#](#floating-point-types)
*class*numpy.half[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.half)
-
Half-precision floating-point number type.

Character code:
-
`'e'`
Alias on this platform (Linux x86_64):
-
: 16-bit-precision floating-point number type: sign bit, 5 bits exponent, 10 bits mantissa.`numpy.float16`
*class*numpy.single[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.single)
-
Single-precision floating-point number type, compatible with C

`float`
.Character code:
-
`'f'`
Alias on this platform (Linux x86_64):
-
: 32-bit-precision floating-point number type: sign bit, 8 bits exponent, 23 bits mantissa.`numpy.float32`
*class*numpy.double(*x=0*,*/*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.double)
-
Double-precision floating-point number type, compatible with Python

*float*and C`double`
.Character code:
-
`'d'`
Alias:
-
Alias on this platform (Linux x86_64):
-
: 64-bit precision floating-point number type: sign bit, 11 bits exponent, 52 bits mantissa.`numpy.float64`
*class*numpy.longdouble[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.longdouble)
-
Extended-precision floating-point number type, compatible with C

`long double`
but not necessarily with IEEE 754 quadruple-precision.Character code:
-
`'g'`
Alias:
-
Alias on this platform (Linux x86_64):
-
: 128-bit extended-precision floating-point number type.`numpy.float128`
#### Complex floating-point types[#](#complex-floating-point-types)
*class*numpy.complexfloating[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.complexfloating)
-
Abstract base class of all complex number scalar types that are made up of floating-point numbers.

*class*numpy.csingle[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.csingle)
-
Complex number type composed of two single-precision floating-point numbers.

Character code:
-
`'F'`
Alias:
-
Alias on this platform (Linux x86_64):
-
: Complex number type composed of 2 32-bit-precision floating-point numbers.`numpy.complex64`
*class*numpy.cdouble(*real=0*,*imag=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.cdouble)
-
Complex number type composed of two double-precision floating-point numbers, compatible with Python

*complex*.Character code:
-
`'D'`
Alias:
-
Alias:
-
Alias on this platform (Linux x86_64):
-
: Complex number type composed of 2 64-bit-precision floating-point numbers.`numpy.complex128`
*class*numpy.clongdouble[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.clongdouble)
-
Complex number type composed of two extended-precision floating-point numbers.

Character code:
-
`'G'`
Alias:
-
Alias:
-
Alias on this platform (Linux x86_64):
-
: Complex number type composed of 2 128-bit extended-precision floating-point numbers.`numpy.complex256`
### Other types[#](#other-types)
*class*numpy.bool_[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.bool_)
-
Boolean type (True or False), stored as a byte.

Warning

The

type is not a subclass of the`bool_`
type (the`int_`
is not even a number type). This is different than Python’s default implementation of`bool_`
as a sub-class of`bool`
.`int`
Character code:
-
`'?'`
*class*numpy.datetime64[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.datetime64)
-
If created from a 64-bit integer, it represents an offset from

`1970-01-01T00:00:00`
. If created from string, the string can be in ISO 8601 date or datetime format.>>> np.datetime64(10, 'Y') numpy.datetime64('1980') >>> np.datetime64('1980', 'Y') numpy.datetime64('1980') >>> np.datetime64(10, 'D') numpy.datetime64('1970-01-11')
See

[Datetimes and Timedeltas](arrays.datetime.html#arrays-datetime)for more information.Character code:
-
`'M'`
*class*numpy.timedelta64[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.timedelta64)
-
A timedelta stored as a 64-bit integer.

See

[Datetimes and Timedeltas](arrays.datetime.html#arrays-datetime)for more information.Character code:
-
`'m'`
Note

The data actually stored in object arrays
(*i.e.*, arrays having dtype [ object_](#numpy.object_)) are references to
Python objects, not the objects themselves. Hence, object arrays
behave more like usual Python

[, in the sense that their contents need not be of the same Python type.](https://docs.python.org/3/library/stdtypes.html#list)
`lists`
The object type is also special because an array containing
[ object_](#numpy.object_) items does not return an

[object on item access, but instead returns the actual object that the array item refers to.](#numpy.object_)
`object_`
The following data types are **flexible**: they have no predefined
size and the data they describe can be of different length in different
arrays. (In the character codes `#`
is an integer denoting how many
elements the data type consists of.)

*class*numpy.flexible[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.flexible)
-
Abstract base class of all scalar types without predefined length. The actual size of these types depends on the specific

*np.dtype*instantiation.
*class*numpy.bytes_[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.bytes_)
-
A byte string.

When used in arrays, this type strips trailing null bytes.

Character code:
-
`'S'`
Alias:
-
*class*numpy.str_[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.str_)
-
A unicode string.

This type strips trailing null codepoints.

>>> s = np.str_("abc\x00") >>> s 'abc'
Unlike the builtin

*str*, this supports the[Buffer Protocol](https://docs.python.org/3/c-api/buffer.html#bufferobjects), exposing its contents as UCS4:>>> m = memoryview(np.str_("abc")) >>> m.format '3w' >>> m.tobytes() b'a\x00\x00\x00b\x00\x00\x00c\x00\x00\x00'
Character code:
-
`'U'`
Alias:
-
*class*numpy.void(*length_or_data*,*/*,*dtype=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.void)
-
Create a new structured or unstructured void scalar.

Parameters:
-
**length_or_data**int, array-like, bytes-like, object
One of multiple meanings (see notes). The length or bytes data of an unstructured void. Or alternatively, the data to be stored in the new scalar when

is provided. This can be an array-like, in which case an array may be returned.`dtype`
**dtype**dtype, optional
If provided the dtype of the new scalar. This dtype must be “void” dtype (i.e. a structured or unstructured void, see also

[Structured Datatypes](../user/basics.rec.html#defining-structured-types))...versionadded:: 1.24

Notes

For historical reasons and because void scalars can represent both arbitrary byte data and structured dtypes, the void constructor has three calling conventions:

`np.void(5)`
creates a`dtype="V5"`
scalar filled with five`\0`
bytes. The 5 can be a Python or NumPy integer.
`np.void(b"bytes-like")`
creates a void scalar from the byte string. The dtype itemsize will match the byte string length, here`"V10"`
.
When a

`dtype=`
is passed the call is roughly the same as an array creation. However, a void scalar rather than array is returned.
Please see the examples which show all three different conventions.

Examples

>>> np.void(5) void(b'\x00\x00\x00\x00\x00') >>> np.void(b'abcd') void(b'\x61\x62\x63\x64') >>> np.void((5, 3.2, "eggs"), dtype="i,d,S5") (5, 3.2, b'eggs') # looks like a tuple, but is `np.void` >>> np.void(3, dtype=[('x', np.int8), ('y', np.int8)]) (3, 3) # looks like a tuple, but is `np.void`
Character code:
-
`'V'`
Warning

See [Note on string types](arrays.dtypes.html#string-dtype-note).

Numeric Compatibility: If you used old typecode characters in your
Numeric code (which was never recommended), you will need to change
some of them to the new characters. In particular, the needed
changes are `c -> S1`
, `b -> B`
, `1 -> b`
, `s -> h`
, ```
w ->
H
```
, and `u -> I`
. These changes make the type character
convention more consistent with other Python modules such as the
[ struct](https://docs.python.org/3/library/struct.html#module-struct) module.

### Sized aliases[#](#sized-aliases)
Along with their (mostly)
C-derived names, the integer, float, and complex data-types are also
available using a bit-width convention so that an array of the right
size can always be ensured. Two aliases ([ numpy.intp](#numpy.intp) and

[) pointing to the integer type that is sufficiently large to hold a C pointer are also provided.](#numpy.uintp)
`numpy.uintp`
numpy.int8[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.int8)
-
numpy.int16[#](#numpy.int16)
-
numpy.int32[#](#numpy.int32)
-
numpy.int64[#](#numpy.int64)
-
Aliases for the signed integer types (one of

,`numpy.byte`
,`numpy.short`
,`numpy.intc`
and`numpy.int_`
) with the specified number of bits.`numpy.longlong`
Compatible with the C99

`int8_t`
,`int16_t`
,`int32_t`
, and`int64_t`
, respectively.
numpy.uint8[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.uint8)
-
numpy.uint16[#](#numpy.uint16)
-
numpy.uint32[#](#numpy.uint32)
-
numpy.uint64[#](#numpy.uint64)
-
Alias for the unsigned integer types (one of

,`numpy.ubyte`
,`numpy.ushort`
,`numpy.uintc`
and`numpy.uint`
) with the specified number of bits.`numpy.ulonglong`
Compatible with the C99

`uint8_t`
,`uint16_t`
,`uint32_t`
, and`uint64_t`
, respectively.
numpy.intp[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.intp)
-
Alias for the signed integer type (one of

,`numpy.byte`
,`numpy.short`
,`numpy.intc`
and`numpy.int_`
*np.longlong*) that is the same size as a pointer.Compatible with the C

`intptr_t`
.Character code:
-
`'p'`
numpy.uintp[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.uintp)
-
Alias for the unsigned integer type (one of

,`numpy.ubyte`
,`numpy.ushort`
,`numpy.uintc`
and`numpy.uint`
*np.ulonglong*) that is the same size as a pointer.Compatible with the C

`uintptr_t`
.Character code:
-
`'P'`
numpy.float96[#](#numpy.float96)
-
numpy.float128[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.float128)
-
Alias for

, named after its size in bits. The existence of these aliases depends on the platform.`numpy.longdouble`
numpy.complex192[#](#numpy.complex192)
-
numpy.complex256[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.complex256)
-
Alias for

, named after its size in bits. The existence of these aliases depends on the platform.`numpy.clongdouble`
### Other aliases[#](#other-aliases)
The first two of these are conveniences which resemble the names of the
builtin types, in the same style as [ bool_](#numpy.bool_),

[,](#numpy.int_)
`int_`
[,](#numpy.str_)
`str_`
[, and](#numpy.bytes_)
`bytes_`
[:](#numpy.object_)
`object_`
Some more use alternate naming conventions for extended-precision floats and complex numbers:

numpy.longfloat[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.longfloat)
-
alias of

`longdouble`
numpy.longcomplex[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.longcomplex)
-
alias of

`clongdouble`
numpy.clongfloat[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.clongfloat)
-
alias of

`clongdouble`
The following aliases originate from Python 2, and it is recommended that they not be used in new code.

## Attributes[#](#attributes)
The array scalar objects have an [ array priority](arrays.classes.html#numpy.class.__array_priority__) of

[(-1,000,000.0). They also do not (yet) have a](c-api/array.html#c.NPY_SCALAR_PRIORITY)
`NPY_SCALAR_PRIORITY`
[attribute. Otherwise, they share the same attributes as arrays:](generated/numpy.ndarray.ctypes.html#numpy.ndarray.ctypes)
`ctypes`
The integer value of flags.

|
Tuple of array dimensions.

|
Tuple of bytes steps in each dimension.

|
The number of array dimensions.

|
Pointer to start of data.

|
The number of elements in the gentype.

|
The length of one element in bytes.

|
Scalar attribute identical to the corresponding array attribute.

|
Get array data-descriptor.

|
The real part of the scalar.

|
The imaginary part of the scalar.

|
A 1-D view of the scalar.

|
Scalar attribute identical to the corresponding array attribute.

|
Array protocol: Python side

|
Array protocol: struct

|
Array priority.

|
sc.__array_wrap__(obj) return scalar from array

|
## Indexing[#](#indexing)
See also

Array scalars can be indexed like 0-dimensional arrays: if *x* is an
array scalar,

`x[()]`
returns a copy of array scalar
`x[...]`
returns a 0-dimensional`ndarray`
`x['field-name']`
returns the array scalar in the field*field-name*. (*x*can have fields, for example, when it corresponds to a structured data type.)
## Methods[#](#methods)
Array scalars have exactly the same methods as arrays. The default
behavior of these methods is to internally convert the scalar to an
equivalent 0-dimensional array and to call the corresponding array
method. In addition, math operations on array scalars are defined so
that the same hardware flags are set and used to interpret the results
as for [ufunc](ufuncs.html#ufuncs), so that the error state used for ufuncs
also carries over to the math on array scalars.

The exceptions to the above rules are given below:

sc.__array__(dtype) return 0-dim array from scalar with specified dtype

|
sc.__array_wrap__(obj) return scalar from array

|
Scalar method identical to the corresponding array attribute.

|
Scalar method identical to the corresponding array attribute.

|
Helper for pickle.

|
Scalar method identical to the corresponding array attribute.

|
Utility method for typing:

|
Return a parametrized wrapper around the

|
## Defining new types[#](#defining-new-types)
There are two ways to effectively define a new array scalar type
(apart from composing structured types [dtypes](arrays.dtypes.html#arrays-dtypes) from
the built-in scalar types): One way is to simply subclass the
[ ndarray](generated/numpy.ndarray.html#numpy.ndarray) and overwrite the methods of interest. This will work to
a degree, but internally certain behaviors are fixed by the data type of
the array. To fully customize the data type of an array you need to
define a new data-type, and register it with NumPy. Such new types can only
be defined in C, using the

[NumPy C-API](c-api/index.html#c-api).# Universal functions (`ufunc`
)[#](#universal-functions-ufunc)
`ufunc`
See also

A universal function (or [ufunc](../glossary.html#term-ufunc) for short) is a function that
operates on [ ndarrays](generated/numpy.ndarray.html#numpy.ndarray) in an element-by-element fashion,
supporting

[array broadcasting](../user/basics.ufuncs.html#ufuncs-broadcasting),
[type casting](../user/basics.ufuncs.html#ufuncs-casting), and several other standard features. That is, a ufunc is a “
[vectorized](../glossary.html#term-vectorization)” wrapper for a function that takes a fixed number of specific inputs and produces a fixed number of specific outputs. For detailed information on universal functions, see
[Universal functions (ufunc) basics](../user/basics.ufuncs.html#ufuncs-basics).
`ufunc`
[#](#ufunc)
`ufunc`
Functions that operate element by element on whole arrays.

|
### Optional keyword arguments[#](#optional-keyword-arguments)
All ufuncs take optional keyword arguments. Most of these represent advanced usage and will not typically be used.

*out*
New in version 1.6.

The first output can be provided as either a positional or a keyword parameter. Keyword ‘out’ arguments are incompatible with positional ones.

New in version 1.10.

The ‘out’ keyword argument is expected to be a tuple with one entry per output (which can be None for arrays to be allocated by the ufunc). For ufuncs with a single output, passing a single array (instead of a tuple holding a single array) is also valid.

Passing a single array in the ‘out’ keyword argument to a ufunc with multiple outputs is deprecated, and will raise a warning in numpy 1.10, and an error in a future release.

If ‘out’ is None (the default), a uninitialized return array is created. The output array is then filled with the results of the ufunc in the places that the broadcast ‘where’ is True. If ‘where’ is the scalar True (the default), then this corresponds to the entire output being filled. Note that outputs not explicitly filled are left with their uninitialized values.

New in version 1.13.

Operations where ufunc input and output operands have memory overlap are
defined to be the same as for equivalent operations where there
is no memory overlap. Operations affected make temporary copies
as needed to eliminate data dependency. As detecting these cases
is computationally expensive, a heuristic is used, which may in rare
cases result in needless temporary copies. For operations where the
data dependency is simple enough for the heuristic to analyze,
temporary copies will not be made even if the arrays overlap, if it
can be deduced copies are not necessary. As an example,
`np.add(a, b, out=a)`
will not involve copies.

*where*
New in version 1.7.

Accepts a boolean array which is broadcast together with the operands. Values of True indicate to calculate the ufunc at that position, values of False indicate to leave the value in the output alone. This argument cannot be used for generalized ufuncs as those take non-scalar input.

Note that if an uninitialized return array is created, values of False
will leave those values **uninitialized**.

*axes*
New in version 1.15.

A list of tuples with indices of axes a generalized ufunc should operate
on. For instance, for a signature of `(i,j),(j,k)->(i,k)`
appropriate
for matrix multiplication, the base elements are two-dimensional matrices
and these are taken to be stored in the two last axes of each argument.
The corresponding axes keyword would be `[(-2, -1), (-2, -1), (-2, -1)]`
.
For simplicity, for generalized ufuncs that operate on 1-dimensional arrays
(vectors), a single integer is accepted instead of a single-element tuple,
and for generalized ufuncs for which all outputs are scalars, the output
tuples can be omitted.

*axis*
New in version 1.15.

A single axis over which a generalized ufunc should operate. This is a
short-cut for ufuncs that operate over a single, shared core dimension,
equivalent to passing in `axes`
with entries of `(axis,)`
for each
single-core-dimension argument and `()`
for all others. For instance,
for a signature `(i),(i)->()`
, it is equivalent to passing in
`axes=[(axis,), (axis,), ()]`
.

*keepdims*
New in version 1.15.

If this is set to *True*, axes which are reduced over will be left in the
result as a dimension with size one, so that the result will broadcast
correctly against the inputs. This option can only be used for generalized
ufuncs that operate on inputs that all have the same number of core
dimensions and with outputs that have no core dimensions, i.e., with
signatures like `(i),(i)->()`
or `(m,m)->()`
. If used, the location of
the dimensions in the output can be controlled with `axes`
and `axis`
.

*casting*
New in version 1.6.

May be ‘no’, ‘equiv’, ‘safe’, ‘same_kind’, or ‘unsafe’.
See [ can_cast](generated/numpy.can_cast.html#numpy.can_cast) for explanations of the parameter values.

Provides a policy for what kind of casting is permitted. For compatibility with previous versions of NumPy, this defaults to ‘unsafe’ for numpy < 1.7. In numpy 1.7 a transition to ‘same_kind’ was begun where ufuncs produce a DeprecationWarning for calls which are allowed under the ‘unsafe’ rules, but not under the ‘same_kind’ rules. From numpy 1.10 and onwards, the default is ‘same_kind’.

*order*
New in version 1.6.

Specifies the calculation iteration order/memory layout of the output array. Defaults to ‘K’. ‘C’ means the output should be C-contiguous, ‘F’ means F-contiguous, ‘A’ means F-contiguous if the inputs are F-contiguous and not also not C-contiguous, C-contiguous otherwise, and ‘K’ means to match the element ordering of the inputs as closely as possible.

*dtype*
New in version 1.6.

Overrides the DType of the output arrays the same way as the *signature*.
This should ensure a matching precision of the calculation. The exact
calculation DTypes chosen may depend on the ufunc and the inputs may be
cast to this DType to perform the calculation.

*subok*
New in version 1.6.

Defaults to true. If set to false, the output will always be a strict array, not a subtype.

*signature*
Either a Dtype, a tuple of DTypes, or a special signature string indicating the input and output types of a ufunc.

This argument allows the user to specify exact DTypes to be used for the
calculation. Casting will be used as necessary. The actual DType of the
input arrays is not considered unless `signature`
is `None`
for
that array.

When all DTypes are fixed, a specific loop is chosen or an error raised
if no matching loop exists.
If some DTypes are not specified and left `None`
, the behaviour may
depend on the ufunc.
At this time, a list of available signatures is provided by the **types**
attribute of the ufunc. (This list may be missing DTypes not defined
by NumPy.)

The `signature`
only specifies the DType class/type. For example, it
can specify that the operation should be `datetime64`
or `float64`
operation. It does not specify the `datetime64`
time-unit or the
`float64`
byte-order.

For backwards compatibility this argument can also be provided as *sig*,
although the long form is preferred. Note that this should not be
confused with the generalized ufunc [signature](c-api/generalized-ufuncs.html#details-of-signature)
that is stored in the **signature** attribute of the of the ufunc object.

*extobj*
A list of length 3 specifying the ufunc buffer-size, the error mode integer, and the error call-back function. Normally, these values are looked up in a thread-specific dictionary. Passing them here circumvents that look up and uses the low-level specification provided for the error mode. This may be useful, for example, as an optimization for calculations requiring many ufunc calls on small arrays in a loop.

### Attributes[#](#attributes)
There are some informational attributes that universal functions possess. None of the attributes can be set.

|
A docstring for each ufunc. The first part of the docstring is dynamically generated from the number of outputs, the name, and the number of inputs. The second part of the docstring is provided at creation time and stored with the ufunc.

|
|
The name of the ufunc.

|
The number of inputs.

|
The number of outputs.

|
The number of arguments.

|
The number of types.

|
Returns a list with types grouped input->output.

|
The identity value.

|
Definition of the core elements a generalized ufunc operates on.

|
### Methods[#](#methods)
|
Reduces

|
|
Accumulate the result of applying the operator to all elements.

|
|
Performs a (local) reduce with specified slices over a single axis.

|
|
Apply the ufunc

|
|
Performs unbuffered in place operation on operand 'a' for elements specified by 'indices'.

|
Warning

A reduce-like operation on an array with a data-type that has a
range “too small” to handle the result will silently wrap. One
should use [ dtype](generated/numpy.dtype.html#numpy.dtype) to increase the size of the data-type over which
reduction takes place.

## Available ufuncs[#](#available-ufuncs)
There are currently more than 60 universal functions defined in
[ numpy](index.html#module-numpy) on one or more types, covering a wide variety of
operations. Some of these ufuncs are called automatically on arrays
when the relevant infix notation is used (

*e.g.*,
[is called internally when](generated/numpy.add.html#numpy.add)
`add(a, b)`
`a + b`
is written and *a*or
*b*is an
[). Nevertheless, you may still want to use the ufunc call in order to use the optional output argument(s) to place the output(s) in an object (or objects) of your choice.](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
Recall that each ufunc operates element-by-element. Therefore, each scalar ufunc will be described as if acting on a set of scalar inputs to return a set of scalar outputs.

Note

The ufunc still returns its output(s) even if you use the optional output argument(s).

### Math operations[#](#math-operations)
|
Add arguments element-wise.

|
|
Subtract arguments, element-wise.

|
|
Multiply arguments element-wise.

|
|
Matrix product of two arrays.

|
|
Divide arguments element-wise.

|
|
Logarithm of the sum of exponentiations of the inputs.

|
|
Logarithm of the sum of exponentiations of the inputs in base-2.

|
|
Divide arguments element-wise.

|
|
Return the largest integer smaller or equal to the division of the inputs.

|
|
Numerical negative, element-wise.

|
|
Numerical positive, element-wise.

|
|
First array elements raised to powers from second array, element-wise.

|
|
First array elements raised to powers from second array, element-wise.

|
|
Returns the element-wise remainder of division.

|
|
Returns the element-wise remainder of division.

|
|
Returns the element-wise remainder of division.

|
|
Return element-wise quotient and remainder simultaneously.

|
|
Calculate the absolute value element-wise.

|
|
Compute the absolute values element-wise.

|
|
Round elements of the array to the nearest integer.

|
|
Returns an element-wise indication of the sign of a number.

|
|
Compute the Heaviside step function.

|
|
Return the complex conjugate, element-wise.

|
|
Return the complex conjugate, element-wise.

|
|
Calculate the exponential of all elements in the input array.

|
|
Calculate

|
|
Natural logarithm, element-wise.

|
|
Base-2 logarithm of

|
|
Return the base 10 logarithm of the input array, element-wise.

|
|
Calculate

|
|
Return the natural logarithm of one plus the input array, element-wise.

|
|
Return the non-negative square-root of an array, element-wise.

|
|
Return the element-wise square of the input.

|
|
Return the cube-root of an array, element-wise.

|
|
Return the reciprocal of the argument, element-wise.

|
|
Returns the greatest common divisor of

|
|
Returns the lowest common multiple of

|
Tip

The optional output arguments can be used to help you save memory
for large calculations. If your arrays are large, complicated
expressions can take longer than absolutely necessary due to the
creation and (later) destruction of temporary calculation
spaces. For example, the expression `G = A * B + C`
is equivalent to
`T1 = A * B; G = T1 + C; del T1`
. It will be more quickly executed
as `G = A * B; add(G, C, G)`
which is the same as
`G = A * B; G += C`
.

### Trigonometric functions[#](#trigonometric-functions)
All trigonometric functions use radians when an angle is called for. The ratio of degrees to radians is \(180^{\circ}/\pi.\)

|
Trigonometric sine, element-wise.

|
|
Cosine element-wise.

|
|
Compute tangent element-wise.

|
|
Inverse sine, element-wise.

|
|
Trigonometric inverse cosine, element-wise.

|
|
Trigonometric inverse tangent, element-wise.

|
|
Element-wise arc tangent of

|
|
Given the "legs" of a right triangle, return its hypotenuse.

|
|
Hyperbolic sine, element-wise.

|
|
Hyperbolic cosine, element-wise.

|
|
Compute hyperbolic tangent element-wise.

|
|
Inverse hyperbolic sine element-wise.

|
|
Inverse hyperbolic cosine, element-wise.

|
|
Inverse hyperbolic tangent element-wise.

|
|
Convert angles from radians to degrees.

|
|
Convert angles from degrees to radians.

|
|
Convert angles from degrees to radians.

|
|
Convert angles from radians to degrees.

|
### Bit-twiddling functions[#](#bit-twiddling-functions)
These function all require integer arguments and they manipulate the bit-pattern of those arguments.

|
Compute the bit-wise AND of two arrays element-wise.

|
|
Compute the bit-wise OR of two arrays element-wise.

|
|
Compute the bit-wise XOR of two arrays element-wise.

|
|
Compute bit-wise inversion, or bit-wise NOT, element-wise.

|
|
Shift the bits of an integer to the left.

|
|
Shift the bits of an integer to the right.

|
### Comparison functions[#](#comparison-functions)
|
Return the truth value of (x1 > x2) element-wise.

|
|
Return the truth value of (x1 >= x2) element-wise.

|
|
Return the truth value of (x1 < x2) element-wise.

|
|
Return the truth value of (x1 <= x2) element-wise.

|
|
Return (x1 != x2) element-wise.

|
|
Return (x1 == x2) element-wise.

|
Warning

Do not use the Python keywords `and`
and `or`
to combine
logical array expressions. These keywords will test the truth
value of the entire array (not element-by-element as you might
expect). Use the bitwise operators & and | instead.

|
Compute the truth value of x1 AND x2 element-wise.

|
|
Compute the truth value of x1 OR x2 element-wise.

|
|
Compute the truth value of x1 XOR x2, element-wise.

|
|
Compute the truth value of NOT x element-wise.

|
Warning

The bit-wise operators & and | are the proper way to perform
element-by-element array comparisons. Be sure you understand the
operator precedence: `(a > 2) & (a < 5)`
is the proper syntax because
`a > 2 & a < 5`
will result in an error due to the fact that `2 & a`
is evaluated first.

|
Element-wise maximum of array elements.

|
Tip

The Python function `max()`
will find the maximum over a one-dimensional
array, but it will do so using a slower sequence interface. The reduce
method of the maximum ufunc is much faster. Also, the `max()`
method
will not give answers you might expect for arrays with greater than
one dimension. The reduce method of minimum also allows you to compute
a total minimum over an array.

|
Element-wise minimum of array elements.

|
Warning

the behavior of `maximum(a, b)`
is different than that of `max(a, b)`
.
As a ufunc, `maximum(a, b)`
performs an element-by-element comparison
of *a* and *b* and chooses each element of the result according to which
element in the two arrays is larger. In contrast, `max(a, b)`
treats
the objects *a* and *b* as a whole, looks at the (total) truth value of
`a > b`
and uses it to return either *a* or *b* (as a whole). A similar
difference exists between `minimum(a, b)`
and `min(a, b)`
.

|
Element-wise maximum of array elements.

|
|
Element-wise minimum of array elements.

|
### Floating functions[#](#floating-functions)
Recall that all of these functions work element-by-element over an array, returning an array output. The description details only a single operation.

|
Test element-wise for finiteness (not infinity and not Not a Number).

|
|
Test element-wise for positive or negative infinity.

|
|
Test element-wise for NaN and return result as a boolean array.

|
|
Test element-wise for NaT (not a time) and return result as a boolean array.

|
|
Compute the absolute values element-wise.

|
|
Returns element-wise True where signbit is set (less than zero).

|
|
Change the sign of x1 to that of x2, element-wise.

|
|
Return the next floating-point value after x1 towards x2, element-wise.

|
|
Return the distance between x and the nearest adjacent number.

|
|
Return the fractional and integral parts of an array, element-wise.

|
|
Returns x1 * 2**x2, element-wise.

|
|
Decompose the elements of x into mantissa and twos exponent.

|
|
Returns the element-wise remainder of division.

|
|
Return the floor of the input, element-wise.

|
|
Return the ceiling of the input, element-wise.

|
|
Return the truncated value of the input, element-wise.

|# Packaging (`numpy.distutils`
)[#](#module-numpy.distutils)
`numpy.distutils`
Warning

`numpy.distutils`
is deprecated, and will be removed for
Python >= 3.12. For more details, see [Status of numpy.distutils and migration advice](distutils_status_migration.html#distutils-status-migration)
Warning

Note that `setuptools`
does major releases often and those may contain
changes that break `numpy.distutils`
, which will *not* be updated anymore
for new `setuptools`
versions. It is therefore recommended to set an
upper version bound in your build configuration for the last known version
of `setuptools`
that works with your build.

NumPy provides enhanced distutils functionality to make it easier to
build and install sub-packages, auto-generate code, and extension
modules that use Fortran-compiled libraries. To use features of NumPy
distutils, use the `setup`
command from
`numpy.distutils.core`
. A useful [ Configuration](#numpy.distutils.misc_util.Configuration) class is also provided in

[that can make it easier to construct keyword arguments to pass to the setup function (by passing the dictionary obtained from the todict() method of the class). More information is available in the](distutils/misc_util.html#module-numpy.distutils.misc_util)
`numpy.distutils.misc_util`
[NumPy distutils - users guide](distutils_guide.html#distutils-user-guide).
The choice and location of linked libraries such as BLAS and LAPACK as well as
include paths and other such build options can be specified in a `site.cfg`
file located in the NumPy root repository or a `.numpy-site.cfg`
file in your
home directory. See the `site.cfg.example`
example file included in the NumPy
repository or sdist for documentation.

## Modules in `numpy.distutils`
[#](#modules-in-numpy-distutils)
`numpy.distutils`
[distutils.misc_util](distutils/misc_util.html)`all_strings`
`allpath`
`appendpath`
`as_list`
`blue_text`
`cyan_text`
`cyg2win32`
`default_config_dict`
`dict_append`
`dot_join`
`exec_mod_from_location`
`filter_sources`
`generate_config_py`
`get_build_architecture`
`get_cmd`
`get_data_files`
`get_dependencies`
`get_ext_source_files`
`get_frame`
`get_info`
`get_language`
`get_lib_source_files`
`get_mathlibs`
`get_num_build_jobs`
`get_numpy_include_dirs`
`get_pkg_info`
`get_script_files`
`gpaths`
`green_text`
`has_cxx_sources`
`has_f_sources`
`is_local_src_dir`
`is_sequence`
`is_string`
`mingw32`
`minrelpath`
`njoin`
`red_text`
`sanitize_cxx_flags`
`terminal_has_colors`
`yellow_text`
Provides the

|
|
|
exec_command

|
|
|
notfound_action:

|
Returns a list of files named 'fname' from 1) System-wide directory (directory-location of this module) 2) Users HOME directory (os.environ['HOME']) 3) Local directory

|
## Configuration class[#](#configuration-class)
*class*numpy.distutils.misc_util.Configuration(*package_name=None*,*parent_name=None*,*top_path=None*,*package_path=None*,***attrs*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L759-L2128)[#](#numpy.distutils.misc_util.Configuration)
-
Construct a configuration instance for the given package name. If

*parent_name*is not None, then construct the package as a sub-package of the*parent_name*package. If*top_path*and*package_path*are None then they are assumed equal to the path of the file this instance was created in. The setup.py files in the numpy distribution are good examples of how to use theinstance.`Configuration`
todict()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L866-L883)[#](#numpy.distutils.misc_util.Configuration.todict)
-
Return a dictionary compatible with the keyword arguments of distutils setup function.

Examples

>>> setup(**config.todict())
get_subpackage(*subpackage_name*,*subpackage_path=None*,*parent_name=None*,*caller_level=1*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L966-L1025)[#](#numpy.distutils.misc_util.Configuration.get_subpackage)
-
Return list of subpackage configurations.

Parameters:
-
**subpackage_name**str or None
Name of the subpackage to get the configuration. ‘*’ in subpackage_name is handled as a wildcard.

**subpackage_path**str
If None, then the path is assumed to be the local path plus the subpackage_name. If a setup.py file is not found in the subpackage_path, then a default configuration is used.

**parent_name**str
Parent name.

add_subpackage(*subpackage_name*,*subpackage_path=None*,*standalone=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1027-L1068)[#](#numpy.distutils.misc_util.Configuration.add_subpackage)
-
Add a sub-package to the current Configuration instance.

This is useful in a setup.py script for adding sub-packages to a package.

Parameters:
-
**subpackage_name**str
name of the subpackage

**subpackage_path**str
if given, the subpackage path such as the subpackage is in subpackage_path / subpackage_name. If None,the subpackage is assumed to be located in the local path / subpackage_name.

**standalone**bool
add_data_files(**files*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1200-L1349)[#](#numpy.distutils.misc_util.Configuration.add_data_files)
-
Add data files to configuration data_files.

Parameters:
-
**files**sequence
Argument(s) can be either

2-sequence (<datadir prefix>,<path to data file(s)>)

paths to data files where python datadir prefix defaults to package dir.

Notes

The form of each element of the files sequence is very flexible allowing many combinations of where to get the files from the package and where they should ultimately be installed on the system. The most basic usage is for an element of the files argument sequence to be a simple filename. This will cause that file from the local path to be installed to the installation path of the self.name package (package path). The file argument can also be a relative path in which case the entire relative path will be installed into the package directory. Finally, the file can be an absolute path name in which case the file will be found at the absolute path name but installed to the package path.

This basic behavior can be augmented by passing a 2-tuple in as the file argument. The first element of the tuple should specify the relative path (under the package install directory) where the remaining sequence of files should be installed to (it has nothing to do with the file-names in the source distribution). The second element of the tuple is the sequence of files that should be installed. The files in this sequence can be filenames, relative paths, or absolute paths. For absolute paths the file will be installed in the top-level package installation directory (regardless of the first argument). Filenames and relative path names will be installed in the package install directory under the path name given as the first element of the tuple.

Rules for installation paths:

file.txt -> (., file.txt)-> parent/file.txt

foo/file.txt -> (foo, foo/file.txt) -> parent/foo/file.txt

/foo/bar/file.txt -> (., /foo/bar/file.txt) -> parent/file.txt

`*`
.txt -> parent/a.txt, parent/b.txt
foo/

`*`
.txt`` -> parent/foo/a.txt, parent/foo/b.txt
`*/*.txt`
-> (`*`
,`*`
/`*`
.txt) -> parent/c/a.txt, parent/d/b.txt
(sun, file.txt) -> parent/sun/file.txt

(sun, bar/file.txt) -> parent/sun/file.txt

(sun, /foo/bar/file.txt) -> parent/sun/file.txt

(sun,

`*`
.txt) -> parent/sun/a.txt, parent/sun/b.txt
(sun, bar/

`*`
.txt) -> parent/sun/a.txt, parent/sun/b.txt
(sun/

`*`
,`*`
/`*`
.txt) -> parent/sun/c/a.txt, parent/d/b.txt
An additional feature is that the path to a data-file can actually be a function that takes no arguments and returns the actual path(s) to the data-files. This is useful when the data files are generated while building the package.

Examples

Add files to the list of data_files to be included with the package.

>>> self.add_data_files('foo.dat', ... ('fun', ['gun.dat', 'nun/pun.dat', '/tmp/sun.dat']), ... 'bar/cat.dat', ... '/full/path/to/can.dat')
will install these data files to:

<package install directory>/ foo.dat fun/ gun.dat nun/ pun.dat sun.dat bar/ car.dat can.dat
where <package install directory> is the package (or sub-package) directory such as ‘/usr/lib/python2.4/site-packages/mypackage’ (‘C: Python2.4 Lib site-packages mypackage’) or ‘/usr/lib/python2.4/site- packages/mypackage/mysubpackage’ (‘C: Python2.4 Lib site-packages mypackage mysubpackage’).

add_data_dir(*data_path*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1070-L1189)[#](#numpy.distutils.misc_util.Configuration.add_data_dir)
-
Recursively add files under data_path to data_files list.

Recursively add files under data_path to the list of data_files to be installed (and distributed). The data_path can be either a relative path-name, or an absolute path-name, or a 2-tuple where the first argument shows where in the install directory the data directory should be installed to.

Parameters:
-
**data_path**seq or str
Argument can be either

2-sequence (<datadir suffix>, <path to data directory>)

path to data directory where python datadir suffix defaults to package dir.

Notes

Rules for installation paths:

foo/bar -> (foo/bar, foo/bar) -> parent/foo/bar (gun, foo/bar) -> parent/gun foo/* -> (foo/a, foo/a), (foo/b, foo/b) -> parent/foo/a, parent/foo/b (gun, foo/*) -> (gun, foo/a), (gun, foo/b) -> gun (gun/*, foo/*) -> parent/gun/a, parent/gun/b /foo/bar -> (bar, /foo/bar) -> parent/bar (gun, /foo/bar) -> parent/gun (fun/*/gun/*, sun/foo/bar) -> parent/fun/foo/gun/bar
Examples

For example suppose the source directory contains fun/foo.dat and fun/bar/car.dat:

>>> self.add_data_dir('fun') >>> self.add_data_dir(('sun', 'fun')) >>> self.add_data_dir(('gun', '/full/path/to/fun'))
Will install data-files to the locations:

<package install directory>/ fun/ foo.dat bar/ car.dat sun/ foo.dat bar/ car.dat gun/ foo.dat car.dat
add_include_dirs(**paths*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1369-L1383)[#](#numpy.distutils.misc_util.Configuration.add_include_dirs)
-
Add paths to configuration include directories.

Add the given sequence of paths to the beginning of the include_dirs list. This list will be visible to all extension modules of the current package.

add_headers(**files*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1385-L1417)[#](#numpy.distutils.misc_util.Configuration.add_headers)
-
Add installable headers to configuration.

Add the given sequence of files to the beginning of the headers list. By default, headers will be installed under <python- include>/<self.name.replace(‘.’,’/’)>/ directory. If an item of files is a tuple, then its first argument specifies the actual installation location relative to the <python-include> path.

Parameters:
-
**files**str or seq
Argument(s) can be either:

2-sequence (<includedir suffix>,<path to header file(s)>)

path(s) to header file(s) where python includedir suffix will default to package name.

add_extension(*name*,*sources*,***kw*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1442-L1543)[#](#numpy.distutils.misc_util.Configuration.add_extension)
-
Add extension to configuration.

Create and add an Extension instance to the ext_modules list. This method also takes the following optional keyword arguments that are passed on to the Extension constructor.

Parameters:
-
**name**str
name of the extension

**sources**seq
list of the sources. The list of sources may contain functions (called source generators) which must take an extension instance and a build directory as inputs and return a source file or list of source files or None. If None is returned then no sources are generated. If the Extension instance has no sources after processing all source generators, then no extension module is built.

**include_dirs**
**define_macros**
**undef_macros**
**library_dirs**
**libraries**
**runtime_library_dirs**
**extra_objects**
**extra_compile_args**
**extra_link_args**
**extra_f77_compile_args**
**extra_f90_compile_args**
**export_symbols**
**swig_opts**
**depends**
The depends list contains paths to files or directories that the sources of the extension module depend on. If any path in the depends list is newer than the extension module, then the module will be rebuilt.

**language**
**f2py_options**
**module_dirs**
**extra_info**dict or list
dict or list of dict of keywords to be appended to keywords.

Notes

The self.paths(…) method is applied to all lists that may contain paths.

add_library(*name*,*sources*,***build_info*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1545-L1579)[#](#numpy.distutils.misc_util.Configuration.add_library)
-
Add library to configuration.

Parameters:
-
**name**str
Name of the extension.

**sources**sequence
List of the sources. The list of sources may contain functions (called source generators) which must take an extension instance and a build directory as inputs and return a source file or list of source files or None. If None is returned then no sources are generated. If the Extension instance has no sources after processing all source generators, then no extension module is built.

**build_info**dict, optional
The following keys are allowed:

depends

macros

include_dirs

extra_compiler_args

extra_f77_compile_args

extra_f90_compile_args

f2py_options

language

add_scripts(**files*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1755-L1769)[#](#numpy.distutils.misc_util.Configuration.add_scripts)
-
Add scripts to configuration.

Add the sequence of files to the beginning of the scripts list. Scripts will be installed under the <prefix>/bin/ directory.

add_installed_library(*name*,*sources*,*install_dir*,*build_info=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1597-L1646)[#](#numpy.distutils.misc_util.Configuration.add_installed_library)
-
Similar to add_library, but the specified library is installed.

Most C libraries used with

are only used to build python extensions, but libraries built through this method will be installed so that they can be reused by third-party packages.`distutils`
Parameters:
-
**name**str
Name of the installed library.

**sources**sequence
List of the library’s source files. See

for details.`add_library`
**install_dir**str
Path to install the library, relative to the current sub-package.

**build_info**dict, optional
The following keys are allowed:

depends

macros

include_dirs

extra_compiler_args

extra_f77_compile_args

extra_f90_compile_args

f2py_options

language

Returns:
-
None
-
See also

Notes

The best way to encode the options required to link against the specified C libraries is to use a “libname.ini” file, and use

to retrieve the required options (see`get_info`
for more information).`add_npy_pkg_config`
add_npy_pkg_config(*template*,*install_dir*,*subst_dict=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1648-L1752)[#](#numpy.distutils.misc_util.Configuration.add_npy_pkg_config)
-
Generate and install a npy-pkg config file from a template.

The config file generated from

*template*is installed in the given install directory, using*subst_dict*for variable substitution.Parameters:
-
**template**str
The path of the template, relatively to the current package path.

**install_dir**str
Where to install the npy-pkg config file, relatively to the current package path.

**subst_dict**dict, optional
If given, any string of the form

`@key@`
will be replaced by`subst_dict[key]`
in the template file when installed. The install prefix is always available through the variable`@prefix@`
, since the install prefix is not easy to get reliably from setup.py.
See also

Notes

This works for both standard installs and in-place builds, i.e. the

`@prefix@`
refer to the source directory for in-place builds.Examples

config.add_npy_pkg_config('foo.ini.in', 'lib', {'foo': bar})
Assuming the foo.ini.in file has the following content:

[meta] Name=@foo@ Version=1.0 Description=dummy description [default] Cflags=-I@prefix@/include Libs=
The generated file will have the following content:

[meta] Name=bar Version=1.0 Description=dummy description [default] Cflags=-Iprefix_dir/include Libs=
and will be installed as foo.ini in the ‘lib’ subpath.

When cross-compiling with numpy distutils, it might be necessary to use modified npy-pkg-config files. Using the default/generated files will link with the host libraries (i.e. libnpymath.a). For cross-compilation you of-course need to link with target libraries, while using the host Python installation.

You can copy out the numpy/core/lib/npy-pkg-config directory, add a pkgdir value to the .ini files and set NPY_PKG_CONFIG_PATH environment variable to point to the directory with the modified npy-pkg-config files.

Example npymath.ini modified for cross-compilation:

[meta] Name=npymath Description=Portable, core math library implementing C99 standard Version=0.1 [variables] pkgname=numpy.core pkgdir=/build/arm-linux-gnueabi/sysroot/usr/lib/python3.7/site-packages/numpy/core prefix=${pkgdir} libdir=${prefix}/lib includedir=${prefix}/include [default] Libs=-L${libdir} -lnpymath Cflags=-I${includedir} Requires=mlib [msvc] Libs=/LIBPATH:${libdir} npymath.lib Cflags=/INCLUDE:${includedir} Requires=mlib
paths(**paths*,***kws*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1419-L1432)[#](#numpy.distutils.misc_util.Configuration.paths)
-
Apply glob to paths and prepend local_path if needed.

Applies glob.glob(…) to each path in the sequence (if needed) and pre-pends the local_path if needed. Because this is called on all source lists, this allows wildcard characters to be specified in lists of sources for extension modules and libraries and scripts and allows path-names be relative to the source directory.

get_build_temp_dir()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1823-L1830)[#](#numpy.distutils.misc_util.Configuration.get_build_temp_dir)
-
Return a path to a temporary directory where temporary files should be placed.

have_f77c()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1832-L1849)[#](#numpy.distutils.misc_util.Configuration.have_f77c)
-
Check for availability of Fortran 77 compiler.

Use it inside source generating function to ensure that setup distribution instance has been initialized.

Notes

True if a Fortran 77 compiler is available (because a simple Fortran 77 code was able to be compiled successfully).

have_f90c()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1851-L1868)[#](#numpy.distutils.misc_util.Configuration.have_f90c)
-
Check for availability of Fortran 90 compiler.

Use it inside source generating function to ensure that setup distribution instance has been initialized.

Notes

True if a Fortran 90 compiler is available (because a simple Fortran 90 code was able to be compiled successfully)

get_version(*version_file=None*,*version_variable=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L1951-L2025)[#](#numpy.distutils.misc_util.Configuration.get_version)
-
Try to get version string of a package.

Return a version string of the current package or None if the version information could not be detected.

Notes

This method scans files named __version__.py, <packagename>_version.py, version.py, and __svn_version__.py for string variables version, __version__, and <packagename>_version, until a version number is found.

make_svn_version_py(*delete=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2027-L2066)[#](#numpy.distutils.misc_util.Configuration.make_svn_version_py)
-
Appends a data function to the data_files list that will generate __svn_version__.py file to the current package directory.

Generate package __svn_version__.py file from SVN revision number, it will be removed after python exits but will be available when sdist, etc commands are executed.

Notes

If __svn_version__.py existed before, nothing is done.

This is intended for working with source directories that are in an SVN repository.

make_config_py(*name='__config__'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2108-L2116)[#](#numpy.distutils.misc_util.Configuration.make_config_py)
-
Generate package __config__.py file containing system_info information used during building the package.

This file is installed to the package installation directory.

todict()
-
## Building Installable C libraries[#](#building-installable-c-libraries)
Conventional C libraries (installed through *add_library*) are not installed, and
are just used during the build (they are statically linked). An installable C
library is a pure C library, which does not depend on the python C runtime, and
is installed such that it may be used by third-party packages. To build and
install the C library, you just use the method *add_installed_library* instead of
*add_library*, which takes the same arguments except for an additional
`install_dir`
argument:

```
.. hidden in a comment so as to be included in refguide but not rendered documentation
>>> import numpy.distutils.misc_util
>>> config = np.distutils.misc_util.Configuration(None, '', '.')
>>> with open('foo.c', 'w') as f: pass
>>> config.add_installed_library('foo', sources=['foo.c'], install_dir='lib')
```
### npy-pkg-config files[#](#npy-pkg-config-files)
To make the necessary build options available to third parties, you could use
the *npy-pkg-config* mechanism implemented in [ numpy.distutils](#module-numpy.distutils). This mechanism is
based on a .ini file which contains all the options. A .ini file is very
similar to .pc files as used by the pkg-config unix utility:

```
[meta]
Name: foo
Version: 1.0
Description: foo library
[variables]
prefix = /home/user/local
libdir = ${prefix}/lib
includedir = ${prefix}/include
[default]
cflags = -I${includedir}
libs = -L${libdir} -lfoo
```
Generally, the file needs to be generated during the build, since it needs some
information known at build time only (e.g. prefix). This is mostly automatic if
one uses the [ Configuration](#numpy.distutils.misc_util.Configuration) method

*add_npy_pkg_config*. Assuming we have a template file foo.ini.in as follows:
```
[meta]
Name: foo
Version: @version@
Description: foo library
[variables]
prefix = @prefix@
libdir = ${prefix}/lib
includedir = ${prefix}/include
[default]
cflags = -I${includedir}
libs = -L${libdir} -lfoo
```
and the following code in setup.py:

```
>>> config.add_installed_library('foo', sources=['foo.c'], install_dir='lib')
>>> subst = {'version': '1.0'}
>>> config.add_npy_pkg_config('foo.ini.in', 'lib', subst_dict=subst)
```
This will install the file foo.ini into the directory package_dir/lib, and the
foo.ini file will be generated from foo.ini.in, where each `@version@`
will be
replaced by `subst_dict['version']`
. The dictionary has an additional prefix
substitution rule automatically added, which contains the install prefix (since
this is not easy to get from setup.py). npy-pkg-config files can also be
installed at the same location as used for numpy, using the path returned from
`get_npy_pkg_dir`
function.

### Reusing a C library from another package[#](#reusing-a-c-library-from-another-package)
Info are easily retrieved from the [ get_info](distutils/misc_util.html#numpy.distutils.misc_util.get_info) function in

[:](distutils/misc_util.html#module-numpy.distutils.misc_util)
`numpy.distutils.misc_util`
```
>>> info = np.distutils.misc_util.get_info('npymath')
>>> config.add_extension('foo', sources=['foo.c'], extra_info=info)
<numpy.distutils.extension.Extension('foo') at 0x...>
```
An additional list of paths to look for .ini files can be given to [ get_info](distutils/misc_util.html#numpy.distutils.misc_util.get_info).

## Conversion of `.src`
files[#](#conversion-of-src-files)
NumPy distutils supports automatic conversion of source files named
<somefile>.src. This facility can be used to maintain very similar
code blocks requiring only simple changes between blocks. During the
build phase of setup, if a template file named <somefile>.src is
encountered, a new file named <somefile> is constructed from the
template and placed in the build directory to be used instead. Two
forms of template conversion are supported. The first form occurs for
files named <file>.ext.src where ext is a recognized Fortran
extension (f, f90, f95, f77, for, ftn, pyf). The second form is used
for all other cases. See [Conversion of .src files using Templates](distutils_guide.html#templating).# Routines[#](#routines)
In this chapter routine docstrings are presented, grouped by functionality. Many docstrings contain example code, which demonstrates basic usage of the routine. The examples assume that NumPy is imported with:

```
>>> import numpy as np
```
A convenient way to execute examples is the `%doctest_mode`
mode of
IPython, which allows for pasting of multi-line examples and preserves
indentation.

[Array creation routines](routines.array-creation.html)
[Array manipulation routines](routines.array-manipulation.html)
[Binary operations](routines.bitwise.html)
[String operations](routines.char.html)
[C-Types foreign function interface (](routines.ctypeslib.html)`numpy.ctypeslib`
)
[Datetime support functions](routines.datetime.html)
[Data type routines](routines.dtype.html)
[Mathematical functions with automatic domain](routines.emath.html)
[Floating point error handling](routines.err.html)
[Discrete Fourier Transform (](routines.fft.html)`numpy.fft`
)
[Functional programming](routines.functional.html)
[NumPy-specific help functions](routines.help.html)
[Input and output](routines.io.html)
[Linear algebra (](routines.linalg.html)`numpy.linalg`
)
[Logic functions](routines.logic.html)
[Masked array operations](routines.ma.html)
[Mathematical functions](routines.math.html)
[Matrix library (](routines.matlib.html)`numpy.matlib`
)
[Miscellaneous routines](routines.other.html)
[Padding Arrays](routines.padding.html)
[Polynomials](routines.polynomials.html)
[Random sampling (](random/index.html)`numpy.random`
)
[Set routines](routines.set.html)
[Sorting, searching, and counting](routines.sort.html)
[Statistics](routines.statistics.html)
[Test Support (](routines.testing.html)`numpy.testing`
)
[Support for testing overrides (](routines.testing.overrides.html)`numpy.testing.overrides`
)
[Window functions](routines.window.html)# Linear algebra (`numpy.linalg`
)[#](#linear-algebra-numpy-linalg)
`numpy.linalg`
The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient
low level implementations of standard linear algebra algorithms. Those
libraries may be provided by NumPy itself using C versions of a subset of their
reference implementations but, when possible, highly optimized libraries that
take advantage of specialized processor functionality are preferred. Examples
of such libraries are [OpenBLAS](https://www.openblas.net/), MKL (TM), and ATLAS. Because those libraries
are multithreaded and processor dependent, environmental variables and external
packages such as [threadpoolctl](https://github.com/joblib/threadpoolctl) may be needed to control the number of threads
or specify the processor architecture.

The SciPy library also contains a [ linalg](https://docs.scipy.org/doc/scipy/reference/linalg.html#module-scipy.linalg) submodule, and there is
overlap in the functionality provided by the SciPy and NumPy submodules. SciPy
contains functions not found in

[, such as functions related to LU decomposition and the Schur decomposition, multiple ways of calculating the pseudoinverse, and matrix transcendentals such as the matrix logarithm. Some functions that exist in both have augmented functionality in](#module-numpy.linalg)
`numpy.linalg`
[. For example,](https://docs.scipy.org/doc/scipy/reference/linalg.html#module-scipy.linalg)
`scipy.linalg`
[can take a second matrix argument for solving generalized eigenvalue problems. Some functions in NumPy, however, have more flexible broadcasting options. For example,](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eig.html#scipy.linalg.eig)
`scipy.linalg.eig`
[can handle “stacked” arrays, while](generated/numpy.linalg.solve.html#numpy.linalg.solve)
`numpy.linalg.solve`
[accepts only a single square array as its first argument.](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve.html#scipy.linalg.solve)
`scipy.linalg.solve`
Note

The term *matrix* as it is used on this page indicates a 2d [ numpy.array](generated/numpy.array.html#numpy.array)
object, and

*not*a
[object. The latter is no longer recommended, even for linear algebra. See](generated/numpy.matrix.html#numpy.matrix)
`numpy.matrix`
[the matrix object documentation](arrays.classes.html#matrix-objects)for more information.
## The `@`
operator[#](#the-operator)
Introduced in NumPy 1.10.0, the `@`
operator is preferable to
other methods when computing the matrix product between 2d arrays. The
[ numpy.matmul](generated/numpy.matmul.html#numpy.matmul) function implements the

`@`
operator.## Matrix and vector products[#](#matrix-and-vector-products)
|
Dot product of two arrays.

|
|
Compute the dot product of two or more arrays in a single function call, while automatically selecting the fastest evaluation order.

|
|
Return the dot product of two vectors.

|
|
Inner product of two arrays.

|
|
Compute the outer product of two vectors.

|
|
Matrix product of two arrays.

|
|
Compute tensor dot product along specified axes.

|
|
Evaluates the Einstein summation convention on the operands.

|
|
Evaluates the lowest cost contraction order for an einsum expression by considering the creation of intermediate arrays.

|
|
Raise a square matrix to the (integer) power

|
|
Kronecker product of two arrays.

|
## Decompositions[#](#decompositions)
Cholesky decomposition.

|
|
Compute the qr factorization of a matrix.

|
|
Singular Value Decomposition.

|
## Matrix eigenvalues[#](#matrix-eigenvalues)
|
Compute the eigenvalues and right eigenvectors of a square array.

|
|
Return the eigenvalues and eigenvectors of a complex Hermitian (conjugate symmetric) or a real symmetric matrix.

|
Compute the eigenvalues of a general matrix.

|
|
Compute the eigenvalues of a complex Hermitian or real symmetric matrix.

|
## Norms and other numbers[#](#norms-and-other-numbers)
|
Matrix or vector norm.

|
|
Compute the condition number of a matrix.

|
|
Compute the determinant of an array.

|
|
Return matrix rank of array using SVD method

|
Compute the sign and (natural) logarithm of the determinant of an array.

|
|
Return the sum along diagonals of the array.

|
## Solving equations and inverting matrices[#](#solving-equations-and-inverting-matrices)
|
Solve a linear matrix equation, or system of linear scalar equations.

|
|
Solve the tensor equation

|
|
Return the least-squares solution to a linear matrix equation.

|
|
Compute the (multiplicative) inverse of a matrix.

|
|
Compute the (Moore-Penrose) pseudo-inverse of a matrix.

|
|
Compute the 'inverse' of an N-dimensional array.

|
## Exceptions[#](#exceptions)
Generic Python-exception-derived object raised by linalg functions.

|
## Linear algebra on several matrices at once[#](#linear-algebra-on-several-matrices-at-once)
New in version 1.8.0.

Several of the linear algebra routines listed above are able to compute results for several matrices at once, if they are stacked into the same array.

This is indicated in the documentation via input parameter
specifications such as `a : (..., M, M) array_like`
. This means that
if for instance given an input array `a.shape == (N, M, M)`
, it is
interpreted as a “stack” of N matrices, each of size M-by-M. Similar
specification applies to return values, for instance the determinant
has `det : (...)`
and will in this case return an array of shape
`det(a).shape == (N,)`
. This generalizes to linear algebra
operations on higher-dimensional arrays: the last 1 or 2 dimensions of
a multidimensional array are interpreted as vectors or matrices, as
appropriate for each operation.# Discrete Fourier Transform (`numpy.fft`
)[#](#discrete-fourier-transform-numpy-fft)
`numpy.fft`
The SciPy module [ scipy.fft](https://docs.scipy.org/doc/scipy/reference/fft.html#module-scipy.fft) is a more comprehensive superset
of

`numpy.fft`
, which includes only a basic set of routines.## Standard FFTs[#](#standard-ffts)
|
Compute the one-dimensional discrete Fourier Transform.

|
|
Compute the one-dimensional inverse discrete Fourier Transform.

|
|
Compute the 2-dimensional discrete Fourier Transform.

|
|
Compute the 2-dimensional inverse discrete Fourier Transform.

|
|
Compute the N-dimensional discrete Fourier Transform.

|
|
Compute the N-dimensional inverse discrete Fourier Transform.

|
## Real FFTs[#](#real-ffts)
|
Compute the one-dimensional discrete Fourier Transform for real input.

|
|
Computes the inverse of

|
|
Compute the 2-dimensional FFT of a real array.

|
|
Computes the inverse of

|
|
Compute the N-dimensional discrete Fourier Transform for real input.

|
|
Computes the inverse of

|
## Hermitian FFTs[#](#hermitian-ffts)
|
Compute the FFT of a signal that has Hermitian symmetry, i.e., a real spectrum.

|
|
Compute the inverse FFT of a signal that has Hermitian symmetry.

|
## Helper routines[#](#helper-routines)
|
Return the Discrete Fourier Transform sample frequencies.

|
|
Return the Discrete Fourier Transform sample frequencies (for usage with rfft, irfft).

|
|
Shift the zero-frequency component to the center of the spectrum.

|
|
The inverse of

|
## Background information[#](#background-information)
Fourier analysis is fundamentally a method for expressing a function as a
sum of periodic components, and for recovering the function from those
components. When both the function and its Fourier transform are
replaced with discretized counterparts, it is called the discrete Fourier
transform (DFT). The DFT has become a mainstay of numerical computing in
part because of a very fast algorithm for computing it, called the Fast
Fourier Transform (FFT), which was known to Gauss (1805) and was brought
to light in its current form by Cooley and Tukey [[CT]](#rfb1dc64dd6a5-ct). Press et al. [[NR]](#rfb1dc64dd6a5-nr)
provide an accessible introduction to Fourier analysis and its
applications.

Because the discrete Fourier transform separates its input into
components that contribute at discrete frequencies, it has a great number
of applications in digital signal processing, e.g., for filtering, and in
this context the discretized input to the transform is customarily
referred to as a *signal*, which exists in the *time domain*. The output
is called a *spectrum* or *transform* and exists in the *frequency
domain*.

## Implementation details[#](#implementation-details)
There are many ways to define the DFT, varying in the sign of the exponent, normalization, etc. In this implementation, the DFT is defined as

The DFT is in general defined for complex inputs and outputs, and a single-frequency component at linear frequency \(f\) is represented by a complex exponential \(a_m = \exp\{2\pi i\,f m\Delta t\}\), where \(\Delta t\) is the sampling interval.

The values in the result follow so-called “standard” order: If ```
A =
fft(a, n)
```
, then `A[0]`
contains the zero-frequency term (the sum of
the signal), which is always purely real for real inputs. Then `A[1:n/2]`
contains the positive-frequency terms, and `A[n/2+1:]`
contains the
negative-frequency terms, in order of decreasingly negative frequency.
For an even number of input points, `A[n/2]`
represents both positive and
negative Nyquist frequency, and is also purely real for real input. For
an odd number of input points, `A[(n-1)/2]`
contains the largest positive
frequency, while `A[(n+1)/2]`
contains the largest negative frequency.
The routine `np.fft.fftfreq(n)`
returns an array giving the frequencies
of corresponding elements in the output. The routine
`np.fft.fftshift(A)`
shifts transforms and their frequencies to put the
zero-frequency components in the middle, and `np.fft.ifftshift(A)`
undoes
that shift.

When the input *a* is a time-domain signal and `A = fft(a)`
, `np.abs(A)`
is its amplitude spectrum and `np.abs(A)**2`
is its power spectrum.
The phase spectrum is obtained by `np.angle(A)`
.

The inverse DFT is defined as

It differs from the forward transform by the sign of the exponential argument and the default normalization by \(1/n\).

## Type Promotion[#](#type-promotion)
[ numpy.fft](#module-numpy.fft) promotes
`float32`
and `complex64`
arrays to `float64`
and
`complex128`
arrays respectively. For an FFT implementation that does not
promote input arrays, see [.](https://docs.scipy.org/doc/scipy/reference/fftpack.html#module-scipy.fftpack)
`scipy.fftpack`
## Normalization[#](#normalization)
The argument `norm`
indicates which direction of the pair of direct/inverse
transforms is scaled and with what normalization factor.
The default normalization (`"backward"`
) has the direct (forward) transforms
unscaled and the inverse (backward) transforms scaled by \(1/n\). It is
possible to obtain unitary transforms by setting the keyword argument `norm`
to `"ortho"`
so that both direct and inverse transforms are scaled by
\(1/\sqrt{n}\). Finally, setting the keyword argument `norm`
to
`"forward"`
has the direct transforms scaled by \(1/n\) and the inverse
transforms unscaled (i.e. exactly opposite to the default `"backward"`
).
*None* is an alias of the default option `"backward"`
for backward
compatibility.

## Real and Hermitian transforms[#](#real-and-hermitian-transforms)
When the input is purely real, its transform is Hermitian, i.e., the
component at frequency \(f_k\) is the complex conjugate of the
component at frequency \(-f_k\), which means that for real
inputs there is no information in the negative frequency components that
is not already available from the positive frequency components.
The family of [ rfft](generated/numpy.fft.rfft.html#numpy.fft.rfft) functions is
designed to operate on real inputs, and exploits this symmetry by
computing only the positive frequency components, up to and including the
Nyquist frequency. Thus,

`n`
input points produce `n/2+1`
complex
output points. The inverses of this family assumes the same symmetry of
its input, and for an output of `n`
points uses `n/2+1`
input points.Correspondingly, when the spectrum is purely real, the signal is
Hermitian. The [ hfft](generated/numpy.fft.hfft.html#numpy.fft.hfft) family of functions exploits this symmetry by
using

`n/2+1`
complex points in the input (time) domain for `n`
real
points in the frequency domain.In higher dimensions, FFTs are used, e.g., for image analysis and filtering. The computational efficiency of the FFT means that it can also be a faster way to compute large convolutions, using the property that a convolution in the time domain is equivalent to a point-by-point multiplication in the frequency domain.

## Higher dimensions[#](#higher-dimensions)
In two dimensions, the DFT is defined as

which extends in the obvious way to higher dimensions, and the inverses in higher dimensions also extend in the same way.

## References[#](#references)
[CT](#id1)]
Cooley, James W., and John W. Tukey, 1965, “An algorithm for the
machine calculation of complex Fourier series,” *Math. Comput.*
19: 297-301.

[NR](#id2)]
Press, W., Teukolsky, S., Vetterline, W.T., and Flannery, B.P.,
2007, *Numerical Recipes: The Art of Scientific Computing*, ch.
12-13. Cambridge Univ. Press, Cambridge, UK.

## Examples[#](#examples)
For examples, see the various functions.# String operations[#](#module-numpy.char)
The [ numpy.char](#module-numpy.char) module provides a set of vectorized string
operations for arrays of type

[or](arrays.scalars.html#numpy.str_)
`numpy.str_`
[. For example](arrays.scalars.html#numpy.bytes_)
`numpy.bytes_`
```
>>> np.char.capitalize(["python", "numpy"])
array(['Python', 'Numpy'], dtype='<U6')
>>> np.char.add(["num", "doc"], ["py", "umentation"])
array(['numpy', 'documentation'], dtype='<U13')
```
The methods in this module are based on the methods in `String`

## String operations[#](#id1)
|
Return element-wise string concatenation for two arrays of str or unicode.

|
|
Return (a * i), that is string multiple concatenation, element-wise.

|
|
Return (a % i), that is pre-Python 2.6 string formatting (interpolation), element-wise for a pair of array_likes of str or unicode.

|
|
Return a copy of

|
|
Return a copy of

|
|
Calls

|
|
Calls

|
|
Return a copy of each string element where all tab characters are replaced by one or more spaces.

|
|
Return a string which is the concatenation of the strings in the sequence

|
|
Return an array with the elements of

|
|
Return an array with the elements converted to lowercase.

|
|
For each element in

|
|
Partition each element in

|
|
For each element in

|
|
Return an array with the elements of

|
|
Partition (split) each element around the right-most separator.

|
|
For each element in

|
|
For each element in

|
|
For each element in

|
|
For each element in

|
|
For each element in

|
|
Return element-wise a copy of the string with uppercase characters converted to lowercase and vice versa.

|
|
Return element-wise title cased version of string or unicode.

|
|
For each element in

|
|
Return an array with the elements converted to uppercase.

|
|
Return the numeric string left-filled with zeros

|
## Comparison[#](#comparison)
Unlike the standard numpy comparison operators, the ones in the *char*
module strip trailing whitespace characters before performing the
comparison.

|
Return (x1 == x2) element-wise.

|
|
Return (x1 != x2) element-wise.

|
|
Return (x1 >= x2) element-wise.

|
|
Return (x1 <= x2) element-wise.

|
|
Return (x1 > x2) element-wise.

|
|
Return (x1 < x2) element-wise.

|
|
Performs element-wise comparison of two string arrays using the comparison operator specified by

|
## String information[#](#string-information)
|
Returns an array with the number of non-overlapping occurrences of substring

|
|
Returns a boolean array which is

|
|
For each element, return the lowest index in the string where substring

|
|
Like

ValueError when the substring is not found. |
|
Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise.

|
|
Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.

|
|
For each element, return True if there are only decimal characters in the element.

|
|
Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.

|
|
Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise.

|
|
For each element, return True if there are only numeric characters in the element.

|
|
Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise.

|
|
Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise.

|
|
Return true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise.

|
|
For each element in

|
|
Like

ValueError when the substring sub is not found. |
|
Returns a boolean array which is

|
|
Return len(a) element-wise.

|
## Convenience class[#](#convenience-class)
|
Create a

|
|
Convert the input to a

|
|
Provides a convenient view on arrays of string and unicode values.

|# NumPy security[#](#numpy-security)
Security issues can be reported privately as described in the project README
and when opening a [new issue on the issue tracker](https://github.com/numpy/numpy/issues/new/choose).
The [Python security reporting guidelines](https://www.python.org/dev/security/)
are a good resource and its notes apply also to NumPy.

NumPy’s maintainers are not security experts. However, we are conscientious about security and experts of both the NumPy codebase and how it’s used. Please do notify us before creating security advisories against NumPy as we are happy to prioritize issues or help with assessing the severity of a bug. A security advisory we are not aware of beforehand can lead to a lot of work for all involved parties.

## Advice for using NumPy on untrusted data[#](#advice-for-using-numpy-on-untrusted-data)
A user who can freely execute NumPy (or Python) functions must be considered to have the same privilege as the process/Python interpreter.

That said, NumPy should be generally safe to use on *data* provided by
unprivileged users and read through safe API functions (e.g. loaded from a
text file or `.npy`
file without pickle support).
Malicious *values* or *data sizes* should never lead to privilege escalation.

The following points may be useful or should be noted when working with untrusted data:

Exhausting memory can result in an out-of-memory kill, which is a possible denial of service attack. Possible causes could be:

Functions reading text files, which may require much more memory than the original input file size.

If users can create arbitrarily shaped arrays, NumPy’s broadcasting means that intermediate or result arrays can be much larger than the inputs.

NumPy structured dtypes allow for a large amount of complexity. Fortunately, most code fails gracefully when a structured dtype is provided unexpectedly. However, code should either disallow untrusted users to provide these (e.g. via

`.npy`
files) or carefully check the fields included for nested structured/subarray dtypes.
Passing on user input should generally be considered unsafe (except for the data being read). An example would be

`np.dtype(user_string)`
or`dtype=user_string`
.
The speed of operations can depend on values and memory order can lead to larger temporary memory use and slower execution. This means that operations may be significantly slower or use more memory compared to simple test cases.

When reading data, consider enforcing a specific shape (e.g. one dimensional) or dtype such as

`float64`
,`float32`
, or`int64`
to reduce complexity.
When working with non-trivial untrusted data, it is advisable to sandbox the analysis to guard against potential privilege escalation. This is especially advisable if further libraries based on NumPy are used since these add additional complexity and potential security issues.# numpy.i: a SWIG Interface File for NumPy[#](#numpy-i-a-swig-interface-file-for-numpy)
## Introduction[#](#introduction)
The Simple Wrapper and Interface Generator (or [SWIG](http://www.swig.org)) is a powerful tool for generating wrapper
code for interfacing to a wide variety of scripting languages.
[SWIG](http://www.swig.org) can parse header files, and using only the code prototypes,
create an interface to the target language. But [SWIG](http://www.swig.org) is not
omnipotent. For example, it cannot know from the prototype:

```
double rms(double* seq, int n);
```
what exactly `seq`
is. Is it a single value to be altered in-place?
Is it an array, and if so what is its length? Is it input-only?
Output-only? Input-output? [SWIG](http://www.swig.org) cannot determine these details,
and does not attempt to do so.

If we designed `rms`
, we probably made it a routine that takes an
input-only array of length `n`
of `double`
values called `seq`
and returns the root mean square. The default behavior of [SWIG](http://www.swig.org),
however, will be to create a wrapper function that compiles, but is
nearly impossible to use from the scripting language in the way the C
routine was intended.

For Python, the preferred way of handling contiguous (or technically,
*strided*) blocks of homogeneous data is with NumPy, which provides full
object-oriented access to multidimensial arrays of data. Therefore, the most
logical Python interface for the `rms`
function would be (including doc
string):

```
def rms(seq):
"""
rms: return the root mean square of a sequence
rms(numpy.ndarray) -> double
rms(list) -> double
rms(tuple) -> double
"""
```
where `seq`
would be a NumPy array of `double`
values, and its
length `n`
would be extracted from `seq`
internally before being
passed to the C routine. Even better, since NumPy supports
construction of arrays from arbitrary Python sequences, `seq`
itself could be a nearly arbitrary sequence (so long as each element
can be converted to a `double`
) and the wrapper code would
internally convert it to a NumPy array before extracting its data
and length.

[SWIG](http://www.swig.org) allows these types of conversions to be defined via a
mechanism called *typemaps*. This document provides information on
how to use `numpy.i`
, a [SWIG](http://www.swig.org) interface file that defines a series
of typemaps intended to make the type of array-related conversions
described above relatively simple to implement. For example, suppose
that the `rms`
function prototype defined above was in a header file
named `rms.h`
. To obtain the Python interface discussed above, your
[SWIG](http://www.swig.org) interface file would need the following:
```
%{
#define SWIG_FILE_WITH_INIT
#include "rms.h"
%}
%include "numpy.i"
%init %{
import_array();
%}
%apply (double* IN_ARRAY1, int DIM1) {(double* seq, int n)};
%include "rms.h"
```
Typemaps are keyed off a list of one or more function arguments,
either by type or by type and name. We will refer to such lists as
*signatures*. One of the many typemaps defined by `numpy.i`
is used
above and has the signature `(double* IN_ARRAY1, int DIM1)`
. The
argument names are intended to suggest that the `double*`
argument
is an input array of one dimension and that the `int`
represents the
size of that dimension. This is precisely the pattern in the `rms`
prototype.

Most likely, no actual prototypes to be wrapped will have the argument
names `IN_ARRAY1`
and `DIM1`
. We use the [SWIG](http://www.swig.org) `%apply`
directive to apply the typemap for one-dimensional input arrays of
type `double`
to the actual prototype used by `rms`
. Using
`numpy.i`
effectively, therefore, requires knowing what typemaps are
available and what they do.

A [SWIG](http://www.swig.org) interface file that includes the [SWIG](http://www.swig.org) directives given
above will produce wrapper code that looks something like:

```
1 PyObject *_wrap_rms(PyObject *args) {
2 PyObject *resultobj = 0;
3 double *arg1 = (double *) 0 ;
4 int arg2 ;
5 double result;
6 PyArrayObject *array1 = NULL ;
7 int is_new_object1 = 0 ;
8 PyObject * obj0 = 0 ;
9
10 if (!PyArg_ParseTuple(args,(char *)"O:rms",&obj0)) SWIG_fail;
11 {
12 array1 = obj_to_array_contiguous_allow_conversion(
13 obj0, NPY_DOUBLE, &is_new_object1);
14 npy_intp size[1] = {
15 -1
16 };
17 if (!array1 || !require_dimensions(array1, 1) ||
18 !require_size(array1, size, 1)) SWIG_fail;
19 arg1 = (double*) array1->data;
20 arg2 = (int) array1->dimensions[0];
21 }
22 result = (double)rms(arg1,arg2);
23 resultobj = SWIG_From_double((double)(result));
24 {
25 if (is_new_object1 && array1) Py_DECREF(array1);
26 }
27 return resultobj;
28 fail:
29 {
30 if (is_new_object1 && array1) Py_DECREF(array1);
31 }
32 return NULL;
33 }
```
The typemaps from `numpy.i`
are responsible for the following lines
of code: 12–20, 25 and 30. Line 10 parses the input to the `rms`
function. From the format string `"O:rms"`
, we can see that the
argument list is expected to be a single Python object (specified
by the `O`
before the colon) and whose pointer is stored in
`obj0`
. A number of functions, supplied by `numpy.i`
, are called
to make and check the (possible) conversion from a generic Python
object to a NumPy array. These functions are explained in the
section [Helper Functions](#helper-functions), but hopefully their names are
self-explanatory. At line 12 we use `obj0`
to construct a NumPy
array. At line 17, we check the validity of the result: that it is
non-null and that it has a single dimension of arbitrary length. Once
these states are verified, we extract the data buffer and length in
lines 19 and 20 so that we can call the underlying C function at line
22. Line 25 performs memory management for the case where we have
created a new array that is no longer needed.

This code has a significant amount of error handling. Note the
`SWIG_fail`
is a macro for `goto fail`
, referring to the label at
line 28. If the user provides the wrong number of arguments, this
will be caught at line 10. If construction of the NumPy array
fails or produces an array with the wrong number of dimensions, these
errors are caught at line 17. And finally, if an error is detected,
memory is still managed correctly at line 30.

Note that if the C function signature was in a different order:

```
double rms(int n, double* seq);
```
that [SWIG](http://www.swig.org) would not match the typemap signature given above with
the argument list for `rms`
. Fortunately, `numpy.i`
has a set of
typemaps with the data pointer given last:

```
%apply (int DIM1, double* IN_ARRAY1) {(int n, double* seq)};
```
This simply has the effect of switching the definitions of `arg1`
and `arg2`
in lines 3 and 4 of the generated code above, and their
assignments in lines 19 and 20.

## Using numpy.i[#](#using-numpy-i)
The `numpy.i`
file is currently located in the `tools/swig`
sub-directory under the `numpy`
installation directory. Typically,
you will want to copy it to the directory where you are developing
your wrappers.

A simple module that only uses a single [SWIG](http://www.swig.org) interface file should
include the following:

```
%{
#define SWIG_FILE_WITH_INIT
%}
%include "numpy.i"
%init %{
import_array();
%}
```
Within a compiled Python module, `import_array()`
should only get
called once. This could be in a C/C++ file that you have written and
is linked to the module. If this is the case, then none of your
interface files should `#define SWIG_FILE_WITH_INIT`
or call
`import_array()`
. Or, this initialization call could be in a
wrapper file generated by [SWIG](http://www.swig.org) from an interface file that has the
`%init`
block as above. If this is the case, and you have more than
one [SWIG](http://www.swig.org) interface file, then only one interface file should
`#define SWIG_FILE_WITH_INIT`
and call `import_array()`
.

## Available Typemaps[#](#available-typemaps)
The typemap directives provided by `numpy.i`
for arrays of different
data types, say `double`
and `int`
, and dimensions of different
types, say `int`
or `long`
, are identical to one another except
for the C and NumPy type specifications. The typemaps are
therefore implemented (typically behind the scenes) via a macro:

```
%numpy_typemaps(DATA_TYPE, DATA_TYPECODE, DIM_TYPE)
```
that can be invoked for appropriate ```
(DATA_TYPE, DATA_TYPECODE,
DIM_TYPE)
```
triplets. For example:

```
%numpy_typemaps(double, NPY_DOUBLE, int)
%numpy_typemaps(int, NPY_INT , int)
```
The `numpy.i`
interface file uses the `%numpy_typemaps`
macro to
implement typemaps for the following C data types and `int`
dimension types:

-
`signed char`
-
`unsigned char`
-
`short`
-
`unsigned short`
-
`int`
-
`unsigned int`
-
`long`
-
`unsigned long`
-
`long long`
-
`unsigned long long`
-
`float`
-
`double`
In the following descriptions, we reference a generic `DATA_TYPE`
, which
could be any of the C data types listed above, and `DIM_TYPE`
which
should be one of the many types of integers.

The typemap signatures are largely differentiated on the name given to
the buffer pointer. Names with `FARRAY`
are for Fortran-ordered
arrays, and names with `ARRAY`
are for C-ordered (or 1D arrays).

### Input Arrays[#](#input-arrays)
Input arrays are defined as arrays of data that are passed into a routine but are not altered in-place or returned to the user. The Python input array is therefore allowed to be almost any Python sequence (such as a list) that can be converted to the requested type of array. The input array signatures are

1D:

-
`( DATA_TYPE IN_ARRAY1[ANY] )`
-
`( DATA_TYPE* IN_ARRAY1, int DIM1 )`
-
`( int DIM1, DATA_TYPE* IN_ARRAY1 )`
2D:

-
`( DATA_TYPE IN_ARRAY2[ANY][ANY] )`
-
`( DATA_TYPE* IN_ARRAY2, int DIM1, int DIM2 )`
-
`( int DIM1, int DIM2, DATA_TYPE* IN_ARRAY2 )`
-
`( DATA_TYPE* IN_FARRAY2, int DIM1, int DIM2 )`
-
`( int DIM1, int DIM2, DATA_TYPE* IN_FARRAY2 )`
3D:

-
`( DATA_TYPE IN_ARRAY3[ANY][ANY][ANY] )`
-
`( DATA_TYPE* IN_ARRAY3, int DIM1, int DIM2, int DIM3 )`
-
`( int DIM1, int DIM2, int DIM3, DATA_TYPE* IN_ARRAY3 )`
-
`( DATA_TYPE* IN_FARRAY3, int DIM1, int DIM2, int DIM3 )`
-
`( int DIM1, int DIM2, int DIM3, DATA_TYPE* IN_FARRAY3 )`
4D:

-
`(DATA_TYPE IN_ARRAY4[ANY][ANY][ANY][ANY])`
-
`(DATA_TYPE* IN_ARRAY4, DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, DIM_TYPE DIM4)`
-
`(DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, , DIM_TYPE DIM4, DATA_TYPE* IN_ARRAY4)`
-
`(DATA_TYPE* IN_FARRAY4, DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, DIM_TYPE DIM4)`
-
`(DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, DIM_TYPE DIM4, DATA_TYPE* IN_FARRAY4)`
The first signature listed, `( DATA_TYPE IN_ARRAY[ANY] )`
is for
one-dimensional arrays with hard-coded dimensions. Likewise,
`( DATA_TYPE IN_ARRAY2[ANY][ANY] )`
is for two-dimensional arrays
with hard-coded dimensions, and similarly for three-dimensional.

### In-Place Arrays[#](#in-place-arrays)
In-place arrays are defined as arrays that are modified in-place. The input values may or may not be used, but the values at the time the function returns are significant. The provided Python argument must therefore be a NumPy array of the required type. The in-place signatures are

1D:

-
`( DATA_TYPE INPLACE_ARRAY1[ANY] )`
-
`( DATA_TYPE* INPLACE_ARRAY1, int DIM1 )`
-
`( int DIM1, DATA_TYPE* INPLACE_ARRAY1 )`
2D:

-
`( DATA_TYPE INPLACE_ARRAY2[ANY][ANY] )`
-
`( DATA_TYPE* INPLACE_ARRAY2, int DIM1, int DIM2 )`
-
`( int DIM1, int DIM2, DATA_TYPE* INPLACE_ARRAY2 )`
-
`( DATA_TYPE* INPLACE_FARRAY2, int DIM1, int DIM2 )`
-
`( int DIM1, int DIM2, DATA_TYPE* INPLACE_FARRAY2 )`
3D:

-
`( DATA_TYPE INPLACE_ARRAY3[ANY][ANY][ANY] )`
-
`( DATA_TYPE* INPLACE_ARRAY3, int DIM1, int DIM2, int DIM3 )`
-
`( int DIM1, int DIM2, int DIM3, DATA_TYPE* INPLACE_ARRAY3 )`
-
`( DATA_TYPE* INPLACE_FARRAY3, int DIM1, int DIM2, int DIM3 )`
-
`( int DIM1, int DIM2, int DIM3, DATA_TYPE* INPLACE_FARRAY3 )`
4D:

-
`(DATA_TYPE INPLACE_ARRAY4[ANY][ANY][ANY][ANY])`
-
`(DATA_TYPE* INPLACE_ARRAY4, DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, DIM_TYPE DIM4)`
-
`(DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, , DIM_TYPE DIM4, DATA_TYPE* INPLACE_ARRAY4)`
-
`(DATA_TYPE* INPLACE_FARRAY4, DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, DIM_TYPE DIM4)`
-
`(DIM_TYPE DIM1, DIM_TYPE DIM2, DIM_TYPE DIM3, DIM_TYPE DIM4, DATA_TYPE* INPLACE_FARRAY4)`
These typemaps now check to make sure that the `INPLACE_ARRAY`
arguments use native byte ordering. If not, an exception is raised.

There is also a “flat” in-place array for situations in which you would like to modify or process each element, regardless of the number of dimensions. One example is a “quantization” function that quantizes each element of an array in-place, be it 1D, 2D or whatever. This form checks for continuity but allows either C or Fortran ordering.

ND:

-
`(DATA_TYPE* INPLACE_ARRAY_FLAT, DIM_TYPE DIM_FLAT)`
### Argout Arrays[#](#argout-arrays)
Argout arrays are arrays that appear in the input arguments in C, but are in fact output arrays. This pattern occurs often when there is more than one output variable and the single return argument is therefore not sufficient. In Python, the conventional way to return multiple arguments is to pack them into a sequence (tuple, list, etc.) and return the sequence. This is what the argout typemaps do. If a wrapped function that uses these argout typemaps has more than one return argument, they are packed into a tuple or list, depending on the version of Python. The Python user does not pass these arrays in, they simply get returned. For the case where a dimension is specified, the python user must provide that dimension as an argument. The argout signatures are

1D:

-
`( DATA_TYPE ARGOUT_ARRAY1[ANY] )`
-
`( DATA_TYPE* ARGOUT_ARRAY1, int DIM1 )`
-
`( int DIM1, DATA_TYPE* ARGOUT_ARRAY1 )`
2D:

-
`( DATA_TYPE ARGOUT_ARRAY2[ANY][ANY] )`
3D:

-
`( DATA_TYPE ARGOUT_ARRAY3[ANY][ANY][ANY] )`
4D:

-
`( DATA_TYPE ARGOUT_ARRAY4[ANY][ANY][ANY][ANY] )`
These are typically used in situations where in C/C++, you would allocate a(n) array(s) on the heap, and call the function to fill the array(s) values. In Python, the arrays are allocated for you and returned as new array objects.

Note that we support `DATA_TYPE*`
argout typemaps in 1D, but not 2D
or 3D. This is because of a quirk with the [SWIG](http://www.swig.org) typemap syntax and
cannot be avoided. Note that for these types of 1D typemaps, the
Python function will take a single argument representing `DIM1`
.

### Argout View Arrays[#](#argout-view-arrays)
Argoutview arrays are for when your C code provides you with a view of its internal data and does not require any memory to be allocated by the user. This can be dangerous. There is almost no way to guarantee that the internal data from the C code will remain in existence for the entire lifetime of the NumPy array that encapsulates it. If the user destroys the object that provides the view of the data before destroying the NumPy array, then using that array may result in bad memory references or segmentation faults. Nevertheless, there are situations, working with large data sets, where you simply have no other choice.

The C code to be wrapped for argoutview arrays are characterized by pointers: pointers to the dimensions and double pointers to the data, so that these values can be passed back to the user. The argoutview typemap signatures are therefore

1D:

-
`( DATA_TYPE** ARGOUTVIEW_ARRAY1, DIM_TYPE* DIM1 )`
-
`( DIM_TYPE* DIM1, DATA_TYPE** ARGOUTVIEW_ARRAY1 )`
2D:

-
`( DATA_TYPE** ARGOUTVIEW_ARRAY2, DIM_TYPE* DIM1, DIM_TYPE* DIM2 )`
-
`( DIM_TYPE* DIM1, DIM_TYPE* DIM2, DATA_TYPE** ARGOUTVIEW_ARRAY2 )`
-
`( DATA_TYPE** ARGOUTVIEW_FARRAY2, DIM_TYPE* DIM1, DIM_TYPE* DIM2 )`
-
`( DIM_TYPE* DIM1, DIM_TYPE* DIM2, DATA_TYPE** ARGOUTVIEW_FARRAY2 )`
3D:

-
`( DATA_TYPE** ARGOUTVIEW_ARRAY3, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3)`
-
`( DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DATA_TYPE** ARGOUTVIEW_ARRAY3)`
-
`( DATA_TYPE** ARGOUTVIEW_FARRAY3, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3)`
-
`( DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DATA_TYPE** ARGOUTVIEW_FARRAY3)`
4D:

-
`(DATA_TYPE** ARGOUTVIEW_ARRAY4, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4, DATA_TYPE** ARGOUTVIEW_ARRAY4)`
-
`(DATA_TYPE** ARGOUTVIEW_FARRAY4, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4, DATA_TYPE** ARGOUTVIEW_FARRAY4)`
Note that arrays with hard-coded dimensions are not supported. These cannot follow the double pointer signatures of these typemaps.

### Memory Managed Argout View Arrays[#](#memory-managed-argout-view-arrays)
A recent addition to `numpy.i`
are typemaps that permit argout
arrays with views into memory that is managed. See the discussion [here](http://blog.enthought.com/python/numpy-arrays-with-pre-allocated-memory).

1D:

-
`(DATA_TYPE** ARGOUTVIEWM_ARRAY1, DIM_TYPE* DIM1)`
-
`(DIM_TYPE* DIM1, DATA_TYPE** ARGOUTVIEWM_ARRAY1)`
2D:

-
`(DATA_TYPE** ARGOUTVIEWM_ARRAY2, DIM_TYPE* DIM1, DIM_TYPE* DIM2)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DATA_TYPE** ARGOUTVIEWM_ARRAY2)`
-
`(DATA_TYPE** ARGOUTVIEWM_FARRAY2, DIM_TYPE* DIM1, DIM_TYPE* DIM2)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DATA_TYPE** ARGOUTVIEWM_FARRAY2)`
3D:

-
`(DATA_TYPE** ARGOUTVIEWM_ARRAY3, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DATA_TYPE** ARGOUTVIEWM_ARRAY3)`
-
`(DATA_TYPE** ARGOUTVIEWM_FARRAY3, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DATA_TYPE** ARGOUTVIEWM_FARRAY3)`
4D:

-
`(DATA_TYPE** ARGOUTVIEWM_ARRAY4, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4, DATA_TYPE** ARGOUTVIEWM_ARRAY4)`
-
`(DATA_TYPE** ARGOUTVIEWM_FARRAY4, DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4)`
-
`(DIM_TYPE* DIM1, DIM_TYPE* DIM2, DIM_TYPE* DIM3, DIM_TYPE* DIM4, DATA_TYPE** ARGOUTVIEWM_FARRAY4)`
### Output Arrays[#](#output-arrays)
The `numpy.i`
interface file does not support typemaps for output
arrays, for several reasons. First, C/C++ return arguments are
limited to a single value. This prevents obtaining dimension
information in a general way. Second, arrays with hard-coded lengths
are not permitted as return arguments. In other words:

```
double[3] newVector(double x, double y, double z);
```
is not legal C/C++ syntax. Therefore, we cannot provide typemaps of the form:

```
%typemap(out) (TYPE[ANY]);
```
If you run into a situation where a function or method is returning a
pointer to an array, your best bet is to write your own version of the
function to be wrapped, either with `%extend`
for the case of class
methods or `%ignore`
and `%rename`
for the case of functions.

### Other Common Types: bool[#](#other-common-types-bool)
Note that C++ type `bool`
is not supported in the list in the
[Available Typemaps](#available-typemaps) section. NumPy bools are a single byte, while
the C++ `bool`
is four bytes (at least on my system). Therefore:

```
%numpy_typemaps(bool, NPY_BOOL, int)
```
will result in typemaps that will produce code that reference improper data lengths. You can implement the following macro expansion:

```
%numpy_typemaps(bool, NPY_UINT, int)
```
to fix the data length problem, and [Input Arrays](#input-arrays) will work fine,
but [In-Place Arrays](#in-place-arrays) might fail type-checking.

### Other Common Types: complex[#](#other-common-types-complex)
Typemap conversions for complex floating-point types is also not
supported automatically. This is because Python and NumPy are
written in C, which does not have native complex types. Both
Python and NumPy implement their own (essentially equivalent)
`struct`
definitions for complex variables:

```
/* Python */
typedef struct {double real; double imag;} Py_complex;
/* NumPy */
typedef struct {float real, imag;} npy_cfloat;
typedef struct {double real, imag;} npy_cdouble;
```
We could have implemented:

```
%numpy_typemaps(Py_complex , NPY_CDOUBLE, int)
%numpy_typemaps(npy_cfloat , NPY_CFLOAT , int)
%numpy_typemaps(npy_cdouble, NPY_CDOUBLE, int)
```
which would have provided automatic type conversions for arrays of
type `Py_complex`
, `npy_cfloat`
and `npy_cdouble`
. However, it
seemed unlikely that there would be any independent (non-Python,
non-NumPy) application code that people would be using [SWIG](http://www.swig.org) to
generate a Python interface to, that also used these definitions
for complex types. More likely, these application codes will define
their own complex types, or in the case of C++, use `std::complex`
.
Assuming these data structures are compatible with Python and
NumPy complex types, `%numpy_typemap`
expansions as above (with
the user’s complex type substituted for the first argument) should
work.

## NumPy Array Scalars and SWIG[#](#numpy-array-scalars-and-swig)
[SWIG](http://www.swig.org) has sophisticated type checking for numerical types. For
example, if your C/C++ routine expects an integer as input, the code
generated by [SWIG](http://www.swig.org) will check for both Python integers and
Python long integers, and raise an overflow error if the provided
Python integer is too big to cast down to a C integer. With the
introduction of NumPy scalar arrays into your Python code, you
might conceivably extract an integer from a NumPy array and attempt
to pass this to a [SWIG](http://www.swig.org)-wrapped C/C++ function that expects an
`int`
, but the [SWIG](http://www.swig.org) type checking will not recognize the NumPy
array scalar as an integer. (Often, this does in fact work – it
depends on whether NumPy recognizes the integer type you are using
as inheriting from the Python integer type on the platform you are
using. Sometimes, this means that code that works on a 32-bit machine
will fail on a 64-bit machine.)
If you get a Python error that looks like the following:

```
TypeError: in method 'MyClass_MyMethod', argument 2 of type 'int'
```
and the argument you are passing is an integer extracted from a
NumPy array, then you have stumbled upon this problem. The
solution is to modify the [SWIG](http://www.swig.org) type conversion system to accept
NumPy array scalars in addition to the standard integer types.
Fortunately, this capability has been provided for you. Simply copy
the file:

```
pyfragments.swg
```
to the working build directory for you project, and this problem will be fixed. It is suggested that you do this anyway, as it only increases the capabilities of your Python interface.

### Why is There a Second File?[#](#why-is-there-a-second-file)
The [SWIG](http://www.swig.org) type checking and conversion system is a complicated
combination of C macros, [SWIG](http://www.swig.org) macros, [SWIG](http://www.swig.org) typemaps and [SWIG](http://www.swig.org)
fragments. Fragments are a way to conditionally insert code into your
wrapper file if it is needed, and not insert it if not needed. If
multiple typemaps require the same fragment, the fragment only gets
inserted into your wrapper code once.

There is a fragment for converting a Python integer to a C
`long`
. There is a different fragment that converts a Python
integer to a C `int`
, that calls the routine defined in the
`long`
fragment. We can make the changes we want here by changing
the definition for the `long`
fragment. [SWIG](http://www.swig.org) determines the
active definition for a fragment using a “first come, first served”
system. That is, we need to define the fragment for `long`
conversions prior to [SWIG](http://www.swig.org) doing it internally. [SWIG](http://www.swig.org) allows us
to do this by putting our fragment definitions in the file
`pyfragments.swg`
. If we were to put the new fragment definitions
in `numpy.i`
, they would be ignored.

## Helper Functions[#](#helper-functions)
The `numpy.i`
file contains several macros and routines that it
uses internally to build its typemaps. However, these functions may
be useful elsewhere in your interface file. These macros and routines
are implemented as fragments, which are described briefly in the
previous section. If you try to use one or more of the following
macros or functions, but your compiler complains that it does not
recognize the symbol, then you need to force these fragments to appear
in your code using:

```
%fragment("NumPy_Fragments");
```
in your [SWIG](http://www.swig.org) interface file.

### Macros[#](#macros)
is_array(a)
-
Evaluates as true if

`a`
is non-`NULL`
and can be cast to a`PyArrayObject*`
.
array_type(a)
-
Evaluates to the integer data type code of

`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_numdims(a)
-
Evaluates to the integer number of dimensions of

`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_dimensions(a)
-
Evaluates to an array of type

`npy_intp`
and length`array_numdims(a)`
, giving the lengths of all of the dimensions of`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_size(a,i)
-
Evaluates to the

`i`
-th dimension size of`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_strides(a)
-
Evaluates to an array of type

`npy_intp`
and length`array_numdims(a)`
, giving the stridess of all of the dimensions of`a`
, assuming`a`
can be cast to a`PyArrayObject*`
. A stride is the distance in bytes between an element and its immediate neighbor along the same axis.
array_stride(a,i)
-
Evaluates to the

`i`
-th stride of`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_data(a)
-
Evaluates to a pointer of type

`void*`
that points to the data buffer of`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_descr(a)
-
Returns a borrowed reference to the dtype property (

`PyArray_Descr*`
) of`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_flags(a)
-
Returns an integer representing the flags of

`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_enableflags(a,f)
-
Sets the flag represented by

`f`
of`a`
, assuming`a`
can be cast to a`PyArrayObject*`
.
array_is_contiguous(a)
-
Evaluates as true if

`a`
is a contiguous array. Equivalent to`(PyArray_ISCONTIGUOUS(a))`
.
array_is_native(a)
-
Evaluates as true if the data buffer of

`a`
uses native byte order. Equivalent to`(PyArray_ISNOTSWAPPED(a))`
.
array_is_fortran(a)
-
Evaluates as true if

`a`
is FORTRAN ordered.
### Routines[#](#routines)

pytype_string()Return type:

`const char*`
Arguments:

-
`PyObject* py_obj`
, a general Python object.Return a string describing the type of

`py_obj`
.

typecode_string()Return type:

`const char*`
Arguments:

-
`int typecode`
, a NumPy integer typecode.Return a string describing the type corresponding to the NumPy

`typecode`
.

type_match()Return type:

`int`
Arguments:

-
`int actual_type`
, the NumPy typecode of a NumPy array.
-
`int desired_type`
, the desired NumPy typecode.Make sure that

`actual_type`
is compatible with`desired_type`
. For example, this allows character and byte types, or int and long types, to match. This is now equivalent to`PyArray_EquivTypenums()`
.

obj_to_array_no_conversion()Return type:

`PyArrayObject*`
Arguments:

-
`PyObject* input`
, a general Python object.
-
`int typecode`
, the desired NumPy typecode.Cast

`input`
to a`PyArrayObject*`
if legal, and ensure that it is of type`typecode`
. If`input`
cannot be cast, or the`typecode`
is wrong, set a Python error and return`NULL`
.

obj_to_array_allow_conversion()Return type:

`PyArrayObject*`
Arguments:

-
`PyObject* input`
, a general Python object.
-
`int typecode`
, the desired NumPy typecode of the resulting array.
-
`int* is_new_object`
, returns a value of 0 if no conversion performed, else 1.Convert

`input`
to a NumPy array with the given`typecode`
. On success, return a valid`PyArrayObject*`
with the correct type. On failure, the Python error string will be set and the routine returns`NULL`
.

make_contiguous()Return type:

`PyArrayObject*`
Arguments:

-
`PyArrayObject* ary`
, a NumPy array.
-
`int* is_new_object`
, returns a value of 0 if no conversion performed, else 1.
-
`int min_dims`
, minimum allowable dimensions.
-
`int max_dims`
, maximum allowable dimensions.Check to see if

`ary`
is contiguous. If so, return the input pointer and flag it as not a new object. If it is not contiguous, create a new`PyArrayObject*`
using the original data, flag it as a new object and return the pointer.

make_fortran()Return type:

`PyArrayObject*`
Arguments

-
`PyArrayObject* ary`
, a NumPy array.
-
`int* is_new_object`
, returns a value of 0 if no conversion performed, else 1.Check to see if

`ary`
is Fortran contiguous. If so, return the input pointer and flag it as not a new object. If it is not Fortran contiguous, create a new`PyArrayObject*`
using the original data, flag it as a new object and return the pointer.

obj_to_array_contiguous_allow_conversion()Return type:

`PyArrayObject*`
Arguments:

-
`PyObject* input`
, a general Python object.
-
`int typecode`
, the desired NumPy typecode of the resulting array.
-
`int* is_new_object`
, returns a value of 0 if no conversion performed, else 1.Convert

`input`
to a contiguous`PyArrayObject*`
of the specified type. If the input object is not a contiguous`PyArrayObject*`
, a new one will be created and the new object flag will be set.

obj_to_array_fortran_allow_conversion()Return type:

`PyArrayObject*`
Arguments:

-
`PyObject* input`
, a general Python object.
-
`int typecode`
, the desired NumPy typecode of the resulting array.
-
`int* is_new_object`
, returns a value of 0 if no conversion performed, else 1.Convert

`input`
to a Fortran contiguous`PyArrayObject*`
of the specified type. If the input object is not a Fortran contiguous`PyArrayObject*`
, a new one will be created and the new object flag will be set.

require_contiguous()Return type:

`int`
Arguments:

-
`PyArrayObject* ary`
, a NumPy array.Test whether

`ary`
is contiguous. If so, return 1. Otherwise, set a Python error and return 0.

require_native()Return type:

`int`
Arguments:

-
`PyArray_Object* ary`
, a NumPy array.Require that

`ary`
is not byte-swapped. If the array is not byte-swapped, return 1. Otherwise, set a Python error and return 0.

require_dimensions()Return type:

`int`
Arguments:

-
`PyArrayObject* ary`
, a NumPy array.
-
`int exact_dimensions`
, the desired number of dimensions.Require

`ary`
to have a specified number of dimensions. If the array has the specified number of dimensions, return 1. Otherwise, set a Python error and return 0.

require_dimensions_n()Return type:

`int`
Arguments:

-
`PyArrayObject* ary`
, a NumPy array.
-
`int* exact_dimensions`
, an array of integers representing acceptable numbers of dimensions.
-
`int n`
, the length of`exact_dimensions`
.Require

`ary`
to have one of a list of specified number of dimensions. If the array has one of the specified number of dimensions, return 1. Otherwise, set the Python error string and return 0.

require_size()Return type:

`int`
Arguments:

-
`PyArrayObject* ary`
, a NumPy array.
-
`npy_int* size`
, an array representing the desired lengths of each dimension.
-
`int n`
, the length of`size`
.Require

`ary`
to have a specified shape. If the array has the specified shape, return 1. Otherwise, set the Python error string and return 0.

require_fortran()Return type:

`int`
Arguments:

-
`PyArrayObject* ary`
, a NumPy array.Require the given

`PyArrayObject`
to be Fortran ordered. If the`PyArrayObject`
is already Fortran ordered, do nothing. Else, set the Fortran ordering flag and recompute the strides.
## Beyond the Provided Typemaps[#](#beyond-the-provided-typemaps)
There are many C or C++ array/NumPy array situations not covered by
a simple `%include "numpy.i"`
and subsequent `%apply`
directives.

### A Common Example[#](#a-common-example)
Consider a reasonable prototype for a dot product function:

```
double dot(int len, double* vec1, double* vec2);
```
The Python interface that we want is:

```
def dot(vec1, vec2):
"""
dot(PyObject,PyObject) -> double
"""
```
The problem here is that there is one dimension argument and two array
arguments, and our typemaps are set up for dimensions that apply to a
single array (in fact, [SWIG](http://www.swig.org) does not provide a mechanism for
associating `len`
with `vec2`
that takes two Python input
arguments). The recommended solution is the following:

```
%apply (int DIM1, double* IN_ARRAY1) {(int len1, double* vec1),
(int len2, double* vec2)}
%rename (dot) my_dot;
%exception my_dot {
$action
if (PyErr_Occurred()) SWIG_fail;
}
%inline %{
double my_dot(int len1, double* vec1, int len2, double* vec2) {
if (len1 != len2) {
PyErr_Format(PyExc_ValueError,
"Arrays of lengths (%d,%d) given",
len1, len2);
return 0.0;
}
return dot(len1, vec1, vec2);
}
%}
```
If the header file that contains the prototype for `double dot()`
also contains other prototypes that you want to wrap, so that you need
to `%include`
this header file, then you will also need a ```
%ignore
dot;
```
directive, placed after the `%rename`
and before the
`%include`
directives. Or, if the function in question is a class
method, you will want to use `%extend`
rather than `%inline`
in
addition to `%ignore`
.

**A note on error handling:** Note that `my_dot`
returns a
`double`
but that it can also raise a Python error. The
resulting wrapper function will return a Python float
representation of 0.0 when the vector lengths do not match. Since
this is not `NULL`
, the Python interpreter will not know to check
for an error. For this reason, we add the `%exception`
directive
above for `my_dot`
to get the behavior we want (note that
`$action`
is a macro that gets expanded to a valid call to
`my_dot`
). In general, you will probably want to write a [SWIG](http://www.swig.org)
macro to perform this task.
### Other Situations[#](#other-situations)
There are other wrapping situations in which `numpy.i`
may be
helpful when you encounter them.

-
In some situations, it is possible that you could use the

`%numpy_typemaps`
macro to implement typemaps for your own types. See the[Other Common Types: bool]or[Other Common Types: complex]sections for examples. Another situation is if your dimensions are of a type other than`int`
(say`long`
for example):%numpy_typemaps(double, NPY_DOUBLE, long)
-
You can use the code in

`numpy.i`
to write your own typemaps. For example, if you had a five-dimensional array as a function argument, you could cut-and-paste the appropriate four-dimensional typemaps into your interface file. The modifications for the fourth dimension would be trivial.
-
Sometimes, the best approach is to use the

`%extend`
directive to define new methods for your classes (or overload existing ones) that take a`PyObject*`
(that either is or can be converted to a`PyArrayObject*`
) instead of a pointer to a buffer. In this case, the helper routines in`numpy.i`
can be very useful.
-
Writing typemaps can be a bit nonintuitive. If you have specific questions about writing

[SWIG]typemaps for NumPy, the developers of`numpy.i`
do monitor the[Numpy-discussion]and[Swig-user]mail lists.
### A Final Note[#](#a-final-note)
When you use the `%apply`
directive, as is usually necessary to use
`numpy.i`
, it will remain in effect until you tell [SWIG](http://www.swig.org) that it
shouldn’t be. If the arguments to the functions or methods that you
are wrapping have common names, such as `length`
or `vector`
,
these typemaps may get applied in situations you do not expect or
want. Therefore, it is always a good idea to add a `%clear`
directive after you are done with a specific typemap:

```
%apply (double* IN_ARRAY1, int DIM1) {(double* vector, int length)}
%include "my_header.h"
%clear (double* vector, int length);
```
In general, you should target these typemap signatures specifically where you want them, and then clear them after you are done.

## Summary[#](#summary)
Out of the box, `numpy.i`
provides typemaps that support conversion
between NumPy arrays and C arrays:

-
That can be one of 12 different scalar types:

`signed char`
,`unsigned char`
,`short`
,`unsigned short`
,`int`
,`unsigned int`
,`long`
,`unsigned long`
,`long long`
,`unsigned long long`
,`float`
and`double`
.
-
That support 74 different argument signatures for each data type, including:

-
One-dimensional, two-dimensional, three-dimensional and four-dimensional arrays.

-
Input-only, in-place, argout, argoutview, and memory managed argoutview behavior.

-
Hard-coded dimensions, data-buffer-then-dimensions specification, and dimensions-then-data-buffer specification.

-
Both C-ordering (“last dimension fastest”) or Fortran-ordering (“first dimension fastest”) support for 2D, 3D and 4D arrays.

The `numpy.i`
interface file also provides additional tools for
wrapper developers, including:

-
A

[SWIG]macro (`%numpy_typemaps`
) with three arguments for implementing the 74 argument signatures for the user’s choice of (1) C data type, (2) NumPy data type (assuming they match), and (3) dimension type.
-
Fourteen C macros and fifteen C functions that can be used to write specialized typemaps, extensions, or inlined functions that handle cases not covered by the provided typemaps. Note that the macros and functions are coded specifically to work with the NumPy C/API regardless of NumPy version number, both before and after the deprecation of some aspects of the API after version 1.6.# Standard array subclasses[#](#standard-array-subclasses)
Note

Subclassing a `numpy.ndarray`
is possible but if your goal is to create
an array with *modified* behavior, as do dask arrays for distributed
computation and cupy arrays for GPU-based computation, subclassing is
discouraged. Instead, using numpy’s
[dispatch mechanism](../user/basics.dispatch.html#basics-dispatch) is recommended.

The [ ndarray](generated/numpy.ndarray.html#numpy.ndarray) can be inherited from (in Python or in C)
if desired. Therefore, it can form a foundation for many useful
classes. Often whether to sub-class the array object or to simply use
the core array component as an internal part of a new class is a
difficult decision, and can be simply a matter of choice. NumPy has
several tools for simplifying how your new object interacts with other
array objects, and so the choice may not be significant in the
end. One way to simplify the question is by asking yourself if the
object you are interested in can be replaced as a single array or does
it really require two or more arrays at its core.

Note that [ asarray](generated/numpy.asarray.html#numpy.asarray) always returns the base-class ndarray. If
you are confident that your use of the array object can handle any
subclass of an ndarray, then

[can be used to allow subclasses to propagate more cleanly through your subroutine. In principal a subclass could redefine any aspect of the array and therefore, under strict guidelines,](generated/numpy.asanyarray.html#numpy.asanyarray)
`asanyarray`
[would rarely be useful. However, most subclasses of the array object will not redefine certain aspects of the array object such as the buffer interface, or the attributes of the array. One important example, however, of why your subroutine may not be able to handle an arbitrary subclass of an array is that matrices redefine the “*” operator to be matrix-multiplication, rather than element-by-element multiplication.](generated/numpy.asanyarray.html#numpy.asanyarray)
`asanyarray`
## Special attributes and methods[#](#special-attributes-and-methods)
See also

NumPy provides several hooks that classes can customize:

class.__array_ufunc__(*ufunc*,*method*,**inputs*,***kwargs*)[#](#numpy.class.__array_ufunc__)
-
New in version 1.13.

Any class, ndarray subclass or not, can define this method or set it to None in order to override the behavior of NumPy’s ufuncs. This works quite similarly to Python’s

`__mul__`
and other binary operation routines.*ufunc*is the ufunc object that was called.
*method*is a string indicating which Ufunc method was called (one of`"__call__"`
,`"reduce"`
,`"reduceat"`
,`"accumulate"`
,`"outer"`
,`"inner"`
).
*inputs*is a tuple of the input arguments to the`ufunc`
.
*kwargs*is a dictionary containing the optional input arguments of the ufunc. If given, any`out`
arguments, both positional and keyword, are passed as ain`tuple`
*kwargs*. See the discussion in[Universal functions (ufunc)](ufuncs.html#ufuncs)for details.
The method should return either the result of the operation, or

if the operation requested is not implemented.`NotImplemented`
If one of the input, output, or

`where`
arguments has amethod, it is executed`__array_ufunc__`
*instead*of the ufunc. If more than one of the arguments implements, they are tried in the order: subclasses before superclasses, inputs before outputs, outputs before`__array_ufunc__`
`where`
, otherwise left to right. The first routine returning something other thandetermines the result. If all of the`NotImplemented`
operations return`__array_ufunc__`
, a`NotImplemented`
is raised.`TypeError`
Note

We intend to re-implement numpy functions as (generalized) Ufunc, in which case it will become possible for them to be overridden by the

`__array_ufunc__`
method. A prime candidate is, which currently is not a Ufunc, but could be relatively easily be rewritten as a (set of) generalized Ufuncs. The same may happen with functions such as`matmul`
,`median`
, and`amin`
.`argsort`
Like with some other special methods in python, such as

`__hash__`
and`__iter__`
, it is possible to indicate that your class does*not*support ufuncs by setting`__array_ufunc__ = None`
. Ufuncs always raisewhen called on an object that sets`TypeError`
`__array_ufunc__ = None`
.The presence of

also influences how`__array_ufunc__`
handles binary operations like`ndarray`
`arr + obj`
and`arr < obj`
when`arr`
is anand`ndarray`
`obj`
is an instance of a custom class. There are two possibilities. If`obj.__array_ufunc__`
is present and not None, then`ndarray.__add__`
and friends will delegate to the ufunc machinery, meaning that`arr + obj`
becomes`np.add(arr, obj)`
, and theninvokes`add`
`obj.__array_ufunc__`
. This is useful if you want to define an object that acts like an array.Alternatively, if

`obj.__array_ufunc__`
is set to None, then as a special case, special methods like`ndarray.__add__`
will notice this and*unconditionally*raise. This is useful if you want to create objects that interact with arrays via binary operations, but are not themselves arrays. For example, a units handling system might have an object`TypeError`
`m`
representing the “meters” unit, and want to support the syntax`arr * m`
to represent that the array has units of “meters”, but not want to otherwise interact with arrays via ufuncs or otherwise. This can be done by setting`__array_ufunc__ = None`
and defining`__mul__`
and`__rmul__`
methods. (Note that this means that writing an`__array_ufunc__`
that always returnsis not quite the same as setting`NotImplemented`
`__array_ufunc__ = None`
: in the former case,`arr + obj`
will raise, while in the latter case it is possible to define a`TypeError`
`__radd__`
method to prevent this.)The above does not hold for in-place operators, for which

never returns`ndarray`
. Hence,`NotImplemented`
`arr += obj`
would always lead to a. This is because for arrays in-place operations cannot generically be replaced by a simple reverse operation. (For instance, by default,`TypeError`
`arr += obj`
would be translated to`arr = arr + obj`
, i.e.,`arr`
would be replaced, contrary to what is expected for in-place array operations.)Note

If you define

`__array_ufunc__`
:If you are not a subclass of

, we recommend your class define special methods like`ndarray`
`__add__`
and`__lt__`
that delegate to ufuncs just like ndarray does. An easy way to do this is to subclass from.`NDArrayOperatorsMixin`
If you subclass

, we recommend that you put all your override logic in`ndarray`
`__array_ufunc__`
and not also override special methods. This ensures the class hierarchy is determined in only one place rather than separately by the ufunc machinery and by the binary operation rules (which gives preference to special methods of subclasses; the alternative way to enforce a one-place only hierarchy, of settingto None, would seem very unexpected and thus confusing, as then the subclass would not work at all with ufuncs).`__array_ufunc__`
defines its own`ndarray`
, which, evaluates the ufunc if no arguments have overrides, and returns`__array_ufunc__`
otherwise. This may be useful for subclasses for which`NotImplemented`
converts any instances of its own class to`__array_ufunc__`
: it can then pass these on to its superclass using`ndarray`
`super().__array_ufunc__(*inputs, **kwargs)`
, and finally return the results after possible back-conversion. The advantage of this practice is that it ensures that it is possible to have a hierarchy of subclasses that extend the behaviour. See[Subclassing ndarray](../user/basics.subclassing.html#basics-subclassing)for details.
Note

If a class defines the

method, this disables the`__array_ufunc__`
,`__array_wrap__`
,`__array_prepare__`
mechanism described below for ufuncs (which may eventually be deprecated).`__array_priority__`
class.__array_function__(*func*,*types*,*args*,*kwargs*)[#](#numpy.class.__array_function__)
-
New in version 1.16.

`func`
is an arbitrary callable exposed by NumPy’s public API, which was called in the form`func(*args, **kwargs)`
.
`types`
is a collectionof unique argument types from the original NumPy function call that implement`collections.abc.Collection`
`__array_function__`
.
The tuple

`args`
and dict`kwargs`
are directly passed on from the original call.
As a convenience for

`__array_function__`
implementors,`types`
provides all argument types with an`'__array_function__'`
attribute. This allows implementors to quickly identify cases where they should defer to`__array_function__`
implementations on other arguments. Implementations should not rely on the iteration order of`types`
.Most implementations of

`__array_function__`
will start with two checks:Is the given function something that we know how to overload?

Are all arguments of a type that we know how to handle?

If these conditions hold,

`__array_function__`
should return the result from calling its implementation for`func(*args, **kwargs)`
. Otherwise, it should return the sentinel value`NotImplemented`
, indicating that the function is not implemented by these types.There are no general requirements on the return value from

`__array_function__`
, although most sensible implementations should probably return array(s) with the same type as one of the function’s arguments.It may also be convenient to define a custom decorators (

`implements`
below) for registering`__array_function__`
implementations.HANDLED_FUNCTIONS = {} class MyArray: def __array_function__(self, func, types, args, kwargs): if func not in HANDLED_FUNCTIONS: return NotImplemented # Note: this allows subclasses that don't override # __array_function__ to handle MyArray objects if not all(issubclass(t, MyArray) for t in types): return NotImplemented return HANDLED_FUNCTIONS[func](*args, **kwargs) def implements(numpy_function): """Register an __array_function__ implementation for MyArray objects.""" def decorator(func): HANDLED_FUNCTIONS[numpy_function] = func return func return decorator @implements(np.concatenate) def concatenate(arrays, axis=0, out=None): ... # implementation of concatenate for MyArray objects @implements(np.broadcast_to) def broadcast_to(array, shape): ... # implementation of broadcast_to for MyArray objects
Note that it is not required for

`__array_function__`
implementations to include*all*of the corresponding NumPy function’s optional arguments (e.g.,`broadcast_to`
above omits the irrelevant`subok`
argument). Optional arguments are only passed in to`__array_function__`
if they were explicitly used in the NumPy function call.Just like the case for builtin special methods like

`__add__`
, properly written`__array_function__`
methods should always return`NotImplemented`
when an unknown type is encountered. Otherwise, it will be impossible to correctly override NumPy functions from another object if the operation also includes one of your objects.For the most part, the rules for dispatch with

`__array_function__`
match those for`__array_ufunc__`
. In particular:NumPy will gather implementations of

`__array_function__`
from all specified inputs and call them in order: subclasses before superclasses, and otherwise left to right. Note that in some edge cases involving subclasses, this differs slightly from the[current behavior](https://bugs.python.org/issue30140)of Python.
Implementations of

`__array_function__`
indicate that they can handle the operation by returning any value other than`NotImplemented`
.
If all

`__array_function__`
methods return`NotImplemented`
, NumPy will raise`TypeError`
.
If no

`__array_function__`
methods exists, NumPy will default to calling its own implementation, intended for use on NumPy arrays. This case arises, for example, when all array-like arguments are Python numbers or lists. (NumPy arrays do have a`__array_function__`
method, given below, but it always returns`NotImplemented`
if any argument other than a NumPy array subclass implements`__array_function__`
.)One deviation from the current behavior of

`__array_ufunc__`
is that NumPy will only call`__array_function__`
on the*first*argument of each unique type. This matches Python’s[rule for calling reflected methods](https://docs.python.org/3/reference/datamodel.html#object.__ror__), and this ensures that checking overloads has acceptable performance even when there are a large number of overloaded arguments.
class.__array_finalize__(*obj*)[#](#numpy.class.__array_finalize__)
-
This method is called whenever the system internally allocates a new array from

*obj*, where*obj*is a subclass (subtype) of the. It can be used to change attributes of`ndarray`
*self*after construction (so as to ensure a 2-d matrix for example), or to update meta-information from the “parent.” Subclasses inherit a default implementation of this method that does nothing.
class.__array_prepare__(*array*,*context=None*)[#](#numpy.class.__array_prepare__)
-
At the beginning of every

[ufunc](../user/basics.ufuncs.html#ufuncs-output-type), this method is called on the input object with the highest array priority, or the output object if one was specified. The output array is passed in and whatever is returned is passed to the ufunc. Subclasses inherit a default implementation of this method which simply returns the output array unmodified. Subclasses may opt to use this method to transform the output array into an instance of the subclass and update metadata before returning the array to the ufunc for computation.
class.__array_wrap__(*array*,*context=None*)[#](#numpy.class.__array_wrap__)
-
At the end of every

[ufunc](../user/basics.ufuncs.html#ufuncs-output-type), this method is called on the input object with the highest array priority, or the output object if one was specified. The ufunc-computed array is passed in and whatever is returned is passed to the user. Subclasses inherit a default implementation of this method, which transforms the array into a new instance of the object’s class. Subclasses may opt to use this method to transform the output array into an instance of the subclass and update metadata before returning the array to the user.
class.__array_priority__[#](#numpy.class.__array_priority__)
-
The value of this attribute is used to determine what type of object to return in situations where there is more than one possibility for the Python type of the returned object. Subclasses inherit a default value of 0.0 for this attribute.

## Matrix objects[#](#matrix-objects)
Note

It is strongly advised *not* to use the matrix subclass. As described
below, it makes writing functions that deal consistently with matrices
and regular arrays very difficult. Currently, they are mainly used for
interacting with `scipy.sparse`
. We hope to provide an alternative
for this use, however, and eventually remove the `matrix`
subclass.

[ matrix](generated/numpy.matrix.html#numpy.matrix) objects inherit from the ndarray and therefore, they
have the same attributes and methods of ndarrays. There are six
important differences of matrix objects, however, that may lead to
unexpected results when you use matrices but expect them to act like
arrays:
Matrix objects can be created using a string notation to allow Matlab-style syntax where spaces separate columns and semicolons (‘;’) separate rows.

Matrix objects are always two-dimensional. This has far-reaching implications, in that m.ravel() is still two-dimensional (with a 1 in the first dimension) and item selection returns two-dimensional objects so that sequence behavior is fundamentally different than arrays.

Matrix objects over-ride multiplication to be matrix-multiplication.

**Make sure you understand this for functions that you may want to receive matrices. Especially in light of the fact that asanyarray(m) returns a matrix when m is a matrix.**
Matrix objects over-ride power to be matrix raised to a power. The same warning about using power inside a function that uses asanyarray(…) to get an array object holds for this fact.

The default __array_priority__ of matrix objects is 10.0, and therefore mixed operations with ndarrays always produce matrices.

Matrices have special attributes which make calculations easier. These are

Returns the transpose of the matrix.

Returns the (complex) conjugate transpose of

*self*.Returns the (multiplicative) inverse of invertible

*self*.Return

*self*as anobject.`ndarray`
Warning

Matrix objects over-ride multiplication, ‘*’, and power, ‘**’, to be matrix-multiplication and matrix power, respectively. If your subroutine can accept sub-classes and you do not convert to base- class arrays, then you must use the ufuncs multiply and power to be sure that you are performing the correct operation for all inputs.

The matrix class is a Python subclass of the ndarray and can be used
as a reference for how to construct your own subclass of the ndarray.
Matrices can be created from other matrices, strings, and anything
else that can be converted to an `ndarray`
. The name “mat “is an
alias for “matrix “in NumPy.

|
Note

It is no longer recommended to use this class, even for linear

|
|
Interpret the input as a matrix.

|
|
Build a matrix object from a string, nested sequence, or array.

|
Example 1: Matrix creation from a string

```
>>> a = np.mat('1 2 3; 4 5 3')
>>> print((a*a.T).I)
[[ 0.29239766 -0.13450292]
[-0.13450292 0.08187135]]
```
Example 2: Matrix creation from nested sequence

```
>>> np.mat([[1,5,10],[1.0,3,4j]])
matrix([[ 1.+0.j, 5.+0.j, 10.+0.j],
[ 1.+0.j, 3.+0.j, 0.+4.j]])
```
Example 3: Matrix creation from an array

```
>>> np.mat(np.random.rand(3,3)).T
matrix([[4.17022005e-01, 3.02332573e-01, 1.86260211e-01],
[7.20324493e-01, 1.46755891e-01, 3.45560727e-01],
[1.14374817e-04, 9.23385948e-02, 3.96767474e-01]])
```
## Memory-mapped file arrays[#](#memory-mapped-file-arrays)
Memory-mapped files are useful for reading and/or modifying small segments of a large file with regular layout, without reading the entire file into memory. A simple subclass of the ndarray uses a memory-mapped file for the data buffer of the array. For small files, the over-head of reading the entire file into memory is typically not significant, however for large files using memory mapping can save considerable resources.

Memory-mapped-file arrays have one additional method (besides those
they inherit from the ndarray): [ .flush()](generated/numpy.memmap.flush.html#numpy.memmap.flush) which
must be called manually by the user to ensure that any changes to the
array actually get written to disk.

|
Create a memory-map to an array stored in a

|
Write any changes in the array to the file on disk.

|
Example:

```
>>> a = np.memmap('newfile.dat', dtype=float, mode='w+', shape=1000)
>>> a[10] = 10.0
>>> a[30] = 30.0
>>> del a
>>> b = np.fromfile('newfile.dat', dtype=float)
>>> print(b[10], b[30])
10.0 30.0
>>> a = np.memmap('newfile.dat', dtype=float)
>>> print(a[10], a[30])
10.0 30.0
```
## Character arrays (`numpy.char`
)[#](#character-arrays-numpy-char)
`numpy.char`
Note

The [ chararray](generated/numpy.char.chararray.html#numpy.char.chararray) class exists for backwards compatibility with
Numarray, it is not recommended for new development. Starting from numpy
1.4, if one needs arrays of strings, it is recommended to use arrays of

`dtype`
[,](arrays.scalars.html#numpy.object_)
`object_`
[or](arrays.scalars.html#numpy.bytes_)
`bytes_`
[, and use the free functions in the](arrays.scalars.html#numpy.str_)
`str_`
[module for fast vectorized string operations.](routines.char.html#module-numpy.char)
`numpy.char`
These are enhanced arrays of either [ str_](arrays.scalars.html#numpy.str_) type or

[type. These arrays inherit from the](arrays.scalars.html#numpy.bytes_)
`bytes_`
[, but specially-define the operations](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
`+`
, `*`
,
and `%`
on a (broadcasting) element-by-element basis. These
operations are not available on the standard [of character type. In addition, the](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
[has all of the standard](generated/numpy.char.chararray.html#numpy.char.chararray)
`chararray`
[(and](https://docs.python.org/3/library/stdtypes.html#str)
`str`
[) methods, executing them on an element-by-element basis. Perhaps the easiest way to create a chararray is to use](https://docs.python.org/3/library/stdtypes.html#bytes)
`bytes`
[where](generated/numpy.ndarray.view.html#numpy.ndarray.view)
`self.view(chararray)`
*self*is an ndarray of str or unicode data-type. However, a chararray can also be created using the
[constructor, or via the](generated/numpy.char.chararray.html#numpy.char.chararray)
`numpy.chararray`
[function:](generated/numpy.core.defchararray.array.html#numpy.core.defchararray.array)
`numpy.char.array`
|
Provides a convenient view on arrays of string and unicode values.

|
|
Create a

|
Another difference with the standard ndarray of str data-type is that the chararray inherits the feature introduced by Numarray that white-space at the end of any element in the array will be ignored on item retrieval and comparison operations.

## Record arrays (`numpy.rec`
)[#](#record-arrays-numpy-rec)
NumPy provides the [ recarray](generated/numpy.recarray.html#numpy.recarray) class which allows accessing the
fields of a structured array as attributes, and a corresponding
scalar data type object

[.](generated/numpy.record.html#numpy.record)
`record`
|
Construct an ndarray that allows field access using attributes.

|
A data-type scalar that allows field access as attribute lookup.

|
## Masked arrays (`numpy.ma`
)[#](#masked-arrays-numpy-ma)
`numpy.ma`
See also

## Standard container class[#](#standard-container-class)
For backward compatibility and as a standard “container “class, the
UserArray from Numeric has been brought over to NumPy and named
[ numpy.lib.user_array.container](generated/numpy.lib.user_array.container.html#numpy.lib.user_array.container) The container class is a
Python class whose self.array attribute is an ndarray. Multiple
inheritance is probably easier with numpy.lib.user_array.container
than with the ndarray itself and so it is included by default. It is
not documented here beyond mentioning its existence because you are
encouraged to use the ndarray class directly if you can.

|
Standard container-class for easy multiple-inheritance.

|
## Array Iterators[#](#array-iterators)
Iterators are a powerful concept for array processing. Essentially,
iterators implement a generalized for-loop. If *myiter* is an iterator
object, then the Python code:

```
for val in myiter:
...
some code involving val
...
```
calls `val = next(myiter)`
repeatedly until [ StopIteration](https://docs.python.org/3/library/exceptions.html#StopIteration) is
raised by the iterator. There are several ways to iterate over an
array that may be useful: default iteration, flat iteration, and
\(N\)-dimensional enumeration.

### Default iteration[#](#default-iteration)
The default iterator of an ndarray object is the default Python iterator of a sequence type. Thus, when the array object itself is used as an iterator. The default behavior is equivalent to:

```
for i in range(arr.shape[0]):
val = arr[i]
```
This default iterator selects a sub-array of dimension \(N-1\) from the array. This can be a useful construct for defining recursive algorithms. To loop over the entire array requires \(N\) for-loops.

```
>>> a = np.arange(24).reshape(3,2,4)+10
>>> for val in a:
... print('item:', val)
item: [[10 11 12 13]
[14 15 16 17]]
item: [[18 19 20 21]
[22 23 24 25]]
item: [[26 27 28 29]
[30 31 32 33]]
```
### Flat iteration[#](#flat-iteration)
A 1-D iterator over the array.

|
As mentioned previously, the flat attribute of ndarray objects returns an iterator that will cycle over the entire array in C-style contiguous order.

```
>>> for i, val in enumerate(a.flat):
... if i%5 == 0: print(i, val)
0 10
5 15
10 20
15 25
20 30
```
Here, I’ve used the built-in enumerate iterator to return the iterator index as well as the value.

### N-dimensional enumeration[#](#n-dimensional-enumeration)
|
Multidimensional index iterator.

|
Sometimes it may be useful to get the N-dimensional index while iterating. The ndenumerate iterator can achieve this.

```
>>> for i, val in np.ndenumerate(a):
... if sum(i)%5 == 0: print(i, val)
(0, 0, 0) 10
(1, 1, 3) 25
(2, 0, 3) 29
(2, 1, 2) 32
```
### Iterator for broadcasting[#](#iterator-for-broadcasting)
Produce an object that mimics broadcasting.

|
The general concept of broadcasting is also available from Python
using the [ broadcast](generated/numpy.broadcast.html#numpy.broadcast) iterator. This object takes \(N\)
objects as inputs and returns an iterator that returns tuples
providing each of the input sequence elements in the broadcasted
result.

```
>>> for val in np.broadcast([[1,0],[2,3]],[0,1]):
... print(val)
(1, 0)
(0, 1)
(2, 0)
(3, 1)
```# Data Type API[#](#data-type-api)
The standard array can have 24 different data types (and has some support for adding your own types). These data types all have an enumerated type, an enumerated type-character, and a corresponding array scalar Python type object (placed in a hierarchy). There are also standard C typedefs to make it easier to manipulate elements of the given data type. For the numeric types, there are also bit-width equivalent C typedefs and named typenumbers that make it easier to select the precision desired.

Warning

The names for the types in c code follows c naming conventions
more closely. The Python names for these types follow Python
conventions. Thus, [ NPY_FLOAT](#c.NPY_TYPES.NPY_FLOAT) picks up a 32-bit float in
C, but

[in Python corresponds to a 64-bit double. The bit-width names can be used in both Python and C for clarity.](../arrays.scalars.html#numpy.float_)
`numpy.float_`
## Enumerated Types[#](#enumerated-types)
enum NPY_TYPES[#](#c.NPY_TYPES)
-
There is a list of enumerated types defined providing the basic 24 data types plus some useful generic names. Whenever the code requires a type number, one of these enumerated types is requested. The types are all called

`NPY_{NAME}`
:
enumerator NPY_BOOL[#](#c.NPY_TYPES.NPY_BOOL)
-
The enumeration value for the boolean type, stored as one byte. It may only be set to the values 0 and 1.

enumerator NPY_BYTE[#](#c.NPY_TYPES.NPY_BYTE)
-
enumerator NPY_INT8[#](#c.NPY_TYPES.NPY_INT8)
-
The enumeration value for an 8-bit/1-byte signed integer.

enumerator NPY_SHORT[#](#c.NPY_TYPES.NPY_SHORT)
-
enumerator NPY_INT16[#](#c.NPY_TYPES.NPY_INT16)
-
The enumeration value for a 16-bit/2-byte signed integer.

enumerator NPY_INT[#](#c.NPY_TYPES.NPY_INT)
-
enumerator NPY_INT32[#](#c.NPY_TYPES.NPY_INT32)
-
The enumeration value for a 32-bit/4-byte signed integer.

enumerator NPY_LONG[#](#c.NPY_TYPES.NPY_LONG)
-
Equivalent to either NPY_INT or NPY_LONGLONG, depending on the platform.

enumerator NPY_LONGLONG[#](#c.NPY_TYPES.NPY_LONGLONG)
-
enumerator NPY_INT64[#](#c.NPY_TYPES.NPY_INT64)
-
The enumeration value for a 64-bit/8-byte signed integer.

enumerator NPY_UBYTE[#](#c.NPY_TYPES.NPY_UBYTE)
-
enumerator NPY_UINT8[#](#c.NPY_TYPES.NPY_UINT8)
-
The enumeration value for an 8-bit/1-byte unsigned integer.

enumerator NPY_USHORT[#](#c.NPY_TYPES.NPY_USHORT)
-
enumerator NPY_UINT16[#](#c.NPY_TYPES.NPY_UINT16)
-
The enumeration value for a 16-bit/2-byte unsigned integer.

enumerator NPY_UINT[#](#c.NPY_TYPES.NPY_UINT)
-
enumerator NPY_UINT32[#](#c.NPY_TYPES.NPY_UINT32)
-
The enumeration value for a 32-bit/4-byte unsigned integer.

enumerator NPY_ULONG[#](#c.NPY_TYPES.NPY_ULONG)
-
Equivalent to either NPY_UINT or NPY_ULONGLONG, depending on the platform.

enumerator NPY_ULONGLONG[#](#c.NPY_TYPES.NPY_ULONGLONG)
-
enumerator NPY_UINT64[#](#c.NPY_TYPES.NPY_UINT64)
-
The enumeration value for a 64-bit/8-byte unsigned integer.

enumerator NPY_HALF[#](#c.NPY_TYPES.NPY_HALF)
-
enumerator NPY_FLOAT16[#](#c.NPY_TYPES.NPY_FLOAT16)
-
The enumeration value for a 16-bit/2-byte IEEE 754-2008 compatible floating point type.

enumerator NPY_FLOAT[#](#c.NPY_TYPES.NPY_FLOAT)
-
enumerator NPY_FLOAT32[#](#c.NPY_TYPES.NPY_FLOAT32)
-
The enumeration value for a 32-bit/4-byte IEEE 754 compatible floating point type.

enumerator NPY_DOUBLE[#](#c.NPY_TYPES.NPY_DOUBLE)
-
enumerator NPY_FLOAT64[#](#c.NPY_TYPES.NPY_FLOAT64)
-
The enumeration value for a 64-bit/8-byte IEEE 754 compatible floating point type.

enumerator NPY_LONGDOUBLE[#](#c.NPY_TYPES.NPY_LONGDOUBLE)
-
The enumeration value for a platform-specific floating point type which is at least as large as NPY_DOUBLE, but larger on many platforms.

enumerator NPY_CFLOAT[#](#c.NPY_TYPES.NPY_CFLOAT)
-
enumerator NPY_COMPLEX64[#](#c.NPY_TYPES.NPY_COMPLEX64)
-
The enumeration value for a 64-bit/8-byte complex type made up of two NPY_FLOAT values.

enumerator NPY_CDOUBLE[#](#c.NPY_TYPES.NPY_CDOUBLE)
-
enumerator NPY_COMPLEX128[#](#c.NPY_TYPES.NPY_COMPLEX128)
-
The enumeration value for a 128-bit/16-byte complex type made up of two NPY_DOUBLE values.

enumerator NPY_CLONGDOUBLE[#](#c.NPY_TYPES.NPY_CLONGDOUBLE)
-
The enumeration value for a platform-specific complex floating point type which is made up of two NPY_LONGDOUBLE values.

enumerator NPY_DATETIME[#](#c.NPY_TYPES.NPY_DATETIME)
-
The enumeration value for a data type which holds dates or datetimes with a precision based on selectable date or time units.

enumerator NPY_TIMEDELTA[#](#c.NPY_TYPES.NPY_TIMEDELTA)
-
The enumeration value for a data type which holds lengths of times in integers of selectable date or time units.

enumerator NPY_STRING[#](#c.NPY_TYPES.NPY_STRING)
-
The enumeration value for ASCII strings of a selectable size. The strings have a fixed maximum size within a given array.

enumerator NPY_UNICODE[#](#c.NPY_TYPES.NPY_UNICODE)
-
The enumeration value for UCS4 strings of a selectable size. The strings have a fixed maximum size within a given array.

enumerator NPY_OBJECT[#](#c.NPY_TYPES.NPY_OBJECT)
-
The enumeration value for references to arbitrary Python objects.

enumerator NPY_VOID[#](#c.NPY_TYPES.NPY_VOID)
-
Primarily used to hold struct dtypes, but can contain arbitrary binary data.

Some useful aliases of the above types are

enumerator NPY_INTP[#](#c.NPY_TYPES.NPY_INTP)
-
The enumeration value for a signed integer type which is the same size as a (void *) pointer. This is the type used by all arrays of indices.

enumerator NPY_UINTP[#](#c.NPY_TYPES.NPY_UINTP)
-
The enumeration value for an unsigned integer type which is the same size as a (void *) pointer.

enumerator NPY_MASK[#](#c.NPY_TYPES.NPY_MASK)
-
The enumeration value of the type used for masks, such as with the

iterator flag. This is equivalent to`NPY_ITER_ARRAYMASK`
.`NPY_UINT8`
enumerator NPY_DEFAULT_TYPE[#](#c.NPY_TYPES.NPY_DEFAULT_TYPE)
-
The default type to use when no dtype is explicitly specified, for example when calling np.zero(shape). This is equivalent to

.`NPY_DOUBLE`
enumerator NPY_BOOL
-
Other useful related constants are

NPY_NTYPES[#](#c.NPY_NTYPES)
-
The total number of built-in NumPy types. The enumeration covers the range from 0 to NPY_NTYPES-1.

NPY_NOTYPE[#](#c.NPY_NOTYPE)
-
A signal value guaranteed not to be a valid type enumeration number.

NPY_USERDEF[#](#c.NPY_USERDEF)
-
The start of type numbers used for Custom Data types.

The various character codes indicating certain types are also part of
an enumerated list. References to type characters (should they be
needed at all) should always use these enumerations. The form of them
is `NPY_{NAME}LTR`
where `{NAME}`
can be


BOOL,BYTE,UBYTE,SHORT,USHORT,INT,UINT,LONG,ULONG,LONGLONG,ULONGLONG,HALF,FLOAT,DOUBLE,LONGDOUBLE,CFLOAT,CDOUBLE,CLONGDOUBLE,DATETIME,TIMEDELTA,OBJECT,STRING,VOID

INTP,UINTP

GENBOOL,SIGNED,UNSIGNED,FLOATING,COMPLEX
The latter group of `{NAME}s`
corresponds to letters used in the array
interface typestring specification.

## Defines[#](#defines)
### Max and min values for integers[#](#max-and-min-values-for-integers)
`NPY_MAX_INT{bits}`
,`NPY_MAX_UINT{bits}`
,`NPY_MIN_INT{bits}`
These are defined for

`{bits}`
= 8, 16, 32, 64, 128, and 256 and provide the maximum (minimum) value of the corresponding (unsigned) integer type. Note: the actual integer type may not be available on all platforms (i.e. 128-bit and 256-bit integers are rare).
`NPY_MIN_{type}`
This is defined for

`{type}`
=**BYTE**,**SHORT**,**INT**,**LONG**,**LONGLONG**,**INTP**
`NPY_MAX_{type}`
This is defined for all defined for

`{type}`
=**BYTE**,**UBYTE**,**SHORT**,**USHORT**,**INT**,**UINT**,**LONG**,**ULONG**,**LONGLONG**,**ULONGLONG**,**INTP**,**UINTP**
### Number of bits in data types[#](#number-of-bits-in-data-types)
All `NPY_SIZEOF_{CTYPE}`
constants have corresponding
`NPY_BITSOF_{CTYPE}`
constants defined. The `NPY_BITSOF_{CTYPE}`
constants provide the number of bits in the data type. Specifically,
the available `{CTYPE}s`
are


BOOL,CHAR,SHORT,INT,LONG,LONGLONG,FLOAT,DOUBLE,LONGDOUBLE
### Bit-width references to enumerated typenums[#](#bit-width-references-to-enumerated-typenums)
All of the numeric data types (integer, floating point, and complex)
have constants that are defined to be a specific enumerated type
number. Exactly which enumerated type a bit-width type refers to is
platform dependent. In particular, the constants available are
`PyArray_{NAME}{BITS}`
where `{NAME}`
is **INT**, **UINT**,
**FLOAT**, **COMPLEX** and `{BITS}`
can be 8, 16, 32, 64, 80, 96, 128,
160, 192, 256, and 512. Obviously not all bit-widths are available on
all platforms for all the kinds of numeric types. Commonly 8-, 16-,
32-, 64-bit integers; 32-, 64-bit floats; and 64-, 128-bit complex
types are available.

### Integer that can hold a pointer[#](#integer-that-can-hold-a-pointer)
The constants **NPY_INTP** and **NPY_UINTP** refer to an
enumerated integer type that is large enough to hold a pointer on the
platform. Index arrays should always be converted to **NPY_INTP**
, because the dimension of the array is of type npy_intp.

## C-type names[#](#c-type-names)
There are standard variable types for each of the numeric data types and the bool data type. Some of these are already available in the C-specification. You can create variables in extension code with these types.

### Boolean[#](#boolean)
### (Un)Signed Integer[#](#un-signed-integer)
Unsigned versions of the integers can be defined by pre-pending a ‘u’ to the front of the integer name.

type npy_byte[#](#c.npy_byte)
-
char

type npy_ubyte[#](#c.npy_ubyte)
-
unsigned char

type npy_short[#](#c.npy_short)
-
short

type npy_ushort[#](#c.npy_ushort)
-
unsigned short

type npy_int[#](#c.npy_int)
-
int

type npy_uint[#](#c.npy_uint)
-
unsigned int

type npy_int16[#](#c.npy_int16)
-
16-bit integer

type npy_uint16[#](#c.npy_uint16)
-
16-bit unsigned integer

type npy_int32[#](#c.npy_int32)
-
32-bit integer

type npy_uint32[#](#c.npy_uint32)
-
32-bit unsigned integer

type npy_int64[#](#c.npy_int64)
-
64-bit integer

type npy_uint64[#](#c.npy_uint64)
-
64-bit unsigned integer

type npy_long[#](#c.npy_long)
-
long int

type npy_ulong[#](#c.npy_ulong)
-
unsigned long int

type npy_longlong[#](#c.npy_longlong)
-
long long int

type npy_ulonglong[#](#c.npy_ulonglong)
-
unsigned long long int

type npy_intp[#](#c.npy_intp)
-
Py_intptr_t (an integer that is the size of a pointer on the platform).

type npy_uintp[#](#c.npy_uintp)
-
unsigned Py_intptr_t (an integer that is the size of a pointer on the platform).

### (Complex) Floating point[#](#complex-floating-point)
type npy_half[#](#c.npy_half)
-
16-bit float

type npy_float[#](#c.npy_float)
-
32-bit float

type npy_cfloat[#](#c.npy_cfloat)
-
32-bit complex float

type npy_double[#](#c.npy_double)
-
64-bit double

type npy_cdouble[#](#c.npy_cdouble)
-
64-bit complex double

type npy_longdouble[#](#c.npy_longdouble)
-
long double

type npy_clongdouble[#](#c.npy_clongdouble)
-
long complex double

complex types are structures with **.real** and **.imag** members (in
that order).

### Bit-width names[#](#bit-width-names)
There are also typedefs for signed integers, unsigned integers, floating point, and complex floating point types of specific bit- widths. The available type names are


`npy_int{bits}`
,`npy_uint{bits}`
,`npy_float{bits}`
, and`npy_complex{bits}`
where `{bits}`
is the number of bits in the type and can be **8**,
**16**, **32**, **64**, 128, and 256 for integer types; 16, **32**
, **64**, 80, 96, 128, and 256 for floating-point types; and 32,
**64**, **128**, 160, 192, and 512 for complex-valued types. Which
bit-widths are available is platform dependent. The bolded bit-widths
are usually available on all platforms.

## Printf Formatting[#](#printf-formatting)
For help in printing, the following strings are defined as the correct format specifier in printf and related commands.

NPY_LONGLONG_FMT[#](#c.NPY_LONGLONG_FMT)
-
NPY_ULONGLONG_FMT[#](#c.NPY_ULONGLONG_FMT)
-
NPY_INTP_FMT[#](#c.NPY_INTP_FMT)
-
NPY_UINTP_FMT[#](#c.NPY_UINTP_FMT)
-
NPY_LONGDOUBLE_FMT[#](#c.NPY_LONGDOUBLE_FMT)
-# NumPy 1.4.0 Release Notes[#](#numpy-1-4-0-release-notes)
This minor includes numerous bug fixes, as well as a few new features. It is backward compatible with 1.3.0 release.

## Highlights[#](#highlights)
New datetime dtype support to deal with dates in arrays

Faster import time

Extended array wrapping mechanism for ufuncs

New Neighborhood iterator (C-level only)

C99-like complex functions in npymath

## New features[#](#new-features)
### Extended array wrapping mechanism for ufuncs[#](#extended-array-wrapping-mechanism-for-ufuncs)
An __array_prepare__ method has been added to ndarray to provide subclasses
greater flexibility to interact with ufuncs and ufunc-like functions. ndarray
already provided __array_wrap__, which allowed subclasses to set the array type
for the result and populate metadata on the way out of the ufunc (as seen in
the implementation of MaskedArray). For some applications it is necessary to
provide checks and populate metadata *on the way in*. __array_prepare__ is
therefore called just after the ufunc has initialized the output array but
before computing the results and populating it. This way, checks can be made
and errors raised before operations which may modify data in place.

### Automatic detection of forward incompatibilities[#](#automatic-detection-of-forward-incompatibilities)
Previously, if an extension was built against a version N of NumPy, and used on a system with NumPy M < N, the import_array was successful, which could cause crashes because the version M does not have a function in N. Starting from NumPy 1.4.0, this will cause a failure in import_array, so the error will be caught early on.

### New iterators[#](#new-iterators)
A new neighborhood iterator has been added to the C API. It can be used to iterate over the items in a neighborhood of an array, and can handle boundaries conditions automatically. Zero and one padding are available, as well as arbitrary constant value, mirror and circular padding.

### New polynomial support[#](#new-polynomial-support)
New modules chebyshev and polynomial have been added. The new polynomial module
is not compatible with the current polynomial support in numpy, but is much
like the new chebyshev module. The most noticeable difference to most will
be that coefficients are specified from low to high power, that the low
level functions do *not* work with the Chebyshev and Polynomial classes as
arguments, and that the Chebyshev and Polynomial classes include a domain.
Mapping between domains is a linear substitution and the two classes can be
converted one to the other, allowing, for instance, a Chebyshev series in
one domain to be expanded as a polynomial in another domain. The new classes
should generally be used instead of the low level functions, the latter are
provided for those who wish to build their own classes.

The new modules are not automatically imported into the numpy namespace, they must be explicitly brought in with an “import numpy.polynomial” statement.

### New C API[#](#new-c-api)
The following C functions have been added to the C API:

-
PyArray_GetNDArrayCFeatureVersion: return the

APIversion of the loaded numpy.
-
PyArray_Correlate2 - like PyArray_Correlate, but implements the usual definition of correlation. Inputs are not swapped, and conjugate is taken for complex arrays.

-
PyArray_NeighborhoodIterNew - a new iterator to iterate over a neighborhood of a point, with automatic boundaries handling. It is documented in the iterators section of the C-API reference, and you can find some examples in the multiarray_test.c.src file in numpy.core.

### New ufuncs[#](#new-ufuncs)
The following ufuncs have been added to the C API:

-
copysign - return the value of the first argument with the sign copied from the second argument.

-
nextafter - return the next representable floating point value of the first argument toward the second argument.

### New defines[#](#new-defines)
The alpha processor is now defined and available in numpy/npy_cpu.h. The failed detection of the PARISC processor has been fixed. The defines are:

-
NPY_CPU_HPPA: PARISC

-
NPY_CPU_ALPHA: Alpha

### Testing[#](#testing)
-
deprecated decorator: this decorator may be used to avoid cluttering testing output while testing DeprecationWarning is effectively raised by the decorated test.

-
assert_array_almost_equal_nulp: new method to compare two arrays of floating point values. With this function, two values are considered close if there are not many representable floating point values in between, thus being more robust than assert_array_almost_equal when the values fluctuate a lot.

-
assert_array_max_ulp: raise an assertion if there are more than N representable numbers between two floating point values.

-
assert_warns: raise an AssertionError if a callable does not generate a warning of the appropriate class, without altering the warning state.

### Reusing npymath[#](#reusing-npymath)
In 1.3.0, we started putting portable C math routines in npymath library, so that people can use those to write portable extensions. Unfortunately, it was not possible to easily link against this library: in 1.4.0, support has been added to numpy.distutils so that 3rd party can reuse this library. See coremath documentation for more information.

### Improved set operations[#](#improved-set-operations)
In previous versions of NumPy some set functions (intersect1d, setxor1d, setdiff1d and setmember1d) could return incorrect results if the input arrays contained duplicate items. These now work correctly for input arrays with duplicates. setmember1d has been renamed to in1d, as with the change to accept arrays with duplicates it is no longer a set operation, and is conceptually similar to an elementwise version of the Python operator ‘in’. All of these functions now accept the boolean keyword assume_unique. This is False by default, but can be set True if the input arrays are known not to contain duplicates, which can increase the functions’ execution speed.

## Improvements[#](#improvements)
-
numpy import is noticeably faster (from 20 to 30 % depending on the platform and computer)

-
The sort functions now sort nans to the end.

-
Real sort order is [R, nan]

-
Complex sort order is [R + Rj, R + nanj, nan + Rj, nan + nanj]

Complex numbers with the same nan placements are sorted according to the non-nan part if it exists.

-
The type comparison functions have been made consistent with the new sort order of nans. Searchsorted now works with sorted arrays containing nan values.

-
Complex division has been made more resistant to overflow.

-
Complex floor division has been made more resistant to overflow.

## Deprecations[#](#deprecations)
The following functions are deprecated:

-
correlate: it takes a new keyword argument old_behavior. When True (the default), it returns the same result as before. When False, compute the conventional correlation, and take the conjugate for complex arrays. The old behavior will be removed in NumPy 1.5, and raises a DeprecationWarning in 1.4.

-
unique1d: use unique instead. unique1d raises a deprecation warning in 1.4, and will be removed in 1.5.

-
intersect1d_nu: use intersect1d instead. intersect1d_nu raises a deprecation warning in 1.4, and will be removed in 1.5.

-
setmember1d: use in1d instead. setmember1d raises a deprecation warning in 1.4, and will be removed in 1.5.

The following raise errors:

-
When operating on 0-d arrays,

`numpy.max`
and other functions accept only`axis=0`
,`axis=-1`
and`axis=None`
. Using an out-of-bounds axes is an indication of a bug, so Numpy raises an error for these cases now.
-
Specifying

`axis > MAX_DIMS`
is no longer allowed; Numpy raises now an error instead of behaving similarly as for`axis=None`
.
## Internal changes[#](#internal-changes)
### Use C99 complex functions when available[#](#use-c99-complex-functions-when-available)
The numpy complex types are now guaranteed to be ABI compatible with C99 complex type, if available on the platform. Moreover, the complex ufunc now use the platform C99 functions instead of our own.

### split multiarray and umath source code[#](#split-multiarray-and-umath-source-code)
The source code of multiarray and umath has been split into separate logic compilation units. This should make the source code more amenable for newcomers.

### Separate compilation[#](#separate-compilation)
By default, every file of multiarray (and umath) is merged into one for compilation as was the case before, but if NPY_SEPARATE_COMPILATION env variable is set to a non-negative value, experimental individual compilation of each file is enabled. This makes the compile/debug cycle much faster when working on core numpy.

### Separate core math library[#](#separate-core-math-library)
New functions which have been added:

-
npy_copysign

-
npy_nextafter

-
npy_cpack

-
npy_creal

-
npy_cimag

-
npy_cabs

-
npy_cexp

-
npy_clog

-
npy_cpow

-
npy_csqr

-
npy_ccos

-
npy_csin# NumPy 1.20.0 Release Notes[#](#numpy-1-20-0-release-notes)
This NumPy release is the largest so made to date, some 684 PRs contributed by 184 people have been merged. See the list of highlights below for more details. The Python versions supported for this release are 3.7-3.9, support for Python 3.6 has been dropped. Highlights are

Annotations for NumPy functions. This work is ongoing and improvements can be expected pending feedback from users.

Wider use of SIMD to increase execution speed of ufuncs. Much work has been done in introducing universal functions that will ease use of modern features across different hardware platforms. This work is ongoing.

Preliminary work in changing the dtype and casting implementations in order to provide an easier path to extending dtypes. This work is ongoing but enough has been done to allow experimentation and feedback.

Extensive documentation improvements comprising some 185 PR merges. This work is ongoing and part of the larger project to improve NumPy’s online presence and usefulness to new users.

Further cleanups related to removing Python 2.7. This improves code readability and removes technical debt.

Preliminary support for the upcoming Cython 3.0.

## New functions[#](#new-functions)
### The random.Generator class has a new `permuted`
function.[#](#the-random-generator-class-has-a-new-permuted-function)
The new function differs from `shuffle`
and `permutation`
in that the
subarrays indexed by an axis are permuted rather than the axis being treated as
a separate 1-D array for every combination of the other indexes. For example,
it is now possible to permute the rows or columns of a 2-D array.

([gh-15121](https://github.com/numpy/numpy/pull/15121))

`sliding_window_view`
provides a sliding window view for numpy arrays[#](#sliding-window-view-provides-a-sliding-window-view-for-numpy-arrays)
[ numpy.lib.stride_tricks.sliding_window_view](../reference/generated/numpy.lib.stride_tricks.sliding_window_view.html#numpy.lib.stride_tricks.sliding_window_view) constructs views on numpy
arrays that offer a sliding or moving window access to the array. This allows
for the simple implementation of certain algorithms, such as running means.
([gh-17394](https://github.com/numpy/numpy/pull/17394))

`numpy.broadcast_shapes`
is a new user-facing function[#](#numpy-broadcast-shapes-is-a-new-user-facing-function)
`numpy.broadcast_shapes`
[ broadcast_shapes](../reference/generated/numpy.broadcast_shapes.html#numpy.broadcast_shapes) gets the resulting shape from
broadcasting the given shape tuples against each other.
```
>>> np.broadcast_shapes((1, 2), (3, 1))
(3, 2)
>>> np.broadcast_shapes(2, (3, 1))
(3, 2)
>>> np.broadcast_shapes((6, 7), (5, 6, 1), (7,), (5, 1, 7))
(5, 6, 7)
```
([gh-17535](https://github.com/numpy/numpy/pull/17535))

## Deprecations[#](#deprecations)
### Using the aliases of builtin types like `np.int`
is deprecated[#](#using-the-aliases-of-builtin-types-like-np-int-is-deprecated)
For a long time, `np.int`
has been an alias of the builtin `int`
. This is
repeatedly a cause of confusion for newcomers, and existed mainly for historic
reasons.

These aliases have been deprecated. The table below shows the full list of deprecated aliases, along with their exact meaning. Replacing uses of items in the first column with the contents of the second column will work identically and silence the deprecation warning.

The third column lists alternative NumPy names which may occasionally be
preferential. See also [Data types](../user/basics.types.html#basics-types) for additional details.

Deprecated name

|
Identical to

|
NumPy scalar type names

|
---|---|---|
|
|
|
|
`numpy.int64`
, or `numpy.int32`
|
|
|
`numpy.float_`
|
|
|
`numpy.complex_`
|
|
|
|
|
|
|
`long`
),
`numpy.longlong`
|
|
|
To give a clear guideline for the vast majority of cases, for the types
`bool`
, `object`
, `str`
(and `unicode`
) using the plain version
is shorter and clear, and generally a good replacement.
For `float`
and `complex`
you can use `float64`
and `complex128`
if you wish to be more explicit about the precision.

For `np.int`
a direct replacement with `np.int_`
or `int`
is also
good and will not change behavior, but the precision will continue to depend
on the computer and operating system.
If you want to be more explicit and review the current use, you have the
following alternatives:

`np.int64`
or`np.int32`
to specify the precision exactly. This ensures that results cannot depend on the computer or operating system.
`np.int_`
or`int`
(the default), but be aware that it depends on the computer and operating system.
The C types:

`np.cint`
(int),`np.int_`
(long),`np.longlong`
.
`np.intp`
which is 32bit on 32bit machines 64bit on 64bit machines. This can be the best type to use for indexing.
When used with `np.dtype(...)`
or `dtype=...`
changing it to the
NumPy name as mentioned above will have no effect on the output.
If used as a scalar with:

```
np.float(123)
```
changing it can subtly change the result. In this case, the Python version
`float(123)`
or `int(12.)`
is normally preferable, although the NumPy
version may be useful for consistency with NumPy arrays (for example,
NumPy behaves differently for things like division by zero).

([gh-14882](https://github.com/numpy/numpy/pull/14882))

### Passing `shape=None`
to functions with a non-optional shape argument is deprecated[#](#passing-shape-none-to-functions-with-a-non-optional-shape-argument-is-deprecated)
Previously, this was an alias for passing `shape=()`
.
This deprecation is emitted by *PyArray_IntpConverter* in the C API. If your
API is intended to support passing `None`
, then you should check for `None`
prior to invoking the converter, so as to be able to distinguish `None`
and
`()`
.

([gh-15886](https://github.com/numpy/numpy/pull/15886))

### Indexing errors will be reported even when index result is empty[#](#indexing-errors-will-be-reported-even-when-index-result-is-empty)
In the future, NumPy will raise an IndexError when an integer array index contains out of bound values even if a non-indexed dimension is of length 0. This will now emit a DeprecationWarning. This can happen when the array is previously empty, or an empty slice is involved:

```
arr1 = np.zeros((5, 0))
arr1[[20]]
arr2 = np.zeros((5, 5))
arr2[[20], :0]
```
Previously the non-empty index `[20]`
was not checked for correctness.
It will now be checked causing a deprecation warning which will be turned
into an error. This also applies to assignments.

([gh-15900](https://github.com/numpy/numpy/pull/15900))

### Inexact matches for `mode`
and `searchside`
are deprecated[#](#inexact-matches-for-mode-and-searchside-are-deprecated)
Inexact and case insensitive matches for `mode`
and `searchside`
were valid
inputs earlier and will give a DeprecationWarning now. For example, below are
some example usages which are now deprecated and will give a
DeprecationWarning:

```
import numpy as np
arr = np.array([[3, 6, 6], [4, 5, 1]])
# mode: inexact match
np.ravel_multi_index(arr, (7, 6), mode="clap") # should be "clip"
# searchside: inexact match
np.searchsorted(arr[0], 4, side='random') # should be "right"
```
([gh-16056](https://github.com/numpy/numpy/pull/16056))

### Deprecation of *numpy.dual*[#](#deprecation-of-numpy-dual)
The module *numpy.dual* is deprecated. Instead of importing functions
from *numpy.dual*, the functions should be imported directly from NumPy
or SciPy.

([gh-16156](https://github.com/numpy/numpy/pull/16156))

`outer`
and `ufunc.outer`
deprecated for matrix[#](#outer-and-ufunc-outer-deprecated-for-matrix)
`np.matrix`
use with [ outer](../reference/generated/numpy.outer.html#numpy.outer) or generic ufunc outer
calls such as
`numpy.add.outer`
. Previously, matrix was
converted to an array here. This will not be done in the future
requiring a manual conversion to arrays.([gh-16232](https://github.com/numpy/numpy/pull/16232))

### Further Numeric Style types Deprecated[#](#further-numeric-style-types-deprecated)
The remaining numeric-style type codes `Bytes0`
, `Str0`
,
`Uint32`
, `Uint64`
, and `Datetime64`
have been deprecated. The lower-case variants should be used
instead. For bytes and string `"S"`
and `"U"`
are further alternatives.

([gh-16554](https://github.com/numpy/numpy/pull/16554))

### The `ndincr`
method of `ndindex`
is deprecated[#](#the-ndincr-method-of-ndindex-is-deprecated)
The documentation has warned against using this function since NumPy 1.8.
Use `next(it)`
instead of `it.ndincr()`
.

([gh-17233](https://github.com/numpy/numpy/pull/17233))

### ArrayLike objects which do not define `__len__`
and `__getitem__`
[#](#arraylike-objects-which-do-not-define-len-and-getitem)
Objects which define one of the protocols `__array__`
,
`__array_interface__`
, or `__array_struct__`
but are not sequences
(usually defined by having a `__len__`
and `__getitem__`
) will behave
differently during array-coercion in the future.

When nested inside sequences, such as `np.array([array_like])`
, these
were handled as a single Python object rather than an array.
In the future they will behave identically to:

```
np.array([np.array(array_like)])
```
This change should only have an effect if `np.array(array_like)`
is not 0-D.
The solution to this warning may depend on the object:

Some array-likes may expect the new behaviour, and users can ignore the warning. The object can choose to expose the sequence protocol to opt-in to the new behaviour.

For example,

`shapely`
will allow conversion to an array-like using`line.coords`
rather than`np.asarray(line)`
. Users may work around the warning, or use the new convention when it becomes available.
Unfortunately, using the new behaviour can only be achieved by
calling `np.array(array_like)`
.

If you wish to ensure that the old behaviour remains unchanged, please create an object array and then fill it explicitly, for example:

```
arr = np.empty(3, dtype=object)
arr[:] = [array_like1, array_like2, array_like3]
```
This will ensure NumPy knows to not enter the array-like and use it as a object instead.

([gh-17973](https://github.com/numpy/numpy/pull/17973))

## Future Changes[#](#future-changes)
### Arrays cannot be using subarray dtypes[#](#arrays-cannot-be-using-subarray-dtypes)
Array creation and casting using `np.array(arr, dtype)`
and `arr.astype(dtype)`
will use different logic when `dtype`
is a subarray dtype such as `np.dtype("(2)i,")`
.

For such a `dtype`
the following behaviour is true:

```
res = np.array(arr, dtype)
res.dtype is not dtype
res.dtype is dtype.base
res.shape == arr.shape + dtype.shape
```
But `res`
is filled using the logic:

```
res = np.empty(arr.shape + dtype.shape, dtype=dtype.base)
res[...] = arr
```
which uses incorrect broadcasting (and often leads to an error). In the future, this will instead cast each element individually, leading to the same result as:

```
res = np.array(arr, dtype=np.dtype(["f", dtype]))["f"]
```
Which can normally be used to opt-in to the new behaviour.

This change does not affect `np.array(list, dtype="(2)i,")`
unless the
`list`
itself includes at least one array. In particular, the behaviour
is unchanged for a list of tuples.

([gh-17596](https://github.com/numpy/numpy/pull/17596))

## Expired deprecations[#](#expired-deprecations)
The deprecation of numeric style type-codes

`np.dtype("Complex64")`
(with upper case spelling), is expired.`"Complex64"`
corresponded to`"complex128"`
and`"Complex32"`
corresponded to`"complex64"`
.
The deprecation of

`np.sctypeNA`
and`np.typeNA`
is expired. Both have been removed from the public API. Use`np.typeDict`
instead.(

[gh-16554](https://github.com/numpy/numpy/pull/16554))
The 14-year deprecation of

`np.ctypeslib.ctypes_load_library`
is expired. Useinstead, which is identical.`load_library`
(

[gh-17116](https://github.com/numpy/numpy/pull/17116))
### Financial functions removed[#](#financial-functions-removed)
In accordance with NEP 32, the financial functions are removed
from NumPy 1.20. The functions that have been removed are `fv`
,
`ipmt`
, `irr`
, `mirr`
, `nper`
, `npv`
, `pmt`
, `ppmt`
,
`pv`
, and `rate`
. These functions are available in the
[numpy_financial](https://pypi.org/project/numpy-financial)
library.

([gh-17067](https://github.com/numpy/numpy/pull/17067))

## Compatibility notes[#](#compatibility-notes)
`isinstance(dtype, np.dtype)`
and not `type(dtype) is not np.dtype`
[#](#isinstance-dtype-np-dtype-and-not-type-dtype-is-not-np-dtype)
NumPy dtypes are not direct instances of `np.dtype`
anymore. Code that
may have used `type(dtype) is np.dtype`
will always return `False`
and
must be updated to use the correct version `isinstance(dtype, np.dtype)`
.

This change also affects the C-side macro `PyArray_DescrCheck`
if compiled
against a NumPy older than 1.16.6. If code uses this macro and wishes to
compile against an older version of NumPy, it must replace the macro
(see also [C API changes](#c-api-changes) section).

### Same kind casting in concatenate with `axis=None`
[#](#same-kind-casting-in-concatenate-with-axis-none)
When [ concatenate](../reference/generated/numpy.concatenate.html#numpy.concatenate) is called with

`axis=None`
,
the flattened arrays were cast with `unsafe`
. Any other axis
choice uses “same kind”. That different default
has been deprecated and “same kind” casting will be used
instead. The new `casting`
keyword argument
can be used to retain the old behaviour.([gh-16134](https://github.com/numpy/numpy/pull/16134))

### NumPy Scalars are cast when assigned to arrays[#](#numpy-scalars-are-cast-when-assigned-to-arrays)
When creating or assigning to arrays, in all relevant cases NumPy scalars will now be cast identically to NumPy arrays. In particular this changes the behaviour in some cases which previously raised an error:

```
np.array([np.float64(np.nan)], dtype=np.int64)
```
will succeed and return an undefined result (usually the smallest possible integer). This also affects assignments:

```
arr[0] = np.float64(np.nan)
```
At this time, NumPy retains the behaviour for:

```
np.array(np.float64(np.nan), dtype=np.int64)
```
The above changes do not affect Python scalars:

```
np.array([float("NaN")], dtype=np.int64)
```
remains unaffected (`np.nan`
is a Python `float`
, not a NumPy one).
Unlike signed integers, unsigned integers do not retain this special case,
since they always behaved more like casting.
The following code stops raising an error:

```
np.array([np.float64(np.nan)], dtype=np.uint64)
```
To avoid backward compatibility issues, at this time assignment from
`datetime64`
scalar to strings of too short length remains supported.
This means that `np.asarray(np.datetime64("2020-10-10"), dtype="S5")`
succeeds now, when it failed before. In the long term this may be
deprecated or the unsafe cast may be allowed generally to make assignment
of arrays and scalars behave consistently.

### Array coercion changes when Strings and other types are mixed[#](#array-coercion-changes-when-strings-and-other-types-are-mixed)
When strings and other types are mixed, such as:

```
np.array(["string", np.float64(3.)], dtype="S")
```
The results will change, which may lead to string dtypes with longer strings
in some cases. In particularly, if `dtype="S"`
is not provided any numerical
value will lead to a string results long enough to hold all possible numerical
values. (e.g. “S32” for floats). Note that you should always provide
`dtype="S"`
when converting non-strings to strings.

If `dtype="S"`
is provided the results will be largely identical to before,
but NumPy scalars (not a Python float like `1.0`
), will still enforce
a uniform string length:

```
np.array([np.float64(3.)], dtype="S") # gives "S32"
np.array([3.0], dtype="S") # gives "S3"
```
Previously the first version gave the same result as the second.

### Array coercion restructure[#](#array-coercion-restructure)
Array coercion has been restructured. In general, this should not affect users. In extremely rare corner cases where array-likes are nested:

```
np.array([array_like1])
```
Things will now be more consistent with:

```
np.array([np.array(array_like1)])
```
This can subtly change output for some badly defined array-likes.
One example for this are array-like objects which are not also sequences
of matching shape.
In NumPy 1.20, a warning will be given when an array-like is not also a
sequence (but behaviour remains identical, see deprecations).
If an array like is also a sequence (defines `__getitem__`
and `__len__`
)
NumPy will now only use the result given by `__array__`
,
`__array_interface__`
, or `__array_struct__`
. This will result in
differences when the (nested) sequence describes a different shape.

([gh-16200](https://github.com/numpy/numpy/pull/16200))

### Writing to the result of `numpy.broadcast_arrays`
will export readonly buffers[#](#writing-to-the-result-of-numpy-broadcast-arrays-will-export-readonly-buffers)
`numpy.broadcast_arrays`
In NumPy 1.17 [ numpy.broadcast_arrays](../reference/generated/numpy.broadcast_arrays.html#numpy.broadcast_arrays) started warning when the resulting array
was written to. This warning was skipped when the array was used through the
buffer interface (e.g.

`memoryview(arr)`
). The same thing will now occur for the
two protocols `__array_interface__`
, and `__array_struct__`
returning read-only
buffers instead of giving a warning.([gh-16350](https://github.com/numpy/numpy/pull/16350))

### Numeric-style type names have been removed from type dictionaries[#](#numeric-style-type-names-have-been-removed-from-type-dictionaries)
To stay in sync with the deprecation for `np.dtype("Complex64")`
and other numeric-style (capital case) types. These were removed
from `np.sctypeDict`
and `np.typeDict`
. You should use
the lower case versions instead. Note that `"Complex64"`
corresponds to `"complex128"`
and `"Complex32"`
corresponds
to `"complex64"`
. The numpy style (new) versions, denote the full
size and not the size of the real/imaginary part.

([gh-16554](https://github.com/numpy/numpy/pull/16554))

### The `operator.concat`
function now raises TypeError for array arguments[#](#the-operator-concat-function-now-raises-typeerror-for-array-arguments)
The previous behavior was to fall back to addition and add the two arrays, which was thought to be unexpected behavior for a concatenation function.

([gh-16570](https://github.com/numpy/numpy/pull/16570))

`nickname`
attribute removed from ABCPolyBase[#](#nickname-attribute-removed-from-abcpolybase)
An abstract property `nickname`
has been removed from `ABCPolyBase`
as it
was no longer used in the derived convenience classes.
This may affect users who have derived classes from `ABCPolyBase`
and
overridden the methods for representation and display, e.g. `__str__`
,
`__repr__`
, `_repr_latex`
, etc.

([gh-16589](https://github.com/numpy/numpy/pull/16589))

`float->timedelta`
and `uint64->timedelta`
promotion will raise a TypeError[#](#float-timedelta-and-uint64-timedelta-promotion-will-raise-a-typeerror)
Float and timedelta promotion consistently raises a TypeError.
`np.promote_types("float32", "m8")`
aligns with
`np.promote_types("m8", "float32")`
now and both raise a TypeError.
Previously, `np.promote_types("float32", "m8")`
returned `"m8"`
which
was considered a bug.

Uint64 and timedelta promotion consistently raises a TypeError.
`np.promote_types("uint64", "m8")`
aligns with
`np.promote_types("m8", "uint64")`
now and both raise a TypeError.
Previously, `np.promote_types("uint64", "m8")`
returned `"m8"`
which
was considered a bug.

([gh-16592](https://github.com/numpy/numpy/pull/16592))

`numpy.genfromtxt`
now correctly unpacks structured arrays[#](#numpy-genfromtxt-now-correctly-unpacks-structured-arrays)
Previously, [ numpy.genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) failed to unpack if it was called with

`unpack=True`
and a structured datatype was passed to the `dtype`
argument
(or `dtype=None`
was passed and a structured datatype was inferred).
For example:```
>>> data = StringIO("21 58.0\n35 72.0")
>>> np.genfromtxt(data, dtype=None, unpack=True)
array([(21, 58.), (35, 72.)], dtype=[('f0', '<i8'), ('f1', '<f8')])
```
Structured arrays will now correctly unpack into a list of arrays, one for each column:

```
>>> np.genfromtxt(data, dtype=None, unpack=True)
[array([21, 35]), array([58., 72.])]
```
([gh-16650](https://github.com/numpy/numpy/pull/16650))

`mgrid`
, `r_`
, etc. consistently return correct outputs for non-default precision input[#](#mgrid-r-etc-consistently-return-correct-outputs-for-non-default-precision-input)
Previously, `np.mgrid[np.float32(0.1):np.float32(0.35):np.float32(0.1),]`
and `np.r_[0:10:np.complex64(3j)]`
failed to return meaningful output.
This bug potentially affects [ mgrid](../reference/generated/numpy.mgrid.html#numpy.mgrid),

[,](../reference/generated/numpy.ogrid.html#numpy.ogrid)
`ogrid`
[, and](../reference/generated/numpy.r_.html#numpy.r_)
`r_`
[when an input with dtype other than the default](../reference/generated/numpy.c_.html#numpy.c_)
`c_`
`float64`
and `complex128`
and equivalent Python types were used.
The methods have been fixed to handle varying precision correctly.([gh-16815](https://github.com/numpy/numpy/pull/16815))

### Boolean array indices with mismatching shapes now properly give `IndexError`
[#](#boolean-array-indices-with-mismatching-shapes-now-properly-give-indexerror)
Previously, if a boolean array index matched the size of the indexed array but
not the shape, it was incorrectly allowed in some cases. In other cases, it
gave an error, but the error was incorrectly a `ValueError`
with a message
about broadcasting instead of the correct `IndexError`
.

For example, the following used to incorrectly give ```
ValueError: operands
could not be broadcast together with shapes (2,2) (1,4)
```
:

```
np.empty((2, 2))[np.array([[True, False, False, False]])]
```
And the following used to incorrectly return `array([], dtype=float64)`
:

```
np.empty((2, 2))[np.array([[False, False, False, False]])]
```
Both now correctly give ```
IndexError: boolean index did not match indexed
array along dimension 0; dimension is 2 but corresponding boolean dimension is
1
```
.

([gh-17010](https://github.com/numpy/numpy/pull/17010))

### Casting errors interrupt Iteration[#](#casting-errors-interrupt-iteration)
When iterating while casting values, an error may stop the iteration
earlier than before. In any case, a failed casting operation always
returned undefined, partial results. Those may now be even more
undefined and partial.
For users of the `NpyIter`
C-API such cast errors will now
cause the *iternext()* function to return 0 and thus abort
iteration.
Currently, there is no API to detect such an error directly.
It is necessary to check `PyErr_Occurred()`
, which
may be problematic in combination with `NpyIter_Reset`
.
These issues always existed, but new API could be added
if required by users.

([gh-17029](https://github.com/numpy/numpy/pull/17029))

### f2py generated code may return unicode instead of byte strings[#](#f2py-generated-code-may-return-unicode-instead-of-byte-strings)
Some byte strings previously returned by f2py generated code may now be unicode strings. This results from the ongoing Python2 -> Python3 cleanup.

([gh-17068](https://github.com/numpy/numpy/pull/17068))

### The first element of the `__array_interface__["data"]`
tuple must be an integer[#](#the-first-element-of-the-array-interface-data-tuple-must-be-an-integer)
This has been the documented interface for many years, but there was still code that would accept a byte string representation of the pointer address. That code has been removed, passing the address as a byte string will now raise an error.

([gh-17241](https://github.com/numpy/numpy/pull/17241))

### poly1d respects the dtype of all-zero argument[#](#poly1d-respects-the-dtype-of-all-zero-argument)
Previously, constructing an instance of `poly1d`
with all-zero
coefficients would cast the coefficients to `np.float64`
.
This affected the output dtype of methods which construct
`poly1d`
instances internally, such as `np.polymul`
.

([gh-17577](https://github.com/numpy/numpy/pull/17577))

### The numpy.i file for swig is Python 3 only.[#](#the-numpy-i-file-for-swig-is-python-3-only)
Uses of Python 2.7 C-API functions have been updated to Python 3 only. Users who need the old version should take it from an older version of NumPy.

([gh-17580](https://github.com/numpy/numpy/pull/17580))

### Void dtype discovery in `np.array`
[#](#void-dtype-discovery-in-np-array)
In calls using `np.array(..., dtype="V")`
, `arr.astype("V")`
,
and similar a TypeError will now be correctly raised unless all
elements have the identical void length. An example for this is:

```
np.array([b"1", b"12"], dtype="V")
```
Which previously returned an array with dtype `"V2"`
which
cannot represent `b"1"`
faithfully.

([gh-17706](https://github.com/numpy/numpy/pull/17706))

## C API changes[#](#c-api-changes)
### The `PyArray_DescrCheck`
macro is modified[#](#the-pyarray-descrcheck-macro-is-modified)
The `PyArray_DescrCheck`
macro has been updated since NumPy 1.16.6 to be:

```
#define PyArray_DescrCheck(op) PyObject_TypeCheck(op, &PyArrayDescr_Type)
```
Starting with NumPy 1.20 code that is compiled against an earlier version will be API incompatible with NumPy 1.20. The fix is to either compile against 1.16.6 (if the NumPy 1.16 release is the oldest release you wish to support), or manually inline the macro by replacing it with the new definition:

```
PyObject_TypeCheck(op, &PyArrayDescr_Type)
```
which is compatible with all NumPy versions.

### Size of `np.ndarray`
and `np.void_`
changed[#](#size-of-np-ndarray-and-np-void-changed)
The size of the `PyArrayObject`
and `PyVoidScalarObject`
structures have changed. The following header definition has been
removed:

```
#define NPY_SIZEOF_PYARRAYOBJECT (sizeof(PyArrayObject_fields))
```
since the size must not be considered a compile time constant: it will change for different runtime versions of NumPy.

The most likely relevant use are potential subclasses written in C which
will have to be recompiled and should be updated. Please see the
documentation for [ PyArrayObject](../reference/c-api/types-and-structures.html#c.PyArrayObject) for more details and contact
the NumPy developers if you are affected by this change.

NumPy will attempt to give a graceful error but a program expecting a fixed structure size may have undefined behaviour and likely crash.

([gh-16938](https://github.com/numpy/numpy/pull/16938))

## New Features[#](#new-features)
`where`
keyword argument for `numpy.all`
and `numpy.any`
functions[#](#where-keyword-argument-for-numpy-all-and-numpy-any-functions)
The keyword argument `where`
is added and allows to only consider specified
elements or subaxes from an array in the Boolean evaluation of `all`
and
`any`
. This new keyword is available to the functions `all`
and `any`
both via `numpy`
directly or in the methods of `numpy.ndarray`
.

Any broadcastable Boolean array or a scalar can be set as `where`
. It
defaults to `True`
to evaluate the functions for all elements in an array if
`where`
is not set by the user. Examples are given in the documentation of
the functions.

`where`
keyword argument for `numpy`
functions `mean`
, `std`
, `var`
[#](#where-keyword-argument-for-numpy-functions-mean-std-var)
The keyword argument `where`
is added and allows to limit the scope in the
calculation of `mean`
, `std`
and `var`
to only a subset of elements. It
is available both via `numpy`
directly or in the methods of
`numpy.ndarray`
.

Any broadcastable Boolean array or a scalar can be set as `where`
. It
defaults to `True`
to evaluate the functions for all elements in an array if
`where`
is not set by the user. Examples are given in the documentation of
the functions.

([gh-15852](https://github.com/numpy/numpy/pull/15852))

`norm=backward`
, `forward`
keyword options for `numpy.fft`
functions[#](#norm-backward-forward-keyword-options-for-numpy-fft-functions)
The keyword argument option `norm=backward`
is added as an alias for `None`
and acts as the default option; using it has the direct transforms unscaled
and the inverse transforms scaled by `1/n`
.

Using the new keyword argument option `norm=forward`
has the direct
transforms scaled by `1/n`
and the inverse transforms unscaled (i.e. exactly
opposite to the default option `norm=backward`
).

([gh-16476](https://github.com/numpy/numpy/pull/16476))

### NumPy is now typed[#](#numpy-is-now-typed)
Type annotations have been added for large parts of NumPy. There is
also a new [ numpy.typing](../reference/typing.html#module-numpy.typing) module that contains useful types for
end-users. The currently available types are

`ArrayLike`
: for objects that can be coerced to an array
`DtypeLike`
: for objects that can be coerced to a dtype
([gh-16515](https://github.com/numpy/numpy/pull/16515))

`numpy.typing`
is accessible at runtime[#](#numpy-typing-is-accessible-at-runtime)
The types in `numpy.typing`
can now be imported at runtime. Code
like the following will now work:

```
from numpy.typing import ArrayLike
x: ArrayLike = [1, 2, 3, 4]
```
([gh-16558](https://github.com/numpy/numpy/pull/16558))

### New `__f2py_numpy_version__`
attribute for f2py generated modules.[#](#new-f2py-numpy-version-attribute-for-f2py-generated-modules)
Because f2py is released together with NumPy, `__f2py_numpy_version__`
provides a way to track the version f2py used to generate the module.

([gh-16594](https://github.com/numpy/numpy/pull/16594))

`mypy`
tests can be run via runtests.py[#](#mypy-tests-can-be-run-via-runtests-py)
Currently running mypy with the NumPy stubs configured requires either:

Installing NumPy

Adding the source directory to MYPYPATH and linking to the

`mypy.ini`
Both options are somewhat inconvenient, so add a `--mypy`
option to runtests
that handles setting things up for you. This will also be useful in the future
for any typing codegen since it will ensure the project is built before type
checking.

([gh-17123](https://github.com/numpy/numpy/pull/17123))

### Negation of user defined BLAS/LAPACK detection order[#](#negation-of-user-defined-blas-lapack-detection-order)
[ distutils](../reference/distutils.html#module-numpy.distutils) allows negation of libraries when determining BLAS/LAPACK
libraries.
This may be used to remove an item from the library resolution phase, i.e.
to disallow NetLIB libraries one could do:
```
NPY_BLAS_ORDER='^blas' NPY_LAPACK_ORDER='^lapack' python setup.py build
```
That will use any of the accelerated libraries instead.

([gh-17219](https://github.com/numpy/numpy/pull/17219))

### Allow passing optimizations arguments to asv build[#](#allow-passing-optimizations-arguments-to-asv-build)
It is now possible to pass `-j`
, `--cpu-baseline`
, `--cpu-dispatch`
and
`--disable-optimization`
flags to ASV build when the `--bench-compare`
argument is used.

([gh-17284](https://github.com/numpy/numpy/pull/17284))

### The NVIDIA HPC SDK nvfortran compiler is now supported[#](#the-nvidia-hpc-sdk-nvfortran-compiler-is-now-supported)
Support for the nvfortran compiler, a version of pgfortran, has been added.

([gh-17344](https://github.com/numpy/numpy/pull/17344))

`dtype`
option for `cov`
and `corrcoef`
[#](#dtype-option-for-cov-and-corrcoef)
The `dtype`
option is now available for [ numpy.cov](../reference/generated/numpy.cov.html#numpy.cov) and

[. It specifies which data-type the returned result should have. By default the functions still return a](../reference/generated/numpy.corrcoef.html#numpy.corrcoef)
`numpy.corrcoef`
[result.](../reference/arrays.scalars.html#numpy.float64)
`numpy.float64`
([gh-17456](https://github.com/numpy/numpy/pull/17456))

## Improvements[#](#improvements)
### Improved string representation for polynomials (`__str__`
)[#](#improved-string-representation-for-polynomials-str)
The string representation (`__str__`
) of all six polynomial types in
[ numpy.polynomial](../reference/routines.polynomials.package.html#module-numpy.polynomial) has been updated to give the polynomial as a mathematical
expression instead of an array of coefficients. Two package-wide formats for
the polynomial expressions are available - one using Unicode characters for
superscripts and subscripts, and another using only ASCII characters.

([gh-15666](https://github.com/numpy/numpy/pull/15666))

### Remove the Accelerate library as a candidate LAPACK library[#](#remove-the-accelerate-library-as-a-candidate-lapack-library)
Apple no longer supports Accelerate. Remove it.

([gh-15759](https://github.com/numpy/numpy/pull/15759))

### Object arrays containing multi-line objects have a more readable `repr`
[#](#object-arrays-containing-multi-line-objects-have-a-more-readable-repr)
If elements of an object array have a `repr`
containing new lines, then the
wrapped lines will be aligned by column. Notably, this improves the `repr`
of
nested arrays:

```
>>> np.array([np.eye(2), np.eye(3)], dtype=object)
array([array([[1., 0.],
[0., 1.]]),
array([[1., 0., 0.],
[0., 1., 0.],
[0., 0., 1.]])], dtype=object)
```
([gh-15997](https://github.com/numpy/numpy/pull/15997))

### Concatenate supports providing an output dtype[#](#concatenate-supports-providing-an-output-dtype)
Support was added to [ concatenate](../reference/generated/numpy.concatenate.html#numpy.concatenate) to provide
an output

`dtype`
and `casting`
using keyword
arguments. The `dtype`
argument cannot be provided
in conjunction with the `out`
one.([gh-16134](https://github.com/numpy/numpy/pull/16134))

### Thread safe f2py callback functions[#](#thread-safe-f2py-callback-functions)
Callback functions in f2py are now thread safe.

([gh-16519](https://github.com/numpy/numpy/pull/16519))

`numpy.core.records.fromfile`
now supports file-like objects[#](#numpy-core-records-fromfile-now-supports-file-like-objects)
`numpy.core.records.fromfile`
`numpy.rec.fromfile`
can now use file-like objects, for instance
`io.BytesIO`
([gh-16675](https://github.com/numpy/numpy/pull/16675))

### RPATH support on AIX added to distutils[#](#rpath-support-on-aix-added-to-distutils)
This allows SciPy to be built on AIX.

([gh-16710](https://github.com/numpy/numpy/pull/16710))

### Use f90 compiler specified by the command line args[#](#use-f90-compiler-specified-by-the-command-line-args)
The compiler command selection for Fortran Portland Group Compiler is changed
in `numpy.distutils.fcompiler`
. This only affects the linking command. This
forces the use of the executable provided by the command line option (if
provided) instead of the pgfortran executable. If no executable is provided to
the command line option it defaults to the pgf90 executable, which is an alias
for pgfortran according to the PGI documentation.

([gh-16730](https://github.com/numpy/numpy/pull/16730))

### Add NumPy declarations for Cython 3.0 and later[#](#add-numpy-declarations-for-cython-3-0-and-later)
The pxd declarations for Cython 3.0 were improved to avoid using deprecated
NumPy C-API features. Extension modules built with Cython 3.0+ that use NumPy
can now set the C macro `NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION`
to avoid
C compiler warnings about deprecated API usage.

([gh-16986](https://github.com/numpy/numpy/pull/16986))

### Make the window functions exactly symmetric[#](#make-the-window-functions-exactly-symmetric)
Make sure the window functions provided by NumPy are symmetric. There were previously small deviations from symmetry due to numerical precision that are now avoided by better arrangement of the computation.

([gh-17195](https://github.com/numpy/numpy/pull/17195))

## Performance improvements and changes[#](#performance-improvements-and-changes)
### Enable multi-platform SIMD compiler optimizations[#](#enable-multi-platform-simd-compiler-optimizations)
A series of improvements for NumPy infrastructure to pave the way to
**NEP-38**, that can be summarized as follow:

**New Build Arguments**`--cpu-baseline`
to specify the minimal set of required optimizations, default value is`min`
which provides the minimum CPU features that can safely run on a wide range of users platforms.
`--cpu-dispatch`
to specify the dispatched set of additional optimizations, default value is`max -xop -fma4`
which enables all CPU features, except for AMD legacy features.
`--disable-optimization`
to explicitly disable the whole new improvements, It also adds a new**C**compiler #definition called`NPY_DISABLE_OPTIMIZATION`
which it can be used as guard for any SIMD code.
**Advanced CPU dispatcher**A flexible cross-architecture CPU dispatcher built on the top of Python/Numpy distutils, support all common compilers with a wide range of CPU features.

The new dispatcher requires a special file extension

`*.dispatch.c`
to mark the dispatch-able**C**sources. These sources have the ability to be compiled multiple times so that each compilation process represents certain CPU features and provides different #definitions and flags that affect the code paths.
**New auto-generated C header ``core/src/common/_cpu_dispatch.h``**This header is generated by the distutils module

`ccompiler_opt`
, and contains all the #definitions and headers of instruction sets, that had been configured through command arguments ‘–cpu-baseline’ and ‘–cpu-dispatch’.
**New C header ``core/src/common/npy_cpu_dispatch.h``**This header contains all utilities that required for the whole CPU dispatching process, it also can be considered as a bridge linking the new infrastructure work with NumPy CPU runtime detection.

**Add new attributes to NumPy umath module(Python level)**`__cpu_baseline__`
a list contains the minimal set of required optimizations that supported by the compiler and platform according to the specified values to command argument ‘–cpu-baseline’.
`__cpu_dispatch__`
a list contains the dispatched set of additional optimizations that supported by the compiler and platform according to the specified values to command argument ‘–cpu-dispatch’.
**Print the supported CPU features during the run of PytestTester**
([gh-13516](https://github.com/numpy/numpy/pull/13516))

## Changes[#](#changes)
`np.linspace`
on integers now uses floor[#](#np-linspace-on-integers-now-uses-floor)
When using a `int`
dtype in [ numpy.linspace](../reference/generated/numpy.linspace.html#numpy.linspace), previously float values would
be rounded towards zero. Now

[is used instead, which rounds toward](../reference/generated/numpy.floor.html#numpy.floor)
`numpy.floor`
`-inf`
. This changes the results for negative values. For example, the
following would previously give:```
>>> np.linspace(-3, 1, 8, dtype=int)
array([-3, -2, -1, -1, 0, 0, 0, 1])
```
and now results in:

```
>>> np.linspace(-3, 1, 8, dtype=int)
array([-3, -3, -2, -2, -1, -1, 0, 1])
```
The former result can still be obtained with:

```
>>> np.linspace(-3, 1, 8).astype(int)
array([-3, -2, -1, -1, 0, 0, 0, 1])
```
([gh-16841](https://github.com/numpy/numpy/pull/16841))# NumPy 1.16.0 Release Notes[#](#numpy-1-16-0-release-notes)
This NumPy release is the last one to support Python 2.7 and will be maintained as a long term release with bug fixes until 2020. Support for Python 3.4 been dropped, the supported Python versions are 2.7 and 3.5-3.7. The wheels on PyPI are linked with OpenBLAS v0.3.4+, which should fix the known threading issues found in previous OpenBLAS versions.

Downstream developers building this release should use Cython >= 0.29 and, if using OpenBLAS, OpenBLAS > v0.3.4.

This release has seen a lot of refactoring and features many bug fixes, improved code organization, and better cross platform compatibility. Not all of these improvements will be visible to users, but they should help make maintenance easier going forward.

## Highlights[#](#highlights)
Experimental (opt-in only) support for overriding numpy functions, see

`__array_function__`
below.
The

`matmul`
function is now a ufunc. This provides better performance and allows overriding with`__array_ufunc__`
.
Improved support for the ARM and POWER architectures.

Improved support for AIX and PyPy.

Improved interop with ctypes.

Improved support for PEP 3118.

## New functions[#](#new-functions)
New functions added to the

*numpy.lib.recfuntions*module to ease the structured assignment changes:`assign_fields_by_name`
`structured_to_unstructured`
`unstructured_to_structured`
`apply_along_fields`
`require_fields`
See the user guide at <

[https://docs.scipy.org/doc/numpy/user/basics.rec.html](https://docs.scipy.org/doc/numpy/user/basics.rec.html)> for more info.
## New deprecations[#](#new-deprecations)
The type dictionaries

*numpy.core.typeNA*and*numpy.core.sctypeNA*are deprecated. They were buggy and not documented and will be removed in the 1.18 release. Use`numpy.sctypeDict` instead.
The

*numpy.asscalar*function is deprecated. It is an alias to the more powerful, not tested, and fails for scalars.`numpy.ndarray.item`
The

*numpy.set_array_ops*and*numpy.get_array_ops*functions are deprecated. As part of*NEP 15*, they have been deprecated along with the C-API functionsand`PyArray_SetNumericOps`
. Users who wish to override the inner loop functions in built-in ufuncs should use`PyArray_GetNumericOps`
.`PyUFunc_ReplaceLoopBySignature`
The

keyword argument`numpy.unravel_index`
`dims`
is deprecated, use`shape`
instead.
The

`numpy.histogram`
`normed`
argument is deprecated. It was deprecated previously, but no warning was issued.
The

`positive`
operator (`+`
) applied to non-numerical arrays is deprecated. See below for details.
Passing an iterator to the stack functions is deprecated

## Expired deprecations[#](#expired-deprecations)
NaT comparisons now return

`False`
without a warning, finishing a deprecation cycle begun in NumPy 1.11.
`np.lib.function_base.unique`
was removed, finishing a deprecation cycle begun in NumPy 1.4. Useinstead.`numpy.unique`
multi-field indexing now returns views instead of copies, finishing a deprecation cycle begun in NumPy 1.7. The change was previously attempted in NumPy 1.14 but reverted until now.

`np.PackageLoader`
and`np.pkgload`
have been removed. These were deprecated in 1.10, had no tests, and seem to no longer work in 1.15.
## Future changes[#](#future-changes)
NumPy 1.17 will drop support for Python 2.7.

## Compatibility notes[#](#compatibility-notes)
### f2py script on Windows[#](#f2py-script-on-windows)
On Windows, the installed script for running f2py is now an `.exe`
file
rather than a `*.py`
file and should be run from the command line as `f2py`
whenever the `Scripts`
directory is in the path. Running `f2py`
as a module
`python -m numpy.f2py [...]`
will work without path modification in any
version of NumPy.

### NaT comparisons[#](#nat-comparisons)
Consistent with the behavior of NaN, all comparisons other than inequality
checks with datetime64 or timedelta64 NaT (“not-a-time”) values now always
return `False`
, and inequality checks with NaT now always return `True`
.
This includes comparisons between NaT values. For compatibility with the
old behavior, use `np.isnat`
to explicitly check for NaT or convert
datetime64/timedelta64 arrays with `.astype(np.int64)`
before making
comparisons.

### complex64/128 alignment has changed[#](#complex64-128-alignment-has-changed)
The memory alignment of complex types is now the same as a C-struct composed of
two floating point values, while before it was equal to the size of the type.
For many users (for instance on x64/unix/gcc) this means that complex64 is now
4-byte aligned instead of 8-byte aligned. An important consequence is that
aligned structured dtypes may now have a different size. For instance,
`np.dtype('c8,u1', align=True)`
used to have an itemsize of 16 (on x64/gcc)
but now it is 12.

More in detail, the complex64 type now has the same alignment as a C-struct
`struct {float r, i;}`
, according to the compiler used to compile numpy, and
similarly for the complex128 and complex256 types.

### nd_grid __len__ removal[#](#nd-grid-len-removal)
`len(np.mgrid)`
and `len(np.ogrid)`
are now considered nonsensical
and raise a `TypeError`
.
`np.unravel_index`
now accepts `shape`
keyword argument[#](#np-unravel-index-now-accepts-shape-keyword-argument)
Previously, only the `dims`
keyword argument was accepted
for specification of the shape of the array to be used
for unraveling. `dims`
remains supported, but is now deprecated.

### multi-field views return a view instead of a copy[#](#multi-field-views-return-a-view-instead-of-a-copy)
Indexing a structured array with multiple fields, e.g., `arr[['f1', 'f3']]`
,
returns a view into the original array instead of a copy. The returned view
will often have extra padding bytes corresponding to intervening fields in the
original array, unlike before, which will affect code such as
`arr[['f1', 'f3']].view('float64')`
. This change has been planned since numpy
1.7. Operations hitting this path have emitted `FutureWarnings`
since then.
Additional `FutureWarnings`
about this change were added in 1.12.

To help users update their code to account for these changes, a number of
functions have been added to the `numpy.lib.recfunctions`
module which
safely allow such operations. For instance, the code above can be replaced
with `structured_to_unstructured(arr[['f1', 'f3']], dtype='float64')`
.
See the “accessing multiple fields” section of the
[user guide](https://docs.scipy.org/doc/numpy/user/basics.rec.html#accessing-multiple-fields).

## C API changes[#](#c-api-changes)
The [ NPY_FEATURE_VERSION](../reference/c-api/array.html#c.NPY_FEATURE_VERSION) was incremented to 0x0000D, due to
the addition of:

## New Features[#](#new-features)
### Integrated squared error (ISE) estimator added to `histogram`
[#](#integrated-squared-error-ise-estimator-added-to-histogram)
This method (`bins='stone'`
) for optimizing the bin number is a
generalization of the Scott’s rule. The Scott’s rule assumes the distribution
is approximately Normal, while the [ISE](https://en.wikipedia.org/wiki/Histogram#Minimizing_cross-validation_estimated_squared_error) is a non-parametric method based on
cross-validation.

`max_rows`
keyword added for `np.loadtxt`
[#](#max-rows-keyword-added-for-np-loadtxt)
New keyword `max_rows`
in [ numpy.loadtxt](../reference/generated/numpy.loadtxt.html#numpy.loadtxt) sets the maximum rows of the
content to be read after

`skiprows`
, as in [.](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)
`numpy.genfromtxt`
### modulus operator support added for `np.timedelta64`
operands[#](#modulus-operator-support-added-for-np-timedelta64-operands)
The modulus (remainder) operator is now supported for two operands
of type `np.timedelta64`
. The operands may have different units
and the return value will match the type of the operands.

## Improvements[#](#improvements)
### no-copy pickling of numpy arrays[#](#no-copy-pickling-of-numpy-arrays)
Up to protocol 4, numpy array pickling created 2 spurious copies of the data
being serialized. With pickle protocol 5, and the `PickleBuffer`
API, a
large variety of numpy arrays can now be serialized without any copy using
out-of-band buffers, and with one less copy using in-band buffers. This
results, for large arrays, in an up to 66% drop in peak memory usage.

### build shell independence[#](#build-shell-independence)
NumPy builds should no longer interact with the host machine
shell directly. `exec_command`
has been replaced with
`subprocess.check_output`
where appropriate.

*np.polynomial.Polynomial* classes render in LaTeX in Jupyter notebooks[#](#np-polynomial-polynomial-classes-render-in-latex-in-jupyter-notebooks)
When used in a front-end that supports it, *Polynomial* instances are now
rendered through LaTeX. The current format is experimental, and is subject to
change.

`randint`
and `choice`
now work on empty distributions[#](#randint-and-choice-now-work-on-empty-distributions)
Even when no elements needed to be drawn, `np.random.randint`
and
`np.random.choice`
raised an error when the arguments described an empty
distribution. This has been fixed so that e.g.
`np.random.choice([], 0) == np.array([], dtype=float64)`
.

`linalg.lstsq`
, `linalg.qr`
, and `linalg.svd`
now work with empty arrays[#](#linalg-lstsq-linalg-qr-and-linalg-svd-now-work-with-empty-arrays)
Previously, a `LinAlgError`
would be raised when an empty matrix/empty
matrices (with zero rows and/or columns) is/are passed in. Now outputs of
appropriate shapes are returned.

### Chain exceptions to give better error messages for invalid PEP3118 format strings[#](#chain-exceptions-to-give-better-error-messages-for-invalid-pep3118-format-strings)
This should help track down problems.

### Einsum optimization path updates and efficiency improvements[#](#einsum-optimization-path-updates-and-efficiency-improvements)
Einsum was synchronized with the current upstream work.

`numpy.angle`
and `numpy.expand_dims`
now work on `ndarray`
subclasses[#](#numpy-angle-and-numpy-expand-dims-now-work-on-ndarray-subclasses)
`numpy.angle`
`numpy.expand_dims`
In particular, they now work for masked arrays.

`NPY_NO_DEPRECATED_API`
compiler warning suppression[#](#npy-no-deprecated-api-compiler-warning-suppression)
Setting `NPY_NO_DEPRECATED_API`
to a value of 0 will suppress the current compiler
warnings when the deprecated numpy API is used.

`np.diff`
Added kwargs prepend and append[#](#np-diff-added-kwargs-prepend-and-append)
New kwargs `prepend`
and `append`
, allow for values to be inserted on
either end of the differences. Similar to options for *ediff1d*. Now the
inverse of *cumsum* can be obtained easily via `prepend=0`
.

### ARM support updated[#](#arm-support-updated)
Support for ARM CPUs has been updated to accommodate 32 and 64 bit targets, and also big and little endian byte ordering. AARCH32 memory alignment issues have been addressed. CI testing has been expanded to include AARCH64 targets via the services of shippable.com.

### Appending to build flags[#](#appending-to-build-flags)
[ numpy.distutils](../reference/distutils.html#module-numpy.distutils) has always overridden rather than appended to
*LDFLAGS*and other similar such environment variables for compiling Fortran extensions. Now, if the
*NPY_DISTUTILS_APPEND_FLAGS*environment variable is set to 1, the behavior will be appending. This applied to:
*LDFLAGS*,
*F77FLAGS*,
*F90FLAGS*,
*FREEFLAGS*,
*FOPT*,
*FDEBUG*, and
*FFLAGS*. See gh-11525 for more details.
### Generalized ufunc signatures now allow fixed-size dimensions[#](#generalized-ufunc-signatures-now-allow-fixed-size-dimensions)
By using a numerical value in the signature of a generalized ufunc, one can
indicate that the given function requires input or output to have dimensions
with the given size. E.g., the signature of a function that converts a polar
angle to a two-dimensional cartesian unit vector would be `()->(2)`
; that
for one that converts two spherical angles to a three-dimensional unit vector
would be `(),()->(3)`
; and that for the cross product of two
three-dimensional vectors would be `(3),(3)->(3)`
.

Note that to the elementary function these dimensions are not treated any differently from variable ones indicated with a name starting with a letter; the loop still is passed the corresponding size, but it can now count on that size being equal to the fixed one given in the signature.

### Generalized ufunc signatures now allow flexible dimensions[#](#generalized-ufunc-signatures-now-allow-flexible-dimensions)
Some functions, in particular numpy’s implementation of `@`
as `matmul`
,
are very similar to generalized ufuncs in that they operate over core
dimensions, but one could not present them as such because they were able to
deal with inputs in which a dimension is missing. To support this, it is now
allowed to postfix a dimension name with a question mark to indicate that the
dimension does not necessarily have to be present.

With this addition, the signature for `matmul`
can be expressed as
`(m?,n),(n,p?)->(m?,p?)`
. This indicates that if, e.g., the second operand
has only one dimension, for the purposes of the elementary function it will be
treated as if that input has core shape `(n, 1)`
, and the output has the
corresponding core shape of `(m, 1)`
. The actual output array, however, has
the flexible dimension removed, i.e., it will have shape `(..., m)`
.
Similarly, if both arguments have only a single dimension, the inputs will be
presented as having shapes `(1, n)`
and `(n, 1)`
to the elementary
function, and the output as `(1, 1)`
, while the actual output array returned
will have shape `()`
. In this way, the signature allows one to use a
single elementary function for four related but different signatures,
`(m,n),(n,p)->(m,p)`
, `(n),(n,p)->(p)`
, `(m,n),(n)->(m)`
and
`(n),(n)->()`
.

`np.clip`
and the `clip`
method check for memory overlap[#](#np-clip-and-the-clip-method-check-for-memory-overlap)
The `out`
argument to these functions is now always tested for memory overlap
to avoid corrupted results when memory overlap occurs.

### New value `unscaled`
for option `cov`
in `np.polyfit`
[#](#new-value-unscaled-for-option-cov-in-np-polyfit)
A further possible value has been added to the `cov`
parameter of the
`np.polyfit`
function. With `cov='unscaled'`
the scaling of the covariance
matrix is disabled completely (similar to setting `absolute_sigma=True`
in
`scipy.optimize.curve_fit`
). This would be useful in occasions, where the
weights are given by 1/sigma with sigma being the (known) standard errors of
(Gaussian distributed) data points, in which case the unscaled matrix is
already a correct estimate for the covariance matrix.

### Detailed docstrings for scalar numeric types[#](#detailed-docstrings-for-scalar-numeric-types)
The `help`
function, when applied to numeric types such as [ numpy.intc](../reference/arrays.scalars.html#numpy.intc),

[, and](../reference/arrays.scalars.html#numpy.int_)
`numpy.int_`
[, now lists all of the aliased names for that type, distinguishing between platform -dependent and -independent aliases.](../reference/arrays.scalars.html#numpy.longlong)
`numpy.longlong`
`__module__`
attribute now points to public modules[#](#module-attribute-now-points-to-public-modules)
The `__module__`
attribute on most NumPy functions has been updated to refer
to the preferred public module from which to access a function, rather than
the module in which the function happens to be defined. This produces more
informative displays for functions in tools such as IPython, e.g., instead of
`<function 'numpy.core.fromnumeric.sum'>`
you now see
`<function 'numpy.sum'>`
.

### Large allocations marked as suitable for transparent hugepages[#](#large-allocations-marked-as-suitable-for-transparent-hugepages)
On systems that support transparent hugepages over the madvise system call
numpy now marks that large memory allocations can be backed by hugepages which
reduces page fault overhead and can in some fault heavy cases improve
performance significantly. On Linux the setting for huge pages to be used,
*/sys/kernel/mm/transparent_hugepage/enabled*, must be at least *madvise*.
Systems which already have it set to *always* will not see much difference as
the kernel will automatically use huge pages where appropriate.

Users of very old Linux kernels (~3.x and older) should make sure that
*/sys/kernel/mm/transparent_hugepage/defrag* is not set to *always* to avoid
performance problems due concurrency issues in the memory defragmentation.

### Alpine Linux (and other musl c library distros) support[#](#alpine-linux-and-other-musl-c-library-distros-support)
We now default to use *fenv.h* for floating point status error reporting.
Previously we had a broken default that sometimes would not report underflow,
overflow, and invalid floating point operations. Now we can support non-glibc
distributions like Alpine Linux as long as they ship *fenv.h*.

### Speedup `np.block`
for large arrays[#](#speedup-np-block-for-large-arrays)
Large arrays (greater than `512 * 512`
) now use a blocking algorithm based on
copying the data directly into the appropriate slice of the resulting array.
This results in significant speedups for these large arrays, particularly for
arrays being blocked along more than 2 dimensions.

`arr.ctypes.data_as(...)`
holds a reference to arr[#](#arr-ctypes-data-as-holds-a-reference-to-arr)
Previously the caller was responsible for keeping the array alive for the lifetime of the pointer.

### Speedup `np.take`
for read-only arrays[#](#speedup-np-take-for-read-only-arrays)
The implementation of `np.take`
no longer makes an unnecessary copy of the
source array when its `writeable`
flag is set to `False`
.

### Support path-like objects for more functions[#](#support-path-like-objects-for-more-functions)
The `np.core.records.fromfile`
function now supports `pathlib.Path`
and other path-like objects in addition to a file object. Furthermore, the
`np.load`
function now also supports path-like objects when using memory
mapping (`mmap_mode`
keyword argument).

### Better behaviour of ufunc identities during reductions[#](#better-behaviour-of-ufunc-identities-during-reductions)
Universal functions have an `.identity`
which is used when `.reduce`
is
called on an empty axis.

As of this release, the logical binary ufuncs, *logical_and*, *logical_or*,
and *logical_xor*, now have `identity`
s of type *bool*, where previously they
were of type *int*. This restores the 1.14 behavior of getting `bool`
s when
reducing empty object arrays with these ufuncs, while also keeping the 1.15
behavior of getting `int`
s when reducing empty object arrays with arithmetic
ufuncs like `add`
and `multiply`
.

Additionally, *logaddexp* now has an identity of `-inf`
, allowing it to be
called on empty sequences, where previously it could not be.

This is possible thanks to the new
[ PyUFunc_FromFuncAndDataAndSignatureAndIdentity](../reference/c-api/ufunc.html#c.PyUFunc_FromFuncAndDataAndSignatureAndIdentity), which allows
arbitrary values to be used as identities now.

### Improved conversion from ctypes objects[#](#improved-conversion-from-ctypes-objects)
Numpy has always supported taking a value or type from `ctypes`
and
converting it into an array or dtype, but only behaved correctly for simpler
types. As of this release, this caveat is lifted - now:

The

`_pack_`
attribute of`ctypes.Structure`
, used to emulate C’s`__attribute__((packed))`
, is respected.
Endianness of all ctypes objects is preserved

`ctypes.Union`
is supported
Non-representable constructs raise exceptions, rather than producing dangerously incorrect results:

Bitfields are no longer interpreted as sub-arrays

Pointers are no longer replaced with the type that they point to

### A new `ndpointer.contents`
member[#](#a-new-ndpointer-contents-member)
This matches the `.contents`
member of normal ctypes arrays, and can be used
to construct an `np.array`
around the pointers contents. This replaces
`np.array(some_nd_pointer)`
, which stopped working in 1.15. As a side effect
of this change, `ndpointer`
now supports dtypes with overlapping fields and
padding.

`matmul`
is now a `ufunc`
[#](#matmul-is-now-a-ufunc)
[ numpy.matmul](../reference/generated/numpy.matmul.html#numpy.matmul) is now a ufunc which means that both the function and the
`__matmul__`
operator can now be overridden by `__array_ufunc__`
. Its
implementation has also changed. It uses the same BLAS routines as
[, ensuring its performance is similar for large matrices.](../reference/generated/numpy.dot.html#numpy.dot)
`numpy.dot`
### Start and stop arrays for `linspace`
, `logspace`
and `geomspace`
[#](#start-and-stop-arrays-for-linspace-logspace-and-geomspace)
These functions used to be limited to scalar stop and start values, but can now take arrays, which will be properly broadcast and result in an output which has one axis prepended. This can be used, e.g., to obtain linearly interpolated points between sets of points.

### CI extended with additional services[#](#ci-extended-with-additional-services)
We now use additional free CI services, thanks to the companies that provide:

Codecoverage testing via codecov.io

Arm testing via shippable.com

Additional test runs on azure pipelines

These are in addition to our continued use of travis, appveyor (for wheels) and LGTM

## Changes[#](#changes)
### Comparison ufuncs will now error rather than return NotImplemented[#](#comparison-ufuncs-will-now-error-rather-than-return-notimplemented)
Previously, comparison ufuncs such as `np.equal`
would return
*NotImplemented* if their arguments had structured dtypes, to help comparison
operators such as `__eq__`
deal with those. This is no longer needed, as the
relevant logic has moved to the comparison operators proper (which thus do
continue to return *NotImplemented* as needed). Hence, like all other ufuncs,
the comparison ufuncs will now error on structured dtypes.

### Positive will now raise a deprecation warning for non-numerical arrays[#](#positive-will-now-raise-a-deprecation-warning-for-non-numerical-arrays)
Previously, `+array`
unconditionally returned a copy. Now, it will
raise a `DeprecationWarning`
if the array is not numerical (i.e.,
if `np.positive(array)`
raises a `TypeError`
. For `ndarray`
subclasses that override the default `__array_ufunc__`
implementation,
the `TypeError`
is passed on.

`NDArrayOperatorsMixin`
now implements matrix multiplication[#](#ndarrayoperatorsmixin-now-implements-matrix-multiplication)
Previously, `np.lib.mixins.NDArrayOperatorsMixin`
did not implement the
special methods for Python’s matrix multiplication operator (`@`
). This has
changed now that `matmul`
is a ufunc and can be overridden using
`__array_ufunc__`
.

### The scaling of the covariance matrix in `np.polyfit`
is different[#](#the-scaling-of-the-covariance-matrix-in-np-polyfit-is-different)
So far, `np.polyfit`
used a non-standard factor in the scaling of the the
covariance matrix. Namely, rather than using the standard `chisq/(M-N)`
, it
scaled it with `chisq/(M-N-2)`
where M is the number of data points and N is the
number of parameters. This scaling is inconsistent with other fitting programs
such as e.g. `scipy.optimize.curve_fit`
and was changed to `chisq/(M-N)`
.

`maximum`
and `minimum`
no longer emit warnings[#](#maximum-and-minimum-no-longer-emit-warnings)
As part of code introduced in 1.10, `float32`
and `float64`
set invalid
float status when a Nan is encountered in [ numpy.maximum](../reference/generated/numpy.maximum.html#numpy.maximum) and

[, when using SSE2 semantics. This caused a](../reference/generated/numpy.minimum.html#numpy.minimum)
`numpy.minimum`
*RuntimeWarning*to sometimes be emitted. In 1.15 we fixed the inconsistencies which caused the warnings to become more conspicuous. Now no warnings will be emitted.
### Umath and multiarray c-extension modules merged into a single module[#](#umath-and-multiarray-c-extension-modules-merged-into-a-single-module)
The two modules were merged, according to [NEP 15](http://www.numpy.org/neps/nep-0015-merge-multiarray-umath.html). Previously *np.core.umath*
and *np.core.multiarray* were separate c-extension modules. They are now python
wrappers to the single *np.core/_multiarray_math* c-extension module.

`getfield`
validity checks extended[#](#getfield-validity-checks-extended)
[ numpy.ndarray.getfield](../reference/generated/numpy.ndarray.getfield.html#numpy.ndarray.getfield) now checks the dtype and offset arguments to prevent
accessing invalid memory locations.
### NumPy functions now support overrides with `__array_function__`
[#](#numpy-functions-now-support-overrides-with-array-function)
NumPy has a new experimental mechanism for overriding the implementation of
almost all NumPy functions on non-NumPy arrays by defining an
`__array_function__`
method, as described in [NEP 18](http://www.numpy.org/neps/nep-0018-array-function-protocol.html).

This feature is not yet been enabled by default, but has been released to facilitate experimentation by potential users. See the NEP for details on setting the appropriate environment variable. We expect the NumPy 1.17 release will enable overrides by default, which will also be more performant due to a new implementation written in C.

### Arrays based off readonly buffers cannot be set `writeable`
[#](#arrays-based-off-readonly-buffers-cannot-be-set-writeable)
We now disallow setting the `writeable`
flag True on arrays created
from `fromstring(readonly-buffer)`
.# NumPy 1.16.4 Release Notes[#](#numpy-1-16-4-release-notes)
The NumPy 1.16.4 release fixes bugs reported against the 1.16.3 release, and also backports several enhancements from master that seem appropriate for a release series that is the last to support Python 2.7. The wheels on PyPI are linked with OpenBLAS v0.3.7-dev, which should fix issues on Skylake series cpus.

Downstream developers building this release should use Cython >= 0.29.2 and, if using OpenBLAS, OpenBLAS > v0.3.7. The supported Python versions are 2.7 and 3.5-3.7.

## New deprecations[#](#new-deprecations)
### Writeable flag of C-API wrapped arrays[#](#writeable-flag-of-c-api-wrapped-arrays)
When an array is created from the C-API to wrap a pointer to data, the only
indication we have of the read-write nature of the data is the `writeable`
flag set during creation. It is dangerous to force the flag to writeable. In
the future it will not be possible to switch the writeable flag to `True`
from python. This deprecation should not affect many users since arrays
created in such a manner are very rare in practice and only available through
the NumPy C-API.

## Compatibility notes[#](#compatibility-notes)
### Potential changes to the random stream[#](#potential-changes-to-the-random-stream)
Due to bugs in the application of log to random floating point numbers,
the stream may change when sampling from `np.random.beta`
, `np.random.binomial`
,
`np.random.laplace`
, `np.random.logistic`
, `np.random.logseries`
or
`np.random.multinomial`
if a 0 is generated in the underlying MT19937 random stream.
There is a 1 in \(10^{53}\) chance of this occurring, and so the probability that
the stream changes for any given seed is extremely small. If a 0 is encountered in the
underlying generator, then the incorrect value produced (either `np.inf`
or `np.nan`
) is now dropped.

## Changes[#](#changes)
`numpy.lib.recfunctions.structured_to_unstructured`
does not squeeze single-field views[#](#numpy-lib-recfunctions-structured-to-unstructured-does-not-squeeze-single-field-views)
`numpy.lib.recfunctions.structured_to_unstructured`
Previously `structured_to_unstructured(arr[['a']])`
would produce a squeezed
result inconsistent with `structured_to_unstructured(arr[['a', b']])`
. This
was accidental. The old behavior can be retained with
`structured_to_unstructured(arr[['a']]).squeeze(axis=-1)`
or far more simply,
`arr['a']`
.

## Contributors[#](#contributors)
A total of 10 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Eric Wieser

Dennis Zollo +

Hunter Damron +

Jingbei Li +

Kevin Sheppard

Matti Picus

Nicola Soranzo +

Sebastian Berg

Tyler Reddy

## Pull requests merged[#](#pull-requests-merged)
A total of 16 pull requests were merged for this release.

[#13392](https://github.com/numpy/numpy/pull/13392): BUG: Some PyPy versions lack PyStructSequence_InitType2.
[#13394](https://github.com/numpy/numpy/pull/13394): MAINT, DEP: Fix deprecated`assertEquals()`
[#13396](https://github.com/numpy/numpy/pull/13396): BUG: Fix structured_to_unstructured on single-field types (backport)
[#13549](https://github.com/numpy/numpy/pull/13549): BLD: Make CI pass again with pytest 4.5
[#13552](https://github.com/numpy/numpy/pull/13552): TST: Register markers in conftest.py.
[#13559](https://github.com/numpy/numpy/pull/13559): BUG: Removes ValueError for empty kwargs in arraymultiter_new
[#13560](https://github.com/numpy/numpy/pull/13560): BUG: Add TypeError to accepted exceptions in crackfortran.
[#13561](https://github.com/numpy/numpy/pull/13561): BUG: Handle subarrays in descr_to_dtype
[#13562](https://github.com/numpy/numpy/pull/13562): BUG: Protect generators from log(0.0)
[#13563](https://github.com/numpy/numpy/pull/13563): BUG: Always return views from structured_to_unstructured when…
[#13564](https://github.com/numpy/numpy/pull/13564): BUG: Catch stderr when checking compiler version
[#13565](https://github.com/numpy/numpy/pull/13565): BUG: longdouble(int) does not work
[#13587](https://github.com/numpy/numpy/pull/13587): BUG: distutils/system_info.py fix missing subprocess import (#13523)
[#13620](https://github.com/numpy/numpy/pull/13620): BUG,DEP: Fix writeable flag setting for arrays without base
[#13641](https://github.com/numpy/numpy/pull/13641): MAINT: Prepare for the 1.16.4 release.
[#13644](https://github.com/numpy/numpy/pull/13644): BUG: special case object arrays when printing rel-, abs-error# NumPy 1.3.0 Release Notes[#](#numpy-1-3-0-release-notes)
This minor includes numerous bug fixes, official python 2.6 support, and several new features such as generalized ufuncs.

## Highlights[#](#highlights)
### Python 2.6 support[#](#python-2-6-support)
Python 2.6 is now supported on all previously supported platforms, including windows.

### Generalized ufuncs[#](#generalized-ufuncs)
There is a general need for looping over not only functions on scalars but also
over functions on vectors (or arrays), as explained on
[http://scipy.org/scipy/numpy/wiki/GeneralLoopingFunctions](http://scipy.org/scipy/numpy/wiki/GeneralLoopingFunctions). We propose to
realize this concept by generalizing the universal functions (ufuncs), and
provide a C implementation that adds ~500 lines to the numpy code base. In
current (specialized) ufuncs, the elementary function is limited to
element-by-element operations, whereas the generalized version supports
“sub-array” by “sub-array” operations. The Perl vector library PDL provides a
similar functionality and its terms are re-used in the following.

Each generalized ufunc has information associated with it that states what the “core” dimensionality of the inputs is, as well as the corresponding dimensionality of the outputs (the element-wise ufuncs have zero core dimensions). The list of the core dimensions for all arguments is called the “signature” of a ufunc. For example, the ufunc numpy.add has signature “(),()->()” defining two scalar inputs and one scalar output.

Another example is (see the GeneralLoopingFunctions page) the function inner1d(a,b) with a signature of “(i),(i)->()”. This applies the inner product along the last axis of each input, but keeps the remaining indices intact. For example, where a is of shape (3,5,N) and b is of shape (5,N), this will return an output of shape (3,5). The underlying elementary function is called 3*5 times. In the signature, we specify one core dimension “(i)” for each input and zero core dimensions “()” for the output, since it takes two 1-d arrays and returns a scalar. By using the same name “i”, we specify that the two corresponding dimensions should be of the same size (or one of them is of size 1 and will be broadcasted).

The dimensions beyond the core dimensions are called “loop” dimensions. In the above example, this corresponds to (3,5).

The usual numpy “broadcasting” rules apply, where the signature determines how the dimensions of each input/output object are split into core and loop dimensions:

While an input array has a smaller dimensionality than the corresponding number of core dimensions, 1’s are pre-pended to its shape. The core dimensions are removed from all inputs and the remaining dimensions are broadcasted; defining the loop dimensions. The output is given by the loop dimensions plus the output core dimensions.

### Experimental Windows 64 bits support[#](#experimental-windows-64-bits-support)
Numpy can now be built on windows 64 bits (amd64 only, not IA64), with both MS compilers and mingw-w64 compilers:

This is *highly experimental*: DO NOT USE FOR PRODUCTION USE. See INSTALL.txt,
Windows 64 bits section for more information on limitations and how to build it
by yourself.

## New features[#](#new-features)
### Formatting issues[#](#formatting-issues)
Float formatting is now handled by numpy instead of the C runtime: this enables locale independent formatting, more robust fromstring and related methods. Special values (inf and nan) are also more consistent across platforms (nan vs IND/NaN, etc…), and more consistent with recent python formatting work (in 2.6 and later).

### Nan handling in max/min[#](#nan-handling-in-max-min)
The maximum/minimum ufuncs now reliably propagate nans. If one of the arguments is a nan, then nan is returned. This affects np.min/np.max, amin/amax and the array methods max/min. New ufuncs fmax and fmin have been added to deal with non-propagating nans.

### Nan handling in sign[#](#nan-handling-in-sign)
The ufunc sign now returns nan for the sign of anan.

### New ufuncs[#](#new-ufuncs)
fmax - same as maximum for integer types and non-nan floats. Returns the non-nan argument if one argument is nan and returns nan if both arguments are nan.

fmin - same as minimum for integer types and non-nan floats. Returns the non-nan argument if one argument is nan and returns nan if both arguments are nan.

deg2rad - converts degrees to radians, same as the radians ufunc.

rad2deg - converts radians to degrees, same as the degrees ufunc.

log2 - base 2 logarithm.

exp2 - base 2 exponential.

trunc - truncate floats to nearest integer towards zero.

logaddexp - add numbers stored as logarithms and return the logarithm of the result.

logaddexp2 - add numbers stored as base 2 logarithms and return the base 2 logarithm of the result.

### Masked arrays[#](#masked-arrays)
Several new features and bug fixes, including:

-
structured arrays should now be fully supported by MaskedArray (r6463, r6324, r6305, r6300, r6294…)

-
Minor bug fixes (r6356, r6352, r6335, r6299, r6298)

-
Improved support for __iter__ (r6326)

-
made baseclass, sharedmask and hardmask accessible to the user (but read-only)

-
doc update

### gfortran support on windows[#](#gfortran-support-on-windows)
Gfortran can now be used as a fortran compiler for numpy on windows, even when the C compiler is Visual Studio (VS 2005 and above; VS 2003 will NOT work). Gfortran + Visual studio does not work on windows 64 bits (but gcc + gfortran does). It is unclear whether it will be possible to use gfortran and visual studio at all on x64.

### Arch option for windows binary[#](#arch-option-for-windows-binary)
Automatic arch detection can now be bypassed from the command line for the superpack installed:

numpy-1.3.0-superpack-win32.exe /arch=nosse

will install a numpy which works on any x86, even if the running computer supports SSE set.

## Deprecated features[#](#deprecated-features)
### Histogram[#](#histogram)
The semantics of histogram has been modified to fix long-standing issues with outliers handling. The main changes concern

the definition of the bin edges, now including the rightmost edge, and

the handling of upper outliers, now ignored rather than tallied in the rightmost bin.

The previous behavior is still accessible using *new=False*, but this is
deprecated, and will be removed entirely in 1.4.0.

## Documentation changes[#](#documentation-changes)
A lot of documentation has been added. Both user guide and references can be built from sphinx.

## New C API[#](#new-c-api)
### Multiarray API[#](#multiarray-api)
The following functions have been added to the multiarray C API:

-
PyArray_GetEndianness: to get runtime endianness

### Ufunc API[#](#ufunc-api)
The following functions have been added to the ufunc API:

-
PyUFunc_FromFuncAndDataAndSignature: to declare a more general ufunc (generalized ufunc).

### New defines[#](#new-defines)
New public C defines are available for ARCH specific code through numpy/npy_cpu.h:

-
NPY_CPU_X86: x86 arch (32 bits)

-
NPY_CPU_AMD64: amd64 arch (x86_64, NOT Itanium)

-
NPY_CPU_PPC: 32 bits ppc

-
NPY_CPU_PPC64: 64 bits ppc

-
NPY_CPU_SPARC: 32 bits sparc

-
NPY_CPU_SPARC64: 64 bits sparc

-
NPY_CPU_S390: S390

-
NPY_CPU_IA64: ia64

-
NPY_CPU_PARISC: PARISC

New macros for CPU endianness has been added as well (see internal changes below for details):

-
NPY_BYTE_ORDER: integer

-
NPY_LITTLE_ENDIAN/NPY_BIG_ENDIAN defines

Those provide portable alternatives to glibc endian.h macros for platforms without it.

### Portable NAN, INFINITY, etc…[#](#portable-nan-infinity-etc)
npy_math.h now makes available several portable macro to get NAN, INFINITY:

-
NPY_NAN: equivalent to NAN, which is a GNU extension

-
NPY_INFINITY: equivalent to C99 INFINITY

-
NPY_PZERO, NPY_NZERO: positive and negative zero respectively

Corresponding single and extended precision macros are available as well. All references to NAN, or home-grown computation of NAN on the fly have been removed for consistency.

## Internal changes[#](#internal-changes)
### numpy.core math configuration revamp[#](#numpy-core-math-configuration-revamp)
This should make the porting to new platforms easier, and more robust. In particular, the configuration stage does not need to execute any code on the target platform, which is a first step toward cross-compilation.

### umath refactor[#](#umath-refactor)
A lot of code cleanup for umath/ufunc code (charris).

### Improvements to build warnings[#](#improvements-to-build-warnings)
Numpy can now build with -W -Wall without warnings

### Separate core math library[#](#separate-core-math-library)
The core math functions (sin, cos, etc… for basic C types) have been put into a separate library; it acts as a compatibility layer, to support most C99 maths functions (real only for now). The library includes platform-specific fixes for various maths functions, such as using those versions should be more robust than using your platform functions directly. The API for existing functions is exactly the same as the C99 math functions API; the only difference is the npy prefix (npy_cos vs cos).

The core library will be made available to any extension in 1.4.0.

### CPU arch detection[#](#cpu-arch-detection)
npy_cpu.h defines numpy specific CPU defines, such as NPY_CPU_X86, etc… Those are portable across OS and toolchains, and set up when the header is parsed, so that they can be safely used even in the case of cross-compilation (the values is not set when numpy is built), or for multi-arch binaries (e.g. fat binaries on Max OS X).

npy_endian.h defines numpy specific endianness defines, modeled on the glibc endian.h. NPY_BYTE_ORDER is equivalent to BYTE_ORDER, and one of NPY_LITTLE_ENDIAN or NPY_BIG_ENDIAN is defined. As for CPU archs, those are set when the header is parsed by the compiler, and as such can be used for cross-compilation and multi-arch binaries.# NumPy 1.14.0 Release Notes[#](#numpy-1-14-0-release-notes)
Numpy 1.14.0 is the result of seven months of work and contains a large number of bug fixes and new features, along with several changes with potential compatibility issues. The major change that users will notice are the stylistic changes in the way numpy arrays and scalars are printed, a change that will affect doctests. See below for details on how to preserve the old style printing when needed.

A major decision affecting future development concerns the schedule for
dropping Python 2.7 support in the runup to 2020. The decision has been made to
support 2.7 for all releases made in 2018, with the last release being
designated a long term release with support for bug fixes extending through
2019. In 2019 support for 2.7 will be dropped in all new releases. More details
can be found in [NEP 12](http://www.numpy.org/neps/nep-0014-dropping-python2.7-proposal.html).

This release supports Python 2.7 and 3.4 - 3.6.

## Highlights[#](#highlights)
The

*np.einsum*function uses BLAS when possible
`genfromtxt`
,`loadtxt`
,`fromregex`
and`savetxt`
can now handle files with arbitrary Python supported encoding.
Major improvements to printing of NumPy arrays and scalars.

## New functions[#](#new-functions)
`parametrize`
: decorator added to numpy.testing
`chebinterpolate`
: Interpolate function at Chebyshev points.
`format_float_positional`
and`format_float_scientific`
: format floating-point scalars unambiguously with control of rounding and padding.
`PyArray_ResolveWritebackIfCopy`
and`PyArray_SetWritebackIfCopyBase`
, new C-API functions useful in achieving PyPy compatibility.
## Deprecations[#](#deprecations)
Using

`np.bool_`
objects in place of integers is deprecated. Previously`operator.index(np.bool_)`
was legal and allowed constructs such as`[1, 2, 3][np.True_]`
. That was misleading, as it behaved differently from`np.array([1, 2, 3])[np.True_]`
.
Truth testing of an empty array is deprecated. To check if an array is not empty, use

`array.size > 0`
.
Calling

`np.bincount`
with`minlength=None`
is deprecated.`minlength=0`
should be used instead.
Calling

`np.fromstring`
with the default value of the`sep`
argument is deprecated. When that argument is not provided, a broken version of`np.frombuffer`
is used that silently accepts unicode strings and – after encoding them as either utf-8 (python 3) or the default encoding (python 2) – treats them as binary data. If reading binary data is desired,`np.frombuffer`
should be used directly.
The

`style`
option of array2string is deprecated in non-legacy printing mode.
`PyArray_SetUpdateIfCopyBase`
has been deprecated. For NumPy versions >= 1.14 use`PyArray_SetWritebackIfCopyBase`
instead, see*C API changes*below for more details.
The use of

`UPDATEIFCOPY`
arrays is deprecated, see*C API changes*below for details. We will not be dropping support for those arrays, but they are not compatible with PyPy.
## Future Changes[#](#future-changes)
`np.issubdtype`
will stop downcasting dtype-like arguments. It might be expected that`issubdtype(np.float32, 'float64')`
and`issubdtype(np.float32, np.float64)`
mean the same thing - however, there was an undocumented special case that translated the former into`issubdtype(np.float32, np.floating)`
, giving the surprising result of True.This translation now gives a warning that explains what translation is occurring. In the future, the translation will be disabled, and the first example will be made equivalent to the second.

`np.linalg.lstsq`
default for`rcond`
will be changed. The`rcond`
parameter to`np.linalg.lstsq`
will change its default to machine precision times the largest of the input array dimensions. A FutureWarning is issued when`rcond`
is not passed explicitly.
`a.flat.__array__()`
will return a writeable copy of`a`
when`a`
is non-contiguous. Previously it returned an UPDATEIFCOPY array when`a`
was writeable. Currently it returns a non-writeable copy. See gh-7054 for a discussion of the issue.
Unstructured void array’s

`.item`
method will return a bytes object. In the future, calling`.item()`
on arrays or scalars of`np.void`
datatype will return a`bytes`
object instead of a buffer or int array, the same as returned by`bytes(void_scalar)`
. This may affect code which assumed the return value was mutable, which will no longer be the case. A`FutureWarning`
is now issued when this would occur.
## Compatibility notes[#](#compatibility-notes)
### The mask of a masked array view is also a view rather than a copy[#](#the-mask-of-a-masked-array-view-is-also-a-view-rather-than-a-copy)
There was a FutureWarning about this change in NumPy 1.11.x. In short, it is
now the case that, when changing a view of a masked array, changes to the mask
are propagated to the original. That was not previously the case. This change
affects slices in particular. Note that this does not yet work properly if the
mask of the original array is `nomask`
and the mask of the view is changed.
See gh-5580 for an extended discussion. The original behavior of having a copy
of the mask can be obtained by calling the `unshare_mask`
method of the view.

`np.ma.masked`
is no longer writeable[#](#np-ma-masked-is-no-longer-writeable)
Attempts to mutate the `masked`
constant now error, as the underlying arrays
are marked readonly. In the past, it was possible to get away with:

```
# emulating a function that sometimes returns np.ma.masked
val = random.choice([np.ma.masked, 10])
var_arr = np.asarray(val)
val_arr += 1 # now errors, previously changed np.ma.masked.data
```
`np.ma`
functions producing `fill_value`
s have changed[#](#np-ma-functions-producing-fill-value-s-have-changed)
Previously, `np.ma.default_fill_value`
would return a 0d array, but
`np.ma.minimum_fill_value`
and `np.ma.maximum_fill_value`
would return a
tuple of the fields. Instead, all three methods return a structured `np.void`
object, which is what you would already find in the `.fill_value`
attribute.

Additionally, the dtype guessing now matches that of `np.array`
- so when
passing a python scalar `x`
, `maximum_fill_value(x)`
is always the same as
`maximum_fill_value(np.array(x))`
. Previously `x = long(1)`
on Python 2
violated this assumption.

`a.flat.__array__()`
returns non-writeable arrays when `a`
is non-contiguous[#](#a-flat-array-returns-non-writeable-arrays-when-a-is-non-contiguous)
The intent is that the UPDATEIFCOPY array previously returned when `a`
was
non-contiguous will be replaced by a writeable copy in the future. This
temporary measure is aimed to notify folks who expect the underlying array be
modified in this situation that that will no longer be the case. The most
likely places for this to be noticed is when expressions of the form
`np.asarray(a.flat)`
are used, or when `a.flat`
is passed as the out
parameter to a ufunc.

`np.tensordot`
now returns zero array when contracting over 0-length dimension[#](#np-tensordot-now-returns-zero-array-when-contracting-over-0-length-dimension)
Previously `np.tensordot`
raised a ValueError when contracting over 0-length
dimension. Now it returns a zero array, which is consistent with the behaviour
of `np.dot`
and `np.einsum`
.

`numpy.testing`
reorganized[#](#numpy-testing-reorganized)
This is not expected to cause problems, but possibly something has been left
out. If you experience an unexpected import problem using `numpy.testing`
let us know.

`np.asfarray`
no longer accepts non-dtypes through the `dtype`
argument[#](#np-asfarray-no-longer-accepts-non-dtypes-through-the-dtype-argument)
This previously would accept `dtype=some_array`
, with the implied semantics
of `dtype=some_array.dtype`
. This was undocumented, unique across the numpy
functions, and if used would likely correspond to a typo.

### 1D `np.linalg.norm`
preserves float input types, even for arbitrary orders[#](#d-np-linalg-norm-preserves-float-input-types-even-for-arbitrary-orders)
Previously, this would promote to `float64`
when arbitrary orders were
passed, despite not doing so under the simple cases:

```
>>> f32 = np.float32([[1, 2]])
>>> np.linalg.norm(f32, 2.0, axis=-1).dtype
dtype('float32')
>>> np.linalg.norm(f32, 2.0001, axis=-1).dtype
dtype('float64') # numpy 1.13
dtype('float32') # numpy 1.14
```
This change affects only `float32`
and `float16`
arrays.

`count_nonzero(arr, axis=())`
now counts over no axes, not all axes[#](#count-nonzero-arr-axis-now-counts-over-no-axes-not-all-axes)
Elsewhere, `axis==()`
is always understood as “no axes”, but
*count_nonzero* had a special case to treat this as “all axes”. This was
inconsistent and surprising. The correct way to count over all axes has always
been to pass `axis == None`
.

`__init__.py`
files added to test directories[#](#init-py-files-added-to-test-directories)
This is for pytest compatibility in the case of duplicate test file names in
the different directories. As a result, `run_module_suite`
no longer works,
i.e., `python <path-to-test-file>`
results in an error.

`.astype(bool)`
on unstructured void arrays now calls `bool`
on each element[#](#astype-bool-on-unstructured-void-arrays-now-calls-bool-on-each-element)
On Python 2, `void_array.astype(bool)`
would always return an array of
`True`
, unless the dtype is `V0`
. On Python 3, this operation would usually
crash. Going forwards, *astype* matches the behavior of `bool(np.void)`
,
considering a buffer of all zeros as false, and anything else as true.
Checks for `V0`
can still be done with `arr.dtype.itemsize == 0`
.

`MaskedArray.squeeze`
never returns `np.ma.masked`
[#](#maskedarray-squeeze-never-returns-np-ma-masked)
`np.squeeze`
is documented as returning a view, but the masked variant would
sometimes return `masked`
, which is not a view. This has been fixed, so that
the result is always a view on the original masked array.
This breaks any code that used `masked_arr.squeeze() is np.ma.masked`
, but
fixes code that writes to the result of *squeeze()*.
### Renamed first parameter of `can_cast`
from `from`
to `from_`
[#](#renamed-first-parameter-of-can-cast-from-from-to-from)
The previous parameter name `from`
is a reserved keyword in Python, which made
it difficult to pass the argument by name. This has been fixed by renaming
the parameter to `from_`
.

`isnat`
raises `TypeError`
when passed wrong type[#](#isnat-raises-typeerror-when-passed-wrong-type)
The ufunc `isnat`
used to raise a `ValueError`
when it was not passed
variables of type `datetime`
or `timedelta`
. This has been changed to
raising a `TypeError`
.

`dtype.__getitem__`
raises `TypeError`
when passed wrong type[#](#dtype-getitem-raises-typeerror-when-passed-wrong-type)
When indexed with a float, the dtype object used to raise `ValueError`
.

### User-defined types now need to implement `__str__`
and `__repr__`
[#](#user-defined-types-now-need-to-implement-str-and-repr)
Previously, user-defined types could fall back to a default implementation of
`__str__`
and `__repr__`
implemented in numpy, but this has now been
removed. Now user-defined types will fall back to the python default
`object.__str__`
and `object.__repr__`
.

### Many changes to array printing, disableable with the new “legacy” printing mode[#](#many-changes-to-array-printing-disableable-with-the-new-legacy-printing-mode)
The `str`
and `repr`
of ndarrays and numpy scalars have been changed in
a variety of ways. These changes are likely to break downstream user’s
doctests.

These new behaviors can be disabled to mostly reproduce numpy 1.13 behavior by
enabling the new 1.13 “legacy” printing mode. This is enabled by calling
`np.set_printoptions(legacy="1.13")`
, or using the new `legacy`
argument to
`np.array2string`
, as `np.array2string(arr, legacy='1.13')`
.

In summary, the major changes are:

For floating-point types:

The

`repr`
of float arrays often omits a space previously printed in the sign position. See the new`sign`
option to`np.set_printoptions`
.
Floating-point arrays and scalars use a new algorithm for decimal representations, giving the shortest unique representation. This will usually shorten

`float16`
fractional output, and sometimes`float32`
and`float128`
output.`float64`
should be unaffected. See the new`floatmode`
option to`np.set_printoptions`
.
Float arrays printed in scientific notation no longer use fixed-precision, and now instead show the shortest unique representation.

The

`str`
of floating-point scalars is no longer truncated in python2.
For other data types:

Non-finite complex scalars print like

`nanj`
instead of`nan*j`
.
`NaT`
values in datetime arrays are now properly aligned.
Arrays and scalars of

`np.void`
datatype are now printed using hex notation.
For line-wrapping:

The “dtype” part of ndarray reprs will now be printed on the next line if there isn’t space on the last line of array output.

The

`linewidth`
format option is now always respected. The*repr*or*str*of an array will never exceed this, unless a single element is too wide.
The last line of an array string will never have more elements than earlier lines.

An extra space is no longer inserted on the first line if the elements are too wide.

For summarization (the use of

`...`
to shorten long arrays):A trailing comma is no longer inserted for

`str`
. Previously,`str(np.arange(1001))`
gave`'[ 0 1 2 ..., 998 999 1000]'`
, which has an extra comma.
For arrays of 2-D and beyond, when

`...`
is printed on its own line in order to summarize any but the last axis, newlines are now appended to that line to match its leading newlines and a trailing space character is removed.
`MaskedArray`
arrays now separate printed elements with commas, always print the dtype, and correctly wrap the elements of long arrays to multiple lines. If there is more than 1 dimension, the array attributes are now printed in a new “left-justified” printing style.
`recarray`
arrays no longer print a trailing space before their dtype, and wrap to the right number of columns.
0d arrays no longer have their own idiosyncratic implementations of

`str`
and`repr`
. The`style`
argument to`np.array2string`
is deprecated.
Arrays of

`bool`
datatype will omit the datatype in the`repr`
.
User-defined

`dtypes`
(subclasses of`np.generic`
) now need to implement`__str__`
and`__repr__`
.
Some of these changes are described in more detail below. If you need to retain the previous behavior for doctests or other reasons, you may want to do something like:

```
# FIXME: We need the str/repr formatting used in Numpy < 1.14.
try:
np.set_printoptions(legacy='1.13')
except TypeError:
pass
```
## C API changes[#](#c-api-changes)
### PyPy compatible alternative to `UPDATEIFCOPY`
arrays[#](#pypy-compatible-alternative-to-updateifcopy-arrays)
`UPDATEIFCOPY`
arrays are contiguous copies of existing arrays, possibly with
different dimensions, whose contents are copied back to the original array when
their refcount goes to zero and they are deallocated. Because PyPy does not use
refcounts, they do not function correctly with PyPy. NumPy is in the process of
eliminating their use internally and two new C-API functions,
`PyArray_SetWritebackIfCopyBase`
`PyArray_ResolveWritebackIfCopy`
,
have been added together with a complementary flag,
`NPY_ARRAY_WRITEBACKIFCOPY`
. Using the new functionality also requires that
some flags be changed when new arrays are created, to wit:
`NPY_ARRAY_INOUT_ARRAY`
should be replaced by `NPY_ARRAY_INOUT_ARRAY2`
and
`NPY_ARRAY_INOUT_FARRAY`
should be replaced by `NPY_ARRAY_INOUT_FARRAY2`
.
Arrays created with these new flags will then have the `WRITEBACKIFCOPY`
semantics.

If PyPy compatibility is not a concern, these new functions can be ignored,
although there will be a `DeprecationWarning`
. If you do wish to pursue PyPy
compatibility, more information on these functions and their use may be found
in the [c-api](https://github.com/numpy/numpy/blob/master/doc/source/reference/c-api.array.rst) documentation and the example in [how-to-extend](https://github.com/numpy/numpy/blob/master/doc/source/user/c-info.how-to-extend.rst).

## New Features[#](#new-features)
### Encoding argument for text IO functions[#](#encoding-argument-for-text-io-functions)
`genfromtxt`
, `loadtxt`
, `fromregex`
and `savetxt`
can now handle files
with arbitrary encoding supported by Python via the encoding argument.
For backward compatibility the argument defaults to the special `bytes`
value
which continues to treat text as raw byte values and continues to pass latin1
encoded bytes to custom converters.
Using any other value (including `None`
for system default) will switch the
functions to real text IO so one receives unicode strings instead of bytes in
the resulting arrays.
### External `nose`
plugins are usable by `numpy.testing.Tester`
[#](#external-nose-plugins-are-usable-by-numpy-testing-tester)
`numpy.testing.Tester`
is now aware of `nose`
plugins that are outside the
`nose`
built-in ones. This allows using, for example, `nose-timer`
like
so: `np.test(extra_argv=['--with-timer', '--timer-top-n', '20'])`
to
obtain the runtime of the 20 slowest tests. An extra keyword `timer`
was
also added to `Tester.test`
, so `np.test(timer=20)`
will also report the 20
slowest tests.
`parametrize`
decorator added to `numpy.testing`
[#](#parametrize-decorator-added-to-numpy-testing)
A basic `parametrize`
decorator is now available in `numpy.testing`
. It is
intended to allow rewriting yield based tests that have been deprecated in
pytest so as to facilitate the transition to pytest in the future. The nose
testing framework has not been supported for several years and looks like
abandonware.

The new `parametrize`
decorator does not have the full functionality of the
one in pytest. It doesn’t work for classes, doesn’t support nesting, and does
not substitute variable names. Even so, it should be adequate to rewrite the
NumPy tests.

`chebinterpolate`
function added to `numpy.polynomial.chebyshev`
[#](#chebinterpolate-function-added-to-numpy-polynomial-chebyshev)
The new `chebinterpolate`
function interpolates a given function at the
Chebyshev points of the first kind. A new `Chebyshev.interpolate`
class
method adds support for interpolation over arbitrary intervals using the scaled
and shifted Chebyshev points of the first kind.

### Support for reading lzma compressed text files in Python 3[#](#support-for-reading-lzma-compressed-text-files-in-python-3)
With Python versions containing the `lzma`
module the text IO functions can
now transparently read from files with `xz`
or `lzma`
extension.

`sign`
option added to `np.setprintoptions`
and `np.array2string`
[#](#sign-option-added-to-np-setprintoptions-and-np-array2string)
This option controls printing of the sign of floating-point types, and may be one of the characters ‘-’, ‘+’ or ‘ ‘. With ‘+’ numpy always prints the sign of positive values, with ‘ ‘ it always prints a space (whitespace character) in the sign position of positive values, and with ‘-’ it will omit the sign character for positive values. The new default is ‘-‘.

This new default changes the float output relative to numpy 1.13. The old behavior can be obtained in 1.13 “legacy” printing mode, see compatibility notes above.

`hermitian`
option added to``np.linalg.matrix_rank``[#](#hermitian-option-added-to-np-linalg-matrix-rank)
The new `hermitian`
option allows choosing between standard SVD based matrix
rank calculation and the more efficient eigenvalue based method for
symmetric/hermitian matrices.

`threshold`
and `edgeitems`
options added to `np.array2string`
[#](#threshold-and-edgeitems-options-added-to-np-array2string)
These options could previously be controlled using `np.set_printoptions`
, but
now can be changed on a per-call basis as arguments to `np.array2string`
.

`concatenate`
and `stack`
gained an `out`
argument[#](#concatenate-and-stack-gained-an-out-argument)
A preallocated buffer of the desired dtype can now be used for the output of these functions.

### Support for PGI flang compiler on Windows[#](#support-for-pgi-flang-compiler-on-windows)
The PGI flang compiler is a Fortran front end for LLVM released by NVIDIA under the Apache 2 license. It can be invoked by

```
python setup.py config --compiler=clang --fcompiler=flang install
```
There is little experience with this new compiler, so any feedback from people using it will be appreciated.

## Improvements[#](#improvements)
### Numerator degrees of freedom in `random.noncentral_f`
need only be positive.[#](#numerator-degrees-of-freedom-in-random-noncentral-f-need-only-be-positive)
Prior to NumPy 1.14.0, the numerator degrees of freedom needed to be > 1, but the distribution is valid for values > 0, which is the new requirement.

### The GIL is released for all `np.einsum`
variations[#](#the-gil-is-released-for-all-np-einsum-variations)
Some specific loop structures which have an accelerated loop version did not release the GIL prior to NumPy 1.14.0. This oversight has been fixed.

### The *np.einsum* function will use BLAS when possible and optimize by default[#](#the-np-einsum-function-will-use-blas-when-possible-and-optimize-by-default)
The `np.einsum`
function will now call `np.tensordot`
when appropriate.
Because `np.tensordot`
uses BLAS when possible, that will speed up execution.
By default, `np.einsum`
will also attempt optimization as the overhead is
small relative to the potential improvement in speed.

`f2py`
now handles arrays of dimension 0[#](#f2py-now-handles-arrays-of-dimension-0)
`f2py`
now allows for the allocation of arrays of dimension 0. This allows
for more consistent handling of corner cases downstream.
`numpy.distutils`
supports using MSVC and mingw64-gfortran together[#](#numpy-distutils-supports-using-msvc-and-mingw64-gfortran-together)
Numpy distutils now supports using Mingw64 gfortran and MSVC compilers together. This enables the production of Python extension modules on Windows containing Fortran code while retaining compatibility with the binaries distributed by Python.org. Not all use cases are supported, but most common ways to wrap Fortran for Python are functional.

Compilation in this mode is usually enabled automatically, and can be
selected via the `--fcompiler`
and `--compiler`
options to
`setup.py`
. Moreover, linking Fortran codes to static OpenBLAS is
supported; by default a gfortran compatible static archive
`openblas.a`
is looked for.

`np.linalg.pinv`
now works on stacked matrices[#](#np-linalg-pinv-now-works-on-stacked-matrices)
Previously it was limited to a single 2d array.

`numpy.save`
aligns data to 64 bytes instead of 16[#](#numpy-save-aligns-data-to-64-bytes-instead-of-16)
Saving NumPy arrays in the `npy`
format with `numpy.save`
inserts
padding before the array data to align it at 64 bytes. Previously
this was only 16 bytes (and sometimes less due to a bug in the code
for version 2). Now the alignment is 64 bytes, which matches the
widest SIMD instruction set commonly available, and is also the most
common cache line size. This makes `npy`
files easier to use in
programs which open them with `mmap`
, especially on Linux where an
`mmap`
offset must be a multiple of the page size.

### NPZ files now can be written without using temporary files[#](#npz-files-now-can-be-written-without-using-temporary-files)
In Python 3.6+ `numpy.savez`
and `numpy.savez_compressed`
now write
directly to a ZIP file, without creating intermediate temporary files.

### Better support for empty structured and string types[#](#better-support-for-empty-structured-and-string-types)
Structured types can contain zero fields, and string dtypes can contain zero characters. Zero-length strings still cannot be created directly, and must be constructed through structured dtypes:

```
str0 = np.empty(10, np.dtype([('v', str, N)]))['v']
void0 = np.empty(10, np.void)
```
It was always possible to work with these, but the following operations are now supported for these arrays:

-
arr.sort()
-
arr.view(bytes)
-
arr.resize(…)
-
pickle.dumps(arr)
### Support for `decimal.Decimal`
in `np.lib.financial`
[#](#support-for-decimal-decimal-in-np-lib-financial)
Unless otherwise stated all functions within the `financial`
package now
support using the `decimal.Decimal`
built-in type.

### Float printing now uses “dragon4” algorithm for shortest decimal representation[#](#float-printing-now-uses-dragon4-algorithm-for-shortest-decimal-representation)
The `str`
and `repr`
of floating-point values (16, 32, 64 and 128 bit) are
now printed to give the shortest decimal representation which uniquely
identifies the value from others of the same type. Previously this was only
true for `float64`
values. The remaining float types will now often be shorter
than in numpy 1.13. Arrays printed in scientific notation now also use the
shortest scientific representation, instead of fixed precision as before.

Additionally, the

strof float scalars scalars will no longer be truncated in python2, unlike python2float`s. `np.doublescalars now have a`str`
and`repr`
identical to that of a python3 float.
New functions `np.format_float_scientific`
and `np.format_float_positional`
are provided to generate these decimal representations.

A new option `floatmode`
has been added to `np.set_printoptions`
and
`np.array2string`
, which gives control over uniqueness and rounding of
printed elements in an array. The new default is `floatmode='maxprec'`
with
`precision=8`
, which will print at most 8 fractional digits, or fewer if an
element can be uniquely represented with fewer. A useful new mode is
`floatmode="unique"`
, which will output enough digits to specify the array
elements uniquely.

Numpy complex-floating-scalars with values like `inf*j`
or `nan*j`
now
print as `infj`
and `nanj`
, like the pure-python `complex`
type.

The `FloatFormat`
and `LongFloatFormat`
classes are deprecated and should
both be replaced by `FloatingFormat`
. Similarly `ComplexFormat`
and
`LongComplexFormat`
should be replaced by `ComplexFloatingFormat`
.

`void`
datatype elements are now printed in hex notation[#](#void-datatype-elements-are-now-printed-in-hex-notation)
A hex representation compatible with the python `bytes`
type is now printed
for unstructured `np.void`
elements, e.g., `V4`
datatype. Previously, in
python2 the raw void data of the element was printed to stdout, or in python3
the integer byte values were shown.

### printing style for `void`
datatypes is now independently customizable[#](#printing-style-for-void-datatypes-is-now-independently-customizable)
The printing style of `np.void`
arrays is now independently customizable
using the `formatter`
argument to `np.set_printoptions`
, using the
`'void'`
key, instead of the catch-all `numpystr`
key as before.

### Reduced memory usage of `np.loadtxt`
[#](#reduced-memory-usage-of-np-loadtxt)
`np.loadtxt`
now reads files in chunks instead of all at once which decreases
its memory usage significantly for large files.
## Changes[#](#changes)
### Multiple-field indexing/assignment of structured arrays[#](#multiple-field-indexing-assignment-of-structured-arrays)
The indexing and assignment of structured arrays with multiple fields has changed in a number of ways, as warned about in previous releases.

First, indexing a structured array with multiple fields, e.g.,
`arr[['f1', 'f3']]`
, returns a view into the original array instead of a
copy. The returned view will have extra padding bytes corresponding to
intervening fields in the original array, unlike the copy in 1.13, which will
affect code such as `arr[['f1', 'f3']].view(newdtype)`
.

Second, assignment between structured arrays will now occur “by position” instead of “by field name”. The Nth field of the destination will be set to the Nth field of the source regardless of field name, unlike in numpy versions 1.6 to 1.13 in which fields in the destination array were set to the identically-named field in the source array or to 0 if the source did not have a field.

Correspondingly, the order of fields in a structured dtypes now matters when computing dtype equality. For example, with the dtypes

```
x = dtype({'names': ['A', 'B'], 'formats': ['i4', 'f4'], 'offsets': [0, 4]})
y = dtype({'names': ['B', 'A'], 'formats': ['f4', 'i4'], 'offsets': [4, 0]})
```
the expression `x == y`
will now return `False`
, unlike before.
This makes dictionary based dtype specifications like
`dtype({'a': ('i4', 0), 'b': ('f4', 4)})`
dangerous in python < 3.6
since dict key order is not preserved in those versions.

Assignment from a structured array to a boolean array now raises a ValueError,
unlike in 1.13, where it always set the destination elements to `True`
.

Assignment from structured array with more than one field to a non-structured array now raises a ValueError. In 1.13 this copied just the first field of the source to the destination.

Using field “titles” in multiple-field indexing is now disallowed, as is repeating a field name in a multiple-field index.

The documentation for structured arrays in the user guide has been significantly updated to reflect these changes.

### Integer and Void scalars are now unaffected by `np.set_string_function`
[#](#integer-and-void-scalars-are-now-unaffected-by-np-set-string-function)
Previously, unlike most other numpy scalars, the `str`
and `repr`
of
integer and void scalars could be controlled by `np.set_string_function`
.
This is no longer possible.

### 0d array printing changed, `style`
arg of array2string deprecated[#](#d-array-printing-changed-style-arg-of-array2string-deprecated)
Previously the `str`
and `repr`
of 0d arrays had idiosyncratic
implementations which returned `str(a.item())`
and ```
'array(' +
repr(a.item()) + ')'
```
respectively for 0d array `a`
, unlike both numpy
scalars and higher dimension ndarrays.

Now, the `str`
of a 0d array acts like a numpy scalar using `str(a[()])`
and the `repr`
acts like higher dimension arrays using `formatter(a[()])`
,
where `formatter`
can be specified using `np.set_printoptions`
. The
`style`
argument of `np.array2string`
is deprecated.

This new behavior is disabled in 1.13 legacy printing mode, see compatibility notes above.

### Seeding `RandomState`
using an array requires a 1-d array[#](#seeding-randomstate-using-an-array-requires-a-1-d-array)
`RandomState`
previously would accept empty arrays or arrays with 2 or more
dimensions, which resulted in either a failure to seed (empty arrays) or for
some of the passed values to be ignored when setting the seed.
`MaskedArray`
objects show a more useful `repr`
[#](#maskedarray-objects-show-a-more-useful-repr)
The `repr`
of a `MaskedArray`
is now closer to the python code that would
produce it, with arrays now being shown with commas and dtypes. Like the other
formatting changes, this can be disabled with the 1.13 legacy printing mode in
order to help transition doctests.

### The `repr`
of `np.polynomial`
classes is more explicit[#](#the-repr-of-np-polynomial-classes-is-more-explicit)
It now shows the domain and window parameters as keyword arguments to make them more clear:

```
>>> np.polynomial.Polynomial(range(4))
Polynomial([0., 1., 2., 3.], domain=[-1, 1], window=[-1, 1])
```# NumPy 1.26.0 Release Notes[#](#numpy-1-26-0-release-notes)
The NumPy 1.26.0 release is a continuation of the 1.25.x release cycle with the addition of Python 3.12.0 support. Python 3.12 dropped distutils, consequently supporting it required finding a replacement for the setup.py/distutils based build system NumPy was using. We have chosen to use the Meson build system instead, and this is the first NumPy release supporting it. This is also the first release that supports Cython 3.0 in addition to retaining 0.29.X compatibility. Supporting those two upgrades was a large project, over 100 files have been touched in this release. The changelog doesn’t capture the full extent of the work, special thanks to Ralf Gommers, Sayed Adel, Stéfan van der Walt, and Matti Picus who did much of the work in the main development branch.

The highlights of this release are:

Python 3.12.0 support.

Cython 3.0.0 compatibility.

Use of the Meson build system

Updated SIMD support

f2py fixes, meson and bind(x) support

Support for the updated Accelerate BLAS/LAPACK library

The Python versions supported in this release are 3.9-3.12.

## New Features[#](#new-features)
### Array API v2022.12 support in `numpy.array_api`
[#](#array-api-v2022-12-support-in-numpy-array-api)
`numpy.array_api`
now full supports the[v2022.12 version](https://data-apis.org/array-api/2022.12)of the array API standard. Note that this does not yet include the optional`fft`
extension in the standard.
([gh-23789](https://github.com/numpy/numpy/pull/23789))

### Support for the updated Accelerate BLAS/LAPACK library[#](#support-for-the-updated-accelerate-blas-lapack-library)
Support for the updated Accelerate BLAS/LAPACK library, including ILP64 (64-bit integer) support, in macOS 13.3 has been added. This brings arm64 support, and significant performance improvements of up to 10x for commonly used linear algebra operations. When Accelerate is selected at build time, the 13.3+ version will automatically be used if available.

([gh-24053](https://github.com/numpy/numpy/pull/24053))

`meson`
backend for `f2py`
[#](#meson-backend-for-f2py)
`f2py`
in compile mode (i.e. `f2py -c`
) now accepts the `--backend meson`
option. This is the default option for Python `3.12`
on-wards. Older versions
will still default to `--backend distutils`
.
To support this in realistic use-cases, in compile mode `f2py`
takes a
`--dep`
flag one or many times which maps to `dependency()`
calls in the
`meson`
backend, and does nothing in the `distutils`
backend.

There are no changes for users of `f2py`
only as a code generator, i.e.
without `-c`
.

([gh-24532](https://github.com/numpy/numpy/pull/24532))

`bind(c)`
support for `f2py`
[#](#bind-c-support-for-f2py)
Both functions and subroutines can be annotated with `bind(c)`
. `f2py`
will
handle both the correct type mapping, and preserve the unique label for other
`C`
interfaces.

**Note:** `bind(c, name = 'routine_name_other_than_fortran_routine')`
is not
honored by the `f2py`
bindings by design, since `bind(c)`
with the `name`
is meant to guarantee only the same name in `C`
and `Fortran`
, not in
`Python`
and `Fortran`
.
([gh-24555](https://github.com/numpy/numpy/pull/24555))

## Improvements[#](#improvements)
`iso_c_binding`
support for `f2py`
[#](#iso-c-binding-support-for-f2py)
Previously, users would have to define their own custom `f2cmap`
file to use
type mappings defined by the Fortran2003 `iso_c_binding`
intrinsic module.
These type maps are now natively supported by `f2py`

([gh-24555](https://github.com/numpy/numpy/pull/24555))

## Build system changes[#](#build-system-changes)
In this release, NumPy has switched to Meson as the build system and
meson-python as the build backend. Installing NumPy or building a wheel can be
done with standard tools like `pip`
and `pypa/build`
. The following are
supported:

Regular installs:

`pip install numpy`
or (in a cloned repo)`pip install .`
Building a wheel:

`python -m build`
(preferred), or`pip wheel .`
Editable installs:

`pip install -e . --no-build-isolation`
Development builds through the custom CLI implemented with

[spin](https://github.com/scientific-python/spin):`spin build`
.
All the regular `pip`
and `pypa/build`
flags (e.g.,
`--no-build-isolation`
) should work as expected.

### NumPy-specific build customization[#](#numpy-specific-build-customization)
Many of the NumPy-specific ways of customizing builds have changed.
The `NPY_*`
environment variables which control BLAS/LAPACK, SIMD, threading,
and other such options are no longer supported, nor is a `site.cfg`
file to
select BLAS and LAPACK. Instead, there are command-line flags that can be
passed to the build via `pip`
/`build`
’s config-settings interface. These
flags are all listed in the `meson_options.txt`
file in the root of the repo.
Detailed documented will be available before the final 1.26.0 release; for now
please see [the SciPy “building from source” docs](http://scipy.github.io/devdocs/building/index.html) since most build
customization works in an almost identical way in SciPy as it does in NumPy.

### Build dependencies[#](#build-dependencies)
While the runtime dependencies of NumPy have not changed, the build
dependencies have. Because we temporarily vendor Meson and meson-python,
there are several new dependencies - please see the `[build-system]`
section
of `pyproject.toml`
for details.

### Troubleshooting[#](#troubleshooting)
This build system change is quite large. In case of unexpected issues, it is
still possible to use a `setup.py`
-based build as a temporary workaround (on
Python 3.9-3.11, not 3.12), by copying `pyproject.toml.setuppy`
to
`pyproject.toml`
. However, please open an issue with details on the NumPy
issue tracker. We aim to phase out `setup.py`
builds as soon as possible, and
therefore would like to see all potential blockers surfaced early on in the
1.26.0 release cycle.

## Contributors[#](#contributors)
A total of 20 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

@DWesl

Albert Steppi +

Bas van Beek

Charles Harris

Developer-Ecosystem-Engineering

Filipe Laíns +

Jake Vanderplas

Liang Yan +

Marten van Kerkwijk

Matti Picus

Melissa Weber Mendonça

Namami Shanker

Nathan Goldbaum

Ralf Gommers

Rohit Goswami

Sayed Adel

Sebastian Berg

Stefan van der Walt

Tyler Reddy

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 59 pull requests were merged for this release.

[#24305](https://github.com/numpy/numpy/pull/24305): MAINT: Prepare 1.26.x branch for development
[#24308](https://github.com/numpy/numpy/pull/24308): MAINT: Massive update of files from main for numpy 1.26
[#24322](https://github.com/numpy/numpy/pull/24322): CI: fix wheel builds on the 1.26.x branch
[#24326](https://github.com/numpy/numpy/pull/24326): BLD: update openblas to newer version
[#24327](https://github.com/numpy/numpy/pull/24327): TYP: Trim down the`_NestedSequence.__getitem__`
signature
[#24328](https://github.com/numpy/numpy/pull/24328): BUG: fix choose refcount leak
[#24337](https://github.com/numpy/numpy/pull/24337): TST: fix running the test suite in builds without BLAS/LAPACK
[#24338](https://github.com/numpy/numpy/pull/24338): BUG: random: Fix generation of nan by dirichlet.
[#24340](https://github.com/numpy/numpy/pull/24340): MAINT: Dependabot updates from main
[#24342](https://github.com/numpy/numpy/pull/24342): MAINT: Add back NPY_RUN_MYPY_IN_TESTSUITE=1
[#24353](https://github.com/numpy/numpy/pull/24353): MAINT: Update`extbuild.py`
from main.
[#24356](https://github.com/numpy/numpy/pull/24356): TST: fix distutils tests for deprecations in recent setuptools…
[#24375](https://github.com/numpy/numpy/pull/24375): MAINT: Update cibuildwheel to version 2.15.0
[#24381](https://github.com/numpy/numpy/pull/24381): MAINT: Fix codespaces setup.sh script
[#24403](https://github.com/numpy/numpy/pull/24403): ENH: Vendor meson for multi-target build support
[#24404](https://github.com/numpy/numpy/pull/24404): BLD: vendor meson-python to make the Windows builds with SIMD…
[#24405](https://github.com/numpy/numpy/pull/24405): BLD, SIMD: The meson CPU dispatcher implementation
[#24406](https://github.com/numpy/numpy/pull/24406): MAINT: Remove versioneer
[#24409](https://github.com/numpy/numpy/pull/24409): REL: Prepare for the NumPy 1.26.0b1 release.
[#24453](https://github.com/numpy/numpy/pull/24453): MAINT: Pin upper version of sphinx.
[#24455](https://github.com/numpy/numpy/pull/24455): ENH: Add prefix to _ALIGN Macro
[#24456](https://github.com/numpy/numpy/pull/24456): BUG: cleanup warnings [skip azp][skip circle][skip travis][skip…
[#24460](https://github.com/numpy/numpy/pull/24460): MAINT: Upgrade to spin 0.5
[#24495](https://github.com/numpy/numpy/pull/24495): BUG:`asv dev`
has been removed, use`asv run`
.
[#24496](https://github.com/numpy/numpy/pull/24496): BUG: Fix meson build failure due to unchanged inplace auto-generated…
[#24521](https://github.com/numpy/numpy/pull/24521): BUG: fix issue with git-version script, needs a shebang to run
[#24522](https://github.com/numpy/numpy/pull/24522): BUG: Use a default assignment for git_hash [skip ci]
[#24524](https://github.com/numpy/numpy/pull/24524): BUG: fix NPY_cast_info error handling in choose
[#24526](https://github.com/numpy/numpy/pull/24526): BUG: Fix common block handling in f2py
[#24541](https://github.com/numpy/numpy/pull/24541): CI,TYP: Bump mypy to 1.4.1
[#24542](https://github.com/numpy/numpy/pull/24542): BUG: Fix assumed length f2py regression
[#24544](https://github.com/numpy/numpy/pull/24544): MAINT: Harmonize fortranobject
[#24545](https://github.com/numpy/numpy/pull/24545): TYP: add kind argument to numpy.isin type specification
[#24561](https://github.com/numpy/numpy/pull/24561): BUG: fix comparisons between masked and unmasked structured arrays
[#24590](https://github.com/numpy/numpy/pull/24590): CI: Exclude import libraries from list of DLLs on Cygwin.
[#24591](https://github.com/numpy/numpy/pull/24591): BLD: fix`_umath_linalg`
dependencies
[#24594](https://github.com/numpy/numpy/pull/24594): MAINT: Stop testing on ppc64le.
[#24602](https://github.com/numpy/numpy/pull/24602): BLD: meson-cpu: fix SIMD support on platforms with no features
[#24606](https://github.com/numpy/numpy/pull/24606): BUG: Change Cython`binding`
directive to “False”.
[#24613](https://github.com/numpy/numpy/pull/24613): ENH: Adopt new macOS Accelerate BLAS/LAPACK Interfaces, including…
[#24614](https://github.com/numpy/numpy/pull/24614): DOC: Update building docs to use Meson
[#24615](https://github.com/numpy/numpy/pull/24615): TYP: Add the missing`casting`
keyword to`np.clip`
[#24616](https://github.com/numpy/numpy/pull/24616): TST: convert cython test from setup.py to meson
[#24617](https://github.com/numpy/numpy/pull/24617): MAINT: Fixup`fromnumeric.pyi`
[#24622](https://github.com/numpy/numpy/pull/24622): BUG, ENH: Fix`iso_c_binding`
type maps and fix`bind(c)`
…
[#24629](https://github.com/numpy/numpy/pull/24629): TYP: Allow`binary_repr`
to accept any object implementing…
[#24630](https://github.com/numpy/numpy/pull/24630): TYP: Explicitly declare`dtype`
and`generic`
hashable
[#24637](https://github.com/numpy/numpy/pull/24637): ENH: Refactor the typing “reveal” tests using`typing.assert_type`
[#24638](https://github.com/numpy/numpy/pull/24638): MAINT: Bump actions/checkout from 3.6.0 to 4.0.0
[#24647](https://github.com/numpy/numpy/pull/24647): ENH:`meson`
backend for`f2py`
[#24648](https://github.com/numpy/numpy/pull/24648): MAINT: Refactor partial load Workaround for Clang
[#24653](https://github.com/numpy/numpy/pull/24653): REL: Prepare for the NumPy 1.26.0rc1 release.
[#24659](https://github.com/numpy/numpy/pull/24659): BLD: allow specifying the long double format to avoid the runtime…
[#24665](https://github.com/numpy/numpy/pull/24665): BLD: fix bug in random.mtrand extension, don’t link libnpyrandom
[#24675](https://github.com/numpy/numpy/pull/24675): BLD: build wheels for 32-bit Python on Windows, using MSVC
[#24700](https://github.com/numpy/numpy/pull/24700): BLD: fix issue with compiler selection during cross compilation
[#24701](https://github.com/numpy/numpy/pull/24701): BUG: Fix data stmt handling for complex values in f2py
[#24707](https://github.com/numpy/numpy/pull/24707): TYP: Add annotations for the py3.12 buffer protocol
[#24718](https://github.com/numpy/numpy/pull/24718): DOC: fix a few doc build issues on 1.26.x and update*spin docs*…# NumPy 1.16.1 Release Notes[#](#numpy-1-16-1-release-notes)
The NumPy 1.16.1 release fixes bugs reported against the 1.16.0 release, and also backports several enhancements from master that seem appropriate for a release series that is the last to support Python 2.7. The wheels on PyPI are linked with OpenBLAS v0.3.4+, which should fix the known threading issues found in previous OpenBLAS versions.

Downstream developers building this release should use Cython >= 0.29.2 and, if using OpenBLAS, OpenBLAS > v0.3.4.

If you are installing using pip, you may encounter a problem with older
installed versions of NumPy that pip did not delete becoming mixed with the
current version, resulting in an `ImportError`
. That problem is particularly
common on Debian derived distributions due to a modified pip. The fix is to
make sure all previous NumPy versions installed by pip have been removed. See
[#12736](https://github.com/numpy/numpy/issues/12736) for discussion of the
issue. Note that previously this problem resulted in an `AttributeError`
.

## Contributors[#](#contributors)
A total of 16 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Antoine Pitrou

Arcesio Castaneda Medina +

Charles Harris

Chris Markiewicz +

Christoph Gohlke

Christopher J. Markiewicz +

Daniel Hrisca +

EelcoPeacs +

Eric Wieser

Kevin Sheppard

Matti Picus

OBATA Akio +

Ralf Gommers

Sebastian Berg

Stephan Hoyer

Tyler Reddy

## Enhancements[#](#enhancements)
[#12767](https://github.com/numpy/numpy/pull/12767): ENH: add mm->q floordiv
[#12768](https://github.com/numpy/numpy/pull/12768): ENH: port np.core.overrides to C for speed
[#12769](https://github.com/numpy/numpy/pull/12769): ENH: Add np.ctypeslib.as_ctypes_type(dtype), improve*np.ctypeslib.as_ctypes*
[#12773](https://github.com/numpy/numpy/pull/12773): ENH: add “max difference” messages to np.testing.assert_array_equal…
[#12820](https://github.com/numpy/numpy/pull/12820): ENH: Add mm->qm divmod
[#12890](https://github.com/numpy/numpy/pull/12890): ENH: add _dtype_ctype to namespace for freeze analysis
## Compatibility notes[#](#compatibility-notes)
The changed error message emitted by array comparison testing functions may affect doctests. See below for detail.

Casting from double and single denormals to float16 has been corrected. In some rare cases, this may result in results being rounded up instead of down, changing the last bit (ULP) of the result.

## New Features[#](#new-features)
### divmod operation is now supported for two `timedelta64`
operands[#](#divmod-operation-is-now-supported-for-two-timedelta64-operands)
The divmod operator now handles two `np.timedelta64`
operands, with
type signature `mm->qm`
.

## Improvements[#](#improvements)
### Further improvements to `ctypes`
support in `np.ctypeslib`
[#](#further-improvements-to-ctypes-support-in-np-ctypeslib)
A new [ numpy.ctypeslib.as_ctypes_type](../reference/routines.ctypeslib.html#numpy.ctypeslib.as_ctypes_type) function has been added, which can be
used to converts a

*dtype*into a best-guess
[type. Thanks to this new function,](https://docs.python.org/3/library/ctypes.html#module-ctypes)
`ctypes`
[now supports a much wider range of array types, including structures, booleans, and integers of non-native endianness.](../reference/routines.ctypeslib.html#numpy.ctypeslib.as_ctypes)
`numpy.ctypeslib.as_ctypes`
### Array comparison assertions include maximum differences[#](#array-comparison-assertions-include-maximum-differences)
Error messages from array comparison tests such as
*np.testing.assert_allclose* now include “max absolute difference” and
“max relative difference,” in addition to the previous “mismatch” percentage.
This information makes it easier to update absolute and relative error
tolerances.

## Changes[#](#changes)
`timedelta64 % 0`
behavior adjusted to return `NaT`
[#](#timedelta64-0-behavior-adjusted-to-return-nat)
The modulus operation with two `np.timedelta64`
operands now returns
`NaT`
in the case of division by zero, rather than returning zero# NumPy 1.24 Release Notes[#](#numpy-1-24-release-notes)
The NumPy 1.24.0 release continues the ongoing work to improve the handling and promotion of dtypes, increase the execution speed, and clarify the documentation. There are also a large number of new and expired deprecations due to changes in promotion and cleanups. This might be called a deprecation release. Highlights are

Many new deprecations, check them out.

Many expired deprecations,

New F2PY features and fixes.

New “dtype” and “casting” keywords for stacking functions.

See below for the details,

This release supports Python versions 3.8-3.11.

## Deprecations[#](#deprecations)
### Deprecate fastCopyAndTranspose and PyArray_CopyAndTranspose[#](#deprecate-fastcopyandtranspose-and-pyarray-copyandtranspose)
The `numpy.fastCopyAndTranspose`
function has been deprecated. Use the
corresponding copy and transpose methods directly:

```
arr.T.copy()
```
The underlying C function `PyArray_CopyAndTranspose`
has also been deprecated
from the NumPy C-API.

([gh-22313](https://github.com/numpy/numpy/pull/22313))

### Conversion of out-of-bound Python integers[#](#conversion-of-out-of-bound-python-integers)
Attempting a conversion from a Python integer to a NumPy value will now always
check whether the result can be represented by NumPy. This means the following
examples will fail in the future and give a `DeprecationWarning`
now:

```
np.uint8(-1)
np.array([3000], dtype=np.int8)
```
Many of these did succeed before. Such code was mainly useful for unsigned
integers with negative values such as `np.uint8(-1)`
giving
`np.iinfo(np.uint8).max`
.

Note that conversion between NumPy integers is unaffected, so that
`np.array(-1).astype(np.uint8)`
continues to work and use C integer overflow
logic. For negative values, it will also work to view the array:
`np.array(-1, dtype=np.int8).view(np.uint8)`
.
In some cases, using `np.iinfo(np.uint8).max`
or `val % 2**8`
may also
work well.

In rare cases input data may mix both negative values and very large unsigned
values (i.e. `-1`
and `2**63`
). There it is unfortunately necessary
to use `%`
on the Python value or use signed or unsigned conversion
depending on whether negative values are expected.

([gh-22385](https://github.com/numpy/numpy/pull/22385))

### Deprecate `msort`
[#](#deprecate-msort)
The `numpy.msort`
function is deprecated. Use `np.sort(a, axis=0)`
instead.

([gh-22456](https://github.com/numpy/numpy/pull/22456))

`np.str0`
and similar are now deprecated[#](#np-str0-and-similar-are-now-deprecated)
The scalar type aliases ending in a 0 bit size: `np.object0`
, `np.str0`
,
`np.bytes0`
, `np.void0`
, `np.int0`
, `np.uint0`
as well as `np.bool8`
are now deprecated and will eventually be removed.

([gh-22607](https://github.com/numpy/numpy/pull/22607))

## Expired deprecations[#](#expired-deprecations)
The

`normed`
keyword argument has been removed from*np.histogram*,*np.histogram2d*, and*np.histogramdd*. Use`density`
instead. If`normed`
was passed by position,`density`
is now used.(

[gh-21645](https://github.com/numpy/numpy/pull/21645))
Ragged array creation will now always raise a

`ValueError`
unless`dtype=object`
is passed. This includes very deeply nested sequences.(

[gh-22004](https://github.com/numpy/numpy/pull/22004))
Support for Visual Studio 2015 and earlier has been removed.

Support for the Windows Interix POSIX interop layer has been removed.

(

[gh-22139](https://github.com/numpy/numpy/pull/22139))
Support for Cygwin < 3.3 has been removed.

(

[gh-22159](https://github.com/numpy/numpy/pull/22159))
The mini() method of

`np.ma.MaskedArray`
has been removed. Use either`np.ma.MaskedArray.min()`
or`np.ma.minimum.reduce()`
.
The single-argument form of

`np.ma.minimum`
and`np.ma.maximum`
has been removed. Use`np.ma.minimum.reduce()`
or`np.ma.maximum.reduce()`
instead.(

[gh-22228](https://github.com/numpy/numpy/pull/22228))
Passing dtype instances other than the canonical (mainly native byte-order) ones to

`dtype=`
or`signature=`
in ufuncs will now raise a`TypeError`
. We recommend passing the strings`"int8"`
or scalar types`np.int8`
since the byte-order, datetime/timedelta unit, etc. are never enforced. (Initially deprecated in NumPy 1.21.)(

[gh-22540](https://github.com/numpy/numpy/pull/22540))
The

`dtype=`
argument to comparison ufuncs is now applied correctly. That means that only`bool`
and`object`
are valid values and`dtype=object`
is enforced.(

[gh-22541](https://github.com/numpy/numpy/pull/22541))
The deprecation for the aliases

`np.object`
,`np.bool`
,`np.float`
,`np.complex`
,`np.str`
, and`np.int`
is expired (introduces NumPy 1.20). Some of these will now give a FutureWarning in addition to raising an error since they will be mapped to the NumPy scalars in the future.(

[gh-22607](https://github.com/numpy/numpy/pull/22607))
## Compatibility notes[#](#compatibility-notes)
`array.fill(scalar)`
may behave slightly different[#](#array-fill-scalar-may-behave-slightly-different)
`numpy.ndarray.fill`
may in some cases behave slightly different now due to
the fact that the logic is aligned with item assignment:
```
arr = np.array([1]) # with any dtype/value
arr.fill(scalar)
# is now identical to:
arr[0] = scalar
```
Previously casting may have produced slightly different answers when using
values that could not be represented in the target `dtype`
or when the target
had `object`
dtype.

([gh-20924](https://github.com/numpy/numpy/pull/20924))

### Subarray to object cast now copies[#](#subarray-to-object-cast-now-copies)
Casting a dtype that includes a subarray to an object will now ensure a copy of the subarray. Previously an unsafe view was returned:

```
arr = np.ones(3, dtype=[("f", "i", 3)])
subarray_fields = arr.astype(object)[0]
subarray = subarray_fields[0] # "f" field
np.may_share_memory(subarray, arr)
```
Is now always false. While previously it was true for the specific cast.

([gh-21925](https://github.com/numpy/numpy/pull/21925))

### Returned arrays respect uniqueness of dtype kwarg objects[#](#returned-arrays-respect-uniqueness-of-dtype-kwarg-objects)
When the `dtype`
keyword argument is used with `np.array`
or
[ asarray](../reference/generated/numpy.asarray.html#numpy.asarray), the dtype of the returned array now always exactly
matches the dtype provided by the caller.

In some cases this change means that a *view* rather than the input array is
returned. The following is an example for this on 64bit Linux where `long`
and `longlong`
are the same precision but different `dtypes`
:

```
>>> arr = np.array([1, 2, 3], dtype="long")
>>> new_dtype = np.dtype("longlong")
>>> new = np.asarray(arr, dtype=new_dtype)
>>> new.dtype is new_dtype
True
>>> new is arr
False
```
Before the change, the `dtype`
did not match because `new is arr`
was
`True`
.

([gh-21995](https://github.com/numpy/numpy/pull/21995))

### DLPack export raises `BufferError`
[#](#dlpack-export-raises-buffererror)
When an array buffer cannot be exported via DLPack a `BufferError`
is now
always raised where previously `TypeError`
or `RuntimeError`
was raised.
This allows falling back to the buffer protocol or `__array_interface__`
when
DLPack was tried first.

([gh-22542](https://github.com/numpy/numpy/pull/22542))

### NumPy builds are no longer tested on GCC-6[#](#numpy-builds-are-no-longer-tested-on-gcc-6)
Ubuntu 18.04 is deprecated for GitHub actions and GCC-6 is not available on Ubuntu 20.04, so builds using that compiler are no longer tested. We still test builds using GCC-7 and GCC-8.

([gh-22598](https://github.com/numpy/numpy/pull/22598))

## New Features[#](#new-features)
### New attribute `symbol`
added to polynomial classes[#](#new-attribute-symbol-added-to-polynomial-classes)
The polynomial classes in the `numpy.polynomial`
package have a new
`symbol`
attribute which is used to represent the indeterminate of the
polynomial. This can be used to change the value of the variable when
printing:

```
>>> P_y = np.polynomial.Polynomial([1, 0, -1], symbol="y")
>>> print(P_y)
1.0 + 0.0·y¹ - 1.0·y²
```
Note that the polynomial classes only support 1D polynomials, so operations that involve polynomials with different symbols are disallowed when the result would be multivariate:

```
>>> P = np.polynomial.Polynomial([1, -1]) # default symbol is "x"
>>> P_z = np.polynomial.Polynomial([1, 1], symbol="z")
>>> P * P_z
Traceback (most recent call last)
...
ValueError: Polynomial symbols differ
```
The symbol can be any valid Python identifier. The default is `symbol=x`
,
consistent with existing behavior.

([gh-16154](https://github.com/numpy/numpy/pull/16154))

### F2PY support for Fortran `character`
strings[#](#f2py-support-for-fortran-character-strings)
F2PY now supports wrapping Fortran functions with:

character (e.g.

`character x`
)
character array (e.g.

`character, dimension(n) :: x`
)
character string (e.g.

`character(len=10) x`
)
and character string array (e.g.

`character(len=10), dimension(n, m) :: x`
)
arguments, including passing Python unicode strings as Fortran character string arguments.

([gh-19388](https://github.com/numpy/numpy/pull/19388))

### New function `np.show_runtime`
[#](#new-function-np-show-runtime)
A new function `numpy.show_runtime`
has been added to display the runtime
information of the machine in addition to `numpy.show_config`
which displays
the build-related information.

([gh-21468](https://github.com/numpy/numpy/pull/21468))

`strict`
option for `testing.assert_array_equal`
[#](#strict-option-for-testing-assert-array-equal)
The `strict`
option is now available for `testing.assert_array_equal`
.
Setting `strict=True`
will disable the broadcasting behaviour for scalars and
ensure that input arrays have the same data type.

([gh-21595](https://github.com/numpy/numpy/pull/21595))

### New parameter `equal_nan`
added to `np.unique`
[#](#new-parameter-equal-nan-added-to-np-unique)
`np.unique`
was changed in 1.21 to treat all `NaN`
values as equal and
return a single `NaN`
. Setting `equal_nan=False`
will restore pre-1.21
behavior to treat `NaNs`
as unique. Defaults to `True`
.
([gh-21623](https://github.com/numpy/numpy/pull/21623))

`casting`
and `dtype`
keyword arguments for `numpy.stack`
[#](#casting-and-dtype-keyword-arguments-for-numpy-stack)
The `casting`
and `dtype`
keyword arguments are now available for
`numpy.stack`
. To use them, write ```
np.stack(..., dtype=None,
casting='same_kind')
```
.

`casting`
and `dtype`
keyword arguments for `numpy.vstack`
[#](#casting-and-dtype-keyword-arguments-for-numpy-vstack)
The `casting`
and `dtype`
keyword arguments are now available for
`numpy.vstack`
. To use them, write ```
np.vstack(..., dtype=None,
casting='same_kind')
```
.

`casting`
and `dtype`
keyword arguments for `numpy.hstack`
[#](#casting-and-dtype-keyword-arguments-for-numpy-hstack)
The `casting`
and `dtype`
keyword arguments are now available for
`numpy.hstack`
. To use them, write ```
np.hstack(..., dtype=None,
casting='same_kind')
```
.

([gh-21627](https://github.com/numpy/numpy/pull/21627))

### The bit generator underlying the singleton RandomState can be changed[#](#the-bit-generator-underlying-the-singleton-randomstate-can-be-changed)
The singleton `RandomState`
instance exposed in the `numpy.random`
module
is initialized at startup with the `MT19937`
bit generator. The new function
`set_bit_generator`
allows the default bit generator to be replaced with a
user-provided bit generator. This function has been introduced to provide a
method allowing seamless integration of a high-quality, modern bit generator in
new code with existing code that makes use of the singleton-provided random
variate generating functions. The companion function `get_bit_generator`
returns the current bit generator being used by the singleton `RandomState`
.
This is provided to simplify restoring the original source of randomness if
required.

The preferred method to generate reproducible random numbers is to use a modern
bit generator in an instance of `Generator`
. The function `default_rng`
simplifies instantiation:

```
>>> rg = np.random.default_rng(3728973198)
>>> rg.random()
```
The same bit generator can then be shared with the singleton instance so that
calling functions in the `random`
module will use the same bit generator:

```
>>> orig_bit_gen = np.random.get_bit_generator()
>>> np.random.set_bit_generator(rg.bit_generator)
>>> np.random.normal()
```
The swap is permanent (until reversed) and so any call to functions in the
`random`
module will use the new bit generator. The original can be restored
if required for code to run correctly:

```
>>> np.random.set_bit_generator(orig_bit_gen)
```
([gh-21976](https://github.com/numpy/numpy/pull/21976))

`np.void`
now has a `dtype`
argument[#](#np-void-now-has-a-dtype-argument)
NumPy now allows constructing structured void scalars directly by
passing the `dtype`
argument to `np.void`
.

([gh-22316](https://github.com/numpy/numpy/pull/22316))

## Improvements[#](#improvements)
### F2PY Improvements[#](#f2py-improvements)
The generated extension modules don’t use the deprecated NumPy-C API anymore

Improved

`f2py`
generated exception messages
Numerous bug and

`flake8`
warning fixes
various CPP macros that one can use within C-expressions of signature files are prefixed with

`f2py_`
. For example, one should use`f2py_len(x)`
instead of`len(x)`
A new construct

`character(f2py_len=...)`
is introduced to support returning assumed length character strings (e.g.`character(len=*)`
) from wrapper functions
A hook to support rewriting `f2py`
internal data structures after reading all
its input files is introduced. This is required, for instance, for BC of SciPy
support where character arguments are treated as character strings arguments in
`C`
expressions.

([gh-19388](https://github.com/numpy/numpy/pull/19388))

### IBM zSystems Vector Extension Facility (SIMD)[#](#ibm-zsystems-vector-extension-facility-simd)
Added support for SIMD extensions of zSystem (z13, z14, z15), through the universal intrinsics interface. This support leads to performance improvements for all SIMD kernels implemented using the universal intrinsics, including the following operations: rint, floor, trunc, ceil, sqrt, absolute, square, reciprocal, tanh, sin, cos, equal, not_equal, greater, greater_equal, less, less_equal, maximum, minimum, fmax, fmin, argmax, argmin, add, subtract, multiply, divide.

([gh-20913](https://github.com/numpy/numpy/pull/20913))

### NumPy now gives floating point errors in casts[#](#numpy-now-gives-floating-point-errors-in-casts)
In most cases, NumPy previously did not give floating point warnings or errors when these happened during casts. For examples, casts like:

```
np.array([2e300]).astype(np.float32) # overflow for float32
np.array([np.inf]).astype(np.int64)
```
Should now generally give floating point warnings. These warnings should warn that floating point overflow occurred. For errors when converting floating point values to integers users should expect invalid value warnings.

Users can modify the behavior of these warnings using `np.errstate`
.

Note that for float to int casts, the exact warnings that are given may be platform dependent. For example:

```
arr = np.full(100, fill_value=1000, dtype=np.float64)
arr.astype(np.int8)
```
May give a result equivalent to (the intermediate cast means no warning is given):

```
arr.astype(np.int64).astype(np.int8)
```
May return an undefined result, with a warning set:

```
RuntimeWarning: invalid value encountered in cast
```
The precise behavior is subject to the C99 standard and its implementation in both software and hardware.

([gh-21437](https://github.com/numpy/numpy/pull/21437))

### F2PY supports the value attribute[#](#f2py-supports-the-value-attribute)
The Fortran standard requires that variables declared with the `value`
attribute must be passed by value instead of reference. F2PY now supports this
use pattern correctly. So `integer, intent(in), value :: x`
in Fortran codes
will have correct wrappers generated.

([gh-21807](https://github.com/numpy/numpy/pull/21807))

### Added pickle support for third-party BitGenerators[#](#added-pickle-support-for-third-party-bitgenerators)
The pickle format for bit generators was extended to allow each bit generator
to supply its own constructor when during pickling. Previous versions of NumPy
only supported unpickling `Generator`
instances created with one of the core
set of bit generators supplied with NumPy. Attempting to unpickle a
`Generator`
that used a third-party bit generators would fail since the
constructor used during the unpickling was only aware of the bit generators
included in NumPy.

([gh-22014](https://github.com/numpy/numpy/pull/22014))

### arange() now explicitly fails with dtype=str[#](#arange-now-explicitly-fails-with-dtype-str)
Previously, the `np.arange(n, dtype=str)`
function worked for `n=1`
and
`n=2`
, but would raise a non-specific exception message for other values of
`n`
. Now, it raises a *TypeError* informing that `arange`
does not support
string dtypes:

```
>>> np.arange(2, dtype=str)
Traceback (most recent call last)
...
TypeError: arange() not supported for inputs with DType <class 'numpy.dtype[str_]'>.
```
([gh-22055](https://github.com/numpy/numpy/pull/22055))

`numpy.typing`
protocols are now runtime checkable[#](#numpy-typing-protocols-are-now-runtime-checkable)
The protocols used in `numpy.typing.ArrayLike`
and `numpy.typing.DTypeLike`
are now properly marked as runtime checkable, making them easier to use for
runtime type checkers.

([gh-22357](https://github.com/numpy/numpy/pull/22357))

## Performance improvements and changes[#](#performance-improvements-and-changes)
### Faster version of `np.isin`
and `np.in1d`
for integer arrays[#](#faster-version-of-np-isin-and-np-in1d-for-integer-arrays)
`np.in1d`
(used by `np.isin`
) can now switch to a faster algorithm (up to
>10x faster) when it is passed two integer arrays. This is often automatically
used, but you can use `kind="sort"`
or `kind="table"`
to force the old or
new method, respectively.
([gh-12065](https://github.com/numpy/numpy/pull/12065))

### Faster comparison operators[#](#faster-comparison-operators)
The comparison functions (`numpy.equal`
, `numpy.not_equal`
, `numpy.less`
,
`numpy.less_equal`
, `numpy.greater`
and `numpy.greater_equal`
) are now
much faster as they are now vectorized with universal intrinsics. For a CPU
with SIMD extension AVX512BW, the performance gain is up to 2.57x, 1.65x and
19.15x for integer, float and boolean data types, respectively (with N=50000).

([gh-21483](https://github.com/numpy/numpy/pull/21483))

## Changes[#](#changes)
### Better reporting of integer division overflow[#](#better-reporting-of-integer-division-overflow)
Integer division overflow of scalars and arrays used to provide a
`RuntimeWarning`
and the return value was undefined leading to crashes at
rare occasions:

```
>>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)
<stdin>:1: RuntimeWarning: divide by zero encountered in floor_divide
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)
```
Integer division overflow now returns the input dtype’s minimum value and raise
the following `RuntimeWarning`
:

```
>>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)
<stdin>:1: RuntimeWarning: overflow encountered in floor_divide
array([-2147483648, -2147483648, -2147483648, -2147483648, -2147483648,
-2147483648, -2147483648, -2147483648, -2147483648, -2147483648],
dtype=int32)
```
([gh-21506](https://github.com/numpy/numpy/pull/21506))

`masked_invalid`
now modifies the mask in-place[#](#masked-invalid-now-modifies-the-mask-in-place)
When used with `copy=False`
, `numpy.ma.masked_invalid`
now modifies the
input masked array in-place. This makes it behave identically to
`masked_where`
and better matches the documentation.

([gh-22046](https://github.com/numpy/numpy/pull/22046))

`nditer`
/`NpyIter`
allows all allocating all operands[#](#nditer-npyiter-allows-all-allocating-all-operands)
The NumPy iterator available through `np.nditer`
in Python and as `NpyIter`
in C now supports allocating all arrays. The iterator shape defaults to `()`
in this case. The operands dtype must be provided, since a “common dtype”
cannot be inferred from the other inputs.

([gh-22457](https://github.com/numpy/numpy/pull/22457))# NumPy 1.14.4 Release Notes[#](#numpy-1-14-4-release-notes)
This is a bugfix release for bugs reported following the 1.14.3 release. The most significant fixes are:

fixes for compiler instruction reordering that resulted in NaN’s not being properly propagated in

*np.max*and*np.min*,
fixes for bus faults on SPARC and older ARM due to incorrect alignment checks.

There are also improvements to printing of long doubles on PPC platforms. All is not yet perfect on that platform, the whitespace padding is still incorrect and is to be fixed in numpy 1.15, consequently NumPy still fails some printing-related (and other) unit tests on ppc systems. However, the printed values are now correct.

Note that NumPy will error on import if it detects incorrect float32 *dot*
results. This problem has been seen on the Mac when working in the Anaconda
environment and is due to a subtle interaction between MKL and PyQt5. It is not
strictly a NumPy problem, but it is best that users be aware of it. See the
gh-8577 NumPy issue for more information.

The Python versions supported in this release are 2.7 and 3.4 - 3.6. The Python 3.6 wheels available from PIP are built with Python 3.6.2 and should be compatible with all previous versions of Python 3.6. The source releases were cythonized with Cython 0.28.2 and should work for the upcoming Python 3.7.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Charles Harris

Marten van Kerkwijk

Matti Picus

Pauli Virtanen

Ryan Soklaski +

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 11 pull requests were merged for this release.

[#11104](https://github.com/numpy/numpy/pull/11104): BUG: str of DOUBLE_DOUBLE format wrong on ppc64
[#11170](https://github.com/numpy/numpy/pull/11170): TST: linalg: add regression test for gh-8577
[#11174](https://github.com/numpy/numpy/pull/11174): MAINT: add sanity-checks to be run at import time
[#11181](https://github.com/numpy/numpy/pull/11181): BUG: void dtype setup checked offset not actual pointer for alignment
[#11194](https://github.com/numpy/numpy/pull/11194): BUG: Python2 doubles don’t print correctly in interactive shell.
[#11198](https://github.com/numpy/numpy/pull/11198): BUG: optimizing compilers can reorder call to npy_get_floatstatus
[#11199](https://github.com/numpy/numpy/pull/11199): BUG: reduce using SSE only warns if inside SSE loop
[#11203](https://github.com/numpy/numpy/pull/11203): BUG: Bytes delimiter/comments in genfromtxt should be decoded
[#11211](https://github.com/numpy/numpy/pull/11211): BUG: Fix reference count/memory leak exposed by better testing
[#11219](https://github.com/numpy/numpy/pull/11219): BUG: Fixes einsum broadcasting bug when optimize=True
[#11251](https://github.com/numpy/numpy/pull/11251): DOC: Document 1.14.4 release.# NumPy 1.22.3 Release Notes[#](#numpy-1-22-3-release-notes)
NumPy 1.22.3 is a maintenance release that fixes bugs discovered after the 1.22.2 release. The most noticeable fixes may be those for DLPack. One that may cause some problems is disallowing strings as inputs to logical ufuncs. It is still undecided how strings should be treated in those functions and it was thought best to simply disallow them until a decision was reached. That should not cause problems with older code.

The Python versions supported for this release are 3.8-3.10. Note that the Mac wheels are now based on OS X 10.14 rather than 10.9 that was used in previous NumPy release cycles. 10.14 is the oldest release supported by Apple.

## Contributors[#](#contributors)
A total of 9 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

@GalaxySnail +

Alexandre de Siqueira

Bas van Beek

Charles Harris

Melissa Weber Mendonça

Ross Barnowski

Sebastian Berg

Tirth Patel

Matthieu Darbois

## Pull requests merged[#](#pull-requests-merged)
A total of 10 pull requests were merged for this release.

[#21048](https://github.com/numpy/numpy/pull/21048): MAINT: Use “3.10” instead of “3.10-dev” on travis.
[#21106](https://github.com/numpy/numpy/pull/21106): TYP,MAINT: Explicitly allow sequences of array-likes in`np.concatenate`
[#21137](https://github.com/numpy/numpy/pull/21137): BLD,DOC: skip broken ipython 8.1.0
[#21138](https://github.com/numpy/numpy/pull/21138): BUG, ENH: np._from_dlpack: export correct device information
[#21139](https://github.com/numpy/numpy/pull/21139): BUG: Fix numba DUFuncs added loops getting picked up
[#21140](https://github.com/numpy/numpy/pull/21140): BUG: Fix unpickling an empty ndarray with a non-zero dimension…
[#21141](https://github.com/numpy/numpy/pull/21141): BUG: use ThreadPoolExecutor instead of ThreadPool
[#21142](https://github.com/numpy/numpy/pull/21142): API: Disallow strings in logical ufuncs
[#21143](https://github.com/numpy/numpy/pull/21143): MAINT, DOC: Fix SciPy intersphinx link
[#21148](https://github.com/numpy/numpy/pull/21148): BUG,ENH: np._from_dlpack: export arrays with any strided size-1…# NumPy 1.22.0 Release Notes[#](#numpy-1-22-0-release-notes)
NumPy 1.22.0 is a big release featuring the work of 153 contributors spread over 609 pull requests. There have been many improvements, highlights are:

Annotations of the main namespace are essentially complete. Upstream is a moving target, so there will likely be further improvements, but the major work is done. This is probably the most user visible enhancement in this release.

A preliminary version of the proposed Array-API is provided. This is a step in creating a standard collection of functions that can be used across applications such as CuPy and JAX.

NumPy now has a DLPack backend. DLPack provides a common interchange format for array (tensor) data.

New methods for

`quantile`
,`percentile`
, and related functions. The new methods provide a complete set of the methods commonly found in the literature.
The universal functions have been refactored to implement most of

[NEP 43](https://numpy.org/neps/nep-0043-extensible-ufuncs.html#nep43). This also unlocks the ability to experiment with the future DType API.
A new configurable allocator for use by downstream projects.

These are in addition to the ongoing work to provide SIMD support for commonly used functions, improvements to F2PY, and better documentation.

The Python versions supported in this release are 3.8-3.10, Python 3.7 has been dropped. Note that the Mac wheels are now based on OS X 10.14 rather than 10.9 that was used in previous NumPy release cycles. 10.14 is the oldest release supported by Apple. Also note that 32 bit wheels are only provided for Python 3.8 and 3.9 on Windows, all other wheels are 64 bits on account of Ubuntu, Fedora, and other Linux distributions dropping 32 bit support. All 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix the occasional problems encountered by folks using truly huge arrays.

## Expired deprecations[#](#expired-deprecations)
### Deprecated numeric style dtype strings have been removed[#](#deprecated-numeric-style-dtype-strings-have-been-removed)
Using the strings `"Bytes0"`
, `"Datetime64"`
, `"Str0"`
, `"Uint32"`
,
and `"Uint64"`
as a dtype will now raise a `TypeError`
.

([gh-19539](https://github.com/numpy/numpy/pull/19539))

### Expired deprecations for `loads`
, `ndfromtxt`
, and `mafromtxt`
in npyio[#](#expired-deprecations-for-loads-ndfromtxt-and-mafromtxt-in-npyio)
`numpy.loads`
was deprecated in v1.15, with the recommendation that users use
`pickle.loads`
instead. `ndfromtxt`
and `mafromtxt`
were both deprecated
in v1.17 - users should use `numpy.genfromtxt`
instead with the appropriate
value for the `usemask`
parameter.
([gh-19615](https://github.com/numpy/numpy/pull/19615))

## Deprecations[#](#deprecations)
### Use delimiter rather than delimitor as kwarg in mrecords[#](#use-delimiter-rather-than-delimitor-as-kwarg-in-mrecords)
The misspelled keyword argument `delimitor`
of
`numpy.ma.mrecords.fromtextfile()`
has been changed to `delimiter`
, using
it will emit a deprecation warning.

([gh-19921](https://github.com/numpy/numpy/pull/19921))

### Passing boolean `kth`
values to (arg-)partition has been deprecated[#](#passing-boolean-kth-values-to-arg-partition-has-been-deprecated)
`numpy.partition`
and `numpy.argpartition`
would previously accept boolean
values for the `kth`
parameter, which would subsequently be converted into
integers. This behavior has now been deprecated.
([gh-20000](https://github.com/numpy/numpy/pull/20000))

### The `np.MachAr`
class has been deprecated[#](#the-np-machar-class-has-been-deprecated)
The `numpy.MachAr`
class and `finfo.machar <numpy.finfo>`
attribute have
been deprecated. Users are encouraged to access the property if interest
directly from the corresponding `numpy.finfo`
attribute.

([gh-20201](https://github.com/numpy/numpy/pull/20201))

## Compatibility notes[#](#compatibility-notes)
### Distutils forces strict floating point model on clang[#](#distutils-forces-strict-floating-point-model-on-clang)
NumPy now sets the `-ftrapping-math`
option on clang to enforce correct
floating point error handling for universal functions. Clang defaults to
non-IEEE and C99 conform behaviour otherwise. This change (using the
equivalent but newer `-ffp-exception-behavior=strict`
) was attempted in NumPy
1.21, but was effectively never used.

([gh-19479](https://github.com/numpy/numpy/pull/19479))

### Removed floor division support for complex types[#](#removed-floor-division-support-for-complex-types)
Floor division of complex types will now result in a `TypeError`

```
>>> a = np.arange(10) + 1j* np.arange(10)
>>> a // 1
TypeError: ufunc 'floor_divide' not supported for the input types...
```
([gh-19135](https://github.com/numpy/numpy/pull/19135))

`numpy.vectorize`
functions now produce the same output class as the base function[#](#numpy-vectorize-functions-now-produce-the-same-output-class-as-the-base-function)
When a function that respects `numpy.ndarray`
subclasses is vectorized using
`numpy.vectorize`
, the vectorized function will now be subclass-safe also for
cases that a signature is given (i.e., when creating a `gufunc`
): the output
class will be the same as that returned by the first call to the underlying
function.

([gh-19356](https://github.com/numpy/numpy/pull/19356))

### Python 3.7 is no longer supported[#](#python-3-7-is-no-longer-supported)
Python support has been dropped. This is rather strict, there are changes that require Python >= 3.8.

([gh-19665](https://github.com/numpy/numpy/pull/19665))

### str/repr of complex dtypes now include space after punctuation[#](#str-repr-of-complex-dtypes-now-include-space-after-punctuation)
The repr of `np.dtype({"names": ["a"], "formats": [int], "offsets": [2]})`
is
now ```
dtype({'names': ['a'], 'formats': ['<i8'], 'offsets': [2], 'itemsize':
10})
```
, whereas spaces where previously omitted after colons and between
fields.

The old behavior can be restored via `np.set_printoptions(legacy="1.21")`
.

([gh-19687](https://github.com/numpy/numpy/pull/19687))

### Corrected `advance`
in `PCG64DSXM`
and `PCG64`
[#](#corrected-advance-in-pcg64dsxm-and-pcg64)
Fixed a bug in the `advance`
method of `PCG64DSXM`
and `PCG64`
. The bug
only affects results when the step was larger than \(2^{64}\) on platforms
that do not support 128-bit integers(e.g., Windows and 32-bit Linux).

([gh-20049](https://github.com/numpy/numpy/pull/20049))

### Change in generation of random 32 bit floating point variates[#](#change-in-generation-of-random-32-bit-floating-point-variates)
There was bug in the generation of 32 bit floating point values from the uniform distribution that would result in the least significant bit of the random variate always being 0. This has been fixed.

This change affects the variates produced by the `random.Generator`
methods
`random`
, `standard_normal`
, `standard_exponential`
, and
`standard_gamma`
, but only when the dtype is specified as `numpy.float32`
.

([gh-20314](https://github.com/numpy/numpy/pull/20314))

## C API changes[#](#c-api-changes)
### Masked inner-loops cannot be customized anymore[#](#masked-inner-loops-cannot-be-customized-anymore)
The masked inner-loop selector is now never used. A warning will be given in the unlikely event that it was customized.

We do not expect that any code uses this. If you do use it, you must unset the selector on newer NumPy version. Please also contact the NumPy developers, we do anticipate providing a new, more specific, mechanism.

The customization was part of a never-implemented feature to allow for faster masked operations.

([gh-19259](https://github.com/numpy/numpy/pull/19259))

### Experimental exposure of future DType and UFunc API[#](#experimental-exposure-of-future-dtype-and-ufunc-api)
The new header `experimental_public_dtype_api.h`
allows to experiment with
future API for improved universal function and especially user DType support.
At this time it is advisable to experiment using the development version
of NumPy since some changes are expected and new features will be unlocked.

([gh-19919](https://github.com/numpy/numpy/pull/19919))

## New Features[#](#new-features)
### NEP 49 configurable allocators[#](#nep-49-configurable-allocators)
As detailed in [NEP 49](https://numpy.org/neps/nep-0049.html), the function used for allocation of the data segment
of a ndarray can be changed. The policy can be set globally or in a context.
For more information see the NEP and the [Memory management in NumPy](../reference/c-api/data_memory.html#data-memory) reference docs.
Also add a `NUMPY_WARN_IF_NO_MEM_POLICY`
override to warn on dangerous use
of transfering ownership by setting `NPY_ARRAY_OWNDATA`
.

([gh-17582](https://github.com/numpy/numpy/pull/17582))

### Implementation of the NEP 47 (adopting the array API standard)[#](#implementation-of-the-nep-47-adopting-the-array-api-standard)
An initial implementation of [NEP 47](https://numpy.org/neps/nep-0047-array-api-standard.html) (adoption the array API standard) has
been added as `numpy.array_api`
. The implementation is experimental and will
issue a UserWarning on import, as the [array API standard](https://data-apis.org/array-api/latest/index.html) is still in draft state.
`numpy.array_api`
is a conforming implementation of the array API standard,
which is also minimal, meaning that only those functions and behaviors that are
required by the standard are implemented (see the NEP for more info).
Libraries wishing to make use of the array API standard are encouraged to use
`numpy.array_api`
to check that they are only using functionality that is
guaranteed to be present in standard conforming implementations.

([gh-18585](https://github.com/numpy/numpy/pull/18585))

### Generate C/C++ API reference documentation from comments blocks is now possible[#](#generate-c-c-api-reference-documentation-from-comments-blocks-is-now-possible)
This feature depends on [Doxygen](https://www.doxygen.nl/index.html) in the generation process and on [Breathe](https://breathe.readthedocs.io/en/latest/) to
integrate it with Sphinx.

([gh-18884](https://github.com/numpy/numpy/pull/18884))

### Assign the platform-specific `c_intp`
precision via a mypy plugin[#](#assign-the-platform-specific-c-intp-precision-via-a-mypy-plugin)
The [mypy](http://mypy-lang.org/) plugin, introduced in [numpy/numpy#17843](https://github.com/numpy/numpy/pull/17843), has again been expanded:
the plugin now is now responsible for setting the platform-specific precision
of `numpy.ctypeslib.c_intp`
, the latter being used as data type for various
`numpy.ndarray.ctypes`
attributes.

Without the plugin, aforementioned type will default to `ctypes.c_int64`
.

To enable the plugin, one must add it to their mypy [configuration file](https://mypy.readthedocs.io/en/stable/config_file.html):

```
[mypy]
plugins = numpy.typing.mypy_plugin
```
([gh-19062](https://github.com/numpy/numpy/pull/19062))

### Add NEP 47-compatible dlpack support[#](#add-nep-47-compatible-dlpack-support)
Add a `ndarray.__dlpack__()`
method which returns a `dlpack`
C structure
wrapped in a `PyCapsule`
. Also add a `np._from_dlpack(obj)`
function, where
`obj`
supports `__dlpack__()`
, and returns an `ndarray`
.

([gh-19083](https://github.com/numpy/numpy/pull/19083))

`keepdims`
optional argument added to `numpy.argmin`
, `numpy.argmax`
[#](#keepdims-optional-argument-added-to-numpy-argmin-numpy-argmax)
`keepdims`
argument is added to `numpy.argmin`
, `numpy.argmax`
. If set
to `True`
, the axes which are reduced are left in the result as dimensions
with size one. The resulting array has the same number of dimensions and will
broadcast with the input array.
([gh-19211](https://github.com/numpy/numpy/pull/19211))

`bit_count`
to compute the number of 1-bits in an integer[#](#bit-count-to-compute-the-number-of-1-bits-in-an-integer)
Computes the number of 1-bits in the absolute value of the input.
This works on all the numpy integer types. Analogous to the builtin
`int.bit_count`
or `popcount`
in C++.

```
>>> np.uint32(1023).bit_count()
10
>>> np.int32(-127).bit_count()
7
```
([gh-19355](https://github.com/numpy/numpy/pull/19355))

### The `ndim`
and `axis`
attributes have been added to `numpy.AxisError`
[#](#the-ndim-and-axis-attributes-have-been-added-to-numpy-axiserror)
The `ndim`
and `axis`
parameters are now also stored as attributes
within each `numpy.AxisError`
instance.

([gh-19459](https://github.com/numpy/numpy/pull/19459))

### Preliminary support for `windows/arm64`
target[#](#preliminary-support-for-windows-arm64-target)
`numpy`
added support for windows/arm64 target. Please note `OpenBLAS`
support is not yet available for windows/arm64 target.
([gh-19513](https://github.com/numpy/numpy/pull/19513))

### Added support for LoongArch[#](#added-support-for-loongarch)
LoongArch is a new instruction set, numpy compilation failure on LoongArch architecture, so add the commit.

([gh-19527](https://github.com/numpy/numpy/pull/19527))

### A `.clang-format`
file has been added[#](#a-clang-format-file-has-been-added)
Clang-format is a C/C++ code formatter, together with the added
`.clang-format`
file, it produces code close enough to the NumPy
C_STYLE_GUIDE for general use. Clang-format version 12+ is required due to the
use of several new features, it is available in Fedora 34 and Ubuntu Focal
among other distributions.

([gh-19754](https://github.com/numpy/numpy/pull/19754))

`is_integer`
is now available to `numpy.floating`
and `numpy.integer`
[#](#is-integer-is-now-available-to-numpy-floating-and-numpy-integer)
Based on its counterpart in Python `float`
and `int`
, the numpy floating
point and integer types now support `float.is_integer`
. Returns `True`
if
the number is finite with integral value, and `False`
otherwise.

```
>>> np.float32(-2.0).is_integer()
True
>>> np.float64(3.2).is_integer()
False
>>> np.int32(-2).is_integer()
True
```
([gh-19803](https://github.com/numpy/numpy/pull/19803))

### Symbolic parser for Fortran dimension specifications[#](#symbolic-parser-for-fortran-dimension-specifications)
A new symbolic parser has been added to f2py in order to correctly parse dimension specifications. The parser is the basis for future improvements and provides compatibility with Draft Fortran 202x.

([gh-19805](https://github.com/numpy/numpy/pull/19805))

`ndarray`
, `dtype`
and `number`
are now runtime-subscriptable[#](#ndarray-dtype-and-number-are-now-runtime-subscriptable)
Mimicking [ PEP 585](https://peps.python.org/pep-0585/), the

`numpy.ndarray`
, `numpy.dtype`
and
`numpy.number`
classes are now subscriptable for python 3.9 and later.
Consequently, expressions that were previously only allowed in .pyi stub files
or with the help of `from __future__ import annotations`
are now also legal
during runtime.```
>>> import numpy as np
>>> from typing import Any
>>> np.ndarray[Any, np.dtype[np.float64]]
numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]
```
([gh-19879](https://github.com/numpy/numpy/pull/19879))

## Improvements[#](#improvements)
`ctypeslib.load_library`
can now take any path-like object[#](#ctypeslib-load-library-can-now-take-any-path-like-object)
All parameters in the can now take any [path-like object](https://docs.python.org/3/glossary.html#term-path-like-object).
This includes the likes of strings, bytes and objects implementing the
[ __fspath__](https://docs.python.org/3/library/os.html#os.PathLike.__fspath__) protocol.

([gh-17530](https://github.com/numpy/numpy/pull/17530))

### Add `smallest_normal`
and `smallest_subnormal`
attributes to `finfo`
[#](#add-smallest-normal-and-smallest-subnormal-attributes-to-finfo)
The attributes `smallest_normal`
and `smallest_subnormal`
are available as
an extension of `finfo`
class for any floating-point data type. To use these
new attributes, write `np.finfo(np.float64).smallest_normal`
or
`np.finfo(np.float64).smallest_subnormal`
.

([gh-18536](https://github.com/numpy/numpy/pull/18536))

`numpy.linalg.qr`
accepts stacked matrices as inputs[#](#numpy-linalg-qr-accepts-stacked-matrices-as-inputs)
`numpy.linalg.qr`
is able to produce results for stacked matrices as inputs.
Moreover, the implementation of QR decomposition has been shifted to C from
Python.
([gh-19151](https://github.com/numpy/numpy/pull/19151))

`numpy.fromregex`
now accepts `os.PathLike`
implementations[#](#numpy-fromregex-now-accepts-os-pathlike-implementations)
`numpy.fromregex`
now accepts objects implementing the `__fspath__<os.PathLike>`
protocol, *e.g.* `pathlib.Path`
.
([gh-19680](https://github.com/numpy/numpy/pull/19680))

### Add new methods for `quantile`
and `percentile`
[#](#add-new-methods-for-quantile-and-percentile)
`quantile`
and `percentile`
now have have a `method=`
keyword argument
supporting 13 different methods. This replaces the `interpolation=`
keyword
argument.
The methods are now aligned with nine methods which can be found in scientific literature and the R language. The remaining methods are the previous discontinuous variations of the default “linear” one.

Please see the documentation of `numpy.percentile`
for more information.

([gh-19857](https://github.com/numpy/numpy/pull/19857))

### Missing parameters have been added to the `nan<x>`
functions[#](#missing-parameters-have-been-added-to-the-nan-x-functions)
A number of the `nan<x>`
functions previously lacked parameters that were
present in their `<x>`
-based counterpart, *e.g.* the `where`
parameter was
present in `numpy.mean`
but absent from `numpy.nanmean`
.

The following parameters have now been added to the `nan<x>`
functions:

nanmin:

`initial`
&`where`
nanmax:

`initial`
&`where`
nanargmin:

`keepdims`
&`out`
nanargmax:

`keepdims`
&`out`
nansum:

`initial`
&`where`
nanprod:

`initial`
&`where`
nanmean:

`where`
nanvar:

`where`
nanstd:

`where`
([gh-20027](https://github.com/numpy/numpy/pull/20027))

### Annotating the main Numpy namespace[#](#annotating-the-main-numpy-namespace)
Starting from the 1.20 release, PEP 484 type annotations have been included for parts of the NumPy library; annotating the remaining functions being a work in progress. With the release of 1.22 this process has been completed for the main NumPy namespace, which is now fully annotated.

Besides the main namespace, a limited number of sub-packages contain
annotations as well. This includes, among others, `numpy.testing`
,
`numpy.linalg`
and `numpy.random`
(available since 1.21).

([gh-20217](https://github.com/numpy/numpy/pull/20217))

### Vectorize umath module using AVX-512[#](#vectorize-umath-module-using-avx-512)
By leveraging Intel Short Vector Math Library (SVML), 18 umath functions
(`exp2`
, `log2`
, `log10`
, `expm1`
, `log1p`
, `cbrt`
, `sin`
,
`cos`
, `tan`
, `arcsin`
, `arccos`
, `arctan`
, `sinh`
, `cosh`
,
`tanh`
, `arcsinh`
, `arccosh`
, `arctanh`
) are vectorized using AVX-512
instruction set for both single and double precision implementations. This
change is currently enabled only for Linux users and on processors with AVX-512
instruction set. It provides an average speed up of 32x and 14x for single and
double precision functions respectively.

([gh-19478](https://github.com/numpy/numpy/pull/19478))

### OpenBLAS v0.3.18[#](#openblas-v0-3-18)
Update the OpenBLAS used in testing and in wheels to v0.3.18

([gh-20058](https://github.com/numpy/numpy/pull/20058))# NumPy 1.5.0 Release Notes[#](#numpy-1-5-0-release-notes)
## Highlights[#](#highlights)
### Python 3 compatibility[#](#python-3-compatibility)
This is the first NumPy release which is compatible with Python 3. Support for
Python 3 and Python 2 is done from a single code base. Extensive notes on
changes can be found at
[https://web.archive.org/web/20100814160313/http://projects.scipy.org/numpy/browser/trunk/doc/Py3K.txt](https://web.archive.org/web/20100814160313/http://projects.scipy.org/numpy/browser/trunk/doc/Py3K.txt).

Note that the Numpy testing framework relies on nose, which does not have a
Python 3 compatible release yet. A working Python 3 branch of nose can be found
at [https://web.archive.org/web/20100817112505/http://bitbucket.org/jpellerin/nose3/](https://web.archive.org/web/20100817112505/http://bitbucket.org/jpellerin/nose3/) however.

Porting of SciPy to Python 3 is expected to be completed soon.

**PEP 3118** compatibility[#](#pep-3118-compatibility)
**PEP 3118**
The new buffer protocol described by PEP 3118 is fully supported in this version of Numpy. On Python versions >= 2.6 Numpy arrays expose the buffer interface, and array(), asarray() and other functions accept new-style buffers as input.

## New features[#](#new-features)
### Warning on casting complex to real[#](#warning-on-casting-complex-to-real)
Numpy now emits a `numpy.ComplexWarning`
when a complex number is cast
into a real number. For example:

```
>>> x = np.array([1,2,3])
>>> x[:2] = np.array([1+2j, 1-2j])
ComplexWarning: Casting complex values to real discards the imaginary part
```
The cast indeed discards the imaginary part, and this may not be the intended behavior in all cases, hence the warning. This warning can be turned off in the standard way:

```
>>> import warnings
>>> warnings.simplefilter("ignore", np.ComplexWarning)
```
### Dot method for ndarrays[#](#dot-method-for-ndarrays)
Ndarrays now have the dot product also as a method, which allows writing chains of matrix products as

```
>>> a.dot(b).dot(c)
```
instead of the longer alternative

```
>>> np.dot(a, np.dot(b, c))
```
### linalg.slogdet function[#](#linalg-slogdet-function)
The slogdet function returns the sign and logarithm of the determinant of a matrix. Because the determinant may involve the product of many small/large values, the result is often more accurate than that obtained by simple multiplication.

### new header[#](#new-header)
The new header file ndarraytypes.h contains the symbols from ndarrayobject.h that do not depend on the PY_ARRAY_UNIQUE_SYMBOL and NO_IMPORT/_ARRAY macros. Broadly, these symbols are types, typedefs, and enumerations; the array function calls are left in ndarrayobject.h. This allows users to include array-related types and enumerations without needing to concern themselves with the macro expansions and their side- effects.

## Changes[#](#changes)
### polynomial.polynomial[#](#polynomial-polynomial)
The polyint and polyder functions now check that the specified number integrations or derivations is a non-negative integer. The number 0 is a valid value for both functions.

A degree method has been added to the Polynomial class.

A trimdeg method has been added to the Polynomial class. It operates like truncate except that the argument is the desired degree of the result, not the number of coefficients.

Polynomial.fit now uses None as the default domain for the fit. The default Polynomial domain can be specified by using [] as the domain value.

Weights can be used in both polyfit and Polynomial.fit

A linspace method has been added to the Polynomial class to ease plotting.

The polymulx function was added.

### polynomial.chebyshev[#](#polynomial-chebyshev)
The chebint and chebder functions now check that the specified number integrations or derivations is a non-negative integer. The number 0 is a valid value for both functions.

A degree method has been added to the Chebyshev class.

A trimdeg method has been added to the Chebyshev class. It operates like truncate except that the argument is the desired degree of the result, not the number of coefficients.

Chebyshev.fit now uses None as the default domain for the fit. The default Chebyshev domain can be specified by using [] as the domain value.

Weights can be used in both chebfit and Chebyshev.fit

A linspace method has been added to the Chebyshev class to ease plotting.

The chebmulx function was added.

Added functions for the Chebyshev points of the first and second kind.

### histogram[#](#histogram)
After a two years transition period, the old behavior of the histogram function has been phased out, and the “new” keyword has been removed.

### correlate[#](#correlate)
The old behavior of correlate was deprecated in 1.4.0, the new behavior (the usual definition for cross-correlation) is now the default.# NumPy 1.16.6 Release Notes[#](#numpy-1-16-6-release-notes)
The NumPy 1.16.6 release fixes bugs reported against the 1.16.5 release, and also backports several enhancements from master that seem appropriate for a release series that is the last to support Python 2.7. The wheels on PyPI are linked with OpenBLAS v0.3.7, which should fix errors on Skylake series cpus.

Downstream developers building this release should use Cython >= 0.29.2 and, if using OpenBLAS, OpenBLAS >= v0.3.7. The supported Python versions are 2.7 and 3.5-3.7.

## Highlights[#](#highlights)
The

`np.testing.utils`
functions have been updated from 1.19.0-dev0. This improves the function documentation and error messages as well extending the`assert_array_compare`
function to additional types.
## New functions[#](#new-functions)
### Allow matmul (*@* operator) to work with object arrays.[#](#allow-matmul-operator-to-work-with-object-arrays)
This is an enhancement that was added in NumPy 1.17 and seems reasonable to include in the LTS 1.16 release series.

## Compatibility notes[#](#compatibility-notes)
### Fix regression in matmul (*@* operator) for boolean types[#](#fix-regression-in-matmul-operator-for-boolean-types)
Booleans were being treated as integers rather than booleans, which was a regression from previous behavior.

## Improvements[#](#improvements)
### Array comparison assertions include maximum differences[#](#array-comparison-assertions-include-maximum-differences)
Error messages from array comparison tests such as `testing.assert_allclose`
now include “max absolute difference” and “max relative difference,” in
addition to the previous “mismatch” percentage. This information makes it
easier to update absolute and relative error tolerances.

## Contributors[#](#contributors)
A total of 10 people contributed to this release.

CakeWithSteak

Charles Harris

Chris Burr

Eric Wieser

Fernando Saravia

Lars Grueter

Matti Picus

Maxwell Aladago

Qiming Sun

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 14 pull requests were merged for this release.

[#14211](https://github.com/numpy/numpy/pull/14211): BUG: Fix uint-overflow if padding with linear_ramp and negative…
[#14275](https://github.com/numpy/numpy/pull/14275): BUG: fixing to allow unpickling of PY3 pickles from PY2
[#14340](https://github.com/numpy/numpy/pull/14340): BUG: Fix misuse of .names and .fields in various places (backport…
[#14423](https://github.com/numpy/numpy/pull/14423): BUG: test, fix regression in converting to ctypes.
[#14434](https://github.com/numpy/numpy/pull/14434): BUG: Fixed maximum relative error reporting in assert_allclose
[#14509](https://github.com/numpy/numpy/pull/14509): BUG: Fix regression in boolean matmul.
[#14686](https://github.com/numpy/numpy/pull/14686): BUG: properly define PyArray_DescrCheck
[#14853](https://github.com/numpy/numpy/pull/14853): BLD: add ‘apt update’ to shippable
[#14854](https://github.com/numpy/numpy/pull/14854): BUG: Fix _ctypes class circular reference. (#13808)
[#14856](https://github.com/numpy/numpy/pull/14856): BUG: Fix*np.einsum*errors on Power9 Linux and z/Linux
[#14863](https://github.com/numpy/numpy/pull/14863): BLD: Prevent -flto from optimising long double representation…
[#14864](https://github.com/numpy/numpy/pull/14864): BUG: lib: Fix histogram problem with signed integer arrays.
[#15172](https://github.com/numpy/numpy/pull/15172): ENH: Backport improvements to testing functions.
[#15191](https://github.com/numpy/numpy/pull/15191): REL: Prepare for 1.16.6 release.# NumPy 1.16.2 Release Notes[#](#numpy-1-16-2-release-notes)
NumPy 1.16.2 is a quick release fixing several problems encountered on Windows. The Python versions supported are 2.7 and 3.5-3.7. The Windows problems addressed are:

DLL load problems for NumPy wheels on Windows,

distutils command line parsing on Windows.

There is also a regression fix correcting signed zeros produced by divmod, see below for details.

Downstream developers building this release should use Cython >= 0.29.2 and, if using OpenBLAS, OpenBLAS > v0.3.4.

If you are installing using pip, you may encounter a problem with older
installed versions of NumPy that pip did not delete becoming mixed with the
current version, resulting in an `ImportError`
. That problem is particularly
common on Debian derived distributions due to a modified pip. The fix is to
make sure all previous NumPy versions installed by pip have been removed. See
[#12736](https://github.com/numpy/numpy/issues/12736) for discussion of the
issue.

## Compatibility notes[#](#compatibility-notes)
### Signed zero when using divmod[#](#signed-zero-when-using-divmod)
Starting in version 1.12.0, numpy incorrectly returned a negatively signed zero
when using the `divmod`
and `floor_divide`
functions when the result was
zero. For example:

```
>>> np.zeros(10)//1
array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.])
```
With this release, the result is correctly returned as a positively signed zero:

```
>>> np.zeros(10)//1
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
```
## Contributors[#](#contributors)
A total of 5 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Eric Wieser

Matti Picus

Tyler Reddy

Tony LaTorre +

## Pull requests merged[#](#pull-requests-merged)
A total of 7 pull requests were merged for this release.

[#12909](https://github.com/numpy/numpy/pull/12909): TST: fix vmImage dispatch in Azure
[#12923](https://github.com/numpy/numpy/pull/12923): MAINT: remove complicated test of multiarray import failure mode
[#13020](https://github.com/numpy/numpy/pull/13020): BUG: fix signed zero behavior in npy_divmod
[#13026](https://github.com/numpy/numpy/pull/13026): MAINT: Add functions to parse shell-strings in the platform-native…
[#13028](https://github.com/numpy/numpy/pull/13028): BUG: Fix regression in parsing of F90 and F77 environment variables
[#13038](https://github.com/numpy/numpy/pull/13038): BUG: parse shell escaping in extra_compile_args and extra_link_args
[#13041](https://github.com/numpy/numpy/pull/13041): BLD: Windows absolute path DLL loading# NumPy 1.13.3 Release Notes[#](#numpy-1-13-3-release-notes)
This is a bugfix release for some problems found since 1.13.1. The most important fixes are for CVE-2017-12852 and temporary elision. Users of earlier versions of 1.13 should upgrade.

The Python versions supported are 2.7 and 3.4 - 3.6. The Python 3.6 wheels available from PIP are built with Python 3.6.2 and should be compatible with all previous versions of Python 3.6. It was cythonized with Cython 0.26.1, which should be free of the bugs found in 0.27 while also being compatible with Python 3.7-dev. The Windows wheels were built with OpenBlas instead ATLAS, which should improve the performance of the linear algebra functions.

The NumPy 1.13.3 release is a re-release of 1.13.2, which suffered from a bug in Cython 0.27.0.

## Contributors[#](#contributors)
A total of 12 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Brandon Carter

Charles Harris

Eric Wieser

Iryna Shcherbina +

James Bourbeau +

Jonathan Helmus

Julian Taylor

Matti Picus

Michael Lamparski +

Michael Seifert

Ralf Gommers

## Pull requests merged[#](#pull-requests-merged)
A total of 22 pull requests were merged for this release.

#9390 BUG: Return the poly1d coefficients array directly

#9555 BUG: Fix regression in 1.13.x in distutils.mingw32ccompiler.

#9556 BUG: Fix true_divide when dtype=np.float64 specified.

#9557 DOC: Fix some rst markup in numpy/doc/basics.py.

#9558 BLD: Remove -xhost flag from IntelFCompiler.

#9559 DOC: Removes broken docstring example (source code, png, pdf)…

#9580 BUG: Add hypot and cabs functions to WIN32 blacklist.

#9732 BUG: Make scalar function elision check if temp is writeable.

#9736 BUG: Various fixes to np.gradient

#9742 BUG: Fix np.pad for CVE-2017-12852

#9744 BUG: Check for exception in sort functions, add tests

#9745 DOC: Add whitespace after “versionadded::” directive so it actually…

#9746 BUG: Memory leak in np.dot of size 0

#9747 BUG: Adjust gfortran version search regex

#9757 BUG: Cython 0.27 breaks NumPy on Python 3.

#9764 BUG: Ensure

*_npy_scaled_cexp{,f,l}*is defined when needed.
#9765 BUG: PyArray_CountNonzero does not check for exceptions

#9766 BUG: Fixes histogram monotonicity check for unsigned bin values

#9767 BUG: Ensure consistent result dtype of count_nonzero

#9771 BUG: MAINT: Fix mtrand for Cython 0.27.

#9772 DOC: Create the 1.13.2 release notes.

#9794 DOC: Create 1.13.3 release notes.# NumPy 1.19.4 Release Notes[#](#numpy-1-19-4-release-notes)
NumPy 1.19.4 is a quick release to revert the OpenBLAS library version. It was hoped that the 0.3.12 OpenBLAS version used in 1.19.3 would work around the Microsoft fmod bug, but problems in some docker environments turned up. Instead, 1.19.4 will use the older library and run a sanity check on import, raising an error if the problem is detected. Microsoft is aware of the problem and has promised a fix, users should upgrade when it becomes available.

This release supports Python 3.6-3.9

## Contributors[#](#contributors)
A total of 1 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

## Pull requests merged[#](#pull-requests-merged)
A total of 2 pull requests were merged for this release.# NumPy 1.14.3 Release Notes[#](#numpy-1-14-3-release-notes)
This is a bugfix release for a few bugs reported following the 1.14.2 release:

np.lib.recfunctions.fromrecords accepts a list-of-lists, until 1.15

In python2, float types use the new print style when printing to a file

style arg in “legacy” print mode now works for 0d arrays

The Python versions supported in this release are 2.7 and 3.4 - 3.6. The Python 3.6 wheels available from PIP are built with Python 3.6.2 and should be compatible with all previous versions of Python 3.6. The source releases were cythonized with Cython 0.28.2.

## Contributors[#](#contributors)
A total of 6 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Charles Harris

Jonathan March +

Malcolm Smith +

Matti Picus

Pauli Virtanen

## Pull requests merged[#](#pull-requests-merged)
A total of 8 pull requests were merged for this release.

[#10862](https://github.com/numpy/numpy/pull/10862): BUG: floating types should override tp_print (1.14 backport)
[#10905](https://github.com/numpy/numpy/pull/10905): BUG: for 1.14 back-compat, accept list-of-lists in fromrecords
[#10947](https://github.com/numpy/numpy/pull/10947): BUG: ‘style’ arg to array2string broken in legacy mode (1.14…
[#10959](https://github.com/numpy/numpy/pull/10959): BUG: test, fix for missing flags[‘WRITEBACKIFCOPY’] key
[#10960](https://github.com/numpy/numpy/pull/10960): BUG: Add missing underscore to prototype in check_embedded_lapack
[#10961](https://github.com/numpy/numpy/pull/10961): BUG: Fix encoding regression in ma/bench.py (Issue #10868)
[#10962](https://github.com/numpy/numpy/pull/10962): BUG: core: fix NPY_TITLE_KEY macro on pypy
[#10974](https://github.com/numpy/numpy/pull/10974): BUG: test, fix PyArray_DiscardWritebackIfCopy…# NumPy 1.11.1 Release Notes[#](#numpy-1-11-1-release-notes)
Numpy 1.11.1 supports Python 2.6 - 2.7 and 3.2 - 3.5. It fixes bugs and regressions found in Numpy 1.11.0 and includes several build related improvements. Wheels for Linux, Windows, and OSX can be found on PyPI.

## Fixes Merged[#](#fixes-merged)
#7506 BUG: Make sure numpy imports on python 2.6 when nose is unavailable.

#7530 BUG: Floating exception with invalid axis in np.lexsort.

#7535 BUG: Extend glibc complex trig functions blacklist to glibc < 2.18.

#7551 BUG: Allow graceful recovery for no compiler.

#7558 BUG: Constant padding expected wrong type in constant_values.

#7578 BUG: Fix OverflowError in Python 3.x. in swig interface.

#7590 BLD: Fix configparser.InterpolationSyntaxError.

#7597 BUG: Make np.ma.take work on scalars.

#7608 BUG: linalg.norm(): Don’t convert object arrays to float.

#7638 BLD: Correct C compiler customization in system_info.py.

#7654 BUG: ma.median of 1d array should return a scalar.

#7656 BLD: Remove hardcoded Intel compiler flag -xSSE4.2.

#7660 BUG: Temporary fix for str(mvoid) for object field types.

#7665 BUG: Fix incorrect printing of 1D masked arrays.

#7670 BUG: Correct initial index estimate in histogram.

#7671 BUG: Boolean assignment no GIL release when transfer needs API.

#7676 BUG: Fix handling of right edge of final histogram bin.

#7680 BUG: Fix np.clip bug NaN handling for Visual Studio 2015.

#7724 BUG: Fix segfaults in np.random.shuffle.

#7731 MAINT: Change mkl_info.dir_env_var from MKL to MKLROOT.

#7737 BUG: Fix issue on OS X with Python 3.x, npymath.ini not installed.# NumPy 1.21.5 Release Notes[#](#numpy-1-21-5-release-notes)
NumPy 1.21.5 is a maintenance release that fixes a few bugs discovered after the 1.21.4 release and does some maintenance to extend the 1.21.x lifetime. The Python versions supported in this release are 3.7-3.10. If you want to compile your own version using gcc-11, you will need to use gcc-11.2+ to avoid problems.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Bas van Beek

Charles Harris

Matti Picus

Rohit Goswami

Ross Barnowski

Sayed Adel

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 11 pull requests were merged for this release.

[#20357](https://github.com/numpy/numpy/pull/20357): MAINT: Do not forward`__(deep)copy__`
calls of`_GenericAlias`
…
[#20462](https://github.com/numpy/numpy/pull/20462): BUG: Fix float16 einsum fastpaths using wrong tempvar
[#20463](https://github.com/numpy/numpy/pull/20463): BUG, DIST: Print os error message when the executable not exist
[#20464](https://github.com/numpy/numpy/pull/20464): BLD: Verify the ability to compile C++ sources before initiating…
[#20465](https://github.com/numpy/numpy/pull/20465): BUG: Force`npymath` ` to respect ``npy_longdouble`
[#20466](https://github.com/numpy/numpy/pull/20466): BUG: Fix failure to create aligned, empty structured dtype
[#20467](https://github.com/numpy/numpy/pull/20467): ENH: provide a convenience function to replace npy_load_module
[#20495](https://github.com/numpy/numpy/pull/20495): MAINT: update wheel to version that supports python3.10
[#20497](https://github.com/numpy/numpy/pull/20497): BUG: Clear errors correctly in F2PY conversions
[#20613](https://github.com/numpy/numpy/pull/20613): DEV: add a warningfilter to fix pytest workflow.
[#20618](https://github.com/numpy/numpy/pull/20618): MAINT: Help boost::python libraries at least not crash# NumPy 1.22.4 Release Notes[#](#numpy-1-22-4-release-notes)
NumPy 1.22.4 is a maintenance release that fixes bugs discovered after the
1.22.3 release. In addition, the wheels for this release are built using the
recently released Cython 0.29.30, which should fix the reported problems with
[debugging](https://github.com/numpy/numpy/issues/21008).

The Python versions supported for this release are 3.8-3.10. Note that the Mac wheels are based on OS X 10.15 rather than 10.9 that was used in previous NumPy release cycles.

## Contributors[#](#contributors)
A total of 12 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Alexander Shadchin

Bas van Beek

Charles Harris

Hood Chatham

Jarrod Millman

John-Mark Gurney +

Junyan Ou +

Mariusz Felisiak +

Ross Barnowski

Sebastian Berg

Serge Guelton

Stefan van der Walt

## Pull requests merged[#](#pull-requests-merged)
A total of 22 pull requests were merged for this release.

[#21191](https://github.com/numpy/numpy/pull/21191): TYP, BUG: Fix`np.lib.stride_tricks`
re-exported under the…
[#21192](https://github.com/numpy/numpy/pull/21192): TST: Bump mypy from 0.931 to 0.940
[#21243](https://github.com/numpy/numpy/pull/21243): MAINT: Explicitly re-export the types in`numpy._typing`
[#21245](https://github.com/numpy/numpy/pull/21245): MAINT: Specify sphinx, numpydoc versions for CI doc builds
[#21275](https://github.com/numpy/numpy/pull/21275): BUG: Fix typos
[#21277](https://github.com/numpy/numpy/pull/21277): ENH, BLD: Fix math feature detection for wasm
[#21350](https://github.com/numpy/numpy/pull/21350): MAINT: Fix failing simd and cygwin tests.
[#21438](https://github.com/numpy/numpy/pull/21438): MAINT: Fix failing Python 3.8 32-bit Windows test.
[#21444](https://github.com/numpy/numpy/pull/21444): BUG: add linux guard per #21386
[#21445](https://github.com/numpy/numpy/pull/21445): BUG: Allow legacy dtypes to cast to datetime again
[#21446](https://github.com/numpy/numpy/pull/21446): BUG: Make mmap handling safer in frombuffer
[#21447](https://github.com/numpy/numpy/pull/21447): BUG: Stop using PyBytesObject.ob_shash deprecated in Python 3.11.
[#21448](https://github.com/numpy/numpy/pull/21448): ENH: Introduce numpy.core.setup_common.NPY_CXX_FLAGS
[#21472](https://github.com/numpy/numpy/pull/21472): BUG: Ensure compile errors are raised correclty
[#21473](https://github.com/numpy/numpy/pull/21473): BUG: Fix segmentation fault
[#21474](https://github.com/numpy/numpy/pull/21474): MAINT: Update doc requirements
[#21475](https://github.com/numpy/numpy/pull/21475): MAINT: Mark`npy_memchr`
with`no_sanitize("alignment")`
on clang
[#21512](https://github.com/numpy/numpy/pull/21512): DOC: Proposal - make the doc landing page cards more similar…
[#21525](https://github.com/numpy/numpy/pull/21525): MAINT: Update Cython version to 0.29.30.
[#21536](https://github.com/numpy/numpy/pull/21536): BUG: Fix GCC error during build configuration
[#21541](https://github.com/numpy/numpy/pull/21541): REL: Prepare for the NumPy 1.22.4 release.
[#21547](https://github.com/numpy/numpy/pull/21547): MAINT: Skip tests that fail on PyPy.# numpy.matrix.sort[#](#numpy-matrix-sort)
method

matrix.sort(*axis=-1*,*kind=None*,*order=None*)[#](#numpy.matrix.sort)
-
Sort an array in-place. Refer to

for full documentation.`numpy.sort`
Parameters:
-
**axis**int, optional
Axis along which to sort. Default is -1, which means sort along the last axis.

**kind**{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, optional
Sorting algorithm. The default is ‘quicksort’. Note that both ‘stable’ and ‘mergesort’ use timsort under the covers and, in general, the actual implementation will vary with datatype. The ‘mergesort’ option is retained for backwards compatibility.

Changed in version 1.15.0: The ‘stable’ option was added.

**order**str or list of str, optional
When

*a*is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.
See also

`numpy.sort`
Return a sorted copy of an array.

`numpy.argsort`
Indirect sort.

`numpy.lexsort`
Indirect stable sort on multiple keys.

`numpy.searchsorted`
Find elements in sorted array.

`numpy.partition`
Partial sort.

Notes

See

for notes on the different sorting algorithms.`numpy.sort`
Examples

>>> a = np.array([[1,4], [3,1]]) >>> a.sort(axis=1) >>> a array([[1, 4], [1, 3]]) >>> a.sort(axis=0) >>> a array([[1, 3], [1, 4]])
Use the

*order*keyword to specify a field to use when sorting a structured array:>>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)]) >>> a.sort(order='y') >>> a array([(b'c', 1), (b'a', 2)], dtype=[('x', 'S1'), ('y', '<i8')])# numpy.polynomial.legendre.legval2d[#](#numpy-polynomial-legendre-legval2d)
polynomial.legendre.legval2d(*x*,*y*,*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L917-L963)[#](#numpy.polynomial.legendre.legval2d)
-
Evaluate a 2-D Legendre series at points (x, y).

This function returns the values:

\[p(x,y) = \sum_{i,j} c_{i,j} * L_i(x) * L_j(y)\]The parameters

*x*and*y*are converted to arrays only if they are tuples or a lists, otherwise they are treated as a scalars and they must have the same shape after conversion. In either case, either*x*and*y*or their elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*is a 1-D array a one is implicitly appended to its shape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape.Parameters:
-
**x, y**array_like, compatible objects
The two dimensional series is evaluated at the points

*(x, y)*, where*x*and*y*must have the same shape. If*x*or*y*is a list or tuple, it is first converted to an ndarray, otherwise it is left unchanged and if it isn’t an ndarray it is treated as a scalar.
**c**array_like
Array of coefficients ordered so that the coefficient of the term of multi-degree i,j is contained in

`c[i,j]`
. If*c*has dimension greater than two the remaining indices enumerate multiple sets of coefficients.
Returns:
-
**values**ndarray, compatible object
The values of the two dimensional Legendre series at points formed from pairs of corresponding values from

*x*and*y*.
Notes

New in version 1.7.0.# numpy.empty[#](#numpy-empty)
numpy.empty(*shape*,*dtype=float*,*order='C'*,***,*like=None*)[#](#numpy.empty)
-
Return a new array of given shape and type, without initializing entries.

Parameters:
-
**shape**int or tuple of int
Shape of the empty array, e.g.,

`(2, 3)`
or`2`
.
**dtype**data-type, optional
Desired output data-type for the array, e.g,

. Default is`numpy.int8`
.`numpy.float64`
**order**{‘C’, ‘F’}, optional, default: ‘C’
Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**out**ndarray
Array of uninitialized (arbitrary) data of the given shape, dtype, and order. Object arrays will be initialized to None.

See also

`empty_like`
Return an empty array with shape and type of input.

`ones`
Return a new array setting values to one.

`zeros`
Return a new array setting values to zero.

`full`
Return a new array of given shape filled with value.

Notes

, unlike`empty`
, does not set the array values to zero, and may therefore be marginally faster. On the other hand, it requires the user to manually set all the values in the array, and should be used with caution.`zeros`
Examples

>>> np.empty([2, 2]) array([[ -9.74499359e+001, 6.69583040e-309], [ 2.13182611e-314, 3.06959433e-309]]) #uninitialized
>>> np.empty([2, 2], dtype=int) array([[-1073741821, -1067949133], [ 496041986, 19249760]]) #uninitialized# numpy.chararray.astype[#](#numpy-chararray-astype)
method

chararray.astype(*dtype*,*order='K'*,*casting='unsafe'*,*subok=True*,*copy=True*)[#](#numpy.chararray.astype)
-
Copy of the array, cast to a specified type.

Parameters:
-
**dtype**str or dtype
Typecode or data-type to which the array is cast.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout order of the result. ‘C’ means C order, ‘F’ means Fortran order, ‘A’ means ‘F’ order if all the arrays are Fortran contiguous, ‘C’ order otherwise, and ‘K’ means as close to the order the array elements appear in memory as possible. Default is ‘K’.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘unsafe’ for backwards compatibility.

‘no’ means the data types should not be cast at all.

‘equiv’ means only byte-order changes are allowed.

‘safe’ means only casts which can preserve values are allowed.

‘same_kind’ means only safe casts or casts within a kind, like float64 to float32, are allowed.

‘unsafe’ means any data conversions may be done.

**subok**bool, optional
If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.

**copy**bool, optional
By default, astype always returns a newly allocated array. If this is set to false, and the

,`dtype`
*order*, and*subok*requirements are satisfied, the input array is returned instead of a copy.
Returns:
-
Raises:
-
ComplexWarning
-
When casting from complex to float or int. To avoid this, one should use

`a.real.astype(t)`
.
Notes

Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for “unsafe” casting. Casting to multiple fields is allowed, but casting from multiple fields is not.

Changed in version 1.9.0: Casting from numeric to string types in ‘safe’ casting mode requires that the string dtype length is long enough to store the max integer/float value converted.

Examples

>>> x = np.array([1, 2, 2.5]) >>> x array([1. , 2. , 2.5])
>>> x.astype(int) array([1, 2, 2])# Beyond the Basics[#](#beyond-the-basics)
*Marcel Proust*
*Albert Szent-Gyorgi*
## Iterating over elements in the array[#](#iterating-over-elements-in-the-array)
### Basic Iteration[#](#basic-iteration)
One common algorithmic requirement is to be able to walk over all elements in a multidimensional array. The array iterator object makes this easy to do in a generic way that works for arrays of any dimension. Naturally, if you know the number of dimensions you will be using, then you can always write nested for loops to accomplish the iteration. If, however, you want to write code that works with any number of dimensions, then you can make use of the array iterator. An array iterator object is returned when accessing the .flat attribute of an array.

Basic usage is to call [ PyArray_IterNew](../reference/c-api/array.html#c.PyArray_IterNew) (

`array`
) where array
is an ndarray object (or one of its sub-classes). The returned object
is an array-iterator object (the same object returned by the .flat
attribute of the ndarray). This object is usually cast to
PyArrayIterObject* so that its members can be accessed. The only
members that are needed are `iter->size`
which contains the total
size of the array, `iter->index`
, which contains the current 1-d
index into the array, and `iter->dataptr`
which is a pointer to the
data for the current element of the array. Sometimes it is also
useful to access `iter->ao`
which is a pointer to the underlying
ndarray object.After processing data at the current element of the array, the next
element of the array can be obtained using the macro
[ PyArray_ITER_NEXT](../reference/c-api/array.html#c.PyArray_ITER_NEXT) (

`iter`
). The iteration always proceeds in a
C-style contiguous fashion (last index varying the fastest). The
[(](../reference/c-api/array.html#c.PyArray_ITER_GOTO)
`PyArray_ITER_GOTO`
`iter`
, `destination`
) can be used to
jump to a particular point in the array, where `destination`
is an
array of npy_intp data-type with space to handle at least the number
of dimensions in the underlying array. Occasionally it is useful to
use [(](../reference/c-api/array.html#c.PyArray_ITER_GOTO1D)
`PyArray_ITER_GOTO1D`
`iter`
, `index`
) which will jump
to the 1-d index given by the value of `index`
. The most common
usage, however, is given in the following example.```
PyObject *obj; /* assumed to be some ndarray object */
PyArrayIterObject *iter;
...
iter = (PyArrayIterObject *)PyArray_IterNew(obj);
if (iter == NULL) goto fail; /* Assume fail has clean-up code */
while (iter->index < iter->size) {
/* do something with the data at it->dataptr */
PyArray_ITER_NEXT(it);
}
...
```
You can also use [ PyArrayIter_Check](../reference/c-api/array.html#c.PyArrayIter_Check) (

`obj`
) to ensure you have
an iterator object and [(](../reference/c-api/array.html#c.PyArray_ITER_RESET)
`PyArray_ITER_RESET`
`iter`
) to reset an
iterator object back to the beginning of the array.It should be emphasized at this point that you may not need the array iterator if your array is already contiguous (using an array iterator will work but will be slower than the fastest code you could write). The major purpose of array iterators is to encapsulate iteration over N-dimensional arrays with arbitrary strides. They are used in many, many places in the NumPy source code itself. If you already know your array is contiguous (Fortran or C), then simply adding the element- size to a running pointer variable will step you through the array very efficiently. In other words, code like this will probably be faster for you in the contiguous case (assuming doubles).

```
npy_intp size;
double *dptr; /* could make this any variable type */
size = PyArray_SIZE(obj);
dptr = PyArray_DATA(obj);
while(size--) {
/* do something with the data at dptr */
dptr++;
}
```
### Iterating over all but one axis[#](#iterating-over-all-but-one-axis)
A common algorithm is to loop over all elements of an array and perform some function with each element by issuing a function call. As function calls can be time consuming, one way to speed up this kind of algorithm is to write the function so it takes a vector of data and then write the iteration so the function call is performed for an entire dimension of data at a time. This increases the amount of work done per function call, thereby reducing the function-call over-head to a small(er) fraction of the total time. Even if the interior of the loop is performed without a function call it can be advantageous to perform the inner loop over the dimension with the highest number of elements to take advantage of speed enhancements available on micro- processors that use pipelining to enhance fundamental operations.

The [ PyArray_IterAllButAxis](../reference/c-api/array.html#c.PyArray_IterAllButAxis) (

`array`
, `&dim`
) constructs an
iterator object that is modified so that it will not iterate over the
dimension indicated by dim. The only restriction on this iterator
object, is that the [(](../reference/c-api/array.html#c.PyArray_ITER_GOTO1D)
`PyArray_ITER_GOTO1D`
`it`
, `ind`
) macro
cannot be used (thus flat indexing won’t work either if you pass this
object back to Python — so you shouldn’t do this). Note that the
returned object from this routine is still usually cast to
PyArrayIterObject *. All that’s been done is to modify the strides
and dimensions of the returned iterator to simulate iterating over
array[…,0,…] where 0 is placed on the
\(\textrm{dim}^{\textrm{th}}\) dimension. If dim is negative, then
the dimension with the largest axis is found and used.### Iterating over multiple arrays[#](#iterating-over-multiple-arrays)
Very often, it is desirable to iterate over several arrays at the same time. The universal functions are an example of this kind of behavior. If all you want to do is iterate over arrays with the same shape, then simply creating several iterator objects is the standard procedure. For example, the following code iterates over two arrays assumed to be the same shape and size (actually obj1 just has to have at least as many total elements as does obj2):

```
/* It is already assumed that obj1 and obj2
are ndarrays of the same shape and size.
*/
iter1 = (PyArrayIterObject *)PyArray_IterNew(obj1);
if (iter1 == NULL) goto fail;
iter2 = (PyArrayIterObject *)PyArray_IterNew(obj2);
if (iter2 == NULL) goto fail; /* assume iter1 is DECREF'd at fail */
while (iter2->index < iter2->size) {
/* process with iter1->dataptr and iter2->dataptr */
PyArray_ITER_NEXT(iter1);
PyArray_ITER_NEXT(iter2);
}
```
### Broadcasting over multiple arrays[#](#broadcasting-over-multiple-arrays)
When multiple arrays are involved in an operation, you may want to use the
same broadcasting rules that the math operations (*i.e.* the ufuncs) use.
This can be done easily using the [ PyArrayMultiIterObject](../reference/c-api/types-and-structures.html#c.PyArrayMultiIterObject). This is
the object returned from the Python command numpy.broadcast and it is almost
as easy to use from C. The function

[(](../reference/c-api/array.html#c.PyArray_MultiIterNew)
`PyArray_MultiIterNew`
`n`
, `...`
) is used (with `n`
input
objects in place of `...`
). The input objects can be arrays or anything
that can be converted into an array. A pointer to a PyArrayMultiIterObject is
returned. Broadcasting has already been accomplished which adjusts the
iterators so that all that needs to be done to advance to the next element in
each array is for PyArray_ITER_NEXT to be called for each of the inputs. This
incrementing is automatically performed by
[(](../reference/c-api/array.html#c.PyArray_MultiIter_NEXT)
`PyArray_MultiIter_NEXT`
`obj`
) macro (which can handle a
multiterator `obj`
as either a [PyArrayMultiIterObject](../reference/c-api/types-and-structures.html#c.PyArrayMultiIterObject)* or a
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*). The data from input number
`i`
is available using
[(](../reference/c-api/array.html#c.PyArray_MultiIter_DATA)
`PyArray_MultiIter_DATA`
`obj`
, `i`
). An example of using this
feature follows.```
mobj = PyArray_MultiIterNew(2, obj1, obj2);
size = mobj->size;
while(size--) {
ptr1 = PyArray_MultiIter_DATA(mobj, 0);
ptr2 = PyArray_MultiIter_DATA(mobj, 1);
/* code using contents of ptr1 and ptr2 */
PyArray_MultiIter_NEXT(mobj);
}
```
The function [ PyArray_RemoveSmallest](../reference/c-api/array.html#c.PyArray_RemoveSmallest) (

`multi`
) can be used to
take a multi-iterator object and adjust all the iterators so that
iteration does not take place over the largest dimension (it makes
that dimension of size 1). The code being looped over that makes use
of the pointers will very-likely also need the strides data for each
of the iterators. This information is stored in
multi->iters[i]->strides.There are several examples of using the multi-iterator in the NumPy source code as it makes N-dimensional broadcasting-code very simple to write. Browse the source for more examples.

## User-defined data-types[#](#user-defined-data-types)
NumPy comes with 24 builtin data-types. While this covers a large majority of possible use cases, it is conceivable that a user may have a need for an additional data-type. There is some support for adding an additional data-type into the NumPy system. This additional data- type will behave much like a regular data-type except ufuncs must have 1-d loops registered to handle it separately. Also checking for whether or not other data-types can be cast “safely” to and from this new type or not will always return “can cast” unless you also register which types your new data-type can be cast to and from.

The NumPy source code includes an example of a custom data-type as part
of its test suite. The file `_rational_tests.c.src`
in the source code
directory `numpy/numpy/core/src/umath/`
contains an implementation of
a data-type that represents a rational number as the ratio of two 32 bit
integers.

### Adding the new data-type[#](#adding-the-new-data-type)
To begin to make use of the new data-type, you need to first define a new Python type to hold the scalars of your new data-type. It should be acceptable to inherit from one of the array scalars if your new type has a binary compatible layout. This will allow your new data type to have the methods and attributes of array scalars. New data- types must have a fixed memory size (if you want to define a data-type that needs a flexible representation, like a variable-precision number, then use a pointer to the object as the data-type). The memory layout of the object structure for the new Python type must be PyObject_HEAD followed by the fixed-size memory needed for the data- type. For example, a suitable structure for the new Python type is:

```
typedef struct {
PyObject_HEAD;
some_data_type obval;
/* the name can be whatever you want */
} PySomeDataTypeObject;
```
After you have defined a new Python type object, you must then define
a new [ PyArray_Descr](../reference/c-api/types-and-structures.html#c.PyArray_Descr) structure whose typeobject member will contain a
pointer to the data-type you’ve just defined. In addition, the
required functions in the “.f” member must be defined: nonzero,
copyswap, copyswapn, setitem, getitem, and cast. The more functions in
the “.f” member you define, however, the more useful the new data-type
will be. It is very important to initialize unused functions to NULL.
This can be achieved using

[(f).](../reference/c-api/array.html#c.PyArray_InitArrFuncs)
`PyArray_InitArrFuncs`
Once a new [ PyArray_Descr](../reference/c-api/types-and-structures.html#c.PyArray_Descr) structure is created and filled with the
needed information and useful functions you call

[(new_descr). The return value from this call is an integer providing you with a unique type_number that specifies your data-type. This type number should be stored and made available by your module so that other modules can use it to recognize your data-type (the other mechanism for finding a user-defined data-type number is to search based on the name of the type-object associated with the data-type using](../reference/c-api/array.html#c.PyArray_RegisterDataType)
`PyArray_RegisterDataType`
[).](../reference/c-api/array.html#c.PyArray_TypeNumFromName)
`PyArray_TypeNumFromName`
### Registering a casting function[#](#registering-a-casting-function)
You may want to allow builtin (and other user-defined) data-types to be cast automatically to your data-type. In order to make this possible, you must register a casting function with the data-type you want to be able to cast from. This requires writing low-level casting functions for each conversion you want to support and then registering these functions with the data-type descriptor. A low-level casting function has the signature.

void castfunc(void *from, void *to, [npy_intp](../reference/c-api/dtype.html#c.npy_intp)n, void *fromarr, void *toarr)[#](#c.castfunc)
-
Cast

`n`
elements`from`
one type`to`
another. The data to cast from is in a contiguous, correctly-swapped and aligned chunk of memory pointed to by from. The buffer to cast to is also contiguous, correctly-swapped and aligned. The fromarr and toarr arguments should only be used for flexible-element-sized arrays (string, unicode, void).
An example castfunc is:

```
static void
double_to_float(double *from, float* to, npy_intp n,
void* ignore1, void* ignore2) {
while (n--) {
(*to++) = (double) *(from++);
}
}
```
This could then be registered to convert doubles to floats using the code:

```
doub = PyArray_DescrFromType(NPY_DOUBLE);
PyArray_RegisterCastFunc(doub, NPY_FLOAT,
(PyArray_VectorUnaryFunc *)double_to_float);
Py_DECREF(doub);
```
### Registering coercion rules[#](#registering-coercion-rules)
By default, all user-defined data-types are not presumed to be safely
castable to any builtin data-types. In addition builtin data-types are
not presumed to be safely castable to user-defined data-types. This
situation limits the ability of user-defined data-types to participate
in the coercion system used by ufuncs and other times when automatic
coercion takes place in NumPy. This can be changed by registering
data-types as safely castable from a particular data-type object. The
function [ PyArray_RegisterCanCast](../reference/c-api/array.html#c.PyArray_RegisterCanCast) (from_descr, totype_number,
scalarkind) should be used to specify that the data-type object
from_descr can be cast to the data-type with type number
totype_number. If you are not trying to alter scalar coercion rules,
then use

[for the scalarkind argument.](../reference/c-api/array.html#c.NPY_SCALARKIND.NPY_NOSCALAR)
`NPY_NOSCALAR`
If you want to allow your new data-type to also be able to share in
the scalar coercion rules, then you need to specify the scalarkind
function in the data-type object’s “.f” member to return the kind of
scalar the new data-type should be seen as (the value of the scalar is
available to that function). Then, you can register data-types that
can be cast to separately for each scalar kind that may be returned
from your user-defined data-type. If you don’t register scalar
coercion handling, then all of your user-defined data-types will be
seen as [ NPY_NOSCALAR](../reference/c-api/array.html#c.NPY_SCALARKIND.NPY_NOSCALAR).

### Registering a ufunc loop[#](#registering-a-ufunc-loop)
You may also want to register low-level ufunc loops for your data-type so that an ndarray of your data-type can have math applied to it seamlessly. Registering a new loop with exactly the same arg_types signature, silently replaces any previously registered loops for that data-type.

Before you can register a 1-d loop for a ufunc, the ufunc must be
previously created. Then you call [ PyUFunc_RegisterLoopForType](../reference/c-api/ufunc.html#c.PyUFunc_RegisterLoopForType)
(…) with the information needed for the loop. The return value of
this function is

`0`
if the process was successful and `-1`
with
an error condition set if it was not successful.## Subtyping the ndarray in C[#](#subtyping-the-ndarray-in-c)
One of the lesser-used features that has been lurking in Python since 2.2 is the ability to sub-class types in C. This facility is one of the important reasons for basing NumPy off of the Numeric code-base which was already in C. A sub-type in C allows much more flexibility with regards to memory management. Sub-typing in C is not difficult even if you have only a rudimentary understanding of how to create new types for Python. While it is easiest to sub-type from a single parent type, sub-typing from multiple parent types is also possible. Multiple inheritance in C is generally less useful than it is in Python because a restriction on Python sub-types is that they have a binary compatible memory layout. Perhaps for this reason, it is somewhat easier to sub-type from a single parent type.

All C-structures corresponding to Python objects must begin with
[ PyObject_HEAD](https://docs.python.org/3/c-api/structures.html#c.PyObject_HEAD) (or

[). In the same way, any sub-type must have a C-structure that begins with exactly the same memory layout as the parent type (or all of the parent types in the case of multiple-inheritance). The reason for this is that Python may attempt to access a member of the sub-type structure as if it had the parent structure (](https://docs.python.org/3/c-api/structures.html#c.PyObject_VAR_HEAD)
`PyObject_VAR_HEAD`
*i.e.*it will cast a given pointer to a pointer to the parent structure and then dereference one of it’s members). If the memory layouts are not compatible, then this attempt will cause unpredictable behavior (eventually leading to a memory violation and program crash).
One of the elements in [ PyObject_HEAD](https://docs.python.org/3/c-api/structures.html#c.PyObject_HEAD) is a pointer to a
type-object structure. A new Python type is created by creating a new
type-object structure and populating it with functions and pointers to
describe the desired behavior of the type. Typically, a new
C-structure is also created to contain the instance-specific
information needed for each object of the type as well. For example,

[is a pointer to the type-object table for the ndarray while a](../reference/c-api/types-and-structures.html#c.PyArray_Type)
`&PyArray_Type`
[PyArrayObject](../reference/c-api/types-and-structures.html#c.PyArrayObject)* variable is a pointer to a particular instance of an ndarray (one of the members of the ndarray structure is, in turn, a pointer to the type- object table
[). Finally](../reference/c-api/types-and-structures.html#c.PyArray_Type)
`&PyArray_Type`
[(<pointer_to_type_object>) must be called for every new Python type.](https://docs.python.org/3/c-api/type.html#c.PyType_Ready)
`PyType_Ready`
### Creating sub-types[#](#creating-sub-types)
To create a sub-type, a similar procedure must be followed except
only behaviors that are different require new entries in the type-
object structure. All other entries can be NULL and will be filled in
by [ PyType_Ready](https://docs.python.org/3/c-api/type.html#c.PyType_Ready) with appropriate functions from the parent
type(s). In particular, to create a sub-type in C follow these steps:

If needed create a new C-structure to handle each instance of your type. A typical C-structure would be:

typedef _new_struct { PyArrayObject base; /* new things here */ } NewArrayObject;
Notice that the full PyArrayObject is used as the first entry in order to ensure that the binary layout of instances of the new type is identical to the PyArrayObject.

Fill in a new Python type-object structure with pointers to new functions that will over-ride the default behavior while leaving any function that should remain the same unfilled (or NULL). The tp_name element should be different.

Fill in the tp_base member of the new type-object structure with a pointer to the (main) parent type object. For multiple-inheritance, also fill in the tp_bases member with a tuple containing all of the parent objects in the order they should be used to define inheritance. Remember, all parent-types must have the same C-structure for multiple inheritance to work properly.

Call

(<pointer_to_new_type>). If this function returns a negative number, a failure occurred and the type is not initialized. Otherwise, the type is ready to be used. It is generally important to place a reference to the new type into the module dictionary so it can be accessed from Python.`PyType_Ready`
More information on creating sub-types in C can be learned by reading
PEP 253 (available at [https://www.python.org/dev/peps/pep-0253](https://www.python.org/dev/peps/pep-0253)).

### Specific features of ndarray sub-typing[#](#specific-features-of-ndarray-sub-typing)
Some special methods and attributes are used by arrays in order to facilitate the interoperation of sub-types with the base ndarray type.

#### The __array_finalize__ method[#](#the-array-finalize-method)
ndarray.__array_finalize__[#](#ndarray.__array_finalize__)
-
Several array-creation functions of the ndarray allow specification of a particular sub-type to be created. This allows sub-types to be handled seamlessly in many routines. When a sub-type is created in such a fashion, however, neither the __new__ method nor the __init__ method gets called. Instead, the sub-type is allocated and the appropriate instance-structure members are filled in. Finally, the

attribute is looked-up in the object dictionary. If it is present and not None, then it can be either a`__array_finalize__`
containing a pointer to a`PyCapsule`
or it can be a method taking a single argument (which could be None)`PyArray_FinalizeFunc`
If the

attribute is a`__array_finalize__`
, then the pointer must be a pointer to a function with the signature:`PyCapsule`
(int) (PyArrayObject *, PyObject *)
The first argument is the newly created sub-type. The second argument (if not NULL) is the “parent” array (if the array was created using slicing or some other operation where a clearly-distinguishable parent is present). This routine can do anything it wants to. It should return a -1 on error and 0 otherwise.

If the

attribute is not None nor a`__array_finalize__`
, then it must be a Python method that takes the parent array as an argument (which could be None if there is no parent), and returns nothing. Errors in this method will be caught and handled.`PyCapsule`
#### The __array_priority__ attribute[#](#the-array-priority-attribute)
ndarray.__array_priority__[#](#ndarray.__array_priority__)
-
This attribute allows simple but flexible determination of which sub- type should be considered “primary” when an operation involving two or more sub-types arises. In operations where different sub-types are being used, the sub-type with the largest

attribute will determine the sub-type of the output(s). If two sub- types have the same`__array_priority__`
then the sub-type of the first argument determines the output. The default`__array_priority__`
attribute returns a value of 0.0 for the base ndarray type and 1.0 for a sub-type. This attribute can also be defined by objects that are not sub-types of the ndarray and can be used to determine which`__array_priority__`
method should be called for the return output.`__array_wrap__`
#### The __array_wrap__ method[#](#the-array-wrap-method)
ndarray.__array_wrap__[#](#ndarray.__array_wrap__)
-
Any class or type can define this method which should take an ndarray argument and return an instance of the type. It can be seen as the opposite of the

method. This method is used by the ufuncs (and other NumPy functions) to allow other objects to pass through. For Python >2.4, it can also be used to write a decorator that converts a function that works only with ndarrays to one that works with any type with`__array__`
and`__array__`
methods.`__array_wrap__`# numpy.tanh[#](#numpy-tanh)
numpy.tanh(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'tanh'>*[#](#numpy.tanh)
-
Compute hyperbolic tangent element-wise.

Equivalent to

`np.sinh(x)/np.cosh(x)`
or`-1j * np.tan(1j*x)`
.Parameters:
-
**x**array_like
Input array.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray
The corresponding hyperbolic tangent values. This is a scalar if

*x*is a scalar.
Notes

If

*out*is provided, the function writes the result into it, and returns a reference to*out*. (See Examples)References

[1]M. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions. New York, NY: Dover, 1972, pg. 83.

[https://personal.math.ubc.ca/~cbm/aands/page_83.htm](https://personal.math.ubc.ca/~cbm/aands/page_83.htm)[2]Wikipedia, “Hyperbolic function”,

[https://en.wikipedia.org/wiki/Hyperbolic_function](https://en.wikipedia.org/wiki/Hyperbolic_function)Examples

>>> np.tanh((0, np.pi*1j, np.pi*1j/2)) array([ 0. +0.00000000e+00j, 0. -1.22460635e-16j, 0. +1.63317787e+16j])
>>> # Example of providing the optional output parameter illustrating >>> # that what is returned is a reference to said parameter >>> out1 = np.array([0], dtype='d') >>> out2 = np.tanh([0.1], out1) >>> out2 is out1 True
>>> # Example of ValueError due to provision of shape mis-matched `out` >>> np.tanh(np.zeros((3,3)),np.zeros((2,2))) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: operands could not be broadcast together with shapes (3,3) (2,2)# numpy.linalg.matrix_rank[#](#numpy-linalg-matrix-rank)
linalg.matrix_rank(*A*,*tol=None*,*hermitian=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L1825-L1927)[#](#numpy.linalg.matrix_rank)
-
Return matrix rank of array using SVD method

Rank of the array is the number of singular values of the array that are greater than

*tol*.Changed in version 1.14: Can now operate on stacks of matrices

Parameters:
-
**A**{(M,), (…, M, N)} array_like
Input vector or stack of matrices.

**tol**(…) array_like, float, optional
Threshold below which SVD values are considered zero. If

*tol*is None, and`S`
is an array with singular values for*M*, and`eps`
is the epsilon value for datatype of`S`
, then*tol*is set to`S.max() * max(M, N) * eps`
.Changed in version 1.14: Broadcasted against the stack of matrices

**hermitian**bool, optional
If True,

*A*is assumed to be Hermitian (symmetric if real-valued), enabling a more efficient method for finding singular values. Defaults to False.New in version 1.14.

Returns:
-
**rank**(…) array_like
Rank of A.

Notes

The default threshold to detect rank deficiency is a test on the magnitude of the singular values of

*A*. By default, we identify singular values less than`S.max() * max(M, N) * eps`
as indicating rank deficiency (with the symbols defined above). This is the algorithm MATLAB uses [1]. It also appears in*Numerical recipes*in the discussion of SVD solutions for linear least squares [2].This default threshold is designed to detect rank deficiency accounting for the numerical errors of the SVD computation. Imagine that there is a column in

*A*that is an exact (in floating point) linear combination of other columns in*A*. Computing the SVD on*A*will not produce a singular value exactly equal to 0 in general: any difference of the smallest SVD value from 0 will be caused by numerical imprecision in the calculation of the SVD. Our threshold for small SVD values takes this numerical imprecision into account, and the default threshold will detect such numerical rank deficiency. The threshold may declare a matrix*A*rank deficient even if the linear combination of some columns of*A*is not exactly equal to another column of*A*but only numerically very close to another column of*A*.We chose our default threshold because it is in wide use. Other thresholds are possible. For example, elsewhere in the 2007 edition of

*Numerical recipes*there is an alternative threshold of`S.max() * np.finfo(A.dtype).eps / 2. * np.sqrt(m + n + 1.)`
. The authors describe this threshold as being based on “expected roundoff error” (p 71).The thresholds above deal with floating point roundoff error in the calculation of the SVD. However, you may have more information about the sources of error in

*A*that would make you consider other tolerance values to detect*effective*rank deficiency. The most useful measure of the tolerance depends on the operations you intend to use on your matrix. For example, if your data come from uncertain measurements with uncertainties greater than floating point epsilon, choosing a tolerance near that uncertainty may be preferable. The tolerance may be absolute if the uncertainties are absolute rather than relative.References

[1]MATLAB reference documentation, “Rank”

[https://www.mathworks.com/help/techdoc/ref/rank.html](https://www.mathworks.com/help/techdoc/ref/rank.html)[2]W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery, “Numerical Recipes (3rd edition)”, Cambridge University Press, 2007, page 795.

Examples

>>> from numpy.linalg import matrix_rank >>> matrix_rank(np.eye(4)) # Full rank matrix 4 >>> I=np.eye(4); I[-1,-1] = 0. # rank deficient matrix >>> matrix_rank(I) 3 >>> matrix_rank(np.ones((4,))) # 1 dimension - rank 1 unless all 0 1 >>> matrix_rank(np.zeros((4,))) 0# numpy.random.RandomState.multivariate_normal[#](#numpy-random-randomstate-multivariate-normal)
method

random.RandomState.multivariate_normal(*mean*,*cov*,*size=None*,*check_valid='warn'*,*tol=1e-8*)[#](#numpy.random.RandomState.multivariate_normal)
-
Draw random samples from a multivariate normal distribution.

The multivariate normal, multinormal or Gaussian distribution is a generalization of the one-dimensional normal distribution to higher dimensions. Such a distribution is specified by its mean and covariance matrix. These parameters are analogous to the mean (average or “center”) and variance (standard deviation, or “width,” squared) of the one-dimensional normal distribution.

Note

New code should use the

method of a`multivariate_normal`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**mean**1-D array_like, of length N
Mean of the N-dimensional distribution.

**cov**2-D array_like, of shape (N, N)
Covariance matrix of the distribution. It must be symmetric and positive-semidefinite for proper sampling.

**size**int or tuple of ints, optional
Given a shape of, for example,

`(m,n,k)`
,`m*n*k`
samples are generated, and packed in an*m*-by-*n*-by-*k*arrangement. Because each sample is*N*-dimensional, the output shape is`(m,n,k,N)`
. If no shape is specified, a single (*N*-D) sample is returned.
**check_valid**{ ‘warn’, ‘raise’, ‘ignore’ }, optional
Behavior when the covariance matrix is not positive semidefinite.

**tol**float, optional
Tolerance when checking the singular values in covariance matrix. cov is cast to double before the check.

Returns:
-
**out**ndarray
The drawn samples, of shape

*size*, if that was provided. If not, the shape is`(N,)`
.In other words, each entry

`out[i,j,...,:]`
is an N-dimensional value drawn from the distribution.
See also

`random.Generator.multivariate_normal`
which should be used for new code.

Notes

The mean is a coordinate in N-dimensional space, which represents the location where samples are most likely to be generated. This is analogous to the peak of the bell curve for the one-dimensional or univariate normal distribution.

Covariance indicates the level to which two variables vary together. From the multivariate normal distribution, we draw N-dimensional samples, \(X = [x_1, x_2, ... x_N]\). The covariance matrix element \(C_{ij}\) is the covariance of \(x_i\) and \(x_j\). The element \(C_{ii}\) is the variance of \(x_i\) (i.e. its “spread”).

Instead of specifying the full covariance matrix, popular approximations include:

This geometrical property can be seen in two dimensions by plotting generated data-points:

>>> mean = [0, 0] >>> cov = [[1, 0], [0, 100]] # diagonal covariance
Diagonal covariance means that points are oriented along x or y-axis:

>>> import matplotlib.pyplot as plt >>> x, y = np.random.multivariate_normal(mean, cov, 5000).T >>> plt.plot(x, y, 'x') >>> plt.axis('equal') >>> plt.show()
Note that the covariance matrix must be positive semidefinite (a.k.a. nonnegative-definite). Otherwise, the behavior of this method is undefined and backwards compatibility is not guaranteed.

References

[1]Papoulis, A., “Probability, Random Variables, and Stochastic Processes,” 3rd ed., New York: McGraw-Hill, 1991.

[2]Duda, R. O., Hart, P. E., and Stork, D. G., “Pattern Classification,” 2nd ed., New York: Wiley, 2001.

Examples

>>> mean = (1, 2) >>> cov = [[1, 0], [0, 1]] >>> x = np.random.multivariate_normal(mean, cov, (3, 3)) >>> x.shape (3, 3, 2)
Here we generate 800 samples from the bivariate normal distribution with mean [0, 0] and covariance matrix [[6, -3], [-3, 3.5]]. The expected variances of the first and second components of the sample are 6 and 3.5, respectively, and the expected correlation coefficient is -3/sqrt(6*3.5) ≈ -0.65465.

>>> cov = np.array([[6, -3], [-3, 3.5]]) >>> pts = np.random.multivariate_normal([0, 0], cov, size=800)
Check that the mean, covariance, and correlation coefficient of the sample are close to the expected values:

>>> pts.mean(axis=0) array([ 0.0326911 , -0.01280782]) # may vary >>> np.cov(pts.T) array([[ 5.96202397, -2.85602287], [-2.85602287, 3.47613949]]) # may vary >>> np.corrcoef(pts.T)[0, 1] -0.6273591314603949 # may vary
We can visualize this data with a scatter plot. The orientation of the point cloud illustrates the negative correlation of the components of this sample.

>>> import matplotlib.pyplot as plt >>> plt.plot(pts[:, 0], pts[:, 1], '.', alpha=0.5) >>> plt.axis('equal') >>> plt.grid() >>> plt.show()# numpy.histogramdd[#](#numpy-histogramdd)
numpy.histogramdd(*sample*,*bins=10*,*range=None*,*density=None*,*weights=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/histograms.py#L901-L1072)[#](#numpy.histogramdd)
-
Compute the multidimensional histogram of some data.

Parameters:
-
**sample**(N, D) array, or (N, D) array_like
The data to be histogrammed.

Note the unusual interpretation of sample when an array_like:

When an array, each row is a coordinate in a D-dimensional space - such as

`histogramdd(np.array([p1, p2, p3]))`
.
When an array_like, each element is the list of values for single coordinate - such as

`histogramdd((X, Y, Z))`
.
The first form should be preferred.

**bins**sequence or int, optional
The bin specification:

A sequence of arrays describing the monotonically increasing bin edges along each dimension.

The number of bins for each dimension (nx, ny, … =bins)

The number of bins for all dimensions (nx=ny=…=bins).

**range**sequence, optional
A sequence of length D, each an optional (lower, upper) tuple giving the outer bin edges to be used if the edges are not given explicitly in

*bins*. An entry of None in the sequence results in the minimum and maximum values being used for the corresponding dimension. The default, None, is equivalent to passing a tuple of D None values.
**density**bool, optional
If False, the default, returns the number of samples in each bin. If True, returns the probability

*density*function at the bin,`bin_count / sample_count / bin_volume`
.
**weights**(N,) array_like, optional
An array of values

*w_i*weighing each sample*(x_i, y_i, z_i, …)*. Weights are normalized to 1 if density is True. If density is False, the values of the returned histogram are equal to the sum of the weights belonging to the samples falling into each bin.
Returns:
-
**H**ndarray
The multidimensional histogram of sample x. See density and weights for the different possible semantics.

**edges**list
A list of D arrays describing the bin edges for each dimension.

See also

`histogram`
1-D histogram

`histogram2d`
2-D histogram

Examples

>>> r = np.random.randn(100,3) >>> H, edges = np.histogramdd(r, bins = (5, 8, 4)) >>> H.shape, edges[0].size, edges[1].size, edges[2].size ((5, 8, 4), 6, 9, 5)# numpy.geterr[#](#numpy-geterr)
numpy.geterr()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_ufunc_config.py#L132-L179)[#](#numpy.geterr)
-
Get the current way of handling floating-point errors.

Returns:
-
**res**dict
A dictionary with keys “divide”, “over”, “under”, and “invalid”, whose values are from the strings “ignore”, “print”, “log”, “warn”, “raise”, and “call”. The keys represent possible floating-point exceptions, and the values define how these exceptions are handled.

See also

Notes

For complete documentation of the types of floating-point exceptions and treatment options, see

.`seterr`
Examples

>>> np.geterr() {'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'} >>> np.arange(3.) / np.arange(3.) array([nan, 1., 1.])
>>> oldsettings = np.seterr(all='warn', over='raise') >>> np.geterr() {'divide': 'warn', 'over': 'raise', 'under': 'warn', 'invalid': 'warn'} >>> np.arange(3.) / np.arange(3.) array([nan, 1., 1.])# numpy.deprecate[#](#numpy-deprecate)
numpy.deprecate(**args*,***kwargs*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/utils.py#L186-L236)[#](#numpy.deprecate)
-
Issues a DeprecationWarning, adds warning to

*old_name*’s docstring, rebinds`old_name.__name__`
and returns the new function object.This function may also be used as a decorator.

Parameters:
-
**func**function
The function to be deprecated.

**old_name**str, optional
The name of the function to be deprecated. Default is None, in which case the name of

*func*is used.
**new_name**str, optional
The new name for the function. Default is None, in which case the deprecation message is that

*old_name*is deprecated. If given, the deprecation message is that*old_name*is deprecated and*new_name*should be used instead.
**message**str, optional
Additional explanation of the deprecation. Displayed in the docstring after the warning.

Returns:
-
**old_func**function
The deprecated function.

Examples

Note that

`olduint`
returns a value after printing Deprecation Warning:>>> olduint = np.deprecate(np.uint) DeprecationWarning: `uint64` is deprecated! # may vary >>> olduint(6) 6# numpy.char.chararray.reshape[#](#numpy-char-chararray-reshape)
method

char.chararray.reshape(*shape*,*order='C'*)[#](#numpy.char.chararray.reshape)
-
Returns an array containing the same data with a new shape.

Refer to

for full documentation.`numpy.reshape`
See also

`numpy.reshape`
equivalent function

Notes

Unlike the free function

, this method on`numpy.reshape`
allows the elements of the shape parameter to be passed in as separate arguments. For example,`ndarray`
`a.reshape(10, 11)`
is equivalent to`a.reshape((10, 11))`
.# numpy.polynomial.legendre.leggauss[#](#numpy-polynomial-legendre-leggauss)
polynomial.legendre.leggauss(*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L1520-L1585)[#](#numpy.polynomial.legendre.leggauss)
-
Gauss-Legendre quadrature.

Computes the sample points and weights for Gauss-Legendre quadrature. These sample points and weights will correctly integrate polynomials of degree \(2*deg - 1\) or less over the interval \([-1, 1]\) with the weight function \(f(x) = 1\).

Parameters:
-
**deg**int
Number of sample points and weights. It must be >= 1.

Returns:
-
**x**ndarray
1-D ndarray containing the sample points.

**y**ndarray
1-D ndarray containing the weights.

Notes

New in version 1.7.0.

The results have only been tested up to degree 100, higher degrees may be problematic. The weights are determined by using the fact that

\[w_k = c / (L'_n(x_k) * L_{n-1}(x_k))\]where \(c\) is a constant independent of \(k\) and \(x_k\) is the k’th root of \(L_n\), and then scaling the results to get the right value when integrating 1.# numpy.round[#](#numpy-round)
numpy.round(*a*,*decimals=0*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L3269-L3360)[#](#numpy.round)
-
Evenly round to the given number of decimals.

Parameters:
-
**a**array_like
Input data.

**decimals**int, optional
Number of decimal places to round to (default: 0). If decimals is negative, it specifies the number of positions to the left of the decimal point.

**out**ndarray, optional
Alternative output array in which to place the result. It must have the same shape as the expected output, but the type of the output values will be cast if necessary. See

[Output type determination](../../user/basics.ufuncs.html#ufuncs-output-type)for more details.
Returns:
-
**rounded_array**ndarray
An array of the same type as

*a*, containing the rounded values. Unless*out*was specified, a new array is created. A reference to the result is returned.The real and imaginary parts of complex numbers are rounded separately. The result of rounding a float is a float.

See also

Notes

For values exactly halfway between rounded decimal values, NumPy rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0, -0.5 and 0.5 round to 0.0, etc.

`np.round`
uses a fast but sometimes inexact algorithm to round floating-point datatypes. For positive*decimals*it is equivalent to`np.true_divide(np.rint(a * 10**decimals), 10**decimals)`
, which has error due to the inexact representation of decimal fractions in the IEEE floating point standard[[1]](#r25ee6110317b-1)and errors introduced when scaling by powers of ten. For instance, note the extra “1” in the following:>>> np.round(56294995342131.5, 3) 56294995342131.51
If your goal is to print such values with a fixed number of decimals, it is preferable to use numpy’s float printing routines to limit the number of printed decimals:

>>> np.format_float_positional(56294995342131.5, precision=3) '56294995342131.5'
The float printing routines use an accurate but much more computationally demanding algorithm to compute the number of digits after the decimal point.

Alternatively, Python’s builtin

function uses a more accurate but slower algorithm for 64-bit floating point values:`round`
>>> round(56294995342131.5, 3) 56294995342131.5 >>> np.round(16.055, 2), round(16.055, 2) # equals 16.0549999999999997 (16.06, 16.05)
References

[[1](#id1)]“Lecture Notes on the Status of IEEE 754”, William Kahan,

[https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF](https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF)Examples

>>> np.round([0.37, 1.64]) array([0., 2.]) >>> np.round([0.37, 1.64], decimals=1) array([0.4, 1.6]) >>> np.round([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value array([0., 2., 2., 4., 4.]) >>> np.round([1,2,3,11], decimals=1) # ndarray of ints is returned array([ 1, 2, 3, 11]) >>> np.round([1,2,3,11], decimals=-1) array([ 0, 0, 0, 10])# numpy.ma.MaskedArray.flatten[#](#numpy-ma-maskedarray-flatten)
method

ma.MaskedArray.flatten(*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2571-L2581)[#](#numpy.ma.MaskedArray.flatten)
-
Return a copy of the array collapsed into one dimension.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
‘C’ means to flatten in row-major (C-style) order. ‘F’ means to flatten in column-major (Fortran- style) order. ‘A’ means to flatten in column-major order if

*a*is Fortran*contiguous*in memory, row-major order otherwise. ‘K’ means to flatten*a*in the order the elements occur in memory. The default is ‘C’.
Returns:
-
**y**ndarray
A copy of the input array, flattened to one dimension.

Examples

>>> a = np.array([[1,2], [3,4]]) >>> a.flatten() array([1, 2, 3, 4]) >>> a.flatten('F') array([1, 3, 2, 4])# numpy.ma.hstack[#](#numpy-ma-hstack)
ma.hstack*= <numpy.ma.extras._fromnxfunction_seq object>*[#](#numpy.ma.hstack)
-
hstack

Stack arrays in sequence horizontally (column wise).

This is equivalent to concatenation along the second axis, except for 1-D arrays where it concatenates along the first axis. Rebuilds arrays divided by

.`hsplit`
This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions

,`concatenate`
and`stack`
provide more general stacking and concatenation operations.`block`
Parameters:
-
**tup**sequence of ndarrays
The arrays must have the same shape along all but the second axis, except 1-D arrays which can be any length.

**dtype**str or dtype
If provided, the destination array will have this dtype. Cannot be provided together with

*out*.
**.. versionadded:: 1.24**
**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘same_kind’.

**.. versionadded:: 1.24**
Returns:
-
**stacked**ndarray
The array formed by stacking the given arrays.

See also

`concatenate`
Join a sequence of arrays along an existing axis.

`stack`
Join a sequence of arrays along a new axis.

`block`
Assemble an nd-array from nested lists of blocks.

`vstack`
Stack arrays in sequence vertically (row wise).

`dstack`
Stack arrays in sequence depth wise (along third axis).

`column_stack`
Stack 1-D arrays as columns into a 2-D array.

`hsplit`
Split an array into multiple sub-arrays horizontally (column-wise).

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> a = np.array((1,2,3)) >>> b = np.array((4,5,6)) >>> np.hstack((a,b)) array([1, 2, 3, 4, 5, 6]) >>> a = np.array([[1],[2],[3]]) >>> b = np.array([[4],[5],[6]]) >>> np.hstack((a,b)) array([[1, 4], [2, 5], [3, 6]])# numpy.ma.masked_array.setflags[#](#numpy-ma-masked-array-setflags)
method

ma.masked_array.setflags(*write=None*,*align=None*,*uic=None*)[#](#numpy.ma.masked_array.setflags)
-
Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY, respectively.

These Boolean-valued flags affect how numpy interprets the memory area used by

*a*(see Notes below). The ALIGNED flag can only be set to True if the data is actually aligned according to the type. The WRITEBACKIFCOPY and flag can never be set to True. The flag WRITEABLE can only be set to True if the array owns its own memory, or the ultimate owner of the memory exposes a writeable buffer interface, or is a string. (The exception for string is made so that unpickling can be done without copying memory.)Parameters:
-
**write**bool, optional
Describes whether or not

*a*can be written to.
**align**bool, optional
Describes whether or not

*a*is aligned properly for its type.
**uic**bool, optional
Describes whether or not

*a*is a copy of another “base” array.
Notes

Array flags provide information about how the memory area used for the array is to be interpreted. There are 7 Boolean flags in use, only four of which can be changed by the user: WRITEBACKIFCOPY, WRITEABLE, and ALIGNED.

WRITEABLE (W) the data area can be written to;

ALIGNED (A) the data and strides are aligned appropriately for the hardware (as determined by the compiler);

WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by .base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the base array will be updated with the contents of this array.

All flags can be accessed using the single (upper case) letter as well as the full name.

Examples

>>> y = np.array([[3, 1, 7], ... [2, 0, 0], ... [8, 5, 9]]) >>> y array([[3, 1, 7], [2, 0, 0], [8, 5, 9]]) >>> y.flags C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False >>> y.setflags(write=0, align=0) >>> y.flags C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : False ALIGNED : False WRITEBACKIFCOPY : False >>> y.setflags(uic=1) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: cannot set WRITEBACKIFCOPY flag to True# numpy.dtype.fields[#](#numpy-dtype-fields)
attribute

dtype.fields[#](#numpy.dtype.fields)
-
Dictionary of named fields defined for this data type, or

`None`
.The dictionary is indexed by keys that are the names of the fields. Each entry in the dictionary is a tuple fully describing the field:

(dtype, offset[, title])
Offset is limited to C int, which is signed and usually 32 bits. If present, the optional title can be any object (if it is a string or unicode then it will also be a key in the fields dictionary, otherwise it’s meta-data). Notice also that the first two elements of the tuple can be passed directly as arguments to the

`ndarray.getfield`
and`ndarray.setfield`
methods.See also

Examples

>>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))]) >>> print(dt.fields) {'grades': (dtype(('float64',(2,))), 16), 'name': (dtype('|S16'), 0)}# numpy.polynomial.polynomial.polyder[#](#numpy-polynomial-polynomial-polyder)
polynomial.polynomial.polyder(*c*,*m=1*,*scl=1*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L463-L542)[#](#numpy.polynomial.polynomial.polyder)
-
Differentiate a polynomial.

Returns the polynomial coefficients

*c*differentiated*m*times along*axis*. At each iteration the result is multiplied by*scl*(the scaling factor is for use in a linear change of variable). The argument*c*is an array of coefficients from low to high degree along each axis, e.g., [1,2,3] represents the polynomial`1 + 2*x + 3*x**2`
while [[1,2],[1,2]] represents`1 + 1*x + 2*y + 2*x*y`
if axis=0 is`x`
and axis=1 is`y`
.Parameters:
-
**c**array_like
Array of polynomial coefficients. If c is multidimensional the different axis correspond to different variables with the degree in each axis given by the corresponding index.

**m**int, optional
Number of derivatives taken, must be non-negative. (Default: 1)

**scl**scalar, optional
Each differentiation is multiplied by

*scl*. The end result is multiplication by`scl**m`
. This is for use in a linear change of variable. (Default: 1)
**axis**int, optional
Axis over which the derivative is taken. (Default: 0).

New in version 1.7.0.

Returns:
-
**der**ndarray
Polynomial coefficients of the derivative.

See also

Examples

>>> from numpy.polynomial import polynomial as P >>> c = (1,2,3,4) # 1 + 2x + 3x**2 + 4x**3 >>> P.polyder(c) # (d/dx)(c) = 2 + 6x + 12x**2 array([ 2., 6., 12.]) >>> P.polyder(c,3) # (d**3/dx**3)(c) = 24 array([24.]) >>> P.polyder(c,scl=-1) # (d/d(-x))(c) = -2 - 6x - 12x**2 array([ -2., -6., -12.]) >>> P.polyder(c,2,-1) # (d**2/d(-x)**2)(c) = 6 + 24x array([ 6., 24.])# numpy.ndarray.ctypes[#](#numpy-ndarray-ctypes)
attribute

ndarray.ctypes[#](#numpy.ndarray.ctypes)
-
An object to simplify the interaction of the array with the ctypes module.

This attribute creates an object that makes it easier to use arrays when calling shared libraries with the ctypes module. The returned object has, among others, data, shape, and strides attributes (see Notes below) which themselves return ctypes objects that can be used as arguments to a shared library.

Parameters:
-
**None**
Returns:
-
**c**Python object
Possessing attributes data, shape, strides, etc.

See also

Notes

Below are the public attributes of this object which were documented in “Guide to NumPy” (we have omitted undocumented public attributes, as well as documented private attributes):

_ctypes.data
-
A pointer to the memory area of the array as a Python integer. This memory area may contain data that is not aligned, or not in correct byte-order. The memory area may not even be writeable. The array flags and data-type of this array should be respected when passing this attribute to arbitrary C-code to avoid trouble that can include Python crashing. User Beware! The value of this attribute is exactly the same as

`self._array_interface_['data'][0]`
.Note that unlike

`data_as`
, a reference will not be kept to the array: code like`ctypes.c_void_p((a + b).ctypes.data)`
will result in a pointer to a deallocated array, and should be spelt`(a + b).ctypes.data_as(ctypes.c_void_p)`
_ctypes.shape
-
(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the C-integer corresponding to

`dtype('p')`
on this platform (see). This base-type could be`c_intp`
,`ctypes.c_int`
, or`ctypes.c_long`
depending on the platform. The ctypes array contains the shape of the underlying array.`ctypes.c_longlong`
_ctypes.strides
-
(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the same as for the shape attribute. This ctypes array contains the strides information from the underlying array. This strides information is important for showing how many bytes must be jumped to get to the next element in the array.

_ctypes.data_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L267-L284)
-
Return the data pointer cast to a particular c-types object. For example, calling

`self._as_parameter_`
is equivalent to`self.data_as(ctypes.c_void_p)`
. Perhaps you want to use the data as a pointer to a ctypes array of floating-point data:`self.data_as(ctypes.POINTER(ctypes.c_double))`
.The returned pointer will keep a reference to the array.

_ctypes.shape_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L286-L293)
-
Return the shape tuple as an array of some other c-types type. For example:

`self.shape_as(ctypes.c_short)`
.
_ctypes.strides_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L295-L302)
-
Return the strides tuple as an array of some other c-types type. For example:

`self.strides_as(ctypes.c_longlong)`
.
If the ctypes module is not available, then the ctypes attribute of array objects still returns something useful, but ctypes objects are not returned and errors may be raised instead. In particular, the object will still have the

`as_parameter`
attribute which will return an integer equal to the data attribute.Examples

>>> import ctypes >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32) >>> x array([[0, 1], [2, 3]], dtype=int32) >>> x.ctypes.data 31962608 # may vary >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)) <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents c_uint(0) >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents c_ulong(4294967296) >>> x.ctypes.shape <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary >>> x.ctypes.strides <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary# numpy.random.Generator.noncentral_f[#](#numpy-random-generator-noncentral-f)
method

random.Generator.noncentral_f(*dfnum*,*dfden*,*nonc*,*size=None*)[#](#numpy.random.Generator.noncentral_f)
-
Draw samples from the noncentral F distribution.

Samples are drawn from an F distribution with specified parameters,

*dfnum*(degrees of freedom in numerator) and*dfden*(degrees of freedom in denominator), where both parameters > 1.*nonc*is the non-centrality parameter.Parameters:
-
**dfnum**float or array_like of floats
Numerator degrees of freedom, must be > 0.

Changed in version 1.14.0: Earlier NumPy versions required dfnum > 1.

**dfden**float or array_like of floats
Denominator degrees of freedom, must be > 0.

**nonc**float or array_like of floats
Non-centrality parameter, the sum of the squares of the numerator means, must be >= 0.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`dfnum`
,`dfden`
, and`nonc`
are all scalars. Otherwise,`np.broadcast(dfnum, dfden, nonc).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized noncentral Fisher distribution.

Notes

When calculating the power of an experiment (power = probability of rejecting the null hypothesis when a specific alternative is true) the non-central F statistic becomes important. When the null hypothesis is true, the F statistic follows a central F distribution. When the null hypothesis is not true, then it follows a non-central F statistic.

References

[1]Weisstein, Eric W. “Noncentral F-Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/NoncentralF-Distribution.html](http://mathworld.wolfram.com/NoncentralF-Distribution.html)[2]Wikipedia, “Noncentral F-distribution”,

[https://en.wikipedia.org/wiki/Noncentral_F-distribution](https://en.wikipedia.org/wiki/Noncentral_F-distribution)Examples

In a study, testing for a specific alternative to the null hypothesis requires use of the Noncentral F distribution. We need to calculate the area in the tail of the distribution that exceeds the value of the F distribution for the null hypothesis. We’ll plot the two probability distributions for comparison.

>>> rng = np.random.default_rng() >>> dfnum = 3 # between group deg of freedom >>> dfden = 20 # within groups degrees of freedom >>> nonc = 3.0 >>> nc_vals = rng.noncentral_f(dfnum, dfden, nonc, 1000000) >>> NF = np.histogram(nc_vals, bins=50, density=True) >>> c_vals = rng.f(dfnum, dfden, 1000000) >>> F = np.histogram(c_vals, bins=50, density=True) >>> import matplotlib.pyplot as plt >>> plt.plot(F[1][1:], F[0]) >>> plt.plot(NF[1][1:], NF[0]) >>> plt.show()# NumPy C code explanations[#](#numpy-c-code-explanations)
Fanaticism consists of redoubling your efforts when you have forgotten your aim. —

George SantayanaAn authority is a person who can tell you more about something than you really care to know. —

Unknown
This page attempts to explain the logic behind some of the new pieces of code. The purpose behind these explanations is to enable somebody to be able to understand the ideas behind the implementation somewhat more easily than just staring at the code. Perhaps in this way, the algorithms can be improved on, borrowed from, and/or optimized by more people.

## Memory model[#](#memory-model)
One fundamental aspect of the [ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray) is that an array is seen as a
“chunk” of memory starting at some location. The interpretation of
this memory depends on the

[stride](../glossary.html#term-stride)information. For each dimension in an \(N\)-dimensional array, an integer (
[stride](../glossary.html#term-stride)) dictates how many bytes must be skipped to get to the next element in that dimension. Unless you have a single-segment array, this
[stride](../glossary.html#term-stride)information must be consulted when traversing through an array. It is not difficult to write code that accepts strides, you just have to use
`char*`
pointers because strides are in units of bytes. Keep in mind also that
strides do not have to be unit-multiples of the element size. Also,
remember that if the number of dimensions of the array is 0 (sometimes
called a `rank-0`
array), then the [strides](../glossary.html#term-stride)and
[dimensions](../glossary.html#term-dimension)variables are
`NULL`
.Besides the structural information contained in the strides and
dimensions members of the [ PyArrayObject](../reference/c-api/types-and-structures.html#c.PyArrayObject), the flags contain
important information about how the data may be accessed. In particular,
the

[flag is set when the memory is on a suitable boundary according to the datatype array. Even if you have a](../reference/c-api/array.html#c.NPY_ARRAY_ALIGNED)
`NPY_ARRAY_ALIGNED`
[contiguous](../glossary.html#term-contiguous)chunk of memory, you cannot just assume it is safe to dereference a datatype-specific pointer to an element. Only if the
[flag is set, this is a safe operation. On some platforms it will work but on others, like Solaris, it will cause a bus error. The](../reference/c-api/array.html#c.NPY_ARRAY_ALIGNED)
`NPY_ARRAY_ALIGNED`
[should also be ensured if you plan on writing to the memory area of the array. It is also possible to obtain a pointer to an unwritable memory area. Sometimes, writing to the memory area when the](../reference/c-api/array.html#c.NPY_ARRAY_WRITEABLE)
`NPY_ARRAY_WRITEABLE`
[flag is not set will just be rude. Other times it can cause program crashes (](../reference/c-api/array.html#c.NPY_ARRAY_WRITEABLE)
`NPY_ARRAY_WRITEABLE`
*e.g.*a data-area that is a read-only memory-mapped file).
## Data-type encapsulation[#](#data-type-encapsulation)
See also

The [datatype](../reference/arrays.dtypes.html#arrays-dtypes) is an important abstraction of the
[ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray). Operations
will look to the datatype to provide the key functionality that is
needed to operate on the array. This functionality is provided in the
list of function pointers pointed to by the

`f`
member of the
[structure. In this way, the number of datatypes can be extended simply by providing a](../reference/c-api/types-and-structures.html#c.PyArray_Descr)
`PyArray_Descr`
[structure with suitable function pointers in the](../reference/c-api/types-and-structures.html#c.PyArray_Descr)
`PyArray_Descr`
`f`
member. For built-in types, there are some
optimizations that bypass this mechanism, but the point of the datatype
abstraction is to allow new datatypes to be added.One of the built-in datatypes, the [ void](../reference/arrays.scalars.html#numpy.void) datatype allows for
arbitrary

[structured types](../glossary.html#term-structured-data-type)containing 1 or more fields as elements of the array. A
[field](../glossary.html#term-field)is simply another datatype object along with an offset into the current structured type. In order to support arbitrarily nested fields, several recursive implementations of datatype access are implemented for the void type. A common idiom is to cycle through the elements of the dictionary and perform a specific operation based on the datatype object stored at the given offset. These offsets can be arbitrary numbers. Therefore, the possibility of encountering misaligned data must be recognized and taken into account if necessary.
## N-D Iterators[#](#n-d-iterators)
See also

A very common operation in much of NumPy code is the need to iterate
over all the elements of a general, strided, N-dimensional array. This
operation of a general-purpose N-dimensional loop is abstracted in the
notion of an iterator object. To write an N-dimensional loop, you only
have to create an iterator object from an ndarray, work with the
[ dataptr](../reference/c-api/types-and-structures.html#c.PyArrayIterObject.dataptr) member of the iterator object
structure and call the macro

[on the iterator object to move to the next element. The](../reference/c-api/array.html#c.PyArray_ITER_NEXT)
`PyArray_ITER_NEXT`
`next`
element is always in
C-contiguous order. The macro works by first special-casing the C-contiguous,
1-D, and 2-D cases which work very simply.For the general case, the iteration works by keeping track of a list
of coordinate counters in the iterator object. At each iteration, the
last coordinate counter is increased (starting from 0). If this
counter is smaller than one less than the size of the array in that
dimension (a pre-computed and stored value), then the counter is
increased and the [ dataptr](../reference/c-api/types-and-structures.html#c.PyArrayIterObject.dataptr) member is
increased by the strides in that
dimension and the macro ends. If the end of a dimension is reached,
the counter for the last dimension is reset to zero and the

[is moved back to the beginning of that dimension by subtracting the strides value times one less than the number of elements in that dimension (this is also pre-computed and stored in the](../reference/c-api/types-and-structures.html#c.PyArrayIterObject.dataptr)
`dataptr`
[member of the iterator object). In this case, the macro does not end, but a local dimension counter is decremented so that the next-to-last dimension replaces the role that the last dimension played and the previously-described tests are executed again on the next-to-last dimension. In this way, the](../reference/c-api/types-and-structures.html#c.PyArrayIterObject.backstrides)
`backstrides`
[is adjusted appropriately for arbitrary striding.](../reference/c-api/types-and-structures.html#c.PyArrayIterObject.dataptr)
`dataptr`
The [ coordinates](../reference/c-api/types-and-structures.html#c.PyArrayIterObject.coordinates) member of the

[structure maintains the current N-d counter unless the underlying array is C-contiguous in which case the coordinate counting is bypassed. The](../reference/c-api/types-and-structures.html#c.PyArrayIterObject)
`PyArrayIterObject`
[member of the](../reference/c-api/types-and-structures.html#c.PyArrayIterObject.index)
`index`
[keeps track of the current flat index of the iterator. It is updated by the](../reference/c-api/types-and-structures.html#c.PyArrayIterObject)
`PyArrayIterObject`
[macro.](../reference/c-api/array.html#c.PyArray_ITER_NEXT)
`PyArray_ITER_NEXT`
## Broadcasting[#](#broadcasting)
See also

In Numeric, the ancestor of NumPy, broadcasting was implemented in several
lines of code buried deep in `ufuncobject.c`
. In NumPy, the notion of
broadcasting has been abstracted so that it can be performed in multiple places.
Broadcasting is handled by the function [ PyArray_Broadcast](../reference/c-api/array.html#c.PyArray_Broadcast). This
function requires a

[(or something that is a binary equivalent) to be passed in. The](../reference/c-api/types-and-structures.html#c.PyArrayMultiIterObject)
`PyArrayMultiIterObject`
[keeps track of the broadcast number of dimensions and size in each dimension along with the total size of the broadcast result. It also keeps track of the number of arrays being broadcast and a pointer to an iterator for each of the arrays being broadcast.](../reference/c-api/types-and-structures.html#c.PyArrayMultiIterObject)
`PyArrayMultiIterObject`
The [ PyArray_Broadcast](../reference/c-api/array.html#c.PyArray_Broadcast) function takes the iterators that have already
been defined and uses them to determine the broadcast shape in each
dimension (to create the iterators at the same time that broadcasting
occurs then use the

[function). Then, the iterators are adjusted so that each iterator thinks it is iterating over an array with the broadcast size. This is done by adjusting the iterators number of dimensions, and the](../reference/c-api/array.html#c.PyArray_MultiIterNew)
`PyArray_MultiIterNew`
[shape](../glossary.html#term-shape)in each dimension. This works because the iterator strides are also adjusted. Broadcasting only adjusts (or adds) length-1 dimensions. For these dimensions, the strides variable is simply set to 0 so that the data-pointer for the iterator over that array doesn’t move as the broadcasting operation operates over the extended dimension.
Broadcasting was always implemented in Numeric using 0-valued strides
for the extended dimensions. It is done in exactly the same way in
NumPy. The big difference is that now the array of strides is kept
track of in a [ PyArrayIterObject](../reference/c-api/types-and-structures.html#c.PyArrayIterObject), the iterators involved in a
broadcast result are kept track of in a

[, and the](../reference/c-api/types-and-structures.html#c.PyArrayMultiIterObject)
`PyArrayMultiIterObject`
[call implements the](../reference/c-api/array.html#c.PyArray_Broadcast)
`PyArray_Broadcast`
[General Broadcasting Rules](../user/basics.broadcasting.html#general-broadcasting-rules).
## Array Scalars[#](#array-scalars)
See also

The array scalars offer a hierarchy of Python types that allow a one-to-one correspondence between the datatype stored in an array and the Python-type that is returned when an element is extracted from the array. An exception to this rule was made with object arrays. Object arrays are heterogeneous collections of arbitrary Python objects. When you select an item from an object array, you get back the original Python object (and not an object array scalar which does exist but is rarely used for practical purposes).

The array scalars also offer the same methods and attributes as arrays
with the intent that the same code can be used to support arbitrary
dimensions (including 0-dimensions). The array scalars are read-only
(immutable) with the exception of the void scalar which can also be
written to so that structured array field setting works more naturally
(`a[0]['f1'] = value`
).

## Indexing[#](#indexing)
See also

All Python indexing operations `arr[index]`
are organized by first preparing
the index and finding the index type. The supported index types are:

integer

integer arrays/array-likes (advanced)

boolean (single boolean array); if there is more than one boolean array as the index or the shape does not match exactly, the boolean array will be converted to an integer array instead.

0-d boolean (and also integer); 0-d boolean arrays are a special case that has to be handled in the advanced indexing code. They signal that a 0-d boolean array had to be interpreted as an integer array.

As well as the scalar array special case signaling that an integer array
was interpreted as an integer index, which is important because an integer
array index forces a copy but is ignored if a scalar is returned (full integer
index). The prepared index is guaranteed to be valid with the exception of
out of bound values and broadcasting errors for advanced indexing. This
includes that an [ Ellipsis](https://docs.python.org/3/library/constants.html#Ellipsis) is added for incomplete indices for
example when a two-dimensional array is indexed with a single integer.

The next step depends on the type of index which was found. If all
dimensions are indexed with an integer a scalar is returned or set. A
single boolean indexing array will call specialized boolean functions.
Indices containing an [ Ellipsis](https://docs.python.org/3/library/constants.html#Ellipsis) or

[slice](https://docs.python.org/3/glossary.html#term-slice)but no advanced indexing will always create a view into the old array by calculating the new strides and memory offset. This view can then either be returned or, for assignments, filled using
`PyArray_CopyObject`
. Note that
`PyArray_CopyObject`
may also be called on temporary arrays in other branches
to support complicated assignments when the array is of object [.](../reference/generated/numpy.dtype.html#numpy.dtype)
`dtype`
### Advanced indexing[#](#advanced-indexing)
By far the most complex case is advanced indexing, which may or may not be combined with typical view-based indexing. Here integer indices are interpreted as view-based. Before trying to understand this, you may want to make yourself familiar with its subtleties. The advanced indexing code has three different branches and one special case:

There is one indexing array and it, as well as the assignment array, can be iterated trivially. For example, they may be contiguous. Also, the indexing array must be of

type and the value array in assignments should be of the correct type. This is purely a fast path.`intp`
There are only integer array indices so that no subarray exists.

View-based and advanced indexing is mixed. In this case, the view-based indexing defines a collection of subarrays that are combined by the advanced indexing. For example,

`arr[[1, 2, 3], :]`
is created by vertically stacking the subarrays`arr[1, :]`
,`arr[2, :]`
, and`arr[3, :]`
.
There is a subarray but it has exactly one element. This case can be handled as if there is no subarray but needs some care during setup.

Deciding what case applies, checking broadcasting, and determining the kind
of transposition needed are all done in `PyArray_MapIterNew`
. After
setting up, there are two cases. If there is no subarray or it only has one
element, no subarray iteration is necessary and an iterator is prepared
which iterates all indexing arrays *as well as* the result or value array.
If there is a subarray, there are three iterators prepared. One for the
indexing arrays, one for the result or value array (minus its subarray),
and one for the subarrays of the original and the result/assignment array.
The first two iterators give (or allow calculation) of the pointers into
the start of the subarray, which then allows restarting the subarray
iteration.

When advanced indices are next to each other transposing may be necessary.
All necessary transposing is handled by [ PyArray_MapIterSwapAxes](../reference/c-api/array.html#c.PyArray_MapIterSwapAxes) and
has to be handled by the caller unless

`PyArray_MapIterNew`
is asked to
allocate the result.After preparation, getting and setting are relatively straightforward, although the different modes of iteration need to be considered. Unless there is only a single indexing array during item getting, the validity of the indices is checked beforehand. Otherwise, it is handled in the inner loop itself for optimization.

## Universal functions[#](#universal-functions)
Universal functions are callable objects that take \(N\) inputs
and produce \(M\) outputs by wrapping basic 1-D loops that work
element-by-element into full easy-to-use functions that seamlessly
implement [broadcasting](../user/basics.broadcasting.html#basics-broadcasting),
[type-checking](../user/basics.ufuncs.html#ufuncs-casting),
[buffered coercion](../user/basics.ufuncs.html#use-of-internal-buffers), and
[output-argument handling](../user/basics.ufuncs.html#ufuncs-output-type). New universal functions
are normally created in C, although there is a mechanism for creating ufuncs
from Python functions ([ frompyfunc](../reference/generated/numpy.frompyfunc.html#numpy.frompyfunc)). The user must supply a 1-D loop that
implements the basic function taking the input scalar values and
placing the resulting scalars into the appropriate output slots as
explained in implementation.

### Setup[#](#setup)
Every [ ufunc](../reference/generated/numpy.ufunc.html#numpy.ufunc) calculation involves some overhead related to setting up
the calculation. The practical significance of this overhead is that
even though the actual calculation of the ufunc is very fast, you will
be able to write array and type-specific code that will work faster
for small arrays than the ufunc. In particular, using ufuncs to
perform many calculations on 0-D arrays will be slower than other
Python-based solutions (the silently-imported

`scalarmath`
module exists
precisely to give array scalars the look-and-feel of ufunc based
calculations with significantly reduced overhead).When a [ ufunc](../reference/generated/numpy.ufunc.html#numpy.ufunc) is called, many things must be done. The information
collected from these setup operations is stored in a loop object. This
loop object is a C-structure (that could become a Python object but is
not initialized as such because it is only used internally). This loop
object has the layout needed to be used with

[so that the broadcasting can be handled in the same way as it is handled in other sections of code.](../reference/c-api/array.html#c.PyArray_Broadcast)
`PyArray_Broadcast`
The first thing done is to look up in the thread-specific global dictionary the current values for the buffer-size, the error mask, and the associated error object. The state of the error mask controls what happens when an error condition is found. It should be noted that checking of the hardware error flags is only performed after each 1-D loop is executed. This means that if the input and output arrays are contiguous and of the correct type so that a single 1-D loop is performed, then the flags may not be checked until all elements of the array have been calculated. Looking up these values in a thread-specific dictionary takes time which is easily ignored for all but very small arrays.

After checking, the thread-specific global variables, the inputs are evaluated to determine how the ufunc should proceed and the input and output arrays are constructed if necessary. Any inputs which are not arrays are converted to arrays (using context if necessary). Which of the inputs are scalars (and therefore converted to 0-D arrays) is noted.

Next, an appropriate 1-D loop is selected from the 1-D loops available
to the [ ufunc](../reference/generated/numpy.ufunc.html#numpy.ufunc) based on the input array types. This 1-D loop is selected
by trying to match the signature of the datatypes of the inputs
against the available signatures. The signatures corresponding to
built-in types are stored in the

[member of the ufunc structure. The signatures corresponding to user-defined types are stored in a linked list of function information with the head element stored as a](../reference/generated/numpy.ufunc.types.html#numpy.ufunc.types)
`ufunc.types`
`CObject`
in the `userloops`
dictionary keyed by the datatype number
(the first user-defined type in the argument list is used as the key).
The signatures are searched until a signature is found to which the
input arrays can all be cast safely (ignoring any scalar arguments
which are not allowed to determine the type of the result). The
implication of this search procedure is that “lesser types” should be
placed below “larger types” when the signatures are stored. If no 1-D
loop is found, then an error is reported. Otherwise, the `argument_list`
is updated with the stored signature — in case casting is necessary
and to fix the output types assumed by the 1-D loop.If the ufunc has 2 inputs and 1 output and the second input is an
`Object`
array then a special-case check is performed so that
`NotImplemented`
is returned if the second input is not an ndarray, has
the [ __array_priority__](../reference/arrays.classes.html#numpy.class.__array_priority__) attribute, and has an

`__r{op}__`
special method. In this way, Python is signaled to give the other object a
chance to complete the operation instead of using generic object-array
calculations. This allows (for example) sparse matrices to override
the multiplication operator 1-D loop.For input arrays that are smaller than the specified buffer size, copies are made of all non-contiguous, misaligned, or out-of-byteorder arrays to ensure that for small arrays, a single loop is used. Then, array iterators are created for all the input arrays and the resulting collection of iterators is broadcast to a single shape.

The output arguments (if any) are then processed and any missing
return arrays are constructed. If any provided output array doesn’t
have the correct type (or is misaligned) and is smaller than the
buffer size, then a new output array is constructed with the special
[ NPY_ARRAY_WRITEBACKIFCOPY](../reference/c-api/array.html#c.NPY_ARRAY_WRITEBACKIFCOPY) flag set. At the end of the function,

[is called so that its contents will be copied back into the output array. Iterators for the output arguments are then processed.](../reference/c-api/array.html#c.PyArray_ResolveWritebackIfCopy)
`PyArray_ResolveWritebackIfCopy`
Finally, the decision is made about how to execute the looping mechanism to ensure that all elements of the input arrays are combined to produce the output arrays of the correct type. The options for loop execution are one-loop (for :term`contiguous`, aligned, and correct data type), strided-loop (for non-contiguous but still aligned and correct data type), and a buffered loop (for misaligned or incorrect data type situations). Depending on which execution method is called for, the loop is then set up and computed.

### Function call[#](#function-call)
This section describes how the basic universal function computation loop is
set up and executed for each of the three different kinds of execution. If
[ NPY_ALLOW_THREADS](../reference/c-api/array.html#c.NPY_ALLOW_THREADS) is defined during compilation, then as long as
no object arrays are involved, the Python Global Interpreter Lock (GIL) is
released prior to calling the loops. It is re-acquired if necessary to
handle error conditions. The hardware error flags are checked only after
the 1-D loop is completed.

#### One loop[#](#one-loop)
This is the simplest case of all. The ufunc is executed by calling the
underlying 1-D loop exactly once. This is possible only when we have
aligned data of the correct type (including byteorder) for both input
and output and all arrays have uniform strides (either [contiguous](../glossary.html#term-contiguous),
0-D, or 1-D). In this case, the 1-D computational loop is called once
to compute the calculation for the entire array. Note that the
hardware error flags are only checked after the entire calculation is
complete.

#### Strided loop[#](#strided-loop)
When the input and output arrays are aligned and of the correct type, but the striding is not uniform (non-contiguous and 2-D or larger), then a second looping structure is employed for the calculation. This approach converts all of the iterators for the input and output arguments to iterate over all but the largest dimension. The inner loop is then handled by the underlying 1-D computational loop. The outer loop is a standard iterator loop on the converted iterators. The hardware error flags are checked after each 1-D loop is completed.

#### Buffered loop[#](#buffered-loop)
This is the code that handles the situation whenever the input and/or
output arrays are either misaligned or of the wrong datatype
(including being byteswapped) from what the underlying 1-D loop
expects. The arrays are also assumed to be non-contiguous. The code
works very much like the strided-loop except for the inner 1-D loop is
modified so that pre-processing is performed on the inputs and post-processing
is performed on the outputs in `bufsize`
chunks (where
`bufsize`
is a user-settable parameter). The underlying 1-D
computational loop is called on data that is copied over (if it needs
to be). The setup code and the loop code is considerably more
complicated in this case because it has to handle:

memory allocation of the temporary buffers

deciding whether or not to use buffers on the input and output data (misaligned and/or wrong datatype)

copying and possibly casting data for any inputs or outputs for which buffers are necessary.

special-casing

`Object`
arrays so that reference counts are properly handled when copies and/or casts are necessary.
breaking up the inner 1-D loop into

`bufsize`
chunks (with a possible remainder).
Again, the hardware error flags are checked at the end of each 1-D loop.

### Final output manipulation[#](#final-output-manipulation)
Ufuncs allow other array-like classes to be passed seamlessly through
the interface in that inputs of a particular class will induce the
outputs to be of that same class. The mechanism by which this works is
the following. If any of the inputs are not ndarrays and define the
[ __array_wrap__](../reference/arrays.classes.html#numpy.class.__array_wrap__) method, then the class with the largest

[attribute determines the type of all the outputs (with the exception of any output arrays passed in). The](../reference/arrays.classes.html#numpy.class.__array_priority__)
`__array_priority__`
[method of the input array will be called with the ndarray being returned from the ufunc as its input. There are two calling styles of the](../reference/arrays.classes.html#numpy.class.__array_wrap__)
`__array_wrap__`
[function supported. The first takes the ndarray as the first argument and a tuple of “context” as the second argument. The context is (ufunc, arguments, output argument number). This is the first call tried. If a](../reference/arrays.classes.html#numpy.class.__array_wrap__)
`__array_wrap__`
`TypeError`
occurs, then the
function is called with just the ndarray as the first argument.### Methods[#](#methods)
There are three methods of ufuncs that require calculation similar to
the general-purpose ufuncs. These are [ ufunc.reduce](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce),

[, and](../reference/generated/numpy.ufunc.accumulate.html#numpy.ufunc.accumulate)
`ufunc.accumulate`
[. Each of these methods requires a setup command followed by a loop. There are four loop styles possible for the methods corresponding to no-elements, one-element, strided-loop, and buffered-loop. These are the same basic loop styles as implemented for the general-purpose function call except for the no-element and one-element cases which are special-cases occurring when the input array objects have 0 and 1 elements respectively.](../reference/generated/numpy.ufunc.reduceat.html#numpy.ufunc.reduceat)
`ufunc.reduceat`
#### Setup[#](#id1)
The setup function for all three methods is `construct_reduce`
.
This function creates a reducing loop object and fills it with the
parameters needed to complete the loop. All of the methods only work
on ufuncs that take 2-inputs and return 1 output. Therefore, the
underlying 1-D loop is selected assuming a signature of ```
[otype,
otype, otype]
```
where `otype`
is the requested reduction
datatype. The buffer size and error handling are then retrieved from
(per-thread) global storage. For small arrays that are misaligned or
have incorrect datatype, a copy is made so that the un-buffered
section of code is used. Then, the looping strategy is selected. If
there is 1 element or 0 elements in the array, then a simple looping
method is selected. If the array is not misaligned and has the
correct datatype, then strided looping is selected. Otherwise,
buffered looping must be performed. Looping parameters are then
established, and the return array is constructed. The output array is
of a different [shape](../glossary.html#term-shape) depending on whether the method is
[ reduce](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce),

[, or](../reference/generated/numpy.ufunc.accumulate.html#numpy.ufunc.accumulate)
`accumulate`
[. If an output array is already provided, then its shape is checked. If the output array is not C-contiguous, aligned, and of the correct data type, then a temporary copy is made with the](../reference/generated/numpy.ufunc.reduceat.html#numpy.ufunc.reduceat)
`reduceat`
[flag set. In this way, the methods will be able to work with a well-behaved output array but the result will be copied back into the true output array when](../reference/c-api/array.html#c.NPY_ARRAY_WRITEBACKIFCOPY)
`NPY_ARRAY_WRITEBACKIFCOPY`
[is called at function completion. Finally, iterators are set up to loop over the correct](../reference/c-api/array.html#c.PyArray_ResolveWritebackIfCopy)
`PyArray_ResolveWritebackIfCopy`
[axis](../glossary.html#term-axis)(depending on the value of axis provided to the method) and the setup routine returns to the actual computation routine.
`Reduce`
[#](#reduce)
`Reduce`
All of the ufunc methods use the same underlying 1-D computational
loops with input and output arguments adjusted so that the appropriate
reduction takes place. For example, the key to the functioning of
[ reduce](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce) is that the 1-D loop is called with the output
and the second input pointing to the same position in memory and both having
a step-size of 0. The first input is pointing to the input array with a
step-size given by the appropriate stride for the selected axis. In this
way, the operation performed is

where \(N+1\) is the number of elements in the input, \(i\), \(o\) is the output, and \(i[k]\) is the \(k^{\textrm{th}}\) element of \(i\) along the selected axis. This basic operation is repeated for arrays with greater than 1 dimension so that the reduction takes place for every 1-D sub-array along the selected axis. An iterator with the selected dimension removed handles this looping.

For buffered loops, care must be taken to copy and cast data before
the loop function is called because the underlying loop expects
aligned data of the correct datatype (including byteorder). The
buffered loop must handle this copying and casting prior to calling
the loop function on chunks no greater than the user-specified
`bufsize`
.

`Accumulate`
[#](#accumulate)
`Accumulate`
The [ accumulate](../reference/generated/numpy.ufunc.accumulate.html#numpy.ufunc.accumulate) method is very similar to
the

[method in that the output and the second input both point to the output. The difference is that the second input points to memory one stride behind the current output pointer. Thus, the operation performed is](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce)
`reduce`
The output has the same shape as the input and each 1-D loop operates over \(N\) elements when the shape in the selected axis is \(N+1\). Again, buffered loops take care to copy and cast the data before calling the underlying 1-D computational loop.

`Reduceat`
[#](#reduceat)
`Reduceat`
The [ reduceat](../reference/generated/numpy.ufunc.reduceat.html#numpy.ufunc.reduceat) function is a generalization of both the

[and](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce)
`reduce`
[functions. It implements a](../reference/generated/numpy.ufunc.accumulate.html#numpy.ufunc.accumulate)
`accumulate`
[over ranges of the input array specified by indices. The extra indices argument is checked to be sure that every input is not too large for the input array along the selected dimension before the loop calculations take place. The loop implementation is handled using code that is very similar to the](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce)
`reduce`
[code repeated as many times as there are elements in the indices input. In particular: the first input pointer passed to the underlying 1-D computational loop points to the input array at the correct location indicated by the index array. In addition, the output pointer and the second input pointer passed to the underlying 1-D loop point to the same position in memory. The size of the 1-D computational loop is fixed to be the difference between the current index and the next index (when the current index is the last index, then the next index is assumed to be the length of the array along the selected dimension). In this way, the 1-D loop will implement a](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce)
`reduce`
[over the specified indices.](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce)
`reduce`
Misaligned or a loop datatype that does not match the input and/or output datatype is handled using buffered code wherein data is copied to a temporary buffer and cast to the correct datatype if necessary prior to calling the underlying 1-D function. The temporary buffers are created in (element) sizes no bigger than the user settable buffer-size value. Thus, the loop must be flexible enough to call the underlying 1-D computational loop enough times to complete the total calculation in chunks no bigger than the buffer-size.# numpy.polynomial.polynomial.Polynomial.cutdeg[#](#numpy-polynomial-polynomial-polynomial-cutdeg)
method

polynomial.polynomial.Polynomial.cutdeg(*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L710-L733)[#](#numpy.polynomial.polynomial.Polynomial.cutdeg)
-
Truncate series to the given degree.

Reduce the degree of the series to

*deg*by discarding the high order terms. If*deg*is greater than the current degree a copy of the current series is returned. This can be useful in least squares where the coefficients of the high degree terms may be very small.New in version 1.5.0.

Parameters:
-
**deg**non-negative int
The series is reduced to degree

*deg*by discarding the high order terms. The value of*deg*must be a non-negative integer.
Returns:
-
**new_series**series
New instance of series with reduced degree.# numpy.random.Generator.triangular[#](#numpy-random-generator-triangular)
method

random.Generator.triangular(*left*,*mode*,*right*,*size=None*)[#](#numpy.random.Generator.triangular)
-
Draw samples from the triangular distribution over the interval

`[left, right]`
.The triangular distribution is a continuous probability distribution with lower limit left, peak at mode, and upper limit right. Unlike the other distributions, these parameters directly define the shape of the pdf.

Parameters:
-
**left**float or array_like of floats
Lower limit.

**mode**float or array_like of floats
The value where the peak of the distribution occurs. The value must fulfill the condition

`left <= mode <= right`
.
**right**float or array_like of floats
Upper limit, must be larger than

*left*.
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`left`
,`mode`
, and`right`
are all scalars. Otherwise,`np.broadcast(left, mode, right).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized triangular distribution.

Notes

The probability density function for the triangular distribution is

\[\begin{split}P(x;l, m, r) = \begin{cases} \frac{2(x-l)}{(r-l)(m-l)}& \text{for $l \leq x \leq m$},\\ \frac{2(r-x)}{(r-l)(r-m)}& \text{for $m \leq x \leq r$},\\ 0& \text{otherwise}. \end{cases}\end{split}\]The triangular distribution is often used in ill-defined problems where the underlying distribution is not known, but some knowledge of the limits and mode exists. Often it is used in simulations.

References

[1]Wikipedia, “Triangular distribution”

[https://en.wikipedia.org/wiki/Triangular_distribution](https://en.wikipedia.org/wiki/Triangular_distribution)Examples

Draw values from the distribution and plot the histogram:

>>> import matplotlib.pyplot as plt >>> h = plt.hist(np.random.default_rng().triangular(-3, 0, 8, 100000), bins=200, ... density=True) >>> plt.show()# numpy.random.RandomState.weibull[#](#numpy-random-randomstate-weibull)
method

random.RandomState.weibull(*a*,*size=None*)[#](#numpy.random.RandomState.weibull)
-
Draw samples from a Weibull distribution.

Draw samples from a 1-parameter Weibull distribution with the given shape parameter

*a*.\[X = (-ln(U))^{1/a}\]Here, U is drawn from the uniform distribution over (0,1].

The more common 2-parameter Weibull, including a scale parameter \(\lambda\) is just \(X = \lambda(-ln(U))^{1/a}\).

Note

New code should use the

method of a`weibull`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**a**float or array_like of floats
Shape parameter of the distribution. Must be nonnegative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`a`
is a scalar. Otherwise,`np.array(a).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Weibull distribution.

See also

`scipy.stats.weibull_max`
`scipy.stats.weibull_min`
`scipy.stats.genextreme`
`gumbel`
`random.Generator.weibull`
which should be used for new code.

Notes

The Weibull (or Type III asymptotic extreme value distribution for smallest values, SEV Type III, or Rosin-Rammler distribution) is one of a class of Generalized Extreme Value (GEV) distributions used in modeling extreme value problems. This class includes the Gumbel and Frechet distributions.

The probability density for the Weibull distribution is

\[p(x) = \frac{a} {\lambda}(\frac{x}{\lambda})^{a-1}e^{-(x/\lambda)^a},\]where \(a\) is the shape and \(\lambda\) the scale.

The function has its peak (the mode) at \(\lambda(\frac{a-1}{a})^{1/a}\).

When

`a = 1`
, the Weibull distribution reduces to the exponential distribution.References

[1]Waloddi Weibull, Royal Technical University, Stockholm, 1939 “A Statistical Theory Of The Strength Of Materials”, Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939, Generalstabens Litografiska Anstalts Forlag, Stockholm.

[2]Waloddi Weibull, “A Statistical Distribution Function of Wide Applicability”, Journal Of Applied Mechanics ASME Paper 1951.

[3]Wikipedia, “Weibull distribution”,

[https://en.wikipedia.org/wiki/Weibull_distribution](https://en.wikipedia.org/wiki/Weibull_distribution)Examples

Draw samples from the distribution:

>>> a = 5. # shape >>> s = np.random.weibull(a, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> x = np.arange(1,100.)/50. >>> def weib(x,n,a): ... return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)
>>> count, bins, ignored = plt.hist(np.random.weibull(5.,1000)) >>> x = np.arange(1,100.)/50. >>> scale = count.max()/weib(x, 1., 5.).max() >>> plt.plot(x, weib(x, 1., 5.)*scale) >>> plt.show()# numpy.emath.arcsin[#](#numpy-emath-arcsin)
emath.arcsin(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/scimath.py#L531-L574)[#](#numpy.emath.arcsin)
-
Compute the inverse sine of x.

Return the “principal value” (for a description of this, see

) of the inverse sine of`numpy.arcsin`
*x*. For real*x*such that*abs(x) <= 1*, this is a real number in the closed interval \([-\pi/2, \pi/2]\). Otherwise, the complex principle value is returned.Parameters:
-
**x**array_like or scalar
The value(s) whose arcsin is (are) required.

Returns:
-
**out**ndarray or scalar
The inverse sine(s) of the

*x*value(s). If*x*was a scalar, so is*out*, otherwise an array object is returned.
See also

Notes

For an arcsin() that returns

`NAN`
when real*x*is not in the interval`[-1,1]`
, use.`numpy.arcsin`
Examples

>>> np.set_printoptions(precision=4)
>>> np.emath.arcsin(0) 0.0
>>> np.emath.arcsin([0,1]) array([0. , 1.5708])# numpy.char.chararray.resize[#](#numpy-char-chararray-resize)
method

char.chararray.resize(*new_shape*,*refcheck=True*)[#](#numpy.char.chararray.resize)
-
Change shape and size of array in-place.

Parameters:
-
**new_shape**tuple of ints, or*n*ints
Shape of resized array.

**refcheck**bool, optional
If False, reference count will not be checked. Default is True.

Returns:
-
None
-
Raises:
-
ValueError
-
If

*a*does not own its own data or references or views to it exist, and the data memory must be changed. PyPy only: will always raise if the data memory must be changed, since there is no reliable way to determine if references or views to it exist.
SystemError
-
If the

*order*keyword argument is specified. This behaviour is a bug in NumPy.
See also

`resize`
Return a new array with the specified shape.

Notes

This reallocates space for the data area if necessary.

Only contiguous arrays (data elements consecutive in memory) can be resized.

The purpose of the reference count check is to make sure you do not use this array as a buffer for another Python object and then reallocate the memory. However, reference counts can increase in other ways so if you are sure that you have not shared the memory for this array with another Python object, then you may safely set

*refcheck*to False.Examples

Shrinking an array: array is flattened (in the order that the data are stored in memory), resized, and reshaped:

>>> a = np.array([[0, 1], [2, 3]], order='C') >>> a.resize((2, 1)) >>> a array([[0], [1]])
>>> a = np.array([[0, 1], [2, 3]], order='F') >>> a.resize((2, 1)) >>> a array([[0], [2]])
Enlarging an array: as above, but missing entries are filled with zeros:

>>> b = np.array([[0, 1], [2, 3]]) >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple >>> b array([[0, 1, 2], [3, 0, 0]])
Referencing an array prevents resizing…

>>> c = a >>> a.resize((1, 1)) Traceback (most recent call last): ... ValueError: cannot resize an array that references or is referenced ...
Unless

*refcheck*is False:>>> a.resize((1, 1), refcheck=False) >>> a array([[0]]) >>> c array([[0]])# numpy.distutils.ccompiler_opt.CCompilerOpt[#](#numpy-distutils-ccompiler-opt-ccompileropt)
*class*numpy.distutils.ccompiler_opt.CCompilerOpt(*ccompiler*,*cpu_baseline='min'*,*cpu_dispatch='max'*,*cache_path=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/ccompiler_opt.py#L2212-L2645)[#](#numpy.distutils.ccompiler_opt.CCompilerOpt)
-
A helper class for

*CCompiler*aims to provide extra build options to effectively control of compiler optimizations that are directly related to CPU features.Attributes:
-
**conf_cache_factors**
**conf_tmp_path**
Methods

Force update the cache.

(flags)`cc_normalize_flags`
Remove the conflicts that caused due gathering implied features flags.

Return a dictionary of supported CPU features by the platform, and accumulate the rest of undefined options in

, the returned dict has same rules and notes in class attribute`conf_features`
, also its override any options that been set in 'conf_features'.`conf_features`
Returns a list of final CPU baseline compiler flags

return a list of final CPU baseline feature names

return a list of final CPU dispatch feature names

(sources, flags[, ccompiler])`dist_compile`
Wrap CCompiler.compile()

(*args)`dist_error`
Raise a compiler error

(*args)`dist_fatal`
Raise a distutils error

Return a tuple containing info about (platform, compiler, extra_args), required by the abstract class '_CCompiler' for discovering the platform environment.

(name, path)`dist_load_module`
Load a module from file, required by the abstract class '_Cache'.

(*args[, stderr])`dist_log`
Print a console message

(source, flags[, macros])`dist_test`
Return True if 'CCompiler.compile()' able to compile a source file with certain flags.

(names)`feature_ahead`
Return list of features in 'names' after remove any implied features and keep the origins.

(feature_name[, tabs])`feature_c_preprocessor`
Generate C preprocessor definitions and include headers of a CPU feature.

(names)`feature_detect`
Return a list of CPU features that required to be detected sorted from the lowest to highest interest.

(names, keyisfalse)`feature_get_til`
same as

*feature_implies_c()*but stop collecting implied features when feature's option that provided through parameter 'keyisfalse' is False, also sorting the returned features.(names[, keep_origins])`feature_implies`
Return a set of CPU features that implied by 'names'

(names)`feature_implies_c`
same as feature_implies() but combining 'names'

(name)`feature_is_exist`
Returns True if a certain feature is exist and covered within

`_Config.conf_features`
.([names, force_flags, macros])`feature_names`
Returns a set of CPU feature names that supported by platform and the

**C**compiler.(names[, reverse])`feature_sorted`
Sort a list of CPU features ordered by the lowest interest.

(names)`feature_untied`
same as 'feature_ahead()' but if both features implied each other and keep the highest interest.

(header_path)`generate_dispatch_header`
Generate the dispatch header which contains the #definitions and headers for platform-specific instruction-sets for the enabled CPU baseline and dispatch-able features.

Returns True if the class loaded from the cache file

(cb)`me`
A static method that can be treated as a decorator to dynamically cache certain methods.

(source)`parse_targets`
Fetch and parse configuration statements that required for defining the targeted CPU features, statements should be declared in the top of source in between

**C**comment and start with a special mark**@targets**.(sources[, src_dir, ccompiler])`try_dispatch`
Compile one or more dispatch-able sources and generates object files, also generates abstract C config headers and macros that used later for the final runtime dispatching process.

**cache_hash****cc_test_cexpr****cc_test_flags****feature_can_autovec****feature_extra_checks****feature_flags****feature_is_supported****feature_test****report**# numpy.nanmedian[#](#numpy-nanmedian)
numpy.nanmedian(*a*,*axis=None*,*out=None*,*overwrite_input=False*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L1126-L1219)[#](#numpy.nanmedian)
-
Compute the median along the specified axis, while ignoring NaNs.

Returns the median of the array elements.

New in version 1.9.0.

Parameters:
-
**a**array_like
Input array or object that can be converted to an array.

**axis**{int, sequence of int, None}, optional
Axis or axes along which the medians are computed. The default is to compute the median along a flattened version of the array. A sequence of axes is supported since version 1.9.0.

**out**ndarray, optional
Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output, but the type (of the output) will be cast if necessary.

**overwrite_input**bool, optional
If True, then allow use of memory of input array

*a*for calculations. The input array will be modified by the call to. This will save memory when you do not need to preserve the contents of the input array. Treat the input as undefined, but it will probably be fully or partially sorted. Default is False. If`median`
*overwrite_input*is`True`
and*a*is not already an, an error will be raised.`ndarray`
**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original

*a*.If this is anything but the default value it will be passed through (in the special case of an empty array) to the

function of the underlying array. If the array is a sub-class and`mean`
does not have the kwarg`mean`
*keepdims*this will raise a RuntimeError.
Returns:
-
**median**ndarray
A new array holding the result. If the input contains integers or floats smaller than

`float64`
, then the output data-type is`np.float64`
. Otherwise, the data-type of the output is the same as that of the input. If*out*is specified, that array is returned instead.
See also

Notes

Given a vector

`V`
of length`N`
, the median of`V`
is the middle value of a sorted copy of`V`
,`V_sorted`
- i.e.,`V_sorted[(N-1)/2]`
, when`N`
is odd and the average of the two middle values of`V_sorted`
when`N`
is even.Examples

>>> a = np.array([[10.0, 7, 4], [3, 2, 1]]) >>> a[0, 1] = np.nan >>> a array([[10., nan, 4.], [ 3., 2., 1.]]) >>> np.median(a) nan >>> np.nanmedian(a) 3.0 >>> np.nanmedian(a, axis=0) array([6.5, 2. , 2.5]) >>> np.median(a, axis=1) array([nan, 2.]) >>> b = a.copy() >>> np.nanmedian(b, axis=1, overwrite_input=True) array([7., 2.]) >>> assert not np.all(a==b) >>> b = a.copy() >>> np.nanmedian(b, axis=None, overwrite_input=True) 3.0 >>> assert not np.all(a==b)# numpy.polynomial.hermite_e.hermediv[#](#numpy-polynomial-hermite-e-hermediv)
polynomial.hermite_e.hermediv(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L507-L550)[#](#numpy.polynomial.hermite_e.hermediv)
-
Divide one Hermite series by another.

Returns the quotient-with-remainder of two Hermite series

*c1*/*c2*. The arguments are sequences of coefficients from lowest order “term” to highest, e.g., [1,2,3] represents the series`P_0 + 2*P_1 + 3*P_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Hermite series coefficients ordered from low to high.

Returns:
-
**[quo, rem]**ndarrays
Of Hermite series coefficients representing the quotient and remainder.

Notes

In general, the (polynomial) division of one Hermite series by another results in quotient and remainder terms that are not in the Hermite polynomial basis set. Thus, to express these results as a Hermite series, it is necessary to “reproject” the results onto the Hermite basis set, which may produce “unintuitive” (but correct) results; see Examples section below.

Examples

>>> from numpy.polynomial.hermite_e import hermediv >>> hermediv([ 14., 15., 28., 7., 6.], [0, 1, 2]) (array([1., 2., 3.]), array([0.])) >>> hermediv([ 15., 17., 28., 7., 6.], [0, 1, 2]) (array([1., 2., 3.]), array([1., 2.]))# numpy.load[#](#numpy-load)
numpy.load(*file*,*mmap_mode=None*,*allow_pickle=False*,*fix_imports=True*,*encoding='ASCII'*,***,*max_header_size=10000*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/npyio.py#L282-L468)[#](#numpy.load)
-
Load arrays or pickled objects from

`.npy`
,`.npz`
or pickled files.Warning

Loading files that contain object arrays uses the

`pickle`
module, which is not secure against erroneous or maliciously constructed data. Consider passing`allow_pickle=False`
to load data that is known not to contain object arrays for the safer handling of untrusted sources.Parameters:
-
**file**file-like object, string, or pathlib.Path
The file to read. File-like objects must support the

`seek()`
and`read()`
methods and must always be opened in binary mode. Pickled files require that the file-like object support the`readline()`
method as well.
**mmap_mode**{None, ‘r+’, ‘r’, ‘w+’, ‘c’}, optional
If not None, then memory-map the file, using the given mode (see

for a detailed description of the modes). A memory-mapped array is kept on disk. However, it can be accessed and sliced like any ndarray. Memory mapping is especially useful for accessing small fragments of large files without reading the entire file into memory.`numpy.memmap`
**allow_pickle**bool, optional
Allow loading pickled object arrays stored in npy files. Reasons for disallowing pickles include security, as loading pickled data can execute arbitrary code. If pickles are disallowed, loading object arrays will fail. Default: False

Changed in version 1.16.3: Made default False in response to CVE-2019-6446.

**fix_imports**bool, optional
Only useful when loading Python 2 generated pickled files on Python 3, which includes npy/npz files containing object arrays. If

*fix_imports*is True, pickle will try to map the old Python 2 names to the new names used in Python 3.
**encoding**str, optional
What encoding to use when reading Python 2 strings. Only useful when loading Python 2 generated pickled files in Python 3, which includes npy/npz files containing object arrays. Values other than ‘latin1’, ‘ASCII’, and ‘bytes’ are not allowed, as they can corrupt numerical data. Default: ‘ASCII’

**max_header_size**int, optional
Maximum allowed size of the header. Large headers may not be safe to load securely and thus require explicitly passing a larger value. See

for details. This option is ignored when`ast.literal_eval`
*allow_pickle*is passed. In that case the file is by definition trusted and the limit is unnecessary.
Returns:
-
**result**array, tuple, dict, etc.
Data stored in the file. For

`.npz`
files, the returned instance of NpzFile class must be closed to avoid leaking file descriptors.
Raises:
-
OSError
-
If the input file does not exist or cannot be read.

UnpicklingError
-
If

`allow_pickle=True`
, but the file cannot be loaded as a pickle.
ValueError
-
The file contains an object array, but

`allow_pickle=False`
given.
EOFError
-
When calling

`np.load`
multiple times on the same file handle, if all data has already been read
See also

,`save`
,`savez`
,`savez_compressed`
`loadtxt`
`memmap`
Create a memory-map to an array stored in a file on disk.

`lib.format.open_memmap`
Create or load a memory-mapped

`.npy`
file.
Notes

If the file contains pickle data, then whatever object is stored in the pickle is returned.

If the file is a

`.npy`
file, then a single array is returned.
If the file is a

`.npz`
file, then a dictionary-like object is returned, containing`{filename: array}`
key-value pairs, one for each file in the archive.
If the file is a

`.npz`
file, the returned value supports the context manager protocol in a similar fashion to the open function:with load('foo.npz') as data: a = data['a']
The underlying file descriptor is closed when exiting the ‘with’ block.

Examples

Store data to disk, and load it again:

>>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]])) >>> np.load('/tmp/123.npy') array([[1, 2, 3], [4, 5, 6]])
Store compressed data to disk, and load it again:

>>> a=np.array([[1, 2, 3], [4, 5, 6]]) >>> b=np.array([1, 2]) >>> np.savez('/tmp/123.npz', a=a, b=b) >>> data = np.load('/tmp/123.npz') >>> data['a'] array([[1, 2, 3], [4, 5, 6]]) >>> data['b'] array([1, 2]) >>> data.close()
Mem-map the stored array, and then access the second row directly from disk:

>>> X = np.load('/tmp/123.npy', mmap_mode='r') >>> X[1, :] memmap([4, 5, 6])# numpy.polynomial.polynomial.Polynomial.fit[#](#numpy-polynomial-polynomial-polynomial-fit)
method

*classmethod*polynomial.polynomial.Polynomial.fit(*x*,*y*,*deg*,*domain=None*,*rcond=None*,*full=False*,*w=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L955-L1045)[#](#numpy.polynomial.polynomial.Polynomial.fit)
-
Least squares fit to data.

Return a series instance that is the least squares fit to the data

*y*sampled at*x*. The domain of the returned instance can be specified and this will often result in a superior fit with less chance of ill conditioning.Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,)
y-coordinates of the M sample points

`(x[i], y[i])`
.
**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**domain**{None, [beg, end], []}, optional
Domain to use for the returned series. If

`None`
, then a minimal domain that covers the points*x*is chosen. If`[]`
the class domain is used. The default value was the class domain in NumPy 1.4 and`None`
in later versions. The`[]`
option was added in numpy 1.5.0.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (M,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.New in version 1.5.0.

**window**{[beg, end]}, optional
Window to use for the returned series. The default value is the default class domain

New in version 1.6.0.

**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
A series that represents the least squares fit to the data and has the domain and window specified in the call. If the coefficients for the unscaled and unshifted basis polynomials are of interest, do

`new_series.convert().coef`
.
**[resid, rank, sv, rcond]**list
These values are only returned if

`full == True`
resid – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

sv – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`linalg.lstsq`# numpy.resize[#](#numpy-resize)
numpy.resize(*a*,*new_shape*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L1407-L1484)[#](#numpy.resize)
-
Return a new array with the specified shape.

If the new array is larger than the original array, then the new array is filled with repeated copies of

*a*. Note that this behavior is different from a.resize(new_shape) which fills with zeros instead of repeated copies of*a*.Parameters:
-
**a**array_like
Array to be resized.

**new_shape**int or tuple of int
Shape of resized array.

Returns:
-
**reshaped_array**ndarray
The new array is formed from the data in the old array, repeated if necessary to fill out the required number of elements. The data are repeated iterating over the array in C-order.

See also

`numpy.reshape`
Reshape an array without changing the total size.

`numpy.pad`
Enlarge and pad an array.

`numpy.repeat`
Repeat elements of an array.

`ndarray.resize`
resize an array in-place.

Notes

When the total size of the array does not change

should be used. In most other cases either indexing (to reduce the size) or padding (to increase the size) may be a more appropriate solution.`reshape`
Warning: This functionality does

**not**consider axes separately, i.e. it does not apply interpolation/extrapolation. It fills the return array with the required number of elements, iterating over*a*in C-order, disregarding axes (and cycling back from the start if the new shape is larger). This functionality is therefore not suitable to resize images, or data where each axis represents a separate and distinct entity.Examples

>>> a=np.array([[0,1],[2,3]]) >>> np.resize(a,(2,3)) array([[0, 1, 2], [3, 0, 1]]) >>> np.resize(a,(1,4)) array([[0, 1, 2, 3]]) >>> np.resize(a,(2,4)) array([[0, 1, 2, 3], [0, 1, 2, 3]])# numpy.ndarray.strides[#](#numpy-ndarray-strides)
attribute

ndarray.strides[#](#numpy.ndarray.strides)
-
Tuple of bytes to step in each dimension when traversing an array.

The byte offset of element

`(i[0], i[1], ..., i[n])`
in an array*a*is:offset = sum(np.array(i) * a.strides)
A more detailed explanation of strides can be found in the “ndarray.rst” file in the NumPy reference guide.

Warning

Setting

`arr.strides`
is discouraged and may be deprecated in the future.should be preferred to create a new view of the same data in a safer way.`numpy.lib.stride_tricks.as_strided`
See also

Notes

Imagine an array of 32-bit integers (each 4 bytes):

x = np.array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], dtype=np.int32)
This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array

*x*will be`(20, 4)`
.Examples

>>> y = np.reshape(np.arange(2*3*4), (2,3,4)) >>> y array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) >>> y.strides (48, 16, 4) >>> y[1,1,1] 17 >>> offset=sum(y.strides * np.array((1,1,1))) >>> offset/y.itemsize 17
>>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0) >>> x.strides (32, 4, 224, 1344) >>> i = np.array([3,5,2,2]) >>> offset = sum(i * x.strides) >>> x[3,5,2,2] 813 >>> offset / x.itemsize 813# numpy.polynomial.legendre.legint[#](#numpy-polynomial-legendre-legint)
polynomial.legendre.legint(*c*,*m=1*,*k=[]*,*lbnd=0*,*scl=1*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L704-L829)[#](#numpy.polynomial.legendre.legint)
-
Integrate a Legendre series.

Returns the Legendre series coefficients

*c*integrated*m*times from*lbnd*along*axis*. At each iteration the resulting series is**multiplied**by*scl*and an integration constant,*k*, is added. The scaling factor is for use in a linear change of variable. (“Buyer beware”: note that, depending on what one is doing, one may want*scl*to be the reciprocal of what one might expect; for more information, see the Notes section below.) The argument*c*is an array of coefficients from low to high degree along each axis, e.g., [1,2,3] represents the series`L_0 + 2*L_1 + 3*L_2`
while [[1,2],[1,2]] represents`1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)`
if axis=0 is`x`
and axis=1 is`y`
.Parameters:
-
**c**array_like
Array of Legendre series coefficients. If c is multidimensional the different axis correspond to different variables with the degree in each axis given by the corresponding index.

**m**int, optional
Order of integration, must be positive. (Default: 1)

**k**{[], list, scalar}, optional
Integration constant(s). The value of the first integral at

`lbnd`
is the first value in the list, the value of the second integral at`lbnd`
is the second value, etc. If`k == []`
(the default), all constants are set to zero. If`m == 1`
, a single scalar can be given instead of a list.
**lbnd**scalar, optional
The lower bound of the integral. (Default: 0)

**scl**scalar, optional
Following each integration the result is

*multiplied*by*scl*before the integration constant is added. (Default: 1)
**axis**int, optional
Axis over which the integral is taken. (Default: 0).

New in version 1.7.0.

Returns:
-
**S**ndarray
Legendre series coefficient array of the integral.

Raises:
-
ValueError
-
If

`m < 0`
,`len(k) > m`
,`np.ndim(lbnd) != 0`
, or`np.ndim(scl) != 0`
.
See also

Notes

Note that the result of each integration is

*multiplied*by*scl*. Why is this important to note? Say one is making a linear change of variable \(u = ax + b\) in an integral relative to*x*. Then \(dx = du/a\), so one will need to set*scl*equal to \(1/a\) - perhaps not what one would have first thought.Also note that, in general, the result of integrating a C-series needs to be “reprojected” onto the C-series basis set. Thus, typically, the result of this function is “unintuitive,” albeit correct; see Examples section below.

Examples

>>> from numpy.polynomial import legendre as L >>> c = (1,2,3) >>> L.legint(c) array([ 0.33333333, 0.4 , 0.66666667, 0.6 ]) # may vary >>> L.legint(c, 3) array([ 1.66666667e-02, -1.78571429e-02, 4.76190476e-02, # may vary -1.73472348e-18, 1.90476190e-02, 9.52380952e-03]) >>> L.legint(c, k=3) array([ 3.33333333, 0.4 , 0.66666667, 0.6 ]) # may vary >>> L.legint(c, lbnd=-2) array([ 7.33333333, 0.4 , 0.66666667, 0.6 ]) # may vary >>> L.legint(c, scl=2) array([ 0.66666667, 0.8 , 1.33333333, 1.2 ]) # may vary# numpy.DataSource[#](#numpy-datasource)
*class*numpy.DataSource(*destpath='.'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/__init__.py)[#](#numpy.DataSource)
-
A generic data source file (file, http, ftp, …).

DataSources can be local files or remote files/URLs. The files may also be compressed or uncompressed. DataSource hides some of the low-level details of downloading the file, allowing you to simply pass in a valid file path (or URL) and obtain a file object.

Parameters:
-
**destpath**str or None, optional
Path to the directory where the source file gets downloaded to for use. If

*destpath*is None, a temporary directory will be created. The default path is the current directory.
Notes

URLs require a scheme string (

`http://`
) to be used, without it they will fail:>>> repos = np.DataSource() >>> repos.exists('www.google.com/index.html') False >>> repos.exists('http://www.google.com/index.html') True
Temporary directories are deleted when the DataSource is deleted.

Examples

>>> ds = np.DataSource('/home/guido') >>> urlname = 'http://www.google.com/' >>> gfile = ds.open('http://www.google.com/') >>> ds.abspath(urlname) '/home/guido/www.google.com/index.html' >>> ds = np.DataSource(None) # use with temporary file >>> ds.open('/home/guido/foobar.txt') <open file '/home/guido.foobar.txt', mode 'r' at 0x91d4430> >>> ds.abspath('/home/guido/foobar.txt') '/tmp/.../home/guido/foobar.txt'
Methods

(path)`abspath`
Return absolute path of file in the DataSource directory.

(path)`exists`
Test if path exists.

(path[, mode, encoding, newline])`open`
Open and return file-like object.# numpy.linalg.lstsq[#](#numpy-linalg-lstsq)
linalg.lstsq(*a*,*b*,*rcond='warn'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L2191-L2348)[#](#numpy.linalg.lstsq)
-
Return the least-squares solution to a linear matrix equation.

Computes the vector

*x*that approximately solves the equation`a @ x = b`
. The equation may be under-, well-, or over-determined (i.e., the number of linearly independent rows of*a*can be less than, equal to, or greater than its number of linearly independent columns). If*a*is square and of full rank, then*x*(but for round-off error) is the “exact” solution of the equation. Else,*x*minimizes the Euclidean 2-norm \(||b - ax||\). If there are multiple minimizing solutions, the one with the smallest 2-norm \(||x||\) is returned.Parameters:
-
**a**(M, N) array_like
“Coefficient” matrix.

**b**{(M,), (M, K)} array_like
Ordinate or “dependent variable” values. If

*b*is two-dimensional, the least-squares solution is calculated for each of the*K*columns of*b*.
**rcond**float, optional
Cut-off ratio for small singular values of

*a*. For the purposes of rank determination, singular values are treated as zero if they are smaller than*rcond*times the largest singular value of*a*.Changed in version 1.14.0: If not set, a FutureWarning is given. The previous default of

`-1`
will use the machine precision as*rcond*parameter, the new default will use the machine precision times*max(M, N)*. To silence the warning and use the new default, use`rcond=None`
, to keep using the old behavior, use`rcond=-1`
.
Returns:
-
**x**{(N,), (N, K)} ndarray
Least-squares solution. If

*b*is two-dimensional, the solutions are in the*K*columns of*x*.
**residuals**{(1,), (K,), (0,)} ndarray
Sums of squared residuals: Squared Euclidean 2-norm for each column in

`b - a @ x`
. If the rank of*a*is < N or M <= N, this is an empty array. If*b*is 1-dimensional, this is a (1,) shape array. Otherwise the shape is (K,).
**rank**int
Rank of matrix

*a*.
**s**(min(M, N),) ndarray
Singular values of

*a*.
Raises:
-
LinAlgError
-
If computation does not converge.

See also

`scipy.linalg.lstsq`
Similar function in SciPy.

Notes

If

*b*is a matrix, then all array results are returned as matrices.Examples

Fit a line,

`y = mx + c`
, through some noisy data-points:>>> x = np.array([0, 1, 2, 3]) >>> y = np.array([-1, 0.2, 0.9, 2.1])
By examining the coefficients, we see that the line should have a gradient of roughly 1 and cut the y-axis at, more or less, -1.

We can rewrite the line equation as

`y = Ap`
, where`A = [[x 1]]`
and`p = [[m], [c]]`
. Now useto solve for`lstsq`
*p*:>>> A = np.vstack([x, np.ones(len(x))]).T >>> A array([[ 0., 1.], [ 1., 1.], [ 2., 1.], [ 3., 1.]])
>>> m, c = np.linalg.lstsq(A, y, rcond=None)[0] >>> m, c (1.0 -0.95) # may vary
Plot the data along with the fitted line:

>>> import matplotlib.pyplot as plt >>> _ = plt.plot(x, y, 'o', label='Original data', markersize=10) >>> _ = plt.plot(x, m*x + c, 'r', label='Fitted line') >>> _ = plt.legend() >>> plt.show()# numpy.nanvar[#](#numpy-nanvar)
numpy.nanvar(*a*,*axis=None*,*dtype=None*,*out=None*,*ddof=0*,*keepdims=<no value>*,***,*where=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L1617-L1770)[#](#numpy.nanvar)
-
Compute the variance along the specified axis, while ignoring NaNs.

Returns the variance of the array elements, a measure of the spread of a distribution. The variance is computed for the flattened array by default, otherwise over the specified axis.

For all-NaN slices or slices with zero degrees of freedom, NaN is returned and a

*RuntimeWarning*is raised.New in version 1.8.0.

Parameters:
-
**a**array_like
Array containing numbers whose variance is desired. If

*a*is not an array, a conversion is attempted.
**axis**{int, tuple of int, None}, optional
Axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.

**dtype**data-type, optional
Type to use in computing the variance. For arrays of integer type the default is

; for arrays of float types it is the same as the array type.`float64`
**out**ndarray, optional
Alternate output array in which to place the result. It must have the same shape as the expected output, but the type is cast if necessary.

**ddof**int, optional
“Delta Degrees of Freedom”: the divisor used in the calculation is

`N - ddof`
, where`N`
represents the number of non-NaN elements. By default*ddof*is zero.
**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original

*a*.
**where**array_like of bool, optional
Elements to include in the variance. See

for details.`reduce`
New in version 1.22.0.

Returns:
-
**variance**ndarray, see dtype parameter above
If

*out*is None, return a new array containing the variance, otherwise return a reference to the output array. If ddof is >= the number of non-NaN elements in a slice or the slice contains only NaNs, then the result for that slice is NaN.
See also

Notes

The variance is the average of the squared deviations from the mean, i.e.,

`var = mean(abs(x - x.mean())**2)`
.The mean is normally calculated as

`x.sum() / N`
, where`N = len(x)`
. If, however,*ddof*is specified, the divisor`N - ddof`
is used instead. In standard statistical practice,`ddof=1`
provides an unbiased estimator of the variance of a hypothetical infinite population.`ddof=0`
provides a maximum likelihood estimate of the variance for normally distributed variables.Note that for complex numbers, the absolute value is taken before squaring, so that the result is always real and nonnegative.

For floating-point input, the variance is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for

(see example below). Specifying a higher-accuracy accumulator using the`float32`
`dtype`
keyword can alleviate this issue.For this function to work on sub-classes of ndarray, they must define

with the kwarg`sum`
*keepdims*Examples

>>> a = np.array([[1, np.nan], [3, 4]]) >>> np.nanvar(a) 1.5555555555555554 >>> np.nanvar(a, axis=0) array([1., 0.]) >>> np.nanvar(a, axis=1) array([0., 0.25]) # may vary# numpy.ma.make_mask[#](#numpy-ma-make-mask)
ma.make_mask(*m*,*copy=False*,*shrink=True*,*dtype=<class 'numpy.bool_'>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L1555-L1641)[#](#numpy.ma.make_mask)
-
Create a boolean mask from an array.

Return

*m*as a boolean mask, creating a copy if necessary or requested. The function can accept any sequence that is convertible to integers, or`nomask`
. Does not require that contents must be 0s and 1s, values of 0 are interpreted as False, everything else as True.Parameters:
-
**m**array_like
Potential mask.

**copy**bool, optional
Whether to return a copy of

*m*(True) or*m*itself (False).
**shrink**bool, optional
Whether to shrink

*m*to`nomask`
if all its values are False.
**dtype**dtype, optional
Data-type of the output mask. By default, the output mask has a dtype of MaskType (bool). If the dtype is flexible, each field has a boolean dtype. This is ignored when

*m*is`nomask`
, in which case`nomask`
is always returned.
Returns:
-
**result**ndarray
A boolean mask derived from

*m*.
Examples

>>> import numpy.ma as ma >>> m = [True, False, True, True] >>> ma.make_mask(m) array([ True, False, True, True]) >>> m = [1, 0, 1, 1] >>> ma.make_mask(m) array([ True, False, True, True]) >>> m = [1, 0, 2, -3] >>> ma.make_mask(m) array([ True, False, True, True])
Effect of the

*shrink*parameter.>>> m = np.zeros(4) >>> m array([0., 0., 0., 0.]) >>> ma.make_mask(m) False >>> ma.make_mask(m, shrink=False) array([False, False, False, False])
Using a flexible

.`dtype`
>>> m = [1, 0, 1, 1] >>> n = [0, 1, 0, 0] >>> arr = [] >>> for man, mouse in zip(m, n): ... arr.append((man, mouse)) >>> arr [(1, 0), (0, 1), (1, 0), (1, 0)] >>> dtype = np.dtype({'names':['man', 'mouse'], ... 'formats':[np.int64, np.int64]}) >>> arr = np.array(arr, dtype=dtype) >>> arr array([(1, 0), (0, 1), (1, 0), (1, 0)], dtype=[('man', '<i8'), ('mouse', '<i8')]) >>> ma.make_mask(arr, dtype=dtype) array([(True, False), (False, True), (True, False), (True, False)], dtype=[('man', '|b1'), ('mouse', '|b1')])# numpy.right_shift[#](#numpy-right-shift)
numpy.right_shift(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'right_shift'>*[#](#numpy.right_shift)
-
Shift the bits of an integer to the right.

Bits are shifted to the right

*x2*. Because the internal representation of numbers is in binary format, this operation is equivalent to dividing*x1*by`2**x2`
.Parameters:
-
**x1**array_like, int
Input values.

**x2**array_like, int
Number of bits to remove at the right of

*x1*. If`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray, int
Return

*x1*with bits shifted*x2*times to the right. This is a scalar if both*x1*and*x2*are scalars.
See also

`left_shift`
Shift the bits of an integer to the left.

`binary_repr`
Return the binary representation of the input number as a string.

Examples

>>> np.binary_repr(10) '1010' >>> np.right_shift(10, 1) 5 >>> np.binary_repr(5) '101'
>>> np.right_shift(10, [1,2,3]) array([5, 2, 1])
The

`>>`
operator can be used as a shorthand for`np.right_shift`
on ndarrays.>>> x1 = 10 >>> x2 = np.array([1,2,3]) >>> x1 >> x2 array([5, 2, 1])# numpy.polynomial.chebyshev.chebx[#](#numpy-polynomial-chebyshev-chebx)
polynomial.chebyshev.chebx*= array([0, 1])*[#](#numpy.polynomial.chebyshev.chebx)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.divmod[#](#numpy-divmod)
numpy.divmod(*x1*,*x2*, [*out1*,*out2*, ]*/*, [*out=(None*,*None)*, ]***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'divmod'>*[#](#numpy.divmod)
-
Return element-wise quotient and remainder simultaneously.

New in version 1.13.0.

`np.divmod(x, y)`
is equivalent to`(x // y, x % y)`
, but faster because it avoids redundant work. It is used to implement the Python built-in function`divmod`
on NumPy arrays.Parameters:
-
**x1**array_like
Dividend array.

**x2**array_like
Divisor array. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out1**ndarray
Element-wise quotient resulting from floor division. This is a scalar if both

*x1*and*x2*are scalars.
**out2**ndarray
Element-wise remainder from floor division. This is a scalar if both

*x1*and*x2*are scalars.
See also

`floor_divide`
Equivalent to Python’s

`//`
operator.
`remainder`
Equivalent to Python’s

`%`
operator.
`modf`
Equivalent to

`divmod(x, 1)`
for positive`x`
with the return values switched.
Examples

>>> np.divmod(np.arange(5), 3) (array([0, 0, 0, 1, 1]), array([0, 1, 2, 0, 1]))
The

function can be used as a shorthand for`divmod`
`np.divmod`
on ndarrays.>>> x = np.arange(5) >>> divmod(x, 3) (array([0, 0, 0, 1, 1]), array([0, 1, 2, 0, 1]))# numpy.random.triangular[#](#numpy-random-triangular)
random.triangular(*left*,*mode*,*right*,*size=None*)[#](#numpy.random.triangular)
-
Draw samples from the triangular distribution over the interval

`[left, right]`
.The triangular distribution is a continuous probability distribution with lower limit left, peak at mode, and upper limit right. Unlike the other distributions, these parameters directly define the shape of the pdf.

Note

New code should use the

method of a`triangular`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**left**float or array_like of floats
Lower limit.

**mode**float or array_like of floats
The value where the peak of the distribution occurs. The value must fulfill the condition

`left <= mode <= right`
.
**right**float or array_like of floats
Upper limit, must be larger than

*left*.
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`left`
,`mode`
, and`right`
are all scalars. Otherwise,`np.broadcast(left, mode, right).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized triangular distribution.

See also

`random.Generator.triangular`
which should be used for new code.

Notes

The probability density function for the triangular distribution is

\[\begin{split}P(x;l, m, r) = \begin{cases} \frac{2(x-l)}{(r-l)(m-l)}& \text{for $l \leq x \leq m$},\\ \frac{2(r-x)}{(r-l)(r-m)}& \text{for $m \leq x \leq r$},\\ 0& \text{otherwise}. \end{cases}\end{split}\]The triangular distribution is often used in ill-defined problems where the underlying distribution is not known, but some knowledge of the limits and mode exists. Often it is used in simulations.

References

[1]Wikipedia, “Triangular distribution”

[https://en.wikipedia.org/wiki/Triangular_distribution](https://en.wikipedia.org/wiki/Triangular_distribution)Examples

Draw values from the distribution and plot the histogram:

>>> import matplotlib.pyplot as plt >>> h = plt.hist(np.random.triangular(-3, 0, 8, 100000), bins=200, ... density=True) >>> plt.show()# numpy.lib.Arrayterator[#](#numpy-lib-arrayterator)
*class*numpy.lib.Arrayterator(*var*,*buf_size=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/arrayterator.py#L16-L219)[#](#numpy.lib.Arrayterator)
-
Buffered iterator for big arrays.

creates a buffered iterator for reading big arrays in small contiguous blocks. The class is useful for objects stored in the file system. It allows iteration over the object`Arrayterator`
*without*reading everything in memory; instead, small blocks are read and iterated over.can be used with any object that supports multidimensional slices. This includes NumPy arrays, but also variables from Scientific.IO.NetCDF or pynetcdf for example.`Arrayterator`
Parameters:
-
**var**array_like
The object to iterate over.

**buf_size**int, optional
The buffer size. If

*buf_size*is supplied, the maximum amount of data that will be read into memory is*buf_size*elements. Default is None, which will read as many element as possible into memory.
See also

`ndenumerate`
Multidimensional array iterator.

`flatiter`
Flat array iterator.

`memmap`
Create a memory-map to an array stored in a binary file on disk.

Notes

The algorithm works by first finding a “running dimension”, along which the blocks will be extracted. Given an array of dimensions

`(d1, d2, ..., dn)`
, e.g. if*buf_size*is smaller than`d1`
, the first dimension will be used. If, on the other hand,`d1 < buf_size < d1*d2`
the second dimension will be used, and so on. Blocks are extracted along this dimension, and when the last block is returned the process continues from the next dimension, until all elements have been read.Examples

>>> a = np.arange(3 * 4 * 5 * 6).reshape(3, 4, 5, 6) >>> a_itor = np.lib.Arrayterator(a, 2) >>> a_itor.shape (3, 4, 5, 6)
Now we can iterate over

`a_itor`
, and it will return arrays of size two. Since*buf_size*was smaller than any dimension, the first dimension will be iterated over first:>>> for subarr in a_itor: ... if not subarr.all(): ... print(subarr, subarr.shape) >>> # [[[[0 1]]]] (1, 1, 1, 2)# numpy.nancumsum[#](#numpy-nancumsum)
numpy.nancumsum(*a*,*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L814-L877)[#](#numpy.nancumsum)
-
Return the cumulative sum of array elements over a given axis treating Not a Numbers (NaNs) as zero. The cumulative sum does not change when NaNs are encountered and leading NaNs are replaced by zeros.

Zeros are returned for slices that are all-NaN or empty.

New in version 1.12.0.

Parameters:
-
**a**array_like
Input array.

**axis**int, optional
Axis along which the cumulative sum is computed. The default (None) is to compute the cumsum over the flattened array.

**dtype**dtype, optional
Type of the returned array and of the accumulator in which the elements are summed. If

is not specified, it defaults to the dtype of`dtype`
*a*, unless*a*has an integer dtype with a precision less than that of the default platform integer. In that case, the default platform integer is used.
**out**ndarray, optional
Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary. See

[Output type determination](../../user/basics.ufuncs.html#ufuncs-output-type)for more details.
Returns:
-
**nancumsum**ndarray.
A new array holding the result is returned unless

*out*is specified, in which it is returned. The result has the same size as*a*, and the same shape as*a*if*axis*is not None or*a*is a 1-d array.
See also

`numpy.cumsum`
Cumulative sum across array propagating NaNs.

`isnan`
Show which elements are NaN.

Examples

>>> np.nancumsum(1) array([1]) >>> np.nancumsum([1]) array([1]) >>> np.nancumsum([1, np.nan]) array([1., 1.]) >>> a = np.array([[1, 2], [3, np.nan]]) >>> np.nancumsum(a) array([1., 3., 6., 6.]) >>> np.nancumsum(a, axis=0) array([[1., 2.], [4., 2.]]) >>> np.nancumsum(a, axis=1) array([[1., 3.], [3., 3.]])# numpy.polynomial.polynomial.polyfit[#](#numpy-polynomial-polynomial-polyfit)
polynomial.polynomial.polyfit(*x*,*y*,*deg*,*rcond=None*,*full=False*,*w=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L1214-L1362)[#](#numpy.polynomial.polynomial.polyfit)
-
Least-squares fit of a polynomial to data.

Return the coefficients of a polynomial of degree

*deg*that is the least squares fit to the data values*y*given at points*x*. If*y*is 1-D the returned coefficients will also be 1-D. If*y*is 2-D multiple fits are done, one for each column of*y*, and the resulting coefficients are stored in the corresponding columns of a 2-D return. The fitted polynomial(s) are in the form\[p(x) = c_0 + c_1 * x + ... + c_n * x^n,\]where

*n*is*deg*.Parameters:
-
**x**array_like, shape (*M*,)
x-coordinates of the

*M*sample (data) points`(x[i], y[i])`
.
**y**array_like, shape (*M*,) or (*M*,*K*)
y-coordinates of the sample points. Several sets of sample points sharing the same x-coordinates can be (independently) fit with one call to

by passing in for`polyfit`
*y*a 2-D array that contains one data set per column.
**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than

*rcond*, relative to the largest singular value, will be ignored. The default value is`len(x)*eps`
, where*eps*is the relative precision of the platform’s float type, about 2e-16 in most cases.
**full**bool, optional
Switch determining the nature of the return value. When

`False`
(the default) just the coefficients are returned; when`True`
, diagnostic information from the singular value decomposition (used to solve the fit’s matrix equation) is also returned.
**w**array_like, shape (*M*,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.New in version 1.5.0.

Returns:
-
**coef**ndarray, shape (*deg*+ 1,) or (*deg*+ 1,*K*)
Polynomial coefficients ordered from low to high. If

*y*was 2-D, the coefficients in column*k*of*coef*represent the polynomial fit to the data in*y*’s*k*-th column.
**[residuals, rank, singular_values, rcond]**list
These values are only returned if

`full == True`
residuals – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

singular_values – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`numpy.linalg.lstsq`
Raises:
-
RankWarning
-
Raised if the matrix in the least-squares fit is rank deficient. The warning is only raised if

`full == False`
. The warnings can be turned off by:>>> import warnings >>> warnings.simplefilter('ignore', np.RankWarning)
See also

`numpy.polynomial.chebyshev.chebfit`
`numpy.polynomial.legendre.legfit`
`numpy.polynomial.laguerre.lagfit`
`numpy.polynomial.hermite.hermfit`
`numpy.polynomial.hermite_e.hermefit`
`polyval`
Evaluates a polynomial.

`polyvander`
Vandermonde matrix for powers.

`numpy.linalg.lstsq`
Computes a least-squares fit from the matrix.

`scipy.interpolate.UnivariateSpline`
Computes spline fits.

Notes

The solution is the coefficients of the polynomial

*p*that minimizes the sum of the weighted squared errors\[E = \sum_j w_j^2 * |y_j - p(x_j)|^2,\]where the \(w_j\) are the weights. This problem is solved by setting up the (typically) over-determined matrix equation:

\[V(x) * c = w * y,\]where

*V*is the weighted pseudo Vandermonde matrix of*x*,*c*are the coefficients to be solved for,*w*are the weights, and*y*are the observed values. This equation is then solved using the singular value decomposition of*V*.If some of the singular values of

*V*are so small that they are neglected (and==`full`
`False`
), awill be raised. This means that the coefficient values may be poorly determined. Fitting to a lower order polynomial will usually get rid of the warning (but may not be what you want, of course; if you have independent reason(s) for choosing the degree which isn’t working, you may have to: a) reconsider those reasons, and/or b) reconsider the quality of your data). The`RankWarning`
*rcond*parameter can also be set to a value smaller than its default, but the resulting fit may be spurious and have large contributions from roundoff error.Polynomial fits using double precision tend to “fail” at about (polynomial) degree 20. Fits using Chebyshev or Legendre series are generally better conditioned, but much can still depend on the distribution of the sample points and the smoothness of the data. If the quality of the fit is inadequate, splines may be a good alternative.

Examples

>>> np.random.seed(123) >>> from numpy.polynomial import polynomial as P >>> x = np.linspace(-1,1,51) # x "data": [-1, -0.96, ..., 0.96, 1] >>> y = x**3 - x + np.random.randn(len(x)) # x^3 - x + Gaussian noise >>> c, stats = P.polyfit(x,y,3,full=True) >>> np.random.seed(123) >>> c # c[0], c[2] should be approx. 0, c[1] approx. -1, c[3] approx. 1 array([ 0.01909725, -1.30598256, -0.00577963, 1.02644286]) # may vary >>> stats # note the large SSR, explaining the rather poor results [array([ 38.06116253]), 4, array([ 1.38446749, 1.32119158, 0.50443316, # may vary 0.28853036]), 1.1324274851176597e-014]
Same thing without the added noise

>>> y = x**3 - x >>> c, stats = P.polyfit(x,y,3,full=True) >>> c # c[0], c[2] should be "very close to 0", c[1] ~= -1, c[3] ~= 1 array([-6.36925336e-18, -1.00000000e+00, -4.08053781e-16, 1.00000000e+00]) >>> stats # note the minuscule SSR [array([ 7.46346754e-31]), 4, array([ 1.38446749, 1.32119158, # may vary 0.50443316, 0.28853036]), 1.1324274851176597e-014]# Permuted Congruential Generator (64-bit, PCG64 DXSM)[#](#permuted-congruential-generator-64-bit-pcg64-dxsm)
*class*numpy.random.PCG64DXSM(*seed=None*)[#](#numpy.random.PCG64DXSM)
-
BitGenerator for the PCG-64 DXSM pseudo-random number generator.

Parameters:
-
**seed**{None, int, array_like[ints], SeedSequence}, optional
A seed to initialize the

. If None, then fresh, unpredictable entropy will be pulled from the OS. If an`BitGenerator`
`int`
or`array_like[ints]`
is passed, then it will be passed toto derive the initial`SeedSequence`
state. One may also pass in a`BitGenerator`
instance.`SeedSequence`
Notes

PCG-64 DXSM is a 128-bit implementation of O’Neill’s permutation congruential generator (

[[1]](#rad26d0f7d970-1),[[2]](#rad26d0f7d970-2)). PCG-64 DXSM has a period of \(2^{128}\) and supports advancing an arbitrary number of steps as well as \(2^{127}\) streams. The specific member of the PCG family that we use is PCG CM DXSM 128/64. It differs from`PCG64`
in that it uses the stronger DXSM output function, a 64-bit “cheap multiplier” in the LCG, and outputs from the state before advancing it rather than advance-then-output.`PCG64DXSM`
provides a capsule containing function pointers that produce doubles, and unsigned 32 and 64- bit integers. These are not directly consumable in Python and must be consumed by a`Generator`
or similar object that supports low-level access.Supports the method

to advance the RNG an arbitrary number of steps. The state of the PCG-64 DXSM RNG is represented by 2 128-bit unsigned integers.`advance`
**State and Seeding**The

`PCG64DXSM`
state vector consists of 2 unsigned 128-bit values, which are represented externally as Python ints. One is the state of the PRNG, which is advanced by a linear congruential generator (LCG). The second is a fixed odd increment used in the LCG.The input seed is processed by

to generate both values. The increment is not independently settable.`SeedSequence`
**Parallel Features**The preferred way to use a BitGenerator in parallel applications is to use the

method to obtain entropy values, and to use these to generate new BitGenerators:`SeedSequence.spawn`
>>> from numpy.random import Generator, PCG64DXSM, SeedSequence >>> sg = SeedSequence(1234) >>> rg = [Generator(PCG64DXSM(s)) for s in sg.spawn(10)]
**Compatibility Guarantee**`PCG64DXSM`
makes a guarantee that a fixed seed will always produce the same random integer stream.References

## State[#](#state)
Get or set the PRNG state

|
## Parallel generation[#](#parallel-generation)
|
Advance the underlying RNG as-if delta draws have occurred.

|
|
Returns a new bit generator with the state jumped.

|
## Extending[#](#extending)
CFFI interface

|
ctypes interface

|# numpy.char.lstrip[#](#numpy-char-lstrip)
char.lstrip(*a*,*chars=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1142-L1194)[#](#numpy.char.lstrip)
-
For each element in

*a*, return a copy with the leading characters removed.Calls

*str.lstrip*element-wise.Parameters:
-
**a**array-like, {str, unicode}
Input array.

**chars**{str, unicode}, optional
The

*chars*argument is a string specifying the set of characters to be removed. If omitted or None, the*chars*argument defaults to removing whitespace. The*chars*argument is not a prefix; rather, all combinations of its values are stripped.
Returns:
-
**out**ndarray, {str, unicode}
Output array of str or unicode, depending on input type

See also

Examples

>>> c = np.array(['aAaAaA', ' aA ', 'abBABba']) >>> c array(['aAaAaA', ' aA ', 'abBABba'], dtype='<U7')
The ‘a’ variable is unstripped from c[1] because whitespace leading.

>>> np.char.lstrip(c, 'a') array(['AaAaA', ' aA ', 'bBABba'], dtype='<U7')
>>> np.char.lstrip(c, 'A') # leaves c unchanged array(['aAaAaA', ' aA ', 'abBABba'], dtype='<U7') >>> (np.char.lstrip(c, ' ') == np.char.lstrip(c, '')).all() ... # XXX: is this a regression? This used to return True ... # np.char.lstrip(c,'') does not modify c at all. False >>> (np.char.lstrip(c, ' ') == np.char.lstrip(c, None)).all() True# numpy.ndarray.shape[#](#numpy-ndarray-shape)
attribute

ndarray.shape[#](#numpy.ndarray.shape)
-
Tuple of array dimensions.

The shape property is usually used to get the current shape of an array, but may also be used to reshape the array in-place by assigning a tuple of array dimensions to it. As with

, one of the new shape dimensions can be -1, in which case its value is inferred from the size of the array and the remaining dimensions. Reshaping an array in-place will fail if a copy is required.`numpy.reshape`
Warning

Setting

`arr.shape`
is discouraged and may be deprecated in the future. Usingis the preferred approach.`ndarray.reshape`
See also

`numpy.shape`
Equivalent getter function.

`numpy.reshape`
Function similar to setting

`shape`
.
`ndarray.reshape`
Method similar to setting

`shape`
.
Examples

>>> x = np.array([1, 2, 3, 4]) >>> x.shape (4,) >>> y = np.zeros((2, 3, 4)) >>> y.shape (2, 3, 4) >>> y.shape = (3, 8) >>> y array([[ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.]]) >>> y.shape = (3, 6) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: total size of new array must be unchanged >>> np.zeros((4,2))[::2].shape = (-1,) Traceback (most recent call last): File "<stdin>", line 1, in <module> AttributeError: Incompatible shape for in-place modification. Use `.reshape()` to make a copy with the desired shape.# numpy.mintypecode[#](#numpy-mintypecode)
numpy.mintypecode(*typechars*,*typeset='GDFgdf'*,*default='d'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/type_check.py#L25-L76)[#](#numpy.mintypecode)
-
Return the character for the minimum-size type to which given types can be safely cast.

The returned type character must represent the smallest size dtype such that an array of the returned type can handle the data from an array of all types in

*typechars*(or if*typechars*is an array, then its dtype.char).Parameters:
-
**typechars**list of str or array_like
If a list of strings, each string should represent a dtype. If array_like, the character representation of the array dtype is used.

**typeset**str or list of str, optional
The set of characters that the returned character is chosen from. The default set is ‘GDFgdf’.

**default**str, optional
The default character, this is returned if none of the characters in

*typechars*matches a character in*typeset*.
Returns:
-
**typechar**str
The character representing the minimum-size type that was found.

See also

Examples

>>> np.mintypecode(['d', 'f', 'S']) 'd' >>> x = np.array([1.1, 2-3.j]) >>> np.mintypecode(x) 'D'
>>> np.mintypecode('abceh', default='G') 'G'# numpy.ma.vstack[#](#numpy-ma-vstack)
ma.vstack*= <numpy.ma.extras._fromnxfunction_seq object>*[#](#numpy.ma.vstack)
-
vstack

Stack arrays in sequence vertically (row wise).

This is equivalent to concatenation along the first axis after 1-D arrays of shape

*(N,)*have been reshaped to*(1,N)*. Rebuilds arrays divided by.`vsplit`
This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions

,`concatenate`
and`stack`
provide more general stacking and concatenation operations.`block`
`np.row_stack`
is an alias for. They are the same function.`vstack`
Parameters:
-
**tup**sequence of ndarrays
The arrays must have the same shape along all but the first axis. 1-D arrays must have the same length.

**dtype**str or dtype
If provided, the destination array will have this dtype. Cannot be provided together with

*out*.
**.. versionadded:: 1.24**
**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘same_kind’.

**.. versionadded:: 1.24**
Returns:
-
**stacked**ndarray
The array formed by stacking the given arrays, will be at least 2-D.

See also

`concatenate`
Join a sequence of arrays along an existing axis.

`stack`
Join a sequence of arrays along a new axis.

`block`
Assemble an nd-array from nested lists of blocks.

`hstack`
Stack arrays in sequence horizontally (column wise).

`dstack`
Stack arrays in sequence depth wise (along third axis).

`column_stack`
Stack 1-D arrays as columns into a 2-D array.

`vsplit`
Split an array into multiple sub-arrays vertically (row-wise).

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> a = np.array([1, 2, 3]) >>> b = np.array([4, 5, 6]) >>> np.vstack((a,b)) array([[1, 2, 3], [4, 5, 6]])
>>> a = np.array([[1], [2], [3]]) >>> b = np.array([[4], [5], [6]]) >>> np.vstack((a,b)) array([[1], [2], [3], [4], [5], [6]])# numpy.polynomial.polynomial.polygrid3d[#](#numpy-polynomial-polynomial-polygrid3d)
polynomial.polynomial.polygrid3d(*x*,*y*,*z*,*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L1002-L1055)[#](#numpy.polynomial.polynomial.polygrid3d)
-
Evaluate a 3-D polynomial on the Cartesian product of x, y and z.

This function returns the values:

\[p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * a^i * b^j * c^k\]where the points

*(a, b, c)*consist of all triples formed by taking*a*from*x*,*b*from*y*, and*c*from*z*. The resulting points form a grid with*x*in the first dimension,*y*in the second, and*z*in the third.The parameters

*x*,*y*, and*z*are converted to arrays only if they are tuples or a lists, otherwise they are treated as a scalars. In either case, either*x*,*y*, and*z*or their elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*has fewer than three dimensions, ones are implicitly appended to its shape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape + y.shape + z.shape.Parameters:
-
**x, y, z**array_like, compatible objects
The three dimensional series is evaluated at the points in the Cartesian product of

*x*,*y*, and*z*. If*x*,`y`, or*z*is a list or tuple, it is first converted to an ndarray, otherwise it is left unchanged and, if it isn’t an ndarray, it is treated as a scalar.
**c**array_like
Array of coefficients ordered so that the coefficients for terms of degree i,j are contained in

`c[i,j]`
. If*c*has dimension greater than two the remaining indices enumerate multiple sets of coefficients.
Returns:
-
**values**ndarray, compatible object
The values of the two dimensional polynomial at points in the Cartesian product of

*x*and*y*.
See also

Notes

New in version 1.7.0.# numpy.logical_xor[#](#numpy-logical-xor)
numpy.logical_xor(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'logical_xor'>*[#](#numpy.logical_xor)
-
Compute the truth value of x1 XOR x2, element-wise.

Parameters:
-
**x1, x2**array_like
Logical XOR is applied to the elements of

*x1*and*x2*. If`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**bool or ndarray of bool
Boolean result of the logical XOR operation applied to the elements of

*x1*and*x2*; the shape is determined by broadcasting. This is a scalar if both*x1*and*x2*are scalars.
See also

Examples

>>> np.logical_xor(True, False) True >>> np.logical_xor([True, True, False, False], [True, False, True, False]) array([False, True, True, False])
>>> x = np.arange(5) >>> np.logical_xor(x < 1, x > 3) array([ True, False, False, False, True])
Simple example showing support of broadcasting

>>> np.logical_xor(0, np.eye(2)) array([[ True, False], [False, True]])# Writing your own ufunc[#](#writing-your-own-ufunc)
*He-Man*
## Creating a new universal function[#](#creating-a-new-universal-function)
Before reading this, it may help to familiarize yourself with the basics
of C extensions for Python by reading/skimming the tutorials in Section 1
of [Extending and Embedding the Python Interpreter](https://docs.python.org/extending/index.html) and in [How to extend
NumPy](c-info.how-to-extend.html)

The umath module is a computer-generated C-module that creates many ufuncs. It provides a great many examples of how to create a universal function. Creating your own ufunc that will make use of the ufunc machinery is not difficult either. Suppose you have a function that you want to operate element-by-element over its inputs. By creating a new ufunc you will obtain a function that handles

broadcasting

N-dimensional looping

automatic type-conversions with minimal memory usage

optional output arrays

It is not difficult to create your own ufunc. All that is required is a 1-d loop for each data-type you want to support. Each 1-d loop must have a specific signature, and only ufuncs for fixed-size data-types can be used. The function call used to create a new ufunc to work on built-in data-types is given below. A different mechanism is used to register ufuncs for user-defined data-types.

In the next several sections we give example code that can be easily modified to create your own ufuncs. The examples are successively more complete or complicated versions of the logit function, a common function in statistical modeling. Logit is also interesting because, due to the magic of IEEE standards (specifically IEEE 754), all of the logit functions created below automatically have the following behavior.

```
>>> logit(0)
-inf
>>> logit(1)
inf
>>> logit(2)
nan
>>> logit(-2)
nan
```
This is wonderful because the function writer doesn’t have to manually propagate infs or nans.

## Example Non-ufunc extension[#](#example-non-ufunc-extension)
For comparison and general edification of the reader we provide
a simple implementation of a C extension of `logit`
that uses no
numpy.

To do this we need two files. The first is the C file which contains
the actual code, and the second is the `setup.py`
file used to create
the module.

#define PY_SSIZE_T_CLEAN #include <Python.h> #include <math.h> /* * spammodule.c * This is the C code for a non-numpy Python extension to * define the logit function, where logit(p) = log(p/(1-p)). * This function will not work on numpy arrays automatically. * numpy.vectorize must be called in python to generate * a numpy-friendly function. * * Details explaining the Python-C API can be found under * 'Extending and Embedding' and 'Python/C API' at * docs.python.org . */ /* This declares the logit function */ static PyObject *spam_logit(PyObject *self, PyObject *args); /* * This tells Python what methods this module has. * See the Python-C API for more information. */ static PyMethodDef SpamMethods[] = { {"logit", spam_logit, METH_VARARGS, "compute logit"}, {NULL, NULL, 0, NULL} }; /* * This actually defines the logit function for * input args from Python. */ static PyObject *spam_logit(PyObject *self, PyObject *args) { double p; /* This parses the Python argument into a double */ if(!PyArg_ParseTuple(args, "d", &p)) { return NULL; } /* THE ACTUAL LOGIT FUNCTION */ p = p/(1-p); p = log(p); /*This builds the answer back into a python object */ return Py_BuildValue("d", p); } /* This initiates the module using the above definitions. */ static struct PyModuleDef moduledef = { PyModuleDef_HEAD_INIT, "spam", NULL, -1, SpamMethods, NULL, NULL, NULL, NULL }; PyMODINIT_FUNC PyInit_spam(void) { PyObject *m; m = PyModule_Create(&moduledef); if (!m) { return NULL; } return m; }
To use the `setup.py file`
, place `setup.py`
and `spammodule.c`
in the same folder. Then `python setup.py build`
will build the module to
import, or `python setup.py install`
will install the module to your
site-packages directory.

''' setup.py file for spammodule.c Calling $python setup.py build_ext --inplace will build the extension library in the current file. Calling $python setup.py build will build a file that looks like ./build/lib*, where lib* is a file that begins with lib. The library will be in this file and end with a C library extension, such as .so Calling $python setup.py install will install the module in your site-packages file. See the distutils section of 'Extending and Embedding the Python Interpreter' at docs.python.org for more information. ''' from distutils.core import setup, Extension module1 = Extension('spam', sources=['spammodule.c'], include_dirs=['/usr/local/lib']) setup(name = 'spam', version='1.0', description='This is my spam package', ext_modules = [module1])
Once the spam module is imported into python, you can call logit
via `spam.logit`
. Note that the function used above cannot be applied
as-is to numpy arrays. To do so we must call [ numpy.vectorize](../reference/generated/numpy.vectorize.html#numpy.vectorize)
on it. For example, if a python interpreter is opened in the file containing
the spam library or spam has been installed, one can perform the
following commands:

```
>>> import numpy as np
>>> import spam
>>> spam.logit(0)
-inf
>>> spam.logit(1)
inf
>>> spam.logit(0.5)
0.0
>>> x = np.linspace(0,1,10)
>>> spam.logit(x)
TypeError: only length-1 arrays can be converted to Python scalars
>>> f = np.vectorize(spam.logit)
>>> f(x)
array([ -inf, -2.07944154, -1.25276297, -0.69314718, -0.22314355,
0.22314355, 0.69314718, 1.25276297, 2.07944154, inf])
```
THE RESULTING LOGIT FUNCTION IS NOT FAST! `numpy.vectorize`
simply
loops over `spam.logit`
. The loop is done at the C level, but the numpy
array is constantly being parsed and build back up. This is expensive.
When the author compared `numpy.vectorize(spam.logit)`
against the
logit ufuncs constructed below, the logit ufuncs were almost exactly
4 times faster. Larger or smaller speedups are, of course, possible
depending on the nature of the function.

## Example NumPy ufunc for one dtype[#](#example-numpy-ufunc-for-one-dtype)
For simplicity we give a ufunc for a single dtype, the `'f8'`
`double`
. As in the previous section, we first give the `.c`
file
and then the `setup.py`
file used to create the module containing the
ufunc.

The place in the code corresponding to the actual computations for
the ufunc are marked with `/\* BEGIN main ufunc computation \*/`
and
`/\* END main ufunc computation \*/`
. The code in between those lines is
the primary thing that must be changed to create your own ufunc.

#define PY_SSIZE_T_CLEAN #include <Python.h> #include "numpy/ndarraytypes.h" #include "numpy/ufuncobject.h" #include "numpy/npy_3kcompat.h" #include <math.h> /* * single_type_logit.c * This is the C code for creating your own * NumPy ufunc for a logit function. * * In this code we only define the ufunc for * a single dtype. The computations that must * be replaced to create a ufunc for * a different function are marked with BEGIN * and END. * * Details explaining the Python-C API can be found under * 'Extending and Embedding' and 'Python/C API' at * docs.python.org . */ static PyMethodDef LogitMethods[] = { {NULL, NULL, 0, NULL} }; /* The loop definition must precede the PyMODINIT_FUNC. */ static void double_logit(char **args, const npy_intp *dimensions, const npy_intp *steps, void *data) { npy_intp i; npy_intp n = dimensions[0]; char *in = args[0], *out = args[1]; npy_intp in_step = steps[0], out_step = steps[1]; double tmp; for (i = 0; i < n; i++) { /* BEGIN main ufunc computation */ tmp = *(double *)in; tmp /= 1 - tmp; *((double *)out) = log(tmp); /* END main ufunc computation */ in += in_step; out += out_step; } } /* This a pointer to the above function */ PyUFuncGenericFunction funcs[1] = {&double_logit}; /* These are the input and return dtypes of logit.*/ static char types[2] = {NPY_DOUBLE, NPY_DOUBLE}; static struct PyModuleDef moduledef = { PyModuleDef_HEAD_INIT, "npufunc", NULL, -1, LogitMethods, NULL, NULL, NULL, NULL }; PyMODINIT_FUNC PyInit_npufunc(void) { PyObject *m, *logit, *d; import_array(); import_umath(); m = PyModule_Create(&moduledef); if (!m) { return NULL; } logit = PyUFunc_FromFuncAndData(funcs, NULL, types, 1, 1, 1, PyUFunc_None, "logit", "logit_docstring", 0); d = PyModule_GetDict(m); PyDict_SetItemString(d, "logit", logit); Py_DECREF(logit); return m; }
This is a `setup.py file`
for the above code. As before, the module
can be build via calling `python setup.py build`
at the command prompt,
or installed to site-packages via `python setup.py install`
. The module
can also be placed into a local folder e.g. `npufunc_directory`
below
using `python setup.py build_ext --inplace`
.

''' setup.py file for single_type_logit.c Note that since this is a numpy extension we use numpy.distutils instead of distutils from the python standard library. Calling $python setup.py build_ext --inplace will build the extension library in the npufunc_directory. Calling $python setup.py build will build a file that looks like ./build/lib*, where lib* is a file that begins with lib. The library will be in this file and end with a C library extension, such as .so Calling $python setup.py install will install the module in your site-packages file. See the distutils section of 'Extending and Embedding the Python Interpreter' at docs.python.org and the documentation on numpy.distutils for more information. ''' def configuration(parent_package='', top_path=None): from numpy.distutils.misc_util import Configuration config = Configuration('npufunc_directory', parent_package, top_path) config.add_extension('npufunc', ['single_type_logit.c']) return config if __name__ == "__main__": from numpy.distutils.core import setup setup(configuration=configuration)
After the above has been installed, it can be imported and used as follows.

```
>>> import numpy as np
>>> import npufunc
>>> npufunc.logit(0.5)
0.0
>>> a = np.linspace(0,1,5)
>>> npufunc.logit(a)
array([ -inf, -1.09861229, 0. , 1.09861229, inf])
```
## Example NumPy ufunc with multiple dtypes[#](#example-numpy-ufunc-with-multiple-dtypes)
We finally give an example of a full ufunc, with inner loops for
half-floats, floats, doubles, and long doubles. As in the previous
sections we first give the `.c`
file and then the corresponding
`setup.py`
file.

The places in the code corresponding to the actual computations for
the ufunc are marked with `/\* BEGIN main ufunc computation \*/`
and
`/\* END main ufunc computation \*/`
. The code in between those lines
is the primary thing that must be changed to create your own ufunc.

#define PY_SSIZE_T_CLEAN #include <Python.h> #include "numpy/ndarraytypes.h" #include "numpy/ufuncobject.h" #include "numpy/halffloat.h" #include <math.h> /* * multi_type_logit.c * This is the C code for creating your own * NumPy ufunc for a logit function. * * Each function of the form type_logit defines the * logit function for a different numpy dtype. Each * of these functions must be modified when you * create your own ufunc. The computations that must * be replaced to create a ufunc for * a different function are marked with BEGIN * and END. * * Details explaining the Python-C API can be found under * 'Extending and Embedding' and 'Python/C API' at * docs.python.org . * */ static PyMethodDef LogitMethods[] = { {NULL, NULL, 0, NULL} }; /* The loop definitions must precede the PyMODINIT_FUNC. */ static void long_double_logit(char **args, const npy_intp *dimensions, const npy_intp *steps, void *data) { npy_intp i; npy_intp n = dimensions[0]; char *in = args[0], *out = args[1]; npy_intp in_step = steps[0], out_step = steps[1]; long double tmp; for (i = 0; i < n; i++) { /* BEGIN main ufunc computation */ tmp = *(long double *)in; tmp /= 1 - tmp; *((long double *)out) = logl(tmp); /* END main ufunc computation */ in += in_step; out += out_step; } } static void double_logit(char **args, const npy_intp *dimensions, const npy_intp *steps, void *data) { npy_intp i; npy_intp n = dimensions[0]; char *in = args[0], *out = args[1]; npy_intp in_step = steps[0], out_step = steps[1]; double tmp; for (i = 0; i < n; i++) { /* BEGIN main ufunc computation */ tmp = *(double *)in; tmp /= 1 - tmp; *((double *)out) = log(tmp); /* END main ufunc computation */ in += in_step; out += out_step; } } static void float_logit(char **args, const npy_intp *dimensions, const npy_intp *steps, void *data) { npy_intp i; npy_intp n = dimensions[0]; char *in = args[0], *out = args[1]; npy_intp in_step = steps[0], out_step = steps[1]; float tmp; for (i = 0; i < n; i++) { /* BEGIN main ufunc computation */ tmp = *(float *)in; tmp /= 1 - tmp; *((float *)out) = logf(tmp); /* END main ufunc computation */ in += in_step; out += out_step; } } static void half_float_logit(char **args, const npy_intp *dimensions, const npy_intp *steps, void *data) { npy_intp i; npy_intp n = dimensions[0]; char *in = args[0], *out = args[1]; npy_intp in_step = steps[0], out_step = steps[1]; float tmp; for (i = 0; i < n; i++) { /* BEGIN main ufunc computation */ tmp = npy_half_to_float(*(npy_half *)in); tmp /= 1 - tmp; tmp = logf(tmp); *((npy_half *)out) = npy_float_to_half(tmp); /* END main ufunc computation */ in += in_step; out += out_step; } } /*This gives pointers to the above functions*/ PyUFuncGenericFunction funcs[4] = {&half_float_logit, &float_logit, &double_logit, &long_double_logit}; static char types[8] = {NPY_HALF, NPY_HALF, NPY_FLOAT, NPY_FLOAT, NPY_DOUBLE, NPY_DOUBLE, NPY_LONGDOUBLE, NPY_LONGDOUBLE}; static struct PyModuleDef moduledef = { PyModuleDef_HEAD_INIT, "npufunc", NULL, -1, LogitMethods, NULL, NULL, NULL, NULL }; PyMODINIT_FUNC PyInit_npufunc(void) { PyObject *m, *logit, *d; import_array(); import_umath(); m = PyModule_Create(&moduledef); if (!m) { return NULL; } logit = PyUFunc_FromFuncAndData(funcs, NULL, types, 4, 1, 1, PyUFunc_None, "logit", "logit_docstring", 0); d = PyModule_GetDict(m); PyDict_SetItemString(d, "logit", logit); Py_DECREF(logit); return m; }
This is a `setup.py`
file for the above code. As before, the module
can be build via calling `python setup.py build`
at the command prompt,
or installed to site-packages via `python setup.py install`
.

''' setup.py file for multi_type_logit.c Note that since this is a numpy extension we use numpy.distutils instead of distutils from the python standard library. Calling $python setup.py build_ext --inplace will build the extension library in the current file. Calling $python setup.py build will build a file that looks like ./build/lib*, where lib* is a file that begins with lib. The library will be in this file and end with a C library extension, such as .so Calling $python setup.py install will install the module in your site-packages file. See the distutils section of 'Extending and Embedding the Python Interpreter' at docs.python.org and the documentation on numpy.distutils for more information. ''' def configuration(parent_package='', top_path=None): from numpy.distutils.misc_util import Configuration, get_info #Necessary for the half-float d-type. info = get_info('npymath') config = Configuration('npufunc_directory', parent_package, top_path) config.add_extension('npufunc', ['multi_type_logit.c'], extra_info=info) return config if __name__ == "__main__": from numpy.distutils.core import setup setup(configuration=configuration)
After the above has been installed, it can be imported and used as follows.

```
>>> import numpy as np
>>> import npufunc
>>> npufunc.logit(0.5)
0.0
>>> a = np.linspace(0,1,5)
>>> npufunc.logit(a)
array([ -inf, -1.09861229, 0. , 1.09861229, inf])
```
## Example NumPy ufunc with multiple arguments/return values[#](#example-numpy-ufunc-with-multiple-arguments-return-values)
Our final example is a ufunc with multiple arguments. It is a modification
of the code for a logit ufunc for data with a single dtype. We
compute `(A * B, logit(A * B))`
.

We only give the C code as the setup.py file is exactly the same as
the `setup.py`
file in [Example NumPy ufunc for one dtype](#example-numpy-ufunc-for-one-dtype), except that
the line

config.add_extension('npufunc', ['single_type_logit.c'])
is replaced with

config.add_extension('npufunc', ['multi_arg_logit.c'])
The C file is given below. The ufunc generated takes two arguments `A`
and `B`
. It returns a tuple whose first element is `A * B`
and whose second
element is `logit(A * B)`
. Note that it automatically supports broadcasting,
as well as all other properties of a ufunc.

#define PY_SSIZE_T_CLEAN #include <Python.h> #include "numpy/ndarraytypes.h" #include "numpy/ufuncobject.h" #include "numpy/halffloat.h" #include <math.h> /* * multi_arg_logit.c * This is the C code for creating your own * NumPy ufunc for a multiple argument, multiple * return value ufunc. The places where the * ufunc computation is carried out are marked * with comments. * * Details explaining the Python-C API can be found under * 'Extending and Embedding' and 'Python/C API' at * docs.python.org. */ static PyMethodDef LogitMethods[] = { {NULL, NULL, 0, NULL} }; /* The loop definition must precede the PyMODINIT_FUNC. */ static void double_logitprod(char **args, const npy_intp *dimensions, const npy_intp *steps, void *data) { npy_intp i; npy_intp n = dimensions[0]; char *in1 = args[0], *in2 = args[1]; char *out1 = args[2], *out2 = args[3]; npy_intp in1_step = steps[0], in2_step = steps[1]; npy_intp out1_step = steps[2], out2_step = steps[3]; double tmp; for (i = 0; i < n; i++) { /* BEGIN main ufunc computation */ tmp = *(double *)in1; tmp *= *(double *)in2; *((double *)out1) = tmp; *((double *)out2) = log(tmp / (1 - tmp)); /* END main ufunc computation */ in1 += in1_step; in2 += in2_step; out1 += out1_step; out2 += out2_step; } } /*This a pointer to the above function*/ PyUFuncGenericFunction funcs[1] = {&double_logitprod}; /* These are the input and return dtypes of logit.*/ static char types[4] = {NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE}; static struct PyModuleDef moduledef = { PyModuleDef_HEAD_INIT, "npufunc", NULL, -1, LogitMethods, NULL, NULL, NULL, NULL }; PyMODINIT_FUNC PyInit_npufunc(void) { PyObject *m, *logit, *d; import_array(); import_umath(); m = PyModule_Create(&moduledef); if (!m) { return NULL; } logit = PyUFunc_FromFuncAndData(funcs, NULL, types, 1, 2, 2, PyUFunc_None, "logit", "logit_docstring", 0); d = PyModule_GetDict(m); PyDict_SetItemString(d, "logit", logit); Py_DECREF(logit); return m; }
## Example NumPy ufunc with structured array dtype arguments[#](#example-numpy-ufunc-with-structured-array-dtype-arguments)
This example shows how to create a ufunc for a structured array dtype.
For the example we show a trivial ufunc for adding two arrays with dtype
`'u8,u8,u8'`
. The process is a bit different from the other examples since
a call to [ PyUFunc_FromFuncAndData](../reference/c-api/ufunc.html#c.PyUFunc_FromFuncAndData) doesn’t fully register ufuncs for
custom dtypes and structured array dtypes. We need to also call

[to finish setting up the ufunc.](../reference/c-api/ufunc.html#c.PyUFunc_RegisterLoopForDescr)
`PyUFunc_RegisterLoopForDescr`
We only give the C code as the `setup.py`
file is exactly the same as
the `setup.py`
file in [Example NumPy ufunc for one dtype](#example-numpy-ufunc-for-one-dtype), except that
the line

config.add_extension('npufunc', ['single_type_logit.c'])
is replaced with

config.add_extension('npufunc', ['add_triplet.c'])
The C file is given below.

#define PY_SSIZE_T_CLEAN #include <Python.h> #include "numpy/ndarraytypes.h" #include "numpy/ufuncobject.h" #include "numpy/npy_3kcompat.h" #include <math.h> /* * add_triplet.c * This is the C code for creating your own * NumPy ufunc for a structured array dtype. * * Details explaining the Python-C API can be found under * 'Extending and Embedding' and 'Python/C API' at * docs.python.org. */ static PyMethodDef StructUfuncTestMethods[] = { {NULL, NULL, 0, NULL} }; /* The loop definition must precede the PyMODINIT_FUNC. */ static void add_uint64_triplet(char **args, const npy_intp *dimensions, const npy_intp *steps, void *data) { npy_intp i; npy_intp is1 = steps[0]; npy_intp is2 = steps[1]; npy_intp os = steps[2]; npy_intp n = dimensions[0]; uint64_t *x, *y, *z; char *i1 = args[0]; char *i2 = args[1]; char *op = args[2]; for (i = 0; i < n; i++) { x = (uint64_t *)i1; y = (uint64_t *)i2; z = (uint64_t *)op; z[0] = x[0] + y[0]; z[1] = x[1] + y[1]; z[2] = x[2] + y[2]; i1 += is1; i2 += is2; op += os; } } /* This a pointer to the above function */ PyUFuncGenericFunction funcs[1] = {&add_uint64_triplet}; /* These are the input and return dtypes of add_uint64_triplet. */ static char types[3] = {NPY_UINT64, NPY_UINT64, NPY_UINT64}; static struct PyModuleDef moduledef = { PyModuleDef_HEAD_INIT, "struct_ufunc_test", NULL, -1, StructUfuncTestMethods, NULL, NULL, NULL, NULL }; PyMODINIT_FUNC PyInit_struct_ufunc_test(void) { PyObject *m, *add_triplet, *d; PyObject *dtype_dict; PyArray_Descr *dtype; PyArray_Descr *dtypes[3]; import_array(); import_umath(); m = PyModule_Create(&moduledef); if (m == NULL) { return NULL; } /* Create a new ufunc object */ add_triplet = PyUFunc_FromFuncAndData(NULL, NULL, NULL, 0, 2, 1, PyUFunc_None, "add_triplet", "add_triplet_docstring", 0); dtype_dict = Py_BuildValue("[(s, s), (s, s), (s, s)]", "f0", "u8", "f1", "u8", "f2", "u8"); PyArray_DescrConverter(dtype_dict, &dtype); Py_DECREF(dtype_dict); dtypes[0] = dtype; dtypes[1] = dtype; dtypes[2] = dtype; /* Register ufunc for structured dtype */ PyUFunc_RegisterLoopForDescr(add_triplet, dtype, &add_uint64_triplet, dtypes, NULL); d = PyModule_GetDict(m); PyDict_SetItemString(d, "add_triplet", add_triplet); Py_DECREF(add_triplet); return m; }
The returned ufunc object is a callable Python object. It should be placed in a (module) dictionary under the same name as was used in the name argument to the ufunc-creation routine. The following example is adapted from the umath module

static PyUFuncGenericFunction atan2_functions[] = { PyUFunc_ff_f, PyUFunc_dd_d, PyUFunc_gg_g, PyUFunc_OO_O_method}; static void *atan2_data[] = { (void *)atan2f, (void *)atan2, (void *)atan2l, (void *)"arctan2"}; static char atan2_signatures[] = { NPY_FLOAT, NPY_FLOAT, NPY_FLOAT, NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE, NPY_LONGDOUBLE, NPY_LONGDOUBLE, NPY_LONGDOUBLE NPY_OBJECT, NPY_OBJECT, NPY_OBJECT}; ... /* in the module initialization code */ PyObject *f, *dict, *module; ... dict = PyModule_GetDict(module); ... f = PyUFunc_FromFuncAndData(atan2_functions, atan2_data, atan2_signatures, 4, 2, 1, PyUFunc_None, "arctan2", "a safe and correct arctan(x1/x2)", 0); PyDict_SetItemString(dict, "arctan2", f); Py_DECREF(f); ...# numpy.ma.frombuffer[#](#numpy-ma-frombuffer)
ma.frombuffer(*buffer*,*dtype=float*,*count=-1*,*offset=0*,***,*like=None*)*= <numpy.ma.core._convert2ma object>*[#](#numpy.ma.frombuffer)
-
Interpret a buffer as a 1-dimensional array.

Parameters:
-
**buffer**buffer_like
An object that exposes the buffer interface.

**dtype**data-type, optional
Data-type of the returned array; default: float.

**count**int, optional
Number of items to read.

`-1`
means all data in the buffer.
**offset**int, optional
Start reading the buffer from this offset (in bytes); default: 0.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
out: MaskedArray
-
See also

`ndarray.tobytes`
Inverse of this operation, construct Python bytes from the raw data bytes in the array.

Notes

If the buffer has data that is not in machine byte-order, this should be specified as part of the data-type, e.g.:

>>> dt = np.dtype(int) >>> dt = dt.newbyteorder('>') >>> np.frombuffer(buf, dtype=dt)
The data of the resulting array will not be byteswapped, but will be interpreted correctly.

This function creates a view into the original object. This should be safe in general, but it may make sense to copy the result when the original object is mutable or untrusted.

Examples

>>> s = b'hello world' >>> np.frombuffer(s, dtype='S1', count=5, offset=6) array([b'w', b'o', b'r', b'l', b'd'], dtype='|S1')
>>> np.frombuffer(b'\x01\x02', dtype=np.uint8) array([1, 2], dtype=uint8) >>> np.frombuffer(b'\x01\x02\x03\x04\x05', dtype=np.uint8, count=3) array([1, 2, 3], dtype=uint8)# numpy.isfinite[#](#numpy-isfinite)
numpy.isfinite(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'isfinite'>*[#](#numpy.isfinite)
-
Test element-wise for finiteness (not infinity and not Not a Number).

The result is returned as a boolean array.

Parameters:
-
**x**array_like
Input values.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray, bool
True where

`x`
is not positive infinity, negative infinity, or NaN; false otherwise. This is a scalar if*x*is a scalar.
Notes

Not a Number, positive infinity and negative infinity are considered to be non-finite.

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). This means that Not a Number is not equivalent to infinity. Also that positive infinity is not equivalent to negative infinity. But infinity is equivalent to positive infinity. Errors result if the second argument is also supplied when

*x*is a scalar input, or if first and second arguments have different shapes.Examples

>>> np.isfinite(1) True >>> np.isfinite(0) True >>> np.isfinite(np.nan) False >>> np.isfinite(np.inf) False >>> np.isfinite(np.NINF) False >>> np.isfinite([np.log(-1.),1.,np.log(0)]) array([False, True, False])
>>> x = np.array([-np.inf, 0., np.inf]) >>> y = np.array([2, 2, 2]) >>> np.isfinite(x, y) array([0, 1, 0]) >>> y array([0, 1, 0])# numpy.heaviside[#](#numpy-heaviside)
numpy.heaviside(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'heaviside'>*[#](#numpy.heaviside)
-
Compute the Heaviside step function.

The Heaviside step function is defined as:

0 if x1 < 0 heaviside(x1, x2) = x2 if x1 == 0 1 if x1 > 0
where

*x2*is often taken to be 0.5, but 0 and 1 are also sometimes used.Parameters:
-
**x1**array_like
Input values.

**x2**array_like
The value of the function when x1 is 0. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray or scalar
The output array, element-wise Heaviside step function of

*x1*. This is a scalar if both*x1*and*x2*are scalars.
Notes

New in version 1.13.0.

References

Examples

>>> np.heaviside([-1.5, 0, 2.0], 0.5) array([ 0. , 0.5, 1. ]) >>> np.heaviside([-1.5, 0, 2.0], 1) array([ 0., 1., 1.])# numpy.ndarray.astype[#](#numpy-ndarray-astype)
method

ndarray.astype(*dtype*,*order='K'*,*casting='unsafe'*,*subok=True*,*copy=True*)[#](#numpy.ndarray.astype)
-
Copy of the array, cast to a specified type.

Parameters:
-
**dtype**str or dtype
Typecode or data-type to which the array is cast.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout order of the result. ‘C’ means C order, ‘F’ means Fortran order, ‘A’ means ‘F’ order if all the arrays are Fortran contiguous, ‘C’ order otherwise, and ‘K’ means as close to the order the array elements appear in memory as possible. Default is ‘K’.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘unsafe’ for backwards compatibility.

‘no’ means the data types should not be cast at all.

‘equiv’ means only byte-order changes are allowed.

‘safe’ means only casts which can preserve values are allowed.

‘same_kind’ means only safe casts or casts within a kind, like float64 to float32, are allowed.

‘unsafe’ means any data conversions may be done.

**subok**bool, optional
If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.

**copy**bool, optional
By default, astype always returns a newly allocated array. If this is set to false, and the

,`dtype`
*order*, and*subok*requirements are satisfied, the input array is returned instead of a copy.
Returns:
-
Raises:
-
ComplexWarning
-
When casting from complex to float or int. To avoid this, one should use

`a.real.astype(t)`
.
Notes

Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for “unsafe” casting. Casting to multiple fields is allowed, but casting from multiple fields is not.

Changed in version 1.9.0: Casting from numeric to string types in ‘safe’ casting mode requires that the string dtype length is long enough to store the max integer/float value converted.

Examples

>>> x = np.array([1, 2, 2.5]) >>> x array([1. , 2. , 2.5])
>>> x.astype(int) array([1, 2, 2])# numpy.polymul[#](#numpy-polymul)
numpy.polymul(*a1*,*a2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/polynomial.py#L910-L970)[#](#numpy.polymul)
-
Find the product of two polynomials.

Note

This forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in

is preferred. A summary of the differences can be found in the`numpy.polynomial`
[transition guide](../routines.polynomials.html).Finds the polynomial resulting from the multiplication of the two input polynomials. Each input must be either a poly1d object or a 1D sequence of polynomial coefficients, from highest to lowest degree.

Parameters:
-
**a1, a2**array_like or poly1d object
Input polynomials.

Returns:
-
**out**ndarray or poly1d object
The polynomial resulting from the multiplication of the inputs. If either inputs is a poly1d object, then the output is also a poly1d object. Otherwise, it is a 1D array of polynomial coefficients from highest to lowest degree.

See also

Examples

>>> np.polymul([1, 2, 3], [9, 5, 1]) array([ 9, 23, 38, 17, 3])
Using poly1d objects:

>>> p1 = np.poly1d([1, 2, 3]) >>> p2 = np.poly1d([9, 5, 1]) >>> print(p1) 2 1 x + 2 x + 3 >>> print(p2) 2 9 x + 5 x + 1 >>> print(np.polymul(p1, p2)) 4 3 2 9 x + 23 x + 38 x + 17 x + 3# numpy.kron[#](#numpy-kron)
numpy.kron(*a*,*b*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L1067-L1178)[#](#numpy.kron)
-
Kronecker product of two arrays.

Computes the Kronecker product, a composite array made of blocks of the second array scaled by the first.

Parameters:
-
**a, b**array_like
Returns:
-
**out**ndarray
See also

`outer`
The outer product

Notes

The function assumes that the number of dimensions of

*a*and*b*are the same, if necessary prepending the smallest with ones. If`a.shape = (r0,r1,..,rN)`
and`b.shape = (s0,s1,...,sN)`
, the Kronecker product has shape`(r0*s0, r1*s1, ..., rN*SN)`
. The elements are products of elements from*a*and*b*, organized explicitly by:kron(a,b)[k0,k1,...,kN] = a[i0,i1,...,iN] * b[j0,j1,...,jN]
where:

kt = it * st + jt, t = 0,...,N
In the common 2-D case (N=1), the block structure can be visualized:

[[ a[0,0]*b, a[0,1]*b, ... , a[0,-1]*b ], [ ... ... ], [ a[-1,0]*b, a[-1,1]*b, ... , a[-1,-1]*b ]]
Examples

>>> np.kron([1,10,100], [5,6,7]) array([ 5, 6, 7, ..., 500, 600, 700]) >>> np.kron([5,6,7], [1,10,100]) array([ 5, 50, 500, ..., 7, 70, 700])
>>> np.kron(np.eye(2), np.ones((2,2))) array([[1., 1., 0., 0.], [1., 1., 0., 0.], [0., 0., 1., 1.], [0., 0., 1., 1.]])
>>> a = np.arange(100).reshape((2,5,2,5)) >>> b = np.arange(24).reshape((2,3,4)) >>> c = np.kron(a,b) >>> c.shape (2, 10, 6, 20) >>> I = (1,3,0,2) >>> J = (0,2,1) >>> J1 = (0,) + J # extend to ndim=4 >>> S1 = (1,) + b.shape >>> K = tuple(np.array(I) * np.array(S1) + np.array(J1)) >>> c[K] == a[I]*b[J] True# numpy.polyval[#](#numpy-polyval)
numpy.polyval(*p*,*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/polynomial.py#L705-L781)[#](#numpy.polyval)
-
Evaluate a polynomial at specific values.

Note

This forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in

is preferred. A summary of the differences can be found in the`numpy.polynomial`
[transition guide](../routines.polynomials.html).If

*p*is of length N, this function returns the value:`p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]`
If

*x*is a sequence, then`p(x)`
is returned for each element of`x`
. If*x*is another polynomial then the composite polynomial`p(x(t))`
is returned.Parameters:
-
**p**array_like or poly1d object
1D array of polynomial coefficients (including coefficients equal to zero) from highest degree to the constant term, or an instance of poly1d.

**x**array_like or poly1d object
A number, an array of numbers, or an instance of poly1d, at which to evaluate

*p*.
Returns:
-
**values**ndarray or poly1d
If

*x*is a poly1d instance, the result is the composition of the two polynomials, i.e.,*x*is “substituted” in*p*and the simplified result is returned. In addition, the type of*x*- array_like or poly1d - governs the type of the output:*x*array_like =>*values*array_like,*x*a poly1d object =>*values*is also.
See also

`poly1d`
A polynomial class.

Notes

Horner’s scheme

[[1]](#r138ee7027ddf-1)is used to evaluate the polynomial. Even so, for polynomials of high degree the values may be inaccurate due to rounding errors. Use carefully.If

*x*is a subtype ofthe return value will be of the same type.`ndarray`
References

[[1](#id1)]I. N. Bronshtein, K. A. Semendyayev, and K. A. Hirsch (Eng. trans. Ed.),

*Handbook of Mathematics*, New York, Van Nostrand Reinhold Co., 1985, pg. 720.Examples

>>> np.polyval([3,0,1], 5) # 3 * 5**2 + 0 * 5**1 + 1 76 >>> np.polyval([3,0,1], np.poly1d(5)) poly1d([76]) >>> np.polyval(np.poly1d([3,0,1]), 5) 76 >>> np.polyval(np.poly1d([3,0,1]), np.poly1d(5)) poly1d([76])# numpy.nanpercentile[#](#numpy-nanpercentile)
numpy.nanpercentile(*a*,*q*,*axis=None*,*out=None*,*overwrite_input=False*,*method='linear'*,*keepdims=<no value>*,***,*interpolation=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L1228-L1385)[#](#numpy.nanpercentile)
-
Compute the qth percentile of the data along the specified axis, while ignoring nan values.

Returns the qth percentile(s) of the array elements.

New in version 1.9.0.

Parameters:
-
**a**array_like
Input array or object that can be converted to an array, containing nan values to be ignored.

**q**array_like of float
Percentile or sequence of percentiles to compute, which must be between 0 and 100 inclusive.

**axis**{int, tuple of int, None}, optional
Axis or axes along which the percentiles are computed. The default is to compute the percentile(s) along a flattened version of the array.

**out**ndarray, optional
Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output, but the type (of the output) will be cast if necessary.

**overwrite_input**bool, optional
If True, then allow the input array

*a*to be modified by intermediate calculations, to save memory. In this case, the contents of the input*a*after this function completes is undefined.
**method**str, optional
This parameter specifies the method to use for estimating the percentile. There are many different methods, some unique to NumPy. See the notes for explanation. The options sorted by their R type as summarized in the H&F paper

[[1]](#re21b1d0b0470-1)are:‘inverted_cdf’

‘averaged_inverted_cdf’

‘closest_observation’

‘interpolated_inverted_cdf’

‘hazen’

‘weibull’

‘linear’ (default)

‘median_unbiased’

‘normal_unbiased’

The first three methods are discontinuous. NumPy further defines the following discontinuous variations of the default ‘linear’ (7.) option:

‘lower’

‘higher’,

‘midpoint’

‘nearest’

Changed in version 1.22.0: This argument was previously called “interpolation” and only offered the “linear” default and last four options.

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array

*a*.If this is anything but the default value it will be passed through (in the special case of an empty array) to the

function of the underlying array. If the array is a sub-class and`mean`
does not have the kwarg`mean`
*keepdims*this will raise a RuntimeError.
**interpolation**str, optional
Deprecated name for the method keyword argument.

Deprecated since version 1.22.0.

Returns:
-
**percentile**scalar or ndarray
If

*q*is a single percentile and*axis=None*, then the result is a scalar. If multiple percentiles are given, first axis of the result corresponds to the percentiles. The other axes are the axes that remain after the reduction of*a*. If the input contains integers or floats smaller than`float64`
, the output data-type is`float64`
. Otherwise, the output data-type is the same as that of the input. If*out*is specified, that array is returned instead.
See also

`nanmean`
`nanmedian`
equivalent to

`nanpercentile(..., 50)`
,`percentile`
,`median`
`mean`
`nanquantile`
equivalent to nanpercentile, except q in range [0, 1].

Notes

For more information please see

`numpy.percentile`
References

[[1](#id1)]R. J. Hyndman and Y. Fan, “Sample quantiles in statistical packages,” The American Statistician, 50(4), pp. 361-365, 1996

Examples

>>> a = np.array([[10., 7., 4.], [3., 2., 1.]]) >>> a[0][1] = np.nan >>> a array([[10., nan, 4.], [ 3., 2., 1.]]) >>> np.percentile(a, 50) nan >>> np.nanpercentile(a, 50) 3.0 >>> np.nanpercentile(a, 50, axis=0) array([6.5, 2. , 2.5]) >>> np.nanpercentile(a, 50, axis=1, keepdims=True) array([[7.], [2.]]) >>> m = np.nanpercentile(a, 50, axis=0) >>> out = np.zeros_like(m) >>> np.nanpercentile(a, 50, axis=0, out=out) array([6.5, 2. , 2.5]) >>> m array([6.5, 2. , 2.5])
>>> b = a.copy() >>> np.nanpercentile(b, 50, axis=1, overwrite_input=True) array([7., 2.]) >>> assert not np.all(a==b)# numpy.ma.argsort[#](#numpy-ma-argsort)
ma.argsort(*a*,*axis=<no value>*,*kind=None*,*order=None*,*endwith=True*,*fill_value=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7001-L7013)[#](#numpy.ma.argsort)
-
Return an ndarray of indices that sort the array along the specified axis. Masked values are filled beforehand to

*fill_value*.Parameters:
-
**axis**int, optional
Axis along which to sort. If None, the default, the flattened array is used.

Changed in version 1.13.0: Previously, the default was documented to be -1, but that was in error. At some future date, the default will change to -1, as originally intended. Until then, the axis should be given explicitly when

`arr.ndim > 1`
, to avoid a FutureWarning.
**kind**{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, optional
The sorting algorithm used.

**order**list, optional
When

*a*is an array with fields defined, this argument specifies which fields to compare first, second, etc. Not all fields need be specified.
**endwith**{True, False}, optional
Whether missing values (if any) should be treated as the largest values (True) or the smallest values (False) When the array contains unmasked values at the same extremes of the datatype, the ordering of these values and the masked values is undefined.

**fill_value**scalar or None, optional
Value used internally for the masked values. If

`fill_value`
is not None, it supersedes`endwith`
.
Returns:
-
**index_array**ndarray, int
Array of indices that sort

*a*along the specified axis. In other words,`a[index_array]`
yields a sorted*a*.
See also

`ma.MaskedArray.sort`
Describes sorting algorithms used.

`lexsort`
Indirect stable sort with multiple keys.

`numpy.ndarray.sort`
Inplace sort.

Notes

See

for notes on the different sorting algorithms.`sort`
Examples

>>> a = np.ma.array([3,2,1], mask=[False, False, True]) >>> a masked_array(data=[3, 2, --], mask=[False, False, True], fill_value=999999) >>> a.argsort() array([1, 0, 2])# numpy.arctanh[#](#numpy-arctanh)
numpy.arctanh(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'arctanh'>*[#](#numpy.arctanh)
-
Inverse hyperbolic tangent element-wise.

Parameters:
-
**x**array_like
Input array.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray or scalar
Array of the same shape as

*x*. This is a scalar if*x*is a scalar.
See also

Notes

is a multivalued function: for each`arctanh`
*x*there are infinitely many numbers*z*such that`tanh(z) = x`
. The convention is to return the*z*whose imaginary part lies in*[-pi/2, pi/2]*.For real-valued input data types,

always returns real output. For each value that cannot be expressed as a real number or infinity, it yields`arctanh`
`nan`
and sets the*invalid*floating point error flag.For complex-valued input,

is a complex analytical function that has branch cuts`arctanh`
*[-1, -inf]*and*[1, inf]*and is continuous from above on the former and from below on the latter.The inverse hyperbolic tangent is also known as

*atanh*or`tanh^-1`
.References

[1]M. Abramowitz and I.A. Stegun, “Handbook of Mathematical Functions”, 10th printing, 1964, pp. 86.

[https://personal.math.ubc.ca/~cbm/aands/page_86.htm](https://personal.math.ubc.ca/~cbm/aands/page_86.htm)[2]Wikipedia, “Inverse hyperbolic function”,

[https://en.wikipedia.org/wiki/Arctanh](https://en.wikipedia.org/wiki/Arctanh)Examples

>>> np.arctanh([0, -0.5]) array([ 0. , -0.54930614])# numpy.busday_count[#](#numpy-busday-count)
numpy.busday_count(*begindates*,*enddates*,*weekmask='1111100'*,*holidays=[]*,*busdaycal=None*,*out=None*)[#](#numpy.busday_count)
-
Counts the number of valid days between

*begindates*and*enddates*, not including the day of*enddates*.If

`enddates`
specifies a date value that is earlier than the corresponding`begindates`
date value, the count will be negative.New in version 1.7.0.

Parameters:
-
**begindates**array_like of datetime64[D]
The array of the first dates for counting.

**enddates**array_like of datetime64[D]
The array of the end dates for counting, which are excluded from the count themselves.

**weekmask**str or array_like of bool, optional
A seven-element array indicating which of Monday through Sunday are valid days. May be specified as a length-seven list or array, like [1,1,1,1,1,0,0]; a length-seven string, like ‘1111100’; or a string like “Mon Tue Wed Thu Fri”, made up of 3-character abbreviations for weekdays, optionally separated by white space. Valid abbreviations are: Mon Tue Wed Thu Fri Sat Sun

**holidays**array_like of datetime64[D], optional
An array of dates to consider as invalid dates. They may be specified in any order, and NaT (not-a-time) dates are ignored. This list is saved in a normalized form that is suited for fast calculations of valid days.

**busdaycal**busdaycalendar, optional
A

object which specifies the valid days. If this parameter is provided, neither weekmask nor holidays may be provided.`busdaycalendar`
**out**array of int, optional
If provided, this array is filled with the result.

Returns:
-
**out**array of int
An array with a shape from broadcasting

`begindates`
and`enddates`
together, containing the number of valid days between the begin and end dates.
See also

`busdaycalendar`
An object that specifies a custom set of valid days.

`is_busday`
Returns a boolean array indicating valid days.

`busday_offset`
Applies an offset counted in valid days.

Examples

>>> # Number of weekdays in January 2011 ... np.busday_count('2011-01', '2011-02') 21 >>> # Number of weekdays in 2011 >>> np.busday_count('2011', '2012') 260 >>> # Number of Saturdays in 2011 ... np.busday_count('2011', '2012', weekmask='Sat') 53# numpy.is_busday[#](#numpy-is-busday)
numpy.is_busday(*dates*,*weekmask='1111100'*,*holidays=None*,*busdaycal=None*,*out=None*)[#](#numpy.is_busday)
-
Calculates which of the given dates are valid days, and which are not.

New in version 1.7.0.

Parameters:
-
**dates**array_like of datetime64[D]
The array of dates to process.

**weekmask**str or array_like of bool, optional
A seven-element array indicating which of Monday through Sunday are valid days. May be specified as a length-seven list or array, like [1,1,1,1,1,0,0]; a length-seven string, like ‘1111100’; or a string like “Mon Tue Wed Thu Fri”, made up of 3-character abbreviations for weekdays, optionally separated by white space. Valid abbreviations are: Mon Tue Wed Thu Fri Sat Sun

**holidays**array_like of datetime64[D], optional
An array of dates to consider as invalid dates. They may be specified in any order, and NaT (not-a-time) dates are ignored. This list is saved in a normalized form that is suited for fast calculations of valid days.

**busdaycal**busdaycalendar, optional
A

object which specifies the valid days. If this parameter is provided, neither weekmask nor holidays may be provided.`busdaycalendar`
**out**array of bool, optional
If provided, this array is filled with the result.

Returns:
-
**out**array of bool
An array with the same shape as

`dates`
, containing True for each valid day, and False for each invalid day.
See also

`busdaycalendar`
An object that specifies a custom set of valid days.

`busday_offset`
Applies an offset counted in valid days.

`busday_count`
Counts how many valid days are in a half-open date range.

Examples

>>> # The weekdays are Friday, Saturday, and Monday ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'], ... holidays=['2011-07-01', '2011-07-04', '2011-07-17']) array([False, False, True])# numpy.random.Generator.uniform[#](#numpy-random-generator-uniform)
method

random.Generator.uniform(*low=0.0*,*high=1.0*,*size=None*)[#](#numpy.random.Generator.uniform)
-
Draw samples from a uniform distribution.

Samples are uniformly distributed over the half-open interval

`[low, high)`
(includes low, but excludes high). In other words, any value within the given interval is equally likely to be drawn by.`uniform`
Parameters:
-
**low**float or array_like of floats, optional
Lower boundary of the output interval. All values generated will be greater than or equal to low. The default value is 0.

**high**float or array_like of floats
Upper boundary of the output interval. All values generated will be less than high. The high limit may be included in the returned array of floats due to floating-point rounding in the equation

`low + (high-low) * random_sample()`
. high - low must be non-negative. The default value is 1.0.
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`low`
and`high`
are both scalars. Otherwise,`np.broadcast(low, high).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized uniform distribution.

See also

Notes

The probability density function of the uniform distribution is

\[p(x) = \frac{1}{b - a}\]anywhere within the interval

`[a, b)`
, and zero elsewhere.When

`high`
==`low`
, values of`low`
will be returned.Examples

Draw samples from the distribution:

>>> s = np.random.default_rng().uniform(-1,0,1000)
All values are within the given interval:

>>> np.all(s >= -1) True >>> np.all(s < 0) True
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 15, density=True) >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color='r') >>> plt.show()# numpy.array_split[#](#numpy-array-split)
numpy.array_split(*ary*,*indices_or_sections*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L731-L784)[#](#numpy.array_split)
-
Split an array into multiple sub-arrays.

Please refer to the

`split`
documentation. The only difference between these functions is that`array_split`
allows*indices_or_sections*to be an integer that does*not*equally divide the axis. For an array of length l that should be split into n sections, it returns l % n sub-arrays of size l//n + 1 and the rest of size l//n.See also

`split`
Split array into multiple sub-arrays of equal size.

Examples

>>> x = np.arange(8.0) >>> np.array_split(x, 3) [array([0., 1., 2.]), array([3., 4., 5.]), array([6., 7.])]
>>> x = np.arange(9) >>> np.array_split(x, 4) [array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]# numpy.ma.masked_array.min[#](#numpy-ma-masked-array-min)
method

ma.masked_array.min(*axis=None*,*out=None*,*fill_value=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5760-L5857)[#](#numpy.ma.masked_array.min)
-
Return the minimum along a given axis.

Parameters:
-
**axis**None or int or tuple of ints, optional
Axis along which to operate. By default,

`axis`
is None and the flattened input is used. .. versionadded:: 1.7.0 If this is a tuple of ints, the minimum is selected over multiple axes, instead of a single axis or all the axes as before.
**out**array_like, optional
Alternative output array in which to place the result. Must be of the same shape and buffer length as the expected output.

**fill_value**scalar or None, optional
Value used to fill in the masked values. If None, use the output of

*minimum_fill_value*.
**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.

Returns:
-
**amin**array_like
New array holding the result. If

`out`
was specified,`out`
is returned.
See also

`ma.minimum_fill_value`
Returns the minimum filling value for a given datatype.

Examples

>>> import numpy.ma as ma >>> x = [[1., -2., 3.], [0.2, -0.7, 0.1]] >>> mask = [[1, 1, 0], [0, 0, 1]] >>> masked_x = ma.masked_array(x, mask) >>> masked_x masked_array( data=[[--, --, 3.0], [0.2, -0.7, --]], mask=[[ True, True, False], [False, False, True]], fill_value=1e+20) >>> ma.min(masked_x) -0.7 >>> ma.min(masked_x, axis=-1) masked_array(data=[3.0, -0.7], mask=[False, False], fill_value=1e+20) >>> ma.min(masked_x, axis=0, keepdims=True) masked_array(data=[[0.2, -0.7, 3.0]], mask=[[False, False, False]], fill_value=1e+20) >>> mask = [[1, 1, 1,], [1, 1, 1]] >>> masked_x = ma.masked_array(x, mask) >>> ma.min(masked_x, axis=0) masked_array(data=[--, --, --], mask=[ True, True, True], fill_value=1e+20, dtype=float64)# numpy.polynomial.hermite.hermfromroots[#](#numpy-polynomial-hermite-hermfromroots)
polynomial.hermite.hermfromroots(*roots*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L257-L310)[#](#numpy.polynomial.hermite.hermfromroots)
-
Generate a Hermite series with given roots.

The function returns the coefficients of the polynomial

\[p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),\]in Hermite form, where the

*r_n*are the roots specified in. If a zero has multiplicity n, then it must appear in`roots`
n times. For instance, if 2 is a root of multiplicity three and 3 is a root of multiplicity 2, then`roots`
looks something like [2, 2, 2, 3, 3]. The roots can appear in any order.`roots`
If the returned coefficients are

*c*, then\[p(x) = c_0 + c_1 * H_1(x) + ... + c_n * H_n(x)\]The coefficient of the last term is not generally 1 for monic polynomials in Hermite form.

Parameters:
-
**roots**array_like
Sequence containing the roots.

Returns:
-
**out**ndarray
1-D array of coefficients. If all roots are real then

*out*is a real array, if some of the roots are complex, then*out*is complex even if all the coefficients in the result are real (see Examples below).
See also

Examples

>>> from numpy.polynomial.hermite import hermfromroots, hermval >>> coef = hermfromroots((-1, 0, 1)) >>> hermval((-1, 0, 1), coef) array([0., 0., 0.]) >>> coef = hermfromroots((-1j, 1j)) >>> hermval((-1j, 1j), coef) array([0.+0.j, 0.+0.j])# numpy.ma.var[#](#numpy-ma-var)
ma.var(*self*,*axis=None*,*dtype=None*,*out=None*,*ddof=0*,*keepdims=<no value>*)*= <numpy.ma.core._frommethod object>*[#](#numpy.ma.var)
-
Compute the variance along the specified axis.

Returns the variance of the array elements, a measure of the spread of a distribution. The variance is computed for the flattened array by default, otherwise over the specified axis.

Parameters:
-
**a**array_like
Array containing numbers whose variance is desired. If

*a*is not an array, a conversion is attempted.
**axis**None or int or tuple of ints, optional
Axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.

New in version 1.7.0.

If this is a tuple of ints, a variance is performed over multiple axes, instead of a single axis or all the axes as before.

**dtype**data-type, optional
Type to use in computing the variance. For arrays of integer type the default is

; for arrays of float types it is the same as the array type.`float64`
**out**ndarray, optional
Alternate output array in which to place the result. It must have the same shape as the expected output, but the type is cast if necessary.

**ddof**int, optional
“Delta Degrees of Freedom”: the divisor used in the calculation is

`N - ddof`
, where`N`
represents the number of elements. By default*ddof*is zero.
**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.

If the default value is passed, then

*keepdims*will not be passed through to themethod of sub-classes of`var`
, however any non-default value will be. If the sub-class’ method does not implement`ndarray`
*keepdims*any exceptions will be raised.
**where**array_like of bool, optional
Elements to include in the variance. See

for details.`reduce`
New in version 1.20.0.

Returns:
-
**variance**ndarray, see dtype parameter above
If

`out=None`
, returns a new array containing the variance; otherwise, a reference to the output array is returned.
Notes

The variance is the average of the squared deviations from the mean, i.e.,

`var = mean(x)`
, where`x = abs(a - a.mean())**2`
.The mean is typically calculated as

`x.sum() / N`
, where`N = len(x)`
. If, however,*ddof*is specified, the divisor`N - ddof`
is used instead. In standard statistical practice,`ddof=1`
provides an unbiased estimator of the variance of a hypothetical infinite population.`ddof=0`
provides a maximum likelihood estimate of the variance for normally distributed variables.Note that for complex numbers, the absolute value is taken before squaring, so that the result is always real and nonnegative.

For floating-point input, the variance is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for

(see example below). Specifying a higher-accuracy accumulator using the`float32`
`dtype`
keyword can alleviate this issue.Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> np.var(a) 1.25 >>> np.var(a, axis=0) array([1., 1.]) >>> np.var(a, axis=1) array([0.25, 0.25])
In single precision, var() can be inaccurate:

>>> a = np.zeros((2, 512*512), dtype=np.float32) >>> a[0, :] = 1.0 >>> a[1, :] = 0.1 >>> np.var(a) 0.20250003
Computing the variance in float64 is more accurate:

>>> np.var(a, dtype=np.float64) 0.20249999932944759 # may vary >>> ((1-0.55)**2 + (0.1-0.55)**2)/2 0.2025
Specifying a where argument:

>>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]]) >>> np.var(a) 6.833333333333333 # may vary >>> np.var(a, where=[[True], [True], [False]]) 4.0# numpy.random.Generator.binomial[#](#numpy-random-generator-binomial)
method

random.Generator.binomial(*n*,*p*,*size=None*)[#](#numpy.random.Generator.binomial)
-
Draw samples from a binomial distribution.

Samples are drawn from a binomial distribution with specified parameters, n trials and p probability of success where n an integer >= 0 and p is in the interval [0,1]. (n may be input as a float, but it is truncated to an integer in use)

Parameters:
-
**n**int or array_like of ints
Parameter of the distribution, >= 0. Floats are also accepted, but they will be truncated to integers.

**p**float or array_like of floats
Parameter of the distribution, >= 0 and <=1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`n`
and`p`
are both scalars. Otherwise,`np.broadcast(n, p).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized binomial distribution, where each sample is equal to the number of successes over the n trials.

See also

`scipy.stats.binom`
probability density function, distribution or cumulative density function, etc.

Notes

The probability density for the binomial distribution is

\[P(N) = \binom{n}{N}p^N(1-p)^{n-N},\]where \(n\) is the number of trials, \(p\) is the probability of success, and \(N\) is the number of successes.

When estimating the standard error of a proportion in a population by using a random sample, the normal distribution works well unless the product p*n <=5, where p = population proportion estimate, and n = number of samples, in which case the binomial distribution is used instead. For example, a sample of 15 people shows 4 who are left handed, and 11 who are right handed. Then p = 4/15 = 27%. 0.27*15 = 4, so the binomial distribution should be used in this case.

References

[1]Dalgaard, Peter, “Introductory Statistics with R”, Springer-Verlag, 2002.

[2]Glantz, Stanton A. “Primer of Biostatistics.”, McGraw-Hill, Fifth Edition, 2002.

[3]Lentner, Marvin, “Elementary Applied Statistics”, Bogden and Quigley, 1972.

[4]Weisstein, Eric W. “Binomial Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/BinomialDistribution.html](http://mathworld.wolfram.com/BinomialDistribution.html)[5]Wikipedia, “Binomial distribution”,

[https://en.wikipedia.org/wiki/Binomial_distribution](https://en.wikipedia.org/wiki/Binomial_distribution)Examples

Draw samples from the distribution:

>>> rng = np.random.default_rng() >>> n, p = 10, .5 # number of trials, probability of each trial >>> s = rng.binomial(n, p, 1000) # result of flipping a coin 10 times, tested 1000 times.
A real world example. A company drills 9 wild-cat oil exploration wells, each with an estimated probability of success of 0.1. All nine wells fail. What is the probability of that happening?

Let’s do 20,000 trials of the model, and count the number that generate zero positive results.

>>> sum(rng.binomial(9, 0.1, 20000) == 0)/20000. # answer = 0.38885, or 39%.# numpy.ma.masked_array.getfield[#](#numpy-ma-masked-array-getfield)
method

ma.masked_array.getfield(*dtype*,*offset=0*)[#](#numpy.ma.masked_array.getfield)
-
Returns a field of the given array as a certain type.

A field is a view of the array data with a given data-type. The values in the view are determined by the given type and the offset into the current array in bytes. The offset needs to be such that the view dtype fits in the array dtype; for example an array of dtype complex128 has 16-byte elements. If taking a view with a 32-bit integer (4 bytes), the offset needs to be between 0 and 12 bytes.

Parameters:
-
**dtype**str or dtype
The data type of the view. The dtype size of the view can not be larger than that of the array itself.

**offset**int
Number of bytes to skip before beginning the element view.

Examples

>>> x = np.diag([1.+1.j]*2) >>> x[1, 1] = 2 + 4.j >>> x array([[1.+1.j, 0.+0.j], [0.+0.j, 2.+4.j]]) >>> x.getfield(np.float64) array([[1., 0.], [0., 2.]])
By choosing an offset of 8 bytes we can select the complex part of the array for our view:

>>> x.getfield(np.float64, offset=8) array([[1., 0.], [0., 4.]])# numpy.random.standard_gamma[#](#numpy-random-standard-gamma)
random.standard_gamma(*shape*,*size=None*)[#](#numpy.random.standard_gamma)
-
Draw samples from a standard Gamma distribution.

Samples are drawn from a Gamma distribution with specified parameters, shape (sometimes designated “k”) and scale=1.

Note

New code should use the

method of a`standard_gamma`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**shape**float or array_like of floats
Parameter, must be non-negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`shape`
is a scalar. Otherwise,`np.array(shape).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized standard gamma distribution.

See also

`scipy.stats.gamma`
probability density function, distribution or cumulative density function, etc.

`random.Generator.standard_gamma`
which should be used for new code.

Notes

The probability density for the Gamma distribution is

\[p(x) = x^{k-1}\frac{e^{-x/\theta}}{\theta^k\Gamma(k)},\]where \(k\) is the shape and \(\theta\) the scale, and \(\Gamma\) is the Gamma function.

The Gamma distribution is often used to model the times to failure of electronic components, and arises naturally in processes for which the waiting times between Poisson distributed events are relevant.

References

[1]Weisstein, Eric W. “Gamma Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/GammaDistribution.html](http://mathworld.wolfram.com/GammaDistribution.html)[2]Wikipedia, “Gamma distribution”,

[https://en.wikipedia.org/wiki/Gamma_distribution](https://en.wikipedia.org/wiki/Gamma_distribution)Examples

Draw samples from the distribution:

>>> shape, scale = 2., 1. # mean and width >>> s = np.random.standard_gamma(shape, 1000000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> import scipy.special as sps >>> count, bins, ignored = plt.hist(s, 50, density=True) >>> y = bins**(shape-1) * ((np.exp(-bins/scale))/ ... (sps.gamma(shape) * scale**shape)) >>> plt.plot(bins, y, linewidth=2, color='r') >>> plt.show()# numpy.save[#](#numpy-save)
numpy.save(*file*,*arr*,*allow_pickle=True*,*fix_imports=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/npyio.py#L475-L547)[#](#numpy.save)
-
Save an array to a binary file in NumPy

`.npy`
format.Parameters:
-
**file**file, str, or pathlib.Path
File or filename to which the data is saved. If file is a file-object, then the filename is unchanged. If file is a string or Path, a

`.npy`
extension will be appended to the filename if it does not already have one.
**arr**array_like
Array data to be saved.

**allow_pickle**bool, optional
Allow saving object arrays using Python pickles. Reasons for disallowing pickles include security (loading pickled data can execute arbitrary code) and portability (pickled objects may not be loadable on different Python installations, for example if the stored objects require libraries that are not available, and not all pickled data is compatible between Python 2 and Python 3). Default: True

**fix_imports**bool, optional
Only useful in forcing objects in object arrays on Python 3 to be pickled in a Python 2 compatible way. If

*fix_imports*is True, pickle will try to map the new Python 3 names to the old module names used in Python 2, so that the pickle data stream is readable with Python 2.
Notes

For a description of the

`.npy`
format, see.`numpy.lib.format`
Any data saved to the file is appended to the end of the file.

Examples

>>> from tempfile import TemporaryFile >>> outfile = TemporaryFile()
>>> x = np.arange(10) >>> np.save(outfile, x)
>>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file >>> np.load(outfile) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> with open('test.npy', 'wb') as f: ... np.save(f, np.array([1, 2])) ... np.save(f, np.array([1, 3])) >>> with open('test.npy', 'rb') as f: ... a = np.load(f) ... b = np.load(f) >>> print(a, b) # [1 2] [1 3]# numpy.invert[#](#numpy-invert)
numpy.invert(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'invert'>*[#](#numpy.invert)
-
Compute bit-wise inversion, or bit-wise NOT, element-wise.

Computes the bit-wise NOT of the underlying binary representation of the integers in the input arrays. This ufunc implements the C/Python operator

`~`
.For signed integer inputs, the two’s complement is returned. In a two’s-complement system negative numbers are represented by the two’s complement of the absolute value. This is the most common method of representing signed integers on computers

[[1]](#rde927b304c4f-1). A N-bit two’s-complement system can represent every integer in the range \(-2^{N-1}\) to \(+2^{N-1}-1\).Parameters:
-
**x**array_like
Only integer and boolean types are handled.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray or scalar
Result. This is a scalar if

*x*is a scalar.
See also

,`bitwise_and`
,`bitwise_or`
`bitwise_xor`
`logical_not`
`binary_repr`
Return the binary representation of the input number as a string.

Notes

`bitwise_not`
is an alias for:`invert`
>>> np.bitwise_not is np.invert True
References

[[1](#id1)]Wikipedia, “Two’s complement”,

[https://en.wikipedia.org/wiki/Two’s_complement](https://en.wikipedia.org/wiki/Two's_complement)Examples

We’ve seen that 13 is represented by

`00001101`
. The invert or bit-wise NOT of 13 is then:>>> x = np.invert(np.array(13, dtype=np.uint8)) >>> x 242 >>> np.binary_repr(x, width=8) '11110010'
The result depends on the bit-width:

>>> x = np.invert(np.array(13, dtype=np.uint16)) >>> x 65522 >>> np.binary_repr(x, width=16) '1111111111110010'
When using signed integer types the result is the two’s complement of the result for the unsigned type:

>>> np.invert(np.array([13], dtype=np.int8)) array([-14], dtype=int8) >>> np.binary_repr(-14, width=8) '11110010'
Booleans are accepted as well:

>>> np.invert(np.array([True, False])) array([False, True])
The

`~`
operator can be used as a shorthand for`np.invert`
on ndarrays.>>> x1 = np.array([True, False]) >>> ~x1 array([False, True])# numpy.subtract[#](#numpy-subtract)
numpy.subtract(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'subtract'>*[#](#numpy.subtract)
-
Subtract arguments, element-wise.

Parameters:
-
**x1, x2**array_like
The arrays to be subtracted from each other. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray
The difference of

*x1*and*x2*, element-wise. This is a scalar if both*x1*and*x2*are scalars.
Notes

Equivalent to

`x1 - x2`
in terms of array broadcasting.Examples

>>> np.subtract(1.0, 4.0) -3.0
>>> x1 = np.arange(9.0).reshape((3, 3)) >>> x2 = np.arange(3.0) >>> np.subtract(x1, x2) array([[ 0., 0., 0.], [ 3., 3., 3.], [ 6., 6., 6.]])
The

`-`
operator can be used as a shorthand for`np.subtract`
on ndarrays.>>> x1 = np.arange(9.0).reshape((3, 3)) >>> x2 = np.arange(3.0) >>> x1 - x2 array([[0., 0., 0.], [3., 3., 3.], [6., 6., 6.]])# numpy.ma.masked_array.put[#](#numpy-ma-masked-array-put)
method

ma.masked_array.put(*indices*,*values*,*mode='raise'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4770-L4853)[#](#numpy.ma.masked_array.put)
-
Set storage-indexed locations to corresponding values.

Sets self._data.flat[n] = values[n] for each n in indices. If

*values*is shorter thanthen it will repeat. If`indices`
*values*has some masked values, the initial mask is updated in consequence, else the corresponding values are unmasked.Parameters:
-
**indices**1-D array_like
Target indices, interpreted as integers.

**values**array_like
Values to place in self._data copy at target indices.

**mode**{‘raise’, ‘wrap’, ‘clip’}, optional
Specifies how out-of-bounds indices will behave. ‘raise’ : raise an error. ‘wrap’ : wrap around. ‘clip’ : clip to the range.

Notes

*values*can be a scalar or length 1 array.Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.put([0,4,8],[10,20,30]) >>> x masked_array( data=[[10, --, 3], [--, 20, --], [7, --, 30]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999)
>>> x.put(4,999) >>> x masked_array( data=[[10, --, 3], [--, 999, --], [7, --, 30]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999)# numpy.random.Generator.weibull[#](#numpy-random-generator-weibull)
method

random.Generator.weibull(*a*,*size=None*)[#](#numpy.random.Generator.weibull)
-
Draw samples from a Weibull distribution.

Draw samples from a 1-parameter Weibull distribution with the given shape parameter

*a*.\[X = (-ln(U))^{1/a}\]Here, U is drawn from the uniform distribution over (0,1].

The more common 2-parameter Weibull, including a scale parameter \(\lambda\) is just \(X = \lambda(-ln(U))^{1/a}\).

Parameters:
-
**a**float or array_like of floats
Shape parameter of the distribution. Must be nonnegative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`a`
is a scalar. Otherwise,`np.array(a).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Weibull distribution.

Notes

The Weibull (or Type III asymptotic extreme value distribution for smallest values, SEV Type III, or Rosin-Rammler distribution) is one of a class of Generalized Extreme Value (GEV) distributions used in modeling extreme value problems. This class includes the Gumbel and Frechet distributions.

The probability density for the Weibull distribution is

\[p(x) = \frac{a} {\lambda}(\frac{x}{\lambda})^{a-1}e^{-(x/\lambda)^a},\]where \(a\) is the shape and \(\lambda\) the scale.

The function has its peak (the mode) at \(\lambda(\frac{a-1}{a})^{1/a}\).

When

`a = 1`
, the Weibull distribution reduces to the exponential distribution.References

[1]Waloddi Weibull, Royal Technical University, Stockholm, 1939 “A Statistical Theory Of The Strength Of Materials”, Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939, Generalstabens Litografiska Anstalts Forlag, Stockholm.

[2]Waloddi Weibull, “A Statistical Distribution Function of Wide Applicability”, Journal Of Applied Mechanics ASME Paper 1951.

[3]Wikipedia, “Weibull distribution”,

[https://en.wikipedia.org/wiki/Weibull_distribution](https://en.wikipedia.org/wiki/Weibull_distribution)Examples

Draw samples from the distribution:

>>> rng = np.random.default_rng() >>> a = 5. # shape >>> s = rng.weibull(a, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> x = np.arange(1,100.)/50. >>> def weib(x,n,a): ... return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)
>>> count, bins, ignored = plt.hist(rng.weibull(5.,1000)) >>> x = np.arange(1,100.)/50. >>> scale = count.max()/weib(x, 1., 5.).max() >>> plt.plot(x, weib(x, 1., 5.)*scale) >>> plt.show()# numpy.polynomial.laguerre.lagvander[#](#numpy-polynomial-laguerre-lagvander)
polynomial.laguerre.lagvander(*x*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L1105-L1162)[#](#numpy.polynomial.laguerre.lagvander)
-
Pseudo-Vandermonde matrix of given degree.

Returns the pseudo-Vandermonde matrix of degree

*deg*and sample points*x*. The pseudo-Vandermonde matrix is defined by\[V[..., i] = L_i(x)\]where

*0 <= i <= deg*. The leading indices of*V*index the elements of*x*and the last index is the degree of the Laguerre polynomial.If

*c*is a 1-D array of coefficients of length*n + 1*and*V*is the array`V = lagvander(x, n)`
, then`np.dot(V, c)`
and`lagval(x, c)`
are the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of Laguerre series of the same degree and sample points.Parameters:
-
**x**array_like
Array of points. The dtype is converted to float64 or complex128 depending on whether any of the elements are complex. If

*x*is scalar it is converted to a 1-D array.
**deg**int
Degree of the resulting matrix.

Returns:
-
**vander**ndarray
The pseudo-Vandermonde matrix. The shape of the returned matrix is

`x.shape + (deg + 1,)`
, where The last index is the degree of the corresponding Laguerre polynomial. The dtype will be the same as the converted*x*.
Examples

>>> from numpy.polynomial.laguerre import lagvander >>> x = np.array([0, 1, 2]) >>> lagvander(x, 3) array([[ 1. , 1. , 1. , 1. ], [ 1. , 0. , -0.5 , -0.66666667], [ 1. , -1. , -1. , -0.33333333]])# numpy.polynomial.polynomial.polyval3d[#](#numpy-polynomial-polynomial-polyval3d)
polynomial.polynomial.polyval3d(*x*,*y*,*z*,*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L951-L999)[#](#numpy.polynomial.polynomial.polyval3d)
-
Evaluate a 3-D polynomial at points (x, y, z).

This function returns the values:

\[p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * x^i * y^j * z^k\]The parameters

*x*,*y*, and*z*are converted to arrays only if they are tuples or a lists, otherwise they are treated as a scalars and they must have the same shape after conversion. In either case, either*x*,*y*, and*z*or their elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*has fewer than 3 dimensions, ones are implicitly appended to its shape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape.Parameters:
-
**x, y, z**array_like, compatible object
The three dimensional series is evaluated at the points

*(x, y, z)*, where*x*,*y*, and*z*must have the same shape. If any of*x*,*y*, or*z*is a list or tuple, it is first converted to an ndarray, otherwise it is left unchanged and if it isn’t an ndarray it is treated as a scalar.
**c**array_like
Array of coefficients ordered so that the coefficient of the term of multi-degree i,j,k is contained in

`c[i,j,k]`
. If*c*has dimension greater than 3 the remaining indices enumerate multiple sets of coefficients.
Returns:
-
**values**ndarray, compatible object
The values of the multidimensional polynomial on points formed with triples of corresponding values from

*x*,*y*, and*z*.
See also

Notes

New in version 1.7.0.# numpy.cosh[#](#numpy-cosh)
numpy.cosh(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'cosh'>*[#](#numpy.cosh)
-
Hyperbolic cosine, element-wise.

Equivalent to

`1/2 * (np.exp(x) + np.exp(-x))`
and`np.cos(1j*x)`
.Parameters:
-
**x**array_like
Input array.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray or scalar
Output array of same shape as

*x*. This is a scalar if*x*is a scalar.
Examples

>>> np.cosh(0) 1.0
The hyperbolic cosine describes the shape of a hanging cable:

>>> import matplotlib.pyplot as plt >>> x = np.linspace(-4, 4, 1000) >>> plt.plot(x, np.cosh(x)) >>> plt.show()# numpy.fft.ihfft[#](#numpy-fft-ihfft)
fft.ihfft(*a*,*n=None*,*axis=-1*,*norm=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/fft/_pocketfft.py#L615-L679)[#](#numpy.fft.ihfft)
-
Compute the inverse FFT of a signal that has Hermitian symmetry.

Parameters:
-
**a**array_like
Input array.

**n**int, optional
Length of the inverse FFT, the number of points along transformation axis in the input to use. If

*n*is smaller than the length of the input, the input is cropped. If it is larger, the input is padded with zeros. If*n*is not given, the length of the input along the axis specified by*axis*is used.
**axis**int, optional
Axis over which to compute the inverse FFT. If not given, the last axis is used.

**norm**{“backward”, “ortho”, “forward”}, optional
New in version 1.10.0.

Normalization mode (see

). Default is “backward”. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.`numpy.fft`
New in version 1.20.0: The “backward”, “forward” values were added.

Returns:
-
**out**complex ndarray
The truncated or zero-padded input, transformed along the axis indicated by

*axis*, or the last one if*axis*is not specified. The length of the transformed axis is`n//2 + 1`
.
Notes

/`hfft`
are a pair analogous to`ihfft`
/`rfft`
, but for the opposite case: here the signal has Hermitian symmetry in the time domain and is real in the frequency domain. So here it’s`irfft`
for which you must supply the length of the result if it is to be odd:`hfft`
even:

`ihfft(hfft(a, 2*len(a) - 2)) == a`
, within roundoff error,
odd:

`ihfft(hfft(a, 2*len(a) - 1)) == a`
, within roundoff error.
Examples

>>> spectrum = np.array([ 15, -4, 0, -1, 0, -4]) >>> np.fft.ifft(spectrum) array([1.+0.j, 2.+0.j, 3.+0.j, 4.+0.j, 3.+0.j, 2.+0.j]) # may vary >>> np.fft.ihfft(spectrum) array([ 1.-0.j, 2.-0.j, 3.-0.j, 4.-0.j]) # may vary# numpy.ma.MaskedArray.astype[#](#numpy-ma-maskedarray-astype)
method

ma.MaskedArray.astype(*dtype*,*order='K'*,*casting='unsafe'*,*subok=True*,*copy=True*)[#](#numpy.ma.MaskedArray.astype)
-
Copy of the array, cast to a specified type.

Parameters:
-
**dtype**str or dtype
Typecode or data-type to which the array is cast.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout order of the result. ‘C’ means C order, ‘F’ means Fortran order, ‘A’ means ‘F’ order if all the arrays are Fortran contiguous, ‘C’ order otherwise, and ‘K’ means as close to the order the array elements appear in memory as possible. Default is ‘K’.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘unsafe’ for backwards compatibility.

‘no’ means the data types should not be cast at all.

‘equiv’ means only byte-order changes are allowed.

‘safe’ means only casts which can preserve values are allowed.

‘same_kind’ means only safe casts or casts within a kind, like float64 to float32, are allowed.

‘unsafe’ means any data conversions may be done.

**subok**bool, optional
If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.

**copy**bool, optional
By default, astype always returns a newly allocated array. If this is set to false, and the

,`dtype`
*order*, and*subok*requirements are satisfied, the input array is returned instead of a copy.
Returns:
-
Raises:
-
ComplexWarning
-
When casting from complex to float or int. To avoid this, one should use

`a.real.astype(t)`
.
Notes

Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for “unsafe” casting. Casting to multiple fields is allowed, but casting from multiple fields is not.

Changed in version 1.9.0: Casting from numeric to string types in ‘safe’ casting mode requires that the string dtype length is long enough to store the max integer/float value converted.

Examples

>>> x = np.array([1, 2, 2.5]) >>> x array([1. , 2. , 2.5])
>>> x.astype(int) array([1, 2, 2])# numpy.ma.MaskedArray.sort[#](#numpy-ma-maskedarray-sort)
method

ma.MaskedArray.sort(*axis=-1*,*kind=None*,*order=None*,*endwith=True*,*fill_value=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5677-L5758)[#](#numpy.ma.MaskedArray.sort)
-
Sort the array, in-place

Parameters:
-
**a**array_like
Array to be sorted.

**axis**int, optional
Axis along which to sort. If None, the array is flattened before sorting. The default is -1, which sorts along the last axis.

**kind**{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, optional
The sorting algorithm used.

**order**list, optional
When

*a*is a structured array, this argument specifies which fields to compare first, second, and so on. This list does not need to include all of the fields.
**endwith**{True, False}, optional
Whether missing values (if any) should be treated as the largest values (True) or the smallest values (False) When the array contains unmasked values sorting at the same extremes of the datatype, the ordering of these values and the masked values is undefined.

**fill_value**scalar or None, optional
Value used internally for the masked values. If

`fill_value`
is not None, it supersedes`endwith`
.
Returns:
-
**sorted_array**ndarray
Array of the same type and shape as

*a*.
See also

`numpy.ndarray.sort`
Method to sort an array in-place.

`argsort`
Indirect sort.

`lexsort`
Indirect stable sort on multiple keys.

`searchsorted`
Find elements in a sorted array.

Notes

See

`sort`
for notes on the different sorting algorithms.Examples

>>> a = np.ma.array([1, 2, 5, 4, 3],mask=[0, 1, 0, 1, 0]) >>> # Default >>> a.sort() >>> a masked_array(data=[1, 3, 5, --, --], mask=[False, False, False, True, True], fill_value=999999)
>>> a = np.ma.array([1, 2, 5, 4, 3],mask=[0, 1, 0, 1, 0]) >>> # Put missing values in the front >>> a.sort(endwith=False) >>> a masked_array(data=[--, --, 1, 3, 5], mask=[ True, True, False, False, False], fill_value=999999)
>>> a = np.ma.array([1, 2, 5, 4, 3],mask=[0, 1, 0, 1, 0]) >>> # fill_value takes over endwith >>> a.sort(endwith=False, fill_value=3) >>> a masked_array(data=[1, --, --, 3, 5], mask=[False, True, True, False, False], fill_value=999999)# numpy.atleast_3d[#](#numpy-atleast-3d)
numpy.atleast_3d(**arys*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/shape_base.py#L139-L204)[#](#numpy.atleast_3d)
-
View inputs as arrays with at least three dimensions.

Parameters:
-
**arys1, arys2, …**array_like
One or more array-like sequences. Non-array inputs are converted to arrays. Arrays that already have three or more dimensions are preserved.

Returns:
-
**res1, res2, …**ndarray
An array, or list of arrays, each with

`a.ndim >= 3`
. Copies are avoided where possible, and views with three or more dimensions are returned. For example, a 1-D array of shape`(N,)`
becomes a view of shape`(1, N, 1)`
, and a 2-D array of shape`(M, N)`
becomes a view of shape`(M, N, 1)`
.
See also

Examples

>>> np.atleast_3d(3.0) array([[[3.]]])
>>> x = np.arange(3.0) >>> np.atleast_3d(x).shape (1, 3, 1)
>>> x = np.arange(12.0).reshape(4,3) >>> np.atleast_3d(x).shape (4, 3, 1) >>> np.atleast_3d(x).base is x.base # x is a reshape, so not base itself True
>>> for arr in np.atleast_3d([1, 2], [[1, 2]], [[[1, 2]]]): ... print(arr, arr.shape) ... [[[1] [2]]] (1, 2, 1) [[[1] [2]]] (1, 2, 1) [[[1 2]]] (1, 1, 2)# numpy.memmap.tofile[#](#numpy-memmap-tofile)
method

memmap.tofile(*fid*,*sep=''*,*format='%s'*)[#](#numpy.memmap.tofile)
-
Write array to a file as text or binary (default).

Data is always written in ‘C’ order, independent of the order of

*a*. The data produced by this method can be recovered using the function fromfile().Parameters:
-
**fid**file or str or Path
An open file object, or a string containing a filename.

Changed in version 1.17.0:

objects are now accepted.`pathlib.Path`
**sep**str
Separator between array items for text output. If “” (empty), a binary file is written, equivalent to

`file.write(a.tobytes())`
.
**format**str
Format string for text file output. Each entry in the array is formatted to text by first converting it to the closest Python type, and then using “format” % item.

Notes

This is a convenience function for quick storage of array data. Information on endianness and precision is lost, so this method is not a good choice for files intended to archive data or transport data between machines with different endianness. Some of these problems can be overcome by outputting the data as text files, at the expense of speed and file size.

When fid is a file object, array contents are directly written to the file, bypassing the file object’s

`write`
method. As a result, tofile cannot be used with files objects supporting compression (e.g., GzipFile) or file-like objects that do not support`fileno()`
(e.g., BytesIO).# numpy.ndarray.resize[#](#numpy-ndarray-resize)
method

ndarray.resize(*new_shape*,*refcheck=True*)[#](#numpy.ndarray.resize)
-
Change shape and size of array in-place.

Parameters:
-
**new_shape**tuple of ints, or*n*ints
Shape of resized array.

**refcheck**bool, optional
If False, reference count will not be checked. Default is True.

Returns:
-
None
-
Raises:
-
ValueError
-
If

*a*does not own its own data or references or views to it exist, and the data memory must be changed. PyPy only: will always raise if the data memory must be changed, since there is no reliable way to determine if references or views to it exist.
SystemError
-
If the

*order*keyword argument is specified. This behaviour is a bug in NumPy.
See also

`resize`
Return a new array with the specified shape.

Notes

This reallocates space for the data area if necessary.

Only contiguous arrays (data elements consecutive in memory) can be resized.

The purpose of the reference count check is to make sure you do not use this array as a buffer for another Python object and then reallocate the memory. However, reference counts can increase in other ways so if you are sure that you have not shared the memory for this array with another Python object, then you may safely set

*refcheck*to False.Examples

Shrinking an array: array is flattened (in the order that the data are stored in memory), resized, and reshaped:

>>> a = np.array([[0, 1], [2, 3]], order='C') >>> a.resize((2, 1)) >>> a array([[0], [1]])
>>> a = np.array([[0, 1], [2, 3]], order='F') >>> a.resize((2, 1)) >>> a array([[0], [2]])
Enlarging an array: as above, but missing entries are filled with zeros:

>>> b = np.array([[0, 1], [2, 3]]) >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple >>> b array([[0, 1, 2], [3, 0, 0]])
Referencing an array prevents resizing…

>>> c = a >>> a.resize((1, 1)) Traceback (most recent call last): ... ValueError: cannot resize an array that references or is referenced ...
Unless

*refcheck*is False:>>> a.resize((1, 1), refcheck=False) >>> a array([[0]]) >>> c array([[0]])# numpy.histogram2d[#](#numpy-histogram2d)
numpy.histogram2d(*x*,*y*,*bins=10*,*range=None*,*density=None*,*weights=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/twodim_base.py#L643-L809)[#](#numpy.histogram2d)
-
Compute the bi-dimensional histogram of two data samples.

Parameters:
-
**x**array_like, shape (N,)
An array containing the x coordinates of the points to be histogrammed.

**y**array_like, shape (N,)
An array containing the y coordinates of the points to be histogrammed.

**bins**int or array_like or [int, int] or [array, array], optional
The bin specification:

If int, the number of bins for the two dimensions (nx=ny=bins).

If array_like, the bin edges for the two dimensions (x_edges=y_edges=bins).

If [int, int], the number of bins in each dimension (nx, ny = bins).

If [array, array], the bin edges in each dimension (x_edges, y_edges = bins).

A combination [int, array] or [array, int], where int is the number of bins and array is the bin edges.

**range**array_like, shape(2,2), optional
The leftmost and rightmost edges of the bins along each dimension (if not specified explicitly in the

*bins*parameters):`[[xmin, xmax], [ymin, ymax]]`
. All values outside of this range will be considered outliers and not tallied in the histogram.
**density**bool, optional
If False, the default, returns the number of samples in each bin. If True, returns the probability

*density*function at the bin,`bin_count / sample_count / bin_area`
.
**weights**array_like, shape(N,), optional
An array of values

`w_i`
weighing each sample`(x_i, y_i)`
. Weights are normalized to 1 if*density*is True. If*density*is False, the values of the returned histogram are equal to the sum of the weights belonging to the samples falling into each bin.
Returns:
-
**H**ndarray, shape(nx, ny)
The bi-dimensional histogram of samples

*x*and*y*. Values in*x*are histogrammed along the first dimension and values in*y*are histogrammed along the second dimension.
**xedges**ndarray, shape(nx+1,)
The bin edges along the first dimension.

**yedges**ndarray, shape(ny+1,)
The bin edges along the second dimension.

See also

`histogram`
1D histogram

`histogramdd`
Multidimensional histogram

Notes

When

*density*is True, then the returned histogram is the sample density, defined such that the sum over bins of the product`bin_value * bin_area`
is 1.Please note that the histogram does not follow the Cartesian convention where

*x*values are on the abscissa and*y*values on the ordinate axis. Rather,*x*is histogrammed along the first dimension of the array (vertical), and*y*along the second dimension of the array (horizontal). This ensures compatibility with.`histogramdd`
Examples

>>> from matplotlib.image import NonUniformImage >>> import matplotlib.pyplot as plt
Construct a 2-D histogram with variable bin width. First define the bin edges:

>>> xedges = [0, 1, 3, 5] >>> yedges = [0, 2, 3, 4, 6]
Next we create a histogram H with random bin content:

>>> x = np.random.normal(2, 1, 100) >>> y = np.random.normal(1, 1, 100) >>> H, xedges, yedges = np.histogram2d(x, y, bins=(xedges, yedges)) >>> # Histogram does not follow Cartesian convention (see Notes), >>> # therefore transpose H for visualization purposes. >>> H = H.T
can only display square bins:`imshow`
>>> fig = plt.figure(figsize=(7, 3)) >>> ax = fig.add_subplot(131, title='imshow: square bins') >>> plt.imshow(H, interpolation='nearest', origin='lower', ... extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]]) <matplotlib.image.AxesImage object at 0x...>
can display actual edges:`pcolormesh`
>>> ax = fig.add_subplot(132, title='pcolormesh: actual edges', ... aspect='equal') >>> X, Y = np.meshgrid(xedges, yedges) >>> ax.pcolormesh(X, Y, H) <matplotlib.collections.QuadMesh object at 0x...>
can be used to display actual bin edges with interpolation:`NonUniformImage`
>>> ax = fig.add_subplot(133, title='NonUniformImage: interpolated', ... aspect='equal', xlim=xedges[[0, -1]], ylim=yedges[[0, -1]]) >>> im = NonUniformImage(ax, interpolation='bilinear') >>> xcenters = (xedges[:-1] + xedges[1:]) / 2 >>> ycenters = (yedges[:-1] + yedges[1:]) / 2 >>> im.set_data(xcenters, ycenters, H) >>> ax.add_image(im) >>> plt.show()
It is also possible to construct a 2-D histogram without specifying bin edges:

>>> # Generate non-symmetric test data >>> n = 10000 >>> x = np.linspace(1, 100, n) >>> y = 2*np.log(x) + np.random.rand(n) - 0.5 >>> # Compute 2d histogram. Note the order of x/y and xedges/yedges >>> H, yedges, xedges = np.histogram2d(y, x, bins=20)
Now we can plot the histogram using

, and a`pcolormesh`
for comparison.`hexbin`
>>> # Plot histogram using pcolormesh >>> fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True) >>> ax1.pcolormesh(xedges, yedges, H, cmap='rainbow') >>> ax1.plot(x, 2*np.log(x), 'k-') >>> ax1.set_xlim(x.min(), x.max()) >>> ax1.set_ylim(y.min(), y.max()) >>> ax1.set_xlabel('x') >>> ax1.set_ylabel('y') >>> ax1.set_title('histogram2d') >>> ax1.grid()
>>> # Create hexbin plot for comparison >>> ax2.hexbin(x, y, gridsize=20, cmap='rainbow') >>> ax2.plot(x, 2*np.log(x), 'k-') >>> ax2.set_title('hexbin') >>> ax2.set_xlim(x.min(), x.max()) >>> ax2.set_xlabel('x') >>> ax2.grid()
>>> plt.show()# numpy.polynomial.chebyshev.chebzero[#](#numpy-polynomial-chebyshev-chebzero)
polynomial.chebyshev.chebzero*= array([0])*[#](#numpy.polynomial.chebyshev.chebzero)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.recarray.byteswap[#](#numpy-recarray-byteswap)
method

recarray.byteswap(*inplace=False*)[#](#numpy.recarray.byteswap)
-
Swap the bytes of the array elements

Toggle between low-endian and big-endian data representation by returning a byteswapped array, optionally swapped in-place. Arrays of byte-strings are not swapped. The real and imaginary parts of a complex number are swapped individually.

Parameters:
-
**inplace**bool, optional
If

`True`
, swap bytes in-place, default is`False`
.
Returns:
-
**out**ndarray
The byteswapped array. If

*inplace*is`True`
, this is a view to self.
Examples

>>> A = np.array([1, 256, 8755], dtype=np.int16) >>> list(map(hex, A)) ['0x1', '0x100', '0x2233'] >>> A.byteswap(inplace=True) array([ 256, 1, 13090], dtype=int16) >>> list(map(hex, A)) ['0x100', '0x1', '0x3322']
Arrays of byte-strings are not swapped

>>> A = np.array([b'ceg', b'fac']) >>> A.byteswap() array([b'ceg', b'fac'], dtype='|S3')
`A.newbyteorder().byteswap()`
produces an array with the same values
but different representation in memory

>>> A = np.array([1, 2, 3]) >>> A.view(np.uint8) array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0], dtype=uint8) >>> A.newbyteorder().byteswap(inplace=True) array([1, 2, 3]) >>> A.view(np.uint8) array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3], dtype=uint8)# numpy.polynomial.chebyshev.chebroots[#](#numpy-polynomial-chebyshev-chebroots)
polynomial.chebyshev.chebroots(*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L1719-L1777)[#](#numpy.polynomial.chebyshev.chebroots)
-
Compute the roots of a Chebyshev series.

Return the roots (a.k.a. “zeros”) of the polynomial

\[p(x) = \sum_i c[i] * T_i(x).\]Parameters:
-
**c**1-D array_like
1-D array of coefficients.

Returns:
-
**out**ndarray
Array of the roots of the series. If all the roots are real, then

*out*is also real, otherwise it is complex.
See also

Notes

The root estimates are obtained as the eigenvalues of the companion matrix, Roots far from the origin of the complex plane may have large errors due to the numerical instability of the series for such values. Roots with multiplicity greater than 1 will also show larger errors as the value of the series near such points is relatively insensitive to errors in the roots. Isolated roots near the origin can be improved by a few iterations of Newton’s method.

The Chebyshev series basis polynomials aren’t powers of

*x*so the results of this function may seem unintuitive.Examples

>>> import numpy.polynomial.chebyshev as cheb >>> cheb.chebroots((-1, 1,-1, 1)) # T3 - T2 + T1 - T0 has real roots array([ -5.00000000e-01, 2.60860684e-17, 1.00000000e+00]) # may vary# numpy.polynomial.laguerre.laggauss[#](#numpy-polynomial-laguerre-laggauss)
polynomial.laguerre.laggauss(*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L1512-L1573)[#](#numpy.polynomial.laguerre.laggauss)
-
Gauss-Laguerre quadrature.

Computes the sample points and weights for Gauss-Laguerre quadrature. These sample points and weights will correctly integrate polynomials of degree \(2*deg - 1\) or less over the interval \([0, \inf]\) with the weight function \(f(x) = \exp(-x)\).

Parameters:
-
**deg**int
Number of sample points and weights. It must be >= 1.

Returns:
-
**x**ndarray
1-D ndarray containing the sample points.

**y**ndarray
1-D ndarray containing the weights.

Notes

New in version 1.7.0.

The results have only been tested up to degree 100 higher degrees may be problematic. The weights are determined by using the fact that

\[w_k = c / (L'_n(x_k) * L_{n-1}(x_k))\]where \(c\) is a constant independent of \(k\) and \(x_k\) is the k’th root of \(L_n\), and then scaling the results to get the right value when integrating 1.# numpy.binary_repr[#](#numpy-binary-repr)
numpy.binary_repr(*num*,*width=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L1936-L2048)[#](#numpy.binary_repr)
-
Return the binary representation of the input number as a string.

For negative numbers, if width is not given, a minus sign is added to the front. If width is given, the two’s complement of the number is returned, with respect to that width.

In a two’s-complement system negative numbers are represented by the two’s complement of the absolute value. This is the most common method of representing signed integers on computers

[[1]](#r962252997619-1). A N-bit two’s-complement system can represent every integer in the range \(-2^{N-1}\) to \(+2^{N-1}-1\).Parameters:
-
**num**int
Only an integer decimal number can be used.

**width**int, optional
The length of the returned string if

*num*is positive, or the length of the two’s complement if*num*is negative, provided that*width*is at least a sufficient number of bits for*num*to be represented in the designated form.If the

*width*value is insufficient, it will be ignored, and*num*will be returned in binary (*num*> 0) or two’s complement (*num*< 0) form with its width equal to the minimum number of bits needed to represent the number in the designated form. This behavior is deprecated and will later raise an error.Deprecated since version 1.12.0.

Returns:
-
**bin**str
Binary representation of

*num*or two’s complement of*num*.
See also

Notes

is equivalent to using`binary_repr`
with base 2, but about 25x faster.`base_repr`
References

[[1](#id1)]Wikipedia, “Two’s complement”,

[https://en.wikipedia.org/wiki/Two’s_complement](https://en.wikipedia.org/wiki/Two's_complement)Examples

>>> np.binary_repr(3) '11' >>> np.binary_repr(-3) '-11' >>> np.binary_repr(3, width=4) '0011'
The two’s complement is returned when the input number is negative and width is specified:

>>> np.binary_repr(-3, width=3) '101' >>> np.binary_repr(-3, width=5) '11101'# numpy.histogram_bin_edges[#](#numpy-histogram-bin-edges)
numpy.histogram_bin_edges(*a*,*bins=10*,*range=None*,*weights=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/histograms.py#L470-L670)[#](#numpy.histogram_bin_edges)
-
Function to calculate only the edges of the bins used by the

function.`histogram`
Parameters:
-
**a**array_like
Input data. The histogram is computed over the flattened array.

**bins**int or sequence of scalars or str, optional
If

*bins*is an int, it defines the number of equal-width bins in the given range (10, by default). If*bins*is a sequence, it defines the bin edges, including the rightmost edge, allowing for non-uniform bin widths.If

*bins*is a string from the list below,will use the method chosen to calculate the optimal bin width and consequently the number of bins (see`histogram_bin_edges`
*Notes*for more detail on the estimators) from the data that falls within the requested range. While the bin width will be optimal for the actual data in the range, the number of bins will be computed to fill the entire range, including the empty portions. For visualisation, using the ‘auto’ option is suggested. Weighted data is not supported for automated bin size selection.‘auto’
-
Maximum of the ‘sturges’ and ‘fd’ estimators. Provides good all around performance.

‘fd’ (Freedman Diaconis Estimator)
-
Robust (resilient to outliers) estimator that takes into account data variability and data size.

‘doane’
-
An improved version of Sturges’ estimator that works better with non-normal datasets.

‘scott’
-
Less robust estimator that takes into account data variability and data size.

‘stone’
-
Estimator based on leave-one-out cross-validation estimate of the integrated squared error. Can be regarded as a generalization of Scott’s rule.

‘rice’
-
Estimator does not take variability into account, only data size. Commonly overestimates number of bins required.

‘sturges’
-
R’s default method, only accounts for data size. Only optimal for gaussian data and underestimates number of bins for large non-gaussian datasets.

‘sqrt’
-
Square root (of data size) estimator, used by Excel and other programs for its speed and simplicity.

**range**(float, float), optional
The lower and upper range of the bins. If not provided, range is simply

`(a.min(), a.max())`
. Values outside the range are ignored. The first element of the range must be less than or equal to the second.*range*affects the automatic bin computation as well. While bin width is computed to be optimal based on the actual data within*range*, the bin count will fill the entire range including portions containing no data.
**weights**array_like, optional
An array of weights, of the same shape as

*a*. Each value in*a*only contributes its associated weight towards the bin count (instead of 1). This is currently not used by any of the bin estimators, but may be in the future.
Returns:
-
**bin_edges**array of dtype float
The edges to pass into

`histogram`
See also

Notes

The methods to estimate the optimal number of bins are well founded in literature, and are inspired by the choices R provides for histogram visualisation. Note that having the number of bins proportional to \(n^{1/3}\) is asymptotically optimal, which is why it appears in most estimators. These are simply plug-in methods that give good starting points for number of bins. In the equations below, \(h\) is the binwidth and \(n_h\) is the number of bins. All estimators that compute bin counts are recast to bin width using the

of the data. The final bin count is obtained from`ptp`
`np.round(np.ceil(range / h))`
. The final bin width is often less than what is returned by the estimators below.‘auto’ (maximum of the ‘sturges’ and ‘fd’ estimators)
-
A compromise to get a good value. For small datasets the Sturges value will usually be chosen, while larger datasets will usually default to FD. Avoids the overly conservative behaviour of FD and Sturges for small and large datasets respectively. Switchover point is usually \(a.size \approx 1000\).

‘fd’ (Freedman Diaconis Estimator)
-
\[h = 2 \frac{IQR}{n^{1/3}}\]The binwidth is proportional to the interquartile range (IQR) and inversely proportional to cube root of a.size. Can be too conservative for small datasets, but is quite good for large datasets. The IQR is very robust to outliers.

-
‘scott’
-
\[h = \sigma \sqrt[3]{\frac{24 \sqrt{\pi}}{n}}\]The binwidth is proportional to the standard deviation of the data and inversely proportional to cube root of

`x.size`
. Can be too conservative for small datasets, but is quite good for large datasets. The standard deviation is not very robust to outliers. Values are very similar to the Freedman-Diaconis estimator in the absence of outliers.
-
‘rice’
-
\[n_h = 2n^{1/3}\]The number of bins is only proportional to cube root of

`a.size`
. It tends to overestimate the number of bins and it does not take into account data variability.
-
‘sturges’
-
\[n_h = \log _{2}(n) + 1\]The number of bins is the base 2 log of

`a.size`
. This estimator assumes normality of data and is too conservative for larger, non-normal datasets. This is the default method in R’s`hist`
method.
-
‘doane’
-
\[ \begin{align}\begin{aligned}n_h = 1 + \log_{2}(n) + \log_{2}\left(1 + \frac{|g_1|}{\sigma_{g_1}}\right)\\g_1 = mean\left[\left(\frac{x - \mu}{\sigma}\right)^3\right]\\\sigma_{g_1} = \sqrt{\frac{6(n - 2)}{(n + 1)(n + 3)}}\end{aligned}\end{align} \]An improved version of Sturges’ formula that produces better estimates for non-normal datasets. This estimator attempts to account for the skew of the data.

-
‘sqrt’
-
\[n_h = \sqrt n\]The simplest and fastest estimator. Only takes into account the data size.

-
Examples

>>> arr = np.array([0, 0, 0, 1, 2, 3, 3, 4, 5]) >>> np.histogram_bin_edges(arr, bins='auto', range=(0, 1)) array([0. , 0.25, 0.5 , 0.75, 1. ]) >>> np.histogram_bin_edges(arr, bins=2) array([0. , 2.5, 5. ])
For consistency with histogram, an array of pre-computed bins is passed through unmodified:

>>> np.histogram_bin_edges(arr, [1, 2]) array([1, 2])
This function allows one set of bins to be computed, and reused across multiple histograms:

>>> shared_bins = np.histogram_bin_edges(arr, bins='auto') >>> shared_bins array([0., 1., 2., 3., 4., 5.])
>>> group_id = np.array([0, 1, 1, 0, 1, 1, 0, 1, 1]) >>> hist_0, _ = np.histogram(arr[group_id == 0], bins=shared_bins) >>> hist_1, _ = np.histogram(arr[group_id == 1], bins=shared_bins)
>>> hist_0; hist_1 array([1, 1, 0, 1, 0]) array([2, 0, 1, 1, 2])
Which gives more easily comparable results than using separate bins for each histogram:

>>> hist_0, bins_0 = np.histogram(arr[group_id == 0], bins='auto') >>> hist_1, bins_1 = np.histogram(arr[group_id == 1], bins='auto') >>> hist_0; hist_1 array([1, 1, 1]) array([2, 1, 1, 2]) >>> bins_0; bins_1 array([0., 1., 2., 3.]) array([0. , 1.25, 2.5 , 3.75, 5. ])# numpy.fft.rfftn[#](#numpy-fft-rfftn)
fft.rfftn(*a*,*s=None*,*axes=None*,*norm=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/fft/_pocketfft.py#L1110-L1205)[#](#numpy.fft.rfftn)
-
Compute the N-dimensional discrete Fourier Transform for real input.

This function computes the N-dimensional discrete Fourier Transform over any number of axes in an M-dimensional real array by means of the Fast Fourier Transform (FFT). By default, all axes are transformed, with the real transform performed over the last axis, while the remaining transforms are complex.

Parameters:
-
**a**array_like
Input array, taken to be real.

**s**sequence of ints, optional
Shape (length along each transformed axis) to use from the input. (

`s[0]`
refers to axis 0,`s[1]`
to axis 1, etc.). The final element of*s*corresponds to*n*for`rfft(x, n)`
, while for the remaining axes, it corresponds to*n*for`fft(x, n)`
. Along any axis, if the given shape is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. if*s*is not given, the shape of the input along the axes specified by*axes*is used.
**axes**sequence of ints, optional
Axes over which to compute the FFT. If not given, the last

`len(s)`
axes are used, or all axes if*s*is also not specified.
**norm**{“backward”, “ortho”, “forward”}, optional
New in version 1.10.0.

Normalization mode (see

). Default is “backward”. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.`numpy.fft`
New in version 1.20.0: The “backward”, “forward” values were added.

Returns:
-
**out**complex ndarray
The truncated or zero-padded input, transformed along the axes indicated by

*axes*, or by a combination of*s*and*a*, as explained in the parameters section above. The length of the last axis transformed will be`s[-1]//2+1`
, while the remaining transformed axes will have lengths according to*s*, or unchanged from the input.
Raises:
-
ValueError
-
If

*s*and*axes*have different length.
IndexError
-
If an element of

*axes*is larger than than the number of axes of*a*.
See also

Notes

The transform for real input is performed over the last transformation axis, as by

, then the transform over the remaining axes is performed as by`rfft`
. The order of the output is as for`fftn`
for the final transformation axis, and as for`rfft`
for the remaining transformation axes.`fftn`
See

for details, definitions and conventions used.`fft`
Examples

>>> a = np.ones((2, 2, 2)) >>> np.fft.rfftn(a) array([[[8.+0.j, 0.+0.j], # may vary [0.+0.j, 0.+0.j]], [[0.+0.j, 0.+0.j], [0.+0.j, 0.+0.j]]])
>>> np.fft.rfftn(a, axes=(2, 0)) array([[[4.+0.j, 0.+0.j], # may vary [4.+0.j, 0.+0.j]], [[0.+0.j, 0.+0.j], [0.+0.j, 0.+0.j]]])# numpy.dtype.isalignedstruct[#](#numpy-dtype-isalignedstruct)
attribute

dtype.isalignedstruct[#](#numpy.dtype.isalignedstruct)
-
Boolean indicating whether the dtype is a struct which maintains field alignment. This flag is sticky, so when combining multiple structs together, it is preserved and produces new dtypes which are also aligned.# numpy.ma.MaskedArray.ravel[#](#numpy-ma-maskedarray-ravel)
method

ma.MaskedArray.ravel(*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4624-L4683)[#](#numpy.ma.MaskedArray.ravel)
-
Returns a 1D version of self, as a view.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
The elements of

*a*are read using this index order. ‘C’ means to index the elements in C-like order, with the last axis index changing fastest, back to the first axis index changing slowest. ‘F’ means to index the elements in Fortran-like index order, with the first index changing fastest, and the last index changing slowest. Note that the ‘C’ and ‘F’ options take no account of the memory layout of the underlying array, and only refer to the order of axis indexing. ‘A’ means to read the elements in Fortran-like index order if*m*is Fortran*contiguous*in memory, C-like order otherwise. ‘K’ means to read the elements in the order they occur in memory, except for reversing the data when strides are negative. By default, ‘C’ index order is used. (Masked arrays currently use ‘A’ on the data when ‘K’ is passed.)
Returns:
-
MaskedArray
-
Output view is of shape

`(self.size,)`
(or`(np.ma.product(self.shape),)`
).
Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.ravel() masked_array(data=[1, --, 3, --, 5, --, 7, --, 9], mask=[False, True, False, True, False, True, False, True, False], fill_value=999999)# numpy.ma.masked_array.max[#](#numpy-ma-masked-array-max)
method

ma.masked_array.max(*axis=None*,*out=None*,*fill_value=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5859-L5964)[#](#numpy.ma.masked_array.max)
-
Return the maximum along a given axis.

Parameters:
-
**axis**None or int or tuple of ints, optional
Axis along which to operate. By default,

`axis`
is None and the flattened input is used. .. versionadded:: 1.7.0 If this is a tuple of ints, the maximum is selected over multiple axes, instead of a single axis or all the axes as before.
**out**array_like, optional
Alternative output array in which to place the result. Must be of the same shape and buffer length as the expected output.

**fill_value**scalar or None, optional
Value used to fill in the masked values. If None, use the output of maximum_fill_value().

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.

Returns:
-
**amax**array_like
New array holding the result. If

`out`
was specified,`out`
is returned.
See also

`ma.maximum_fill_value`
Returns the maximum filling value for a given datatype.

Examples

>>> import numpy.ma as ma >>> x = [[-1., 2.5], [4., -2.], [3., 0.]] >>> mask = [[0, 0], [1, 0], [1, 0]] >>> masked_x = ma.masked_array(x, mask) >>> masked_x masked_array( data=[[-1.0, 2.5], [--, -2.0], [--, 0.0]], mask=[[False, False], [ True, False], [ True, False]], fill_value=1e+20) >>> ma.max(masked_x) 2.5 >>> ma.max(masked_x, axis=0) masked_array(data=[-1.0, 2.5], mask=[False, False], fill_value=1e+20) >>> ma.max(masked_x, axis=1, keepdims=True) masked_array( data=[[2.5], [-2.0], [0.0]], mask=[[False], [False], [False]], fill_value=1e+20) >>> mask = [[1, 1], [1, 1], [1, 1]] >>> masked_x = ma.masked_array(x, mask) >>> ma.max(masked_x, axis=1) masked_array(data=[--, --, --], mask=[ True, True, True], fill_value=1e+20, dtype=float64)# numpy.ma.polyfit[#](#numpy-ma-polyfit)
ma.polyfit(*x*,*y*,*deg*,*rcond=None*,*full=False*,*w=None*,*cov=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L2099-L2131)[#](#numpy.ma.polyfit)
-
Least squares polynomial fit.

Note

This forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in

is preferred. A summary of the differences can be found in the`numpy.polynomial`
[transition guide](../routines.polynomials.html).Fit a polynomial

`p(x) = p[0] * x**deg + ... + p[deg]`
of degree*deg*to points*(x, y)*. Returns a vector of coefficients*p*that minimises the squared error in the order*deg*,*deg-1*, …*0*.The

class method is recommended for new code as it is more stable numerically. See the documentation of the method for more information.`Polynomial.fit`
Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,) or (M, K)
y-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.

**deg**int
Degree of the fitting polynomial

**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (M,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.
**cov**bool or str, optional
If given and not

*False*, return not just the estimate but also its covariance matrix. By default, the covariance are scaled by chi2/dof, where dof = M - (deg + 1), i.e., the weights are presumed to be unreliable except in a relative sense and everything is scaled such that the reduced chi2 is unity. This scaling is omitted if`cov='unscaled'`
, as is relevant for the case that the weights are w = 1/sigma, with sigma known to be a reliable estimate of the uncertainty.
Returns:
-
**p**ndarray, shape (deg + 1,) or (deg + 1, K)
Polynomial coefficients, highest power first. If

*y*was 2-D, the coefficients for*k*-th data set are in`p[:,k]`
.
residuals, rank, singular_values, rcond
-
These values are only returned if

`full == True`
residuals – sum of squared residuals of the least squares fit

rank – the effective rank of the scaled Vandermonde
-
coefficient matrix

singular_values – singular values of the scaled Vandermonde
-
coefficient matrix

rcond – value of

*rcond*.
For more details, see

.`numpy.linalg.lstsq`
**V**ndarray, shape (M,M) or (M,M,K)
Present only if

`full == False`
and`cov == True`
. The covariance matrix of the polynomial coefficient estimates. The diagonal of this matrix are the variance estimates for each coefficient. If y is a 2-D array, then the covariance matrix for the*k*-th data set are in`V[:,:,k]`
Warns:
-
RankWarning
-
The rank of the coefficient matrix in the least-squares fit is deficient. The warning is only raised if

`full == False`
.The warnings can be turned off by

>>> import warnings >>> warnings.simplefilter('ignore', np.RankWarning)
See also

`polyval`
Compute polynomial values.

`linalg.lstsq`
Computes a least-squares fit.

`scipy.interpolate.UnivariateSpline`
Computes spline fits.

Notes

Any masked values in x is propagated in y, and vice-versa.

The solution minimizes the squared error

\[E = \sum_{j=0}^k |p(x_j) - y_j|^2\]in the equations:

x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0] x[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1] ... x[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]
The coefficient matrix of the coefficients

*p*is a Vandermonde matrix.issues a`polyfit`
when the least-squares fit is badly conditioned. This implies that the best fit is not well-defined due to numerical error. The results may be improved by lowering the polynomial degree or by replacing`RankWarning`
*x*by*x*-*x*.mean(). The*rcond*parameter can also be set to a value smaller than its default, but the resulting fit may be spurious: including contributions from the small singular values can add numerical noise to the result.Note that fitting polynomial coefficients is inherently badly conditioned when the degree of the polynomial is large or the interval of sample points is badly centered. The quality of the fit should always be checked in these cases. When polynomial fits are not satisfactory, splines may be a good alternative.

References

[1]Wikipedia, “Curve fitting”,

[https://en.wikipedia.org/wiki/Curve_fitting](https://en.wikipedia.org/wiki/Curve_fitting)[2]Wikipedia, “Polynomial interpolation”,

[https://en.wikipedia.org/wiki/Polynomial_interpolation](https://en.wikipedia.org/wiki/Polynomial_interpolation)Examples

>>> import warnings >>> x = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0]) >>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0]) >>> z = np.polyfit(x, y, 3) >>> z array([ 0.08703704, -0.81349206, 1.69312169, -0.03968254]) # may vary
It is convenient to use

objects for dealing with polynomials:`poly1d`
>>> p = np.poly1d(z) >>> p(0.5) 0.6143849206349179 # may vary >>> p(3.5) -0.34732142857143039 # may vary >>> p(10) 22.579365079365115 # may vary
High-order polynomials may oscillate wildly:

>>> with warnings.catch_warnings(): ... warnings.simplefilter('ignore', np.RankWarning) ... p30 = np.poly1d(np.polyfit(x, y, 30)) ... >>> p30(4) -0.80000000000000204 # may vary >>> p30(5) -0.99999999999999445 # may vary >>> p30(4.5) -0.10547061179440398 # may vary
Illustration:

>>> import matplotlib.pyplot as plt >>> xp = np.linspace(-2, 6, 100) >>> _ = plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--') >>> plt.ylim(-2,2) (-2, 2) >>> plt.show()# numpy.ufunc.accumulate[#](#numpy-ufunc-accumulate)
method

ufunc.accumulate(*array*,*axis=0*,*dtype=None*,*out=None*)[#](#numpy.ufunc.accumulate)
-
Accumulate the result of applying the operator to all elements.

For a one-dimensional array, accumulate produces results equivalent to:

r = np.empty(len(A)) t = op.identity # op = the ufunc being applied to A's elements for i in range(len(A)): t = op(t, A[i]) r[i] = t return r
For example, add.accumulate() is equivalent to np.cumsum().

For a multi-dimensional array, accumulate is applied along only one axis (axis zero by default; see Examples below) so repeated use is necessary if one wants to accumulate over multiple axes.

Parameters:
-
**array**array_like
The array to act on.

**axis**int, optional
The axis along which to apply the accumulation; default is zero.

**dtype**data-type code, optional
The data-type used to represent the intermediate results. Defaults to the data-type of the output array if such is provided, or the data-type of the input array if no output array is provided.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If not provided or None, a freshly-allocated array is returned. For consistency with

`ufunc.__call__`
, if given as a keyword, this may be wrapped in a 1-element tuple.Changed in version 1.13.0: Tuples are allowed for keyword argument.

Returns:
-
**r**ndarray
The accumulated values. If

*out*was supplied,*r*is a reference to*out*.
Examples

1-D array examples:

>>> np.add.accumulate([2, 3, 5]) array([ 2, 5, 10]) >>> np.multiply.accumulate([2, 3, 5]) array([ 2, 6, 30])
2-D array examples:

>>> I = np.eye(2) >>> I array([[1., 0.], [0., 1.]])
Accumulate along axis 0 (rows), down columns:

>>> np.add.accumulate(I, 0) array([[1., 0.], [1., 1.]]) >>> np.add.accumulate(I) # no axis specified = axis zero array([[1., 0.], [1., 1.]])
Accumulate along axis 1 (columns), through rows:

>>> np.add.accumulate(I, 1) array([[1., 1.], [0., 1.]])# numpy.polynomial.legendre.legadd[#](#numpy-polynomial-legendre-legadd)
polynomial.legendre.legadd(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L322-L361)[#](#numpy.polynomial.legendre.legadd)
-
Add one Legendre series to another.

Returns the sum of two Legendre series

*c1*+*c2*. The arguments are sequences of coefficients ordered from lowest order term to highest, i.e., [1,2,3] represents the series`P_0 + 2*P_1 + 3*P_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Legendre series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Array representing the Legendre series of their sum.

Notes

Unlike multiplication, division, etc., the sum of two Legendre series is a Legendre series (without having to “reproject” the result onto the basis set) so addition, just like that of “standard” polynomials, is simply “component-wise.”

Examples

>>> from numpy.polynomial import legendre as L >>> c1 = (1,2,3) >>> c2 = (3,2,1) >>> L.legadd(c1,c2) array([4., 4., 4.])# Random Generator[#](#random-generator)
The [ Generator](#numpy.random.Generator) provides access to
a wide range of distributions, and served as a replacement for

[. The main difference between the two is that](legacy.html#numpy.random.RandomState)
`RandomState`
`Generator`
relies on an additional BitGenerator to
manage state and generate the random bits, which are then transformed into
random values from useful distributions. The default BitGenerator used by
`Generator`
is [. The BitGenerator can be changed by passing an instantized BitGenerator to](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
`Generator`
.
numpy.random.default_rng(*seed=None*)[#](#numpy.random.default_rng)
-
Construct a new Generator with the default BitGenerator (PCG64).

Parameters:
-
**seed**{None, int, array_like[ints], SeedSequence, BitGenerator, Generator}, optional
A seed to initialize the

. If None, then fresh, unpredictable entropy will be pulled from the OS. If an`BitGenerator`
`int`
or`array_like[ints]`
is passed, then it will be passed toto derive the initial`SeedSequence`
state. One may also pass in a`BitGenerator`
instance. Additionally, when passed a`SeedSequence`
, it will be wrapped by`BitGenerator`
. If passed a`Generator`
, it will be returned unaltered.`Generator`
Returns:
-
Generator
-
The initialized generator object.

Notes

If

`seed`
is not aor a`BitGenerator`
, a new`Generator`
is instantiated. This function does not manage a default global instance.`BitGenerator`
See

[Seeding and Entropy](bit_generators/index.html#seeding-and-entropy)for more information about seeding.Examples

`default_rng`
is the recommended constructor for the random number class`Generator`
. Here are several ways we can construct a random number generator using`default_rng`
and the`Generator`
class.Here we use

`default_rng`
to generate a random float:>>> import numpy as np >>> rng = np.random.default_rng(12345) >>> print(rng) Generator(PCG64) >>> rfloat = rng.random() >>> rfloat 0.22733602246716966 >>> type(rfloat) <class 'float'>
Here we use

`default_rng`
to generate 3 random integers between 0 (inclusive) and 10 (exclusive):>>> import numpy as np >>> rng = np.random.default_rng(12345) >>> rints = rng.integers(low=0, high=10, size=3) >>> rints array([6, 2, 7]) >>> type(rints[0]) <class 'numpy.int64'>
Here we specify a seed so that we have reproducible results:

>>> import numpy as np >>> rng = np.random.default_rng(seed=42) >>> print(rng) Generator(PCG64) >>> arr1 = rng.random((3, 3)) >>> arr1 array([[0.77395605, 0.43887844, 0.85859792], [0.69736803, 0.09417735, 0.97562235], [0.7611397 , 0.78606431, 0.12811363]])
If we exit and restart our Python interpreter, we’ll see that we generate the same random numbers again:

>>> import numpy as np >>> rng = np.random.default_rng(seed=42) >>> arr2 = rng.random((3, 3)) >>> arr2 array([[0.77395605, 0.43887844, 0.85859792], [0.69736803, 0.09417735, 0.97562235], [0.7611397 , 0.78606431, 0.12811363]])
*class*numpy.random.Generator(*bit_generator*)[#](#numpy.random.Generator)
-
Container for the BitGenerators.

`Generator`
exposes a number of methods for generating random numbers drawn from a variety of probability distributions. In addition to the distribution-specific arguments, each method takes a keyword argument*size*that defaults to`None`
. If*size*is`None`
, then a single value is generated and returned. If*size*is an integer, then a 1-D array filled with generated values is returned. If*size*is a tuple, then an array with that shape is filled and returned.The function

will instantiate a`numpy.random.default_rng`
with numpy’s default`Generator`
.`BitGenerator`
**No Compatibility Guarantee**`Generator`
does not provide a version compatibility guarantee. In particular, as better algorithms evolve the bit stream may change.Parameters:
-
**bit_generator**BitGenerator
BitGenerator to use as the core generator.

See also

`default_rng`
Recommended constructor for

.`Generator`
Notes

The Python stdlib module

contains pseudo-random number generator with a number of methods that are similar to the ones available in`random`
`Generator`
. It uses Mersenne Twister, and this bit generator can be accessed using`MT19937`
.`Generator`
, besides being NumPy-aware, has the advantage that it provides a much larger number of probability distributions to choose from.Examples

>>> from numpy.random import Generator, PCG64 >>> rng = Generator(PCG64()) >>> rng.standard_normal() -0.203 # random
## Accessing the BitGenerator and Spawning[#](#accessing-the-bitgenerator-and-spawning)
Gets the bit generator instance used by the generator

|
|
Create new independent child generators.

|
## Simple random data[#](#simple-random-data)
|
Return random integers from

|
|
Return random floats in the half-open interval [0.0, 1.0).

|
|
Generates a random sample from a given array

|
|
Return random bytes.

|
## Permutations[#](#permutations)
The methods for randomly permuting a sequence are

|
Modify an array or sequence in-place by shuffling its contents.

|
|
Randomly permute a sequence, or return a permuted range.

|
|
Randomly permute

|
The following table summarizes the behaviors of the methods.

method

|
copy/in-place

|
axis handling

|
---|---|---|
shuffle

|
in-place

|
as if 1d

|
permutation

|
copy

|
as if 1d

|
permuted

|
either (use ‘out’ for in-place)

|
axis independent

|
The following subsections provide more details about the differences.

### In-place vs. copy[#](#in-place-vs-copy)
The main difference between [ Generator.shuffle](generated/numpy.random.Generator.shuffle.html#numpy.random.Generator.shuffle) and

[is that](generated/numpy.random.Generator.permutation.html#numpy.random.Generator.permutation)
`Generator.permutation`
[operates in-place, while](generated/numpy.random.Generator.shuffle.html#numpy.random.Generator.shuffle)
`Generator.shuffle`
[returns a copy.](generated/numpy.random.Generator.permutation.html#numpy.random.Generator.permutation)
`Generator.permutation`
By default, [ Generator.permuted](generated/numpy.random.Generator.permuted.html#numpy.random.Generator.permuted) returns a copy. To operate in-place with

[, pass the same array as the first argument](generated/numpy.random.Generator.permuted.html#numpy.random.Generator.permuted)
`Generator.permuted`
*and*as the value of the
`out`
parameter. For example,```
>>> rng = np.random.default_rng()
>>> x = np.arange(0, 15).reshape(3, 5)
>>> x
array([[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9],
[10, 11, 12, 13, 14]])
>>> y = rng.permuted(x, axis=1, out=x)
>>> x
array([[ 1, 0, 2, 4, 3], # random
[ 6, 7, 8, 9, 5],
[10, 14, 11, 13, 12]])
```
Note that when `out`
is given, the return value is `out`
:

```
>>> y is x
True
```
### Handling the `axis`
parameter[#](#handling-the-axis-parameter)
An important distinction for these methods is how they handle the `axis`
parameter. Both [ Generator.shuffle](generated/numpy.random.Generator.shuffle.html#numpy.random.Generator.shuffle) and

[treat the input as a one-dimensional sequence, and the](generated/numpy.random.Generator.permutation.html#numpy.random.Generator.permutation)
`Generator.permutation`
`axis`
parameter determines
which dimension of the input array to use as the sequence. In the case of a
two-dimensional array, `axis=0`
will, in effect, rearrange the rows of the
array, and `axis=1`
will rearrange the columns. For example```
>>> rng = np.random.default_rng()
>>> x = np.arange(0, 15).reshape(3, 5)
>>> x
array([[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9],
[10, 11, 12, 13, 14]])
>>> rng.permutation(x, axis=1)
array([[ 1, 3, 2, 0, 4], # random
[ 6, 8, 7, 5, 9],
[11, 13, 12, 10, 14]])
```
Note that the columns have been rearranged “in bulk”: the values within each column have not changed.

The method [ Generator.permuted](generated/numpy.random.Generator.permuted.html#numpy.random.Generator.permuted) treats the

`axis`
parameter similar to
how [treats it. Each slice along the given axis is shuffled independently of the others. Compare the following example of the use of](../generated/numpy.sort.html#numpy.sort)
`numpy.sort`
[to the above example of](generated/numpy.random.Generator.permuted.html#numpy.random.Generator.permuted)
`Generator.permuted`
[:](generated/numpy.random.Generator.permutation.html#numpy.random.Generator.permutation)
`Generator.permutation`
```
>>> rng.permuted(x, axis=1)
array([[ 1, 0, 2, 4, 3], # random
[ 5, 7, 6, 9, 8],
[10, 14, 12, 13, 11]])
```
In this example, the values within each row (i.e. the values along
`axis=1`
) have been shuffled independently. This is not a “bulk”
shuffle of the columns.

### Shuffling non-NumPy sequences[#](#shuffling-non-numpy-sequences)
[ Generator.shuffle](generated/numpy.random.Generator.shuffle.html#numpy.random.Generator.shuffle) works on non-NumPy sequences. That is, if it is given
a sequence that is not a NumPy array, it shuffles that sequence in-place.
For example,
```
>>> rng = np.random.default_rng()
>>> a = ['A', 'B', 'C', 'D', 'E']
>>> rng.shuffle(a) # shuffle the list in-place
>>> a
['B', 'D', 'A', 'E', 'C'] # random
```
## Distributions[#](#distributions)
|
Draw samples from a Beta distribution.

|
|
Draw samples from a binomial distribution.

|
|
Draw samples from a chi-square distribution.

|
|
Draw samples from the Dirichlet distribution.

|
|
Draw samples from an exponential distribution.

|
|
Draw samples from an F distribution.

|
|
Draw samples from a Gamma distribution.

|
|
Draw samples from the geometric distribution.

|
|
Draw samples from a Gumbel distribution.

|
|
Draw samples from a Hypergeometric distribution.

|
|
Draw samples from the Laplace or double exponential distribution with specified location (or mean) and scale (decay).

|
|
Draw samples from a logistic distribution.

|
|
Draw samples from a log-normal distribution.

|
|
Draw samples from a logarithmic series distribution.

|
|
Draw samples from a multinomial distribution.

|
|
Generate variates from a multivariate hypergeometric distribution.

|
|
Draw random samples from a multivariate normal distribution.

|
|
Draw samples from a negative binomial distribution.

|
|
Draw samples from a noncentral chi-square distribution.

|
|
Draw samples from the noncentral F distribution.

|
|
Draw random samples from a normal (Gaussian) distribution.

|
|
Draw samples from a Pareto II or Lomax distribution with specified shape.

|
|
Draw samples from a Poisson distribution.

|
|
Draws samples in [0, 1] from a power distribution with positive exponent a - 1.

|
|
Draw samples from a Rayleigh distribution.

|
|
Draw samples from a standard Cauchy distribution with mode = 0.

|
|
Draw samples from the standard exponential distribution.

|
|
Draw samples from a standard Gamma distribution.

|
|
Draw samples from a standard Normal distribution (mean=0, stdev=1).

|
|
Draw samples from a standard Student's t distribution with

|
|
Draw samples from the triangular distribution over the interval

|
|
Draw samples from a uniform distribution.

|
|
Draw samples from a von Mises distribution.

|
|
Draw samples from a Wald, or inverse Gaussian, distribution.

|
|
Draw samples from a Weibull distribution.

|
|
Draw samples from a Zipf distribution.

|# numpy.polynomial.chebyshev.chebmul[#](#numpy-polynomial-chebyshev-chebmul)
polynomial.chebyshev.chebmul(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L701-L747)[#](#numpy.polynomial.chebyshev.chebmul)
-
Multiply one Chebyshev series by another.

Returns the product of two Chebyshev series

*c1***c2*. The arguments are sequences of coefficients, from lowest order “term” to highest, e.g., [1,2,3] represents the series`T_0 + 2*T_1 + 3*T_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Chebyshev series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Of Chebyshev series coefficients representing their product.

Notes

In general, the (polynomial) product of two C-series results in terms that are not in the Chebyshev polynomial basis set. Thus, to express the product as a C-series, it is typically necessary to “reproject” the product onto said basis set, which typically produces “unintuitive live” (but correct) results; see Examples section below.

Examples

>>> from numpy.polynomial import chebyshev as C >>> c1 = (1,2,3) >>> c2 = (3,2,1) >>> C.chebmul(c1,c2) # multiplication requires "reprojection" array([ 6.5, 12. , 12. , 4. , 1.5])# numpy.tile[#](#numpy-tile)
numpy.tile(*A*,*reps*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L1185-L1274)[#](#numpy.tile)
-
Construct an array by repeating A the number of times given by reps.

If

*reps*has length`d`
, the result will have dimension of`max(d, A.ndim)`
.If

`A.ndim < d`
,*A*is promoted to be d-dimensional by prepending new axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication, or shape (1, 1, 3) for 3-D replication. If this is not the desired behavior, promote*A*to d-dimensions manually before calling this function.If

`A.ndim > d`
,*reps*is promoted to*A*.ndim by pre-pending 1’s to it. Thus for an*A*of shape (2, 3, 4, 5), a*reps*of (2, 2) is treated as (1, 1, 2, 2).Note : Although tile may be used for broadcasting, it is strongly recommended to use numpy’s broadcasting operations and functions.

Parameters:
-
**A**array_like
The input array.

**reps**array_like
The number of repetitions of

*A*along each axis.
Returns:
-
**c**ndarray
The tiled output array.

See also

`repeat`
Repeat elements of an array.

`broadcast_to`
Broadcast an array to a new shape

Examples

>>> a = np.array([0, 1, 2]) >>> np.tile(a, 2) array([0, 1, 2, 0, 1, 2]) >>> np.tile(a, (2, 2)) array([[0, 1, 2, 0, 1, 2], [0, 1, 2, 0, 1, 2]]) >>> np.tile(a, (2, 1, 2)) array([[[0, 1, 2, 0, 1, 2]], [[0, 1, 2, 0, 1, 2]]])
>>> b = np.array([[1, 2], [3, 4]]) >>> np.tile(b, 2) array([[1, 2, 1, 2], [3, 4, 3, 4]]) >>> np.tile(b, (2, 1)) array([[1, 2], [3, 4], [1, 2], [3, 4]])
>>> c = np.array([1,2,3,4]) >>> np.tile(c,(4,1)) array([[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]])# numpy.fmod[#](#numpy-fmod)
numpy.fmod(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'fmod'>*[#](#numpy.fmod)
-
Returns the element-wise remainder of division.

This is the NumPy implementation of the C library function fmod, the remainder has the same sign as the dividend

*x1*. It is equivalent to the Matlab(TM)`rem`
function and should not be confused with the Python modulus operator`x1 % x2`
.Parameters:
-
**x1**array_like
Dividend.

**x2**array_like
Divisor. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**array_like
The remainder of the division of

*x1*by*x2*. This is a scalar if both*x1*and*x2*are scalars.
Notes

The result of the modulo operation for negative dividend and divisors is bound by conventions. For

, the sign of result is the sign of the dividend, while for`fmod`
the sign of the result is the sign of the divisor. The`remainder`
function is equivalent to the Matlab(TM)`fmod`
`rem`
function.Examples

>>> np.fmod([-3, -2, -1, 1, 2, 3], 2) array([-1, 0, -1, 1, 0, 1]) >>> np.remainder([-3, -2, -1, 1, 2, 3], 2) array([1, 0, 1, 1, 0, 1])
>>> np.fmod([5, 3], [2, 2.]) array([ 1., 1.]) >>> a = np.arange(-3, 3).reshape(3, 2) >>> a array([[-3, -2], [-1, 0], [ 1, 2]]) >>> np.fmod(a, [2,2]) array([[-1, 0], [-1, 0], [ 1, 0]])# numpy.roll[#](#numpy-roll)
numpy.roll(*a*,*shift*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L1129-L1233)[#](#numpy.roll)
-
Roll array elements along a given axis.

Elements that roll beyond the last position are re-introduced at the first.

Parameters:
-
**a**array_like
Input array.

**shift**int or tuple of ints
The number of places by which elements are shifted. If a tuple, then

*axis*must be a tuple of the same size, and each of the given axes is shifted by the corresponding number. If an int while*axis*is a tuple of ints, then the same value is used for all given axes.
**axis**int or tuple of ints, optional
Axis or axes along which elements are shifted. By default, the array is flattened before shifting, after which the original shape is restored.

Returns:
-
**res**ndarray
Output array, with the same shape as

*a*.
See also

`rollaxis`
Roll the specified axis backwards, until it lies in a given position.

Notes

New in version 1.12.0.

Supports rolling over multiple dimensions simultaneously.

Examples

>>> x = np.arange(10) >>> np.roll(x, 2) array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7]) >>> np.roll(x, -2) array([2, 3, 4, 5, 6, 7, 8, 9, 0, 1])
>>> x2 = np.reshape(x, (2, 5)) >>> x2 array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) >>> np.roll(x2, 1) array([[9, 0, 1, 2, 3], [4, 5, 6, 7, 8]]) >>> np.roll(x2, -1) array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]) >>> np.roll(x2, 1, axis=0) array([[5, 6, 7, 8, 9], [0, 1, 2, 3, 4]]) >>> np.roll(x2, -1, axis=0) array([[5, 6, 7, 8, 9], [0, 1, 2, 3, 4]]) >>> np.roll(x2, 1, axis=1) array([[4, 0, 1, 2, 3], [9, 5, 6, 7, 8]]) >>> np.roll(x2, -1, axis=1) array([[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]) >>> np.roll(x2, (1, 1), axis=(1, 0)) array([[9, 5, 6, 7, 8], [4, 0, 1, 2, 3]]) >>> np.roll(x2, (2, 1), axis=(1, 0)) array([[8, 9, 5, 6, 7], [3, 4, 0, 1, 2]])# numpy.fft.irfftn[#](#numpy-fft-irfftn)
fft.irfftn(*a*,*s=None*,*axes=None*,*norm=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/fft/_pocketfft.py#L1260-L1367)[#](#numpy.fft.irfftn)
-
Computes the inverse of

.`rfftn`
This function computes the inverse of the N-dimensional discrete Fourier Transform for real input over any number of axes in an M-dimensional array by means of the Fast Fourier Transform (FFT). In other words,

`irfftn(rfftn(a), a.shape) == a`
to within numerical accuracy. (The`a.shape`
is necessary like`len(a)`
is for, and for the same reason.)`irfft`
The input should be ordered in the same way as is returned by

, i.e. as for`rfftn`
for the final transformation axis, and as for`irfft`
along all the other axes.`ifftn`
Parameters:
-
**a**array_like
Input array.

**s**sequence of ints, optional
Shape (length of each transformed axis) of the output (

`s[0]`
refers to axis 0,`s[1]`
to axis 1, etc.).*s*is also the number of input points used along this axis, except for the last axis, where`s[-1]//2+1`
points of the input are used. Along any axis, if the shape indicated by*s*is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. If*s*is not given, the shape of the input along the axes specified by axes is used. Except for the last axis which is taken to be`2*(m-1)`
where`m`
is the length of the input along that axis.
**axes**sequence of ints, optional
Axes over which to compute the inverse FFT. If not given, the last

*len(s)*axes are used, or all axes if*s*is also not specified. Repeated indices in*axes*means that the inverse transform over that axis is performed multiple times.
**norm**{“backward”, “ortho”, “forward”}, optional
New in version 1.10.0.

Normalization mode (see

). Default is “backward”. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.`numpy.fft`
New in version 1.20.0: The “backward”, “forward” values were added.

Returns:
-
**out**ndarray
The truncated or zero-padded input, transformed along the axes indicated by

*axes*, or by a combination of*s*or*a*, as explained in the parameters section above. The length of each transformed axis is as given by the corresponding element of*s*, or the length of the input in every axis except for the last one if*s*is not given. In the final transformed axis the length of the output when*s*is not given is`2*(m-1)`
where`m`
is the length of the final transformed axis of the input. To get an odd number of output points in the final axis,*s*must be specified.
Raises:
-
ValueError
-
If

*s*and*axes*have different length.
IndexError
-
If an element of

*axes*is larger than than the number of axes of*a*.
See also

Notes

See

for definitions and conventions used.`fft`
See

for definitions and conventions used for real input.`rfft`
The correct interpretation of the hermitian input depends on the shape of the original data, as given by

*s*. This is because each input shape could correspond to either an odd or even length signal. By default,assumes an even output length which puts the last entry at the Nyquist frequency; aliasing with its symmetric counterpart. When performing the final complex to real transform, the last value is thus treated as purely real. To avoid losing information, the correct shape of the real input`irfftn`
**must**be given.Examples

>>> a = np.zeros((3, 2, 2)) >>> a[0, 0, 0] = 3 * 2 * 2 >>> np.fft.irfftn(a) array([[[1., 1.], [1., 1.]], [[1., 1.], [1., 1.]], [[1., 1.], [1., 1.]]])# numpy.matrix.view[#](#numpy-matrix-view)
method

matrix.view(*[dtype][, type]*)[#](#numpy.matrix.view)
-
New view of array with the same data.

Note

Passing None for

`dtype`
is different from omitting the parameter, since the former invokes`dtype(None)`
which is an alias for`dtype('float_')`
.Parameters:
-
**dtype**data-type or ndarray sub-class, optional
Data-type descriptor of the returned view, e.g., float32 or int16. Omitting it results in the view having the same data-type as

*a*. This argument can also be specified as an ndarray sub-class, which then specifies the type of the returned object (this is equivalent to setting the`type`
parameter).
**type**Python type, optional
Type of the returned view, e.g., ndarray or matrix. Again, omission of the parameter results in type preservation.

Notes

`a.view()`
is used two different ways:`a.view(some_dtype)`
or`a.view(dtype=some_dtype)`
constructs a view of the array’s memory with a different data-type. This can cause a reinterpretation of the bytes of memory.`a.view(ndarray_subclass)`
or`a.view(type=ndarray_subclass)`
just returns an instance of*ndarray_subclass*that looks at the same array (same shape, dtype, etc.) This does not cause a reinterpretation of the memory.For

`a.view(some_dtype)`
, if`some_dtype`
has a different number of bytes per entry than the previous dtype (for example, converting a regular array to a structured array), then the last axis of`a`
must be contiguous. This axis will be resized in the result.Changed in version 1.23.0: Only the last axis needs to be contiguous. Previously, the entire array had to be C-contiguous.

Examples

>>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])
Viewing array data using a different type and dtype:

>>> y = x.view(dtype=np.int16, type=np.matrix) >>> y matrix([[513]], dtype=int16) >>> print(type(y)) <class 'numpy.matrix'>
Creating a view on a structured array so it can be used in calculations

>>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)]) >>> xv = x.view(dtype=np.int8).reshape(-1,2) >>> xv array([[1, 2], [3, 4]], dtype=int8) >>> xv.mean(0) array([2., 3.])
Making changes to the view changes the underlying array

>>> xv[0,1] = 20 >>> x array([(1, 20), (3, 4)], dtype=[('a', 'i1'), ('b', 'i1')])
Using a view to convert an array to a recarray:

>>> z = x.view(np.recarray) >>> z.a array([1, 3], dtype=int8)
Views share data:

>>> x[0] = (9, 10) >>> z[0] (9, 10)
Views that change the dtype size (bytes per entry) should normally be avoided on arrays defined by slices, transposes, fortran-ordering, etc.:

>>> x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int16) >>> y = x[:, ::2] >>> y array([[1, 3], [4, 6]], dtype=int16) >>> y.view(dtype=[('width', np.int16), ('length', np.int16)]) Traceback (most recent call last): ... ValueError: To change to a dtype of a different size, the last axis must be contiguous >>> z = y.copy() >>> z.view(dtype=[('width', np.int16), ('length', np.int16)]) array([[(1, 3)], [(4, 6)]], dtype=[('width', '<i2'), ('length', '<i2')])
However, views that change dtype are totally fine for arrays with a contiguous last axis, even if the rest of the axes are not C-contiguous:

>>> x = np.arange(2 * 3 * 4, dtype=np.int8).reshape(2, 3, 4) >>> x.transpose(1, 0, 2).view(np.int16) array([[[ 256, 770], [3340, 3854]], [[1284, 1798], [4368, 4882]], [[2312, 2826], [5396, 5910]]], dtype=int16)# numpy.ma.MaskedArray.count[#](#numpy-ma-maskedarray-count)
method

ma.MaskedArray.count(*axis=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4525-L4622)[#](#numpy.ma.MaskedArray.count)
-
Count the non-masked elements of the array along the given axis.

Parameters:
-
**axis**None or int or tuple of ints, optional
Axis or axes along which the count is performed. The default, None, performs the count over all the dimensions of the input array.

*axis*may be negative, in which case it counts from the last to the first axis.New in version 1.10.0.

If this is a tuple of ints, the count is performed on multiple axes, instead of a single axis or all the axes as before.

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.

Returns:
-
**result**ndarray or scalar
An array with the same shape as the input array, with the specified axis removed. If the array is a 0-d array, or if

*axis*is None, a scalar is returned.
See also

`ma.count_masked`
Count masked elements in array or along a given axis.

Examples

>>> import numpy.ma as ma >>> a = ma.arange(6).reshape((2, 3)) >>> a[1, :] = ma.masked >>> a masked_array( data=[[0, 1, 2], [--, --, --]], mask=[[False, False, False], [ True, True, True]], fill_value=999999) >>> a.count() 3
When the

*axis*keyword is specified an array of appropriate size is returned.>>> a.count(axis=0) array([1, 1, 1]) >>> a.count(axis=1) array([3, 0])# numpy.blackman[#](#numpy-blackman)
numpy.blackman(*M*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L2910-L3012)[#](#numpy.blackman)
-
Return the Blackman window.

The Blackman window is a taper formed by using the first three terms of a summation of cosines. It was designed to have close to the minimal leakage possible. It is close to optimal, only slightly worse than a Kaiser window.

Parameters:
-
**M**int
Number of points in the output window. If zero or less, an empty array is returned.

Returns:
-
**out**ndarray
The window, with the maximum value normalized to one (the value one appears only if the number of samples is odd).

Notes

The Blackman window is defined as

\[w(n) = 0.42 - 0.5 \cos(2\pi n/M) + 0.08 \cos(4\pi n/M)\]Most references to the Blackman window come from the signal processing literature, where it is used as one of many windowing functions for smoothing values. It is also known as an apodization (which means “removing the foot”, i.e. smoothing discontinuities at the beginning and end of the sampled signal) or tapering function. It is known as a “near optimal” tapering function, almost as good (by some measures) as the kaiser window.

References

Blackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra, Dover Publications, New York.

Oppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing. Upper Saddle River, NJ: Prentice-Hall, 1999, pp. 468-471.

Examples

>>> import matplotlib.pyplot as plt >>> np.blackman(12) array([-1.38777878e-17, 3.26064346e-02, 1.59903635e-01, # may vary 4.14397981e-01, 7.36045180e-01, 9.67046769e-01, 9.67046769e-01, 7.36045180e-01, 4.14397981e-01, 1.59903635e-01, 3.26064346e-02, -1.38777878e-17])
Plot the window and the frequency response:

>>> from numpy.fft import fft, fftshift >>> window = np.blackman(51) >>> plt.plot(window) [<matplotlib.lines.Line2D object at 0x...>] >>> plt.title("Blackman window") Text(0.5, 1.0, 'Blackman window') >>> plt.ylabel("Amplitude") Text(0, 0.5, 'Amplitude') >>> plt.xlabel("Sample") Text(0.5, 0, 'Sample') >>> plt.show()
>>> plt.figure() <Figure size 640x480 with 0 Axes> >>> A = fft(window, 2048) / 25.5 >>> mag = np.abs(fftshift(A)) >>> freq = np.linspace(-0.5, 0.5, len(A)) >>> with np.errstate(divide='ignore', invalid='ignore'): ... response = 20 * np.log10(mag) ... >>> response = np.clip(response, -100, 100) >>> plt.plot(freq, response) [<matplotlib.lines.Line2D object at 0x...>] >>> plt.title("Frequency response of Blackman window") Text(0.5, 1.0, 'Frequency response of Blackman window') >>> plt.ylabel("Magnitude [dB]") Text(0, 0.5, 'Magnitude [dB]') >>> plt.xlabel("Normalized frequency [cycles per sample]") Text(0.5, 0, 'Normalized frequency [cycles per sample]') >>> _ = plt.axis('tight') >>> plt.show()# numpy.ndarray[#](#numpy-ndarray)
*class*numpy.ndarray(*shape*,*dtype=float*,*buffer=None*,*offset=0*,*strides=None*,*order=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/arrayobject.c)[#](#numpy.ndarray)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
ndarray`T`
View of the transposed array.

buffer`data`
Python buffer object pointing to the start of the array’s data.

dtype object`dtype`
Data-type of the array’s elements.

dict`flags`
Information about the memory layout of the array.

numpy.flatiter object`flat`
A 1-D iterator over the array.

ndarray`imag`
The imaginary part of the array.

ndarray`real`
The real part of the array.

int`size`
Number of elements in the array.

int`itemsize`
Length of one array element in bytes.

int`nbytes`
Total bytes consumed by the elements of the array.

int`ndim`
Number of array dimensions.

tuple of ints`shape`
Tuple of array dimensions.

tuple of ints`strides`
Tuple of bytes to step in each dimension when traversing an array.

ctypes object`ctypes`
An object to simplify the interaction of the array with the ctypes module.

ndarray`base`
Base object if memory is from some other object.

Methods

([axis, out, keepdims, where])`all`
Returns True if all elements evaluate to True.

([axis, out, keepdims, where])`any`
Returns True if any of the elements of

*a*evaluate to True.([axis, out, keepdims])`argmax`
Return indices of the maximum values along the given axis.

([axis, out, keepdims])`argmin`
Return indices of the minimum values along the given axis.

(kth[, axis, kind, order])`argpartition`
Returns the indices that would partition this array.

([axis, kind, order])`argsort`
Returns the indices that would sort this array.

(dtype[, order, casting, subok, copy])`astype`
Copy of the array, cast to a specified type.

([inplace])`byteswap`
Swap the bytes of the array elements

(choices[, out, mode])`choose`
Use an index array to construct a new array from a set of choices.

([min, max, out])`clip`
Return an array whose values are limited to

`[min, max]`
.(condition[, axis, out])`compress`
Return selected slices of this array along given axis.

()`conj`
Complex-conjugate all elements.

Return the complex conjugate, element-wise.

([order])`copy`
Return a copy of the array.

([axis, dtype, out])`cumprod`
Return the cumulative product of the elements along the given axis.

([axis, dtype, out])`cumsum`
Return the cumulative sum of the elements along the given axis.

([offset, axis1, axis2])`diagonal`
Return specified diagonals.

(file)`dump`
Dump a pickle of the array to the specified file.

()`dumps`
Returns the pickle of the array as a string.

(value)`fill`
Fill the array with a scalar value.

([order])`flatten`
Return a copy of the array collapsed into one dimension.

(dtype[, offset])`getfield`
Returns a field of the given array as a certain type.

(*args)`item`
Copy an element of an array to a standard Python scalar and return it.

(*args)`itemset`
Insert scalar into an array (scalar is cast to array's dtype, if possible)

([axis, out, keepdims, initial, where])`max`
Return the maximum along a given axis.

([axis, dtype, out, keepdims, where])`mean`
Returns the average of the array elements along given axis.

([axis, out, keepdims, initial, where])`min`
Return the minimum along a given axis.

([new_order])`newbyteorder`
Return the array with the same data viewed with a different byte order.

()`nonzero`
Return the indices of the elements that are non-zero.

(kth[, axis, kind, order])`partition`
Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array.

([axis, dtype, out, keepdims, initial, ...])`prod`
Return the product of the array elements over the given axis

([axis, out, keepdims])`ptp`
Peak to peak (maximum - minimum) value along a given axis.

(indices, values[, mode])`put`
Set

`a.flat[n] = values[n]`
for all*n*in indices.([order])`ravel`
Return a flattened array.

(repeats[, axis])`repeat`
Repeat elements of an array.

(shape[, order])`reshape`
Returns an array containing the same data with a new shape.

(new_shape[, refcheck])`resize`
Change shape and size of array in-place.

([decimals, out])`round`
Return

*a*with each element rounded to the given number of decimals.(v[, side, sorter])`searchsorted`
Find indices where elements of v should be inserted in a to maintain order.

(val, dtype[, offset])`setfield`
Put a value into a specified place in a field defined by a data-type.

([write, align, uic])`setflags`
Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY, respectively.

([axis, kind, order])`sort`
Sort an array in-place.

([axis])`squeeze`
Remove axes of length one from

*a*.([axis, dtype, out, ddof, keepdims, where])`std`
Returns the standard deviation of the array elements along given axis.

([axis, dtype, out, keepdims, initial, where])`sum`
Return the sum of the array elements over the given axis.

(axis1, axis2)`swapaxes`
Return a view of the array with

*axis1*and*axis2*interchanged.(indices[, axis, out, mode])`take`
Return an array formed from the elements of

*a*at the given indices.([order])`tobytes`
Construct Python bytes containing the raw data bytes in the array.

(fid[, sep, format])`tofile`
Write array to a file as text or binary (default).

()`tolist`
Return the array as an

`a.ndim`
-levels deep nested list of Python scalars.([order])`tostring`
A compatibility alias for

, with exactly the same behavior.`tobytes`
([offset, axis1, axis2, dtype, out])`trace`
Return the sum along diagonals of the array.

(*axes)`transpose`
Returns a view of the array with axes transposed.

([axis, dtype, out, ddof, keepdims, where])`var`
Returns the variance of the array elements, along given axis.

([dtype][, type])`view`
New view of array with the same data.

**dot**# numpy.recarray.copy[#](#numpy-recarray-copy)
method

recarray.copy(*order='C'*)[#](#numpy.recarray.copy)
-
Return a copy of the array.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout of the copy. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*a*as closely as possible. (Note that this function andare very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)`numpy.copy`
See also

`numpy.copy`
Similar function with different default behavior

`numpy.copyto`
Notes

This function is the preferred method for creating an array copy. The function

is similar, but it defaults to using order ‘K’, and will not pass sub-classes through by default.`numpy.copy`
Examples

>>> x = np.array([[1,2,3],[4,5,6]], order='F')
>>> y = x.copy()
>>> x.fill(0)
>>> x array([[0, 0, 0], [0, 0, 0]])
>>> y array([[1, 2, 3], [4, 5, 6]])
>>> y.flags['C_CONTIGUOUS'] True# numpy.ma.dot[#](#numpy-ma-dot)
ma.dot(*a*,*b*,*strict=False*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7843-L7922)[#](#numpy.ma.dot)
-
Return the dot product of two arrays.

This function is the equivalent of

that takes masked values into account. Note that`numpy.dot`
*strict*and*out*are in different position than in the method version. In order to maintain compatibility with the corresponding method, it is recommended that the optional arguments be treated as keyword only. At some point that may be mandatory.Parameters:
-
**a, b**masked_array_like
Inputs arrays.

**strict**bool, optional
Whether masked data are propagated (True) or set to 0 (False) for the computation. Default is False. Propagating the mask means that if a masked value appears in a row or column, the whole row or column is considered masked.

**out**masked_array, optional
Output argument. This must have the exact kind that would be returned if it was not used. In particular, it must have the right type, must be C-contiguous, and its dtype must be the dtype that would be returned for

*dot(a,b)*. This is a performance feature. Therefore, if these conditions are not met, an exception is raised, instead of attempting to be flexible.New in version 1.10.2.

See also

`numpy.dot`
Equivalent function for ndarrays.

Examples

>>> a = np.ma.array([[1, 2, 3], [4, 5, 6]], mask=[[1, 0, 0], [0, 0, 0]]) >>> b = np.ma.array([[1, 2], [3, 4], [5, 6]], mask=[[1, 0], [0, 0], [0, 0]]) >>> np.ma.dot(a, b) masked_array( data=[[21, 26], [45, 64]], mask=[[False, False], [False, False]], fill_value=999999) >>> np.ma.dot(a, b, strict=True) masked_array( data=[[--, --], [--, 64]], mask=[[ True, True], [ True, False]], fill_value=999999)# numpy.random.weibull[#](#numpy-random-weibull)
random.weibull(*a*,*size=None*)[#](#numpy.random.weibull)
-
Draw samples from a Weibull distribution.

Draw samples from a 1-parameter Weibull distribution with the given shape parameter

*a*.\[X = (-ln(U))^{1/a}\]Here, U is drawn from the uniform distribution over (0,1].

The more common 2-parameter Weibull, including a scale parameter \(\lambda\) is just \(X = \lambda(-ln(U))^{1/a}\).

Note

New code should use the

method of a`weibull`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**a**float or array_like of floats
Shape parameter of the distribution. Must be nonnegative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`a`
is a scalar. Otherwise,`np.array(a).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Weibull distribution.

See also

`scipy.stats.weibull_max`
`scipy.stats.weibull_min`
`scipy.stats.genextreme`
`gumbel`
`random.Generator.weibull`
which should be used for new code.

Notes

The Weibull (or Type III asymptotic extreme value distribution for smallest values, SEV Type III, or Rosin-Rammler distribution) is one of a class of Generalized Extreme Value (GEV) distributions used in modeling extreme value problems. This class includes the Gumbel and Frechet distributions.

The probability density for the Weibull distribution is

\[p(x) = \frac{a} {\lambda}(\frac{x}{\lambda})^{a-1}e^{-(x/\lambda)^a},\]where \(a\) is the shape and \(\lambda\) the scale.

The function has its peak (the mode) at \(\lambda(\frac{a-1}{a})^{1/a}\).

When

`a = 1`
, the Weibull distribution reduces to the exponential distribution.References

[1]Waloddi Weibull, Royal Technical University, Stockholm, 1939 “A Statistical Theory Of The Strength Of Materials”, Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939, Generalstabens Litografiska Anstalts Forlag, Stockholm.

[2]Waloddi Weibull, “A Statistical Distribution Function of Wide Applicability”, Journal Of Applied Mechanics ASME Paper 1951.

[3]Wikipedia, “Weibull distribution”,

[https://en.wikipedia.org/wiki/Weibull_distribution](https://en.wikipedia.org/wiki/Weibull_distribution)Examples

Draw samples from the distribution:

>>> a = 5. # shape >>> s = np.random.weibull(a, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> x = np.arange(1,100.)/50. >>> def weib(x,n,a): ... return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)
>>> count, bins, ignored = plt.hist(np.random.weibull(5.,1000)) >>> x = np.arange(1,100.)/50. >>> scale = count.max()/weib(x, 1., 5.).max() >>> plt.plot(x, weib(x, 1., 5.)*scale) >>> plt.show()# numpy.polynomial.hermite_e.hermemul[#](#numpy-polynomial-hermite-e-hermemul)
polynomial.hermite_e.hermemul(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L441-L504)[#](#numpy.polynomial.hermite_e.hermemul)
-
Multiply one Hermite series by another.

Returns the product of two Hermite series

*c1***c2*. The arguments are sequences of coefficients, from lowest order “term” to highest, e.g., [1,2,3] represents the series`P_0 + 2*P_1 + 3*P_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Hermite series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Of Hermite series coefficients representing their product.

Notes

In general, the (polynomial) product of two C-series results in terms that are not in the Hermite polynomial basis set. Thus, to express the product as a Hermite series, it is necessary to “reproject” the product onto said basis set, which may produce “unintuitive” (but correct) results; see Examples section below.

Examples

>>> from numpy.polynomial.hermite_e import hermemul >>> hermemul([1, 2, 3], [0, 1, 2]) array([14., 15., 28., 7., 6.])# How to write a NumPy how-to[#](#how-to-write-a-numpy-how-to)
How-tos get straight to the point – they

-
answer a focused question, or

-
narrow a broad question into focused questions that the user can choose among.

## A stranger has asked for directions…[#](#a-stranger-has-asked-for-directions)
**“I need to refuel my car.”**
## Give a brief but explicit answer[#](#give-a-brief-but-explicit-answer)
-
“Three kilometers/miles, take a right at Hayseed Road, it’s on your left.”
Add helpful details for newcomers (“Hayseed Road”, even though it’s the only turnoff at three km/mi). But not irrelevant ones:

-
Don’t also give directions from Route 7.

-
Don’t explain why the town has only one filling station.

If there’s related background (tutorial, explanation, reference, alternative approach), bring it to the user’s attention with a link (“Directions from Route 7,” “Why so few filling stations?”).

## Delegate[#](#delegate)
-
“Three km/mi, take a right at Hayseed Road, follow the signs.”
If the information is already documented and succinct enough for a how-to, just link to it, possibly after an introduction (“Three km/mi, take a right”).

## If the question is broad, narrow and redirect it[#](#if-the-question-is-broad-narrow-and-redirect-it)

“I want to see the sights.”
The *See the sights* how-to should link to a set of narrower how-tos:

Find historic buildings

Find scenic lookouts

Find the town center

and these might in turn link to still narrower how-tos – so the town center page might link to

-
Find the court house

-
Find city hall

By organizing how-tos this way, you not only display the options for people who need to narrow their question, you also have provided answers for users who start with narrower questions (“I want to see historic buildings,” “Which way to city hall?”).

## If there are many steps, break them up[#](#if-there-are-many-steps-break-them-up)
If a how-to has many steps:

-
Consider breaking a step out into an individual how-to and linking to it.

-
Include subheadings. They help readers grasp what’s coming and return where they left off.

## Why write how-tos when there’s Stack Overflow, Reddit, Gitter…?[#](#why-write-how-tos-when-there-s-stack-overflow-reddit-gitter)
-
We have authoritative answers.

-
How-tos make the site less forbidding to non-experts.

-
How-tos bring people into the site and help them discover other information that’s here .

-
Creating how-tos helps us see NumPy usability through new eyes.

## Aren’t how-tos and tutorials the same thing?[#](#aren-t-how-tos-and-tutorials-the-same-thing)
People use the terms “how-to” and “tutorial” interchangeably, but we draw a
distinction, following Daniele Procida’s [taxonomy of documentation](https://documentation.divio.com/).

Documentation needs to meet users where they are. *How-tos* offer get-it-done
information; the user wants steps to copy and doesn’t necessarily want to
understand NumPy. *Tutorials* are warm-fuzzy information; the user wants a
feel for some aspect of NumPy (and again, may or may not care about deeper
knowledge).

We distinguish both tutorials and how-tos from *Explanations*, which are
deep dives intended to give understanding rather than immediate assistance,
and *References*, which give complete, authoritative data on some concrete
part of NumPy (like its API) but aren’t obligated to paint a broader picture.

For more on tutorials, see [Learn to write a NumPy tutorial](https://numpy.org/numpy-tutorials/content/tutorial-style-guide.html)

## Is this page an example of a how-to?[#](#is-this-page-an-example-of-a-how-to)
Yes – until the sections with question-mark headings; they explain rather than giving directions. In a how-to, those would be links.# F2PY and Windows Intel Fortran[#](#f2py-and-windows-intel-fortran)
As of NumPy 1.23, only the classic Intel compilers (`ifort`
) are supported.

Note

The licensing restrictions for beta software [have been relaxed](https://www.intel.com/content/www/us/en/developer/articles/release-notes/oneapi-fortran-compiler-release-notes.html) during
the transition to the LLVM backed `ifx/icc`
family of compilers.
However this document does not endorse the usage of Intel in downstream
projects due to the issues pertaining to [disassembly of components and
liability](https://software.sintel.com/content/www/us/en/develop/articles/end-user-license-agreement.html).

Neither the Python Intel installation nor the *Classic Intel C/C++
Compiler* are required.

The

[Intel Fortran Compilers](https://www.intel.com/content/www/us/en/developer/articles/tool/oneapi-standalone-components.html#inpage-nav-6-1)come in a combined installer providing both Classic and Beta versions; these also take around a gigabyte and a half or so.
We will consider the classic example of the generation of Fibonnaci numbers,
`fib1.f`
, given by:

```
C FILE: FIB1.F
SUBROUTINE FIB(A,N)
C
C CALCULATE FIRST N FIBONACCI NUMBERS
C
INTEGER N
REAL*8 A(N)
DO I=1,N
IF (I.EQ.1) THEN
A(I) = 0.0D0
ELSEIF (I.EQ.2) THEN
A(I) = 1.0D0
ELSE
A(I) = A(I-1) + A(I-2)
ENDIF
ENDDO
END
C END FILE FIB1.F
```
For `cmd.exe`
fans, using the Intel oneAPI command prompt is the easiest approach, as
it loads the required environment for both `ifort`
and `msvc`
. Helper batch
scripts are also provided.

```
# cmd.exe
"C:\Program Files (x86)\Intel\oneAPI\setvars.bat"
python -m numpy.f2py -c fib1.f -m fib1
python -c "import fib1; import numpy as np; a=np.zeros(8); fib1.fib(a); print(a)"
```
Powershell usage is a little less pleasant, and this configuration now works with MSVC as:

```
# Powershell
python -m numpy.f2py -c fib1.f -m fib1 --f77exec='C:\Program Files (x86)\Intel\oneAPI\compiler\latest\windows\bin\intel64\ifort.exe' --f90exec='C:\Program Files (x86)\Intel\oneAPI\compiler\latest\windows\bin\intel64\ifort.exe' -L'C:\Program Files (x86)\Intel\oneAPI\compiler\latest\windows\compiler\lib\ia32'
python -c "import fib1; import numpy as np; a=np.zeros(8); fib1.fib(a); print(a)"
# Alternatively, set environment and reload Powershell in one line
cmd.exe /k '"C:\Program Files (x86)\Intel\oneAPI\setvars.bat" && powershell'
python -m numpy.f2py -c fib1.f -m fib1
python -c "import fib1; import numpy as np; a=np.zeros(8); fib1.fib(a); print(a)"
```
Note that the actual path to your local installation of *ifort* may vary, and the command above will need to be updated accordingly.# Three ways to wrap - getting started[#](#three-ways-to-wrap-getting-started)
Wrapping Fortran or C functions to Python using F2PY consists of the following steps:

Creating the so-called

[signature file](signature-file.html)that contains descriptions of wrappers to Fortran or C functions, also called the signatures of the functions. For Fortran routines, F2PY can create an initial signature file by scanning Fortran source codes and tracking all relevant information needed to create wrapper functions.Optionally, F2PY-created signature files can be edited to optimize wrapper functions, which can make them “smarter” and more “Pythonic”.

F2PY reads a signature file and writes a Python C/API module containing Fortran/C/Python bindings.

F2PY compiles all sources and builds an extension module containing the wrappers.

In building the extension modules, F2PY uses

`numpy_distutils`
which supports a number of Fortran 77/90/95 compilers, including Gnu, Intel, Sun Fortran, SGI MIPSpro, Absoft, NAG, Compaq etc. For different build systems, see[F2PY and Build Systems](buildtools/index.html#f2py-bldsys).
Depending on your operating system, you may need to install the Python development headers (which provide the file

`Python.h`
) separately. In Linux Debian-based distributions this package should be called`python3-dev`
, in Fedora-based distributions it is`python3-devel`
. For macOS, depending how Python was installed, your mileage may vary. In Windows, the headers are typically installed already.
Depending on the situation, these steps can be carried out in a single composite command or step-by-step; in which case some steps can be omitted or combined with others.

Below, we describe three typical approaches of using F2PY. These can be read in order of increasing effort, but also cater to different access levels depending on whether the Fortran code can be freely modified.

The following example Fortran 77 code will be used for
illustration, save it as `fib1.f`
:

```
C FILE: FIB1.F
SUBROUTINE FIB(A,N)
C
C CALCULATE FIRST N FIBONACCI NUMBERS
C
INTEGER N
REAL*8 A(N)
DO I=1,N
IF (I.EQ.1) THEN
A(I) = 0.0D0
ELSEIF (I.EQ.2) THEN
A(I) = 1.0D0
ELSE
A(I) = A(I-1) + A(I-2)
ENDIF
ENDDO
END
C END FILE FIB1.F
```
Note

F2PY parses Fortran/C signatures to build wrapper functions to be used with Python. However, it is not a compiler, and does not check for additional errors in source code, nor does it implement the entire language standards. Some errors may pass silently (or as warnings) and need to be verified by the user.

## The quick way[#](#the-quick-way)
The quickest way to wrap the Fortran subroutine `FIB`
for use in Python is to
run

```
python -m numpy.f2py -c fib1.f -m fib1
```
or, alternatively, if the `f2py`
command-line tool is available,

```
f2py -c fib1.f -m fib1
```
Note

Because the `f2py`
command might not be available in all system, notably on
Windows, we will use the `python -m numpy.f2py`
command throughout this
guide.

This command compiles and wraps `fib1.f`
(`-c`
) to create the extension
module `fib1.so`
(`-m`
) in the current directory. A list of command line
options can be seen by executing `python -m numpy.f2py`
. Now, in Python the
Fortran subroutine `FIB`
is accessible via `fib1.fib`
:

```
>>> import numpy as np
>>> import fib1
>>> print(fib1.fib.__doc__)
fib(a,[n])
Wrapper for ``fib``.
Parameters
----------
a : input rank-1 array('d') with bounds (n)
Other Parameters
----------------
n : input int, optional
Default: len(a)
>>> a = np.zeros(8, 'd')
>>> fib1.fib(a)
>>> print(a)
[ 0. 1. 1. 2. 3. 5. 8. 13.]
```
Note

Note that F2PY recognized that the second argument

`n`
is the dimension of the first array argument`a`
. Since by default all arguments are input-only arguments, F2PY concludes that`n`
can be optional with the default value`len(a)`
.
One can use different values for optional

`n`
:>>> a1 = np.zeros(8, 'd') >>> fib1.fib(a1, 6) >>> print(a1) [ 0. 1. 1. 2. 3. 5. 0. 0.]
but an exception is raised when it is incompatible with the input array

`a`
:>>> fib1.fib(a, 10) Traceback (most recent call last): File "<stdin>", line 1, in <module> fib.error: (len(a)>=n) failed for 1st keyword n: fib:n=10 >>>
F2PY implements basic compatibility checks between related arguments in order to avoid unexpected crashes.

When a NumPy array that is

[Fortran](../glossary.html#term-Fortran-order)[contiguous](../glossary.html#term-contiguous)and has a`dtype`
corresponding to a presumed Fortran type is used as an input array argument, then its C pointer is directly passed to Fortran.Otherwise, F2PY makes a contiguous copy (with the proper

`dtype`
) of the input array and passes a C pointer of the copy to the Fortran subroutine. As a result, any possible changes to the (copy of) input array have no effect on the original argument, as demonstrated below:>>> a = np.ones(8, 'i') >>> fib1.fib(a) >>> print(a) [1 1 1 1 1 1 1 1]
Clearly, this is unexpected, as Fortran typically passes by reference. That the above example worked with

`dtype=float`
is considered accidental.F2PY provides an

`intent(inplace)`
attribute that modifies the attributes of an input array so that any changes made by the Fortran routine will be reflected in the input argument. For example, if one specifies the`intent(inplace) a`
directive (see[Attributes](signature-file.html#f2py-attributes)for details), then the example above would read:>>> a = np.ones(8, 'i') >>> fib1.fib(a) >>> print(a) [ 0. 1. 1. 2. 3. 5. 8. 13.]
However, the recommended way to have changes made by Fortran subroutine propagate to Python is to use the

`intent(out)`
attribute. That approach is more efficient and also cleaner.
The usage of

`fib1.fib`
in Python is very similar to using`FIB`
in Fortran. However, using*in situ*output arguments in Python is poor style, as there are no safety mechanisms in Python to protect against wrong argument types. When using Fortran or C, compilers discover any type mismatches during the compilation process, but in Python the types must be checked at runtime. Consequently, using*in situ*output arguments in Python may lead to difficult to find bugs, not to mention the fact that the codes will be less readable when all required type checks are implemented.
Though the approach to wrapping Fortran routines for Python discussed so far is very straightforward, it has several drawbacks (see the comments above). The drawbacks are due to the fact that there is no way for F2PY to determine the actual intention of the arguments; that is, there is ambiguity in distinguishing between input and output arguments. Consequently, F2PY assumes that all arguments are input arguments by default.

There are ways (see below) to remove this ambiguity by “teaching” F2PY about the true intentions of function arguments, and F2PY is then able to generate more explicit, easier to use, and less error prone wrappers for Fortran functions.

## The smart way[#](#the-smart-way)
If we want to have more control over how F2PY will treat the interface to our Fortran code, we can apply the wrapping steps one by one.

First, we create a signature file from

`fib1.f`
by running:python -m numpy.f2py fib1.f -m fib2 -h fib1.pyf
The signature file is saved to

`fib1.pyf`
(see the`-h`
flag) and its contents are shown below.! -*- f90 -*- python module fib2 ! in interface ! in :fib2 subroutine fib(a,n) ! in :fib2:fib1.f real*8 dimension(n) :: a integer optional,check(len(a)>=n),depend(a) :: n=len(a) end subroutine fib end interface end python module fib2 ! This file was auto-generated with f2py (version:2.28.198-1366). ! See http://cens.ioc.ee/projects/f2py2e/
Next, we’ll teach F2PY that the argument

`n`
is an input argument (using the`intent(in)`
attribute) and that the result, i.e., the contents of`a`
after calling the Fortran function`FIB`
, should be returned to Python (using the`intent(out)`
attribute). In addition, an array`a`
should be created dynamically using the size determined by the input argument`n`
(using the`depend(n)`
attribute to indicate this dependence relation).The contents of a suitably modified version of

`fib1.pyf`
(saved as`fib2.pyf`
) are as follows:! -*- f90 -*- python module fib2 interface subroutine fib(a,n) real*8 dimension(n),intent(out),depend(n) :: a integer intent(in) :: n end subroutine fib end interface end python module fib2
Finally, we build the extension module with

`numpy.distutils`
by running:python -m numpy.f2py -c fib2.pyf fib1.f
In Python:

```
>>> import fib2
>>> print(fib2.fib.__doc__)
a = fib(n)
Wrapper for ``fib``.
Parameters
----------
n : input int
Returns
-------
a : rank-1 array('d') with bounds (n)
>>> print(fib2.fib(8))
[ 0. 1. 1. 2. 3. 5. 8. 13.]
```
Note

The signature of

`fib2.fib`
now more closely corresponds to the intention of the Fortran subroutine`FIB`
: given the number`n`
,`fib2.fib`
returns the first`n`
Fibonacci numbers as a NumPy array. The new Python signature`fib2.fib`
also rules out the unexpected behaviour in`fib1.fib`
.
Note that by default, using a single

`intent(out)`
also implies`intent(hide)`
. Arguments that have the`intent(hide)`
attribute specified will not be listed in the argument list of a wrapper function.
For more details, see [Signature file](signature-file.html).

## The quick and smart way[#](#the-quick-and-smart-way)
The “smart way” of wrapping Fortran functions, as explained above, is suitable for wrapping (e.g. third party) Fortran codes for which modifications to their source codes are not desirable nor even possible.

However, if editing Fortran codes is acceptable, then the generation of an
intermediate signature file can be skipped in most cases. F2PY specific
attributes can be inserted directly into Fortran source codes using F2PY
directives. A F2PY directive consists of special comment lines (starting with
`Cf2py`
or `!f2py`
, for example) which are ignored by Fortran compilers but
interpreted by F2PY as normal lines.

Consider a modified version of the previous Fortran code with F2PY directives,
saved as `fib3.f`
:

```
C FILE: FIB3.F
SUBROUTINE FIB(A,N)
C
C CALCULATE FIRST N FIBONACCI NUMBERS
C
INTEGER N
REAL*8 A(N)
Cf2py intent(in) n
Cf2py intent(out) a
Cf2py depend(n) a
DO I=1,N
IF (I.EQ.1) THEN
A(I) = 0.0D0
ELSEIF (I.EQ.2) THEN
A(I) = 1.0D0
ELSE
A(I) = A(I-1) + A(I-2)
ENDIF
ENDDO
END
C END FILE FIB3.F
```
Building the extension module can be now carried out in one command:

```
python -m numpy.f2py -c -m fib3 fib3.f
```
Notice that the resulting wrapper to `FIB`
is as “smart” (unambiguous) as in
the previous case:

```
>>> import fib3
>>> print(fib3.fib.__doc__)
a = fib(n)
Wrapper for ``fib``.
Parameters
----------
n : input int
Returns
-------
a : rank-1 array('d') with bounds (n)
>>> print(fib3.fib(8))
[ 0. 1. 1. 2. 3. 5. 8. 13.]
```# Advanced F2PY use cases[#](#advanced-f2py-use-cases)
## Adding user-defined functions to F2PY generated modules[#](#adding-user-defined-functions-to-f2py-generated-modules)
User-defined Python C/API functions can be defined inside
signature files using `usercode`
and `pymethoddef`
statements
(they must be used inside the `python module`
block). For
example, the following signature file `spam.pyf`

```
! -*- f90 -*-
python module spam
usercode '''
static char doc_spam_system[] = "Execute a shell command.";
static PyObject *spam_system(PyObject *self, PyObject *args)
{
char *command;
int sts;
if (!PyArg_ParseTuple(args, "s", &command))
return NULL;
sts = system(command);
return Py_BuildValue("i", sts);
}
'''
pymethoddef '''
{"system", spam_system, METH_VARARGS, doc_spam_system},
'''
end python module spam
```
wraps the C library function `system()`
:

```
f2py -c spam.pyf
```
In Python this can then be used as:

```
>>> import spam
>>> status = spam.system('whoami')
pearu
>>> status = spam.system('blah')
sh: line 1: blah: command not found
```
## Adding user-defined variables[#](#adding-user-defined-variables)
The following example illustrates how to add user-defined variables to a F2PY
generated extension module by modifying the dictionary of a F2PY generated
module. Consider the following signature file (compiled with `f2py -c var.pyf`
):

```
! -*- f90 -*-
python module var
usercode '''
int BAR = 5;
'''
interface
usercode '''
PyDict_SetItemString(d,"BAR",PyInt_FromLong(BAR));
'''
end interface
end python module
```
Notice that the second `usercode`
statement must be defined inside
an `interface`
block and the module dictionary is available through
the variable `d`
(see `varmodule.c`
generated by `f2py var.pyf`
for
additional details).

Usage in Python:

```
>>> import var
>>> var.BAR
5
```
## Dealing with KIND specifiers[#](#dealing-with-kind-specifiers)
Currently, F2PY can handle only `<type spec>(kind=<kindselector>)`
declarations where `<kindselector>`
is a numeric integer (e.g. 1, 2,
4,…), but not a function call `KIND(..)`
or any other
expression. F2PY needs to know what would be the corresponding C type
and a general solution for that would be too complicated to implement.

However, F2PY provides a hook to overcome this difficulty, namely, users can define their own <Fortran type> to <C type> maps. For example, if Fortran 90 code contains:

```
REAL(kind=KIND(0.0D0)) ...
```
then create a mapping file containing a Python dictionary:

```
{'real': {'KIND(0.0D0)': 'double'}}
```
for instance.

Use the `--f2cmap`
command-line option to pass the file name to F2PY.
By default, F2PY assumes file name is `.f2py_f2cmap`
in the current
working directory.

More generally, the f2cmap file must contain a dictionary with items:

```
<Fortran typespec> : {<selector_expr>:<C type>}
```
that defines mapping between Fortran type:

```
<Fortran typespec>([kind=]<selector_expr>)
```
and the corresponding <C type>. The <C type> can be one of the following:

```
double
float
long_double
char
signed_char
unsigned_char
short
unsigned_short
int
long
long_long
unsigned
complex_float
complex_double
complex_long_double
string
```
For example, for a Fortran file `func1.f`
containing:

```
subroutine func1(n, x, res)
use, intrinsic :: iso_fortran_env, only: int64, real64
implicit none
integer(int64), intent(in) :: n
real(real64), intent(in) :: x(n)
real(real64), intent(out) :: res
Cf2py intent(hide) :: n
res = sum(x)
end
```
In order to convert `int64`
and `real64`
to valid `C`
data types,
a `.f2py_f2cmap`
file with the following content can be created in the current directory:

```
dict(real=dict(real64='double'), integer=dict(int64='long long'))
```
and create the module as usual. F2PY checks if a `.f2py_f2cmap`
file is present
in the current directory and will use it to map `KIND`
specifiers to `C`
data types.

```
f2py -c func1.f -m func1
```
Alternatively, the mapping file can be saved with any other name, for example
`mapfile.txt`
, and this information can be passed to F2PY by using the `--f2cmap`
option.

```
f2py -c func1.f -m func1 --f2cmap mapfile.txt
```
For more information, see F2Py source code `numpy/f2py/capi_maps.py`
.

## Character strings[#](#character-strings)
### Assumed length character strings[#](#assumed-length-character-strings)
In Fortran, assumed length character string arguments are declared as
`character*(*)`
or `character(len=*)`
, that is, the length of such
arguments are determined by the actual string arguments at runtime.
For `intent(in)`
arguments, this lack of length information poses no
problems for f2py to construct functional wrapper functions. However,
for `intent(out)`
arguments, the lack of length information is
problematic for f2py generated wrappers because there is no size
information available for creating memory buffers for such arguments
and F2PY assumes the length is 0. Depending on how the length of
assumed length character strings are specified, there exist ways to
workaround this problem, as exemplified below.

If the length of the `character*(*)`
output argument is determined
by the state of other input arguments, the required connection can be
established in a signature file or within a f2py-comment by adding an
extra declaration for the corresponding argument that specifies the
length in character selector part. For example, consider a Fortran
file `asterisk1.f90`
:

```
subroutine foo1(s)
character*(*), intent(out) :: s
!f2py character(f2py_len=12) s
s = "123456789A12"
end subroutine foo1
```
Compile it with `f2py -c asterisk1.f90 -m asterisk1`
and then in Python:

```
>>> import asterisk1
>>> asterisk1.foo1()
b'123456789A12'
```
Notice that the extra declaration `character(f2py_len=12) s`
is
interpreted only by f2py and in the `f2py_len=`
specification one
can use C-expressions as a length value.

In the following example:

```
subroutine foo2(s, n)
character(len=*), intent(out) :: s
integer, intent(in) :: n
!f2py character(f2py_len=n), depend(n) :: s
s = "123456789A123456789B"(1:n)
end subroutine foo2
```
the length of the output assumed length string depends on an input
argument `n`
, after wrapping with F2PY, in Python:

```
>>> import asterisk
>>> asterisk.foo2(2)
b'12'
>>> asterisk.foo2(12)
b'123456789A12'
>>>
```# F2PY examples[#](#f2py-examples)
Below are some examples of F2PY usage. This list is not comprehensive, but can be used as a starting point when wrapping your own code.

## F2PY walkthrough: a basic extension module[#](#f2py-walkthrough-a-basic-extension-module)
### Creating source for a basic extension module[#](#creating-source-for-a-basic-extension-module)
Consider the following subroutine, contained in a file named `add.f`

```
C
SUBROUTINE ZADD(A,B,C,N)
C
DOUBLE COMPLEX A(*)
DOUBLE COMPLEX B(*)
DOUBLE COMPLEX C(*)
INTEGER N
DO 20 J = 1, N
C(J) = A(J)+B(J)
20 CONTINUE
END
```
This routine simply adds the elements in two contiguous arrays and places the result in a third. The memory for all three arrays must be provided by the calling routine. A very basic interface to this routine can be automatically generated by f2py:

```
python -m numpy.f2py -m add add.f
```
This command will produce an extension module named `addmodule.c`
in the
current directory. This extension module can now be compiled and used from
Python just like any other extension module.

### Creating a compiled extension module[#](#creating-a-compiled-extension-module)
Note

This usage depends heavily on `numpy.distutils`
, see [F2PY and Build Systems](buildtools/index.html#f2py-bldsys)
for more details.

You can also get f2py to both compile `add.f`
along with the produced
extension module leaving only a shared-library extension file that can
be imported from Python:

```
python -m numpy.f2py -c -m add add.f
```
This command produces a Python extension module compatible with your platform.
This module may then be imported from Python. It will contain a method for each
subroutine in `add`
. The docstring of each method contains information about
how the module method may be called:

```
>>> import add
>>> print(add.zadd.__doc__)
zadd(a,b,c,n)
Wrapper for ``zadd``.
Parameters
----------
a : input rank-1 array('D') with bounds (*)
b : input rank-1 array('D') with bounds (*)
c : input rank-1 array('D') with bounds (*)
n : input int
```
### Improving the basic interface[#](#improving-the-basic-interface)
The default interface is a very literal translation of the Fortran code into
Python. The Fortran array arguments are converted to NumPy arrays and the
integer argument should be mapped to a `C`
integer. The interface will attempt
to convert all arguments to their required types (and shapes) and issue an error
if unsuccessful. However, because `f2py`
knows nothing about the semantics of
the arguments (such that `C`
is an output and `n`
should really match the
array sizes), it is possible to abuse this function in ways that can cause
Python to crash. For example:

```
>>> add.zadd([1, 2, 3], [1, 2], [3, 4], 1000)
```
will cause a program crash on most systems. Under the hood, the lists are being
converted to arrays but then the underlying `add`
function is told to cycle
way beyond the borders of the allocated memory.

In order to improve the interface, `f2py`
supports directives. This is
accomplished by constructing a signature file. It is usually best to start from
the interfaces that `f2py`
produces in that file, which correspond to the
default behavior. To get `f2py`
to generate the interface file use the `-h`
option:

```
python -m numpy.f2py -h add.pyf -m add add.f
```
This command creates the `add.pyf`
file in the current directory. The section
of this file corresponding to `zadd`
is:

```
subroutine zadd(a,b,c,n) ! in :add:add.f
double complex dimension(*) :: a
double complex dimension(*) :: b
double complex dimension(*) :: c
integer :: n
end subroutine zadd
```
By placing intent directives and checking code, the interface can be cleaned up quite a bit so the Python module method is both easier to use and more robust to malformed inputs.

```
subroutine zadd(a,b,c,n) ! in :add:add.f
double complex dimension(n) :: a
double complex dimension(n) :: b
double complex intent(out),dimension(n) :: c
integer intent(hide),depend(a) :: n=len(a)
end subroutine zadd
```
The intent directive, intent(out) is used to tell f2py that `c`
is
an output variable and should be created by the interface before being
passed to the underlying code. The intent(hide) directive tells f2py
to not allow the user to specify the variable, `n`
, but instead to
get it from the size of `a`
. The depend( `a`
) directive is
necessary to tell f2py that the value of n depends on the input a (so
that it won’t try to create the variable n until the variable a is
created).

After modifying `add.pyf`
, the new Python module file can be generated
by compiling both `add.f`
and `add.pyf`
:

```
python -m numpy.f2py -c add.pyf add.f
```
The new interface’s docstring is:

```
>>> import add
>>> print(add.zadd.__doc__)
c = zadd(a,b)
Wrapper for ``zadd``.
Parameters
----------
a : input rank-1 array('D') with bounds (n)
b : input rank-1 array('D') with bounds (n)
Returns
-------
c : rank-1 array('D') with bounds (n)
```
Now, the function can be called in a much more robust way:

```
>>> add.zadd([1, 2, 3], [4, 5, 6])
array([5.+0.j, 7.+0.j, 9.+0.j])
```
Notice the automatic conversion to the correct format that occurred.

### Inserting directives in Fortran source[#](#inserting-directives-in-fortran-source)
The robust interface of the previous section can also be generated automatically by placing the variable directives as special comments in the original Fortran code.

Note

For projects where the Fortran code is being actively developed, this may be preferred.

Thus, if the source code is modified to contain:

```
C
SUBROUTINE ZADD(A,B,C,N)
C
CF2PY INTENT(OUT) :: C
CF2PY INTENT(HIDE) :: N
CF2PY DOUBLE COMPLEX :: A(N)
CF2PY DOUBLE COMPLEX :: B(N)
CF2PY DOUBLE COMPLEX :: C(N)
DOUBLE COMPLEX A(*)
DOUBLE COMPLEX B(*)
DOUBLE COMPLEX C(*)
INTEGER N
DO 20 J = 1, N
C(J) = A(J) + B(J)
20 CONTINUE
END
```
Then, one can compile the extension module using:

```
python -m numpy.f2py -c -m add add.f
```
The resulting signature for the function add.zadd is exactly the same
one that was created previously. If the original source code had
contained `A(N)`
instead of `A(*)`
and so forth with `B`
and `C`
,
then nearly the same interface can be obtained by placing the
`INTENT(OUT) :: C`
comment line in the source code. The only difference
is that `N`
would be an optional input that would default to the length
of `A`
.

## A filtering example[#](#a-filtering-example)
This example shows a function that filters a two-dimensional array of double precision floating-point numbers using a fixed averaging filter. The advantage of using Fortran to index into multi-dimensional arrays should be clear from this example.

```
C
SUBROUTINE DFILTER2D(A,B,M,N)
C
DOUBLE PRECISION A(M,N)
DOUBLE PRECISION B(M,N)
INTEGER N, M
CF2PY INTENT(OUT) :: B
CF2PY INTENT(HIDE) :: N
CF2PY INTENT(HIDE) :: M
DO 20 I = 2,M-1
DO 40 J = 2,N-1
B(I,J) = A(I,J) +
& (A(I-1,J)+A(I+1,J) +
& A(I,J-1)+A(I,J+1) )*0.5D0 +
& (A(I-1,J-1) + A(I-1,J+1) +
& A(I+1,J-1) + A(I+1,J+1))*0.25D0
40 CONTINUE
20 CONTINUE
END
```
This code can be compiled and linked into an extension module named filter using:

```
python -m numpy.f2py -c -m filter filter.f
```
This will produce an extension module in the current directory with a method
named `dfilter2d`
that returns a filtered version of the input.

`depends`
keyword example[#](#depends-keyword-example)
Consider the following code, saved in the file `myroutine.f90`
:

```
subroutine s(n, m, c, x)
implicit none
integer, intent(in) :: n, m
real(kind=8), intent(out), dimension(n,m) :: x
real(kind=8), intent(in) :: c(:)
x = 0.0d0
x(1, 1) = c(1)
end subroutine s
```
Wrapping this with `python -m numpy.f2py -c myroutine.f90 -m myroutine`
, we
can do the following in Python:

```
>>> import numpy as np
>>> import myroutine
>>> x = myroutine.s(2, 3, np.array([5, 6, 7]))
>>> x
array([[5., 0., 0.],
[0., 0., 0.]])
```
Now, instead of generating the extension module directly, we will create a signature file for this subroutine first. This is a common pattern for multi-step extension module generation. In this case, after running

```
python -m numpy.f2py myroutine.f90 -h myroutine.pyf
```
the following signature file is generated:

```
! -*- f90 -*-
! Note: the context of this file is case sensitive.
python module myroutine ! in
interface ! in :myroutine
subroutine s(n,m,c,x) ! in :myroutine:myroutine.f90
integer intent(in) :: n
integer intent(in) :: m
real(kind=8) dimension(:),intent(in) :: c
real(kind=8) dimension(n,m),intent(out),depend(m,n) :: x
end subroutine s
end interface
end python module myroutine
! This file was auto-generated with f2py (version:1.23.0.dev0+120.g4da01f42d).
! See:
! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e
```
Now, if we run `python -m numpy.f2py -c myroutine.pyf myroutine.f90`
we see an
error; note that the signature file included a `depend(m,n)`
statement for
`x`
which is not necessary. Indeed, editing the file above to read

```
! -*- f90 -*-
! Note: the context of this file is case sensitive.
python module myroutine ! in
interface ! in :myroutine
subroutine s(n,m,c,x) ! in :myroutine:myroutine.f90
integer intent(in) :: n
integer intent(in) :: m
real(kind=8) dimension(:),intent(in) :: c
real(kind=8) dimension(n,m),intent(out) :: x
end subroutine s
end interface
end python module myroutine
! This file was auto-generated with f2py (version:1.23.0.dev0+120.g4da01f42d).
! See:
! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e
```
and running `f2py -c myroutine.pyf myroutine.f90`
yields correct results.# Using via `numpy.distutils`
[#](#using-via-numpy-distutils)
`numpy.distutils`
[ numpy.distutils](../../reference/distutils.html#module-numpy.distutils) is part of NumPy, and extends the standard Python
`distutils`
module to deal with Fortran sources and F2PY signature files, e.g.
compile Fortran sources, call F2PY to construct extension modules, etc.## Extensions to `distutils`
[#](#extensions-to-distutils)
[ numpy.distutils](../../reference/distutils.html#module-numpy.distutils) extends
`distutils`
with the following features:class argument`Extension`
`sources`
may contain Fortran source files. In addition, the list`sources`
may contain at most one F2PY signature file, and in this case, the name of an Extension module must match with the`<modulename>`
used in signature file. It is assumed that an F2PY signature file contains exactly one`python module`
block.If

`sources`
do not contain a signature file, then F2PY is used to scan Fortran source files to construct wrappers to the Fortran codes.Additional options to the F2PY executable can be given using the

class argument`Extension`
`f2py_options`
.
The following new

`distutils`
commands are defined:`build_src`
to construct Fortran wrapper extension modules, among many other things.

`config_fc`
to change Fortran compiler options.

Additionally, the

`build_ext`
and`build_clib`
commands are also enhanced to support Fortran sources.Run

python <setup.py file> config_fc build_src build_ext --help
to see available options for these commands.

When building Python packages containing Fortran sources, one can choose different Fortran compilers by using the

`build_ext`
command option`--fcompiler=<Vendor>`
. Here`<Vendor>`
can be one of the following names (on`linux`
systems):absoft compaq fujitsu g95 gnu gnu95 intel intele intelem lahey nag nagfor nv pathf95 pg vast
See

`numpy_distutils/fcompiler.py`
for an up-to-date list of supported compilers for different platforms, or runpython -m numpy.f2py -c --help-fcompiler# Setting up and using your development environment[#](#setting-up-and-using-your-development-environment)
## Recommended development setup[#](#recommended-development-setup)
Since NumPy contains parts written in C and Cython that need to be
compiled before use, make sure you have the necessary compilers and Python
development headers installed - see [Building from source](../user/building.html#building-from-source). Building
NumPy as of version `1.17`
requires a C99 compliant compiler.

Having compiled code also means that importing NumPy from the development
sources needs some additional steps, which are explained below. For the rest
of this chapter we assume that you have set up your git repo as described in
[Git for development](gitwash/index.html#using-git).

Note

If you are having trouble building NumPy from source or setting up your local development environment, you can try to build NumPy with GitHub Codespaces. It allows you to create the correct development environment right in your browser, reducing the need to install local development environments and deal with incompatible dependencies.

If you have good internet connectivity and want a temporary set-up, it is
often faster to work on NumPy in a Codespaces environment. For documentation
on how to get started with Codespaces, see
[the Codespaces docs](https://docs.github.com/en/codespaces).
When creating a codespace for the `numpy/numpy`
repository, the default
2-core machine type works; 4-core will build and work a bit faster (but of
course at a cost of halving your number of free usage hours). Once your
codespace has started, you can run `conda activate numpy-dev`
and your
development environment is completely set up - you can then follow the
relevant parts of the NumPy documentation to build, test, develop, write
docs, and contribute to NumPy.

## Using virtual environments[#](#using-virtual-environments)
A frequently asked question is “How do I set up a development version of NumPy in parallel to a released version that I use to do my job/research?”.

One simple way to achieve this is to install the released version in site-packages, by using pip or conda for example, and set up the development version in a virtual environment.

If you use conda, we recommend creating a separate virtual environment for
numpy development using the `environment.yml`
file in the root of the repo
(this will create the environment and install all development dependencies at
once):

```
$ conda env create -f environment.yml # `mamba` works too for this command
$ conda activate numpy-dev
```
If you installed Python some other way than conda, first install
[virtualenv](http://www.virtualenv.org/) (optionally use [virtualenvwrapper](http://www.doughellmann.com/projects/virtualenvwrapper/)), then create your
virtualenv (named `numpy-dev`
here) with:

```
$ virtualenv numpy-dev
```
Now, whenever you want to switch to the virtual environment, you can use the
command `source numpy-dev/bin/activate`
, and `deactivate`
to exit from the
virtual environment and back to your previous shell.

## Testing builds[#](#testing-builds)
Before running the tests, first install the test dependencies:

```
$ python -m pip install -r test_requirements.txt
$ python -m pip install asv # only for running benchmarks
```
To build the development version of NumPy and run tests, spawn
interactive shells with the Python import paths properly set up etc., use the
[spin](https://github.com/scientific-python/spin) utility. To run tests, do
one of:

```
$ spin test -v
$ spin test numpy/random # to run the tests in a specific module
$ spin test -v -t numpy/core/tests/test_nditer.py::test_iter_c_order
```
This builds NumPy first, so the first time it may take a few minutes.

You can also use `spin bench`
for benchmarking. See `spin --help`
for more
command line options.

Note

If the above commands result in `RuntimeError: Cannot parse version 0+untagged.xxxxx`
,
run `git pull upstream main --tags`
.

Additional arguments may be forwarded to `pytest`
by passing the extra
arguments after a bare `--`
. For example, to run a test method with the
`--pdb`
flag forwarded to the target, run the following:

```
$ spin test -t numpy/tests/test_scripts.py::test_f2py -- --pdb
```
You can also [match test names using python operators](https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests) by passing the `-k`
argument to pytest:

```
$ spin test -v -t numpy/core/tests/test_multiarray.py -- -k "MatMul and not vector"
```
Note

Remember that all tests of NumPy should pass before committing your changes.

Note

Some of the tests in the test suite require a large amount of memory, and are skipped if your system does not have enough.

## Other build options[#](#other-build-options)
For more options including selecting compilers, setting custom compiler flags
and controlling parallelism, see [Compiler selection and customizing a build](https://docs.scipy.org/doc/scipy/building/compilers_and_options.html)
(from the SciPy documentation.)

## Running tests[#](#running-tests)
Besides using `spin`
, there are various ways to run the tests. Inside
the interpreter, tests can be run like this:

```
>>> np.test()
>>> np.test('full') # Also run tests marked as slow
>>> np.test('full', verbose=2) # Additionally print test name/file
An example of a successful test :
``4686 passed, 362 skipped, 9 xfailed, 5 warnings in 213.99 seconds``
```
Or a similar way from the command line:

```
$ python -c "import numpy as np; np.test()"
```
Tests can also be run with `pytest numpy`
, however then the NumPy-specific
plugin is not found which causes strange side effects.

Running individual test files can be useful; it’s much faster than running the
whole test suite or that of a whole module (example: `np.random.test()`
).
This can be done with:

```
$ python path_to_testfile/test_file.py
```
That also takes extra arguments, like `--pdb`
which drops you into the Python
debugger when a test fails or an exception is raised.

Running tests with [tox](https://tox.readthedocs.io/) is also supported. For example, to build NumPy and
run the test suite with Python 3.9, use:

```
$ tox -e py39
```
For more extensive information, see [Testing Guidelines](../reference/testing.html#testing-guidelines).

Note: do not run the tests from the root directory of your numpy git repo without `spin`
,
that will result in strange test errors.

## Running Linting[#](#running-linting)
Lint checks can be performed on newly added lines of Python code.

Install all dependent packages using pip:

```
$ python -m pip install -r linter_requirements.txt
```
To run lint checks before committing new code, run:

```
$ python tools/linter.py
```
To check all changes in newly added Python code of current branch with target branch, run:

```
$ python tools/linter.py --branch main
```
If there are no errors, the script exits with no message. In case of errors, check the error message for details:

```
$ python tools/linter.py --branch main
./numpy/core/tests/test_scalarmath.py:34:5: E303 too many blank lines (3)
1 E303 too many blank lines (3)
```
It is advisable to run lint checks before pushing commits to a remote branch since the linter runs as part of the CI pipeline.

For more details on Style Guidelines:

## Rebuilding & cleaning the workspace[#](#rebuilding-cleaning-the-workspace)
Rebuilding NumPy after making changes to compiled code can be done with the
same build command as you used previously - only the changed files will be
re-built. Doing a full build, which sometimes is necessary, requires cleaning
the workspace first. The standard way of doing this is (*note: deletes any
uncommitted files!*):

```
$ git clean -xdf
```
When you want to discard all changes and go back to the last commit in the repo, use one of:

```
$ git checkout .
$ git reset --hard
```
## Debugging[#](#debugging)
Another frequently asked question is “How do I debug C code inside NumPy?”. First, ensure that you have gdb installed on your system with the Python extensions (often the default on Linux). You can see which version of Python is running inside gdb to verify your setup:

```
(gdb) python
>import sys
>print(sys.version_info)
>end
sys.version_info(major=3, minor=7, micro=0, releaselevel='final', serial=0)
```
Most python builds do not include debug symbols and are built with compiler
optimizations enabled. To get the best debugging experience using a debug build
of Python is encouraged, see [Advanced debugging tools](development_advanced_debugging.html#advanced-debugging).

Next you need to write a Python script that invokes the C code whose execution
you want to debug. For instance `mytest.py`
:

```
import numpy as np
x = np.arange(5)
np.empty_like(x)
```
Now, you can run:

```
$ spin gdb mytest.py
```
And then in the debugger:

```
(gdb) break array_empty_like
(gdb) run
```
The execution will now stop at the corresponding C function and you can step
through it as usual. A number of useful Python-specific commands are available.
For example to see where in the Python code you are, use `py-list`
, to see the
python traceback, use `py-bt`
. For more details, see
[DebuggingWithGdb](https://wiki.python.org/moin/DebuggingWithGdb). Here are some commonly used commands:

-
`list`
: List specified function or line.
-
`next`
: Step program, proceeding through subroutine calls.
-
`step`
: Continue program being debugged, after signal or breakpoint.
-
Rich support for Python debugging requires that the `python-gdb.py`
script
distributed with Python is installed in a path where gdb can find it. If you
installed your Python build from your system package manager, you likely do
not need to manually do anything. However, if you built Python from source,
you will likely need to create a `.gdbinit`
file in your home directory
pointing gdb at the location of your Python installation. For example, a
version of python installed via [pyenv](https://github.com/pyenv/pyenv)
needs a `.gdbinit`
file with the following contents:

```
add-auto-load-safe-path ~/.pyenv
```
Building NumPy with a Python built with debug support (on Linux distributions
typically packaged as `python-dbg`
) is highly recommended.

## Understanding the code & getting started[#](#understanding-the-code-getting-started)
The best strategy to better understand the code base is to pick something you want to change and start reading the code to figure out how it works. When in doubt, you can ask questions on the mailing list. It is perfectly okay if your pull requests aren’t perfect, the community is always happy to help. As a volunteer project, things do sometimes get dropped and it’s totally fine to ping us if something has sat without a response for about two to four weeks.

So go ahead and pick something that annoys or confuses you about NumPy, experiment with the code, hang around for discussions or go through the reference documents to try to fix it. Things will fall in place and soon you’ll have a pretty good understanding of the project as a whole. Good Luck!# Building the NumPy API and reference docs[#](#building-the-numpy-api-and-reference-docs)
If you only want to get the documentation, note that pre-built versions can be found at

in several different formats.

## Development environments[#](#development-environments)
Before proceeding further it should be noted that the documentation is built
with the `make`
tool, which is not natively available on Windows. MacOS or
Linux users can jump to [Prerequisites](#how-todoc-prerequisites). It is recommended for
Windows users to set up their development environment on
GitHub Codespaces (see [Recommended development setup](development_environment.html#recommended-development-setup)) or
[Windows Subsystem for Linux (WSL)](https://learn.microsoft.com/en-us/windows/wsl/install).
WSL is a good option for a persistent local set-up.

## Prerequisites[#](#prerequisites)
Building the NumPy documentation and API reference requires the following:

### NumPy[#](#numpy)
Since large parts of the main documentation are obtained from NumPy via
`import numpy`
and examining the docstrings, you will need to first
[build](development_environment.html#development-environment) and install it so that the correct version is
imported.
NumPy has to be re-built and re-installed every time you fetch the latest version of the
repository, before generating the documentation. This ensures that the NumPy version and
the git repository version are in sync.

Note that you can e.g. install NumPy to a temporary location and set
the PYTHONPATH environment variable appropriately.
Alternatively, if using Python virtual environments (via e.g. `conda`
,
`virtualenv`
or the `venv`
module), installing NumPy into a
new virtual environment is recommended.

### Dependencies[#](#dependencies)
All of the necessary dependencies for building the NumPy docs except for
[Doxygen](https://www.doxygen.nl/index.html) can be installed with:

```
pip install -r doc_requirements.txt
```
We currently use [Sphinx](http://www.sphinx-doc.org/) along with [Doxygen](https://www.doxygen.nl/index.html) for generating the API and
reference documentation for NumPy. In addition, building the documentation
requires the Sphinx extension *plot_directive*, which is shipped with
[Matplotlib](https://matplotlib.org/stable/index.html). We also use [numpydoc](https://numpydoc.readthedocs.io/en/latest/index.html) to render docstrings in
the generated API documentation. [SciPy](https://docs.scipy.org/doc/scipy/index.html)
is installed since some parts of the documentation require SciPy functions.

For installing [Doxygen](https://www.doxygen.nl/index.html), please check the official
[download](https://www.doxygen.nl/download.html#srcbin) and
[installation](https://www.doxygen.nl/manual/install.html) pages, or if you
are using Linux then you can install it through your distribution package manager.

Note

Try to install a newer version of [Doxygen](https://www.doxygen.nl/index.html) > 1.8.10 otherwise you may get some
warnings during the build.

### Submodules[#](#submodules)
If you obtained NumPy via git, also get the git submodules that contain additional parts required for building the documentation:

```
git submodule update --init
```
## Instructions[#](#instructions)
Now you are ready to generate the docs, so write:

```
spin docs
```
This will build NumPy from source if you haven’t already, and run Sphinx to
build the `html`
docs. If all goes well, this will generate a `build/html`
subdirectory in the `/doc`
directory, containing the built documentation.

The documentation for NumPy distributed at [https://numpy.org/doc](https://numpy.org/doc) in html and
pdf format is also built with `make dist`
. See [HOWTO RELEASE](https://github.com/numpy/numpy/blob/main/doc/HOWTO_RELEASE.rst) for details
on how to update [https://numpy.org/doc](https://numpy.org/doc).# How to contribute to the NumPy documentation[#](#how-to-contribute-to-the-numpy-documentation)
This guide will help you decide what to contribute and how to submit it to the official NumPy documentation.

## Documentation team meetings[#](#documentation-team-meetings)
The NumPy community has set a firm goal of improving its documentation. We
hold regular documentation meetings on Zoom (dates are announced on the
[numpy-discussion mailing list](https://mail.python.org/mailman/listinfo/numpy-discussion)), and everyone
is welcome. Reach out if you have questions or need
someone to guide you through your first steps – we’re happy to help.
Minutes are taken [on hackmd.io](https://hackmd.io/oB_boakvRqKR-_2jRV-Qjg)
and stored in the [NumPy Archive repository](https://github.com/numpy/archive).

## What’s needed[#](#what-s-needed)
The [NumPy Documentation](../index.html#numpy-docs-mainpage) has the details covered.
API reference documentation is generated directly from
[docstrings](https://www.python.org/dev/peps/pep-0257/) in the code when the
documentation is [built](howto_build_docs.html#howto-build-docs). Although we have mostly
complete reference documentation for each function and class exposed to users,
there is a lack of usage examples for some of them.

What we lack are docs with broader scope – tutorials, how-tos, and explanations. Reporting defects is another way to contribute. We discuss both.

## Contributing fixes[#](#contributing-fixes)
We’re eager to hear about and fix doc defects. But to attack the biggest problems we end up having to defer or overlook some bug reports. Here are the best defects to go after.

Top priority goes to **technical inaccuracies** – a docstring missing a
parameter, a faulty description of a function/parameter/method, and so on.
Other “structural” defects like broken links also get priority. All these fixes
are easy to confirm and put in place. You can submit
a [pull request (PR)](https://numpy.org/devdocs/dev/index.html#devindex)
with the fix, if you know how to do that; otherwise please [open an issue](https://github.com/numpy/numpy/issues).

**Typos and misspellings** fall on a lower rung; we welcome hearing about them
but may not be able to fix them promptly. These too can be handled as pull
requests or issues.
Obvious **wording** mistakes (like leaving out a “not”) fall into the typo
category, but other rewordings – even for grammar – require a judgment call,
which raises the bar. Test the waters by first presenting the fix as an issue.

Some functions/objects like numpy.ndarray.transpose, numpy.array etc. defined in
C-extension modules have their docstrings defined separately in [_add_newdocs.py](https://github.com/numpy/numpy/blob/main/numpy/core/_add_newdocs.py)

## Contributing new pages[#](#contributing-new-pages)
Your frustrations using our documents are our best guide to what needs fixing.

If you write a missing doc you join the front line of open source, but it’s
a meaningful contribution just to let us know what’s missing. If you want to
compose a doc, run your thoughts by the [mailing list](https://mail.python.org/mailman/listinfo/numpy-discussion) for further
ideas and feedback. If you want to alert us to a gap,
[open an issue](https://github.com/numpy/numpy/issues). See
[this issue](https://github.com/numpy/numpy/issues/15760) for an example.

If you’re looking for subjects, our formal roadmap for documentation is a
*NumPy Enhancement Proposal (NEP)*,
[NEP 44 - Restructuring the NumPy Documentation](https://www.numpy.org/neps/nep-0044-restructuring-numpy-docs).
It identifies areas where our docs need help and lists several
additions we’d like to see, including [Jupyter notebooks](#numpy-tutorials).

### Documentation framework[#](#documentation-framework)
There are formulas for writing useful documents, and four formulas
cover nearly everything. There are four formulas because there are four
categories of document – `tutorial`
, `how-to guide`
, `explanation`
,
and `reference`
. The insight that docs divide up this way belongs to
Daniele Procida and his [Diátaxis Framework](https://diataxis.fr/). When you
begin a document or propose one, have in mind which of these types it will be.

### NumPy tutorials[#](#numpy-tutorials)
In addition to the documentation that is part of the NumPy source tree, you can
submit content in Jupyter Notebook format to the
[NumPy Tutorials](https://numpy.org/numpy-tutorials) page. This
set of tutorials and educational materials is meant to provide high-quality
resources by the NumPy project, both for self-learning and for teaching classes
with. These resources are developed in a separate GitHub repository,
[numpy-tutorials](https://github.com/numpy/numpy-tutorials), where you can
check out existing notebooks, open issues to suggest new topics or submit your
own tutorials as pull requests.

### More on contributing[#](#more-on-contributing)
Don’t worry if English is not your first language, or if you can only come up with a rough draft. Open source is a community effort. Do your best – we’ll help fix issues.

Images and real-life data make text more engaging and powerful, but be sure what you use is appropriately licensed and available. Here again, even a rough idea for artwork can be polished by others.

For now, the only data formats accepted by NumPy are those also used by other Python scientific libraries like pandas, SciPy, or Matplotlib. We’re developing a package to accept more formats; contact us for details.

NumPy documentation is kept in the source code tree. To get your document
into the docbase you must download the tree, [build it](howto_build_docs.html#howto-build-docs), and submit a pull request. If GitHub and pull requests
are new to you, check our [Contributor Guide](index.html#devindex).

Our markup language is reStructuredText (rST), which is more elaborate than
Markdown. Sphinx, the tool many Python projects use to build and link project
documentation, converts the rST into HTML and other formats. For more on
rST, see the [Quick reStructuredText Guide](https://docutils.sourceforge.io/docs/user/rst/quickref.html) or the
[reStructuredText Primer](http://www.sphinx-doc.org/en/stable/usage/restructuredtext/basics.html)

## Contributing indirectly[#](#contributing-indirectly)
If you run across outside material that would be a useful addition to the
NumPy docs, let us know by [opening an issue](https://github.com/numpy/numpy/issues).

You don’t have to contribute here to contribute to NumPy. You’ve contributed if you write a tutorial on your blog, create a YouTube video, or answer questions on Stack Overflow and other sites.

## Documentation style[#](#documentation-style)
### User documentation[#](#user-documentation)
In general, we follow the

[Google developer documentation style guide](https://developers.google.com/style)for the User Guide.
NumPy style governs cases where:

Google has no guidance, or

We prefer not to use the Google style

Our current rules:

We pluralize

*index*as*indices*rather than[indexes](https://developers.google.com/style/word-list#letter-i), following the precedent of.`numpy.indices`
For consistency we also pluralize

*matrix*as*matrices*.
Grammatical issues inadequately addressed by the NumPy or Google rules are decided by the section on “Grammar and Usage” in the most recent edition of the

[Chicago Manual of Style](https://en.wikipedia.org/wiki/The_Chicago_Manual_of_Style).
We welcome being

[alerted](https://github.com/numpy/numpy/issues)to cases we should add to the NumPy style rules.
### Docstrings[#](#docstring-intro)
When using [Sphinx](http://www.sphinx-doc.org/) in combination with the
NumPy conventions, you should use the `numpydoc`
extension so that your
docstrings will be handled correctly. For example, Sphinx will extract the
`Parameters`
section from your docstring and convert it into a field
list. Using `numpydoc`
will also avoid the reStructuredText errors produced
by plain Sphinx when it encounters NumPy docstring conventions like
section headers (e.g. `-------------`
) that sphinx does not expect to
find in docstrings.

It is available from:

Note that for documentation within NumPy, it is not necessary to do
`import numpy as np`
at the beginning of an example.

Please use the `numpydoc`
[formatting standard](https://numpydoc.readthedocs.io/en/latest/format.html#format) as
shown in their [example](https://numpydoc.readthedocs.io/en/latest/example.html#example).

### Documenting C/C++ Code[#](#documenting-c-c-code)
NumPy uses [Doxygen](https://www.doxygen.nl/index.html) to parse specially-formatted C/C++ comment blocks. This generates
XML files, which are converted by [Breathe](https://breathe.readthedocs.io/en/latest/) into RST, which is used by Sphinx.

**It takes three steps to complete the documentation process**:
#### 1. Writing the comment blocks[#](#writing-the-comment-blocks)
Although there is still no commenting style set to follow, the Javadoc is more preferable than the others due to the similarities with the current existing non-indexed comment blocks.

Note

Please see [“Documenting the code”](https://www.doxygen.nl/manual/docblocks.html).

**This is what Javadoc style looks like**:
```
/**
* This a simple brief.
*
* And the details goes here.
* Multi lines are welcome.
*
* @param num leave a comment for parameter num.
* @param str leave a comment for the second parameter.
* @return leave a comment for the returned value.
*/
int doxy_javadoc_example(int num, const char *str);
```
**And here is how it is rendered**:
int doxy_javadoc_example(int num, const char *str)[#](#_CPPv420doxy_javadoc_exampleiPKc)
-
This a simple brief.

And the details goes here. Multi lines are welcome.

Parameters:
-
**num**– leave a comment for parameter num.
**str**– leave a comment for the second parameter.
Returns:
-
leave a comment for the returned value.

**For line comment, you can use a triple forward slash. For example**:
```
/**
* Template to represent limbo numbers.
*
* Specializations for integer types that are part of nowhere.
* It doesn't support with any real types.
*
* @param Tp Type of the integer. Required to be an integer type.
* @param N Number of elements.
*/
template<typename Tp, std::size_t N>
class DoxyLimbo {
public:
/// Default constructor. Initialize nothing.
DoxyLimbo();
/// Set Default behavior for copy the limbo.
DoxyLimbo(const DoxyLimbo<Tp, N> &l);
/// Returns the raw data for the limbo.
const Tp *data();
protected:
Tp p_data[N]; ///< Example for inline comment.
};
```
**And here is how it is rendered**:
template<typename Tp, std::size_t N>
class DoxyLimbo[#](#_CPPv4I0_NSt6size_tEE9DoxyLimbo)
-
Template to represent limbo numbers.

Specializations for integer types that are part of nowhere. It doesn’t support with any real types.

Param Tp:
-
Type of the integer. Required to be an integer type.

Param N:
-
Number of elements.

Public Functions

DoxyLimbo()[#](#_CPPv4N9DoxyLimbo9DoxyLimboEv)
-
Default constructor. Initialize nothing.

##### Example[#](#example)
**Take a look at the following example**:
```
/**
* A comment block contains reST markup.
* @rst
* .. note::
*
* Thanks to Breathe_, we were able to bring it to Doxygen_
*
* Some code example::
*
* int example(int x) {
* return x * 2;
* }
* @endrst
*/
void doxy_reST_example(void);
```
**And here is how it is rendered**:
void doxy_reST_example(void)[#](#_CPPv417doxy_reST_examplev)
-
A comment block contains reST markup.

Some code example:

int example(int x) { return x * 2; }
#### 2. Feeding Doxygen[#](#feeding-doxygen)
Not all headers files are collected automatically. You have to add the desired C/C++ header paths within the sub-config files of Doxygen.

Sub-config files have the unique name `.doxyfile`
, which you can usually find near
directories that contain documented headers. You need to create a new config file if
there’s not one located in a path close(2-depth) to the headers you want to add.

Sub-config files can accept any of [Doxygen](https://www.doxygen.nl/index.html) [configuration options](https://www.doxygen.nl/manual/config.html),
but do not override or re-initialize any configuration option,
rather only use the concatenation operator “+=”. For example:

```
# to specify certain headers
INPUT += @CUR_DIR/header1.h \
@CUR_DIR/header2.h
# to add all headers in certain path
INPUT += @CUR_DIR/to/headers
# to define certain macros
PREDEFINED += C_MACRO(X)=X
# to enable certain branches
PREDEFINED += NPY_HAVE_FEATURE \
NPY_HAVE_FEATURE2
```
Note

@CUR_DIR is a template constant returns the current dir path of the sub-config file.

#### 3. Inclusion directives[#](#inclusion-directives)
[Breathe](https://breathe.readthedocs.io/en/latest/) provides a wide range of custom directives to allow
converting the documents generated by [Doxygen](https://www.doxygen.nl/index.html) into reST files.
Note

For more information, please check out “[Directives & Config Variables](https://breathe.readthedocs.io/en/latest/directives.html)”

##### Common directives:[#](#common-directives)
`doxygenfunction`
This directive generates the appropriate output for a single function. The function name is required to be unique in the project.

```
.. doxygenfunction:: <function name>
:outline:
:no-link:
```
Checkout the [example](https://breathe.readthedocs.io/en/latest/function.html#function-example)
to see it in action.

`doxygenclass`
This directive generates the appropriate output for a single class. It takes the standard project, path, outline and no-link options and additionally the members, protected-members, private-members, undoc-members, membergroups and members-only options:

```
.. doxygenclass:: <class name>
:members: [...]
:protected-members:
:private-members:
:undoc-members:
:membergroups: ...
:members-only:
:outline:
:no-link:
```
Checkout the *doxygenclass documentation <https://breathe.readthedocs.io/en/latest/class.html#class-example>_*
for more details and to see it in action.

`doxygennamespace`
This directive generates the appropriate output for the contents of a namespace. It takes the standard project, path, outline and no-link options and additionally the content-only, members, protected-members, private-members and undoc-members options. To reference a nested namespace, the full namespaced path must be provided, e.g. foo::bar for the bar namespace inside the foo namespace.

```
.. doxygennamespace:: <namespace>
:content-only:
:outline:
:members:
:protected-members:
:private-members:
:undoc-members:
:no-link:
```
Checkout the [doxygennamespace documentation](https://breathe.readthedocs.io/en/latest/namespace.html#namespace-example)
for more details and to see it in action.

`doxygengroup`
This directive generates the appropriate output for the contents of a doxygen group.
A doxygen group can be declared with specific doxygen markup in the source comments
as covered in the doxygen [grouping documentation](https://www.doxygen.nl/manual/grouping.html).

It takes the standard project, path, outline and no-link options and additionally the content-only, members, protected-members, private-members and undoc-members options.

```
.. doxygengroup:: <group name>
:content-only:
:outline:
:members:
:protected-members:
:private-members:
:undoc-members:
:no-link:
:inner:
```
Checkout the [doxygengroup documentation](https://breathe.readthedocs.io/en/latest/group.html#group-example)
for more details and to see it in action.

## Documentation reading[#](#documentation-reading)
The leading organization of technical writers,

[Write the Docs](https://www.writethedocs.org/), holds conferences, hosts learning resources, and runs a Slack channel.
“Every engineer is also a writer,” says Google’s

[collection of technical writing resources](https://developers.google.com/tech-writing), which includes free online courses for developers in planning and writing documents.
[Software Carpentry’s](https://software-carpentry.org/lessons)mission is teaching software to researchers. In addition to hosting the curriculum, the website explains how to present ideas effectively.These are the instructions if you just want to follow the latest
*NumPy* source, but you don’t need to do any development for now.
If you do want to contribute a patch (excellent!) or do more extensive
NumPy development, see [Development workflow](../development_workflow.html#development-workflow).

The steps are:

get local copy of the git repository from

[Github](https://github.com/numpy)
update local copy from time to time

# Get the local copy of the code[#](#get-the-local-copy-of-the-code)
From the command line:

```
git clone https://github.com/numpy/numpy.git
```
You now have a copy of the code tree in the new `numpy`
directory.
If this doesn’t work you can try the alternative read-only url:

```
git clone https://github.com/numpy/numpy.git
```
# Updating the code[#](#updating-the-code)
From time to time you may want to pull down the latest code. Do this with:

```
cd numpy
git fetch
git merge --ff-only
```
The tree in `numpy`
will now have the latest changes from the initial
repository.# numpy.ravel[#](#numpy-ravel)
numpy.ravel(*a*,*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L1768-L1874)[#](#numpy.ravel)
-
Return a contiguous flattened array.

A 1-D array, containing the elements of the input, is returned. A copy is made only if needed.

As of NumPy 1.10, the returned array will have the same type as the input array. (for example, a masked array will be returned for a masked array input)

Parameters:
-
**a**array_like
Input array. The elements in

*a*are read in the order specified by*order*, and packed as a 1-D array.
**order**{‘C’,’F’, ‘A’, ‘K’}, optional
The elements of

*a*are read using this index order. ‘C’ means to index the elements in row-major, C-style order, with the last axis index changing fastest, back to the first axis index changing slowest. ‘F’ means to index the elements in column-major, Fortran-style order, with the first index changing fastest, and the last index changing slowest. Note that the ‘C’ and ‘F’ options take no account of the memory layout of the underlying array, and only refer to the order of axis indexing. ‘A’ means to read the elements in Fortran-like index order if*a*is Fortran*contiguous*in memory, C-like order otherwise. ‘K’ means to read the elements in the order they occur in memory, except for reversing the data when strides are negative. By default, ‘C’ index order is used.
Returns:
-
**y**array_like
y is a contiguous 1-D array of the same subtype as

*a*, with shape`(a.size,)`
. Note that matrices are special cased for backward compatibility, if*a*is a matrix, then y is a 1-D ndarray.
See also

`ndarray.flat`
1-D iterator over an array.

`ndarray.flatten`
1-D array copy of the elements of an array in row-major order.

`ndarray.reshape`
Change the shape of an array without changing its data.

Notes

In row-major, C-style order, in two dimensions, the row index varies the slowest, and the column index the quickest. This can be generalized to multiple dimensions, where row-major order implies that the index along the first axis varies slowest, and the index along the last quickest. The opposite holds for column-major, Fortran-style index ordering.

When a view is desired in as many cases as possible,

`arr.reshape(-1)`
may be preferable. However,`ravel`
supports`K`
in the optional`order`
argument while`reshape`
does not.Examples

It is equivalent to

`reshape(-1, order=order)`
.>>> x = np.array([[1, 2, 3], [4, 5, 6]]) >>> np.ravel(x) array([1, 2, 3, 4, 5, 6])
>>> x.reshape(-1) array([1, 2, 3, 4, 5, 6])
>>> np.ravel(x, order='F') array([1, 4, 2, 5, 3, 6])
When

`order`
is ‘A’, it will preserve the array’s ‘C’ or ‘F’ ordering:>>> np.ravel(x.T) array([1, 4, 2, 5, 3, 6]) >>> np.ravel(x.T, order='A') array([1, 2, 3, 4, 5, 6])
When

`order`
is ‘K’, it will preserve orderings that are neither ‘C’ nor ‘F’, but won’t reverse axes:>>> a = np.arange(3)[::-1]; a array([2, 1, 0]) >>> a.ravel(order='C') array([2, 1, 0]) >>> a.ravel(order='K') array([2, 1, 0])
>>> a = np.arange(12).reshape(2,3,2).swapaxes(1,2); a array([[[ 0, 2, 4], [ 1, 3, 5]], [[ 6, 8, 10], [ 7, 9, 11]]]) >>> a.ravel(order='C') array([ 0, 2, 4, 1, 3, 5, 6, 8, 10, 7, 9, 11]) >>> a.ravel(order='K') array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])# numpy.nonzero[#](#numpy-nonzero)
numpy.nonzero(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L1881-L1973)[#](#numpy.nonzero)
-
Return the indices of the elements that are non-zero.

Returns a tuple of arrays, one for each dimension of

*a*, containing the indices of the non-zero elements in that dimension. The values in*a*are always tested and returned in row-major, C-style order.To group the indices by element, rather than dimension, use

, which returns a row for each non-zero element.`argwhere`
Note

When called on a zero-d array or scalar,

`nonzero(a)`
is treated as`nonzero(atleast_1d(a))`
.Deprecated since version 1.17.0: Use

explicitly if this behavior is deliberate.`atleast_1d`
Parameters:
-
**a**array_like
Input array.

Returns:
-
**tuple_of_arrays**tuple
Indices of elements that are non-zero.

See also

`flatnonzero`
Return indices that are non-zero in the flattened version of the input array.

`ndarray.nonzero`
Equivalent ndarray method.

`count_nonzero`
Counts the number of non-zero elements in the input array.

Notes

While the nonzero values can be obtained with

`a[nonzero(a)]`
, it is recommended to use`x[x.astype(bool)]`
or`x[x != 0]`
instead, which will correctly handle 0-d arrays.Examples

>>> x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]]) >>> x array([[3, 0, 0], [0, 4, 0], [5, 6, 0]]) >>> np.nonzero(x) (array([0, 1, 2, 2]), array([0, 1, 0, 1]))
>>> x[np.nonzero(x)] array([3, 4, 5, 6]) >>> np.transpose(np.nonzero(x)) array([[0, 0], [1, 1], [2, 0], [2, 1]])
A common use for

`nonzero`
is to find the indices of an array, where a condition is True. Given an array*a*, the condition*a*> 3 is a boolean array and since False is interpreted as 0, np.nonzero(a > 3) yields the indices of the*a*where the condition is true.>>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> a > 3 array([[False, False, False], [ True, True, True], [ True, True, True]]) >>> np.nonzero(a > 3) (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))
Using this result to index

*a*is equivalent to using the mask directly:>>> a[np.nonzero(a > 3)] array([4, 5, 6, 7, 8, 9]) >>> a[a > 3] # prefer this spelling array([4, 5, 6, 7, 8, 9])
`nonzero`
can also be called as a method of the array.>>> (a > 3).nonzero() (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))# Broadcasting[#](#broadcasting)
See also

The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. There are, however, cases where broadcasting is a bad idea because it leads to inefficient use of memory that slows computation.

NumPy operations are usually done on pairs of arrays on an element-by-element basis. In the simplest case, the two arrays must have exactly the same shape, as in the following example:

```
>>> a = np.array([1.0, 2.0, 3.0])
>>> b = np.array([2.0, 2.0, 2.0])
>>> a * b
array([2., 4., 6.])
```
NumPy’s broadcasting rule relaxes this constraint when the arrays’ shapes meet certain constraints. The simplest broadcasting example occurs when an array and a scalar value are combined in an operation:

```
>>> a = np.array([1.0, 2.0, 3.0])
>>> b = 2.0
>>> a * b
array([2., 4., 6.])
```
The result is equivalent to the previous example where `b`
was an array.
We can think of the scalar `b`
being *stretched* during the arithmetic
operation into an array with the same shape as `a`
. The new elements in
`b`
, as shown in [Figure 1](#broadcasting-figure-1), are simply copies of the
original scalar. The stretching analogy is
only conceptual. NumPy is smart enough to use the original scalar value
without actually making copies so that broadcasting operations are as
memory and computationally efficient as possible.

The code in the second example is more efficient than that in the first
because broadcasting moves less memory around during the multiplication
(`b`
is a scalar rather than an array).

## General Broadcasting Rules[#](#general-broadcasting-rules)
When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimension and works its way left. Two dimensions are compatible when

they are equal, or

one of them is 1.

If these conditions are not met, a
`ValueError: operands could not be broadcast together`
exception is
thrown, indicating that the arrays have incompatible shapes.

Input arrays do not need to have the same *number* of dimensions. The
resulting array will have the same number of dimensions as the input array
with the greatest number of dimensions, where the *size* of each dimension is
the largest size of the corresponding dimension among the input arrays. Note
that missing dimensions are assumed to have size one.

For example, if you have a `256x256x3`
array of RGB values, and you want
to scale each color in the image by a different value, you can multiply the
image by a one-dimensional array with 3 values. Lining up the sizes of the
trailing axes of these arrays according to the broadcast rules, shows that
they are compatible:

```
Image (3d array): 256 x 256 x 3
Scale (1d array): 3
Result (3d array): 256 x 256 x 3
```
When either of the dimensions compared is one, the other is used. In other words, dimensions with size 1 are stretched or “copied” to match the other.

In the following example, both the `A`
and `B`
arrays have axes with
length one that are expanded to a larger size during the broadcast
operation:

```
A (4d array): 8 x 1 x 6 x 1
B (3d array): 7 x 1 x 5
Result (4d array): 8 x 7 x 6 x 5
```
## Broadcastable arrays[#](#broadcastable-arrays)
A set of arrays is called “broadcastable” to the same shape if the above rules produce a valid result.

For example, if `a.shape`
is (5,1), `b.shape`
is (1,6), `c.shape`
is (6,)
and `d.shape`
is () so that *d* is a scalar, then *a*, *b*, *c*,
and *d* are all broadcastable to dimension (5,6); and

*a*acts like a (5,6) array where`a[:,0]`
is broadcast to the other columns,
*b*acts like a (5,6) array where`b[0,:]`
is broadcast to the other rows,
*c*acts like a (1,6) array and therefore like a (5,6) array where`c[:]`
is broadcast to every row, and finally,
*d*acts like a (5,6) array where the single value is repeated.
Here are some more examples:

```
A (2d array): 5 x 4
B (1d array): 1
Result (2d array): 5 x 4
A (2d array): 5 x 4
B (1d array): 4
Result (2d array): 5 x 4
A (3d array): 15 x 3 x 5
B (3d array): 15 x 1 x 5
Result (3d array): 15 x 3 x 5
A (3d array): 15 x 3 x 5
B (2d array): 3 x 5
Result (3d array): 15 x 3 x 5
A (3d array): 15 x 3 x 5
B (2d array): 3 x 1
Result (3d array): 15 x 3 x 5
```
Here are examples of shapes that do not broadcast:

```
A (1d array): 3
B (1d array): 4 # trailing dimensions do not match
A (2d array): 2 x 1
B (3d array): 8 x 4 x 3 # second from last dimensions mismatched
```
An example of broadcasting when a 1-d array is added to a 2-d array:

```
>>> a = np.array([[ 0.0, 0.0, 0.0],
... [10.0, 10.0, 10.0],
... [20.0, 20.0, 20.0],
... [30.0, 30.0, 30.0]])
>>> b = np.array([1.0, 2.0, 3.0])
>>> a + b
array([[ 1., 2., 3.],
[11., 12., 13.],
[21., 22., 23.],
[31., 32., 33.]])
>>> b = np.array([1.0, 2.0, 3.0, 4.0])
>>> a + b
Traceback (most recent call last):
ValueError: operands could not be broadcast together with shapes (4,3) (4,)
```
As shown in [Figure 2](#broadcasting-figure-2), `b`
is added to each row of `a`
.
In [Figure 3](#broadcasting-figure-3), an exception is raised because of the
incompatible shapes.

Broadcasting provides a convenient way of taking the outer product (or any other outer operation) of two arrays. The following example shows an outer addition operation of two 1-d arrays:

```
>>> a = np.array([0.0, 10.0, 20.0, 30.0])
>>> b = np.array([1.0, 2.0, 3.0])
>>> a[:, np.newaxis] + b
array([[ 1., 2., 3.],
[11., 12., 13.],
[21., 22., 23.],
[31., 32., 33.]])
```
Here the `newaxis`
index operator inserts a new axis into `a`
,
making it a two-dimensional `4x1`
array. Combining the `4x1`
array
with `b`
, which has shape `(3,)`
, yields a `4x3`
array.

## A Practical Example: Vector Quantization[#](#a-practical-example-vector-quantization)
Broadcasting comes up quite often in real world problems. A typical example
occurs in the vector quantization (VQ) algorithm used in information theory,
classification, and other related areas. The basic operation in VQ finds
the closest point in a set of points, called `codes`
in VQ jargon, to a given
point, called the `observation`
. In the very simple, two-dimensional case
shown below, the values in `observation`
describe the weight and height of an
athlete to be classified. The `codes`
represent different classes of
athletes. [[1]](#f1) Finding the closest point requires calculating the distance
between observation and each of the codes. The shortest distance provides the
best match. In this example, `codes[0]`
is the closest class indicating that
the athlete is likely a basketball player.

```
>>> from numpy import array, argmin, sqrt, sum
>>> observation = array([111.0, 188.0])
>>> codes = array([[102.0, 203.0],
... [132.0, 193.0],
... [45.0, 155.0],
... [57.0, 173.0]])
>>> diff = codes - observation # the broadcast happens here
>>> dist = sqrt(sum(diff**2,axis=-1))
>>> argmin(dist)
0
```
In this example, the `observation`
array is stretched to match
the shape of the `codes`
array:

```
Observation (1d array): 2
Codes (2d array): 4 x 2
Diff (2d array): 4 x 2
```
Typically, a large number of `observations`
, perhaps read from a database,
are compared to a set of `codes`
. Consider this scenario:

```
Observation (2d array): 10 x 3
Codes (3d array): 5 x 1 x 3
Diff (3d array): 5 x 10 x 3
```
The three-dimensional array, `diff`
, is a consequence of broadcasting, not a
necessity for the calculation. Large data sets will generate a large
intermediate array that is computationally inefficient. Instead, if each
observation is calculated individually using a Python loop around the code
in the two-dimensional example above, a much smaller array is used.

Broadcasting is a powerful tool for writing short and usually intuitive code that does its computations very efficiently in C. However, there are cases when broadcasting uses unnecessarily large amounts of memory for a particular algorithm. In these cases, it is better to write the algorithm’s outer loop in Python. This may also produce more readable code, as algorithms that use broadcasting tend to become more difficult to interpret as the number of dimensions in the broadcast increases.

Footnotes# numpy.transpose[#](#numpy-transpose)
numpy.transpose(*a*,*axes=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L588-L655)[#](#numpy.transpose)
-
Returns an array with axes transposed.

For a 1-D array, this returns an unchanged view of the original array, as a transposed vector is simply the same vector. To convert a 1-D array into a 2-D column vector, an additional dimension must be added, e.g.,

`np.atleast2d(a).T`
achieves this, as does`a[:, np.newaxis]`
. For a 2-D array, this is the standard matrix transpose. For an n-D array, if axes are given, their order indicates how the axes are permuted (see Examples). If axes are not provided, then`transpose(a).shape == a.shape[::-1]`
.Parameters:
-
**a**array_like
Input array.

**axes**tuple or list of ints, optional
If specified, it must be a tuple or list which contains a permutation of [0,1,…,N-1] where N is the number of axes of

*a*. The*i*’th axis of the returned array will correspond to the axis numbered`axes[i]`
of the input. If not specified, defaults to`range(a.ndim)[::-1]`
, which reverses the order of the axes.
Returns:
-
**p**ndarray
*a*with its axes permuted. A view is returned whenever possible.
See also

`ndarray.transpose`
Equivalent method.

`moveaxis`
Move axes of an array to new positions.

`argsort`
Return the indices that would sort an array.

Notes

Use

`transpose(a, argsort(axes))`
to invert the transposition of tensors when using the*axes*keyword argument.Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> a array([[1, 2], [3, 4]]) >>> np.transpose(a) array([[1, 3], [2, 4]])
>>> a = np.array([1, 2, 3, 4]) >>> a array([1, 2, 3, 4]) >>> np.transpose(a) array([1, 2, 3, 4])
>>> a = np.ones((1, 2, 3)) >>> np.transpose(a, (1, 0, 2)).shape (2, 1, 3)
>>> a = np.ones((2, 3, 4, 5)) >>> np.transpose(a).shape (5, 4, 3, 2)# Internal organization of NumPy arrays[#](#internal-organization-of-numpy-arrays)
It helps to understand a bit about how NumPy arrays are handled under the covers
to help understand NumPy better. This section will not go into great detail.
Those wishing to understand the full details are requested to refer to Travis
Oliphant’s book [Guide to NumPy](http://web.mit.edu/dvp/Public/numpybook.pdf).

NumPy arrays consist of two major components: the raw array data (from now on,
referred to as the data buffer), and the information about the raw array data.
The data buffer is typically what people think of as arrays in C or Fortran,
a [contiguous](../glossary.html#term-contiguous) (and fixed) block of memory containing fixed-sized data
items. NumPy also contains a significant set of data that describes how to
interpret the data in the data buffer. This extra information contains (among
other things):

-
The basic data element’s size in bytes.

-
The start of the data within the data buffer (an offset relative to the beginning of the data buffer).

-
The number of

[dimensions]and the size of each dimension.
-
The separation between elements for each dimension (the

[stride]). This does not have to be a multiple of the element size.
-
The byte order of the data (which may not be the native byte order).

-
Whether the buffer is read-only.

-
Information (via the

[object) about the interpretation of the basic data element. The basic data element may be as simple as an int or a float, or it may be a compound object (e.g.,]`dtype`
[struct-like]), a fixed character field, or Python object pointers.
-
Whether the array is to be interpreted as

[C-order]or[Fortran-order].
This arrangement allows for the very flexible use of arrays. One thing that it
allows is simple changes to the metadata to change the interpretation of the
array buffer. Changing the byteorder of the array is a simple change involving
no rearrangement of the data. The [shape](../glossary.html#term-shape) of the array can be changed very
easily without changing anything in the data buffer or any data copying at all.

Among other things that are made possible is one can create a new array metadata
object that uses the same data buffer
to create a new [view](../glossary.html#term-view) of that data buffer that has a different
interpretation of the buffer (e.g., different shape, offset, byte order,
strides, etc) but shares the same data bytes. Many operations in NumPy do just
this such as [slicing](https://docs.python.org/3/glossary.html#term-slice). Other operations, such as
transpose, don’t move data elements around in the array, but rather change the
information about the shape and strides so that the indexing of the array
changes, but the data in the doesn’t move.

Typically these new versions of the array metadata but the same data buffer are
new views into the data buffer. There is a different [ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray) object,
but it uses the same data buffer. This is why it is necessary to force copies
through the use of the

[method if one really wants to make a new and independent copy of the data buffer.](../reference/generated/numpy.copy.html#numpy.copy)
`copy`
New views into arrays mean the object reference counts for the data buffer increase. Simply doing away with the original array object will not remove the data buffer if other views of it still exist.

## Multidimensional array indexing order issues[#](#multidimensional-array-indexing-order-issues)
See also

What is the right way to index multi-dimensional arrays? Before you jump to conclusions about the one and true way to index multi-dimensional arrays, it pays to understand why this is a confusing issue. This section will try to explain in detail how NumPy indexing works and why we adopt the convention we do for images, and when it may be appropriate to adopt other conventions.

The first thing to understand is that there are two conflicting conventions for indexing 2-dimensional arrays. Matrix notation uses the first index to indicate which row is being selected and the second index to indicate which column is selected. This is opposite the geometrically oriented-convention for images where people generally think the first index represents x position (i.e., column) and the second represents y position (i.e., row). This alone is the source of much confusion; matrix-oriented users and image-oriented users expect two different things with regard to indexing.

The second issue to understand is how indices correspond to the order in which the array is stored in memory. In Fortran, the first index is the most rapidly varying index when moving through the elements of a two-dimensional array as it is stored in memory. If you adopt the matrix convention for indexing, then this means the matrix is stored one column at a time (since the first index moves to the next row as it changes). Thus Fortran is considered a Column-major language. C has just the opposite convention. In C, the last index changes most rapidly as one moves through the array as stored in memory. Thus C is a Row-major language. The matrix is stored by rows. Note that in both cases it presumes that the matrix convention for indexing is being used, i.e., for both Fortran and C, the first index is the row. Note this convention implies that the indexing convention is invariant and that the data order changes to keep that so.

But that’s not the only way to look at it. Suppose one has large two-dimensional arrays (images or matrices) stored in data files. Suppose the data are stored by rows rather than by columns. If we are to preserve our index convention (whether matrix or image) that means that depending on the language we use, we may be forced to reorder the data if it is read into memory to preserve our indexing convention. For example, if we read row-ordered data into memory without reordering, it will match the matrix indexing convention for C, but not for Fortran. Conversely, it will match the image indexing convention for Fortran, but not for C. For C, if one is using data stored in row order, and one wants to preserve the image index convention, the data must be reordered when reading into memory.

In the end, what you do for Fortran or C depends on which is more important, not reordering data or preserving the indexing convention. For large images, reordering data is potentially expensive, and often the indexing convention is inverted to avoid that.

The situation with
NumPy makes this issue yet more complicated. The internal machinery of NumPy
arrays is flexible enough to accept any ordering of indices. One can simply
reorder indices by manipulating the internal [stride](../glossary.html#term-stride) information for
arrays without reordering the data at all. NumPy will know how to map the new
index order to the data without moving the data.

So if this is true, why not choose
the index order that matches what you most expect? In particular, why not define
row-ordered images to use the image convention? (This is sometimes referred
to as the Fortran convention vs the C convention, thus the ‘C’ and ‘FORTRAN’
order options for array ordering in NumPy.) The drawback of doing this is
potential performance penalties. It’s common to access the data sequentially,
either implicitly in array operations or explicitly by looping over rows of an
image. When that is done, then the data will be accessed in non-optimal order.
As the first index is incremented, what is actually happening is that elements
spaced far apart in memory are being sequentially accessed, with usually poor
memory access speeds. For example, for a two-dimensional image `im`
defined so
that `im[0, 10]`
represents the value at `x = 0`
, `y = 10`
. To be
consistent with usual Python behavior then `im[0]`
would represent a column
at `x = 0`
. Yet that data would be spread over the whole array since the data
are stored in row order. Despite the flexibility of NumPy’s indexing, it can’t
really paper over the fact basic operations are rendered inefficient because of
data order or that getting contiguous subarrays is still awkward (e.g.,
`im[:, 0]`
for the first row, vs `im[0]`
). Thus one can’t use an idiom such
as for row in `im`
; for col in `im`
does work, but doesn’t yield contiguous
column data.

As it turns out, NumPy is
smart enough when dealing with [ufuncs](internals.code-explanations.html#ufuncs-internals) to determine
which index is the most rapidly varying one in memory and uses that for the
innermost loop. Thus for ufuncs, there is no large intrinsic advantage to
either approach in most cases. On the other hand, use of [ ndarray.flat](../reference/generated/numpy.ndarray.flat.html#numpy.ndarray.flat)
with a FORTRAN ordered array will lead to non-optimal memory access as adjacent
elements in the flattened array (iterator, actually) are not contiguous in
memory.

Indeed, the fact is that Python indexing on lists and other sequences naturally leads to an outside-to-inside ordering (the first index gets the largest grouping, the next largest, and the last gets the smallest element). Since image data are normally stored in rows, this corresponds to the position within rows being the last item indexed.

If you do want to use Fortran ordering realize that
there are two approaches to consider: 1) accept that the first index is just not
the most rapidly changing in memory and have all your I/O routines reorder
your data when going from memory to disk or visa versa, or use NumPy’s
mechanism for mapping the first index to the most rapidly varying data. We
recommend the former if possible. The disadvantage of the latter is that many
of NumPy’s functions will yield arrays without Fortran ordering unless you are
careful to use the `order`
keyword. Doing this would be highly inconvenient.

Otherwise, we recommend simply learning to reverse the usual order of indices when accessing elements of an array. Granted, it goes against the grain, but it is more in line with Python semantics and the natural order of the data.# numpy.savetxt[#](#numpy-savetxt)
numpy.savetxt(*fname*,*X*,*fmt='%.18e'*,*delimiter=' '*,*newline='\n'*,*header=''*,*footer=''*,*comments='# '*,*encoding=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/npyio.py#L1390-L1635)[#](#numpy.savetxt)
-
Save an array to a text file.

Parameters:
-
**fname**filename or file handle
If the filename ends in

`.gz`
, the file is automatically saved in compressed gzip format.understands gzipped files transparently.`loadtxt`
**X**1D or 2D array_like
Data to be saved to a text file.

**fmt**str or sequence of strs, optional
A single format (%10.5f), a sequence of formats, or a multi-format string, e.g. ‘Iteration %d – %10.5f’, in which case

*delimiter*is ignored. For complex*X*, the legal options for*fmt*are:a single specifier,

*fmt=’%.4e’*, resulting in numbers formatted like*‘ (%s+%sj)’ % (fmt, fmt)*
a full string specifying every real and imaginary part, e.g.

*‘ %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej’*for 3 columns
a list of specifiers, one per column - in this case, the real and imaginary part must have separate specifiers, e.g.

*[‘%.3e + %.3ej’, ‘(%.15e%+.15ej)’]*for 2 columns
**delimiter**str, optional
String or character separating columns.

**newline**str, optional
String or character separating lines.

New in version 1.5.0.

**header**str, optional
String that will be written at the beginning of the file.

New in version 1.7.0.

**footer**str, optional
String that will be written at the end of the file.

New in version 1.7.0.

**comments**str, optional
String that will be prepended to the

`header`
and`footer`
strings, to mark them as comments. Default: ‘# ‘, as expected by e.g.`numpy.loadtxt`
.New in version 1.7.0.

**encoding**{None, str}, optional
Encoding used to encode the outputfile. Does not apply to output streams. If the encoding is something other than ‘bytes’ or ‘latin1’ you will not be able to load the file in NumPy versions < 1.14. Default is ‘latin1’.

New in version 1.14.0.

See also

`save`
Save an array to a binary file in NumPy

`.npy`
format
`savez`
Save several arrays into an uncompressed

`.npz`
archive
`savez_compressed`
Save several arrays into a compressed

`.npz`
archive
Notes

Further explanation of the

*fmt*parameter (`%[flag]width[.precision]specifier`
):flags:
-
`-`
: left justify`+`
: Forces to precede result with + or -.`0`
: Left pad the number with zeros instead of space (see width).
width:
-
Minimum number of characters to be printed. The value is not truncated if it has more characters.

precision:
-
For integer specifiers (eg.

`d,i,o,x`
), the minimum number of digits.
For

`e, E`
and`f`
specifiers, the number of digits to print after the decimal point.
For

`g`
and`G`
, the maximum number of significant digits.
For

`s`
, the maximum number of characters.
specifiers:
-
`c`
: character`d`
or`i`
: signed decimal integer`e`
or`E`
: scientific notation with`e`
or`E`
.`f`
: decimal floating point`g,G`
: use the shorter of`e,E`
or`f`
`o`
: signed octal`s`
: string of characters`u`
: unsigned decimal integer`x,X`
: unsigned hexadecimal integer
This explanation of

`fmt`
is not complete, for an exhaustive specification see[[1]](#r672d4d5b6143-1).References

[[1](#id1)][Format Specification Mini-Language](https://docs.python.org/library/string.html#format-specification-mini-language), Python Documentation.Examples

>>> x = y = z = np.arange(0.0,5.0,1.0) >>> np.savetxt('test.out', x, delimiter=',') # X is an array >>> np.savetxt('test.out', (x,y,z)) # x,y,z equal sized 1D arrays >>> np.savetxt('test.out', x, fmt='%1.4e') # use exponential notation# numpy.partition[#](#numpy-partition)
numpy.partition(*a*,*kth*,*axis=-1*,*kind='introselect'*,*order=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L662-L772)[#](#numpy.partition)
-
Return a partitioned copy of an array.

Creates a copy of the array with its elements rearranged in such a way that the value of the element in k-th position is in the position the value would be in a sorted array. In the partitioned array, all elements before the k-th element are less than or equal to that element, and all the elements after the k-th element are greater than or equal to that element. The ordering of the elements in the two partitions is undefined.

New in version 1.8.0.

Parameters:
-
**a**array_like
Array to be sorted.

**kth**int or sequence of ints
Element index to partition by. The k-th value of the element will be in its final sorted position and all smaller elements will be moved before it and all equal or greater elements behind it. The order of all elements in the partitions is undefined. If provided with a sequence of k-th it will partition all elements indexed by k-th of them into their sorted position at once.

Deprecated since version 1.22.0: Passing booleans as index is deprecated.

**axis**int or None, optional
Axis along which to sort. If None, the array is flattened before sorting. The default is -1, which sorts along the last axis.

**kind**{‘introselect’}, optional
Selection algorithm. Default is ‘introselect’.

**order**str or list of str, optional
When

*a*is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string. Not all fields need be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.
Returns:
-
**partitioned_array**ndarray
Array of the same type and shape as

*a*.
See also

`ndarray.partition`
Method to sort an array in-place.

`argpartition`
Indirect partition.

`sort`
Full sorting

Notes

The various selection algorithms are characterized by their average speed, worst case performance, work space size, and whether they are stable. A stable sort keeps items with the same key in the same relative order. The available algorithms have the following properties:

kind

speed

worst case

work space

stable

‘introselect’

1

O(n)

0

no

All the partition algorithms make temporary copies of the data when partitioning along any but the last axis. Consequently, partitioning along the last axis is faster and uses less space than partitioning along any other axis.

The sort order for complex numbers is lexicographic. If both the real and imaginary parts are non-nan then the order is determined by the real parts except when they are equal, in which case the order is determined by the imaginary parts.

Examples

>>> a = np.array([7, 1, 7, 7, 1, 5, 7, 2, 3, 2, 6, 2, 3, 0]) >>> p = np.partition(a, 4) >>> p array([0, 1, 2, 1, 2, 5, 2, 3, 3, 6, 7, 7, 7, 7])
`p[4]`
is 2; all elements in`p[:4]`
are less than or equal to`p[4]`
, and all elements in`p[5:]`
are greater than or equal to`p[4]`
. The partition is:[0, 1, 2, 1], [2], [5, 2, 3, 3, 6, 7, 7, 7, 7]
The next example shows the use of multiple values passed to

*kth*.>>> p2 = np.partition(a, (4, 8)) >>> p2 array([0, 1, 2, 1, 2, 3, 3, 2, 5, 6, 7, 7, 7, 7])
`p2[4]`
is 2 and`p2[8]`
is 5. All elements in`p2[:4]`
are less than or equal to`p2[4]`
, all elements in`p2[5:8]`
are greater than or equal to`p2[4]`
and less than or equal to`p2[8]`
, and all elements in`p2[9:]`
are greater than or equal to`p2[8]`
. The partition is:[0, 1, 2, 1], [2], [3, 3, 2], [5], [6, 7, 7, 7, 7]# Interoperability with NumPy[#](#interoperability-with-numpy)
NumPy’s ndarray objects provide both a high-level API for operations on
array-structured data and a concrete implementation of the API based on
[strided in-RAM storage](../reference/arrays.html#arrays). While this API is powerful and fairly
general, its concrete implementation has limitations. As datasets grow and NumPy
becomes used in a variety of new environments and architectures, there are cases
where the strided in-RAM storage strategy is inappropriate, which has caused
different libraries to reimplement this API for their own uses. This includes
GPU arrays ([CuPy](https://cupy.dev/)), Sparse arrays ([ scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse),

[PyData/Sparse](https://sparse.pydata.org/)) and parallel arrays (
[Dask](https://docs.dask.org/)arrays) as well as various NumPy-like implementations in deep learning frameworks, like
[TensorFlow](https://www.tensorflow.org/)and
[PyTorch](https://pytorch.org/). Similarly, there are many projects that build on top of the NumPy API for labeled and indexed arrays (
[XArray](http://xarray.pydata.org/)), automatic differentiation (
[JAX](https://jax.readthedocs.io/)), masked arrays (
[), physical units (](../reference/maskedarray.generic.html#module-numpy.ma)
`numpy.ma`
[astropy.units](https://docs.astropy.org/en/stable/units/),
[pint](https://pint.readthedocs.io/),
[unyt](https://unyt.readthedocs.io/)), among others that add additional functionality on top of the NumPy API.
Yet, users still want to work with these arrays using the familiar NumPy API and re-use existing code with minimal (ideally zero) porting overhead. With this goal in mind, various protocols are defined for implementations of multi-dimensional arrays with high-level APIs matching NumPy.

Broadly speaking, there are three groups of features used for interoperability with NumPy:

Methods of turning a foreign object into an ndarray;

Methods of deferring execution from a NumPy function to another array library;

Methods that use NumPy functions and return an instance of a foreign object.

We describe these features below.

## 1. Using arbitrary objects in NumPy[#](#using-arbitrary-objects-in-numpy)
The first set of interoperability features from the NumPy API allows foreign objects to be treated as NumPy arrays whenever possible. When NumPy functions encounter a foreign object, they will try (in order):

The buffer protocol, described

[in the Python C-API documentation](https://docs.python.org/3/c-api/buffer.html).
The

`__array_interface__`
protocol, described[in this page](../reference/arrays.interface.html#arrays-interface). A precursor to Python’s buffer protocol, it defines a way to access the contents of a NumPy array from other C extensions.
The

`__array__()`
method, which asks an arbitrary object to convert itself into an array.
For both the buffer and the `__array_interface__`
protocols, the object
describes its memory layout and NumPy does everything else (zero-copy if
possible). If that’s not possible, the object itself is responsible for
returning a `ndarray`
from `__array__()`
.

[DLPack](https://dmlc.github.io/dlpack/latest/index.html) is yet another protocol to convert foreign objects
to NumPy arrays in a language and device agnostic manner. NumPy doesn’t implicitly
convert objects to ndarrays using DLPack. It provides the function
[ numpy.from_dlpack](../reference/generated/numpy.from_dlpack.html#numpy.from_dlpack) that accepts any object implementing the
`__dlpack__`
method
and outputs a NumPy ndarray (which is generally a view of the input object’s data
buffer). The [Python Specification for DLPack](https://dmlc.github.io/dlpack/latest/python_spec.html#python-spec)page explains the
`__dlpack__`
protocol
in detail.### The array interface protocol[#](#the-array-interface-protocol)
The [array interface protocol](../reference/arrays.interface.html#arrays-interface) defines a way for
array-like objects to re-use each other’s data buffers. Its implementation
relies on the existence of the following attributes or methods:

`__array_interface__`
: a Python dictionary containing the shape, the element type, and optionally, the data buffer address and the strides of an array-like object;
`__array__()`
: a method returning the NumPy ndarray view of an array-like object;
The `__array_interface__`
attribute can be inspected directly:

```
>>> import numpy as np
>>> x = np.array([1, 2, 5.0, 8])
>>> x.__array_interface__
{'data': (94708397920832, False), 'strides': None, 'descr': [('', '<f8')], 'typestr': '<f8', 'shape': (4,), 'version': 3}
```
The `__array_interface__`
attribute can also be used to manipulate the object
data in place:

```
>>> class wrapper():
... pass
...
>>> arr = np.array([1, 2, 3, 4])
>>> buf = arr.__array_interface__
>>> buf
{'data': (140497590272032, False), 'strides': None, 'descr': [('', '<i8')], 'typestr': '<i8', 'shape': (4,), 'version': 3}
>>> buf['shape'] = (2, 2)
>>> w = wrapper()
>>> w.__array_interface__ = buf
>>> new_arr = np.array(w, copy=False)
>>> new_arr
array([[1, 2],
[3, 4]])
```
We can check that `arr`
and `new_arr`
share the same data buffer:

```
>>> new_arr[0, 0] = 1000
>>> new_arr
array([[1000, 2],
[ 3, 4]])
>>> arr
array([1000, 2, 3, 4])
```
### The `__array__()`
method[#](#the-array-method)
The `__array__()`
method ensures that any NumPy-like object (an array, any
object exposing the array interface, an object whose `__array__()`
method
returns an array or any nested sequence) that implements it can be used as a
NumPy array. If possible, this will mean using `__array__()`
to create a NumPy
ndarray view of the array-like object. Otherwise, this copies the data into a
new ndarray object. This is not optimal, as coercing arrays into ndarrays may
cause performance problems or create the need for copies and loss of metadata,
as the original object and any attributes/behavior it may have had, is lost.

To see an example of a custom array implementation including the use of
`__array__()`
, see [Writing custom array containers](basics.dispatch.html#basics-dispatch).

### The DLPack Protocol[#](#the-dlpack-protocol)
The [DLPack](https://dmlc.github.io/dlpack/latest/index.html) protocol defines a memory-layout of
strided n-dimensional array objects. It offers the following syntax
for data exchange:

A

function, which accepts (array) objects with a`numpy.from_dlpack`
`__dlpack__`
method and uses that method to construct a new array containing the data from`x`
.
`__dlpack__(self, stream=None)`
and`__dlpack_device__`
methods on the array object, which will be called from within`from_dlpack`
, to query what device the array is on (may be needed to pass in the correct stream, e.g. in the case of multiple GPUs) and to access the data.
Unlike the buffer protocol, DLPack allows exchanging arrays containing data on
devices other than the CPU (e.g. Vulkan or GPU). Since NumPy only supports CPU,
it can only convert objects whose data exists on the CPU. But other libraries,
like [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/), may exchange data on GPU using this protocol.

## 2. Operating on foreign objects without converting[#](#operating-on-foreign-objects-without-converting)
A second set of methods defined by the NumPy API allows us to defer the execution from a NumPy function to another array library.

Consider the following function.

```
>>> import numpy as np
>>> def f(x):
... return np.mean(np.exp(x))
```
Note that [ np.exp](../reference/generated/numpy.exp.html#numpy.exp) is a

[ufunc](basics.ufuncs.html#ufuncs-basics), which means that it operates on ndarrays in an element-by-element fashion. On the other hand,
[operates along one of the array’s axes.](../reference/generated/numpy.mean.html#numpy.mean)
`np.mean`
We can apply `f`
to a NumPy ndarray object directly:

```
>>> x = np.array([1, 2, 3, 4])
>>> f(x)
21.1977562209304
```
We would like this function to work equally well with any NumPy-like array object.

NumPy allows a class to indicate that it would like to handle computations in a custom-defined way through the following interfaces:

`__array_ufunc__`
: allows third-party objects to support and override[ufuncs](basics.ufuncs.html#ufuncs-basics).
`__array_function__`
: a catch-all for NumPy functionality that is not covered by the`__array_ufunc__`
protocol for universal functions.
As long as foreign objects implement the `__array_ufunc__`
or
`__array_function__`
protocols, it is possible to operate on them without the
need for explicit conversion.

### The `__array_ufunc__`
protocol[#](#the-array-ufunc-protocol)
A [universal function (or ufunc for short)](basics.ufuncs.html#ufuncs-basics) is a
“vectorized” wrapper for a function that takes a fixed number of specific inputs
and produces a fixed number of specific outputs. The output of the ufunc (and
its methods) is not necessarily a ndarray, if not all input arguments are
ndarrays. Indeed, if any input defines an `__array_ufunc__`
method, control
will be passed completely to that function, i.e., the ufunc is overridden. The
`__array_ufunc__`
method defined on that (non-ndarray) object has access to
the NumPy ufunc. Because ufuncs have a well-defined structure, the foreign
`__array_ufunc__`
method may rely on ufunc attributes like `.at()`
,
`.reduce()`
, and others.

A subclass can override what happens when executing NumPy ufuncs on it by
overriding the default `ndarray.__array_ufunc__`
method. This method is
executed instead of the ufunc and should return either the result of the
operation, or `NotImplemented`
if the operation requested is not implemented.

### The `__array_function__`
protocol[#](#the-array-function-protocol)
To achieve enough coverage of the NumPy API to support downstream projects,
there is a need to go beyond `__array_ufunc__`
and implement a protocol that
allows arguments of a NumPy function to take control and divert execution to
another function (for example, a GPU or parallel implementation) in a way that
is safe and consistent across projects.

The semantics of `__array_function__`
are very similar to `__array_ufunc__`
,
except the operation is specified by an arbitrary callable object rather than a
ufunc instance and method. For more details, see [NEP 18 — A dispatch mechanism for NumPy’s high level array functions](https://numpy.org/neps/nep-0018-array-function-protocol.html#nep18).

## 3. Returning foreign objects[#](#returning-foreign-objects)
A third type of feature set is meant to use the NumPy function implementation
and then convert the return value back into an instance of the foreign object.
The `__array_finalize__`
and `__array_wrap__`
methods act behind the scenes
to ensure that the return type of a NumPy function can be specified as needed.

The `__array_finalize__`
method is the mechanism that NumPy provides to allow
subclasses to handle the various ways that new instances get created. This
method is called whenever the system internally allocates a new array from an
object which is a subclass (subtype) of the ndarray. It can be used to change
attributes after construction, or to update meta-information from the “parent.”

The `__array_wrap__`
method “wraps up the action” in the sense of allowing any
object (such as user-defined functions) to set the type of its return value and
update attributes and metadata. This can be seen as the opposite of the
`__array__`
method. At the end of every object that implements
`__array_wrap__`
, this method is called on the input object with the highest
*array priority*, or the output object if one was specified. The
`__array_priority__`
attribute is used to determine what type of object to
return in situations where there is more than one possibility for the Python
type of the returned object. For example, subclasses may opt to use this method
to transform the output array into an instance of the subclass and update
metadata before returning the array to the user.

For more information on these methods, see [Subclassing ndarray](basics.subclassing.html#basics-subclassing) and
[Specific features of ndarray sub-typing](c-info.beyond-basics.html#specific-array-subtyping).

## Interoperability examples[#](#interoperability-examples)
### Example: Pandas `Series`
objects[#](#example-pandas-series-objects)
Consider the following:

```
>>> import pandas as pd
>>> ser = pd.Series([1, 2, 3, 4])
>>> type(ser)
pandas.core.series.Series
```
Now, `ser`
is **not** a ndarray, but because it
[implements the __array_ufunc__ protocol](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe-interoperability-with-numpy-functions),
we can apply ufuncs to it as if it were a ndarray:

```
>>> np.exp(ser)
0 2.718282
1 7.389056
2 20.085537
3 54.598150
dtype: float64
>>> np.sin(ser)
0 0.841471
1 0.909297
2 0.141120
3 -0.756802
dtype: float64
```
We can even do operations with other ndarrays:

```
>>> np.add(ser, np.array([5, 6, 7, 8]))
0 6
1 8
2 10
3 12
dtype: int64
>>> f(ser)
21.1977562209304
>>> result = ser.__array__()
>>> type(result)
numpy.ndarray
```
### Example: PyTorch tensors[#](#example-pytorch-tensors)
[PyTorch](https://pytorch.org/) is an optimized tensor library for deep
learning using GPUs and CPUs. PyTorch arrays are commonly called *tensors*.
Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or
other hardware accelerators. In fact, tensors and NumPy arrays can often share
the same underlying memory, eliminating the need to copy data.
```
>>> import torch
>>> data = [[1, 2],[3, 4]]
>>> x_np = np.array(data)
>>> x_tensor = torch.tensor(data)
```
Note that `x_np`
and `x_tensor`
are different kinds of objects:

```
>>> x_np
array([[1, 2],
[3, 4]])
>>> x_tensor
tensor([[1, 2],
[3, 4]])
```
However, we can treat PyTorch tensors as NumPy arrays without the need for explicit conversion:

```
>>> np.exp(x_tensor)
tensor([[ 2.7183, 7.3891],
[20.0855, 54.5982]], dtype=torch.float64)
```
Also, note that the return type of this function is compatible with the initial data type.

Warning

While this mixing of ndarrays and tensors may be convenient, it is not recommended. It will not work for non-CPU tensors, and will have unexpected behavior in corner cases. Users should prefer explicitly converting the ndarray to a tensor.

Note

PyTorch does not implement `__array_function__`
or `__array_ufunc__`
.
Under the hood, the `Tensor.__array__()`
method returns a NumPy ndarray as
a view of the tensor data buffer. See [this issue](https://github.com/pytorch/pytorch/issues/24015) and the
[__torch_function__ implementation](https://github.com/pytorch/pytorch/blob/master/torch/overrides.py)
for details.

Note also that we can see `__array_wrap__`
in action here, even though
`torch.Tensor`
is not a subclass of ndarray:

```
>>> import torch
>>> t = torch.arange(4)
>>> np.abs(t)
tensor([0, 1, 2, 3])
```
PyTorch implements `__array_wrap__`
to be able to get tensors back from NumPy
functions, and we can modify it directly to control which type of objects are
returned from these functions.

### Example: CuPy arrays[#](#example-cupy-arrays)
CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing
with Python. CuPy implements a subset of the NumPy interface by implementing
`cupy.ndarray`
, [a counterpart to NumPy ndarrays](https://docs.cupy.dev/en/stable/reference/ndarray.html).

```
>>> import cupy as cp
>>> x_gpu = cp.array([1, 2, 3, 4])
```
The `cupy.ndarray`
object implements the `__array_ufunc__`
interface. This
enables NumPy ufuncs to be applied to CuPy arrays (this will defer operation to
the matching CuPy CUDA/ROCm implementation of the ufunc):

```
>>> np.mean(np.exp(x_gpu))
array(21.19775622)
```
Note that the return type of these operations is still consistent with the initial type:

```
>>> arr = cp.random.randn(1, 2, 3, 4).astype(cp.float32)
>>> result = np.sum(arr)
>>> print(type(result))
<class 'cupy._core.core.ndarray'>
```
See [this page in the CuPy documentation for details](https://docs.cupy.dev/en/stable/reference/ufunc.html).

`cupy.ndarray`
also implements the `__array_function__`
interface, meaning
it is possible to do operations such as
```
>>> a = np.random.randn(100, 100)
>>> a_gpu = cp.asarray(a)
>>> qr_gpu = np.linalg.qr(a_gpu)
```
CuPy implements many NumPy functions on `cupy.ndarray`
objects, but not all.
See [the CuPy documentation](https://docs.cupy.dev/en/stable/user_guide/difference.html)
for details.

### Example: Dask arrays[#](#example-dask-arrays)
Dask is a flexible library for parallel computing in Python. Dask Array implements a subset of the NumPy ndarray interface using blocked algorithms, cutting up the large array into many small arrays. This allows computations on larger-than-memory arrays using multiple cores.

Dask supports `__array__()`
and `__array_ufunc__`
.

```
>>> import dask.array as da
>>> x = da.random.normal(1, 0.1, size=(20, 20), chunks=(10, 10))
>>> np.mean(np.exp(x))
dask.array<mean_agg-aggregate, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>
>>> np.mean(np.exp(x)).compute()
5.090097550553843
```
Note

Dask is lazily evaluated, and the result from a computation isn’t computed
until you ask for it by invoking `compute()`
.

See [the Dask array documentation](https://docs.dask.org/en/stable/array.html)
and the [scope of Dask arrays interoperability with NumPy arrays](https://docs.dask.org/en/stable/array.html#scope) for details.

### Example: DLPack[#](#example-dlpack)
Several Python data science libraries implement the `__dlpack__`
protocol.
Among them are [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/). A full list of libraries that implement
this protocol can be found on
[this page of DLPack documentation](https://dmlc.github.io/dlpack/latest/index.html).

Convert a PyTorch CPU tensor to NumPy array:

```
>>> import torch
>>> x_torch = torch.arange(5)
>>> x_torch
tensor([0, 1, 2, 3, 4])
>>> x_np = np.from_dlpack(x_torch)
>>> x_np
array([0, 1, 2, 3, 4])
>>> # note that x_np is a view of x_torch
>>> x_torch[1] = 100
>>> x_torch
tensor([ 0, 100, 2, 3, 4])
>>> x_np
array([ 0, 100, 2, 3, 4])
```
The imported arrays are read-only so writing or operating in-place will fail:

```
>>> x.flags.writeable
False
>>> x_np[1] = 1
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
ValueError: assignment destination is read-only
```
A copy must be created in order to operate on the imported arrays in-place, but will mean duplicating the memory. Do not do this for very large arrays:

```
>>> x_np_copy = x_np.copy()
>>> x_np_copy.sort() # works
```
Note

Note that GPU tensors can’t be converted to NumPy arrays since NumPy doesn’t support GPU devices:

```
>>> x_torch = torch.arange(5, device='cuda')
>>> np.from_dlpack(x_torch)
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
RuntimeError: Unsupported device in DLTensor.
```
But, if both libraries support the device the data buffer is on, it is
possible to use the `__dlpack__`
protocol (e.g. [PyTorch](https://pytorch.org/) and [CuPy](https://cupy.dev/)):

```
>>> x_torch = torch.arange(5, device='cuda')
>>> x_cupy = cupy.from_dlpack(x_torch)
```
Similarly, a NumPy array can be converted to a PyTorch tensor:

```
>>> x_np = np.arange(5)
>>> x_torch = torch.from_dlpack(x_np)
```
Read-only arrays cannot be exported:

```
>>> x_np = np.arange(5)
>>> x_np.flags.writeable = False
>>> torch.from_dlpack(x_np)
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File ".../site-packages/torch/utils/dlpack.py", line 63, in from_dlpack
dlpack = ext_tensor.__dlpack__()
TypeError: NumPy currently only supports dlpack for writeable arrays
```
## Further reading[#](#further-reading)
[Special attributes and methods](../reference/arrays.classes.html#special-attributes-and-methods)(details on the`__array_ufunc__`
and`__array_function__`
protocols)
[Subclassing ndarray](basics.subclassing.html#basics-subclassing)(details on the`__array_wrap__`
and`__array_finalize__`
methods)
[Specific features of ndarray sub-typing](c-info.beyond-basics.html#specific-array-subtyping)(more details on the implementation of`__array_finalize__`
,`__array_wrap__`
and`__array_priority__`
)# Data types[#](#data-types)
See also

## Array types and conversions between types[#](#array-types-and-conversions-between-types)
NumPy supports a much greater variety of numerical types than Python does. This section shows which are available, and how to modify an array’s data-type.

The primitive types supported are tied closely to those in C:

Numpy type

|
C type

|
Description

|
---|---|---|
|
Boolean (True or False) stored as a byte

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
|
Platform-defined

|
Half precision float: sign bit, 5 bits exponent, 10 bits mantissa

|
|
Platform-defined single precision float: typically sign bit, 8 bits exponent, 23 bits mantissa

|
|
Platform-defined double precision float: typically sign bit, 11 bits exponent, 52 bits mantissa.

|
|
Platform-defined extended-precision float

|
|
Complex number, represented by two single-precision floats (real and imaginary components)

|
|
Complex number, represented by two double-precision floats (real and imaginary components).

|
|
Complex number, represented by two extended-precision floats (real and imaginary components).

|
Since many of these have platform-dependent definitions, a set of fixed-size
aliases are provided (See [Sized aliases](../reference/arrays.scalars.html#sized-aliases)).

NumPy numerical types are instances of `dtype`
(data-type) objects, each
having unique characteristics. Once you have imported NumPy using
`>>> import numpy as np`
the dtypes are available as `np.bool_`
, `np.float32`
, etc.

Advanced types, not listed above, are explored in
section [Structured arrays](basics.rec.html#structured-arrays).

There are 5 basic numerical types representing booleans (bool), integers (int),
unsigned integers (uint) floating point (float) and complex. Those with numbers
in their name indicate the bitsize of the type (i.e. how many bits are needed
to represent a single value in memory). Some types, such as `int`
and
`intp`
, have differing bitsizes, dependent on the platforms (e.g. 32-bit
vs. 64-bit machines). This should be taken into account when interfacing
with low-level code (such as C or Fortran) where the raw memory is addressed.

Data-types can be used as functions to convert python numbers to array scalars (see the array scalar section for an explanation), python sequences of numbers to arrays of that type, or as arguments to the dtype keyword that many numpy functions or methods accept. Some examples:

```
>>> x = np.float32(1.0)
>>> x
1.0
>>> y = np.int_([1,2,4])
>>> y
array([1, 2, 4])
>>> z = np.arange(3, dtype=np.uint8)
>>> z
array([0, 1, 2], dtype=uint8)
```
Array types can also be referred to by character codes, mostly to retain backward compatibility with older packages such as Numeric. Some documentation may still refer to these, for example:

```
>>> np.array([1, 2, 3], dtype='f')
array([1., 2., 3.], dtype=float32)
```
We recommend using dtype objects instead.

To convert the type of an array, use the .astype() method (preferred) or the type itself as a function. For example:

```
>>> z.astype(float)
array([0., 1., 2.])
>>> np.int8(z)
array([0, 1, 2], dtype=int8)
```
Note that, above, we use the *Python* float object as a dtype. NumPy knows
that `int`
refers to `np.int_`
, `bool`
means `np.bool_`
,
that `float`
is `np.float_`
and `complex`
is `np.complex_`
.
The other data-types do not have Python equivalents.

To determine the type of an array, look at the dtype attribute:

```
>>> z.dtype
dtype('uint8')
```
dtype objects also contain information about the type, such as its bit-width and its byte-order. The data type can also be used indirectly to query properties of the type, such as whether it is an integer:

```
>>> d = np.dtype(int)
>>> d
dtype('int32')
>>> np.issubdtype(d, np.integer)
True
>>> np.issubdtype(d, np.floating)
False
```
## Array Scalars[#](#array-scalars)
NumPy generally returns elements of arrays as array scalars (a scalar
with an associated dtype). Array scalars differ from Python scalars, but
for the most part they can be used interchangeably (the primary
exception is for versions of Python older than v2.x, where integer array
scalars cannot act as indices for lists and tuples). There are some
exceptions, such as when code requires very specific attributes of a scalar
or when it checks specifically whether a value is a Python scalar. Generally,
problems are easily fixed by explicitly converting array scalars
to Python scalars, using the corresponding Python type function
(e.g., `int`
, `float`
, `complex`
, `str`
, `unicode`
).

The primary advantage of using array scalars is that
they preserve the array type (Python may not have a matching scalar type
available, e.g. `int16`
). Therefore, the use of array scalars ensures
identical behaviour between arrays and scalars, irrespective of whether the
value is inside an array or not. NumPy scalars also have many of the same
methods arrays do.

## Overflow Errors[#](#overflow-errors)
The fixed size of NumPy numeric types may cause overflow errors when a value
requires more memory than available in the data type. For example,
[ numpy.power](../reference/generated/numpy.power.html#numpy.power) evaluates

`100 ** 8`
correctly for 64-bit integers,
but gives 1874919424 (incorrect) for a 32-bit integer.```
>>> np.power(100, 8, dtype=np.int64)
10000000000000000
>>> np.power(100, 8, dtype=np.int32)
1874919424
```
The behaviour of NumPy and Python integer types differs significantly for
integer overflows and may confuse users expecting NumPy integers to behave
similar to Python’s `int`
. Unlike NumPy, the size of Python’s `int`
is
flexible. This means Python integers may expand to accommodate any integer and
will not overflow.

NumPy provides [ numpy.iinfo](../reference/generated/numpy.iinfo.html#numpy.iinfo) and

[to verify the minimum or maximum values of NumPy integer and floating point values respectively](../reference/generated/numpy.finfo.html#numpy.finfo)
`numpy.finfo`
```
>>> np.iinfo(int) # Bounds of the default integer on this system.
iinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)
>>> np.iinfo(np.int32) # Bounds of a 32-bit integer
iinfo(min=-2147483648, max=2147483647, dtype=int32)
>>> np.iinfo(np.int64) # Bounds of a 64-bit integer
iinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)
```
If 64-bit integers are still too small the result may be cast to a floating point number. Floating point numbers offer a larger, but inexact, range of possible values.

```
>>> np.power(100, 100, dtype=np.int64) # Incorrect even with 64-bit int
0
>>> np.power(100, 100, dtype=np.float64)
1e+200
```
## Extended Precision[#](#extended-precision)
Python’s floating-point numbers are usually 64-bit floating-point numbers,
nearly equivalent to `np.float64`
. In some unusual situations it may be
useful to use floating-point numbers with more precision. Whether this
is possible in numpy depends on the hardware and on the development
environment: specifically, x86 machines provide hardware floating-point
with 80-bit precision, and while most C compilers provide this as their
`long double`
type, MSVC (standard for Windows builds) makes
`long double`
identical to `double`
(64 bits). NumPy makes the
compiler’s `long double`
available as `np.longdouble`
(and
`np.clongdouble`
for the complex numbers). You can find out what your
numpy provides with `np.finfo(np.longdouble)`
.

NumPy does not provide a dtype with more precision than C’s
`long double`
; in particular, the 128-bit IEEE quad precision
data type (FORTRAN’s `REAL*16`
) is not available.

For efficient memory alignment, `np.longdouble`
is usually stored
padded with zero bits, either to 96 or 128 bits. Which is more efficient
depends on hardware and development environment; typically on 32-bit
systems they are padded to 96 bits, while on 64-bit systems they are
typically padded to 128 bits. `np.longdouble`
is padded to the system
default; `np.float96`
and `np.float128`
are provided for users who
want specific padding. In spite of the names, `np.float96`
and
`np.float128`
provide only as much precision as `np.longdouble`
,
that is, 80 bits on most x86 machines and 64 bits in standard
Windows builds.

Be warned that even if `np.longdouble`
offers more precision than
python `float`
, it is easy to lose that extra precision, since
python often forces values to pass through `float`
. For example,
the `%`
formatting operator requires its arguments to be converted
to standard python types, and it is therefore impossible to preserve
extended precision even if many decimal places are requested. It can
be useful to test your code with the value
`1 + np.finfo(np.longdouble).eps`
.# Universal functions (`ufunc`
) basics[#](#universal-functions-ufunc-basics)
`ufunc`
See also

A universal function (or [ufunc](../glossary.html#term-ufunc) for short) is a function that
operates on [ ndarrays](../reference/generated/numpy.ndarray.html#numpy.ndarray) in an element-by-element fashion,
supporting

[array broadcasting](#ufuncs-broadcasting),
[type casting](#ufuncs-casting), and several other standard features. That is, a ufunc is a “
[vectorized](../glossary.html#term-vectorization)” wrapper for a function that takes a fixed number of specific inputs and produces a fixed number of specific outputs.
In NumPy, universal functions are instances of the
[ numpy.ufunc](../reference/generated/numpy.ufunc.html#numpy.ufunc) class. Many of the built-in functions are
implemented in compiled C code. The basic ufuncs operate on scalars, but
there is also a generalized kind for which the basic elements are sub-arrays
(vectors, matrices, etc.), and broadcasting is done over other dimensions.
The simplest example is the addition operator:

```
>>> np.array([0,2,3,4]) + np.array([1,1,-1,2])
array([1, 3, 2, 6])
```
One can also produce custom [ numpy.ufunc](../reference/generated/numpy.ufunc.html#numpy.ufunc) instances using the

[factory function.](../reference/generated/numpy.frompyfunc.html#numpy.frompyfunc)
`numpy.frompyfunc`
## Ufunc methods[#](#ufunc-methods)
All ufuncs have four methods. They can be found at
[Methods](../reference/ufuncs.html#ufuncs-methods). However, these methods only make sense on scalar
ufuncs that take two input arguments and return one output argument.
Attempting to call these methods on other ufuncs will cause a
[ ValueError](https://docs.python.org/3/library/exceptions.html#ValueError).

The reduce-like methods all take an *axis* keyword, a *dtype*
keyword, and an *out* keyword, and the arrays must all have dimension >= 1.
The *axis* keyword specifies the axis of the array over which the reduction
will take place (with negative values counting backwards). Generally, it is an
integer, though for [ numpy.ufunc.reduce](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce), it can also be a tuple of

`int`
to reduce over several axes at once, or `None`
, to reduce over all
axes. For example:```
>>> x = np.arange(9).reshape(3,3)
>>> x
array([[0, 1, 2],
[3, 4, 5],
[6, 7, 8]])
>>> np.add.reduce(x, 1)
array([ 3, 12, 21])
>>> np.add.reduce(x, (0, 1))
36
```
The *dtype* keyword allows you to manage a very common problem that arises
when naively using [ ufunc.reduce](../reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce). Sometimes you may
have an array of a certain data type and wish to add up all of its
elements, but the result does not fit into the data type of the
array. This commonly happens if you have an array of single-byte
integers. The

*dtype*keyword allows you to alter the data type over which the reduction takes place (and therefore the type of the output). Thus, you can ensure that the output is a data type with precision large enough to handle your output. The responsibility of altering the reduce type is mostly up to you. There is one exception: if no
*dtype*is given for a reduction on the “add” or “multiply” operations, then if the input type is an integer (or Boolean) data-type and smaller than the size of the
[data type, it will be internally upcast to the](../reference/arrays.scalars.html#numpy.int_)
`numpy.int_`
[(or](../reference/arrays.scalars.html#numpy.int_)
`int_`
[) data-type. In the previous example:](../reference/arrays.scalars.html#numpy.uint)
`numpy.uint`
```
>>> x.dtype
dtype('int64')
>>> np.multiply.reduce(x, dtype=float)
array([ 0., 28., 80.])
```
Finally, the *out* keyword allows you to
provide an output array (for single-output ufuncs, which are currently the only
ones supported; for future extension, however, a tuple with a single argument
can be passed in). If *out* is given, the *dtype* argument is ignored.
Considering `x`
from the previous example:

```
>>> y = np.zeros(3, dtype=int)
>>> y
array([0, 0, 0])
>>> np.multiply.reduce(x, dtype=float, out=y)
array([ 0, 28, 80])
```
Ufuncs also have a fifth method, [ numpy.ufunc.at](../reference/generated/numpy.ufunc.at.html#numpy.ufunc.at), that allows in place
operations to be performed using advanced indexing. No

[buffering](#use-of-internal-buffers)is used on the dimensions where advanced indexing is used, so the advanced index can list an item more than once and the operation will be performed on the result of the previous operation for that item.
## Output type determination[#](#output-type-determination)
The output of the ufunc (and its methods) is not necessarily an
[ ndarray](../reference/generated/numpy.ndarray.html#numpy.ndarray), if all input arguments are not

[. Indeed, if any input defines an](../reference/generated/numpy.ndarray.html#numpy.ndarray)
`ndarrays`
[method, control will be passed completely to that function, i.e., the ufunc is](../reference/arrays.classes.html#numpy.class.__array_ufunc__)
`__array_ufunc__`
[overridden](#ufuncs-overrides).
If none of the inputs overrides the ufunc, then
all output arrays will be passed to the
[ __array_prepare__](../reference/arrays.classes.html#numpy.class.__array_prepare__) and

[methods of the input (besides](../reference/arrays.classes.html#numpy.class.__array_wrap__)
`__array_wrap__`
[, and scalars) that defines it](../reference/generated/numpy.ndarray.html#numpy.ndarray)
`ndarrays`
**and**has the highest
[of any other input to the universal function. The default](../reference/arrays.classes.html#numpy.class.__array_priority__)
`__array_priority__`
[of the ndarray is 0.0, and the default](../reference/arrays.classes.html#numpy.class.__array_priority__)
`__array_priority__`
[of a subtype is 0.0. Matrices have](../reference/arrays.classes.html#numpy.class.__array_priority__)
`__array_priority__`
[equal to 10.0.](../reference/arrays.classes.html#numpy.class.__array_priority__)
`__array_priority__`
All ufuncs can also take output arguments. If necessary, output will
be cast to the data-type(s) of the provided output array(s). If a class
with an [ __array__](../reference/arrays.classes.html#numpy.class.__array__) method is used for the output,
results will be written to the object returned by

[. Then, if the class also has an](../reference/arrays.classes.html#numpy.class.__array__)
`__array__`
[method, it is called so metadata may be determined based on the context of the ufunc (the context consisting of the ufunc itself, the arguments passed to the ufunc, and the ufunc domain.) The array object returned by](../reference/arrays.classes.html#numpy.class.__array_prepare__)
`__array_prepare__`
[is passed to the ufunc for computation. Finally, if the class also has an](../reference/arrays.classes.html#numpy.class.__array_prepare__)
`__array_prepare__`
[method, the returned](../reference/arrays.classes.html#numpy.class.__array_wrap__)
`__array_wrap__`
[result will be passed to that method just before passing control back to the caller.](../reference/generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
## Broadcasting[#](#broadcasting)
See also

Each universal function takes array inputs and produces array outputs
by performing the core function element-wise on the inputs (where an
element is generally a scalar, but can be a vector or higher-order
sub-array for generalized ufuncs). Standard
[broadcasting rules](basics.broadcasting.html#general-broadcasting-rules) are applied
so that inputs not sharing exactly the
same shapes can still be usefully operated on.

By these rules, if an input has a dimension size of 1 in its shape, the
first data entry in that dimension will be used for all calculations along
that dimension. In other words, the stepping machinery of the
[ufunc](../glossary.html#term-ufunc) will simply not step along that dimension (the
[stride](../reference/arrays.ndarray.html#memory-layout) will be 0 for that dimension).

## Type casting rules[#](#type-casting-rules)
Note

In NumPy 1.6.0, a type promotion API was created to encapsulate the
mechanism for determining output types. See the functions
[ numpy.result_type](../reference/generated/numpy.result_type.html#numpy.result_type),

[, and](../reference/generated/numpy.promote_types.html#numpy.promote_types)
`numpy.promote_types`
[for more details.](../reference/generated/numpy.min_scalar_type.html#numpy.min_scalar_type)
`numpy.min_scalar_type`
At the core of every ufunc is a one-dimensional strided loop that
implements the actual function for a specific type combination. When a
ufunc is created, it is given a static list of inner loops and a
corresponding list of type signatures over which the ufunc operates.
The ufunc machinery uses this list to determine which inner loop to
use for a particular case. You can inspect the [ .types](../reference/generated/numpy.ufunc.types.html#numpy.ufunc.types) attribute for a particular ufunc to see which type
combinations have a defined inner loop and which output type they
produce (

[character codes](../reference/arrays.scalars.html#arrays-scalars-character-codes)are used in said output for brevity).
Casting must be done on one or more of the inputs whenever the ufunc does not have a core loop implementation for the input types provided. If an implementation for the input types cannot be found, then the algorithm searches for an implementation with a type signature to which all of the inputs can be cast “safely.” The first one it finds in its internal list of loops is selected and performed, after all necessary type casting. Recall that internal copies during ufuncs (even for casting) are limited to the size of an internal buffer (which is user settable).

Note

Universal functions in NumPy are flexible enough to have mixed type
signatures. Thus, for example, a universal function could be defined
that works with floating-point and integer values. See
[ numpy.ldexp](../reference/generated/numpy.ldexp.html#numpy.ldexp) for an example.

By the above description, the casting rules are essentially
implemented by the question of when a data type can be cast “safely”
to another data type. The answer to this question can be determined in
Python with a function call: [ can_cast(fromtype, totype)](../reference/generated/numpy.can_cast.html#numpy.can_cast). The example below shows the results of this call for
the 24 internally supported types on the author’s 64-bit system. You
can generate this table for your system with the code given in the example.

Example

Code segment showing the “can cast safely” table for a 64-bit system. Generally the output depends on the system; your system might result in a different table.

```
>>> mark = {False: ' -', True: ' Y'}
>>> def print_table(ntypes):
... print('X ' + ' '.join(ntypes))
... for row in ntypes:
... print(row, end='')
... for col in ntypes:
... print(mark[np.can_cast(row, col)], end='')
... print()
...
>>> print_table(np.typecodes['All'])
X ? b h i l q p B H I L Q P e f d g F D G S U V O M m
? Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y
b - Y Y Y Y Y Y - - - - - - Y Y Y Y Y Y Y Y Y Y Y - Y
h - - Y Y Y Y Y - - - - - - - Y Y Y Y Y Y Y Y Y Y - Y
i - - - Y Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y
l - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y
q - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y
p - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y
B - - Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y
H - - - Y Y Y Y - Y Y Y Y Y - Y Y Y Y Y Y Y Y Y Y - Y
I - - - - Y Y Y - - Y Y Y Y - - Y Y - Y Y Y Y Y Y - Y
L - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -
Q - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -
P - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -
e - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y Y - -
f - - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y - -
d - - - - - - - - - - - - - - - Y Y - Y Y Y Y Y Y - -
g - - - - - - - - - - - - - - - - Y - - Y Y Y Y Y - -
F - - - - - - - - - - - - - - - - - Y Y Y Y Y Y Y - -
D - - - - - - - - - - - - - - - - - - Y Y Y Y Y Y - -
G - - - - - - - - - - - - - - - - - - - Y Y Y Y Y - -
S - - - - - - - - - - - - - - - - - - - - Y Y Y Y - -
U - - - - - - - - - - - - - - - - - - - - - Y Y Y - -
V - - - - - - - - - - - - - - - - - - - - - - Y Y - -
O - - - - - - - - - - - - - - - - - - - - - - - Y - -
M - - - - - - - - - - - - - - - - - - - - - - Y Y Y -
m - - - - - - - - - - - - - - - - - - - - - - Y Y - Y
```
You should note that, while included in the table for completeness, the ‘S’, ‘U’, and ‘V’ types cannot be operated on by ufuncs. Also, note that on a 32-bit system the integer types may have different sizes, resulting in a slightly altered table.

Mixed scalar-array operations use a different set of casting rules that ensure that a scalar cannot “upcast” an array unless the scalar is of a fundamentally different kind of data (i.e., under a different hierarchy in the data-type hierarchy) than the array. This rule enables you to use scalar constants in your code (which, as Python types, are interpreted accordingly in ufuncs) without worrying about whether the precision of the scalar constant will cause upcasting on your large (small precision) array.

## Use of internal buffers[#](#use-of-internal-buffers)
Internally, buffers are used for misaligned data, swapped data, and
data that has to be converted from one data type to another. The size
of internal buffers is settable on a per-thread basis. There can
be up to \(2 (n_{\mathrm{inputs}} + n_{\mathrm{outputs}})\)
buffers of the specified size created to handle the data from all the
inputs and outputs of a ufunc. The default size of a buffer is
10,000 elements. Whenever buffer-based calculation would be needed,
but all input arrays are smaller than the buffer size, those
misbehaved or incorrectly-typed arrays will be copied before the
calculation proceeds. Adjusting the size of the buffer may therefore
alter the speed at which ufunc calculations of various sorts are
completed. A simple interface for setting this variable is accessible
using the function [ numpy.setbufsize](../reference/generated/numpy.setbufsize.html#numpy.setbufsize).

## Error handling[#](#error-handling)
Universal functions can trip special floating-point status registers
in your hardware (such as divide-by-zero). If available on your
platform, these registers will be regularly checked during
calculation. Error handling is controlled on a per-thread basis,
and can be configured using the functions [ numpy.seterr](../reference/generated/numpy.seterr.html#numpy.seterr) and

[.](../reference/generated/numpy.seterrcall.html#numpy.seterrcall)
`numpy.seterrcall`
## Overriding ufunc behavior[#](#overriding-ufunc-behavior)
Classes (including ndarray subclasses) can override how ufuncs act on
them by defining certain special methods. For details, see
[Standard array subclasses](../reference/arrays.classes.html#arrays-classes).# Testing the numpy.i Typemaps[#](#testing-the-numpy-i-typemaps)
## Introduction[#](#introduction)
Writing tests for the `numpy.i`
[SWIG](http://www.swig.org)
interface file is a combinatorial headache. At present, 12 different
data types are supported, each with 74 different argument signatures,
for a total of 888 typemaps supported “out of the box”. Each of these
typemaps, in turn, might require several unit tests in order to verify
expected behavior for both proper and improper inputs. Currently,
this results in more than 1,000 individual unit tests executed when
`make test`
is run in the `numpy/tools/swig`
subdirectory.

To facilitate this many similar unit tests, some high-level
programming techniques are employed, including C and [SWIG](http://www.swig.org) macros,
as well as Python inheritance. The purpose of this document is to describe
the testing infrastructure employed to verify that the `numpy.i`
typemaps are working as expected.

## Testing Organization[#](#testing-organization)
There are three independent testing frameworks supported, for one-, two-, and three-dimensional arrays respectively. For one-dimensional arrays, there are two C++ files, a header and a source, named:

```
Vector.h
Vector.cxx
```
that contain prototypes and code for a variety of functions that have one-dimensional arrays as function arguments. The file:

```
Vector.i
```
is a [SWIG](http://www.swig.org) interface file that defines a python module `Vector`
that wraps the functions in `Vector.h`
while utilizing the typemaps
in `numpy.i`
to correctly handle the C arrays.

The `Makefile`
calls `swig`
to generate `Vector.py`
and
`Vector_wrap.cxx`
, and also executes the `setup.py`
script that
compiles `Vector_wrap.cxx`
and links together the extension module
`_Vector.so`
or `_Vector.dylib`
, depending on the platform. This
extension module and the proxy file `Vector.py`
are both placed in a
subdirectory under the `build`
directory.

The actual testing takes place with a Python script named:

```
testVector.py
```
that uses the standard Python library module `unittest`
, which
performs several tests of each function defined in `Vector.h`
for
each data type supported.

Two-dimensional arrays are tested in exactly the same manner. The
above description applies, but with `Matrix`
substituted for
`Vector`
. For three-dimensional tests, substitute `Tensor`
for
`Vector`
. For four-dimensional tests, substitute `SuperTensor`
for `Vector`
. For flat in-place array tests, substitute `Flat`
for `Vector`
.
For the descriptions that follow, we will reference the
`Vector`
tests, but the same information applies to `Matrix`
,
`Tensor`
and `SuperTensor`
tests.

The command `make test`
will ensure that all of the test software is
built and then run all three test scripts.

## Testing Header Files[#](#testing-header-files)
`Vector.h`
is a C++ header file that defines a C macro called
`TEST_FUNC_PROTOS`
that takes two arguments: `TYPE`
, which is a
data type name such as `unsigned int`
; and `SNAME`
, which is a
short name for the same data type with no spaces, e.g. `uint`
. This
macro defines several function prototypes that have the prefix
`SNAME`
and have at least one argument that is an array of type
`TYPE`
. Those functions that have return arguments return a
`TYPE`
value.
`TEST_FUNC_PROTOS`
is then implemented for all of the data types
supported by `numpy.i`
:
-
`signed char`
-
`unsigned char`
-
`short`
-
`unsigned short`
-
`int`
-
`unsigned int`
-
`long`
-
`unsigned long`
-
`long long`
-
`unsigned long long`
-
`float`
-
`double`
## Testing Source Files[#](#testing-source-files)
`Vector.cxx`
is a C++ source file that implements compilable code
for each of the function prototypes specified in `Vector.h`
. It
defines a C macro `TEST_FUNCS`
that has the same arguments and works
in the same way as `TEST_FUNC_PROTOS`
does in `Vector.h`
.
`TEST_FUNCS`
is implemented for each of the 12 data types as above.
## Testing SWIG Interface Files[#](#testing-swig-interface-files)
`Vector.i`
is a [SWIG](http://www.swig.org) interface file that defines python module
`Vector`
. It follows the conventions for using `numpy.i`
as
described in this chapter. It defines a [SWIG](http://www.swig.org) macro
`%apply_numpy_typemaps`
that has a single argument `TYPE`
.
It uses the [SWIG](http://www.swig.org) directive `%apply`
to apply the provided
typemaps to the argument signatures found in `Vector.h`
. This macro
is then implemented for all of the data types supported by
`numpy.i`
. It then does a `%include "Vector.h"`
to wrap all of
the function prototypes in `Vector.h`
using the typemaps in
`numpy.i`
.
## Testing Python Scripts[#](#testing-python-scripts)
After `make`
is used to build the testing extension modules,
`testVector.py`
can be run to execute the tests. As with other
scripts that use `unittest`
to facilitate unit testing,
`testVector.py`
defines a class that inherits from
`unittest.TestCase`
:

```
class VectorTestCase(unittest.TestCase):
```
However, this class is not run directly. Rather, it serves as a base
class to several other python classes, each one specific to a
particular data type. The `VectorTestCase`
class stores two strings
for typing information:

self.typeStr
-
A string that matches one of the

`SNAME`
prefixes used in`Vector.h`
and`Vector.cxx`
. For example,`"double"`
.
self.typeCode
-
A short (typically single-character) string that represents a data type in numpy and corresponds to

`self.typeStr`
. For example, if`self.typeStr`
is`"double"`
, then`self.typeCode`
should be`"d"`
.
Each test defined by the `VectorTestCase`
class extracts the python
function it is trying to test by accessing the `Vector`
module’s
dictionary:

```
length = Vector.__dict__[self.typeStr + "Length"]
```
In the case of double precision tests, this will return the python
function `Vector.doubleLength`
.

We then define a new test case class for each supported data type with a short definition such as:

```
class doubleTestCase(VectorTestCase):
def __init__(self, methodName="runTest"):
VectorTestCase.__init__(self, methodName)
self.typeStr = "double"
self.typeCode = "d"
```
Each of these 12 classes is collected into a `unittest.TestSuite`
,
which is then executed. Errors and failures are summed together and
returned as the exit argument. Any non-zero result indicates that at
least one test did not pass.# Structured arrays[#](#structured-arrays)
## Introduction[#](#introduction)
Structured arrays are ndarrays whose datatype is a composition of simpler
datatypes organized as a sequence of named [fields](../glossary.html#term-field). For example,

```
>>> x = np.array([('Rex', 9, 81.0), ('Fido', 3, 27.0)],
... dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])
>>> x
array([('Rex', 9, 81.), ('Fido', 3, 27.)],
dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f4')])
```
Here `x`
is a one-dimensional array of length two whose datatype is a
structure with three fields: 1. A string of length 10 or less named ‘name’, 2.
a 32-bit integer named ‘age’, and 3. a 32-bit float named ‘weight’.

If you index `x`
at position 1 you get a structure:

```
>>> x[1]
('Fido', 3, 27.)
```
You can access and modify individual fields of a structured array by indexing with the field name:

```
>>> x['age']
array([9, 3], dtype=int32)
>>> x['age'] = 5
>>> x
array([('Rex', 5, 81.), ('Fido', 5, 27.)],
dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f4')])
```
Structured datatypes are designed to be able to mimic ‘structs’ in the C language, and share a similar memory layout. They are meant for interfacing with C code and for low-level manipulation of structured buffers, for example for interpreting binary blobs. For these purposes they support specialized features such as subarrays, nested datatypes, and unions, and allow control over the memory layout of the structure.

Users looking to manipulate tabular data, such as stored in csv files, may find other pydata projects more suitable, such as xarray, pandas, or DataArray. These provide a high-level interface for tabular data analysis and are better optimized for that use. For instance, the C-struct-like memory layout of structured arrays in numpy can lead to poor cache behavior in comparison.

## Structured Datatypes[#](#structured-datatypes)
A structured datatype can be thought of as a sequence of bytes of a certain
length (the structure’s [itemsize](../glossary.html#term-itemsize)) which is interpreted as a collection
of fields. Each field has a name, a datatype, and a byte offset within the
structure. The datatype of a field may be any numpy datatype including other
structured datatypes, and it may also be a [subarray data type](../glossary.html#term-subarray-data-type) which
behaves like an ndarray of a specified shape. The offsets of the fields are
arbitrary, and fields may even overlap. These offsets are usually determined
automatically by numpy, but can also be specified.

### Structured Datatype Creation[#](#structured-datatype-creation)
Structured datatypes may be created using the function [ numpy.dtype](../reference/generated/numpy.dtype.html#numpy.dtype).
There are 4 alternative forms of specification which vary in flexibility and
conciseness. These are further documented in the

[Data Type Objects](../reference/arrays.dtypes.html#arrays-dtypes-constructing)reference page, and in summary they are:
A list of tuples, one tuple per field

Each tuple has the form

`(fieldname, datatype, shape)`
where shape is optional.`fieldname`
is a string (or tuple if titles are used, see[Field Titles](#titles)below),`datatype`
may be any object convertible to a datatype, and`shape`
is a tuple of integers specifying subarray shape.>>> np.dtype([('x', 'f4'), ('y', np.float32), ('z', 'f4', (2, 2))]) dtype([('x', '<f4'), ('y', '<f4'), ('z', '<f4', (2, 2))])
If

`fieldname`
is the empty string`''`
, the field will be given a default name of the form`f#`
, where`#`
is the integer index of the field, counting from 0 from the left:>>> np.dtype([('x', 'f4'), ('', 'i4'), ('z', 'i8')]) dtype([('x', '<f4'), ('f1', '<i4'), ('z', '<i8')])
The byte offsets of the fields within the structure and the total structure itemsize are determined automatically.

A string of comma-separated dtype specifications

In this shorthand notation any of the

[string dtype specifications](../reference/arrays.dtypes.html#arrays-dtypes-constructing)may be used in a string and separated by commas. The itemsize and byte offsets of the fields are determined automatically, and the field names are given the default names`f0`
,`f1`
, etc.>>> np.dtype('i8, f4, S3') dtype([('f0', '<i8'), ('f1', '<f4'), ('f2', 'S3')]) >>> np.dtype('3int8, float32, (2, 3)float64') dtype([('f0', 'i1', (3,)), ('f1', '<f4'), ('f2', '<f8', (2, 3))])
A dictionary of field parameter arrays

This is the most flexible form of specification since it allows control over the byte-offsets of the fields and the itemsize of the structure.

The dictionary has two required keys, ‘names’ and ‘formats’, and four optional keys, ‘offsets’, ‘itemsize’, ‘aligned’ and ‘titles’. The values for ‘names’ and ‘formats’ should respectively be a list of field names and a list of dtype specifications, of the same length. The optional ‘offsets’ value should be a list of integer byte-offsets, one for each field within the structure. If ‘offsets’ is not given the offsets are determined automatically. The optional ‘itemsize’ value should be an integer describing the total size in bytes of the dtype, which must be large enough to contain all the fields.

>>> np.dtype({'names': ['col1', 'col2'], 'formats': ['i4', 'f4']}) dtype([('col1', '<i4'), ('col2', '<f4')]) >>> np.dtype({'names': ['col1', 'col2'], ... 'formats': ['i4', 'f4'], ... 'offsets': [0, 4], ... 'itemsize': 12}) dtype({'names': ['col1', 'col2'], 'formats': ['<i4', '<f4'], 'offsets': [0, 4], 'itemsize': 12})
Offsets may be chosen such that the fields overlap, though this will mean that assigning to one field may clobber any overlapping field’s data. As an exception, fields of

type cannot overlap with other fields, because of the risk of clobbering the internal object pointer and then dereferencing it.`numpy.object_`
The optional ‘aligned’ value can be set to

`True`
to make the automatic offset computation use aligned offsets (see[Automatic Byte Offsets and Alignment](#offsets-and-alignment)), as if the ‘align’ keyword argument ofhad been set to True.`numpy.dtype`
The optional ‘titles’ value should be a list of titles of the same length as ‘names’, see

[Field Titles](#titles)below.
A dictionary of field names

The keys of the dictionary are the field names and the values are tuples specifying type and offset:

>>> np.dtype({'col1': ('i1', 0), 'col2': ('f4', 1)}) dtype([('col1', 'i1'), ('col2', '<f4')])
This form was discouraged because Python dictionaries did not preserve order in Python versions before Python 3.6.

[Field Titles](#titles)may be specified by using a 3-tuple, see below.
### Manipulating and Displaying Structured Datatypes[#](#manipulating-and-displaying-structured-datatypes)
The list of field names of a structured datatype can be found in the `names`
attribute of the dtype object:

```
>>> d = np.dtype([('x', 'i8'), ('y', 'f4')])
>>> d.names
('x', 'y')
```
The dtype of each individual field can be looked up by name:

```
>>> d['x']
dtype('int64')
```
The field names may be modified by assigning to the `names`
attribute using a
sequence of strings of the same length.

The dtype object also has a dictionary-like attribute, `fields`
, whose keys
are the field names (and [Field Titles](#titles), see below) and whose
values are tuples containing the dtype and byte offset of each field.

```
>>> d.fields
mappingproxy({'x': (dtype('int64'), 0), 'y': (dtype('float32'), 8)})
```
Both the `names`
and `fields`
attributes will equal `None`
for
unstructured arrays. The recommended way to test if a dtype is structured is
with *if dt.names is not None* rather than *if dt.names*, to account for dtypes
with 0 fields.

The string representation of a structured datatype is shown in the “list of tuples” form if possible, otherwise numpy falls back to using the more general dictionary form.

### Automatic Byte Offsets and Alignment[#](#automatic-byte-offsets-and-alignment)
Numpy uses one of two methods to automatically determine the field byte offsets
and the overall itemsize of a structured datatype, depending on whether
`align=True`
was specified as a keyword argument to [ numpy.dtype](../reference/generated/numpy.dtype.html#numpy.dtype).

By default (`align=False`
), numpy will pack the fields together such that
each field starts at the byte offset the previous field ended, and the fields
are contiguous in memory.

```
>>> def print_offsets(d):
... print("offsets:", [d.fields[name][1] for name in d.names])
... print("itemsize:", d.itemsize)
>>> print_offsets(np.dtype('u1, u1, i4, u1, i8, u2'))
offsets: [0, 1, 2, 6, 7, 15]
itemsize: 17
```
If `align=True`
is set, numpy will pad the structure in the same way many C
compilers would pad a C-struct. Aligned structures can give a performance
improvement in some cases, at the cost of increased datatype size. Padding
bytes are inserted between fields such that each field’s byte offset will be a
multiple of that field’s alignment, which is usually equal to the field’s size
in bytes for simple datatypes, see [ PyArray_Descr.alignment](../reference/c-api/types-and-structures.html#c.PyArray_Descr.alignment). The
structure will also have trailing padding added so that its itemsize is a
multiple of the largest field’s alignment.

```
>>> print_offsets(np.dtype('u1, u1, i4, u1, i8, u2', align=True))
offsets: [0, 1, 4, 8, 16, 24]
itemsize: 32
```
Note that although almost all modern C compilers pad in this way by default, padding in C structs is C-implementation-dependent so this memory layout is not guaranteed to exactly match that of a corresponding struct in a C program. Some work may be needed, either on the numpy side or the C side, to obtain exact correspondence.

If offsets were specified using the optional `offsets`
key in the
dictionary-based dtype specification, setting `align=True`
will check that
each field’s offset is a multiple of its size and that the itemsize is a
multiple of the largest field size, and raise an exception if not.

If the offsets of the fields and itemsize of a structured array satisfy the
alignment conditions, the array will have the `ALIGNED`
[ flag](../reference/generated/numpy.ndarray.flags.html#numpy.ndarray.flags) set.

A convenience function [ numpy.lib.recfunctions.repack_fields](#numpy.lib.recfunctions.repack_fields) converts an
aligned dtype or array to a packed one and vice versa. It takes either a dtype
or structured ndarray as an argument, and returns a copy with fields re-packed,
with or without padding bytes.

### Field Titles[#](#field-titles)
In addition to field names, fields may also have an associated [title](../glossary.html#term-title),
an alternate name, which is sometimes used as an additional description or
alias for the field. The title may be used to index an array, just like a
field name.

To add titles when using the list-of-tuples form of dtype specification, the field name may be specified as a tuple of two strings instead of a single string, which will be the field’s title and field name respectively. For example:

```
>>> np.dtype([(('my title', 'name'), 'f4')])
dtype([(('my title', 'name'), '<f4')])
```
When using the first form of dictionary-based specification, the titles may be
supplied as an extra `'titles'`
key as described above. When using the second
(discouraged) dictionary-based specification, the title can be supplied by
providing a 3-element tuple `(datatype, offset, title)`
instead of the usual
2-element tuple:

```
>>> np.dtype({'name': ('i4', 0, 'my title')})
dtype([(('my title', 'name'), '<i4')])
```
The `dtype.fields`
dictionary will contain titles as keys, if any
titles are used. This means effectively that a field with a title will be
represented twice in the fields dictionary. The tuple values for these fields
will also have a third element, the field title. Because of this, and because
the `names`
attribute preserves the field order while the `fields`
attribute may not, it is recommended to iterate through the fields of a dtype
using the `names`
attribute of the dtype, which will not list titles, as
in:

```
>>> for name in d.names:
... print(d.fields[name][:2])
(dtype('int64'), 0)
(dtype('float32'), 8)
```
### Union types[#](#union-types)
Structured datatypes are implemented in numpy to have base type
[ numpy.void](../reference/arrays.scalars.html#numpy.void) by default, but it is possible to interpret other numpy
types as structured types using the

`(base_dtype, dtype)`
form of dtype
specification described in
[Data Type Objects](../reference/arrays.dtypes.html#arrays-dtypes-constructing). Here,
`base_dtype`
is
the desired underlying dtype, and fields and flags will be copied from
`dtype`
. This dtype is similar to a ‘union’ in C.## Indexing and Assignment to Structured arrays[#](#indexing-and-assignment-to-structured-arrays)
### Assigning data to a Structured Array[#](#assigning-data-to-a-structured-array)
There are a number of ways to assign values to a structured array: Using python tuples, using scalar values, or using other structured arrays.

#### Assignment from Python Native Types (Tuples)[#](#assignment-from-python-native-types-tuples)
The simplest way to assign values to a structured array is using python tuples. Each assigned value should be a tuple of length equal to the number of fields in the array, and not a list or array as these will trigger numpy’s broadcasting rules. The tuple’s elements are assigned to the successive fields of the array, from left to right:

```
>>> x = np.array([(1, 2, 3), (4, 5, 6)], dtype='i8, f4, f8')
>>> x[1] = (7, 8, 9)
>>> x
array([(1, 2., 3.), (7, 8., 9.)],
dtype=[('f0', '<i8'), ('f1', '<f4'), ('f2', '<f8')])
```
#### Assignment from Scalars[#](#assignment-from-scalars)
A scalar assigned to a structured element will be assigned to all fields. This happens when a scalar is assigned to a structured array, or when an unstructured array is assigned to a structured array:

```
>>> x = np.zeros(2, dtype='i8, f4, ?, S1')
>>> x[:] = 3
>>> x
array([(3, 3., True, b'3'), (3, 3., True, b'3')],
dtype=[('f0', '<i8'), ('f1', '<f4'), ('f2', '?'), ('f3', 'S1')])
>>> x[:] = np.arange(2)
>>> x
array([(0, 0., False, b'0'), (1, 1., True, b'1')],
dtype=[('f0', '<i8'), ('f1', '<f4'), ('f2', '?'), ('f3', 'S1')])
```
Structured arrays can also be assigned to unstructured arrays, but only if the structured datatype has just a single field:

```
>>> twofield = np.zeros(2, dtype=[('A', 'i4'), ('B', 'i4')])
>>> onefield = np.zeros(2, dtype=[('A', 'i4')])
>>> nostruct = np.zeros(2, dtype='i4')
>>> nostruct[:] = twofield
Traceback (most recent call last):
...
TypeError: Cannot cast array data from dtype([('A', '<i4'), ('B', '<i4')]) to dtype('int32') according to the rule 'unsafe'
```
#### Assignment from other Structured Arrays[#](#assignment-from-other-structured-arrays)
Assignment between two structured arrays occurs as if the source elements had been converted to tuples and then assigned to the destination elements. That is, the first field of the source array is assigned to the first field of the destination array, and the second field likewise, and so on, regardless of field names. Structured arrays with a different number of fields cannot be assigned to each other. Bytes of the destination structure which are not included in any of the fields are unaffected.

```
>>> a = np.zeros(3, dtype=[('a', 'i8'), ('b', 'f4'), ('c', 'S3')])
>>> b = np.ones(3, dtype=[('x', 'f4'), ('y', 'S3'), ('z', 'O')])
>>> b[:] = a
>>> b
array([(0., b'0.0', b''), (0., b'0.0', b''), (0., b'0.0', b'')],
dtype=[('x', '<f4'), ('y', 'S3'), ('z', 'O')])
```
#### Assignment involving subarrays[#](#assignment-involving-subarrays)
When assigning to fields which are subarrays, the assigned value will first be broadcast to the shape of the subarray.

### Indexing Structured Arrays[#](#indexing-structured-arrays)
#### Accessing Individual Fields[#](#accessing-individual-fields)
Individual fields of a structured array may be accessed and modified by indexing the array with the field name.

```
>>> x = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])
>>> x['foo']
array([1, 3])
>>> x['foo'] = 10
>>> x
array([(10, 2.), (10, 4.)],
dtype=[('foo', '<i8'), ('bar', '<f4')])
```
The resulting array is a view into the original array. It shares the same memory locations and writing to the view will modify the original array.

```
>>> y = x['bar']
>>> y[:] = 11
>>> x
array([(10, 11.), (10, 11.)],
dtype=[('foo', '<i8'), ('bar', '<f4')])
```
This view has the same dtype and itemsize as the indexed field, so it is typically a non-structured array, except in the case of nested structures.

```
>>> y.dtype, y.shape, y.strides
(dtype('float32'), (2,), (12,))
```
If the accessed field is a subarray, the dimensions of the subarray are appended to the shape of the result:

```
>>> x = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])
>>> x['a'].shape
(2, 2)
>>> x['b'].shape
(2, 2, 3, 3)
```
#### Accessing Multiple Fields[#](#accessing-multiple-fields)
One can index and assign to a structured array with a multi-field index, where the index is a list of field names.

Warning

The behavior of multi-field indexes changed from Numpy 1.15 to Numpy 1.16.

The result of indexing with a multi-field index is a view into the original array, as follows:

```
>>> a = np.zeros(3, dtype=[('a', 'i4'), ('b', 'i4'), ('c', 'f4')])
>>> a[['a', 'c']]
array([(0, 0.), (0, 0.), (0, 0.)],
dtype={'names': ['a', 'c'], 'formats': ['<i4', '<f4'], 'offsets': [0, 8], 'itemsize': 12})
```
Assignment to the view modifies the original array. The view’s fields will be in the order they were indexed. Note that unlike for single-field indexing, the dtype of the view has the same itemsize as the original array, and has fields at the same offsets as in the original array, and unindexed fields are merely missing.

Warning

In Numpy 1.15, indexing an array with a multi-field index returned a copy of
the result above, but with fields packed together in memory as if
passed through [ numpy.lib.recfunctions.repack_fields](#numpy.lib.recfunctions.repack_fields).

The new behavior as of Numpy 1.16 leads to extra “padding” bytes at the location of unindexed fields compared to 1.15. You will need to update any code which depends on the data having a “packed” layout. For instance code such as:

```
>>> a[['a', 'c']].view('i8') # Fails in Numpy 1.16
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
ValueError: When changing to a smaller dtype, its size must be a divisor of the size of original dtype
```
will need to be changed. This code has raised a `FutureWarning`
since
Numpy 1.12, and similar code has raised `FutureWarning`
since 1.7.

In 1.16 a number of functions have been introduced in the
[ numpy.lib.recfunctions](#module-numpy.lib.recfunctions) module to help users account for this
change. These are

[.](#numpy.lib.recfunctions.repack_fields)
`numpy.lib.recfunctions.repack_fields`
[,](#numpy.lib.recfunctions.structured_to_unstructured)
`numpy.lib.recfunctions.structured_to_unstructured`
[,](#numpy.lib.recfunctions.unstructured_to_structured)
`numpy.lib.recfunctions.unstructured_to_structured`
[,](#numpy.lib.recfunctions.apply_along_fields)
`numpy.lib.recfunctions.apply_along_fields`
[, and](#numpy.lib.recfunctions.assign_fields_by_name)
`numpy.lib.recfunctions.assign_fields_by_name`
[.](#numpy.lib.recfunctions.require_fields)
`numpy.lib.recfunctions.require_fields`
The function [ numpy.lib.recfunctions.repack_fields](#numpy.lib.recfunctions.repack_fields) can always be
used to reproduce the old behavior, as it will return a packed copy of the
structured array. The code above, for example, can be replaced with:

```
>>> from numpy.lib.recfunctions import repack_fields
>>> repack_fields(a[['a', 'c']]).view('i8') # supported in 1.16
array([0, 0, 0])
```
Furthermore, numpy now provides a new function
[ numpy.lib.recfunctions.structured_to_unstructured](#numpy.lib.recfunctions.structured_to_unstructured) which is a safer
and more efficient alternative for users who wish to convert structured
arrays to unstructured arrays, as the view above is often intended to do.
This function allows safe conversion to an unstructured type taking into
account padding, often avoids a copy, and also casts the datatypes
as needed, unlike the view. Code such as:

```
>>> b = np.zeros(3, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])
>>> b[['x', 'z']].view('f4')
array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)
```
can be made safer by replacing with:

```
>>> from numpy.lib.recfunctions import structured_to_unstructured
>>> structured_to_unstructured(b[['x', 'z']])
array([[0., 0.],
[0., 0.],
[0., 0.]], dtype=float32)
```
Assignment to an array with a multi-field index modifies the original array:

```
>>> a[['a', 'c']] = (2, 3)
>>> a
array([(2, 0, 3.), (2, 0, 3.), (2, 0, 3.)],
dtype=[('a', '<i4'), ('b', '<i4'), ('c', '<f4')])
```
This obeys the structured array assignment rules described above. For example, this means that one can swap the values of two fields using appropriate multi-field indexes:

```
>>> a[['a', 'c']] = a[['c', 'a']]
```
#### Indexing with an Integer to get a Structured Scalar[#](#indexing-with-an-integer-to-get-a-structured-scalar)
Indexing a single element of a structured array (with an integer index) returns a structured scalar:

```
>>> x = np.array([(1, 2., 3.)], dtype='i, f, f')
>>> scalar = x[0]
>>> scalar
(1, 2., 3.)
>>> type(scalar)
<class 'numpy.void'>
```
Unlike other numpy scalars, structured scalars are mutable and act like views into the original array, such that modifying the scalar will modify the original array. Structured scalars also support access and assignment by field name:

```
>>> x = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])
>>> s = x[0]
>>> s['bar'] = 100
>>> x
array([(1, 100.), (3, 4.)],
dtype=[('foo', '<i8'), ('bar', '<f4')])
```
Similarly to tuples, structured scalars can also be indexed with an integer:

```
>>> scalar = np.array([(1, 2., 3.)], dtype='i, f, f')[0]
>>> scalar[0]
1
>>> scalar[1] = 4
```
Thus, tuples might be thought of as the native Python equivalent to numpy’s
structured types, much like native python integers are the equivalent to
numpy’s integer types. Structured scalars may be converted to a tuple by
calling [ numpy.ndarray.item](../reference/generated/numpy.ndarray.item.html#numpy.ndarray.item):

```
>>> scalar.item(), type(scalar.item())
((1, 4.0, 3.0), <class 'tuple'>)
```
### Viewing Structured Arrays Containing Objects[#](#viewing-structured-arrays-containing-objects)
In order to prevent clobbering object pointers in fields of
[ object](https://docs.python.org/3/library/functions.html#object) type, numpy currently does not allow views of structured
arrays containing objects.

### Structure Comparison and Promotion[#](#structure-comparison-and-promotion)
If the dtypes of two void structured arrays are equal, testing the equality of
the arrays will result in a boolean array with the dimensions of the original
arrays, with elements set to `True`
where all fields of the corresponding
structures are equal:

```
>>> a = np.array([(1, 1), (2, 2)], dtype=[('a', 'i4'), ('b', 'i4')])
>>> b = np.array([(1, 1), (2, 3)], dtype=[('a', 'i4'), ('b', 'i4')])
>>> a == b
array([True, False])
```
NumPy will promote individual field datatypes to perform the comparison.
So the following is also valid (note the `'f4'`
dtype for the `'a'`
field):

```
>>> b = np.array([(1.0, 1), (2.5, 2)], dtype=[("a", "f4"), ("b", "i4")])
>>> a == b
array([True, False])
```
To compare two structured arrays, it must be possible to promote them to a
common dtype as returned by [ numpy.result_type](../reference/generated/numpy.result_type.html#numpy.result_type) and

*np.promote_types*. This enforces that the number of fields, the field names, and the field titles must match precisely. When promotion is not possible, for example due to mismatching field names, NumPy will raise an error. Promotion between two structured dtypes results in a canonical dtype that ensures native byte-order for all fields:
```
>>> np.result_type(np.dtype("i,>i"))
dtype([('f0', '<i4'), ('f1', '<i4')])
>>> np.result_type(np.dtype("i,>i"), np.dtype("i,i"))
dtype([('f0', '<i4'), ('f1', '<i4')])
```
The resulting dtype from promotion is also guaranteed to be packed, meaning that all fields are ordered contiguously and any unnecessary padding is removed:

```
>>> dt = np.dtype("i1,V3,i4,V1")[["f0", "f2"]]
>>> dt
dtype({'names':['f0','f2'], 'formats':['i1','<i4'], 'offsets':[0,4], 'itemsize':9})
>>> np.result_type(dt)
dtype([('f0', 'i1'), ('f2', '<i4')])
```
Note that the result prints without `offsets`
or `itemsize`
indicating no
additional padding.
If a structured dtype is created with `align=True`
ensuring that
`dtype.isalignedstruct`
is true, this property is preserved:

```
>>> dt = np.dtype("i1,V3,i4,V1", align=True)[["f0", "f2"]]
>>> dt
dtype({'names':['f0','f2'], 'formats':['i1','<i4'], 'offsets':[0,4], 'itemsize':12}, align=True)
>>> np.result_type(dt)
dtype([('f0', 'i1'), ('f2', '<i4')], align=True)
>>> np.result_type(dt).isalignedstruct
True
```
When promoting multiple dtypes, the result is aligned if any of the inputs is:

```
>>> np.result_type(np.dtype("i,i"), np.dtype("i,i", align=True))
dtype([('f0', '<i4'), ('f1', '<i4')], align=True)
```
The `<`
and `>`
operators always return `False`
when comparing void
structured arrays, and arithmetic and bitwise operations are not supported.

Changed in version 1.23: Before NumPy 1.23, a warning was given and `False`
returned when
promotion to a common dtype failed.
Further, promotion was much more restrictive: It would reject the mixed
float/integer comparison example above.

## Record Arrays[#](#record-arrays)
As an optional convenience numpy provides an ndarray subclass,
[ numpy.recarray](../reference/generated/numpy.recarray.html#numpy.recarray) that allows access to fields of structured arrays by
attribute instead of only by index.
Record arrays use a special datatype,

[, that allows field access by attribute on the structured scalars obtained from the array. The](../reference/generated/numpy.record.html#numpy.record)
`numpy.record`
`numpy.rec`
module provides functions for creating recarrays from
various objects.
Additional helper functions for creating and manipulating structured arrays
can be found in [.](#module-numpy.lib.recfunctions)
`numpy.lib.recfunctions`
The simplest way to create a record array is with
[ numpy.rec.array](../reference/generated/numpy.core.records.array.html#numpy.core.records.array):

```
>>> recordarr = np.rec.array([(1, 2., 'Hello'), (2, 3., "World")],
... dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'S10')])
>>> recordarr.bar
array([2., 3.], dtype=float32)
>>> recordarr[1:2]
rec.array([(2, 3., b'World')],
dtype=[('foo', '<i4'), ('bar', '<f4'), ('baz', 'S10')])
>>> recordarr[1:2].foo
array([2], dtype=int32)
>>> recordarr.foo[1:2]
array([2], dtype=int32)
>>> recordarr[1].baz
b'World'
```
[ numpy.rec.array](../reference/generated/numpy.core.records.array.html#numpy.core.records.array) can convert a wide variety
of arguments into record arrays, including structured arrays:
```
>>> arr = np.array([(1, 2., 'Hello'), (2, 3., "World")],
... dtype=[('foo', 'i4'), ('bar', 'f4'), ('baz', 'S10')])
>>> recordarr = np.rec.array(arr)
```
The `numpy.rec`
module provides a number of other convenience functions for
creating record arrays, see [record array creation routines](../reference/routines.array-creation.html#routines-array-creation-rec).

A record array representation of a structured array can be obtained using the
appropriate [view](numpy-ndarray-view):

```
>>> arr = np.array([(1, 2., 'Hello'), (2, 3., "World")],
... dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'a10')])
>>> recordarr = arr.view(dtype=np.dtype((np.record, arr.dtype)),
... type=np.recarray)
```
For convenience, viewing an ndarray as type [ numpy.recarray](../reference/generated/numpy.recarray.html#numpy.recarray) will
automatically convert to

[datatype, so the dtype can be left out of the view:](../reference/generated/numpy.record.html#numpy.record)
`numpy.record`
```
>>> recordarr = arr.view(np.recarray)
>>> recordarr.dtype
dtype((numpy.record, [('foo', '<i4'), ('bar', '<f4'), ('baz', 'S10')]))
```
To get back to a plain ndarray both the dtype and type must be reset. The following view does so, taking into account the unusual case that the recordarr was not a structured type:

```
>>> arr2 = recordarr.view(recordarr.dtype.fields or recordarr.dtype, np.ndarray)
```
Record array fields accessed by index or by attribute are returned as a record array if the field has a structured type but as a plain ndarray otherwise.

```
>>> recordarr = np.rec.array([('Hello', (1, 2)), ("World", (3, 4))],
... dtype=[('foo', 'S6'),('bar', [('A', int), ('B', int)])])
>>> type(recordarr.foo)
<class 'numpy.ndarray'>
>>> type(recordarr.bar)
<class 'numpy.recarray'>
```
Note that if a field has the same name as an ndarray attribute, the ndarray attribute takes precedence. Such fields will be inaccessible by attribute but will still be accessible by index.

### Recarray Helper Functions[#](#module-numpy.lib.recfunctions)
Collection of utilities to manipulate structured arrays.

Most of these functions were initially implemented by John Hunter for matplotlib. They have been rewritten and extended for convenience.

numpy.lib.recfunctions.append_fields(*base*,*names*,*data*,*dtypes=None*,*fill_value=-1*,*usemask=True*,*asrecarray=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L653-L721)[#](#numpy.lib.recfunctions.append_fields)
-
Add new fields to an existing array.

The names of the fields are given with the

*names*arguments, the corresponding values with the*data*arguments. If a single field is appended,*names*,*data*and*dtypes*do not have to be lists but just values.Parameters:
-
**base**array
Input array to extend.

**names**string, sequence
String or sequence of strings corresponding to the names of the new fields.

**data**array or sequence of arrays
Array or sequence of arrays storing the fields to add to the base.

**dtypes**sequence of datatypes, optional
Datatype or sequence of datatypes. If None, the datatypes are estimated from the

*data*.
**fill_value**{float}, optional
Filling value used to pad missing data on the shorter arrays.

**usemask**{False, True}, optional
Whether to return a masked array or not.

**asrecarray**{False, True}, optional
Whether to return a recarray (MaskedRecords) or not.

numpy.lib.recfunctions.apply_along_fields(*func*,*arr*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1181-L1222)[#](#numpy.lib.recfunctions.apply_along_fields)
-
Apply function ‘func’ as a reduction across fields of a structured array.

This is similar to

*apply_along_axis*, but treats the fields of a structured array as an extra axis. The fields are all first cast to a common type following the type-promotion rules fromapplied to the field’s dtypes.`numpy.result_type`
Parameters:
-
**func**function
Function to apply on the “field” dimension. This function must support an

*axis*argument, like np.mean, np.sum, etc.
**arr**ndarray
Structured array for which to apply func.

Returns:
-
**out**ndarray
Result of the recution operation

Examples

>>> from numpy.lib import recfunctions as rfn >>> b = np.array([(1, 2, 5), (4, 5, 7), (7, 8 ,11), (10, 11, 12)], ... dtype=[('x', 'i4'), ('y', 'f4'), ('z', 'f8')]) >>> rfn.apply_along_fields(np.mean, b) array([ 2.66666667, 5.33333333, 8.66666667, 11. ]) >>> rfn.apply_along_fields(np.mean, b[['x', 'z']]) array([ 3. , 5.5, 9. , 11. ])
numpy.lib.recfunctions.assign_fields_by_name(*dst*,*src*,*zero_unassigned=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1227-L1263)[#](#numpy.lib.recfunctions.assign_fields_by_name)
-
Assigns values from one structured array to another by field name.

Normally in numpy >= 1.14, assignment of one structured array to another copies fields “by position”, meaning that the first field from the src is copied to the first field of the dst, and so on, regardless of field name.

This function instead copies “by field name”, such that fields in the dst are assigned from the identically named field in the src. This applies recursively for nested structures. This is how structure assignment worked in numpy >= 1.6 to <= 1.13.

Parameters:
-
**dst**ndarray
**src**ndarray
The source and destination arrays during assignment.

**zero_unassigned**bool, optional
If True, fields in the dst for which there was no matching field in the src are filled with the value 0 (zero). This was the behavior of numpy <= 1.13. If False, those fields are not modified.

numpy.lib.recfunctions.drop_fields(*base*,*drop_names*,*usemask=True*,*asrecarray=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L501-L563)[#](#numpy.lib.recfunctions.drop_fields)
-
Return a new array with fields in

*drop_names*dropped.Nested fields are supported.

Changed in version 1.18.0:

returns an array with 0 fields if all fields are dropped, rather than returning`drop_fields`
`None`
as it did previously.Parameters:
-
**base**array
Input array

**drop_names**string or sequence
String or sequence of strings corresponding to the names of the fields to drop.

**usemask**{False, True}, optional
Whether to return a masked array or not.

**asrecarray**string or sequence, optional
Whether to return a recarray or a mrecarray (

*asrecarray=True*) or a plain ndarray or masked array with flexible dtype. The default is False.
Examples

>>> from numpy.lib import recfunctions as rfn >>> a = np.array([(1, (2, 3.0)), (4, (5, 6.0))], ... dtype=[('a', np.int64), ('b', [('ba', np.double), ('bb', np.int64)])]) >>> rfn.drop_fields(a, 'a') array([((2., 3),), ((5., 6),)], dtype=[('b', [('ba', '<f8'), ('bb', '<i8')])]) >>> rfn.drop_fields(a, 'ba') array([(1, (3,)), (4, (6,))], dtype=[('a', '<i8'), ('b', [('bb', '<i8')])]) >>> rfn.drop_fields(a, ['ba', 'bb']) array([(1,), (4,)], dtype=[('a', '<i8')])
numpy.lib.recfunctions.find_duplicates(*a*,*key=None*,*ignoremask=True*,*return_index=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1410-L1465)[#](#numpy.lib.recfunctions.find_duplicates)
-
Find the duplicates in a structured array along a given key

Parameters:
-
**a**array-like
Input array

**key**{string, None}, optional
Name of the fields along which to check the duplicates. If None, the search is performed by records

**ignoremask**{True, False}, optional
Whether masked data should be discarded or considered as duplicates.

**return_index**{False, True}, optional
Whether to return the indices of the duplicated values.

Examples

>>> from numpy.lib import recfunctions as rfn >>> ndtype = [('a', int)] >>> a = np.ma.array([1, 1, 1, 2, 2, 3, 3], ... mask=[0, 0, 1, 0, 0, 0, 1]).view(ndtype) >>> rfn.find_duplicates(a, ignoremask=True, return_index=True) (masked_array(data=[(1,), (1,), (2,), (2,)], mask=[(False,), (False,), (False,), (False,)], fill_value=(999999,), dtype=[('a', '<i8')]), array([0, 1, 3, 4]))
numpy.lib.recfunctions.flatten_descr(*ndtype*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L169-L192)[#](#numpy.lib.recfunctions.flatten_descr)
-
Flatten a structured data-type description.

Examples

>>> from numpy.lib import recfunctions as rfn >>> ndtype = np.dtype([('a', '<i4'), ('b', [('ba', '<f8'), ('bb', '<i4')])]) >>> rfn.flatten_descr(ndtype) (('a', dtype('int32')), ('ba', dtype('float64')), ('bb', dtype('int32')))
numpy.lib.recfunctions.get_fieldstructure(*adtype*,*lastname=None*,*parents=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L225-L269)[#](#numpy.lib.recfunctions.get_fieldstructure)
-
Returns a dictionary with fields indexing lists of their parent fields.

This function is used to simplify access to fields nested in other fields.

Parameters:
-
**adtype**np.dtype
Input datatype

**lastname**optional
Last processed field name (used internally during recursion).

**parents**dictionary
Dictionary of parent fields (used interbally during recursion).

Examples

>>> from numpy.lib import recfunctions as rfn >>> ndtype = np.dtype([('A', int), ... ('B', [('BA', int), ... ('BB', [('BBA', int), ('BBB', int)])])]) >>> rfn.get_fieldstructure(ndtype) ... # XXX: possible regression, order of BBA and BBB is swapped {'A': [], 'B': [], 'BA': ['B'], 'BB': ['B'], 'BBA': ['B', 'BB'], 'BBB': ['B', 'BB']}
numpy.lib.recfunctions.get_names(*adtype*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L105-L134)[#](#numpy.lib.recfunctions.get_names)
-
Returns the field names of the input datatype as a tuple. Input datatype must have fields otherwise error is raised.

Parameters:
-
**adtype**dtype
Input datatype

Examples

>>> from numpy.lib import recfunctions as rfn >>> rfn.get_names(np.empty((1,), dtype=[('A', int)]).dtype) ('A',) >>> rfn.get_names(np.empty((1,), dtype=[('A',int), ('B', float)]).dtype) ('A', 'B') >>> adtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])]) >>> rfn.get_names(adtype) ('a', ('b', ('ba', 'bb')))
numpy.lib.recfunctions.get_names_flat(*adtype*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L137-L166)[#](#numpy.lib.recfunctions.get_names_flat)
-
Returns the field names of the input datatype as a tuple. Input datatype must have fields otherwise error is raised. Nested structure are flattened beforehand.

Parameters:
-
**adtype**dtype
Input datatype

Examples

>>> from numpy.lib import recfunctions as rfn >>> rfn.get_names_flat(np.empty((1,), dtype=[('A', int)]).dtype) is None False >>> rfn.get_names_flat(np.empty((1,), dtype=[('A',int), ('B', str)]).dtype) ('A', 'B') >>> adtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])]) >>> rfn.get_names_flat(adtype) ('a', 'b', 'ba', 'bb')
numpy.lib.recfunctions.join_by(*key*,*r1*,*r2*,*jointype='inner'*,*r1postfix='1'*,*r2postfix='2'*,*defaults=None*,*usemask=True*,*asrecarray=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1474-L1651)[#](#numpy.lib.recfunctions.join_by)
-
Join arrays

*r1*and*r2*on key*key*.The key should be either a string or a sequence of string corresponding to the fields used to join the array. An exception is raised if the

*key*field cannot be found in the two input arrays. Neither*r1*nor*r2*should have any duplicates along*key*: the presence of duplicates will make the output quite unreliable. Note that duplicates are not looked for by the algorithm.Parameters:
-
**key**{string, sequence}
A string or a sequence of strings corresponding to the fields used for comparison.

**r1, r2**arrays
Structured arrays.

**jointype**{‘inner’, ‘outer’, ‘leftouter’}, optional
If ‘inner’, returns the elements common to both r1 and r2. If ‘outer’, returns the common elements as well as the elements of r1 not in r2 and the elements of not in r2. If ‘leftouter’, returns the common elements and the elements of r1 not in r2.

**r1postfix**string, optional
String appended to the names of the fields of r1 that are present in r2 but absent of the key.

**r2postfix**string, optional
String appended to the names of the fields of r2 that are present in r1 but absent of the key.

**defaults**{dictionary}, optional
Dictionary mapping field names to the corresponding default values.

**usemask**{True, False}, optional
Whether to return a MaskedArray (or MaskedRecords is

*asrecarray==True*) or a ndarray.
**asrecarray**{False, True}, optional
Whether to return a recarray (or MaskedRecords if

*usemask==True*) or just a flexible-type ndarray.
Notes

The output is sorted along the key.

A temporary array is formed by dropping the fields not in the key for the two arrays and concatenating the result. This array is then sorted, and the common entries selected. The output is constructed by filling the fields with the selected entries. Matching is not preserved if there are some duplicates…

numpy.lib.recfunctions.merge_arrays(*seqarrays*,*fill_value=-1*,*flatten=False*,*usemask=False*,*asrecarray=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L361-L494)[#](#numpy.lib.recfunctions.merge_arrays)
-
Merge arrays field by field.

Parameters:
-
**seqarrays**sequence of ndarrays
Sequence of arrays

**fill_value**{float}, optional
Filling value used to pad missing data on the shorter arrays.

**flatten**{False, True}, optional
Whether to collapse nested fields.

**usemask**{False, True}, optional
Whether to return a masked array or not.

**asrecarray**{False, True}, optional
Whether to return a recarray (MaskedRecords) or not.

Notes

Without a mask, the missing value will be filled with something, depending on what its corresponding type:

`-1`
for integers
`-1.0`
for floating point numbers
`'-'`
for characters
`'-1'`
for strings
`True`
for boolean values
XXX: I just obtained these values empirically

Examples

>>> from numpy.lib import recfunctions as rfn >>> rfn.merge_arrays((np.array([1, 2]), np.array([10., 20., 30.]))) array([( 1, 10.), ( 2, 20.), (-1, 30.)], dtype=[('f0', '<i8'), ('f1', '<f8')])
>>> rfn.merge_arrays((np.array([1, 2], dtype=np.int64), ... np.array([10., 20., 30.])), usemask=False) array([(1, 10.0), (2, 20.0), (-1, 30.0)], dtype=[('f0', '<i8'), ('f1', '<f8')]) >>> rfn.merge_arrays((np.array([1, 2]).view([('a', np.int64)]), ... np.array([10., 20., 30.])), ... usemask=False, asrecarray=True) rec.array([( 1, 10.), ( 2, 20.), (-1, 30.)], dtype=[('a', '<i8'), ('f1', '<f8')])
numpy.lib.recfunctions.rec_append_fields(*base*,*names*,*data*,*dtypes=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L729-L761)[#](#numpy.lib.recfunctions.rec_append_fields)
-
Add new fields to an existing array.

The names of the fields are given with the

*names*arguments, the corresponding values with the*data*arguments. If a single field is appended,*names*,*data*and*dtypes*do not have to be lists but just values.Parameters:
-
**base**array
Input array to extend.

**names**string, sequence
String or sequence of strings corresponding to the names of the new fields.

**data**array or sequence of arrays
Array or sequence of arrays storing the fields to add to the base.

**dtypes**sequence of datatypes, optional
Datatype or sequence of datatypes. If None, the datatypes are estimated from the

*data*.
Returns:
-
**appended_array**np.recarray
See also

numpy.lib.recfunctions.rec_drop_fields(*base*,*drop_names*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L595-L600)[#](#numpy.lib.recfunctions.rec_drop_fields)
-
Returns a new numpy.recarray with fields in

*drop_names*dropped.
numpy.lib.recfunctions.rec_join(*key*,*r1*,*r2*,*jointype='inner'*,*r1postfix='1'*,*r2postfix='2'*,*defaults=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1660-L1673)[#](#numpy.lib.recfunctions.rec_join)
-
Join arrays

*r1*and*r2*on keys. Alternative to join_by, that always returns a np.recarray.See also

`join_by`
equivalent function

numpy.lib.recfunctions.recursive_fill_fields(*input*,*output*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L35-L71)[#](#numpy.lib.recfunctions.recursive_fill_fields)
-
Fills fields from output with fields from input, with support for nested structures.

Parameters:
-
**input**ndarray
Input array.

**output**ndarray
Output array.

Notes

*output*should be at least the same size as*input*
Examples

>>> from numpy.lib import recfunctions as rfn >>> a = np.array([(1, 10.), (2, 20.)], dtype=[('A', np.int64), ('B', np.float64)]) >>> b = np.zeros((3,), dtype=a.dtype) >>> rfn.recursive_fill_fields(a, b) array([(1, 10.), (2, 20.), (0, 0.)], dtype=[('A', '<i8'), ('B', '<f8')])
numpy.lib.recfunctions.rename_fields(*base*,*namemapper*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L607-L644)[#](#numpy.lib.recfunctions.rename_fields)
-
Rename the fields from a flexible-datatype ndarray or recarray.

Nested fields are supported.

Parameters:
-
**base**ndarray
Input array whose fields must be modified.

**namemapper**dictionary
Dictionary mapping old field names to their new version.

Examples

>>> from numpy.lib import recfunctions as rfn >>> a = np.array([(1, (2, [3.0, 30.])), (4, (5, [6.0, 60.]))], ... dtype=[('a', int),('b', [('ba', float), ('bb', (float, 2))])]) >>> rfn.rename_fields(a, {'a':'A', 'bb':'BB'}) array([(1, (2., [ 3., 30.])), (4, (5., [ 6., 60.]))], dtype=[('A', '<i8'), ('b', [('ba', '<f8'), ('BB', '<f8', (2,))])])
numpy.lib.recfunctions.repack_fields(*a*,*align=False*,*recurse=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L768-L849)[#](#numpy.lib.recfunctions.repack_fields)
-
Re-pack the fields of a structured array or dtype in memory.

The memory layout of structured datatypes allows fields at arbitrary byte offsets. This means the fields can be separated by padding bytes, their offsets can be non-monotonically increasing, and they can overlap.

This method removes any overlaps and reorders the fields in memory so they have increasing byte offsets, and adds or removes padding bytes depending on the

*align*option, which behaves like the*align*option to.`numpy.dtype`
If

*align=False*, this method produces a “packed” memory layout in which each field starts at the byte the previous field ended, and any padding bytes are removed.If

*align=True*, this methods produces an “aligned” memory layout in which each field’s offset is a multiple of its alignment, and the total itemsize is a multiple of the largest alignment, by adding padding bytes as needed.Parameters:
-
**a**ndarray or dtype
array or dtype for which to repack the fields.

**align**boolean
If true, use an “aligned” memory layout, otherwise use a “packed” layout.

**recurse**boolean
If True, also repack nested structures.

Returns:
-
**repacked**ndarray or dtype
Copy of

*a*with fields repacked, or*a*itself if no repacking was needed.
Examples

>>> from numpy.lib import recfunctions as rfn >>> def print_offsets(d): ... print("offsets:", [d.fields[name][1] for name in d.names]) ... print("itemsize:", d.itemsize) ... >>> dt = np.dtype('u1, <i8, <f8', align=True) >>> dt dtype({'names': ['f0', 'f1', 'f2'], 'formats': ['u1', '<i8', '<f8'], 'offsets': [0, 8, 16], 'itemsize': 24}, align=True) >>> print_offsets(dt) offsets: [0, 8, 16] itemsize: 24 >>> packed_dt = rfn.repack_fields(dt) >>> packed_dt dtype([('f0', 'u1'), ('f1', '<i8'), ('f2', '<f8')]) >>> print_offsets(packed_dt) offsets: [0, 1, 9] itemsize: 17
numpy.lib.recfunctions.require_fields(*array*,*required_dtype*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1268-L1309)[#](#numpy.lib.recfunctions.require_fields)
-
Casts a structured array to a new dtype using assignment by field-name.

This function assigns from the old to the new array by name, so the value of a field in the output array is the value of the field with the same name in the source array. This has the effect of creating a new ndarray containing only the fields “required” by the required_dtype.

If a field name in the required_dtype does not exist in the input array, that field is created and set to 0 in the output array.

Parameters:
-
**a**ndarray
array to cast

**required_dtype**dtype
datatype for output array

Returns:
-
**out**ndarray
array with the new dtype, with field values copied from the fields in the input array with the same name

Examples

>>> from numpy.lib import recfunctions as rfn >>> a = np.ones(4, dtype=[('a', 'i4'), ('b', 'f8'), ('c', 'u1')]) >>> rfn.require_fields(a, [('b', 'f4'), ('c', 'u1')]) array([(1., 1), (1., 1), (1., 1), (1., 1)], dtype=[('b', '<f4'), ('c', 'u1')]) >>> rfn.require_fields(a, [('b', 'f4'), ('newf', 'u1')]) array([(1., 0), (1., 0), (1., 0), (1., 0)], dtype=[('b', '<f4'), ('newf', 'u1')])
numpy.lib.recfunctions.stack_arrays(*arrays*,*defaults=None*,*usemask=True*,*asrecarray=False*,*autoconvert=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1317-L1402)[#](#numpy.lib.recfunctions.stack_arrays)
-
Superposes arrays fields by fields

Parameters:
-
**arrays**array or sequence
Sequence of input arrays.

**defaults**dictionary, optional
Dictionary mapping field names to the corresponding default values.

**usemask**{True, False}, optional
Whether to return a MaskedArray (or MaskedRecords is

*asrecarray==True*) or a ndarray.
**asrecarray**{False, True}, optional
Whether to return a recarray (or MaskedRecords if

*usemask==True*) or just a flexible-type ndarray.
**autoconvert**{False, True}, optional
Whether automatically cast the type of the field to the maximum.

Examples

>>> from numpy.lib import recfunctions as rfn >>> x = np.array([1, 2,]) >>> rfn.stack_arrays(x) is x True >>> z = np.array([('A', 1), ('B', 2)], dtype=[('A', '|S3'), ('B', float)]) >>> zz = np.array([('a', 10., 100.), ('b', 20., 200.), ('c', 30., 300.)], ... dtype=[('A', '|S3'), ('B', np.double), ('C', np.double)]) >>> test = rfn.stack_arrays((z,zz)) >>> test masked_array(data=[(b'A', 1.0, --), (b'B', 2.0, --), (b'a', 10.0, 100.0), (b'b', 20.0, 200.0), (b'c', 30.0, 300.0)], mask=[(False, False, True), (False, False, True), (False, False, False), (False, False, False), (False, False, False)], fill_value=(b'N/A', 1.e+20, 1.e+20), dtype=[('A', 'S3'), ('B', '<f8'), ('C', '<f8')])
numpy.lib.recfunctions.structured_to_unstructured(*arr*,*dtype=None*,*copy=False*,*casting='unsafe'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L937-L1064)[#](#numpy.lib.recfunctions.structured_to_unstructured)
-
Converts an n-D structured array into an (n+1)-D unstructured array.

The new array will have a new last dimension equal in size to the number of field-elements of the input array. If not supplied, the output datatype is determined from the numpy type promotion rules applied to all the field datatypes.

Nested fields, as well as each element of any subarray fields, all count as a single field-elements.

Parameters:
-
**arr**ndarray
Structured array or dtype to convert. Cannot contain object datatype.

**dtype**dtype, optional
The dtype of the output unstructured array.

**copy**bool, optional
If true, always return a copy. If false, a view is returned if possible, such as when the

*dtype*and strides of the fields are suitable and the array subtype is one of`np.ndarray`
,`np.recarray`
or`np.memmap`
.Changed in version 1.25.0: A view can now be returned if the fields are separated by a uniform stride.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
See casting argument of

. Controls what kind of data casting may occur.`numpy.ndarray.astype`
Returns:
-
**unstructured**ndarray
Unstructured array with one more dimension.

Examples

>>> from numpy.lib import recfunctions as rfn >>> a = np.zeros(4, dtype=[('a', 'i4'), ('b', 'f4,u2'), ('c', 'f4', 2)]) >>> a array([(0, (0., 0), [0., 0.]), (0, (0., 0), [0., 0.]), (0, (0., 0), [0., 0.]), (0, (0., 0), [0., 0.])], dtype=[('a', '<i4'), ('b', [('f0', '<f4'), ('f1', '<u2')]), ('c', '<f4', (2,))]) >>> rfn.structured_to_unstructured(a) array([[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]])
>>> b = np.array([(1, 2, 5), (4, 5, 7), (7, 8 ,11), (10, 11, 12)], ... dtype=[('x', 'i4'), ('y', 'f4'), ('z', 'f8')]) >>> np.mean(rfn.structured_to_unstructured(b[['x', 'z']]), axis=-1) array([ 3. , 5.5, 9. , 11. ])
numpy.lib.recfunctions.unstructured_to_structured(*arr*,*dtype=None*,*names=None*,*align=False*,*copy=False*,*casting='unsafe'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/recfunctions.py#L1071-L1176)[#](#numpy.lib.recfunctions.unstructured_to_structured)
-
Converts an n-D unstructured array into an (n-1)-D structured array.

The last dimension of the input array is converted into a structure, with number of field-elements equal to the size of the last dimension of the input array. By default all output fields have the input array’s dtype, but an output structured dtype with an equal number of fields-elements can be supplied instead.

Nested fields, as well as each element of any subarray fields, all count towards the number of field-elements.

Parameters:
-
**arr**ndarray
Unstructured array or dtype to convert.

**dtype**dtype, optional
The structured dtype of the output array

**names**list of strings, optional
If dtype is not supplied, this specifies the field names for the output dtype, in order. The field dtypes will be the same as the input array.

**align**boolean, optional
Whether to create an aligned memory layout.

**copy**bool, optional
See copy argument to

. If true, always return a copy. If false, and`numpy.ndarray.astype`
*dtype*requirements are satisfied, a view is returned.
**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
See casting argument of

. Controls what kind of data casting may occur.`numpy.ndarray.astype`
Returns:
-
**structured**ndarray
Structured array with fewer dimensions.

Examples

>>> from numpy.lib import recfunctions as rfn >>> dt = np.dtype([('a', 'i4'), ('b', 'f4,u2'), ('c', 'f4', 2)]) >>> a = np.arange(20).reshape((4,5)) >>> a array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) >>> rfn.unstructured_to_structured(a, dt) array([( 0, ( 1., 2), [ 3., 4.]), ( 5, ( 6., 7), [ 8., 9.]), (10, (11., 12), [13., 14.]), (15, (16., 17), [18., 19.])], dtype=[('a', '<i4'), ('b', [('f0', '<f4'), ('f1', '<u2')]), ('c', '<f4', (2,))])# Array API Standard Compatibility[#](#array-api-standard-compatibility)
Note

The `numpy.array_api`
module is still experimental. See [NEP 47](https://numpy.org/neps/nep-0047-array-api-standard.html).

NumPy includes a reference implementation of the [array API standard](https://data-apis.org/array-api/latest/) in `numpy.array_api`
. [NEP 47](https://numpy.org/neps/nep-0047-array-api-standard.html) describes the
motivation and scope for implementing the array API standard in NumPy.

The `numpy.array_api`
module serves as a minimal, reference implementation
of the array API standard. In being minimal, the module only implements those
things that are explicitly required by the specification. Certain things are
allowed by the specification but are explicitly disallowed in
`numpy.array_api`
. This is so that the module can serve as a reference
implementation for users of the array API standard. Any consumer of the array
API can test their code against `numpy.array_api`
and be sure that they
aren’t using any features that aren’t guaranteed by the spec, and which may
not be present in other conforming libraries.

The `numpy.array_api`
module is not documented here. For a listing of the
functions present in the array API specification, refer to the [array API
standard](https://data-apis.org/array-api/latest/). The `numpy.array_api`
implementation is functionally complete, so all functionality described in the
standard is implemented.

## Table of Differences between `numpy.array_api`
and `numpy`
[#](#table-of-differences-between-numpy-array-api-and-numpy)
This table outlines the primary differences between `numpy.array_api`
from
the main `numpy`
namespace. There are three types of differences:

**Strictness**. Things that are only done so that`numpy.array_api`
is a strict, minimal implementation. They aren’t actually required by the spec, and other conforming libraries may not follow them. In most cases, spec does not specify or require any behavior outside of the given domain. The main`numpy`
namespace would not need to change in any way to be spec-compatible for these.
**Compatible**. Things that could be added to the main`numpy`
namespace without breaking backwards compatibility.
**Breaking**. Things that would break backwards compatibility if implemented in the main`numpy`
namespace.
### Name Differences[#](#name-differences)
Many functions have been renamed in the spec from NumPy. These are otherwise
identical in behavior, and are thus all **compatible** changes, unless
otherwise noted.

#### Function Name Changes[#](#function-name-changes)
The following functions are named differently in the array API

Array API name

|
NumPy namespace name

|
Notes

|
---|---|---|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
This is

|
|
|
|
|
|
|
|
Unlike

|
|
|
|
|
Each is equivalent to

|
#### Function instead of method[#](#function-instead-of-method)
`astype`
is a function in the array API, whereas it is a method on`ndarray`
in`numpy`
.
`linalg`
Namespace Differences[#](#linalg-namespace-differences)
These functions are in the `linalg`
sub-namespace in the array API, but are
only in the top-level namespace in NumPy:

`cross`
`diagonal`
`matmul`
(*)
`outer`
`tensordot`
(*)
`trace`
(*): These functions are also in the top-level namespace in the array API.

#### Keyword Argument Renames[#](#keyword-argument-renames)
The following functions have keyword arguments that have been renamed. The
functionality of the keyword argument is identical unless otherwise stated.
Renamed keyword arguments with the same semantic definition may be considered
either **compatible** or **breaking**, depending on how the change is
implemented.

Note, this page does not list function keyword arguments that are in the main
`numpy`
namespace but not in the array API. Such keyword arguments are
omitted from `numpy.array_api`
for **strictness**, as the spec allows
functions to include additional keyword arguments from those required.

Function

|
Array API keyword name

|
NumPy keyword name

|
Notes

|
---|---|---|---|
|
|
|
The definitions of

|
|
|
|
The definitions of

|
|
|
|
The definitions of

|
|
|
|
|
|
|
The argument may be passed as a positional or keyword argument for both NumPy and the array API.

|
### Type Promotion Differences[#](#type-promotion-differences)
Type promotion is the biggest area where NumPy deviates from the spec. The most notable difference is that NumPy does value-based casting in many cases. The spec explicitly disallows value-based casting. In the array API, the result type of any operation is always determined entirely by the input types, independently of values or shapes.

Feature

|
Type

|
Notes

|
---|---|---|
Limited set of dtypes.

|
|
|
Operators (like

|
|
For example,

|
Operators (like

|
|
For example,

|
In-place operators are disallowed when the left-hand side would be promoted.

|
|
Example:

|
In-place operators are disallowed when the right-hand side operand cannot broadcast to the shape of the left-hand side operand.

|
|
This so-called “reverse broadcasting” should not be allowed. Example:

|
|
|
|
|
|
For example,

|
No cross-kind casting.

|
|
Namely, boolean, integer, and floating-point data types do not cast to
each other, except explicitly with

|
No casting unsigned integer dtypes to floating dtypes (e.g.,

|
|
|
|
The

|
|
|
### Indexing Differences[#](#indexing-differences)
The spec requires only a subset of indexing, but all indexing rules in the spec are compatible with NumPy’s more broad indexing rules.

Feature

|
Type

|
Notes

|
---|---|---|
No implicit ellipses (

|
|
If an index does not include an ellipsis, all axes must be indexed.

|
The start and stop of a slice may not be out of bounds.

|
|
For a slice

|
Boolean array indices are only allowed as the sole index.

|
|
Integer array indices are not allowed at all.

|
|
With the exception of 0-D arrays, which are treated like integers.

|
### Type Strictness[#](#type-strictness)
Functions in `numpy.array_api`
restrict their inputs to only those dtypes
that are explicitly required by the spec, even when the wrapped corresponding
NumPy function would allow a broader set. Here, we list each function and the
dtypes that are allowed in `numpy.array_api`
. These are **strictness**
differences because the spec does not require that other dtypes result in an
error. The categories here are defined as follows:

**Floating-point**:`float32`
or`float64`
.
**Integer**: Any signed or unsigned integer dtype (`int8`
,`int16`
,`int32`
,`int64`
,`uint8`
,`uint16`
,`uint32`
, or`uint64`
).
**Boolean**:`bool`
.
**Integer or boolean**: Any signed or unsigned integer dtype, or`bool`
. For two-argument functions, both arguments must be integer or both must be`bool`
.
**Numeric**: Any integer or floating-point dtype. For two-argument functions, both arguments must be integer or both must be floating-point.
**All**: Any of the above dtype categories. For two-argument functions, both arguments must be the same kind (integer, floating-point, or boolean).
In all cases, the return dtype is chosen according to [the rules outlined in
the spec](https://data-apis.org/array-api/latest/API_specification/type_promotion.html),
and does not differ from NumPy’s return dtype for any of the allowed input
dtypes, except in the cases mentioned specifically in the subsections below.

#### Elementwise Functions[#](#elementwise-functions)
Function Name

|
Dtypes

|
---|---|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Integer or boolean

|
|
Integer or boolean

|
|
Integer

|
|
Integer or boolean

|
|
Integer

|
|
Integer or boolean

|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
All

|
|
Floating-point

|
|
Floating-point

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Boolean

|
|
Boolean

|
|
Boolean

|
|
Boolean

|
|
Numeric

|
|
Numeric

|
|
All

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Numeric

|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Numeric

|
(*) These functions have different names from the main `numpy`
namespace.
See [Function Name Changes](#array-api-name-changes).

#### Creation Functions[#](#creation-functions)
Function Name

|
Dtypes

|
---|---|
|
Any (all input dtypes must be the same)

|
#### Linear Algebra Functions[#](#linear-algebra-functions)
Function Name

|
Dtypes

|
---|---|
|
Floating-point

|
|
Numeric

|
|
Floating-point

|
|
Any

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Any

|
|
Numeric

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Floating-point

|
|
Numeric

|
|
Numeric

|
|
Numeric

|
|
Floating-point

|
(*) These functions are split from `norm`
from the main `numpy`
namespace.
See [Function Name Changes](#array-api-name-changes).

(**) These functions are new in the array API and are not in the main
`numpy`
namespace.

#### Array Object[#](#array-object)
All the special `__operator__`
methods on the array object behave
identically to their corresponding functions (see [the spec](https://data-apis.org/array-api/latest/API_specification/array_object.html#methods)
for a list of which methods correspond to which functions). The exception is
that operators explicitly allow Python scalars according to the [rules
outlined in the spec](https://data-apis.org/array-api/latest/API_specification/type_promotion.html#mixing-arrays-with-python-scalars)
(see [Type Promotion Differences](#array-api-type-promotion-differences)).

### Array Object Differences[#](#array-object-differences)
Feature

|
Type

|
Notes

|
---|---|---|
No array scalars

|
|
The spec does not have array scalars, only 0-D arrays. However, other
than the promotion differences outlined in

|
|
|
|
|
|
The

|
|
See

|
The

|
|
See

|
New method

|
|
The methods would effectively not do anything since NumPy is CPU only

|
### Creation Functions Differences[#](#creation-functions-differences)
Feature

|
Type

|
Notes

|
---|---|---|
|
|
New

|
|
|
### Elementwise Functions Differences[#](#elementwise-functions-differences)
Feature

|
Type

|
Notes

|
---|---|---|
Various functions have been renamed.

|
|
Elementwise functions are only defined for given input type combinations.

|
|
See

|
|
|
|
|
|
### Linear Algebra Differences[#](#linear-algebra-differences)
Feature

|
Type

|
Notes

|
---|---|---|
|
|
|
|
|
|
Strictly speaking this can be

|
|
|
The corresponding

|
New functions

|
|
The

|
|
|
In the array API,

|
|
|
New function

|
|
Unlike

|
|
|
The spec currently only specifies behavior on 1-D arrays but future
behavior will likely be to broadcast, rather than flatten, which is
what

|
|
|
The meaning of

|
|
|
The

|
New function

|
|
Equivalent to

|
The

|
|
In

|
|
|
|
### Manipulation Functions Differences[#](#manipulation-functions-differences)
Feature

|
Type

|
Notes

|
---|---|---|
Various functions have been renamed

|
|
|
|
No cross-kind casting. No value-based casting on scalars (when axis=None).

|
|
|
No cross-kind casting.

|
New function

|
|
Unlike

|
|
|
### Set Functions Differences[#](#set-functions-differences)
Feature

|
Type

|
Notes

|
---|---|---|
New functions

|
|
The four

|
|
|
|
### Set Functions Differences[#](#array-api-set-functions-differences)
Feature

|
Type

|
Notes

|
---|---|---|
|
|
|
|
|
### Statistical Functions Differences[#](#statistical-functions-differences)
Feature

|
Type

|
Notes

|
---|---|---|
|
|
The

|
|
### Other Differences[#](#other-differences)
Feature

|
Type

|
Notes

|
---|---|---|
Dtypes can only be spelled as dtype objects.

|
|
For example,

|
|
|
The exception is Python operators, which accept Python scalars in
certain cases (see

|
|
|
finfo() return type uses

|
|
The spec allows duck typing, so

|
Positional arguments in every function are positional-only.

|
|
See the spec for the exact signature of each function. Note that NumPy
ufuncs already use positional-only arguments, but non-ufuncs like

|# Array API[#](#array-api)
*F. Scott Fitzgerald*
*Richard P. Feynman*
## Array structure and data access[#](#array-structure-and-data-access)
These macros access the [ PyArrayObject](types-and-structures.html#c.PyArrayObject) structure members and are
defined in

`ndarraytypes.h`
. The input argument, *arr*, can be any
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)* that is directly interpretable as a
[PyArrayObject](types-and-structures.html#c.PyArrayObject)* (any instance of the
[and its sub-types).](types-and-structures.html#c.PyArray_Type)
`PyArray_Type`
int PyArray_NDIM([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_NDIM)
-
The number of dimensions in the array.

int PyArray_FLAGS([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_FLAGS)
-
Returns an integer representing the

[array-flags](#array-flags).
int PyArray_TYPE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_TYPE)
-
Return the (builtin) typenumber for the elements of this array.

int PyArray_SETITEM([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, void *itemptr,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_SETITEM)
-
Convert obj and place it in the ndarray,

*arr*, at the place pointed to by itemptr. Return -1 if an error occurs or 0 on success.
void PyArray_ENABLEFLAGS([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, int flags)[#](#c.PyArray_ENABLEFLAGS)
-
New in version 1.7.

Enables the specified array flags. This function does no validation, and assumes that you know what you’re doing.

void PyArray_CLEARFLAGS([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, int flags)[#](#c.PyArray_CLEARFLAGS)
-
New in version 1.7.

Clears the specified array flags. This function does no validation, and assumes that you know what you’re doing.

void *PyArray_DATA([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_DATA)
-
char *PyArray_BYTES([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_BYTES)
-
These two macros are similar and obtain the pointer to the data-buffer for the array. The first macro can (and should be) assigned to a particular pointer where the second is for generic processing. If you have not guaranteed a contiguous and/or aligned array then be sure you understand how to access the data in the array to avoid memory and/or alignment problems.

[npy_intp](dtype.html#c.npy_intp)*PyArray_DIMS([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_DIMS)
-
Returns a pointer to the dimensions/shape of the array. The number of elements matches the number of dimensions of the array. Can return

`NULL`
for 0-dimensional arrays.
[npy_intp](dtype.html#c.npy_intp)*PyArray_SHAPE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_SHAPE)
-
New in version 1.7.

A synonym for

, named to be consistent with the`PyArray_DIMS`
usage within Python.`shape`
[npy_intp](dtype.html#c.npy_intp)*PyArray_STRIDES([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_STRIDES)
-
Returns a pointer to the strides of the array. The number of elements matches the number of dimensions of the array.

[npy_intp](dtype.html#c.npy_intp)PyArray_DIM([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, int n)[#](#c.PyArray_DIM)
-
Return the shape in the

*n*\(^{\textrm{th}}\) dimension.
[npy_intp](dtype.html#c.npy_intp)PyArray_STRIDE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, int n)[#](#c.PyArray_STRIDE)
-
Return the stride in the

*n*\(^{\textrm{th}}\) dimension.
[npy_intp](dtype.html#c.npy_intp)PyArray_ITEMSIZE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_ITEMSIZE)
-
Return the itemsize for the elements of this array.

Note that, in the old API that was deprecated in version 1.7, this function had the return type

`int`
.
[npy_intp](dtype.html#c.npy_intp)PyArray_SIZE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_SIZE)
-
Returns the total size (in number of elements) of the array.

[npy_intp](dtype.html#c.npy_intp)PyArray_Size([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_Size)
-
Returns 0 if

*obj*is not a sub-class of ndarray. Otherwise, returns the total number of elements in the array. Safer version of(`PyArray_SIZE`
*obj*).
[npy_intp](dtype.html#c.npy_intp)PyArray_NBYTES([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_NBYTES)
-
Returns the total number of bytes consumed by the array.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_BASE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_BASE)
-
This returns the base object of the array. In most cases, this means the object which owns the memory the array is pointing at.

If you are constructing an array using the C API, and specifying your own memory, you should use the function

to set the base to an object which owns the memory.`PyArray_SetBaseObject`
If the

flag is set, it has a different meaning, namely base is the array into which the current array will be copied upon copy resolution. This overloading of the base property for two functions is likely to change in a future version of NumPy.`NPY_ARRAY_WRITEBACKIFCOPY`
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DESCR([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_DESCR)
-
Returns a borrowed reference to the dtype property of the array.

[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DTYPE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_DTYPE)
-
New in version 1.7.

A synonym for PyArray_DESCR, named to be consistent with the ‘dtype’ usage within Python.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_GETITEM([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, void *itemptr)[#](#c.PyArray_GETITEM)
-
Get a Python object of a builtin type from the ndarray,

*arr*, at the location pointed to by itemptr. Return`NULL`
on failure.is identical to PyArray_GETITEM.`numpy.ndarray.item`
int PyArray_FinalizeFunc([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_FinalizeFunc)
-
The function pointed to by the

`PyCapsule`
. The first argument is the newly created sub-type. The second argument (if not NULL) is the “parent” array (if the array was created using slicing or some other operation where a clearly-distinguishable parent is present). This routine can do anything it wants to. It should return a -1 on error and 0 otherwise.`__array_finalize__`
### Data access[#](#data-access)
These functions and macros provide easy access to elements of the
ndarray from C. These work for all arrays. You may need to take care
when accessing the data in the array, however, if it is not in machine
byte-order, misaligned, or not writeable. In other words, be sure to
respect the state of the flags unless you know what you are doing, or
have previously guaranteed an array that is writeable, aligned, and in
machine byte-order using [ PyArray_FromAny](#c.PyArray_FromAny). If you wish to handle all
types of arrays, the copyswap function for each type is useful for
handling misbehaved arrays. Some platforms (e.g. Solaris) do not like
misaligned data and will crash if you de-reference a misaligned
pointer. Other platforms (e.g. x86 Linux) will just work more slowly
with misaligned data.

void *PyArray_GetPtr([PyArrayObject](types-and-structures.html#c.PyArrayObject)*aobj,[npy_intp](dtype.html#c.npy_intp)*ind)[#](#c.PyArray_GetPtr)
-
Return a pointer to the data of the ndarray,

*aobj*, at the N-dimensional index given by the c-array,*ind*, (which must be at least*aobj*->nd in size). You may want to typecast the returned pointer to the data type of the ndarray.
void *PyArray_GETPTR1([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj,[npy_intp](dtype.html#c.npy_intp)i)[#](#c.PyArray_GETPTR1)
-
void *PyArray_GETPTR2([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj,[npy_intp](dtype.html#c.npy_intp)i,[npy_intp](dtype.html#c.npy_intp)j)[#](#c.PyArray_GETPTR2)
-
void *PyArray_GETPTR3([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj,[npy_intp](dtype.html#c.npy_intp)i,[npy_intp](dtype.html#c.npy_intp)j,[npy_intp](dtype.html#c.npy_intp)k)[#](#c.PyArray_GETPTR3)
-
void *PyArray_GETPTR4([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj,[npy_intp](dtype.html#c.npy_intp)i,[npy_intp](dtype.html#c.npy_intp)j,[npy_intp](dtype.html#c.npy_intp)k,[npy_intp](dtype.html#c.npy_intp)l)[#](#c.PyArray_GETPTR4)
-
Quick, inline access to the element at the given coordinates in the ndarray,

*obj*, which must have respectively 1, 2, 3, or 4 dimensions (this is not checked). The corresponding*i*,*j*,*k*, and*l*coordinates can be any integer but will be interpreted as`npy_intp`
. You may want to typecast the returned pointer to the data type of the ndarray.
## Creating arrays[#](#creating-arrays)
### From scratch[#](#from-scratch)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_NewFromDescr([PyTypeObject](https://docs.python.org/3/c-api/type.html#c.PyTypeObject)*subtype,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr, int nd,[npy_intp](dtype.html#c.npy_intp)const *dims,[npy_intp](dtype.html#c.npy_intp)const *strides, void *data, int flags,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_NewFromDescr)
-
This function steals a reference to

*descr*. The easiest way to get one is using.`PyArray_DescrFromType`
This is the main array creation function. Most new arrays are created with this flexible function.

The returned object is an object of Python-type

*subtype*, which must be a subtype of. The array has`PyArray_Type`
*nd*dimensions, described by*dims*. The data-type descriptor of the new array is*descr*.If

*subtype*is of an array subclass instead of the base, then`&PyArray_Type`
*obj*is the object to pass to themethod of the subclass.`__array_finalize__`
If

*data*is`NULL`
, then new unitinialized memory will be allocated and*flags*can be non-zero to indicate a Fortran-style contiguous array. Useto initialize the memory.`PyArray_FILLWBYTE`
If

*data*is not`NULL`
, then it is assumed to point to the memory to be used for the array and the*flags*argument is used as the new flags for the array (except the state of,`NPY_ARRAY_OWNDATA`
flag of the new array will be reset).`NPY_ARRAY_WRITEBACKIFCOPY`
In addition, if

*data*is non-NULL, then*strides*can also be provided. If*strides*is`NULL`
, then the array strides are computed as C-style contiguous (default) or Fortran-style contiguous (*flags*is nonzero for*data*=`NULL`
or*flags*&is nonzero non-NULL`NPY_ARRAY_F_CONTIGUOUS`
*data*). Any provided*dims*and*strides*are copied into newly allocated dimension and strides arrays for the new array object.can help verify non-`PyArray_CheckStrides`
`NULL`
stride information.If

`data`
is provided, it must stay alive for the life of the array. One way to manage this is through`PyArray_SetBaseObject`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_NewLikeArray([PyArrayObject](types-and-structures.html#c.PyArrayObject)*prototype,[NPY_ORDER](#c.NPY_ORDER)order,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr, int subok)[#](#c.PyArray_NewLikeArray)
-
New in version 1.6.

This function steals a reference to

*descr*if it is not NULL. This array creation routine allows for the convenient creation of a new array matching an existing array’s shapes and memory layout, possibly changing the layout and/or data type.When

*order*is, the result order is`NPY_ANYORDER`
if`NPY_FORTRANORDER`
*prototype*is a fortran array,otherwise. When`NPY_CORDER`
*order*is, the result order matches that of`NPY_KEEPORDER`
*prototype*, even when the axes of*prototype*aren’t in C or Fortran order.If

*descr*is NULL, the data type of*prototype*is used.If

*subok*is 1, the newly created array will use the sub-type of*prototype*to create the new array, otherwise it will create a base-class array.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_New([PyTypeObject](https://docs.python.org/3/c-api/type.html#c.PyTypeObject)*subtype, int nd,[npy_intp](dtype.html#c.npy_intp)const *dims, int type_num,[npy_intp](dtype.html#c.npy_intp)const *strides, void *data, int itemsize, int flags,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_New)
-
This is similar to

(…) except you specify the data-type descriptor with`PyArray_NewFromDescr`
*type_num*and*itemsize*, where*type_num*corresponds to a builtin (or user-defined) type. If the type always has the same number of bytes, then itemsize is ignored. Otherwise, itemsize specifies the particular size of this array.
Warning

If data is passed to [ PyArray_NewFromDescr](#c.PyArray_NewFromDescr) or

[, this memory must not be deallocated until the new array is deleted. If this data came from another Python object, this can be accomplished using](#c.PyArray_New)
`PyArray_New`
[on that object and setting the base member of the new array to point to that object. If strides are passed in they must be consistent with the dimensions, the itemsize, and the data of the array.](https://docs.python.org/3/c-api/refcounting.html#c.Py_INCREF)
`Py_INCREF`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_SimpleNew(int nd,[npy_intp](dtype.html#c.npy_intp)const *dims, int typenum)[#](#c.PyArray_SimpleNew)
-
Create a new uninitialized array of type,

*typenum*, whose size in each of*nd*dimensions is given by the integer array,*dims*.The memory for the array is uninitialized (unless typenum isin which case each element in the array is set to NULL). The`NPY_OBJECT`
*typenum*argument allows specification of any of the builtin data-types such asor`NPY_FLOAT`
. The memory for the array can be set to zero if desired using`NPY_LONG`
(return_object, 0).This function cannot be used to create a flexible-type array (no itemsize given).`PyArray_FILLWBYTE`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_SimpleNewFromData(int nd,[npy_intp](dtype.html#c.npy_intp)const *dims, int typenum, void *data)[#](#c.PyArray_SimpleNewFromData)
-
Create an array wrapper around

*data*pointed to by the given pointer. The array flags will have a default that the data area is well-behaved and C-style contiguous. The shape of the array is given by the*dims*c-array of length*nd*. The data-type of the array is indicated by*typenum*. If data comes from another reference-counted Python object, the reference count on this object should be increased after the pointer is passed in, and the base member of the returned ndarray should point to the Python object that owns the data. This will ensure that the provided memory is not freed while the returned array is in existence.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_SimpleNewFromDescr(int nd,[npy_int](dtype.html#c.npy_int)const *dims,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyArray_SimpleNewFromDescr)
-
This function steals a reference to

*descr*.Create a new array with the provided data-type descriptor,

*descr*, of the shape determined by*nd*and*dims*.
void PyArray_FILLWBYTE([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int val)[#](#c.PyArray_FILLWBYTE)
-
Fill the array pointed to by

*obj*—which must be a (subclass of) ndarray—with the contents of*val*(evaluated as a byte). This macro calls memset, so obj must be contiguous.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Zeros(int nd,[npy_intp](dtype.html#c.npy_intp)const *dims,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype, int fortran)[#](#c.PyArray_Zeros)
-
Construct a new

*nd*-dimensional array with shape given by*dims*and data type given by*dtype*. If*fortran*is non-zero, then a Fortran-order array is created, otherwise a C-order array is created. Fill the memory with zeros (or the 0 object if*dtype*corresponds to).`NPY_OBJECT`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ZEROS(int nd,[npy_intp](dtype.html#c.npy_intp)const *dims, int type_num, int fortran)[#](#c.PyArray_ZEROS)
-
Macro form of

which takes a type-number instead of a data-type object.`PyArray_Zeros`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Empty(int nd,[npy_intp](dtype.html#c.npy_intp)const *dims,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype, int fortran)[#](#c.PyArray_Empty)
-
Construct a new

*nd*-dimensional array with shape given by*dims*and data type given by*dtype*. If*fortran*is non-zero, then a Fortran-order array is created, otherwise a C-order array is created. The array is uninitialized unless the data type corresponds toin which case the array is filled with`NPY_OBJECT`
.`Py_None`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_EMPTY(int nd,[npy_intp](dtype.html#c.npy_intp)const *dims, int typenum, int fortran)[#](#c.PyArray_EMPTY)
-
Macro form of

which takes a type-number,`PyArray_Empty`
*typenum*, instead of a data-type object.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Arange(double start, double stop, double step, int typenum)[#](#c.PyArray_Arange)
-
Construct a new 1-dimensional array of data-type,

*typenum*, that ranges from*start*to*stop*(exclusive) in increments of*step*. Equivalent to**arange**(*start*,*stop*,*step*, dtype).
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ArangeObj([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*start,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*stop,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*step,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyArray_ArangeObj)
-
Construct a new 1-dimensional array of data-type determined by

`descr`
, that ranges from`start`
to`stop`
(exclusive) in increments of`step`
. Equivalent to arange(`start`
,`stop`
,`step`
,`typenum`
).
int PyArray_SetBaseObject([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_SetBaseObject)
-
New in version 1.7.

This function

**steals a reference**to`obj`
and sets it as the base property of`arr`
.If you construct an array by passing in your own memory buffer as a parameter, you need to set the array’s

*base*property to ensure the lifetime of the memory buffer is appropriate.The return value is 0 on success, -1 on failure.

If the object provided is an array, this function traverses the chain of

*base*pointers so that each array points to the owner of the memory directly. Once the base is set, it may not be changed to another value.
### From other objects[#](#from-other-objects)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromAny([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype, int min_depth, int max_depth, int requirements,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*context)[#](#c.PyArray_FromAny)
-
This is the main function used to obtain an array from any nested sequence, or object that exposes the array interface,

*op*. The parameters allow specification of the required*dtype*, the minimum (*min_depth*) and maximum (*max_depth*) number of dimensions acceptable, and other*requirements*for the array. This function**steals a reference**to the dtype argument, which needs to be astructure indicating the desired data-type (including required byteorder). The`PyArray_Descr`
*dtype*argument may be`NULL`
, indicating that any data-type (and byteorder) is acceptable. Unlessis present in`NPY_ARRAY_FORCECAST`
`flags`
, this call will generate an error if the data type cannot be safely obtained from the object. If you want to use`NULL`
for the*dtype*and ensure the array is not swapped then use. A value of 0 for either of the depth parameters causes the parameter to be ignored. Any of the following array flags can be added (`PyArray_CheckFromAny`
*e.g.*using |) to get the*requirements*argument. If your code can handle general (*e.g.*strided, byte-swapped, or unaligned arrays) then*requirements*may be 0. Also, if*op*is not already an array (or does not expose the array interface), then a new array will be created (and filled from*op*using the sequence protocol). The new array will haveas its flags member. The`NPY_ARRAY_DEFAULT`
*context*argument is unused.
NPY_ARRAY_C_CONTIGUOUS[#](#c.PyArray_FromAny.NPY_ARRAY_C_CONTIGUOUS)
-
Make sure the returned array is C-style contiguous

NPY_ARRAY_F_CONTIGUOUS[#](#c.PyArray_FromAny.NPY_ARRAY_F_CONTIGUOUS)
-
Make sure the returned array is Fortran-style contiguous.

NPY_ARRAY_ALIGNED[#](#c.PyArray_FromAny.NPY_ARRAY_ALIGNED)
-
Make sure the returned array is aligned on proper boundaries for its data type. An aligned array has the data pointer and every strides factor as a multiple of the alignment factor for the data-type- descriptor.

NPY_ARRAY_WRITEABLE[#](#c.PyArray_FromAny.NPY_ARRAY_WRITEABLE)
-
Make sure the returned array can be written to.

NPY_ARRAY_ENSURECOPY[#](#c.PyArray_FromAny.NPY_ARRAY_ENSURECOPY)
-
Make sure a copy is made of

*op*. If this flag is not present, data is not copied if it can be avoided.
NPY_ARRAY_ENSUREARRAY[#](#c.PyArray_FromAny.NPY_ARRAY_ENSUREARRAY)
-
Make sure the result is a base-class ndarray. By default, if

*op*is an instance of a subclass of ndarray, an instance of that same subclass is returned. If this flag is set, an ndarray object will be returned instead.
NPY_ARRAY_FORCECAST[#](#c.PyArray_FromAny.NPY_ARRAY_FORCECAST)
-
Force a cast to the output type even if it cannot be done safely. Without this flag, a data cast will occur only if it can be done safely, otherwise an error is raised.

NPY_ARRAY_WRITEBACKIFCOPY[#](#c.PyArray_FromAny.NPY_ARRAY_WRITEBACKIFCOPY)
-
If

*op*is already an array, but does not satisfy the requirements, then a copy is made (which will satisfy the requirements). If this flag is present and a copy (of an object that is already an array) must be made, then the correspondingflag is set in the returned copy and`NPY_ARRAY_WRITEBACKIFCOPY`
*op*is made to be read-only. You must be sure to callto copy the contents back into`PyArray_ResolveWritebackIfCopy`
*op*and the*op*array will be made writeable again. If*op*is not writeable to begin with, or if it is not already an array, then an error is raised.
NPY_ARRAY_BEHAVED[#](#c.PyArray_FromAny.NPY_ARRAY_BEHAVED)
-
NPY_ARRAY_CARRAY[#](#c.PyArray_FromAny.NPY_ARRAY_CARRAY)
-
NPY_ARRAY_CARRAY_RO[#](#c.PyArray_FromAny.NPY_ARRAY_CARRAY_RO)
-
NPY_ARRAY_FARRAY[#](#c.PyArray_FromAny.NPY_ARRAY_FARRAY)
-
NPY_ARRAY_FARRAY_RO[#](#c.PyArray_FromAny.NPY_ARRAY_FARRAY_RO)
-
NPY_ARRAY_DEFAULT[#](#c.PyArray_FromAny.NPY_ARRAY_DEFAULT)
-
NPY_ARRAY_C_CONTIGUOUS
-
NPY_ARRAY_IN_ARRAY[#](#c.NPY_ARRAY_IN_ARRAY)
-
|`NPY_ARRAY_C_CONTIGUOUS`
`NPY_ARRAY_ALIGNED`
NPY_ARRAY_IN_FARRAY[#](#c.NPY_ARRAY_IN_ARRAY.NPY_ARRAY_IN_FARRAY)
-
NPY_ARRAY_IN_FARRAY
-
NPY_OUT_ARRAY[#](#c.NPY_OUT_ARRAY)
-
|`NPY_ARRAY_C_CONTIGUOUS`
|`NPY_ARRAY_WRITEABLE`
`NPY_ARRAY_ALIGNED`
NPY_ARRAY_OUT_ARRAY[#](#c.NPY_ARRAY_OUT_ARRAY)
-
|`NPY_ARRAY_C_CONTIGUOUS`
|`NPY_ARRAY_ALIGNED`
`NPY_ARRAY_WRITEABLE`
NPY_ARRAY_OUT_FARRAY[#](#c.NPY_ARRAY_OUT_ARRAY.NPY_ARRAY_OUT_FARRAY)
-
|`NPY_ARRAY_F_CONTIGUOUS`
|`NPY_ARRAY_WRITEABLE`
`NPY_ARRAY_ALIGNED`
NPY_ARRAY_OUT_FARRAY
-
NPY_ARRAY_INOUT_ARRAY[#](#c.NPY_ARRAY_INOUT_ARRAY)
-
|`NPY_ARRAY_C_CONTIGUOUS`
|`NPY_ARRAY_WRITEABLE`
|`NPY_ARRAY_ALIGNED`
`NPY_ARRAY_WRITEBACKIFCOPY`
NPY_ARRAY_INOUT_FARRAY[#](#c.NPY_ARRAY_INOUT_ARRAY.NPY_ARRAY_INOUT_FARRAY)
-
|`NPY_ARRAY_F_CONTIGUOUS`
|`NPY_ARRAY_WRITEABLE`
|`NPY_ARRAY_ALIGNED`
`NPY_ARRAY_WRITEBACKIFCOPY`
NPY_ARRAY_INOUT_FARRAY
-
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_CheckFromAny([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype, int min_depth, int max_depth, int requirements,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*context)[#](#c.PyArray_CheckFromAny)
-
Nearly identical to

(…) except`PyArray_FromAny`
*requirements*can contain(over-riding the specification in`NPY_ARRAY_NOTSWAPPED`
*dtype*) andwhich indicates that the array should be aligned in the sense that the strides are multiples of the element size.`NPY_ARRAY_ELEMENTSTRIDES`
In versions 1.6 and earlier of NumPy, the following flags did not have the _ARRAY_ macro namespace in them. That form of the constant names is deprecated in 1.7.

NPY_ARRAY_NOTSWAPPED[#](#c.NPY_ARRAY_NOTSWAPPED)
-
Make sure the returned array has a data-type descriptor that is in machine byte-order, over-riding any specification in the

*dtype*argument. Normally, the byte-order requirement is determined by the*dtype*argument. If this flag is set and the dtype argument does not indicate a machine byte-order descriptor (or is NULL and the object is already an array with a data-type descriptor that is not in machine byte- order), then a new data-type descriptor is created and used with its byte-order field set to native.
NPY_ARRAY_BEHAVED_NS[#](#c.NPY_ARRAY_NOTSWAPPED.NPY_ARRAY_BEHAVED_NS)
-
|`NPY_ARRAY_ALIGNED`
|`NPY_ARRAY_WRITEABLE`
`NPY_ARRAY_NOTSWAPPED`
NPY_ARRAY_BEHAVED_NS
-
NPY_ARRAY_ELEMENTSTRIDES[#](#c.NPY_ARRAY_ELEMENTSTRIDES)
-
Make sure the returned array has strides that are multiples of the element size.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromArray([PyArrayObject](types-and-structures.html#c.PyArrayObject)*op,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*newtype, int requirements)[#](#c.PyArray_FromArray)
-
Special case of

for when`PyArray_FromAny`
*op*is already an array but it needs to be of a specific*newtype*(including byte-order) or has certain*requirements*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromStructInterface([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_FromStructInterface)
-
Returns an ndarray object from a Python object that exposes the

attribute and follows the array interface protocol. If the object does not contain this attribute then a borrowed reference to`__array_struct__`
is returned.`Py_NotImplemented`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromInterface([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_FromInterface)
-
Returns an ndarray object from a Python object that exposes the

attribute following the array interface protocol. If the object does not contain this attribute then a borrowed reference to`__array_interface__`
is returned.`Py_NotImplemented`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromArrayAttr([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*context)[#](#c.PyArray_FromArrayAttr)
-
Return an ndarray object from a Python object that exposes the

method. The`__array__`
method can take 0, or 1 argument`__array__`
`([dtype])`
.`context`
is unused.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ContiguousFromAny([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, int typenum, int min_depth, int max_depth)[#](#c.PyArray_ContiguousFromAny)
-
This function returns a (C-style) contiguous and behaved function array from any nested sequence or array interface exporting object,

*op*, of (non-flexible) type given by the enumerated*typenum*, of minimum depth*min_depth*, and of maximum depth*max_depth*. Equivalent to a call towith requirements set to`PyArray_FromAny`
and the type_num member of the type argument set to`NPY_ARRAY_DEFAULT`
*typenum*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ContiguousFromObject([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, int typenum, int min_depth, int max_depth)[#](#c.PyArray_ContiguousFromObject)
-
This function returns a well-behaved C-style contiguous array from any nested sequence or array-interface exporting object. The minimum number of dimensions the array can have is given by

*min_depth*while the maximum is*max_depth*. This is equivalent to callwith requirements`PyArray_FromAny`
and`NPY_ARRAY_DEFAULT`
.`NPY_ARRAY_ENSUREARRAY`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromObject([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, int typenum, int min_depth, int max_depth)[#](#c.PyArray_FromObject)
-
Return an aligned and in native-byteorder array from any nested sequence or array-interface exporting object, op, of a type given by the enumerated typenum. The minimum number of dimensions the array can have is given by min_depth while the maximum is max_depth. This is equivalent to a call to

with requirements set to BEHAVED.`PyArray_FromAny`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_EnsureArray([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_EnsureArray)
-
This function

**steals a reference**to`op`
and makes sure that`op`
is a base-class ndarray. It special cases array scalars, but otherwise calls(`PyArray_FromAny`
`op`
, NULL, 0, 0,, NULL).`NPY_ARRAY_ENSUREARRAY`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromString(char *string,[npy_intp](dtype.html#c.npy_intp)slen,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[npy_intp](dtype.html#c.npy_intp)num, char *sep)[#](#c.PyArray_FromString)
-
Construct a one-dimensional ndarray of a single type from a binary or (ASCII) text

`string`
of length`slen`
. The data-type of the array to-be-created is given by`dtype`
. If num is -1, then**copy**the entire string and return an appropriately sized array, otherwise,`num`
is the number of items to**copy**from the string. If`sep`
is NULL (or “”), then interpret the string as bytes of binary data, otherwise convert the sub-strings separated by`sep`
to items of data-type`dtype`
. Some data-types may not be readable in text mode and an error will be raised if that occurs. All errors return NULL.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromFile(FILE *fp,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[npy_intp](dtype.html#c.npy_intp)num, char *sep)[#](#c.PyArray_FromFile)
-
Construct a one-dimensional ndarray of a single type from a binary or text file. The open file pointer is

`fp`
, the data-type of the array to be created is given by`dtype`
. This must match the data in the file. If`num`
is -1, then read until the end of the file and return an appropriately sized array, otherwise,`num`
is the number of items to read. If`sep`
is NULL (or “”), then read from the file in binary mode, otherwise read from the file in text mode with`sep`
providing the item separator. Some array types cannot be read in text mode in which case an error is raised.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromBuffer([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*buf,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[npy_intp](dtype.html#c.npy_intp)count,[npy_intp](dtype.html#c.npy_intp)offset)[#](#c.PyArray_FromBuffer)
-
Construct a one-dimensional ndarray of a single type from an object,

`buf`
, that exports the (single-segment) buffer protocol (or has an attribute __buffer__ that returns an object that exports the buffer protocol). A writeable buffer will be tried first followed by a read- only buffer. Theflag of the returned array will reflect which one was successful. The data is assumed to start at`NPY_ARRAY_WRITEABLE`
`offset`
bytes from the start of the memory location for the object. The type of the data in the buffer will be interpreted depending on the data- type descriptor,`dtype.`
If`count`
is negative then it will be determined from the size of the buffer and the requested itemsize, otherwise,`count`
represents how many elements should be converted from the buffer.
int PyArray_CopyInto([PyArrayObject](types-and-structures.html#c.PyArrayObject)*dest,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*src)[#](#c.PyArray_CopyInto)
-
Copy from the source array,

`src`
, into the destination array,`dest`
, performing a data-type conversion if necessary. If an error occurs return -1 (otherwise 0). The shape of`src`
must be broadcastable to the shape of`dest`
. The data areas of dest and src must not overlap.
int PyArray_CopyObject([PyArrayObject](types-and-structures.html#c.PyArrayObject)*dest,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*src)[#](#c.PyArray_CopyObject)
-
Assign an object

`src`
to a NumPy array`dest`
according to array-coercion rules. This is basically identical to, but assigns directly to the output array. Returns 0 on success and -1 on failures.`PyArray_FromAny`
int PyArray_MoveInto([PyArrayObject](types-and-structures.html#c.PyArrayObject)*dest,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*src)[#](#c.PyArray_MoveInto)
-
Move data from the source array,

`src`
, into the destination array,`dest`
, performing a data-type conversion if necessary. If an error occurs return -1 (otherwise 0). The shape of`src`
must be broadcastable to the shape of`dest`
. The data areas of dest and src may overlap.
[PyArrayObject](types-and-structures.html#c.PyArrayObject)*PyArray_GETCONTIGUOUS([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_GETCONTIGUOUS)
-
If

`op`
is already (C-style) contiguous and well-behaved then just return a reference, otherwise return a (contiguous and well-behaved) copy of the array. The parameter op must be a (sub-class of an) ndarray and no checking for that is done.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FROM_O([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_FROM_O)
-
Convert

`obj`
to an ndarray. The argument can be any nested sequence or object that exports the array interface. This is a macro form ofusing`PyArray_FromAny`
`NULL`
, 0, 0, 0 for the other arguments. Your code must be able to handle any data-type descriptor and any combination of data-flags to use this macro.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FROM_OF([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int requirements)[#](#c.PyArray_FROM_OF)
-
Similar to

except it can take an argument of`PyArray_FROM_O`
*requirements*indicating properties the resulting array must have. Available requirements that can be enforced are,`NPY_ARRAY_C_CONTIGUOUS`
,`NPY_ARRAY_F_CONTIGUOUS`
,`NPY_ARRAY_ALIGNED`
,`NPY_ARRAY_WRITEABLE`
,`NPY_ARRAY_NOTSWAPPED`
,`NPY_ARRAY_ENSURECOPY`
,`NPY_ARRAY_WRITEBACKIFCOPY`
, and`NPY_ARRAY_FORCECAST`
. Standard combinations of flags can also be used:`NPY_ARRAY_ENSUREARRAY`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FROM_OT([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int typenum)[#](#c.PyArray_FROM_OT)
-
Similar to

except it can take an argument of`PyArray_FROM_O`
*typenum*specifying the type-number the returned array.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FROM_OTF([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int typenum, int requirements)[#](#c.PyArray_FROM_OTF)
-
Combination of

and`PyArray_FROM_OF`
allowing both a`PyArray_FROM_OT`
*typenum*and a*flags*argument to be provided.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FROMANY([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int typenum, int min, int max, int requirements)[#](#c.PyArray_FROMANY)
-
Similar to

except the data-type is specified using a typenumber.`PyArray_FromAny`
(`PyArray_DescrFromType`
*typenum*) is passed directly to. This macro also adds`PyArray_FromAny`
to requirements if`NPY_ARRAY_DEFAULT`
is passed in as requirements.`NPY_ARRAY_ENSURECOPY`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_CheckAxis([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int *axis, int requirements)[#](#c.PyArray_CheckAxis)
-
Encapsulate the functionality of functions and methods that take the axis= keyword and work properly with None as the axis argument. The input array is

`obj`
, while`*axis`
is a converted integer (so that >=MAXDIMS is the None value), and`requirements`
gives the needed properties of`obj`
. The output is a converted version of the input so that requirements are met and if needed a flattening has occurred. On output negative values of`*axis`
are converted and the new value is checked to ensure consistency with the shape of`obj`
.
## Dealing with types[#](#dealing-with-types)
### General check of Python Type[#](#general-check-of-python-type)
int PyArray_Check([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_Check)
-
Evaluates true if

*op*is a Python object whose type is a sub-type of.`PyArray_Type`
int PyArray_CheckExact([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_CheckExact)
-
Evaluates true if

*op*is a Python object with type.`PyArray_Type`
int PyArray_HasArrayInterface([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*out)[#](#c.PyArray_HasArrayInterface)
-
If

`op`
implements any part of the array interface, then`out`
will contain a new reference to the newly created ndarray using the interface or`out`
will contain`NULL`
if an error during conversion occurs. Otherwise, out will contain a borrowed reference toand no error condition is set.`Py_NotImplemented`
int PyArray_HasArrayInterfaceType([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*context,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*out)[#](#c.PyArray_HasArrayInterfaceType)
-
If

`op`
implements any part of the array interface, then`out`
will contain a new reference to the newly created ndarray using the interface or`out`
will contain`NULL`
if an error during conversion occurs. Otherwise, out will contain a borrowed reference to Py_NotImplemented and no error condition is set. This version allows setting of the dtype in the part of the array interface that looks for theattribute.`__array__`
*context*is unused.
int PyArray_IsZeroDim([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_IsZeroDim)
-
Evaluates true if

*op*is an instance of (a subclass of)and has 0 dimensions.`PyArray_Type`
PyArray_IsScalar(op, cls)[#](#c.PyArray_IsScalar)
-
Evaluates true if

*op*is an instance of`Py{cls}ArrType_Type`
.
int PyArray_CheckScalar([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_CheckScalar)
-
Evaluates true if

*op*is either an array scalar (an instance of a sub-type of`PyGenericArr_Type`
), or an instance of (a sub-class of)whose dimensionality is 0.`PyArray_Type`
int PyArray_IsPythonNumber([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_IsPythonNumber)
-
Evaluates true if

*op*is an instance of a builtin numeric type (int, float, complex, long, bool)
int PyArray_IsPythonScalar([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_IsPythonScalar)
-
Evaluates true if

*op*is a builtin Python scalar object (int, float, complex, bytes, str, long, bool).
int PyArray_IsAnyScalar([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_IsAnyScalar)
-
Evaluates true if

*op*is either a Python scalar object (see) or an array scalar (an instance of a sub- type of`PyArray_IsPythonScalar`
`PyGenericArr_Type`
).
int PyArray_CheckAnyScalar([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_CheckAnyScalar)
-
Evaluates true if

*op*is a Python scalar object (see), an array scalar (an instance of a sub-type of`PyArray_IsPythonScalar`
`PyGenericArr_Type`
) or an instance of a sub-type ofwhose dimensionality is 0.`PyArray_Type`
### Data-type checking[#](#data-type-checking)
For the typenum macros, the argument is an integer representing an
enumerated array data type. For the array type checking macros the
argument must be a [PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)* that can be directly interpreted as a
[PyArrayObject](types-and-structures.html#c.PyArrayObject)*.

int PyTypeNum_ISUNSIGNED(int num)[#](#c.PyTypeNum_ISUNSIGNED)
-
int PyDataType_ISUNSIGNED([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISUNSIGNED)
-
int PyArray_ISUNSIGNED([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISUNSIGNED)
-
Type represents an unsigned integer.

int PyTypeNum_ISSIGNED(int num)[#](#c.PyTypeNum_ISSIGNED)
-
int PyDataType_ISSIGNED([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISSIGNED)
-
int PyArray_ISSIGNED([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISSIGNED)
-
Type represents a signed integer.

int PyTypeNum_ISINTEGER(int num)[#](#c.PyTypeNum_ISINTEGER)
-
int PyDataType_ISINTEGER([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISINTEGER)
-
int PyArray_ISINTEGER([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISINTEGER)
-
Type represents any integer.

int PyTypeNum_ISFLOAT(int num)[#](#c.PyTypeNum_ISFLOAT)
-
int PyDataType_ISFLOAT([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISFLOAT)
-
int PyArray_ISFLOAT([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISFLOAT)
-
Type represents any floating point number.

int PyTypeNum_ISCOMPLEX(int num)[#](#c.PyTypeNum_ISCOMPLEX)
-
int PyDataType_ISCOMPLEX([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISCOMPLEX)
-
int PyArray_ISCOMPLEX([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISCOMPLEX)
-
Type represents any complex floating point number.

int PyTypeNum_ISNUMBER(int num)[#](#c.PyTypeNum_ISNUMBER)
-
int PyDataType_ISNUMBER([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISNUMBER)
-
int PyArray_ISNUMBER([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISNUMBER)
-
Type represents any integer, floating point, or complex floating point number.

int PyTypeNum_ISSTRING(int num)[#](#c.PyTypeNum_ISSTRING)
-
int PyDataType_ISSTRING([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISSTRING)
-
int PyArray_ISSTRING([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISSTRING)
-
Type represents a string data type.

int PyTypeNum_ISPYTHON(int num)[#](#c.PyTypeNum_ISPYTHON)
-
int PyDataType_ISPYTHON([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISPYTHON)
-
int PyArray_ISPYTHON([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISPYTHON)
-
Type represents an enumerated type corresponding to one of the standard Python scalar (bool, int, float, or complex).

int PyTypeNum_ISFLEXIBLE(int num)[#](#c.PyTypeNum_ISFLEXIBLE)
-
int PyDataType_ISFLEXIBLE([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISFLEXIBLE)
-
int PyArray_ISFLEXIBLE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISFLEXIBLE)
-
Type represents one of the flexible array types (

,`NPY_STRING`
, or`NPY_UNICODE`
).`NPY_VOID`
int PyDataType_ISUNSIZED([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISUNSIZED)
-
Type has no size information attached, and can be resized. Should only be called on flexible dtypes. Types that are attached to an array will always be sized, hence the array form of this macro not existing.

Changed in version 1.18.

For structured datatypes with no fields this function now returns False.

int PyTypeNum_ISUSERDEF(int num)[#](#c.PyTypeNum_ISUSERDEF)
-
int PyDataType_ISUSERDEF([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISUSERDEF)
-
int PyArray_ISUSERDEF([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISUSERDEF)
-
Type represents a user-defined type.

int PyTypeNum_ISEXTENDED(int num)[#](#c.PyTypeNum_ISEXTENDED)
-
int PyDataType_ISEXTENDED([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISEXTENDED)
-
int PyArray_ISEXTENDED([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISEXTENDED)
-
Type is either flexible or user-defined.

int PyTypeNum_ISOBJECT(int num)[#](#c.PyTypeNum_ISOBJECT)
-
int PyDataType_ISOBJECT([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISOBJECT)
-
int PyArray_ISOBJECT([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISOBJECT)
-
Type represents object data type.

int PyTypeNum_ISBOOL(int num)[#](#c.PyTypeNum_ISBOOL)
-
int PyDataType_ISBOOL([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_ISBOOL)
-
int PyArray_ISBOOL([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ISBOOL)
-
Type represents Boolean data type.

int PyDataType_HASFIELDS([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr)[#](#c.PyDataType_HASFIELDS)
-
int PyArray_HASFIELDS([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_HASFIELDS)
-
Type has fields associated with it.

int PyArray_ISNOTSWAPPED([PyArrayObject](types-and-structures.html#c.PyArrayObject)*m)[#](#c.PyArray_ISNOTSWAPPED)
-
Evaluates true if the data area of the ndarray

*m*is in machine byte-order according to the array’s data-type descriptor.
int PyArray_ISBYTESWAPPED([PyArrayObject](types-and-structures.html#c.PyArrayObject)*m)[#](#c.PyArray_ISBYTESWAPPED)
-
Evaluates true if the data area of the ndarray

*m*is**not**in machine byte-order according to the array’s data-type descriptor.
[npy_bool](dtype.html#c.npy_bool)PyArray_EquivTypes([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*type1,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*type2)[#](#c.PyArray_EquivTypes)
-
Return

if`NPY_TRUE`
*type1*and*type2*actually represent equivalent types for this platform (the fortran member of each type is ignored). For example, on 32-bit platforms,and`NPY_LONG`
are equivalent. Otherwise return`NPY_INT`
.`NPY_FALSE`
[npy_bool](dtype.html#c.npy_bool)PyArray_EquivArrTypes([PyArrayObject](types-and-structures.html#c.PyArrayObject)*a1,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*a2)[#](#c.PyArray_EquivArrTypes)
-
Return

if`NPY_TRUE`
*a1*and*a2*are arrays with equivalent types for this platform.
[npy_bool](dtype.html#c.npy_bool)PyArray_EquivTypenums(int typenum1, int typenum2)[#](#c.PyArray_EquivTypenums)
-
Special case of

(…) that does not accept flexible data types but may be easier to call.`PyArray_EquivTypes`
int PyArray_EquivByteorders(int b1, int b2)[#](#c.PyArray_EquivByteorders)
-
True if byteorder characters

*b1*and*b2*(,`NPY_LITTLE`
,`NPY_BIG`
,`NPY_NATIVE`
) are either equal or equivalent as to their specification of a native byte order. Thus, on a little-endian machine`NPY_IGNORE`
and`NPY_LITTLE`
are equivalent where they are not equivalent on a big-endian machine.`NPY_NATIVE`
### Converting data types[#](#converting-data-types)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Cast([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, int typenum)[#](#c.PyArray_Cast)
-
Mainly for backwards compatibility to the Numeric C-API and for simple casts to non-flexible types. Return a new array object with the elements of

*arr*cast to the data-type*typenum*which must be one of the enumerated types and not a flexible type.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_CastToType([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*type, int fortran)[#](#c.PyArray_CastToType)
-
Return a new array of the

*type*specified, casting the elements of*arr*as appropriate. The fortran argument specifies the ordering of the output array.
int PyArray_CastTo([PyArrayObject](types-and-structures.html#c.PyArrayObject)*out,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*in)[#](#c.PyArray_CastTo)
-
As of 1.6, this function simply calls

, which handles the casting.`PyArray_CopyInto`
Cast the elements of the array

*in*into the array*out*. The output array should be writeable, have an integer-multiple of the number of elements in the input array (more than one copy can be placed in out), and have a data type that is one of the builtin types. Returns 0 on success and -1 if an error occurs.
PyArray_VectorUnaryFunc *PyArray_GetCastFunc([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*from, int totype)[#](#c.PyArray_GetCastFunc)
-
Return the low-level casting function to cast from the given descriptor to the builtin type number. If no casting function exists return

`NULL`
and set an error. Using this function instead of direct access to*from*->f->cast will allow support of any user-defined casting functions added to a descriptors casting dictionary.
int PyArray_CanCastSafely(int fromtype, int totype)[#](#c.PyArray_CanCastSafely)
-
Returns non-zero if an array of data type

*fromtype*can be cast to an array of data type*totype*without losing information. An exception is that 64-bit integers are allowed to be cast to 64-bit floating point values even though this can lose precision on large integers so as not to proliferate the use of long doubles without explicit requests. Flexible array types are not checked according to their lengths with this function.
int PyArray_CanCastTo([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*fromtype,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*totype)[#](#c.PyArray_CanCastTo)
-
supersedes this function in NumPy 1.6 and later.`PyArray_CanCastTypeTo`
Equivalent to PyArray_CanCastTypeTo(fromtype, totype, NPY_SAFE_CASTING).

int PyArray_CanCastTypeTo([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*fromtype,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*totype,[NPY_CASTING](#c.NPY_CASTING)casting)[#](#c.PyArray_CanCastTypeTo)
-
New in version 1.6.

Returns non-zero if an array of data type

*fromtype*(which can include flexible types) can be cast safely to an array of data type*totype*(which can include flexible types) according to the casting rule*casting*. For simple types with, this is basically a wrapper around`NPY_SAFE_CASTING`
, but for flexible types such as strings or unicode, it produces results taking into account their sizes. Integer and float types can only be cast to a string or unicode type using`PyArray_CanCastSafely`
if the string or unicode type is big enough to hold the max value of the integer/float type being cast from.`NPY_SAFE_CASTING`
int PyArray_CanCastArrayTo([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*totype,[NPY_CASTING](#c.NPY_CASTING)casting)[#](#c.PyArray_CanCastArrayTo)
-
New in version 1.6.

Returns non-zero if

*arr*can be cast to*totype*according to the casting rule given in*casting*. If*arr*is an array scalar, its value is taken into account, and non-zero is also returned when the value will not overflow or be truncated to an integer when converting to a smaller type.This is almost the same as the result of PyArray_CanCastTypeTo(PyArray_MinScalarType(arr), totype, casting), but it also handles a special case arising because the set of uint values is not a subset of the int values for types with the same number of bits.

[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_MinScalarType([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_MinScalarType)
-
New in version 1.6.

If

*arr*is an array, returns its data type descriptor, but if*arr*is an array scalar (has 0 dimensions), it finds the data type of smallest size to which the value may be converted without overflow or truncation to an integer.This function will not demote complex to float or anything to boolean, but will demote a signed integer to an unsigned integer when the scalar value is positive.

[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_PromoteTypes([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*type1,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*type2)[#](#c.PyArray_PromoteTypes)
-
New in version 1.6.

Finds the data type of smallest size and kind to which

*type1*and*type2*may be safely converted. This function is symmetric and associative. A string or unicode result will be the proper size for storing the max value of the input types converted to a string or unicode.
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_ResultType([npy_intp](dtype.html#c.npy_intp)narrs,[PyArrayObject](types-and-structures.html#c.PyArrayObject)**arrs,[npy_intp](dtype.html#c.npy_intp)ndtypes,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**dtypes)[#](#c.PyArray_ResultType)
-
New in version 1.6.

This applies type promotion to all the input arrays and dtype objects, using the NumPy rules for combining scalars and arrays, to determine the output type for an operation with the given set of operands. This is the same result type that ufuncs produce.

See the documentation of

for more detail about the type promotion algorithm.`numpy.result_type`
int PyArray_ObjectType([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, int mintype)[#](#c.PyArray_ObjectType)
-
This function is superseded by

and/or`PyArray_MinScalarType`
.`PyArray_ResultType`
This function is useful for determining a common type that two or more arrays can be converted to. It only works for non-flexible array types as no itemsize information is passed. The

*mintype*argument represents the minimum type acceptable, and*op*represents the object that will be converted to an array. The return value is the enumerated typenumber that represents the data-type that*op*should have.
[PyArrayObject](types-and-structures.html#c.PyArrayObject)**PyArray_ConvertToCommonType([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, int *n)[#](#c.PyArray_ConvertToCommonType)
-
The functionality this provides is largely superseded by iterator

introduced in 1.6, with flag`NpyIter`
or with the same dtype parameter for all operands.`NPY_ITER_COMMON_DTYPE`
Convert a sequence of Python objects contained in

*op*to an array of ndarrays each having the same data type. The type is selected in the same way as*PyArray_ResultType*. The length of the sequence is returned in*n*, and an*n*-length array ofpointers is the return value (or`PyArrayObject`
`NULL`
if an error occurs). The returned array must be freed by the caller of this routine (using) and all the array objects in it`PyDataMem_FREE`
`DECREF`
‘d or a memory-leak will occur. The example template-code below shows a typically usage:Changed in version 1.18.0: A mix of scalars and zero-dimensional arrays now produces a type capable of holding the scalar value. Previously priority was given to the dtype of the arrays.

mps = PyArray_ConvertToCommonType(obj, &n); if (mps==NULL) return NULL; {code} <before return> for (i=0; i<n; i++) Py_DECREF(mps[i]); PyDataMem_FREE(mps); {return}
char *PyArray_Zero([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_Zero)
-
A pointer to newly created memory of size

*arr*->itemsize that holds the representation of 0 for that type. The returned pointer,*ret*,**must be freed**using(ret) when it is not needed anymore.`PyDataMem_FREE`
char *PyArray_One([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_One)
-
A pointer to newly created memory of size

*arr*->itemsize that holds the representation of 1 for that type. The returned pointer,*ret*,**must be freed**using(ret) when it is not needed anymore.`PyDataMem_FREE`
### User-defined data types[#](#user-defined-data-types)
void PyArray_InitArrFuncs([PyArray_ArrFuncs](types-and-structures.html#c.PyArray_ArrFuncs)*f)[#](#c.PyArray_InitArrFuncs)
-
Initialize all function pointers and members to

`NULL`
.
int PyArray_RegisterDataType([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype)[#](#c.PyArray_RegisterDataType)
-
Register a data-type as a new user-defined data type for arrays. The type must have most of its entries filled in. This is not always checked and errors can produce segfaults. In particular, the typeobj member of the

`dtype`
structure must be filled with a Python type that has a fixed-size element-size that corresponds to the elsize member of*dtype*. Also the`f`
member must have the required functions: nonzero, copyswap, copyswapn, getitem, setitem, and cast (some of the cast functions may be`NULL`
if no support is desired). To avoid confusion, you should choose a unique character typecode but this is not enforced and not relied on internally.A user-defined type number is returned that uniquely identifies the type. A pointer to the new structure can then be obtained from

using the returned type number. A -1 is returned if an error occurs. If this`PyArray_DescrFromType`
*dtype*has already been registered (checked only by the address of the pointer), then return the previously-assigned type-number.
int PyArray_RegisterCastFunc([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr, int totype, PyArray_VectorUnaryFunc *castfunc)[#](#c.PyArray_RegisterCastFunc)
-
Register a low-level casting function,

*castfunc*, to convert from the data-type,*descr*, to the given data-type number,*totype*. Any old casting function is over-written. A`0`
is returned on success or a`-1`
on failure.
int PyArray_RegisterCanCast([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*descr, int totype,[NPY_SCALARKIND](#c.NPY_SCALARKIND)scalar)[#](#c.PyArray_RegisterCanCast)
-
Register the data-type number,

*totype*, as castable from data-type object,*descr*, of the given*scalar*kind. Use*scalar*=to register that an array of data-type`NPY_NOSCALAR`
*descr*can be cast safely to a data-type whose type_number is*totype*. The return value is 0 on success or -1 on failure.
int PyArray_TypeNumFromName(char const *str)[#](#c.PyArray_TypeNumFromName)
-
Given a string return the type-number for the data-type with that string as the type-object name. Returns

`NPY_NOTYPE`
without setting an error if no type can be found. Only works for user-defined data-types.
### Special functions for NPY_OBJECT[#](#special-functions-for-npy-object)
Warning

When working with arrays or buffers filled with objects NumPy tries to
ensure such buffers are filled with `None`
before any data may be read.
However, code paths may existed where an array is only initialized to
`NULL`
.
NumPy itself accepts `NULL`
as an alias for `None`
, but may `assert`
non-`NULL`
when compiled in debug mode.

Because NumPy is not yet consistent about initialization with None,
users **must** expect a value of `NULL`
when working with buffers created
by NumPy. Users **should** also ensure to pass fully initialized buffers
to NumPy, since NumPy may make this a strong requirement in the future.

There is currently an intention to ensure that NumPy always initializes object arrays before they may be read. Any failure to do so will be regarded as a bug. In the future, users may be able to rely on non-NULL values when reading from any array, although exceptions for writing to freshly created arrays may remain (e.g. for output arrays in ufunc code). As of NumPy 1.23 known code paths exists where proper filling is not done.

int PyArray_INCREF([PyArrayObject](types-and-structures.html#c.PyArrayObject)*op)[#](#c.PyArray_INCREF)
-
Used for an array,

*op*, that contains any Python objects. It increments the reference count of every object in the array according to the data-type of*op*. A -1 is returned if an error occurs, otherwise 0 is returned.
void PyArray_Item_INCREF(char *ptr, [PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype)[#](#c.PyArray_Item_INCREF)
-
A function to INCREF all the objects at the location

*ptr*according to the data-type*dtype*. If*ptr*is the start of a structured type with an object at any offset, then this will (recursively) increment the reference count of all object-like items in the structured type.
int PyArray_XDECREF([PyArrayObject](types-and-structures.html#c.PyArrayObject)*op)[#](#c.PyArray_XDECREF)
-
Used for an array,

*op*, that contains any Python objects. It decrements the reference count of every object in the array according to the data-type of*op*. Normal return value is 0. A -1 is returned if an error occurs.
void PyArray_Item_XDECREF(char *ptr, [PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype)[#](#c.PyArray_Item_XDECREF)
-
A function to XDECREF all the object-like items at the location

*ptr*as recorded in the data-type,*dtype*. This works recursively so that if`dtype`
itself has fields with data-types that contain object-like items, all the object-like fields will be XDECREF`'d`
.
void PyArray_FillObjectArray([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_FillObjectArray)
-
Fill a newly created array with a single value obj at all locations in the structure with object data-types. No checking is performed but

*arr*must be of data-typeand be single-segment and uninitialized (no previous objects in position). Use`NPY_OBJECT`
(`PyArray_XDECREF`
*arr*) if you need to decrement all the items in the object array prior to calling this function.
int PyArray_SetWritebackIfCopyBase([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*base)[#](#c.PyArray_SetWritebackIfCopyBase)
-
Precondition:

`arr`
is a copy of`base`
(though possibly with different strides, ordering, etc.) Sets theflag and`NPY_ARRAY_WRITEBACKIFCOPY`
`arr->base`
, and set`base`
to READONLY. Callbefore calling`PyArray_ResolveWritebackIfCopy`
*Py_DECREF*in order copy any changes back to`base`
and reset the READONLY flag.Returns 0 for success, -1 for failure.

## Array flags[#](#array-flags)
The `flags`
attribute of the `PyArrayObject`
structure contains
important information about the memory used by the array (pointed to
by the data member) This flag information must be kept accurate or
strange results and even segfaults may result.

There are 6 (binary) flags that describe the memory area used by the
data buffer. These constants are defined in `arrayobject.h`
and
determine the bit-position of the flag. Python exposes a nice
attribute- based interface as well as a dictionary-like interface for
getting (and, if appropriate, setting) these flags.

Memory areas of all kinds can be pointed to by an ndarray, necessitating
these flags. If you get an arbitrary `PyArrayObject`
in C-code, you
need to be aware of the flags that are set. If you need to guarantee
a certain kind of array (like [ NPY_ARRAY_C_CONTIGUOUS](#c.NPY_ARRAY_C_CONTIGUOUS) and

[), then pass these requirements into the PyArray_FromAny function.](#c.NPY_ARRAY_BEHAVED)
`NPY_ARRAY_BEHAVED`
### Basic Array Flags[#](#basic-array-flags)
An ndarray can have a data segment that is not a simple contiguous chunk of well-behaved memory you can manipulate. It may not be aligned with word boundaries (very important on some platforms). It might have its data in a different byte-order than the machine recognizes. It might not be writeable. It might be in Fortran-contiguous order. The array flags are used to indicate what can be said about data associated with an array.

In versions 1.6 and earlier of NumPy, the following flags did not have the _ARRAY_ macro namespace in them. That form of the constant names is deprecated in 1.7.

NPY_ARRAY_C_CONTIGUOUS[#](#c.NPY_ARRAY_C_CONTIGUOUS)
-
The data area is in C-style contiguous order (last index varies the fastest).

NPY_ARRAY_F_CONTIGUOUS[#](#c.NPY_ARRAY_F_CONTIGUOUS)
-
The data area is in Fortran-style contiguous order (first index varies the fastest).

Note

Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.

Even for contiguous arrays a stride for a given dimension
`arr.strides[dim]`
may be *arbitrary* if `arr.shape[dim] == 1`
or the array has no elements.
It does *not* generally hold that `self.strides[-1] == self.itemsize`
for C-style contiguous arrays or `self.strides[0] == self.itemsize`
for
Fortran-style contiguous arrays is true. The correct way to access the
`itemsize`
of an array from the C API is `PyArray_ITEMSIZE(arr)`
.

See also

NPY_ARRAY_OWNDATA[#](#c.NPY_ARRAY_OWNDATA)
-
The data area is owned by this array. Should never be set manually, instead create a

`PyObject`
wrapping the data and set the array’s base to that object. For an example, see the test in`test_mem_policy`
.
NPY_ARRAY_ALIGNED[#](#c.NPY_ARRAY_ALIGNED)
-
The data area and all array elements are aligned appropriately.

NPY_ARRAY_WRITEABLE[#](#c.NPY_ARRAY_WRITEABLE)
-
The data area can be written to.

Notice that the above 3 flags are defined so that a new, well- behaved array has these flags defined as true.

NPY_ARRAY_WRITEBACKIFCOPY[#](#c.NPY_ARRAY_WRITEBACKIFCOPY)
-
The data area represents a (well-behaved) copy whose information should be transferred back to the original when

is called.`PyArray_ResolveWritebackIfCopy`
This is a special flag that is set if this array represents a copy made because a user required certain flags in

and a copy had to be made of some other array (and the user asked for this flag to be set in such a situation). The base attribute then points to the “misbehaved” array (which is set read_only).`PyArray_FromAny`
will copy its contents back to the “misbehaved” array (casting if necessary) and will reset the “misbehaved” array to`PyArray_ResolveWritebackIfCopy`
. If the “misbehaved” array was not`NPY_ARRAY_WRITEABLE`
to begin with then`NPY_ARRAY_WRITEABLE`
would have returned an error because`PyArray_FromAny`
would not have been possible.`NPY_ARRAY_WRITEBACKIFCOPY`
[ PyArray_UpdateFlags](#c.PyArray_UpdateFlags) (obj, flags) will update the
`obj->flags`
for `flags`
which can be any of [,](#c.NPY_ARRAY_C_CONTIGUOUS)
`NPY_ARRAY_C_CONTIGUOUS`
[,](#c.NPY_ARRAY_F_CONTIGUOUS)
`NPY_ARRAY_F_CONTIGUOUS`
[, or](#c.NPY_ARRAY_ALIGNED)
`NPY_ARRAY_ALIGNED`
[.](#c.NPY_ARRAY_WRITEABLE)
`NPY_ARRAY_WRITEABLE`
### Combinations of array flags[#](#combinations-of-array-flags)
NPY_ARRAY_BEHAVED[#](#c.NPY_ARRAY_BEHAVED)
-
NPY_ARRAY_CARRAY[#](#c.NPY_ARRAY_CARRAY)
-
NPY_ARRAY_CARRAY_RO[#](#c.NPY_ARRAY_CARRAY_RO)
-
NPY_ARRAY_FARRAY[#](#c.NPY_ARRAY_FARRAY)
-
NPY_ARRAY_FARRAY_RO[#](#c.NPY_ARRAY_FARRAY_RO)
-
NPY_ARRAY_DEFAULT[#](#c.NPY_ARRAY_DEFAULT)
-
NPY_ARRAY_UPDATE_ALL[#](#c.NPY_ARRAY_UPDATE_ALL)
-
|`NPY_ARRAY_C_CONTIGUOUS`
|`NPY_ARRAY_F_CONTIGUOUS`
`NPY_ARRAY_ALIGNED`
### Flag-like constants[#](#flag-like-constants)
These constants are used in [ PyArray_FromAny](#c.PyArray_FromAny) (and its macro forms) to
specify desired properties of the new array.

NPY_ARRAY_FORCECAST[#](#c.NPY_ARRAY_FORCECAST)
-
Cast to the desired type, even if it can’t be done without losing information.

NPY_ARRAY_ENSURECOPY[#](#c.NPY_ARRAY_ENSURECOPY)
-
Make sure the resulting array is a copy of the original.

NPY_ARRAY_ENSUREARRAY[#](#c.NPY_ARRAY_ENSUREARRAY)
-
Make sure the resulting object is an actual ndarray, and not a sub-class.

### Flag checking[#](#flag-checking)
For all of these macros *arr* must be an instance of a (subclass of)
[ PyArray_Type](types-and-structures.html#c.PyArray_Type).

int PyArray_CHKFLAGS([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr, int flags)[#](#c.PyArray_CHKFLAGS)
-
The first parameter, arr, must be an ndarray or subclass. The parameter,

*flags*, should be an integer consisting of bitwise combinations of the possible flags an array can have:,`NPY_ARRAY_C_CONTIGUOUS`
,`NPY_ARRAY_F_CONTIGUOUS`
,`NPY_ARRAY_OWNDATA`
,`NPY_ARRAY_ALIGNED`
,`NPY_ARRAY_WRITEABLE`
.`NPY_ARRAY_WRITEBACKIFCOPY`
int PyArray_ISFORTRAN([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISFORTRAN)
-
Evaluates true if

*arr*is Fortran-style contiguous and*not*C-style contiguous.is the correct way to test for Fortran-style contiguity.`PyArray_IS_F_CONTIGUOUS`
int PyArray_ISALIGNED([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISALIGNED)
-
Evaluates true if the data area of

*arr*is properly aligned on the machine.
int PyArray_ISBEHAVED([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISBEHAVED)
-
Evaluates true if the data area of

*arr*is aligned and writeable and in machine byte-order according to its descriptor.
int PyArray_ISBEHAVED_RO([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISBEHAVED_RO)
-
Evaluates true if the data area of

*arr*is aligned and in machine byte-order.
int PyArray_ISCARRAY([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISCARRAY)
-
Evaluates true if the data area of

*arr*is C-style contiguous, and(`PyArray_ISBEHAVED`
*arr*) is true.
int PyArray_ISFARRAY([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISFARRAY)
-
Evaluates true if the data area of

*arr*is Fortran-style contiguous and(`PyArray_ISBEHAVED`
*arr*) is true.
int PyArray_ISCARRAY_RO([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISCARRAY_RO)
-
Evaluates true if the data area of

*arr*is C-style contiguous, aligned, and in machine byte-order.
int PyArray_ISFARRAY_RO([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISFARRAY_RO)
-
Evaluates true if the data area of

*arr*is Fortran-style contiguous, aligned, and in machine byte-order**.**
int PyArray_ISONESEGMENT([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_ISONESEGMENT)
-
Evaluates true if the data area of

*arr*consists of a single (C-style or Fortran-style) contiguous segment.
void PyArray_UpdateFlags([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr, int flagmask)[#](#c.PyArray_UpdateFlags)
-
The

,`NPY_ARRAY_C_CONTIGUOUS`
, and`NPY_ARRAY_ALIGNED`
array flags can be “calculated” from the array object itself. This routine updates one or more of these flags of`NPY_ARRAY_F_CONTIGUOUS`
*arr*as specified in*flagmask*by performing the required calculation.
Warning

It is important to keep the flags updated (using
[ PyArray_UpdateFlags](#c.PyArray_UpdateFlags) can help) whenever a manipulation with an
array is performed that might cause them to change. Later
calculations in NumPy that rely on the state of these flags do not
repeat the calculation to update them.

int PyArray_FailUnlessWriteable([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj, const char *name)[#](#c.PyArray_FailUnlessWriteable)
-
This function does nothing and returns 0 if

*obj*is writeable. It raises an exception and returns -1 if*obj*is not writeable. It may also do other house-keeping, such as issuing warnings on arrays which are transitioning to become views. Always call this function at some point before writing to an array.*name*is a name for the array, used to give better error messages. It can be something like “assignment destination”, “output array”, or even just “array”.
## Array method alternative API[#](#array-method-alternative-api)
### Conversion[#](#conversion)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_GetField([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype, int offset)[#](#c.PyArray_GetField)
-
Equivalent to

(`ndarray.getfield`
*self*,*dtype*,*offset*). This function[steals a reference](https://docs.python.org/3/c-api/intro.html?reference-count-details)to*PyArray_Descr*and returns a new array of the given*dtype*using the data in the current array at a specified*offset*in bytes. The*offset*plus the itemsize of the new array type must be less than`self ->descr->elsize`
or an error is raised. The same shape and strides as the original array are used. Therefore, this function has the effect of returning a field from a structured array. But, it can also be used to select specific bytes or groups of bytes from any array type.
int PyArray_SetField([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype, int offset,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*val)[#](#c.PyArray_SetField)
-
Equivalent to

(`ndarray.setfield`
*self*,*val*,*dtype*,*offset*). Set the field starting at*offset*in bytes and of the given*dtype*to*val*. The*offset*plus*dtype*->elsize must be less than*self*->descr->elsize or an error is raised. Otherwise, the*val*argument is converted to an array and copied into the field pointed to. If necessary, the elements of*val*are repeated to fill the destination array, But, the number of elements in the destination must be an integer multiple of the number of elements in*val*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Byteswap([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[npy_bool](dtype.html#c.npy_bool)inplace)[#](#c.PyArray_Byteswap)
-
Equivalent to

(`ndarray.byteswap`
*self*,*inplace*). Return an array whose data area is byteswapped. If*inplace*is non-zero, then do the byteswap inplace and return a reference to self. Otherwise, create a byteswapped copy and leave self unchanged.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_NewCopy([PyArrayObject](types-and-structures.html#c.PyArrayObject)*old,[NPY_ORDER](#c.NPY_ORDER)order)[#](#c.PyArray_NewCopy)
-
Equivalent to

(`ndarray.copy`
*self*,*fortran*). Make a copy of the*old*array. The returned array is always aligned and writeable with data interpreted the same as the old array. If*order*is, then a C-style contiguous array is returned. If`NPY_CORDER`
*order*is, then a Fortran-style contiguous array is returned. If`NPY_FORTRANORDER`
*order is*, then the array returned is Fortran-style contiguous only if the old one is; otherwise, it is C-style contiguous.`NPY_ANYORDER`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ToList([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self)[#](#c.PyArray_ToList)
-
Equivalent to

(`ndarray.tolist`
*self*). Return a nested Python list from*self*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ToString([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[NPY_ORDER](#c.NPY_ORDER)order)[#](#c.PyArray_ToString)
-
Equivalent to

(`ndarray.tobytes`
*self*,*order*). Return the bytes of this array in a Python string.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ToFile([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, FILE *fp, char *sep, char *format)[#](#c.PyArray_ToFile)
-
Write the contents of

*self*to the file pointer*fp*in C-style contiguous fashion. Write the data as binary bytes if*sep*is the string “”or`NULL`
. Otherwise, write the contents of*self*as text using the*sep*string as the item separator. Each item will be printed to the file. If the*format*string is not`NULL`
or “”, then it is a Python print statement format string showing how the items are to be written.
int PyArray_Dump([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*file, int protocol)[#](#c.PyArray_Dump)
-
Pickle the object in

*self*to the given*file*(either a string or a Python file object). If*file*is a Python string it is considered to be the name of a file which is then opened in binary mode. The given*protocol*is used (if*protocol*is negative, or the highest available is used). This is a simple wrapper around cPickle.dump(*self*,*file*,*protocol*).
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Dumps([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*self, int protocol)[#](#c.PyArray_Dumps)
-
Pickle the object in

*self*to a Python string and return it. Use the Pickle*protocol*provided (or the highest available if*protocol*is negative).
int PyArray_FillWithScalar([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_FillWithScalar)
-
Fill the array,

*arr*, with the given scalar object,*obj*. The object is first converted to the data type of*arr*, and then copied into every location. A -1 is returned if an error occurs, otherwise 0 is returned.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_View([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[PyTypeObject](https://docs.python.org/3/c-api/type.html#c.PyTypeObject)*ptype)[#](#c.PyArray_View)
-
Equivalent to

(`ndarray.view`
*self*,*dtype*). Return a new view of the array*self*as possibly a different data-type,*dtype*, and different array subclass*ptype*.If

*dtype*is`NULL`
, then the returned array will have the same data type as*self*. The new data-type must be consistent with the size of*self*. Either the itemsizes must be identical, or*self*must be single-segment and the total number of bytes must be the same. In the latter case the dimensions of the returned array will be altered in the last (or first for Fortran-style contiguous arrays) dimension. The data area of the returned array and self is exactly the same.
### Shape Manipulation[#](#shape-manipulation)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Newshape([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyArray_Dims](types-and-structures.html#c.PyArray_Dims)*newshape,[NPY_ORDER](#c.NPY_ORDER)order)[#](#c.PyArray_Newshape)
-
Result will be a new array (pointing to the same memory location as

*self*if possible), but having a shape given by*newshape*. If the new shape is not compatible with the strides of*self*, then a copy of the array with the new specified shape will be returned.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Reshape([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*shape)[#](#c.PyArray_Reshape)
-
Equivalent to

(`ndarray.reshape`
*self*,*shape*) where*shape*is a sequence. Converts*shape*to astructure and calls`PyArray_Dims`
internally. For back-ward compatibility – Not recommended`PyArray_Newshape`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Squeeze([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self)[#](#c.PyArray_Squeeze)
-
Equivalent to

(`ndarray.squeeze`
*self*). Return a new view of*self*with all of the dimensions of length 1 removed from the shape.
Warning

matrix objects are always 2-dimensional. Therefore,
[ PyArray_Squeeze](#c.PyArray_Squeeze) has no effect on arrays of matrix sub-class.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_SwapAxes([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int a1, int a2)[#](#c.PyArray_SwapAxes)
-
Equivalent to

(`ndarray.swapaxes`
*self*,*a1*,*a2*). The returned array is a new view of the data in*self*with the given axes,*a1*and*a2*, swapped.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Resize([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyArray_Dims](types-and-structures.html#c.PyArray_Dims)*newshape, int refcheck,[NPY_ORDER](#c.NPY_ORDER)fortran)[#](#c.PyArray_Resize)
-
Equivalent to

(`ndarray.resize`
*self*,*newshape*, refcheck`=`
*refcheck*, order= fortran ). This function only works on single-segment arrays. It changes the shape of*self*inplace and will reallocate the memory for*self*if*newshape*has a different total number of elements then the old shape. If reallocation is necessary, then*self*must own its data, have*self*-`>base==NULL`
, have*self*-`>weakrefs==NULL`
, and (unless refcheck is 0) not be referenced by any other array. The fortran argument can be,`NPY_ANYORDER`
, or`NPY_CORDER`
. It currently has no effect. Eventually it could be used to determine how the resize operation should view the data when constructing a differently-dimensioned array. Returns None on success and NULL on error.`NPY_FORTRANORDER`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Transpose([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyArray_Dims](types-and-structures.html#c.PyArray_Dims)*permute)[#](#c.PyArray_Transpose)
-
Equivalent to

(`ndarray.transpose`
*self*,*permute*). Permute the axes of the ndarray object*self*according to the data structure*permute*and return the result. If*permute*is`NULL`
, then the resulting array has its axes reversed. For example if*self*has shape \(10\times20\times30\), and*permute*`.ptr`
is (0,2,1) the shape of the result is \(10\times30\times20.\) If*permute*is`NULL`
, the shape of the result is \(30\times20\times10.\)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Flatten([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[NPY_ORDER](#c.NPY_ORDER)order)[#](#c.PyArray_Flatten)
-
Equivalent to

(`ndarray.flatten`
*self*,*order*). Return a 1-d copy of the array. If*order*isthe elements are scanned out in Fortran order (first-dimension varies the fastest). If`NPY_FORTRANORDER`
*order*is, the elements of`NPY_CORDER`
`self`
are scanned in C-order (last dimension varies the fastest). If*order*, then the result of`NPY_ANYORDER`
(`PyArray_ISFORTRAN`
*self*) is used to determine which order to flatten.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Ravel([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[NPY_ORDER](#c.NPY_ORDER)order)[#](#c.PyArray_Ravel)
-
Equivalent to

*self*.ravel(*order*). Same basic functionality as(`PyArray_Flatten`
*self*,*order*) except if*order*is 0 and*self*is C-style contiguous, the shape is altered but no copy is performed.
### Item selection and manipulation[#](#item-selection-and-manipulation)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_TakeFrom([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*indices, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*ret,[NPY_CLIPMODE](#c.NPY_CLIPMODE)clipmode)[#](#c.PyArray_TakeFrom)
-
Equivalent to

(`ndarray.take`
*self*,*indices*,*axis*,*ret*,*clipmode*) except*axis*=None in Python is obtained by setting*axis*=in C. Extract the items from self indicated by the integer-valued`NPY_MAXDIMS`
*indices*along the given*axis.*The clipmode argument can be,`NPY_RAISE`
, or`NPY_WRAP`
to indicate what to do with out-of-bound indices. The`NPY_CLIP`
*ret*argument can specify an output array rather than having one created internally.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_PutTo([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*values,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*indices,[NPY_CLIPMODE](#c.NPY_CLIPMODE)clipmode)[#](#c.PyArray_PutTo)
-
Equivalent to

*self*.put(*values*,*indices*,*clipmode*). Put*values*into*self*at the corresponding (flattened)*indices*. If*values*is too small it will be repeated as necessary.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_PutMask([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*values,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*mask)[#](#c.PyArray_PutMask)
-
Place the

*values*in*self*wherever corresponding positions (using a flattened context) in*mask*are true. The*mask*and*self*arrays must have the same total number of elements. If*values*is too small, it will be repeated as necessary.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Repeat([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, int axis)[#](#c.PyArray_Repeat)
-
Equivalent to

(`ndarray.repeat`
*self*,*op*,*axis*). Copy the elements of*self*,*op*times along the given*axis*. Either*op*is a scalar integer or a sequence of length*self*->dimensions[*axis*] indicating how many times to repeat each item along the axis.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Choose([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*ret,[NPY_CLIPMODE](#c.NPY_CLIPMODE)clipmode)[#](#c.PyArray_Choose)
-
Equivalent to

(`ndarray.choose`
*self*,*op*,*ret*,*clipmode*). Create a new array by selecting elements from the sequence of arrays in*op*based on the integer values in*self*. The arrays must all be broadcastable to the same shape and the entries in*self*should be between 0 and len(*op*). The output is placed in*ret*unless it is`NULL`
in which case a new output is created. The*clipmode*argument determines behavior for when entries in*self*are not between 0 and len(*op*).
NPY_RAISE[#](#c.PyArray_Choose.NPY_RAISE)
-
raise a ValueError;

NPY_WRAP[#](#c.PyArray_Choose.NPY_WRAP)
-
wrap values < 0 by adding len(

*op*) and values >=len(*op*) by subtracting len(*op*) until they are in range;
NPY_CLIP[#](#c.PyArray_Choose.NPY_CLIP)
-
all values are clipped to the region [0, len(

*op*) ).
NPY_RAISE
-
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Sort([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[NPY_SORTKIND](#c.NPY_SORTKIND)kind)[#](#c.PyArray_Sort)
-
Equivalent to

(`ndarray.sort`
*self*,*axis*,*kind*). Return an array with the items of*self*sorted along*axis*. The array is sorted using the algorithm denoted by*kind*, which is an integer/enum pointing to the type of sorting algorithms used.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ArgSort([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis)[#](#c.PyArray_ArgSort)
-
Equivalent to

(`ndarray.argsort`
*self*,*axis*). Return an array of indices such that selection of these indices along the given`axis`
would return a sorted version of*self*. If*self*->descr is a data-type with fields defined, then self->descr->names is used to determine the sort order. A comparison where the first field is equal will use the second field and so on. To alter the sort order of a structured array, create a new data-type with a different order of names and construct a view of the array with that new data-type.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_LexSort([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*sort_keys, int axis)[#](#c.PyArray_LexSort)
-
Given a sequence of arrays (

*sort_keys*) of the same shape, return an array of indices (similar to(…)) that would sort the arrays lexicographically. A lexicographic sort specifies that when two keys are found to be equal, the order is based on comparison of subsequent keys. A merge sort (which leaves equal entries unmoved) is required to be defined for the types. The sort is accomplished by sorting the indices first using the first`PyArray_ArgSort`
*sort_key*and then using the second*sort_key*and so forth. This is equivalent to the lexsort(*sort_keys*,*axis*) Python command. Because of the way the merge-sort works, be sure to understand the order the*sort_keys*must be in (reversed from the order you would use when comparing two elements).If these arrays are all collected in a structured array, then

(…) can also be used to sort the array directly.`PyArray_Sort`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_SearchSorted([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*values,[NPY_SEARCHSIDE](#c.NPY_SEARCHSIDE)side,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*perm)[#](#c.PyArray_SearchSorted)
-
Equivalent to

(`ndarray.searchsorted`
*self*,*values*,*side*,*perm*). Assuming*self*is a 1-d array in ascending order, then the output is an array of indices the same shape as*values*such that, if the elements in*values*were inserted before the indices, the order of*self*would be preserved. No checking is done on whether or not self is in ascending order.The

*side*argument indicates whether the index returned should be that of the first suitable location (if) or of the last (if`NPY_SEARCHLEFT`
).`NPY_SEARCHRIGHT`
The

*sorter*argument, if not`NULL`
, must be a 1D array of integer indices the same length as*self*, that sorts it into ascending order. This is typically the result of a call to(…) Binary search is used to find the required insertion points.`PyArray_ArgSort`
int PyArray_Partition([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*ktharray, int axis,[NPY_SELECTKIND](#c.NPY_SELECTKIND)which)[#](#c.PyArray_Partition)
-
Equivalent to

(`ndarray.partition`
*self*,*ktharray*,*axis*,*kind*). Partitions the array so that the values of the element indexed by*ktharray*are in the positions they would be if the array is fully sorted and places all elements smaller than the kth before and all elements equal or greater after the kth element. The ordering of all elements within the partitions is undefined. If*self*->descr is a data-type with fields defined, then self->descr->names is used to determine the sort order. A comparison where the first field is equal will use the second field and so on. To alter the sort order of a structured array, create a new data-type with a different order of names and construct a view of the array with that new data-type. Returns zero on success and -1 on failure.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ArgPartition([PyArrayObject](types-and-structures.html#c.PyArrayObject)*op,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*ktharray, int axis,[NPY_SELECTKIND](#c.NPY_SELECTKIND)which)[#](#c.PyArray_ArgPartition)
-
Equivalent to

(`ndarray.argpartition`
*self*,*ktharray*,*axis*,*kind*). Return an array of indices such that selection of these indices along the given`axis`
would return a partitioned version of*self*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Diagonal([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int offset, int axis1, int axis2)[#](#c.PyArray_Diagonal)
-
Equivalent to

(`ndarray.diagonal`
*self*,*offset*,*axis1*,*axis2*). Return the*offset*diagonals of the 2-d arrays defined by*axis1*and*axis2*.
[npy_intp](dtype.html#c.npy_intp)PyArray_CountNonzero([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self)[#](#c.PyArray_CountNonzero)
-
New in version 1.6.

Counts the number of non-zero elements in the array object

*self*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Nonzero([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self)[#](#c.PyArray_Nonzero)
-
Equivalent to

(`ndarray.nonzero`
*self*). Returns a tuple of index arrays that select elements of*self*that are nonzero. If (nd=(`PyArray_NDIM`
`self`
))==1, then a single index array is returned. The index arrays have data type. If a tuple is returned (nd \(\neq\) 1), then its length is nd.`NPY_INTP`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Compress([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*condition, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Compress)
-
Equivalent to

(`ndarray.compress`
*self*,*condition*,*axis*). Return the elements along*axis*corresponding to elements of*condition*that are true.
### Calculation[#](#calculation)
Tip

Pass in [ NPY_MAXDIMS](#c.NPY_MAXDIMS) for axis in order to achieve the same
effect that is obtained by passing in

`axis=None`
in Python
(treating the array as a 1-d array).Note

The out argument specifies where to place the result. If out is
NULL, then the output array is created, otherwise the output is
placed in out which must be the correct size and type. A new
reference to the output array is always returned even when out
is not NULL. The caller of the routine has the responsibility
to `Py_DECREF`
out if not NULL or a memory-leak will occur.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ArgMax([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_ArgMax)
-
Equivalent to

(`ndarray.argmax`
*self*,*axis*). Return the index of the largest element of*self*along*axis*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ArgMin([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_ArgMin)
-
Equivalent to

(`ndarray.argmin`
*self*,*axis*). Return the index of the smallest element of*self*along*axis*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Max([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Max)
-
Equivalent to

(`ndarray.max`
*self*,*axis*). Returns the largest element of*self*along the given*axis*. When the result is a single element, returns a numpy scalar instead of an ndarray.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Min([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Min)
-
Equivalent to

(`ndarray.min`
*self*,*axis*). Return the smallest element of*self*along the given*axis*. When the result is a single element, returns a numpy scalar instead of an ndarray.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Ptp([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Ptp)
-
Equivalent to

(`ndarray.ptp`
*self*,*axis*). Return the difference between the largest element of*self*along*axis*and the smallest element of*self*along*axis*. When the result is a single element, returns a numpy scalar instead of an ndarray.
Note

The rtype argument specifies the data-type the reduction should
take place over. This is important if the data-type of the array
is not “large” enough to handle the output. By default, all
integer data-types are made at least as large as [ NPY_LONG](dtype.html#c.NPY_TYPES.NPY_LONG)
for the “add” and “multiply” ufuncs (which form the basis for
mean, sum, cumsum, prod, and cumprod functions).

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Mean([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis, int rtype,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Mean)
-
Equivalent to

(`ndarray.mean`
*self*,*axis*,*rtype*). Returns the mean of the elements along the given*axis*, using the enumerated type*rtype*as the data type to sum in. Default sum behavior is obtained usingfor`NPY_NOTYPE`
*rtype*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Trace([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int offset, int axis1, int axis2, int rtype,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Trace)
-
Equivalent to

(`ndarray.trace`
*self*,*offset*,*axis1*,*axis2*,*rtype*). Return the sum (using*rtype*as the data type of summation) over the*offset*diagonal elements of the 2-d arrays defined by*axis1*and*axis2*variables. A positive offset chooses diagonals above the main diagonal. A negative offset selects diagonals below the main diagonal.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Clip([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*min,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*max)[#](#c.PyArray_Clip)
-
Equivalent to

(`ndarray.clip`
*self*,*min*,*max*). Clip an array,*self*, so that values larger than*max*are fixed to*max*and values less than*min*are fixed to*min*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Conjugate([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self)[#](#c.PyArray_Conjugate)
-
Equivalent to

(`ndarray.conjugate`
*self*). Return the complex conjugate of*self*. If*self*is not of complex data type, then return*self*with a reference.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Round([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int decimals,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Round)
-
Equivalent to

(`ndarray.round`
*self*,*decimals*,*out*). Returns the array with elements rounded to the nearest decimal place. The decimal place is defined as the \(10^{-\textrm{decimals}}\) digit so that negative*decimals*cause rounding to the nearest 10’s, 100’s, etc. If out is`NULL`
, then the output array is created, otherwise the output is placed in*out*which must be the correct size and type.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Std([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis, int rtype,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Std)
-
Equivalent to

(`ndarray.std`
*self*,*axis*,*rtype*). Return the standard deviation using data along*axis*converted to data type*rtype*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Sum([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis, int rtype,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Sum)
-
Equivalent to

(`ndarray.sum`
*self*,*axis*,*rtype*). Return 1-d vector sums of elements in*self*along*axis*. Perform the sum after converting data to data type*rtype*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_CumSum([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis, int rtype,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_CumSum)
-
Equivalent to

(`ndarray.cumsum`
*self*,*axis*,*rtype*). Return cumulative 1-d sums of elements in*self*along*axis*. Perform the sum after converting data to data type*rtype*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Prod([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis, int rtype,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Prod)
-
Equivalent to

(`ndarray.prod`
*self*,*axis*,*rtype*). Return 1-d products of elements in*self*along*axis*. Perform the product after converting data to data type*rtype*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_CumProd([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis, int rtype,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_CumProd)
-
Equivalent to

(`ndarray.cumprod`
*self*,*axis*,*rtype*). Return 1-d cumulative products of elements in`self`
along`axis`
. Perform the product after converting data to data type`rtype`
.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_All([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_All)
-
Equivalent to

(`ndarray.all`
*self*,*axis*). Return an array with True elements for every 1-d sub-array of`self`
defined by`axis`
in which all the elements are True.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Any([PyArrayObject](types-and-structures.html#c.PyArrayObject)*self, int axis,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_Any)
-
Equivalent to

(`ndarray.any`
*self*,*axis*). Return an array with True elements for every 1-d sub-array of*self*defined by*axis*in which any of the elements are True.
## Functions[#](#functions)
### Array Functions[#](#array-functions)
int PyArray_AsCArray([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)**op, void *ptr,[npy_intp](dtype.html#c.npy_intp)*dims, int nd,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*typedescr)[#](#c.PyArray_AsCArray)
-
Sometimes it is useful to access a multidimensional array as a C-style multi-dimensional array so that algorithms can be implemented using C’s a[i][j][k] syntax. This routine returns a pointer,

*ptr*, that simulates this kind of C-style array, for 1-, 2-, and 3-d ndarrays.Parameters:
-
**op**– The address to any Python object. This Python object will be replaced with an equivalent well-behaved, C-style contiguous, ndarray of the given data type specified by the last two arguments. Be sure that stealing a reference in this way to the input object is justified.
**ptr**– The address to a (ctype* for 1-d, ctype** for 2-d or ctype*** for 3-d) variable where ctype is the equivalent C-type for the data type. On return,*ptr*will be addressable as a 1-d, 2-d, or 3-d array.
**dims**– An output array that contains the shape of the array object. This array gives boundaries on any looping that will take place.
**nd**– The dimensionality of the array (1, 2, or 3).
**typedescr**– Astructure indicating the desired data-type (including required byteorder). The call will steal a reference to the parameter.`PyArray_Descr`
Note

The simulation of a C-style array is not complete for 2-d and 3-d arrays. For example, the simulated arrays of pointers cannot be passed to subroutines expecting specific, statically-defined 2-d and 3-d arrays. To pass to functions requiring those kind of inputs, you must statically define the required array and copy data.

int PyArray_Free([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, void *ptr)[#](#c.PyArray_Free)
-
Must be called with the same objects and memory locations returned from

(…). This function cleans up memory that otherwise would get leaked.`PyArray_AsCArray`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Concatenate([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int axis)[#](#c.PyArray_Concatenate)
-
Join the sequence of objects in

*obj*together along*axis*into a single array. If the dimensions or types are not compatible an error is raised.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_InnerProduct([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj1,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj2)[#](#c.PyArray_InnerProduct)
-
Compute a product-sum over the last dimensions of

*obj1*and*obj2*. Neither array is conjugated.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_MatrixProduct([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj1,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_MatrixProduct)
-
Compute a product-sum over the last dimension of

*obj1*and the second-to-last dimension of*obj2*. For 2-d arrays this is a matrix-product. Neither array is conjugated.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_MatrixProduct2([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj1,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_MatrixProduct2)
-
New in version 1.6.

Same as PyArray_MatrixProduct, but store the result in

*out*. The output array must have the correct shape, type, and be C-contiguous, or an exception is raised.
[PyArrayObject](types-and-structures.html#c.PyArrayObject)*PyArray_EinsteinSum(char *subscripts,[npy_intp](dtype.html#c.npy_intp)nop,[PyArrayObject](types-and-structures.html#c.PyArrayObject)**op_in,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[NPY_ORDER](#c.NPY_ORDER)order,[NPY_CASTING](#c.NPY_CASTING)casting,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*out)[#](#c.PyArray_EinsteinSum)
-
New in version 1.6.

Applies the Einstein summation convention to the array operands provided, returning a new array or placing the result in

*out*. The string in*subscripts*is a comma separated list of index letters. The number of operands is in*nop*, and*op_in*is an array containing those operands. The data type of the output can be forced with*dtype*, the output order can be forced with*order*(is recommended), and when`NPY_KEEPORDER`
*dtype*is specified,*casting*indicates how permissive the data conversion should be.See the

function for more details.`einsum`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_CopyAndTranspose([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_CopyAndTranspose)
-
A specialized copy and transpose function that works only for 2-d arrays. The returned array is a transposed copy of

*op*.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Correlate([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op1,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op2, int mode)[#](#c.PyArray_Correlate)
-
Compute the 1-d correlation of the 1-d arrays

*op1*and*op2*. The correlation is computed at each output point by multiplying*op1*by a shifted version of*op2*and summing the result. As a result of the shift, needed values outside of the defined range of*op1*and*op2*are interpreted as zero. The mode determines how many shifts to return: 0 - return only shifts that did not need to assume zero- values; 1 - return an object that is the same size as*op1*, 2 - return all possible shifts (any overlap at all is accepted).Notes

This does not compute the usual correlation: if op2 is larger than op1, the arguments are swapped, and the conjugate is never taken for complex arrays. See PyArray_Correlate2 for the usual signal processing correlation.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Correlate2([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op1,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op2, int mode)[#](#c.PyArray_Correlate2)
-
Updated version of PyArray_Correlate, which uses the usual definition of correlation for 1d arrays. The correlation is computed at each output point by multiplying

*op1*by a shifted version of*op2*and summing the result. As a result of the shift, needed values outside of the defined range of*op1*and*op2*are interpreted as zero. The mode determines how many shifts to return: 0 - return only shifts that did not need to assume zero- values; 1 - return an object that is the same size as*op1*, 2 - return all possible shifts (any overlap at all is accepted).Notes

Compute z as follows:

z[k] = sum_n op1[n] * conj(op2[n+k])
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Where([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*condition,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*x,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*y)[#](#c.PyArray_Where)
-
If both

`x`
and`y`
are`NULL`
, then return(`PyArray_Nonzero`
*condition*). Otherwise, both*x*and*y*must be given and the object returned is shaped like*condition*and has elements of*x*and*y*where*condition*is respectively True or False.
### Other functions[#](#other-functions)
[npy_bool](dtype.html#c.npy_bool)PyArray_CheckStrides(int elsize, int nd,[npy_intp](dtype.html#c.npy_intp)numbytes,[npy_intp](dtype.html#c.npy_intp)const *dims,[npy_intp](dtype.html#c.npy_intp)const *newstrides)[#](#c.PyArray_CheckStrides)
-
Determine if

*newstrides*is a strides array consistent with the memory of an*nd*-dimensional array with shape`dims`
and element-size,*elsize*. The*newstrides*array is checked to see if jumping by the provided number of bytes in each direction will ever mean jumping more than*numbytes*which is the assumed size of the available memory segment. If*numbytes*is 0, then an equivalent*numbytes*is computed assuming*nd*,*dims*, and*elsize*refer to a single-segment array. Returnif`NPY_TRUE`
*newstrides*is acceptable, otherwise return.`NPY_FALSE`
int PyArray_MultiplyIntList(int const *seq, int n)[#](#c.PyArray_MultiplyIntList)
-
Both of these routines multiply an

*n*-length array,*seq*, of integers and return the result. No overflow checking is performed.
## Auxiliary Data With Object Semantics[#](#auxiliary-data-with-object-semantics)
New in version 1.7.0.

type NpyAuxData[#](#c.NpyAuxData)
-
When working with more complex dtypes which are composed of other dtypes,
such as the struct dtype, creating inner loops that manipulate the dtypes
requires carrying along additional data. NumPy supports this idea
through a struct [ NpyAuxData](#c.NpyAuxData), mandating a few conventions so that
it is possible to do this.

Defining an [ NpyAuxData](#c.NpyAuxData) is similar to defining a class in C++,
but the object semantics have to be tracked manually since the API is in C.
Here’s an example for a function which doubles up an element using
an element copier function as a primitive.

```
typedef struct {
NpyAuxData base;
ElementCopier_Func *func;
NpyAuxData *funcdata;
} eldoubler_aux_data;
void free_element_doubler_aux_data(NpyAuxData *data)
{
eldoubler_aux_data *d = (eldoubler_aux_data *)data;
/* Free the memory owned by this auxdata */
NPY_AUXDATA_FREE(d->funcdata);
PyArray_free(d);
}
NpyAuxData *clone_element_doubler_aux_data(NpyAuxData *data)
{
eldoubler_aux_data *ret = PyArray_malloc(sizeof(eldoubler_aux_data));
if (ret == NULL) {
return NULL;
}
/* Raw copy of all data */
memcpy(ret, data, sizeof(eldoubler_aux_data));
/* Fix up the owned auxdata so we have our own copy */
ret->funcdata = NPY_AUXDATA_CLONE(ret->funcdata);
if (ret->funcdata == NULL) {
PyArray_free(ret);
return NULL;
}
return (NpyAuxData *)ret;
}
NpyAuxData *create_element_doubler_aux_data(
ElementCopier_Func *func,
NpyAuxData *funcdata)
{
eldoubler_aux_data *ret = PyArray_malloc(sizeof(eldoubler_aux_data));
if (ret == NULL) {
PyErr_NoMemory();
return NULL;
}
memset(&ret, 0, sizeof(eldoubler_aux_data));
ret->base->free = &free_element_doubler_aux_data;
ret->base->clone = &clone_element_doubler_aux_data;
ret->func = func;
ret->funcdata = funcdata;
return (NpyAuxData *)ret;
}
```
type NpyAuxData_FreeFunc[#](#c.NpyAuxData_FreeFunc)
-
The function pointer type for NpyAuxData free functions.

type NpyAuxData_CloneFunc[#](#c.NpyAuxData_CloneFunc)
-
The function pointer type for NpyAuxData clone functions. These functions should never set the Python exception on error, because they may be called from a multi-threaded context.

void NPY_AUXDATA_FREE([NpyAuxData](#c.NpyAuxData)*auxdata)[#](#c.NPY_AUXDATA_FREE)
-
A macro which calls the auxdata’s free function appropriately, does nothing if auxdata is NULL.

[NpyAuxData](#c.NpyAuxData)*NPY_AUXDATA_CLONE([NpyAuxData](#c.NpyAuxData)*auxdata)[#](#c.NPY_AUXDATA_CLONE)
-
A macro which calls the auxdata’s clone function appropriately, returning a deep copy of the auxiliary data.

## Array Iterators[#](#array-iterators)
As of NumPy 1.6.0, these array iterators are superseded by
the new array iterator, [ NpyIter](iterator.html#c.NpyIter).

An array iterator is a simple way to access the elements of an
N-dimensional array quickly and efficiently, as seen in [the
example](iterator.html#iteration-example) which provides more description
of this useful approach to looping over an array from C.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_IterNew([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr)[#](#c.PyArray_IterNew)
-
Return an array iterator object from the array,

*arr*. This is equivalent to*arr*.**flat**. The array iterator object makes it easy to loop over an N-dimensional non-contiguous array in C-style contiguous fashion.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_IterAllButAxis([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr, int *axis)[#](#c.PyArray_IterAllButAxis)
-
Return an array iterator that will iterate over all axes but the one provided in

**axis*. The returned iterator cannot be used with. This iterator could be used to write something similar to what ufuncs do wherein the loop over the largest axis is done by a separate sub-routine. If`PyArray_ITER_GOTO1D`
**axis*is negative then**axis*will be set to the axis having the smallest stride and that axis will be used.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_BroadcastToShape([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*arr,[npy_intp](dtype.html#c.npy_intp)const *dimensions, int nd)[#](#c.PyArray_BroadcastToShape)
-
Return an array iterator that is broadcast to iterate as an array of the shape provided by

*dimensions*and*nd*.
int PyArrayIter_Check([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArrayIter_Check)
-
Evaluates true if

*op*is an array iterator (or instance of a subclass of the array iterator type).
void PyArray_ITER_NEXT([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*iterator)[#](#c.PyArray_ITER_NEXT)
-
Incremement the index and the dataptr members of the

*iterator*to point to the next element of the array. If the array is not (C-style) contiguous, also increment the N-dimensional coordinates array.
void PyArray_ITER_GOTO([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*iterator,[npy_intp](dtype.html#c.npy_intp)*destination)[#](#c.PyArray_ITER_GOTO)
-
Set the

*iterator*index, dataptr, and coordinates members to the location in the array indicated by the N-dimensional c-array,*destination*, which must have size at least*iterator*->nd_m1+1.
void PyArray_ITER_GOTO1D([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*iterator,[npy_intp](dtype.html#c.npy_intp)index)[#](#c.PyArray_ITER_GOTO1D)
-
Set the

*iterator*index and dataptr to the location in the array indicated by the integer*index*which points to an element in the C-styled flattened array.
## Broadcasting (multi-iterators)[#](#broadcasting-multi-iterators)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_MultiIterNew(int num, ...)[#](#c.PyArray_MultiIterNew)
-
A simplified interface to broadcasting. This function takes the number of arrays to broadcast and then

*num*extra () arguments. These arguments are converted to arrays and iterators are created.`PyObject *`
is then called on the resulting multi-iterator object. The resulting, broadcasted mult-iterator object is then returned. A broadcasted operation can then be performed using a single loop and using`PyArray_Broadcast`
(..)`PyArray_MultiIter_NEXT`
void PyArray_MultiIter_RESET([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*multi)[#](#c.PyArray_MultiIter_RESET)
-
Reset all the iterators to the beginning in a multi-iterator object,

*multi*.
void PyArray_MultiIter_NEXT([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*multi)[#](#c.PyArray_MultiIter_NEXT)
-
Advance each iterator in a multi-iterator object,

*multi*, to its next (broadcasted) element.
void *PyArray_MultiIter_DATA([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*multi, int i)[#](#c.PyArray_MultiIter_DATA)
-
Return the data-pointer of the

*i*\(^{\textrm{th}}\) iterator in a multi-iterator object.
void PyArray_MultiIter_NEXTi([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*multi, int i)[#](#c.PyArray_MultiIter_NEXTi)
-
Advance the pointer of only the

*i*\(^{\textrm{th}}\) iterator.
void PyArray_MultiIter_GOTO([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*multi,[npy_intp](dtype.html#c.npy_intp)*destination)[#](#c.PyArray_MultiIter_GOTO)
-
Advance each iterator in a multi-iterator object,

*multi*, to the given \(N\) -dimensional*destination*where \(N\) is the number of dimensions in the broadcasted array.
void PyArray_MultiIter_GOTO1D([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*multi,[npy_intp](dtype.html#c.npy_intp)index)[#](#c.PyArray_MultiIter_GOTO1D)
-
Advance each iterator in a multi-iterator object,

*multi*, to the corresponding location of the*index*into the flattened broadcasted array.
int PyArray_MultiIter_NOTDONE([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*multi)[#](#c.PyArray_MultiIter_NOTDONE)
-
Evaluates TRUE as long as the multi-iterator has not looped through all of the elements (of the broadcasted result), otherwise it evaluates FALSE.

int PyArray_Broadcast([PyArrayMultiIterObject](types-and-structures.html#c.PyArrayMultiIterObject)*mit)[#](#c.PyArray_Broadcast)
-
This function encapsulates the broadcasting rules. The

*mit*container should already contain iterators for all the arrays that need to be broadcast. On return, these iterators will be adjusted so that iteration over each simultaneously will accomplish the broadcasting. A negative number is returned if an error occurs.
int PyArray_RemoveSmallest([PyArrayMultiIterObject](types-and-structures.html#c.PyArrayMultiIterObject)*mit)[#](#c.PyArray_RemoveSmallest)
-
This function takes a multi-iterator object that has been previously “broadcasted,” finds the dimension with the smallest “sum of strides” in the broadcasted result and adapts all the iterators so as not to iterate over that dimension (by effectively making them of length-1 in that dimension). The corresponding dimension is returned unless

*mit*->nd is 0, then -1 is returned. This function is useful for constructing ufunc-like routines that broadcast their inputs correctly and then call a strided 1-d version of the routine as the inner-loop. This 1-d version is usually optimized for speed and for this reason the loop should be performed over the axis that won’t require large stride jumps.
## Neighborhood iterator[#](#neighborhood-iterator)
New in version 1.4.0.

Neighborhood iterators are subclasses of the iterator object, and can be used to iter over a neighborhood of a point. For example, you may want to iterate over every voxel of a 3d image, and for every such voxel, iterate over an hypercube. Neighborhood iterator automatically handle boundaries, thus making this kind of code much easier to write than manual boundaries handling, at the cost of a slight overhead.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_NeighborhoodIterNew([PyArrayIterObject](types-and-structures.html#c.PyArrayIterObject)*iter,[npy_intp](dtype.html#c.npy_intp)bounds, int mode,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*fill_value)[#](#c.PyArray_NeighborhoodIterNew)
-
This function creates a new neighborhood iterator from an existing iterator. The neighborhood will be computed relatively to the position currently pointed by

*iter*, the bounds define the shape of the neighborhood iterator, and the mode argument the boundaries handling mode.The

*bounds*argument is expected to be a (2 * iter->ao->nd) arrays, such as the range bound[2*i]->bounds[2*i+1] defines the range where to walk for dimension i (both bounds are included in the walked coordinates). The bounds should be ordered for each dimension (bounds[2*i] <= bounds[2*i+1]).The mode should be one of:

NPY_NEIGHBORHOOD_ITER_ZERO_PADDING[#](#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_ZERO_PADDING)
-
Zero padding. Outside bounds values will be 0.

NPY_NEIGHBORHOOD_ITER_ONE_PADDING[#](#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_ONE_PADDING)
-
One padding, Outside bounds values will be 1.

NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING[#](#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING)
-
Constant padding. Outside bounds values will be the same as the first item in fill_value.

NPY_NEIGHBORHOOD_ITER_MIRROR_PADDING[#](#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_MIRROR_PADDING)
-
Mirror padding. Outside bounds values will be as if the array items were mirrored. For example, for the array [1, 2, 3, 4], x[-2] will be 2, x[-2] will be 1, x[4] will be 4, x[5] will be 1, etc…

NPY_NEIGHBORHOOD_ITER_CIRCULAR_PADDING[#](#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_CIRCULAR_PADDING)
-
Circular padding. Outside bounds values will be as if the array was repeated. For example, for the array [1, 2, 3, 4], x[-2] will be 3, x[-2] will be 4, x[4] will be 1, x[5] will be 2, etc…

If the mode is constant filling (

*NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING*), fill_value should point to an array object which holds the filling value (the first item will be the filling value if the array contains more than one item). For other cases, fill_value may be NULL.The iterator holds a reference to iter

Return NULL on failure (in which case the reference count of iter is not changed)

iter itself can be a Neighborhood iterator: this can be useful for .e.g automatic boundaries handling

the object returned by this function should be safe to use as a normal iterator

If the position of iter is changed, any subsequent call to PyArrayNeighborhoodIter_Next is undefined behavior, and PyArrayNeighborhoodIter_Reset must be called.

If the position of iter is not the beginning of the data and the underlying data for iter is contiguous, the iterator will point to the start of the data instead of position pointed by iter. To avoid this situation, iter should be moved to the required position only after the creation of iterator, and PyArrayNeighborhoodIter_Reset must be called.

PyArrayIterObject *iter; PyArrayNeighborhoodIterObject *neigh_iter; iter = PyArray_IterNew(x); /*For a 3x3 kernel */ bounds = {-1, 1, -1, 1}; neigh_iter = (PyArrayNeighborhoodIterObject*)PyArray_NeighborhoodIterNew( iter, bounds, NPY_NEIGHBORHOOD_ITER_ZERO_PADDING, NULL); for(i = 0; i < iter->size; ++i) { for (j = 0; j < neigh_iter->size; ++j) { /* Walk around the item currently pointed by iter->dataptr */ PyArrayNeighborhoodIter_Next(neigh_iter); } /* Move to the next point of iter */ PyArrayIter_Next(iter); PyArrayNeighborhoodIter_Reset(neigh_iter); }
NPY_NEIGHBORHOOD_ITER_ZERO_PADDING
-
int PyArrayNeighborhoodIter_Reset([PyArrayNeighborhoodIterObject](types-and-structures.html#c.PyArrayNeighborhoodIterObject)*iter)[#](#c.PyArrayNeighborhoodIter_Reset)
-
Reset the iterator position to the first point of the neighborhood. This should be called whenever the iter argument given at PyArray_NeighborhoodIterObject is changed (see example)

int PyArrayNeighborhoodIter_Next([PyArrayNeighborhoodIterObject](types-and-structures.html#c.PyArrayNeighborhoodIterObject)*iter)[#](#c.PyArrayNeighborhoodIter_Next)
-
After this call, iter->dataptr points to the next point of the neighborhood. Calling this function after every point of the neighborhood has been visited is undefined.

## Array mapping[#](#array-mapping)
Array mapping is the machinery behind advanced indexing.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_MapIterArray([PyArrayObject](types-and-structures.html#c.PyArrayObject)*a,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*index)[#](#c.PyArray_MapIterArray)
-
Use advanced indexing to iterate an array.

void PyArray_MapIterSwapAxes([PyArrayMapIterObject](types-and-structures.html#c.PyArrayMapIterObject)*mit,[PyArrayObject](types-and-structures.html#c.PyArrayObject)**ret, int getmap)[#](#c.PyArray_MapIterSwapAxes)
-
Swap the axes to or from their inserted form.

`MapIter`
always puts the advanced (array) indices first in the iteration. But if they are consecutive, it will insert/transpose them back before returning. This is stored as`mit->consec != 0`
(the place where they are inserted). For assignments, the opposite happens: the values to be assigned are transposed (`getmap=1`
instead of`getmap=0`
).`getmap=0`
and`getmap=1`
undo the other operation.
void PyArray_MapIterNext([PyArrayMapIterObject](types-and-structures.html#c.PyArrayMapIterObject)*mit)[#](#c.PyArray_MapIterNext)
-
This function needs to update the state of the map iterator and point

`mit->dataptr`
to the memory-location of the next object.Note that this function never handles an extra operand but provides compatibility for an old (exposed) API.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_MapIterArrayCopyIfOverlap([PyArrayObject](types-and-structures.html#c.PyArrayObject)*a,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*index, int copy_if_overlap,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*extra_op)[#](#c.PyArray_MapIterArrayCopyIfOverlap)
-
Similar to

but with an additional`PyArray_MapIterArray`
`copy_if_overlap`
argument. If`copy_if_overlap != 0`
, checks if`a`
has memory overlap with any of the arrays in`index`
and with`extra_op`
, and make copies as appropriate to avoid problems if the input is modified during the iteration.`iter->array`
may contain a copied array (WRITEBACKIFCOPY set).
## Array Scalars[#](#array-scalars)
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Return([PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_Return)
-
This function steals a reference to

*arr*.This function checks to see if

*arr*is a 0-dimensional array and, if so, returns the appropriate array scalar. It should be used whenever 0-dimensional arrays could be returned to Python.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_Scalar(void *data,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*base)[#](#c.PyArray_Scalar)
-
Return an array scalar object of the given

*dtype*by**copying**from memory pointed to by*data*.*base*is expected to be the array object that is the owner of the data.*base*is required if*dtype*is a`void`
scalar, or if the`NPY_USE_GETITEM`
flag is set and it is known that the`getitem`
method uses the`arr`
argument without checking if it is`NULL`
. Otherwise*base*may be`NULL`
.If the data is not in native byte order (as indicated by

`dtype->byteorder`
) then this function will byteswap the data, because array scalars are always in correct machine-byte order.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_ToScalar(void *data,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*arr)[#](#c.PyArray_ToScalar)
-
Return an array scalar object of the type and itemsize indicated by the array object

*arr*copied from the memory pointed to by*data*and swapping if the data in*arr*is not in machine byte-order.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FromScalar([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*scalar,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*outcode)[#](#c.PyArray_FromScalar)
-
Return a 0-dimensional array of type determined by

*outcode*from*scalar*which should be an array-scalar object. If*outcode*is NULL, then the type is determined from*scalar*.
void PyArray_ScalarAsCtype([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*scalar, void *ctypeptr)[#](#c.PyArray_ScalarAsCtype)
-
Return in

*ctypeptr*a pointer to the actual value in an array scalar. There is no error checking so*scalar*must be an array-scalar object, and ctypeptr must have enough space to hold the correct type. For flexible-sized types, a pointer to the data is copied into the memory of*ctypeptr*, for all other types, the actual data is copied into the address pointed to by*ctypeptr*.
void PyArray_CastScalarToCtype([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*scalar, void *ctypeptr,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*outcode)[#](#c.PyArray_CastScalarToCtype)
-
Return the data (cast to the data type indicated by

*outcode*) from the array-scalar,*scalar*, into the memory pointed to by*ctypeptr*(which must be large enough to handle the incoming memory).
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_TypeObjectFromType(int type)[#](#c.PyArray_TypeObjectFromType)
-
Returns a scalar type-object from a type-number,

*type*. Equivalent to(`PyArray_DescrFromType`
*type*)->typeobj except for reference counting and error-checking. Returns a new reference to the typeobject on success or`NULL`
on failure.
[NPY_SCALARKIND](#c.NPY_SCALARKIND)PyArray_ScalarKind(int typenum,[PyArrayObject](types-and-structures.html#c.PyArrayObject)**arr)[#](#c.PyArray_ScalarKind)
-
See the function

for an alternative mechanism introduced in NumPy 1.6.0.`PyArray_MinScalarType`
Return the kind of scalar represented by

*typenum*and the array in**arr*(if*arr*is not`NULL`
). The array is assumed to be rank-0 and only used if*typenum*represents a signed integer. If*arr*is not`NULL`
and the first element is negative thenis returned, otherwise`NPY_INTNEG_SCALAR`
is returned. The possible return values are the enumerated values in`NPY_INTPOS_SCALAR`
.`NPY_SCALARKIND`
int PyArray_CanCoerceScalar(char thistype, char neededtype, [NPY_SCALARKIND](#c.NPY_SCALARKIND)scalar)[#](#c.PyArray_CanCoerceScalar)
-
See the function

for details of NumPy type promotion, updated in NumPy 1.6.0.`PyArray_ResultType`
Implements the rules for scalar coercion. Scalars are only silently coerced from thistype to neededtype if this function returns nonzero. If scalar is

, then this function is equivalent to`NPY_NOSCALAR`
. The rule is that scalars of the same KIND can be coerced into arrays of the same KIND. This rule means that high-precision scalars will never cause low-precision arrays of the same KIND to be upcast.`PyArray_CanCastSafely`
## Data-type descriptors[#](#data-type-descriptors)
Warning

Data-type objects must be reference counted so be aware of the
action on the data-type reference of different C-API calls. The
standard rule is that when a data-type object is returned it is a
new reference. Functions that take [PyArray_Descr](types-and-structures.html#c.PyArray_Descr)* objects and
return arrays steal references to the data-type their inputs
unless otherwise noted. Therefore, you must own a reference to any
data-type object used as input to such a function.

int PyArray_DescrCheck([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj)[#](#c.PyArray_DescrCheck)
-
Evaluates as true if

*obj*is a data-type object ([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)* ).
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DescrNew([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*obj)[#](#c.PyArray_DescrNew)
-
Return a new data-type object copied from

*obj*(the fields reference is just updated so that the new object points to the same fields dictionary if any).
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DescrNewFromType(int typenum)[#](#c.PyArray_DescrNewFromType)
-
Create a new data-type object from the built-in (or user-registered) data-type indicated by

*typenum*. All builtin types should not have any of their fields changed. This creates a new copy of thestructure so that you can fill it in as appropriate. This function is especially needed for flexible data-types which need to have a new elsize member in order to be meaningful in array construction.`PyArray_Descr`
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DescrNewByteorder([PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*obj, char newendian)[#](#c.PyArray_DescrNewByteorder)
-
Create a new data-type object with the byteorder set according to

*newendian*. All referenced data-type objects (in subdescr and fields members of the data-type object) are also changed (recursively).The value of

*newendian*is one of these macros:
NPY_IGNORE[#](#c.NPY_IGNORE)
-
NPY_SWAP[#](#c.NPY_SWAP)
-
NPY_NATIVE[#](#c.NPY_NATIVE)
-
NPY_LITTLE[#](#c.NPY_LITTLE)
-
NPY_BIG[#](#c.NPY_BIG)
-
If a byteorder of

is encountered it is left alone. If newendian is`NPY_IGNORE`
, then all byte-orders are swapped. Other valid newendian values are`NPY_SWAP`
,`NPY_NATIVE`
, and`NPY_LITTLE`
which all cause the returned data-typed descriptor (and all it’s referenced data-type descriptors) to have the corresponding byte- order.`NPY_BIG`
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DescrFromObject([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*mintype)[#](#c.PyArray_DescrFromObject)
-
Determine an appropriate data-type object from the object

*op*(which should be a “nested” sequence object) and the minimum data-type descriptor mintype (which can be`NULL`
). Similar in behavior to array(*op*).dtype. Don’t confuse this function with. This function essentially looks at all the objects in the (nested) sequence and determines the data-type from the elements it finds.`PyArray_DescrConverter`
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DescrFromScalar([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*scalar)[#](#c.PyArray_DescrFromScalar)
-
Return a data-type object from an array-scalar object. No checking is done to be sure that

*scalar*is an array scalar. If no suitable data-type can be determined, then a data-type ofis returned by default.`NPY_OBJECT`
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*PyArray_DescrFromType(int typenum)[#](#c.PyArray_DescrFromType)
-
Returns a data-type object corresponding to

*typenum*. The*typenum*can be one of the enumerated types, a character code for one of the enumerated types, or a user-defined type. If you want to use a flexible size array, then you need to`flexible typenum`
and set the results`elsize`
parameter to the desired size. The typenum is one of the.`NPY_TYPES`
int PyArray_DescrConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**dtype)[#](#c.PyArray_DescrConverter)
-
Convert any compatible Python object,

*obj*, to a data-type object in*dtype*. A large number of Python objects can be converted to data-type objects. See[Data type objects (dtype)](../arrays.dtypes.html#arrays-dtypes)for a complete description. This version of the converter converts None objects to adata-type object. This function can be used with the “O&” character code in`NPY_DEFAULT_TYPE`
processing.`PyArg_ParseTuple`
int PyArray_DescrConverter2([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**dtype)[#](#c.PyArray_DescrConverter2)
-
Convert any compatible Python object,

*obj*, to a data-type object in*dtype*. This version of the converter converts None objects so that the returned data-type is`NULL`
. This function can also be used with the “O&” character in PyArg_ParseTuple processing.
int Pyarray_DescrAlignConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**dtype)[#](#c.Pyarray_DescrAlignConverter)
-
Like

except it aligns C-struct-like objects on word-boundaries as the compiler would.`PyArray_DescrConverter`
int Pyarray_DescrAlignConverter2([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**dtype)[#](#c.Pyarray_DescrAlignConverter2)
-
Like

except it aligns C-struct-like objects on word-boundaries as the compiler would.`PyArray_DescrConverter2`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_FieldNames([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*dict)[#](#c.PyArray_FieldNames)
-
Take the fields dictionary,

*dict*, such as the one attached to a data-type object and construct an ordered-list of field names such as is stored in the names field of theobject.`PyArray_Descr`
## Conversion Utilities[#](#conversion-utilities)
### For use with `PyArg_ParseTuple`
[#](#for-use-with-pyarg-parsetuple)
`PyArg_ParseTuple`
All of these functions can be used in [ PyArg_ParseTuple](https://docs.python.org/3/c-api/arg.html#c.PyArg_ParseTuple) (…) with
the “O&” format specifier to automatically convert any Python object
to the required C-object. All of these functions return

[if successful and](#c.NPY_SUCCEED)
`NPY_SUCCEED`
[if not. The first argument to all of these function is a Python object. The second argument is the](#c.NPY_FAIL)
`NPY_FAIL`
**address**of the C-type to convert the Python object to.
Warning

Be sure to understand what steps you should take to manage the memory when using these conversion functions. These functions can require freeing memory, and/or altering the reference counts of specific objects based on your use.

int PyArray_Converter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)**address)[#](#c.PyArray_Converter)
-
Convert any Python object to a

. If`PyArrayObject`
(`PyArray_Check`
*obj*) is TRUE then its reference count is incremented and a reference placed in*address*. If*obj*is not an array, then convert it to an array using. No matter what is returned, you must DECREF the object returned by this routine in`PyArray_FromAny`
*address*when you are done with it.
int PyArray_OutputConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArrayObject](types-and-structures.html#c.PyArrayObject)**address)[#](#c.PyArray_OutputConverter)
-
This is a default converter for output arrays given to functions. If

*obj*isor`Py_None`
`NULL`
, then**address*will be`NULL`
but the call will succeed. If(`PyArray_Check`
*obj*) is TRUE then it is returned in**address*without incrementing its reference count.
int PyArray_IntpConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArray_Dims](types-and-structures.html#c.PyArray_Dims)*seq)[#](#c.PyArray_IntpConverter)
-
Convert any Python sequence,

*obj*, smaller thanto a C-array of`NPY_MAXDIMS`
. The Python object could also be a single number. The`npy_intp`
*seq*variable is a pointer to a structure with members ptr and len. On successful return,*seq*->ptr contains a pointer to memory that must be freed, by calling, to avoid a memory leak. The restriction on memory size allows this converter to be conveniently used for sequences intended to be interpreted as array shapes.`PyDimMem_FREE`
int PyArray_BufferConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[PyArray_Chunk](types-and-structures.html#c.PyArray_Chunk)*buf)[#](#c.PyArray_BufferConverter)
-
Convert any Python object,

*obj*, with a (single-segment) buffer interface to a variable with members that detail the object’s use of its chunk of memory. The*buf*variable is a pointer to a structure with base, ptr, len, and flags members. Thestructure is binary compatible with the Python’s buffer object (through its len member on 32-bit platforms and its ptr member on 64-bit platforms). On return, the base member is set to`PyArray_Chunk`
*obj*(or its base if*obj*is already a buffer object pointing to another object). If you need to hold on to the memory be sure to INCREF the base member. The chunk of memory is pointed to by*buf*->ptr member and has length*buf*->len. The flags member of*buf*iswith the`NPY_ARRAY_ALIGNED`
flag set if`NPY_ARRAY_WRITEABLE`
*obj*has a writeable buffer interface.
int PyArray_AxisConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, int *axis)[#](#c.PyArray_AxisConverter)
-
Convert a Python object,

*obj*, representing an axis argument to the proper value for passing to the functions that take an integer axis. Specifically, if*obj*is None,*axis*is set towhich is interpreted correctly by the C-API functions that take axis arguments.`NPY_MAXDIMS`
int PyArray_BoolConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[npy_bool](dtype.html#c.npy_bool)*value)[#](#c.PyArray_BoolConverter)
-
Convert any Python object,

*obj*, toor`NPY_TRUE`
, and place the result in`NPY_FALSE`
*value*.
int PyArray_ByteorderConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, char *endian)[#](#c.PyArray_ByteorderConverter)
-
Convert Python strings into the corresponding byte-order character: ‘>’, ‘<’, ‘s’, ‘=’, or ‘|’.

int PyArray_SortkindConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[NPY_SORTKIND](#c.NPY_SORTKIND)*sort)[#](#c.PyArray_SortkindConverter)
-
Convert Python strings into one of

(starts with ‘q’ or ‘Q’),`NPY_QUICKSORT`
(starts with ‘h’ or ‘H’),`NPY_HEAPSORT`
(starts with ‘m’ or ‘M’) or`NPY_MERGESORT`
(starts with ‘t’ or ‘T’).`NPY_STABLESORT`
and`NPY_MERGESORT`
are aliased to each other for backwards compatibility and may refer to one of several stable sorting algorithms depending on the data type.`NPY_STABLESORT`
int PyArray_SearchsideConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[NPY_SEARCHSIDE](#c.NPY_SEARCHSIDE)*side)[#](#c.PyArray_SearchsideConverter)
-
Convert Python strings into one of

(starts with ‘l’ or ‘L’), or`NPY_SEARCHLEFT`
(starts with ‘r’ or ‘R’).`NPY_SEARCHRIGHT`
int PyArray_OrderConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[NPY_ORDER](#c.NPY_ORDER)*order)[#](#c.PyArray_OrderConverter)
-
Convert the Python strings ‘C’, ‘F’, ‘A’, and ‘K’ into the

enumeration`NPY_ORDER`
,`NPY_CORDER`
,`NPY_FORTRANORDER`
, and`NPY_ANYORDER`
.`NPY_KEEPORDER`
int PyArray_CastingConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj,[NPY_CASTING](#c.NPY_CASTING)*casting)[#](#c.PyArray_CastingConverter)
-
Convert the Python strings ‘no’, ‘equiv’, ‘safe’, ‘same_kind’, and ‘unsafe’ into the

enumeration`NPY_CASTING`
,`NPY_NO_CASTING`
,`NPY_EQUIV_CASTING`
,`NPY_SAFE_CASTING`
, and`NPY_SAME_KIND_CASTING`
.`NPY_UNSAFE_CASTING`
int PyArray_ClipmodeConverter([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*object,[NPY_CLIPMODE](#c.NPY_CLIPMODE)*val)[#](#c.PyArray_ClipmodeConverter)
-
Convert the Python strings ‘clip’, ‘wrap’, and ‘raise’ into the

enumeration`NPY_CLIPMODE`
,`NPY_CLIP`
, and`NPY_WRAP`
.`NPY_RAISE`
int PyArray_ConvertClipmodeSequence([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*object,[NPY_CLIPMODE](#c.NPY_CLIPMODE)*modes, int n)[#](#c.PyArray_ConvertClipmodeSequence)
-
Converts either a sequence of clipmodes or a single clipmode into a C array of

values. The number of clipmodes`NPY_CLIPMODE`
*n*must be known before calling this function. This function is provided to help functions allow a different clipmode for each dimension.
### Other conversions[#](#other-conversions)
int PyArray_PyIntAsInt([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_PyIntAsInt)
-
Convert all kinds of Python objects (including arrays and array scalars) to a standard integer. On error, -1 is returned and an exception set. You may find useful the macro:

`#define error_converting(x) (((x) == -1) && PyErr_Occurred())`
[npy_intp](dtype.html#c.npy_intp)PyArray_PyIntAsIntp([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op)[#](#c.PyArray_PyIntAsIntp)
-
Convert all kinds of Python objects (including arrays and array scalars) to a (platform-pointer-sized) integer. On error, -1 is returned and an exception set.

int PyArray_IntpFromSequence([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*seq,[npy_intp](dtype.html#c.npy_intp)*vals, int maxvals)[#](#c.PyArray_IntpFromSequence)
-
Convert any Python sequence (or single Python number) passed in as

*seq*to (up to)*maxvals*pointer-sized integers and place them in the*vals*array. The sequence can be smaller then*maxvals*as the number of converted objects is returned.
int PyArray_TypestrConvert(int itemsize, int gentype)[#](#c.PyArray_TypestrConvert)
-
Convert typestring characters (with

*itemsize*) to basic enumerated data types. The typestring character corresponding to signed and unsigned integers, floating point numbers, and complex-floating point numbers are recognized and converted. Other values of gentype are returned. This function can be used to convert, for example, the string ‘f4’ to.`NPY_FLOAT32`
## Miscellaneous[#](#miscellaneous)
### Importing the API[#](#importing-the-api)
In order to make use of the C-API from another extension module, the
[ import_array](#c.import_array) function must be called. If the extension module is
self-contained in a single .c file, then that is all that needs to be
done. If, however, the extension module involves multiple files where
the C-API is needed then some additional steps must be taken.

void import_array(void)[#](#c.import_array)
-
This function must be called in the initialization section of a module that will make use of the C-API. It imports the module where the function-pointer table is stored and points the correct variable to it.

PY_ARRAY_UNIQUE_SYMBOL[#](#c.PY_ARRAY_UNIQUE_SYMBOL)
-
NO_IMPORT_ARRAY[#](#c.NO_IMPORT_ARRAY)
-
Using these #defines you can use the C-API in multiple files for a single extension module. In each file you must define

to some name that will hold the C-API (`PY_ARRAY_UNIQUE_SYMBOL`
*e.g.*myextension_ARRAY_API). This must be done**before**including the numpy/arrayobject.h file. In the module initialization routine you call. In addition, in the files that do not have the module initialization sub_routine define`import_array`
prior to including numpy/arrayobject.h.`NO_IMPORT_ARRAY`
Suppose I have two files coolmodule.c and coolhelper.c which need to be compiled and linked into a single extension module. Suppose coolmodule.c contains the required initcool module initialization function (with the import_array() function called). Then, coolmodule.c would have at the top:

#define PY_ARRAY_UNIQUE_SYMBOL cool_ARRAY_API #include numpy/arrayobject.h
On the other hand, coolhelper.c would contain at the top:

#define NO_IMPORT_ARRAY #define PY_ARRAY_UNIQUE_SYMBOL cool_ARRAY_API #include numpy/arrayobject.h
You can also put the common two last lines into an extension-local header file as long as you make sure that NO_IMPORT_ARRAY is #defined before #including that file.

Internally, these #defines work as follows:

If neither is defined, the C-API is declared to be

`static void**`
, so it is only visible within the compilation unit that #includes numpy/arrayobject.h.
If

is #defined, but`PY_ARRAY_UNIQUE_SYMBOL`
is not, the C-API is declared to be`NO_IMPORT_ARRAY`
`void**`
, so that it will also be visible to other compilation units.
If

is #defined, regardless of whether`NO_IMPORT_ARRAY`
is, the C-API is declared to be`PY_ARRAY_UNIQUE_SYMBOL`
`extern void**`
, so it is expected to be defined in another compilation unit.
Whenever

is #defined, it also changes the name of the variable holding the C-API, which defaults to`PY_ARRAY_UNIQUE_SYMBOL`
`PyArray_API`
, to whatever the macro is #defined to.
### Checking the API Version[#](#checking-the-api-version)
Because python extensions are not used in the same way as usual libraries on
most platforms, some errors cannot be automatically detected at build time or
even runtime. For example, if you build an extension using a function available
only for numpy >= 1.3.0, and you import the extension later with numpy 1.2, you
will not get an import error (but almost certainly a segmentation fault when
calling the function). That’s why several functions are provided to check for
numpy versions. The macros [ NPY_VERSION](#c.NPY_VERSION) and

[corresponds to the numpy version used to build the extension, whereas the versions returned by the functions](#c.NPY_FEATURE_VERSION)
`NPY_FEATURE_VERSION`
[and](#c.PyArray_GetNDArrayCVersion)
`PyArray_GetNDArrayCVersion`
[corresponds to the runtime numpy’s version.](#c.PyArray_GetNDArrayCFeatureVersion)
`PyArray_GetNDArrayCFeatureVersion`
The rules for ABI and API compatibilities can be summarized as follows:

-
Whenever

[!=]`NPY_VERSION`
`PyArray_GetNDArrayCVersion()`
, the extension has to be recompiled (ABI incompatibility).
-
[==]`NPY_VERSION`
`PyArray_GetNDArrayCVersion()`
and[<=]`NPY_FEATURE_VERSION`
`PyArray_GetNDArrayCFeatureVersion()`
means backward compatible changes.
ABI incompatibility is automatically detected in every numpy’s version. API
incompatibility detection was added in numpy 1.4.0. If you want to supported
many different numpy versions with one extension binary, you have to build your
extension with the lowest [ NPY_FEATURE_VERSION](#c.NPY_FEATURE_VERSION) as possible.

NPY_VERSION[#](#c.NPY_VERSION)
-
The current version of the ndarray object (check to see if this variable is defined to guarantee the

`numpy/arrayobject.h`
header is being used).
NPY_FEATURE_VERSION[#](#c.NPY_FEATURE_VERSION)
-
The current version of the C-API.

unsigned int PyArray_GetNDArrayCVersion(void)[#](#c.PyArray_GetNDArrayCVersion)
-
This just returns the value

.`NPY_VERSION`
changes whenever a backward incompatible change at the ABI level. Because it is in the C-API, however, comparing the output of this function from the value defined in the current header gives a way to test if the C-API has changed thus requiring a re-compilation of extension modules that use the C-API. This is automatically checked in the function`NPY_VERSION`
.`import_array`
unsigned int PyArray_GetNDArrayCFeatureVersion(void)[#](#c.PyArray_GetNDArrayCFeatureVersion)
-
New in version 1.4.0.

This just returns the value

.`NPY_FEATURE_VERSION`
changes whenever the API changes (e.g. a function is added). A changed value does not always require a recompile.`NPY_FEATURE_VERSION`
### Internal Flexibility[#](#internal-flexibility)
int PyArray_SetNumericOps([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*dict)[#](#c.PyArray_SetNumericOps)
-
NumPy stores an internal table of Python callable objects that are used to implement arithmetic operations for arrays as well as certain array calculation methods. This function allows the user to replace any or all of these Python objects with their own versions. The keys of the dictionary,

*dict*, are the named functions to replace and the paired value is the Python callable object to use. Care should be taken that the function used to replace an internal array operation does not itself call back to that internal array operation (unless you have designed the function to handle that), or an unchecked infinite recursion can result (possibly causing program crash). The key names that represent operations that can be replaced are:**add**,**subtract**,**multiply**,**divide**,**remainder**,**power**,**square**,**reciprocal**,**ones_like**,**sqrt**,**negative**,**positive**,**absolute**,**invert**,**left_shift**,**right_shift**,**bitwise_and**,**bitwise_xor**,**bitwise_or**,**less**,**less_equal**,**equal**,**not_equal**,**greater**,**greater_equal**,**floor_divide**,**true_divide**,**logical_or**,**logical_and**,**floor**,**ceil**,**maximum**,**minimum**,**rint**.These functions are included here because they are used at least once in the array object’s methods. The function returns -1 (without setting a Python Error) if one of the objects being assigned is not callable.

Deprecated since version 1.16.

[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*PyArray_GetNumericOps(void)[#](#c.PyArray_GetNumericOps)
-
Return a Python dictionary containing the callable Python objects stored in the internal arithmetic operation table. The keys of this dictionary are given in the explanation for

.`PyArray_SetNumericOps`
Deprecated since version 1.16.

void PyArray_SetStringFunction([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*op, int repr)[#](#c.PyArray_SetStringFunction)
-
This function allows you to alter the tp_str and tp_repr methods of the array object to any Python function. Thus you can alter what happens for all arrays when str(arr) or repr(arr) is called from Python. The function to be called is passed in as

*op*. If*repr*is non-zero, then this function will be called in response to repr(arr), otherwise the function will be called in response to str(arr). No check on whether or not*op*is callable is performed. The callable passed in to*op*should expect an array argument and should return a string to be printed.
### Memory management[#](#memory-management)
char *PyDataMem_NEW(size_t nbytes)[#](#c.PyDataMem_NEW)
-
void PyDataMem_FREE(char *ptr)[#](#c.PyDataMem_FREE)
-
char *PyDataMem_RENEW(void *ptr, size_t newbytes)[#](#c.PyDataMem_RENEW)
-
Macros to allocate, free, and reallocate memory. These macros are used internally to create arrays.

void PyDimMem_FREE(char *ptr)[#](#c.PyDimMem_FREE)
-
[npy_intp](dtype.html#c.npy_intp)*PyDimMem_RENEW(void *ptr, size_t newnd)[#](#c.PyDimMem_RENEW)
-
Macros to allocate, free, and reallocate dimension and strides memory.

void *PyArray_malloc(size_t nbytes)[#](#c.PyArray_malloc)
-
void PyArray_free(void *ptr)[#](#c.PyArray_free)
-
void *PyArray_realloc([npy_intp](dtype.html#c.npy_intp)*ptr, size_t nbytes)[#](#c.PyArray_realloc)
-
These macros use different memory allocators, depending on the constant

. The system malloc is used when`NPY_USE_PYMEM`
is 0, if`NPY_USE_PYMEM`
is 1, then the Python memory allocator is used.`NPY_USE_PYMEM`
NPY_USE_PYMEM[#](#c.PyArray_realloc.NPY_USE_PYMEM)
-
NPY_USE_PYMEM
-
int PyArray_ResolveWritebackIfCopy([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_ResolveWritebackIfCopy)
-
If

`obj->flags`
has, this function clears the flags,`NPY_ARRAY_WRITEBACKIFCOPY`
*DECREF*s*obj->base*and makes it writeable, and sets`obj->base`
to NULL. It then copies`obj->data`
to*obj->base->data*, and returns the error state of the copy operation. This is the opposite of. Usually this is called once you are finished with`PyArray_SetWritebackIfCopyBase`
`obj`
, just before`Py_DECREF(obj)`
. It may be called multiple times, or with`NULL`
input. See also.`PyArray_DiscardWritebackIfCopy`
Returns 0 if nothing was done, -1 on error, and 1 if action was taken.

### Threading support[#](#threading-support)
These macros are only meaningful if [ NPY_ALLOW_THREADS](#c.NPY_ALLOW_THREADS)
evaluates True during compilation of the extension module. Otherwise,
these macros are equivalent to whitespace. Python uses a single Global
Interpreter Lock (GIL) for each Python process so that only a single
thread may execute at a time (even on multi-cpu machines). When
calling out to a compiled function that may take time to compute (and
does not have side-effects for other threads like updated global
variables), the GIL should be released so that other Python threads
can run while the time-consuming calculations are performed. This can
be accomplished using two groups of macros. Typically, if one macro in
a group is used in a code block, all of them must be used in the same
code block. Currently,

[is defined to the python-defined](#c.NPY_ALLOW_THREADS)
`NPY_ALLOW_THREADS`
[constant unless the environment variable](#c.WITH_THREADS)
`WITH_THREADS`
`NPY_NOSMP`
is set in which case
[is defined to be 0.](#c.NPY_ALLOW_THREADS)
`NPY_ALLOW_THREADS`
NPY_ALLOW_THREADS[#](#c.NPY_ALLOW_THREADS)
-
WITH_THREADS[#](#c.WITH_THREADS)
-
#### Group 1[#](#group-1)
This group is used to call code that may take some time but does not use any Python C-API calls. Thus, the GIL should be released during its calculation.

NPY_BEGIN_ALLOW_THREADS
-
[#]
Equivalent to

[except it uses]`Py_BEGIN_ALLOW_THREADS`
[to determine if the macro if replaced with white-space or not.]`NPY_ALLOW_THREADS`
NPY_END_ALLOW_THREADS
-
[#]
Equivalent to

[except it uses]`Py_END_ALLOW_THREADS`
[to determine if the macro if replaced with white-space or not.]`NPY_ALLOW_THREADS`
NPY_BEGIN_THREADS_DEF
-
[#]
Place in the variable declaration area. This macro sets up the variable needed for storing the Python state.

NPY_BEGIN_THREADS
-
[#]
Place right before code that does not need the Python interpreter (no Python C-API calls). This macro saves the Python state and releases the GIL.

NPY_END_THREADS
-
[#]
Place right after code that does not need the Python interpreter. This macro acquires the GIL and restores the Python state from the saved variable.

void NPY_BEGIN_THREADS_DESCR(
-
[PyArray_Descr]*dtype)[#]
Useful to release the GIL only if

dtypedoes not contain arbitrary Python objects which may need the Python interpreter during execution of the loop.
void NPY_END_THREADS_DESCR(
-
[PyArray_Descr]*dtype)[#]
Useful to regain the GIL in situations where it was released using the BEGIN form of this macro.

void NPY_BEGIN_THREADS_THRESHOLDED(int loop_size)
-
[#]
Useful to release the GIL only if

loop_sizeexceeds a minimum threshold, currently set to 500. Should be matched with a[to regain the GIL.]`NPY_END_THREADS`
#### Group 2[#](#group-2)
This group is used to re-acquire the Python GIL after it has been released. For example, suppose the GIL has been released (using the previous calls), and then some path in the code (perhaps in a different subroutine) requires use of the Python C-API, then these macros are useful to acquire the GIL. These macros accomplish essentially a reverse of the previous three (acquire the LOCK saving what state it had) and then re-release it with the saved state.

NPY_ALLOW_C_API_DEF
-
[#]
Place in the variable declaration area to set up the necessary variable.

NPY_ALLOW_C_API
-
[#]
Place before code that needs to call the Python C-API (when it is known that the GIL has already been released).

NPY_DISABLE_C_API
-
[#]
Place after code that needs to call the Python C-API (to re-release the GIL).

Tip

Never use semicolons after the threading support macros.

### Priority[#](#priority)
NPY_PRIORITY[#](#c.NPY_PRIORITY)
-
Default priority for arrays.

NPY_SUBTYPE_PRIORITY[#](#c.NPY_SUBTYPE_PRIORITY)
-
Default subtype priority.

NPY_SCALAR_PRIORITY[#](#c.NPY_SCALAR_PRIORITY)
-
Default scalar priority (very small)

double PyArray_GetPriority([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*obj, double def)[#](#c.PyArray_GetPriority)
-
Return the

attribute (converted to a double) of`__array_priority__`
*obj*or*def*if no attribute of that name exists. Fast returns that avoid the attribute lookup are provided for objects of type.`PyArray_Type`
### Default buffers[#](#default-buffers)
NPY_BUFSIZE[#](#c.NPY_BUFSIZE)
-
Default size of the user-settable internal buffers.

NPY_MIN_BUFSIZE[#](#c.NPY_MIN_BUFSIZE)
-
Smallest size of user-settable internal buffers.

NPY_MAX_BUFSIZE[#](#c.NPY_MAX_BUFSIZE)
-
Largest size allowed for the user-settable buffers.

### Other constants[#](#other-constants)
NPY_NUM_FLOATTYPE[#](#c.NPY_NUM_FLOATTYPE)
-
The number of floating-point types

NPY_MAXDIMS[#](#c.NPY_MAXDIMS)
-
The maximum number of dimensions allowed in arrays.

NPY_MAXARGS[#](#c.NPY_MAXARGS)
-
The maximum number of array arguments that can be used in functions.

NPY_FALSE[#](#c.NPY_FALSE)
-
Defined as 0 for use with Bool.

NPY_TRUE[#](#c.NPY_TRUE)
-
Defined as 1 for use with Bool.

NPY_FAIL[#](#c.NPY_FAIL)
-
The return value of failed converter functions which are called using the “O&” syntax in

-like functions.`PyArg_ParseTuple`
NPY_SUCCEED[#](#c.NPY_SUCCEED)
-
The return value of successful converter functions which are called using the “O&” syntax in

-like functions.`PyArg_ParseTuple`
### Miscellaneous Macros[#](#miscellaneous-macros)
int PyArray_SAMESHAPE([PyArrayObject](types-and-structures.html#c.PyArrayObject)*a1,[PyArrayObject](types-and-structures.html#c.PyArrayObject)*a2)[#](#c.PyArray_SAMESHAPE)
-
Evaluates as True if arrays

*a1*and*a2*have the same shape.
PyArray_MAX(a, b)[#](#c.PyArray_MAX)
-
Returns the maximum of

*a*and*b*. If (*a*) or (*b*) are expressions they are evaluated twice.
PyArray_MIN(a, b)[#](#c.PyArray_MIN)
-
Returns the minimum of

*a*and*b*. If (*a*) or (*b*) are expressions they are evaluated twice.
PyArray_CLT(a, b)[#](#c.PyArray_CLT)
-
PyArray_CGT(a, b)[#](#c.PyArray_CGT)
-
PyArray_CLE(a, b)[#](#c.PyArray_CLE)
-
PyArray_CGE(a, b)[#](#c.PyArray_CGE)
-
PyArray_CEQ(a, b)[#](#c.PyArray_CEQ)
-
PyArray_CNE(a, b)[#](#c.PyArray_CNE)
-
Implements the complex comparisons between two complex numbers (structures with a real and imag member) using NumPy’s definition of the ordering which is lexicographic: comparing the real parts first and then the complex parts if the real parts are equal.

void PyArray_DiscardWritebackIfCopy([PyArrayObject](types-and-structures.html#c.PyArrayObject)*obj)[#](#c.PyArray_DiscardWritebackIfCopy)
-
If

`obj->flags`
has, this function clears the flags,`NPY_ARRAY_WRITEBACKIFCOPY`
*DECREF*s*obj->base*and makes it writeable, and sets`obj->base`
to NULL. In contrast toit makes no attempt to copy the data from`PyArray_ResolveWritebackIfCopy`
*obj->base*. This undoes. Usually this is called after an error when you are finished with`PyArray_SetWritebackIfCopyBase`
`obj`
, just before`Py_DECREF(obj)`
. It may be called multiple times, or with`NULL`
input.
### Enumerated Types[#](#enumerated-types)
enum NPY_SORTKIND[#](#c.NPY_SORTKIND)
-
A special variable-type which can take on different values to indicate the sorting algorithm being used.

enumerator NPY_QUICKSORT[#](#c.NPY_SORTKIND.NPY_QUICKSORT)
-
enumerator NPY_HEAPSORT[#](#c.NPY_SORTKIND.NPY_HEAPSORT)
-
enumerator NPY_MERGESORT[#](#c.NPY_SORTKIND.NPY_MERGESORT)
-
enumerator NPY_STABLESORT[#](#c.NPY_SORTKIND.NPY_STABLESORT)
-
Used as an alias of

and vica versa.`NPY_MERGESORT`
enumerator NPY_NSORTS[#](#c.NPY_SORTKIND.NPY_NSORTS)
-
Defined to be the number of sorts. It is fixed at three by the need for backwards compatibility, and consequently

and`NPY_MERGESORT`
are aliased to each other and may refer to one of several stable sorting algorithms depending on the data type.`NPY_STABLESORT`
enumerator NPY_QUICKSORT
-
enum NPY_SCALARKIND[#](#c.NPY_SCALARKIND)
-
A special variable type indicating the number of “kinds” of scalars distinguished in determining scalar-coercion rules. This variable can take on the values:

enumerator NPY_NOSCALAR[#](#c.NPY_SCALARKIND.NPY_NOSCALAR)
-
enumerator NPY_BOOL_SCALAR[#](#c.NPY_SCALARKIND.NPY_BOOL_SCALAR)
-
enumerator NPY_INTPOS_SCALAR[#](#c.NPY_SCALARKIND.NPY_INTPOS_SCALAR)
-
enumerator NPY_INTNEG_SCALAR[#](#c.NPY_SCALARKIND.NPY_INTNEG_SCALAR)
-
enumerator NPY_FLOAT_SCALAR[#](#c.NPY_SCALARKIND.NPY_FLOAT_SCALAR)
-
enumerator NPY_COMPLEX_SCALAR[#](#c.NPY_SCALARKIND.NPY_COMPLEX_SCALAR)
-
enumerator NPY_OBJECT_SCALAR[#](#c.NPY_SCALARKIND.NPY_OBJECT_SCALAR)
-
enumerator NPY_NSCALARKINDS[#](#c.NPY_SCALARKIND.NPY_NSCALARKINDS)
-
Defined to be the number of scalar kinds (not including

).`NPY_NOSCALAR`
enumerator NPY_NOSCALAR
-
enum NPY_ORDER[#](#c.NPY_ORDER)
-
An enumeration type indicating the element order that an array should be interpreted in. When a brand new array is created, generally only

**NPY_CORDER**and**NPY_FORTRANORDER**are used, whereas when one or more inputs are provided, the order can be based on them.
enumerator NPY_ANYORDER[#](#c.NPY_ORDER.NPY_ANYORDER)
-
Fortran order if all the inputs are Fortran, C otherwise.

enumerator NPY_CORDER[#](#c.NPY_ORDER.NPY_CORDER)
-
C order.

enumerator NPY_FORTRANORDER[#](#c.NPY_ORDER.NPY_FORTRANORDER)
-
Fortran order.

enumerator NPY_KEEPORDER[#](#c.NPY_ORDER.NPY_KEEPORDER)
-
An order as close to the order of the inputs as possible, even if the input is in neither C nor Fortran order.

enumerator NPY_ANYORDER
-
enum NPY_CLIPMODE[#](#c.NPY_CLIPMODE)
-
A variable type indicating the kind of clipping that should be applied in certain functions.

enumerator NPY_RAISE[#](#c.NPY_CLIPMODE.NPY_RAISE)
-
The default for most operations, raises an exception if an index is out of bounds.

enumerator NPY_CLIP[#](#c.NPY_CLIPMODE.NPY_CLIP)
-
Clips an index to the valid range if it is out of bounds.

enumerator NPY_WRAP[#](#c.NPY_CLIPMODE.NPY_WRAP)
-
Wraps an index to the valid range if it is out of bounds.

enumerator NPY_RAISE
-
enum NPY_SEARCHSIDE[#](#c.NPY_SEARCHSIDE)
-
A variable type indicating whether the index returned should be that of the first suitable location (if

) or of the last (if`NPY_SEARCHLEFT`
).`NPY_SEARCHRIGHT`
enumerator NPY_SEARCHLEFT[#](#c.NPY_SEARCHSIDE.NPY_SEARCHLEFT)
-
enumerator NPY_SEARCHRIGHT[#](#c.NPY_SEARCHSIDE.NPY_SEARCHRIGHT)
-
enumerator NPY_SEARCHLEFT
-
enum NPY_SELECTKIND[#](#c.NPY_SELECTKIND)
-
A variable type indicating the selection algorithm being used.

enumerator NPY_INTROSELECT[#](#c.NPY_SELECTKIND.NPY_INTROSELECT)
-
enumerator NPY_INTROSELECT
-
enum NPY_CASTING[#](#c.NPY_CASTING)
-
New in version 1.6.

An enumeration type indicating how permissive data conversions should be. This is used by the iterator added in NumPy 1.6, and is intended to be used more broadly in a future version.

enumerator NPY_NO_CASTING[#](#c.NPY_CASTING.NPY_NO_CASTING)
-
Only allow identical types.

enumerator NPY_EQUIV_CASTING[#](#c.NPY_CASTING.NPY_EQUIV_CASTING)
-
Allow identical and casts involving byte swapping.

enumerator NPY_SAFE_CASTING[#](#c.NPY_CASTING.NPY_SAFE_CASTING)
-
Only allow casts which will not cause values to be rounded, truncated, or otherwise changed.

enumerator NPY_SAME_KIND_CASTING[#](#c.NPY_CASTING.NPY_SAME_KIND_CASTING)
-
Allow any safe casts, and casts between types of the same kind. For example, float64 -> float32 is permitted with this rule.

enumerator NPY_UNSAFE_CASTING[#](#c.NPY_CASTING.NPY_UNSAFE_CASTING)
-
Allow any cast, no matter what kind of data loss may occur.

enumerator NPY_NO_CASTING
-# Array Iterator API[#](#array-iterator-api)
New in version 1.6.

## Array Iterator[#](#array-iterator)
The array iterator encapsulates many of the key features in ufuncs, allowing user code to support features like output parameters, preservation of memory layouts, and buffering of data with the wrong alignment or type, without requiring difficult coding.

This page documents the API for the iterator.
The iterator is named `NpyIter`
and functions are
named `NpyIter_*`
.

There is an [introductory guide to array iteration](../arrays.nditer.html#arrays-nditer)
which may be of interest for those using this C API. In many instances,
testing out ideas by creating the iterator in Python is a good idea
before writing the C iteration code.

## Iteration Example[#](#iteration-example)
The best way to become familiar with the iterator is to look at its
usage within the NumPy codebase itself. For example, here is a slightly
tweaked version of the code for [ PyArray_CountNonzero](array.html#c.PyArray_CountNonzero), which counts the
number of non-zero elements in an array.

```
npy_intp PyArray_CountNonzero(PyArrayObject* self)
{
/* Nonzero boolean function */
PyArray_NonzeroFunc* nonzero = PyArray_DESCR(self)->f->nonzero;
NpyIter* iter;
NpyIter_IterNextFunc *iternext;
char** dataptr;
npy_intp nonzero_count;
npy_intp* strideptr,* innersizeptr;
/* Handle zero-sized arrays specially */
if (PyArray_SIZE(self) == 0) {
return 0;
}
/*
* Create and use an iterator to count the nonzeros.
* flag NPY_ITER_READONLY
* - The array is never written to.
* flag NPY_ITER_EXTERNAL_LOOP
* - Inner loop is done outside the iterator for efficiency.
* flag NPY_ITER_NPY_ITER_REFS_OK
* - Reference types are acceptable.
* order NPY_KEEPORDER
* - Visit elements in memory order, regardless of strides.
* This is good for performance when the specific order
* elements are visited is unimportant.
* casting NPY_NO_CASTING
* - No casting is required for this operation.
*/
iter = NpyIter_New(self, NPY_ITER_READONLY|
NPY_ITER_EXTERNAL_LOOP|
NPY_ITER_REFS_OK,
NPY_KEEPORDER, NPY_NO_CASTING,
NULL);
if (iter == NULL) {
return -1;
}
/*
* The iternext function gets stored in a local variable
* so it can be called repeatedly in an efficient manner.
*/
iternext = NpyIter_GetIterNext(iter, NULL);
if (iternext == NULL) {
NpyIter_Deallocate(iter);
return -1;
}
/* The location of the data pointer which the iterator may update */
dataptr = NpyIter_GetDataPtrArray(iter);
/* The location of the stride which the iterator may update */
strideptr = NpyIter_GetInnerStrideArray(iter);
/* The location of the inner loop size which the iterator may update */
innersizeptr = NpyIter_GetInnerLoopSizePtr(iter);
nonzero_count = 0;
do {
/* Get the inner loop data/stride/count values */
char* data = *dataptr;
npy_intp stride = *strideptr;
npy_intp count = *innersizeptr;
/* This is a typical inner loop for NPY_ITER_EXTERNAL_LOOP */
while (count--) {
if (nonzero(data, self)) {
++nonzero_count;
}
data += stride;
}
/* Increment the iterator to the next inner loop */
} while(iternext(iter));
NpyIter_Deallocate(iter);
return nonzero_count;
}
```
## Multi-Iteration Example[#](#multi-iteration-example)
Here is a copy function using the iterator. The `order`
parameter
is used to control the memory layout of the allocated result, typically
[ NPY_KEEPORDER](array.html#c.NPY_ORDER.NPY_KEEPORDER) is desired.

```
PyObject *CopyArray(PyObject *arr, NPY_ORDER order)
{
NpyIter *iter;
NpyIter_IterNextFunc *iternext;
PyObject *op[2], *ret;
npy_uint32 flags;
npy_uint32 op_flags[2];
npy_intp itemsize, *innersizeptr, innerstride;
char **dataptrarray;
/*
* No inner iteration - inner loop is handled by CopyArray code
*/
flags = NPY_ITER_EXTERNAL_LOOP;
/*
* Tell the constructor to automatically allocate the output.
* The data type of the output will match that of the input.
*/
op[0] = arr;
op[1] = NULL;
op_flags[0] = NPY_ITER_READONLY;
op_flags[1] = NPY_ITER_WRITEONLY | NPY_ITER_ALLOCATE;
/* Construct the iterator */
iter = NpyIter_MultiNew(2, op, flags, order, NPY_NO_CASTING,
op_flags, NULL);
if (iter == NULL) {
return NULL;
}
/*
* Make a copy of the iternext function pointer and
* a few other variables the inner loop needs.
*/
iternext = NpyIter_GetIterNext(iter, NULL);
innerstride = NpyIter_GetInnerStrideArray(iter)[0];
itemsize = NpyIter_GetDescrArray(iter)[0]->elsize;
/*
* The inner loop size and data pointers may change during the
* loop, so just cache the addresses.
*/
innersizeptr = NpyIter_GetInnerLoopSizePtr(iter);
dataptrarray = NpyIter_GetDataPtrArray(iter);
/*
* Note that because the iterator allocated the output,
* it matches the iteration order and is packed tightly,
* so we don't need to check it like the input.
*/
if (innerstride == itemsize) {
do {
memcpy(dataptrarray[1], dataptrarray[0],
itemsize * (*innersizeptr));
} while (iternext(iter));
} else {
/* For efficiency, should specialize this based on item size... */
npy_intp i;
do {
npy_intp size = *innersizeptr;
char *src = dataptrarray[0], *dst = dataptrarray[1];
for(i = 0; i < size; i++, src += innerstride, dst += itemsize) {
memcpy(dst, src, itemsize);
}
} while (iternext(iter));
}
/* Get the result from the iterator object array */
ret = NpyIter_GetOperandArray(iter)[1];
Py_INCREF(ret);
if (NpyIter_Deallocate(iter) != NPY_SUCCEED) {
Py_DECREF(ret);
return NULL;
}
return ret;
}
```
## Multi Index Tracking Example[#](#multi-index-tracking-example)
This example shows you how to work with the [ NPY_ITER_MULTI_INDEX](#c.NPY_ITER_MULTI_INDEX) flag. For simplicity, we assume the argument is a two-dimensional array.

```
int PrintMultiIndex(PyArrayObject *arr) {
NpyIter *iter;
NpyIter_IterNextFunc *iternext;
npy_intp multi_index[2];
iter = NpyIter_New(
arr, NPY_ITER_READONLY | NPY_ITER_MULTI_INDEX | NPY_ITER_REFS_OK,
NPY_KEEPORDER, NPY_NO_CASTING, NULL);
if (iter == NULL) {
return -1;
}
if (NpyIter_GetNDim(iter) != 2) {
NpyIter_Deallocate(iter);
PyErr_SetString(PyExc_ValueError, "Array must be 2-D");
return -1;
}
if (NpyIter_GetIterSize(iter) != 0) {
iternext = NpyIter_GetIterNext(iter, NULL);
if (iternext == NULL) {
NpyIter_Deallocate(iter);
return -1;
}
NpyIter_GetMultiIndexFunc *get_multi_index =
NpyIter_GetGetMultiIndex(iter, NULL);
if (get_multi_index == NULL) {
NpyIter_Deallocate(iter);
return -1;
}
do {
get_multi_index(iter, multi_index);
printf("multi_index is [%" NPY_INTP_FMT ", %" NPY_INTP_FMT "]\n",
multi_index[0], multi_index[1]);
} while (iternext(iter));
}
if (!NpyIter_Deallocate(iter)) {
return -1;
}
return 0;
}
```
When called with a 2x3 array, the above example prints:

```
multi_index is [0, 0]
multi_index is [0, 1]
multi_index is [0, 2]
multi_index is [1, 0]
multi_index is [1, 1]
multi_index is [1, 2]
```
## Iterator Data Types[#](#iterator-data-types)
The iterator layout is an internal detail, and user code only sees an incomplete struct.

type NpyIter[#](#c.NpyIter)
-
This is an opaque pointer type for the iterator. Access to its contents can only be done through the iterator API.

type NpyIter_Type[#](#c.NpyIter_Type)
-
This is the type which exposes the iterator to Python. Currently, no API is exposed which provides access to the values of a Python-created iterator. If an iterator is created in Python, it must be used in Python and vice versa. Such an API will likely be created in a future version.

type NpyIter_IterNextFunc[#](#c.NpyIter_IterNextFunc)
-
This is a function pointer for the iteration loop, returned by

.`NpyIter_GetIterNext`
type NpyIter_GetMultiIndexFunc[#](#c.NpyIter_GetMultiIndexFunc)
-
This is a function pointer for getting the current iterator multi-index, returned by

.`NpyIter_GetGetMultiIndex`
## Construction and Destruction[#](#construction-and-destruction)
[NpyIter](#c.NpyIter)*NpyIter_New([PyArrayObject](types-and-structures.html#c.PyArrayObject)*op,[npy_uint32](dtype.html#c.npy_uint32)flags,[NPY_ORDER](array.html#c.NPY_ORDER)order,[NPY_CASTING](array.html#c.NPY_CASTING)casting,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)*dtype)[#](#c.NpyIter_New)
-
Creates an iterator for the given numpy array object

`op`
.Flags that may be passed in

`flags`
are any combination of the global and per-operand flags documented in, except for`NpyIter_MultiNew`
.`NPY_ITER_ALLOCATE`
Any of the

enum values may be passed to`NPY_ORDER`
`order`
. For efficient iteration,is the best option, and the other orders enforce the particular iteration pattern.`NPY_KEEPORDER`
Any of the

enum values may be passed to`NPY_CASTING`
`casting`
. The values include,`NPY_NO_CASTING`
,`NPY_EQUIV_CASTING`
,`NPY_SAFE_CASTING`
, and`NPY_SAME_KIND_CASTING`
. To allow the casts to occur, copying or buffering must also be enabled.`NPY_UNSAFE_CASTING`
If

`dtype`
isn’t`NULL`
, then it requires that data type. If copying is allowed, it will make a temporary copy if the data is castable. Ifis enabled, it will also copy the data back with another cast upon iterator destruction.`NPY_ITER_UPDATEIFCOPY`
Returns NULL if there is an error, otherwise returns the allocated iterator.

To make an iterator similar to the old iterator, this should work.

iter = NpyIter_New(op, NPY_ITER_READWRITE, NPY_CORDER, NPY_NO_CASTING, NULL);
If you want to edit an array with aligned

`double`
code, but the order doesn’t matter, you would use this.dtype = PyArray_DescrFromType(NPY_DOUBLE); iter = NpyIter_New(op, NPY_ITER_READWRITE| NPY_ITER_BUFFERED| NPY_ITER_NBO| NPY_ITER_ALIGNED, NPY_KEEPORDER, NPY_SAME_KIND_CASTING, dtype); Py_DECREF(dtype);
[NpyIter](#c.NpyIter)*NpyIter_MultiNew([npy_intp](dtype.html#c.npy_intp)nop,[PyArrayObject](types-and-structures.html#c.PyArrayObject)**op,[npy_uint32](dtype.html#c.npy_uint32)flags,[NPY_ORDER](array.html#c.NPY_ORDER)order,[NPY_CASTING](array.html#c.NPY_CASTING)casting,[npy_uint32](dtype.html#c.npy_uint32)*op_flags,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**op_dtypes)[#](#c.NpyIter_MultiNew)
-
Creates an iterator for broadcasting the

`nop`
array objects provided in`op`
, using regular NumPy broadcasting rules.Any of the

enum values may be passed to`NPY_ORDER`
`order`
. For efficient iteration,is the best option, and the other orders enforce the particular iteration pattern. When using`NPY_KEEPORDER`
, if you also want to ensure that the iteration is not reversed along an axis, you should pass the flag`NPY_KEEPORDER`
.`NPY_ITER_DONT_NEGATE_STRIDES`
Any of the

enum values may be passed to`NPY_CASTING`
`casting`
. The values include,`NPY_NO_CASTING`
,`NPY_EQUIV_CASTING`
,`NPY_SAFE_CASTING`
, and`NPY_SAME_KIND_CASTING`
. To allow the casts to occur, copying or buffering must also be enabled.`NPY_UNSAFE_CASTING`
If

`op_dtypes`
isn’t`NULL`
, it specifies a data type or`NULL`
for each`op[i]`
.Returns NULL if there is an error, otherwise returns the allocated iterator.

Flags that may be passed in

`flags`
, applying to the whole iterator, are:
NPY_ITER_C_INDEX[#](#c.NPY_ITER_C_INDEX)
-
Causes the iterator to track a raveled flat index matching C order. This option cannot be used with

.`NPY_ITER_F_INDEX`
NPY_ITER_F_INDEX[#](#c.NPY_ITER_F_INDEX)
-
Causes the iterator to track a raveled flat index matching Fortran order. This option cannot be used with

.`NPY_ITER_C_INDEX`
NPY_ITER_MULTI_INDEX[#](#c.NPY_ITER_MULTI_INDEX)
-
Causes the iterator to track a multi-index. This prevents the iterator from coalescing axes to produce bigger inner loops. If the loop is also not buffered and no index is being tracked (

*NpyIter_RemoveAxis*can be called), then the iterator size can be`-1`
to indicate that the iterator is too large. This can happen due to complex broadcasting and will result in errors being created when the setting the iterator range, removing the multi index, or getting the next function. However, it is possible to remove axes again and use the iterator normally if the size is small enough after removal.
NPY_ITER_EXTERNAL_LOOP[#](#c.NPY_ITER_EXTERNAL_LOOP)
-
Causes the iterator to skip iteration of the innermost loop, requiring the user of the iterator to handle it.

This flag is incompatible with

,`NPY_ITER_C_INDEX`
, and`NPY_ITER_F_INDEX`
.`NPY_ITER_MULTI_INDEX`
NPY_ITER_DONT_NEGATE_STRIDES[#](#c.NPY_ITER_DONT_NEGATE_STRIDES)
-
This only affects the iterator when

is specified for the order parameter. By default with`NPY_KEEPORDER`
, the iterator reverses axes which have negative strides, so that memory is traversed in a forward direction. This disables this step. Use this flag if you want to use the underlying memory-ordering of the axes, but don’t want an axis reversed. This is the behavior of`NPY_KEEPORDER`
`numpy.ravel(a, order='K')`
, for instance.
NPY_ITER_COMMON_DTYPE[#](#c.NPY_ITER_COMMON_DTYPE)
-
Causes the iterator to convert all the operands to a common data type, calculated based on the ufunc type promotion rules. Copying or buffering must be enabled.

If the common data type is known ahead of time, don’t use this flag. Instead, set the requested dtype for all the operands.

NPY_ITER_REFS_OK[#](#c.NPY_ITER_REFS_OK)
-
Indicates that arrays with reference types (object arrays or structured arrays containing an object type) may be accepted and used in the iterator. If this flag is enabled, the caller must be sure to check whether NpyIter_IterationNeedsAPI(iter) is true, in which case it may not release the GIL during iteration.

NPY_ITER_ZEROSIZE_OK[#](#c.NPY_ITER_ZEROSIZE_OK)
-
Indicates that arrays with a size of zero should be permitted. Since the typical iteration loop does not naturally work with zero-sized arrays, you must check that the IterSize is larger than zero before entering the iteration loop. Currently only the operands are checked, not a forced shape.

NPY_ITER_REDUCE_OK[#](#c.NPY_ITER_REDUCE_OK)
-
Permits writeable operands with a dimension with zero stride and size greater than one. Note that such operands must be read/write.

When buffering is enabled, this also switches to a special buffering mode which reduces the loop length as necessary to not trample on values being reduced.

Note that if you want to do a reduction on an automatically allocated output, you must use

to get its reference, then set every value to the reduction unit before doing the iteration loop. In the case of a buffered reduction, this means you must also specify the flag`NpyIter_GetOperandArray`
, then reset the iterator after initializing the allocated operand to prepare the buffers.`NPY_ITER_DELAY_BUFALLOC`
NPY_ITER_RANGED[#](#c.NPY_ITER_RANGED)
-
Enables support for iteration of sub-ranges of the full

`iterindex`
range`[0, NpyIter_IterSize(iter))`
. Use the functionto specify a range for iteration.`NpyIter_ResetToIterIndexRange`
This flag can only be used with

when`NPY_ITER_EXTERNAL_LOOP`
is enabled. This is because without buffering, the inner loop is always the size of the innermost iteration dimension, and allowing it to get cut up would require special handling, effectively making it more like the buffered version.`NPY_ITER_BUFFERED`
NPY_ITER_BUFFERED[#](#c.NPY_ITER_BUFFERED)
-
Causes the iterator to store buffering data, and use buffering to satisfy data type, alignment, and byte-order requirements. To buffer an operand, do not specify the

or`NPY_ITER_COPY`
flags, because they will override buffering. Buffering is especially useful for Python code using the iterator, allowing for larger chunks of data at once to amortize the Python interpreter overhead.`NPY_ITER_UPDATEIFCOPY`
If used with

, the inner loop for the caller may get larger chunks than would be possible without buffering, because of how the strides are laid out.`NPY_ITER_EXTERNAL_LOOP`
Note that if an operand is given the flag

or`NPY_ITER_COPY`
, a copy will be made in preference to buffering. Buffering will still occur when the array was broadcast so elements need to be duplicated to get a constant stride.`NPY_ITER_UPDATEIFCOPY`
In normal buffering, the size of each inner loop is equal to the buffer size, or possibly larger if

is specified. If`NPY_ITER_GROWINNER`
is enabled and a reduction occurs, the inner loops may become smaller depending on the structure of the reduction.`NPY_ITER_REDUCE_OK`
NPY_ITER_GROWINNER[#](#c.NPY_ITER_GROWINNER)
-
When buffering is enabled, this allows the size of the inner loop to grow when buffering isn’t necessary. This option is best used if you’re doing a straight pass through all the data, rather than anything with small cache-friendly arrays of temporary values for each inner loop.

NPY_ITER_DELAY_BUFALLOC[#](#c.NPY_ITER_DELAY_BUFALLOC)
-
When buffering is enabled, this delays allocation of the buffers until

or another reset function is called. This flag exists to avoid wasteful copying of buffer data when making multiple copies of a buffered iterator for multi-threaded iteration.`NpyIter_Reset`
Another use of this flag is for setting up reduction operations. After the iterator is created, and a reduction output is allocated automatically by the iterator (be sure to use READWRITE access), its value may be initialized to the reduction unit. Use

to get the object. Then, call`NpyIter_GetOperandArray`
to allocate and fill the buffers with their initial values.`NpyIter_Reset`
NPY_ITER_COPY_IF_OVERLAP[#](#c.NPY_ITER_COPY_IF_OVERLAP)
-
If any write operand has overlap with any read operand, eliminate all overlap by making temporary copies (enabling UPDATEIFCOPY for write operands, if necessary). A pair of operands has overlap if there is a memory address that contains data common to both arrays.

Because exact overlap detection has exponential runtime in the number of dimensions, the decision is made based on heuristics, which has false positives (needless copies in unusual cases) but has no false negatives.

If any read/write overlap exists, this flag ensures the result of the operation is the same as if all operands were copied. In cases where copies would need to be made,

**the result of the computation may be undefined without this flag!**Flags that may be passed in

`op_flags[i]`
, where`0 <= i < nop`
:
NPY_ITER_READWRITE[#](#c.NPY_ITER_READWRITE)
-
NPY_ITER_READONLY[#](#c.NPY_ITER_READONLY)
-
NPY_ITER_WRITEONLY[#](#c.NPY_ITER_WRITEONLY)
-
Indicate how the user of the iterator will read or write to

`op[i]`
. Exactly one of these flags must be specified per operand. Using`NPY_ITER_READWRITE`
or`NPY_ITER_WRITEONLY`
for a user-provided operand may trigger*WRITEBACKIFCOPY`*semantics. The data will be written back to the original array when`NpyIter_Deallocate`
is called.
NPY_ITER_COPY[#](#c.NPY_ITER_COPY)
-
Allow a copy of

`op[i]`
to be made if it does not meet the data type or alignment requirements as specified by the constructor flags and parameters.
NPY_ITER_UPDATEIFCOPY[#](#c.NPY_ITER_UPDATEIFCOPY)
-
Triggers

, and when an array operand is flagged for writing and is copied, causes the data in a copy to be copied back to`NPY_ITER_COPY`
`op[i]`
when`NpyIter_Deallocate`
is called.If the operand is flagged as write-only and a copy is needed, an uninitialized temporary array will be created and then copied to back to

`op[i]`
on calling`NpyIter_Deallocate`
, instead of doing the unnecessary copy operation.
NPY_ITER_NBO[#](#c.NPY_ITER_NBO)
-
NPY_ITER_ALIGNED[#](#c.NPY_ITER_ALIGNED)
-
NPY_ITER_CONTIG[#](#c.NPY_ITER_CONTIG)
-
Causes the iterator to provide data for

`op[i]`
that is in native byte order, aligned according to the dtype requirements, contiguous, or any combination.By default, the iterator produces pointers into the arrays provided, which may be aligned or unaligned, and with any byte order. If copying or buffering is not enabled and the operand data doesn’t satisfy the constraints, an error will be raised.

The contiguous constraint applies only to the inner loop, successive inner loops may have arbitrary pointer changes.

If the requested data type is in non-native byte order, the NBO flag overrides it and the requested data type is converted to be in native byte order.

NPY_ITER_ALLOCATE[#](#c.NPY_ITER_ALLOCATE)
-
This is for output arrays, and requires that the flag

or`NPY_ITER_WRITEONLY`
be set. If`NPY_ITER_READWRITE`
`op[i]`
is NULL, creates a new array with the final broadcast dimensions, and a layout matching the iteration order of the iterator.When

`op[i]`
is NULL, the requested data type`op_dtypes[i]`
may be NULL as well, in which case it is automatically generated from the dtypes of the arrays which are flagged as readable. The rules for generating the dtype are the same is for UFuncs. Of special note is handling of byte order in the selected dtype. If there is exactly one input, the input’s dtype is used as is. Otherwise, if more than one input dtypes are combined together, the output will be in native byte order.After being allocated with this flag, the caller may retrieve the new array by calling

and getting the i-th object in the returned C array. The caller must call Py_INCREF on it to claim a reference to the array.`NpyIter_GetOperandArray`
NPY_ITER_NO_SUBTYPE[#](#c.NPY_ITER_NO_SUBTYPE)
-
For use with

, this flag disables allocating an array subtype for the output, forcing it to be a straight ndarray.`NPY_ITER_ALLOCATE`
TODO: Maybe it would be better to introduce a function

`NpyIter_GetWrappedOutput`
and remove this flag?
NPY_ITER_NO_BROADCAST[#](#c.NPY_ITER_NO_BROADCAST)
-
Ensures that the input or output matches the iteration dimensions exactly.

NPY_ITER_ARRAYMASK[#](#c.NPY_ITER_ARRAYMASK)
-
New in version 1.7.

Indicates that this operand is the mask to use for selecting elements when writing to operands which have the

flag applied to them. Only one operand may have`NPY_ITER_WRITEMASKED`
flag applied to it.`NPY_ITER_ARRAYMASK`
The data type of an operand with this flag should be either

,`NPY_BOOL`
, or a struct dtype whose fields are all valid mask dtypes. In the latter case, it must match up with a struct operand being WRITEMASKED, as it is specifying a mask for each field of that array.`NPY_MASK`
This flag only affects writing from the buffer back to the array. This means that if the operand is also

or`NPY_ITER_READWRITE`
, code doing iteration can write to this operand to control which elements will be untouched and which ones will be modified. This is useful when the mask should be a combination of input masks.`NPY_ITER_WRITEONLY`
NPY_ITER_WRITEMASKED[#](#c.NPY_ITER_WRITEMASKED)
-
New in version 1.7.

This array is the mask for all

operands. Code uses the`writemasked`
`writemasked`
flag which indicates that only elements where the chosen ARRAYMASK operand is True will be written to. In general, the iterator does not enforce this, it is up to the code doing the iteration to follow that promise.When

`writemasked`
flag is used, and this operand is buffered, this changes how data is copied from the buffer into the array. A masked copying routine is used, which only copies the elements in the buffer for which`writemasked`
returns true from the corresponding element in the ARRAYMASK operand.
NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE[#](#c.NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE)
-
In memory overlap checks, assume that operands with

`NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE`
enabled are accessed only in the iterator order.This enables the iterator to reason about data dependency, possibly avoiding unnecessary copies.

This flag has effect only if

`NPY_ITER_COPY_IF_OVERLAP`
is enabled on the iterator.
[NpyIter](#c.NpyIter)*NpyIter_AdvancedNew([npy_intp](dtype.html#c.npy_intp)nop,[PyArrayObject](types-and-structures.html#c.PyArrayObject)**op,[npy_uint32](dtype.html#c.npy_uint32)flags,[NPY_ORDER](array.html#c.NPY_ORDER)order,[NPY_CASTING](array.html#c.NPY_CASTING)casting,[npy_uint32](dtype.html#c.npy_uint32)*op_flags,[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**op_dtypes, int oa_ndim, int **op_axes,[npy_intp](dtype.html#c.npy_intp)const *itershape,[npy_intp](dtype.html#c.npy_intp)buffersize)[#](#c.NpyIter_AdvancedNew)
-
Extends

with several advanced options providing more control over broadcasting and buffering.`NpyIter_MultiNew`
If -1/NULL values are passed to

`oa_ndim`
,`op_axes`
,`itershape`
, and`buffersize`
, it is equivalent to.`NpyIter_MultiNew`
The parameter

`oa_ndim`
, when not zero or -1, specifies the number of dimensions that will be iterated with customized broadcasting. If it is provided,`op_axes`
must and`itershape`
can also be provided. The`op_axes`
parameter let you control in detail how the axes of the operand arrays get matched together and iterated. In`op_axes`
, you must provide an array of`nop`
pointers to`oa_ndim`
-sized arrays of type`npy_intp`
. If an entry in`op_axes`
is NULL, normal broadcasting rules will apply. In`op_axes[j][i]`
is stored either a valid axis of`op[j]`
, or -1 which means`newaxis`
. Within each`op_axes[j]`
array, axes may not be repeated. The following example is how normal broadcasting applies to a 3-D array, a 2-D array, a 1-D array and a scalar.**Note**: Before NumPy 1.8`oa_ndim == 0` was used for signalling that ``op_axes`
and`itershape`
are unused. This is deprecated and should be replaced with -1. Better backward compatibility may be achieved by usingfor this case.`NpyIter_MultiNew`
int oa_ndim = 3; /* # iteration axes */ int op0_axes[] = {0, 1, 2}; /* 3-D operand */ int op1_axes[] = {-1, 0, 1}; /* 2-D operand */ int op2_axes[] = {-1, -1, 0}; /* 1-D operand */ int op3_axes[] = {-1, -1, -1} /* 0-D (scalar) operand */ int* op_axes[] = {op0_axes, op1_axes, op2_axes, op3_axes};
The

`itershape`
parameter allows you to force the iterator to have a specific iteration shape. It is an array of length`oa_ndim`
. When an entry is negative, its value is determined from the operands. This parameter allows automatically allocated outputs to get additional dimensions which don’t match up with any dimension of an input.If

`buffersize`
is zero, a default buffer size is used, otherwise it specifies how big of a buffer to use. Buffers which are powers of 2 such as 4096 or 8192 are recommended.Returns NULL if there is an error, otherwise returns the allocated iterator.

[NpyIter](#c.NpyIter)*NpyIter_Copy([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_Copy)
-
Makes a copy of the given iterator. This function is provided primarily to enable multi-threaded iteration of the data.

*TODO*: Move this to a section about multithreaded iteration.The recommended approach to multithreaded iteration is to first create an iterator with the flags

,`NPY_ITER_EXTERNAL_LOOP`
,`NPY_ITER_RANGED`
,`NPY_ITER_BUFFERED`
, and possibly`NPY_ITER_DELAY_BUFALLOC`
. Create a copy of this iterator for each thread (minus one for the first iterator). Then, take the iteration index range`NPY_ITER_GROWINNER`
`[0, NpyIter_GetIterSize(iter))`
and split it up into tasks, for example using a TBB parallel_for loop. When a thread gets a task to execute, it then uses its copy of the iterator by callingand iterating over the full range.`NpyIter_ResetToIterIndexRange`
When using the iterator in multi-threaded code or in code not holding the Python GIL, care must be taken to only call functions which are safe in that context.

cannot be safely called without the Python GIL, because it increments Python references. The`NpyIter_Copy`
`Reset*`
and some other functions may be safely called by passing in the`errmsg`
parameter as non-NULL, so that the functions will pass back errors through it instead of setting a Python exception.must be called for each copy.`NpyIter_Deallocate`
int NpyIter_RemoveAxis([NpyIter](#c.NpyIter)*iter, int axis)[#](#c.NpyIter_RemoveAxis)
-
Removes an axis from iteration. This requires that

was set for iterator creation, and does not work if buffering is enabled or an index is being tracked. This function also resets the iterator to its initial state.`NPY_ITER_MULTI_INDEX`
This is useful for setting up an accumulation loop, for example. The iterator can first be created with all the dimensions, including the accumulation axis, so that the output gets created correctly. Then, the accumulation axis can be removed, and the calculation done in a nested fashion.

**WARNING**: This function may change the internal memory layout of the iterator. Any cached functions or pointers from the iterator must be retrieved again! The iterator range will be reset as well.Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
int NpyIter_RemoveMultiIndex([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_RemoveMultiIndex)
-
If the iterator is tracking a multi-index, this strips support for them, and does further iterator optimizations that are possible if multi-indices are not needed. This function also resets the iterator to its initial state.

**WARNING**: This function may change the internal memory layout of the iterator. Any cached functions or pointers from the iterator must be retrieved again!After calling this function,

[NpyIter_HasMultiIndex](#c.NpyIter_HasMultiIndex)([iter](#c.NpyIter_RemoveMultiIndex)) will return false.Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
int NpyIter_EnableExternalLoop([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_EnableExternalLoop)
-
If

was called, you may want to enable the flag`NpyIter_RemoveMultiIndex`
. This flag is not permitted together with`NPY_ITER_EXTERNAL_LOOP`
, so this function is provided to enable the feature after`NPY_ITER_MULTI_INDEX`
is called. This function also resets the iterator to its initial state.`NpyIter_RemoveMultiIndex`
**WARNING**: This function changes the internal logic of the iterator. Any cached functions or pointers from the iterator must be retrieved again!Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
int NpyIter_Deallocate([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_Deallocate)
-
Deallocates the iterator object and resolves any needed writebacks.

Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
int NpyIter_Reset([NpyIter](#c.NpyIter)*iter, char **errmsg)[#](#c.NpyIter_Reset)
-
Resets the iterator back to its initial state, at the beginning of the iteration range.

Returns

`NPY_SUCCEED`
or`NPY_FAIL`
. If errmsg is non-NULL, no Python exception is set when`NPY_FAIL`
is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL.
int NpyIter_ResetToIterIndexRange([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)istart,[npy_intp](dtype.html#c.npy_intp)iend, char **errmsg)[#](#c.NpyIter_ResetToIterIndexRange)
-
Resets the iterator and restricts it to the

`iterindex`
range`[istart, iend)`
. Seefor an explanation of how to use this for multi-threaded iteration. This requires that the flag`NpyIter_Copy`
was passed to the iterator constructor.`NPY_ITER_RANGED`
If you want to reset both the

`iterindex`
range and the base pointers at the same time, you can do the following to avoid extra buffer copying (be sure to add the return code error checks when you copy this code)./* Set to a trivial empty range */ NpyIter_ResetToIterIndexRange(iter, 0, 0); /* Set the base pointers */ NpyIter_ResetBasePointers(iter, baseptrs); /* Set to the desired range */ NpyIter_ResetToIterIndexRange(iter, istart, iend);
Returns

`NPY_SUCCEED`
or`NPY_FAIL`
. If errmsg is non-NULL, no Python exception is set when`NPY_FAIL`
is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL.
int NpyIter_ResetBasePointers([NpyIter](#c.NpyIter)*iter, char **baseptrs, char **errmsg)[#](#c.NpyIter_ResetBasePointers)
-
Resets the iterator back to its initial state, but using the values in

`baseptrs`
for the data instead of the pointers from the arrays being iterated. This functions is intended to be used, together with the`op_axes`
parameter, by nested iteration code with two or more iterators.Returns

`NPY_SUCCEED`
or`NPY_FAIL`
. If errmsg is non-NULL, no Python exception is set when`NPY_FAIL`
is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL.*TODO*: Move the following into a special section on nested iterators.Creating iterators for nested iteration requires some care. All the iterator operands must match exactly, or the calls to

will be invalid. This means that automatic copies and output allocation should not be used haphazardly. It is possible to still use the automatic data conversion and casting features of the iterator by creating one of the iterators with all the conversion parameters enabled, then grabbing the allocated operands with the`NpyIter_ResetBasePointers`
function and passing them into the constructors for the rest of the iterators.`NpyIter_GetOperandArray`
**WARNING**: When creating iterators for nested iteration, the code must not use a dimension more than once in the different iterators. If this is done, nested iteration will produce out-of-bounds pointers during iteration.**WARNING**: When creating iterators for nested iteration, buffering can only be applied to the innermost iterator. If a buffered iterator is used as the source for`baseptrs`
, it will point into a small buffer instead of the array and the inner iteration will be invalid.The pattern for using nested iterators is as follows.

NpyIter *iter1, *iter1; NpyIter_IterNextFunc *iternext1, *iternext2; char **dataptrs1; /* * With the exact same operands, no copies allowed, and * no axis in op_axes used both in iter1 and iter2. * Buffering may be enabled for iter2, but not for iter1. */ iter1 = ...; iter2 = ...; iternext1 = NpyIter_GetIterNext(iter1); iternext2 = NpyIter_GetIterNext(iter2); dataptrs1 = NpyIter_GetDataPtrArray(iter1); do { NpyIter_ResetBasePointers(iter2, dataptrs1); do { /* Use the iter2 values */ } while (iternext2(iter2)); } while (iternext1(iter1));
int NpyIter_GotoMultiIndex([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)const *multi_index)[#](#c.NpyIter_GotoMultiIndex)
-
Adjusts the iterator to point to the

`ndim`
indices pointed to by`multi_index`
. Returns an error if a multi-index is not being tracked, the indices are out of bounds, or inner loop iteration is disabled.Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
int NpyIter_GotoIndex([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)index)[#](#c.NpyIter_GotoIndex)
-
Adjusts the iterator to point to the

`index`
specified. If the iterator was constructed with the flag,`NPY_ITER_C_INDEX`
`index`
is the C-order index, and if the iterator was constructed with the flag,`NPY_ITER_F_INDEX`
`index`
is the Fortran-order index. Returns an error if there is no index being tracked, the index is out of bounds, or inner loop iteration is disabled.Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
[npy_intp](dtype.html#c.npy_intp)NpyIter_GetIterSize([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetIterSize)
-
Returns the number of elements being iterated. This is the product of all the dimensions in the shape. When a multi index is being tracked (and

*NpyIter_RemoveAxis*may be called) the size may be`-1`
to indicate an iterator is too large. Such an iterator is invalid, but may become valid after*NpyIter_RemoveAxis*is called. It is not necessary to check for this case.
[npy_intp](dtype.html#c.npy_intp)NpyIter_GetIterIndex([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetIterIndex)
-
Gets the

`iterindex`
of the iterator, which is an index matching the iteration order of the iterator.
void NpyIter_GetIterIndexRange([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)*istart,[npy_intp](dtype.html#c.npy_intp)*iend)[#](#c.NpyIter_GetIterIndexRange)
-
Gets the

`iterindex`
sub-range that is being iterated. Ifwas not specified, this always returns the range`NPY_ITER_RANGED`
`[0, NpyIter_IterSize(iter))`
.
int NpyIter_GotoIterIndex([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)iterindex)[#](#c.NpyIter_GotoIterIndex)
-
Adjusts the iterator to point to the

`iterindex`
specified. The IterIndex is an index matching the iteration order of the iterator. Returns an error if the`iterindex`
is out of bounds, buffering is enabled, or inner loop iteration is disabled.Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
[npy_bool](dtype.html#c.npy_bool)NpyIter_HasDelayedBufAlloc([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_HasDelayedBufAlloc)
-
Returns 1 if the flag

was passed to the iterator constructor, and no call to one of the Reset functions has been done yet, 0 otherwise.`NPY_ITER_DELAY_BUFALLOC`
[npy_bool](dtype.html#c.npy_bool)NpyIter_HasExternalLoop([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_HasExternalLoop)
-
Returns 1 if the caller needs to handle the inner-most 1-dimensional loop, or 0 if the iterator handles all looping. This is controlled by the constructor flag

or`NPY_ITER_EXTERNAL_LOOP`
.`NpyIter_EnableExternalLoop`
[npy_bool](dtype.html#c.npy_bool)NpyIter_HasMultiIndex([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_HasMultiIndex)
-
Returns 1 if the iterator was created with the

flag, 0 otherwise.`NPY_ITER_MULTI_INDEX`
[npy_bool](dtype.html#c.npy_bool)NpyIter_HasIndex([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_HasIndex)
-
Returns 1 if the iterator was created with the

or`NPY_ITER_C_INDEX`
flag, 0 otherwise.`NPY_ITER_F_INDEX`
[npy_bool](dtype.html#c.npy_bool)NpyIter_RequiresBuffering([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_RequiresBuffering)
-
Returns 1 if the iterator requires buffering, which occurs when an operand needs conversion or alignment and so cannot be used directly.

[npy_bool](dtype.html#c.npy_bool)NpyIter_IsBuffered([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_IsBuffered)
-
Returns 1 if the iterator was created with the

flag, 0 otherwise.`NPY_ITER_BUFFERED`
[npy_bool](dtype.html#c.npy_bool)NpyIter_IsGrowInner([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_IsGrowInner)
-
Returns 1 if the iterator was created with the

flag, 0 otherwise.`NPY_ITER_GROWINNER`
[npy_intp](dtype.html#c.npy_intp)NpyIter_GetBufferSize([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetBufferSize)
-
If the iterator is buffered, returns the size of the buffer being used, otherwise returns 0.

int NpyIter_GetNDim([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetNDim)
-
Returns the number of dimensions being iterated. If a multi-index was not requested in the iterator constructor, this value may be smaller than the number of dimensions in the original objects.

[npy_intp](dtype.html#c.npy_intp)*NpyIter_GetAxisStrideArray([NpyIter](#c.NpyIter)*iter, int axis)[#](#c.NpyIter_GetAxisStrideArray)
-
Gets the array of strides for the specified axis. Requires that the iterator be tracking a multi-index, and that buffering not be enabled.

This may be used when you want to match up operand axes in some fashion, then remove them with

to handle their processing manually. By calling this function before removing the axes, you can get the strides for the manual processing.`NpyIter_RemoveAxis`
Returns

`NULL`
on error.
int NpyIter_GetShape([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)*outshape)[#](#c.NpyIter_GetShape)
-
Returns the broadcast shape of the iterator in

`outshape`
. This can only be called on an iterator which is tracking a multi-index.Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
[PyArray_Descr](types-and-structures.html#c.PyArray_Descr)**NpyIter_GetDescrArray([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetDescrArray)
-
This gives back a pointer to the

`nop`
data type Descrs for the objects being iterated. The result points into`iter`
, so the caller does not gain any references to the Descrs.This pointer may be cached before the iteration loop, calling

`iternext`
will not change it.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)**NpyIter_GetOperandArray([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetOperandArray)
-
This gives back a pointer to the

`nop`
operand PyObjects that are being iterated. The result points into`iter`
, so the caller does not gain any references to the PyObjects.
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*NpyIter_GetIterView([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)i)[#](#c.NpyIter_GetIterView)
-
This gives back a reference to a new ndarray view, which is a view into the i-th object in the array

, whose dimensions and strides match the internal optimized iteration pattern. A C-order iteration of this view is equivalent to the iterator’s iteration order.`NpyIter_GetOperandArray`
For example, if an iterator was created with a single array as its input, and it was possible to rearrange all its axes and then collapse it into a single strided iteration, this would return a view that is a one-dimensional array.

void NpyIter_GetReadFlags([NpyIter](#c.NpyIter)*iter, char *outreadflags)[#](#c.NpyIter_GetReadFlags)
-
Fills

`nop`
flags. Sets`outreadflags[i]`
to 1 if`op[i]`
can be read from, and to 0 if not.
void NpyIter_GetWriteFlags([NpyIter](#c.NpyIter)*iter, char *outwriteflags)[#](#c.NpyIter_GetWriteFlags)
-
Fills

`nop`
flags. Sets`outwriteflags[i]`
to 1 if`op[i]`
can be written to, and to 0 if not.
int NpyIter_CreateCompatibleStrides([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)itemsize,[npy_intp](dtype.html#c.npy_intp)*outstrides)[#](#c.NpyIter_CreateCompatibleStrides)
-
Builds a set of strides which are the same as the strides of an output array created using the

flag, where NULL was passed for op_axes. This is for data packed contiguously, but not necessarily in C or Fortran order. This should be used together with`NPY_ITER_ALLOCATE`
and`NpyIter_GetShape`
with the flag`NpyIter_GetNDim`
passed into the constructor.`NPY_ITER_MULTI_INDEX`
A use case for this function is to match the shape and layout of the iterator and tack on one or more dimensions. For example, in order to generate a vector per input value for a numerical gradient, you pass in ndim*itemsize for itemsize, then add another dimension to the end with size ndim and stride itemsize. To do the Hessian matrix, you do the same thing but add two dimensions, or take advantage of the symmetry and pack it into 1 dimension with a particular encoding.

This function may only be called if the iterator is tracking a multi-index and if

was used to prevent an axis from being iterated in reverse order.`NPY_ITER_DONT_NEGATE_STRIDES`
If an array is created with this method, simply adding ‘itemsize’ for each iteration will traverse the new array matching the iterator.

Returns

`NPY_SUCCEED`
or`NPY_FAIL`
.
[npy_bool](dtype.html#c.npy_bool)NpyIter_IsFirstVisit([NpyIter](#c.NpyIter)*iter, int iop)[#](#c.NpyIter_IsFirstVisit)
-
New in version 1.7.

Checks to see whether this is the first time the elements of the specified reduction operand which the iterator points at are being seen for the first time. The function returns a reasonable answer for reduction operands and when buffering is disabled. The answer may be incorrect for buffered non-reduction operands.

This function is intended to be used in EXTERNAL_LOOP mode only, and will produce some wrong answers when that mode is not enabled.

If this function returns true, the caller should also check the inner loop stride of the operand, because if that stride is 0, then only the first element of the innermost external loop is being visited for the first time.

*WARNING*: For performance reasons, ‘iop’ is not bounds-checked, it is not confirmed that ‘iop’ is actually a reduction operand, and it is not confirmed that EXTERNAL_LOOP mode is enabled. These checks are the responsibility of the caller, and should be done outside of any inner loops.
## Functions For Iteration[#](#functions-for-iteration)
[NpyIter_IterNextFunc](#c.NpyIter_IterNextFunc)*NpyIter_GetIterNext([NpyIter](#c.NpyIter)*iter, char **errmsg)[#](#c.NpyIter_GetIterNext)
-
Returns a function pointer for iteration. A specialized version of the function pointer may be calculated by this function instead of being stored in the iterator structure. Thus, to get good performance, it is required that the function pointer be saved in a variable rather than retrieved for each loop iteration.

Returns NULL if there is an error. If errmsg is non-NULL, no Python exception is set when

`NPY_FAIL`
is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL.The typical looping construct is as follows.

NpyIter_IterNextFunc *iternext = NpyIter_GetIterNext(iter, NULL); char** dataptr = NpyIter_GetDataPtrArray(iter); do { /* use the addresses dataptr[0], ... dataptr[nop-1] */ } while(iternext(iter));
When

is specified, the typical inner loop construct is as follows.`NPY_ITER_EXTERNAL_LOOP`
NpyIter_IterNextFunc *iternext = NpyIter_GetIterNext(iter, NULL); char** dataptr = NpyIter_GetDataPtrArray(iter); npy_intp* stride = NpyIter_GetInnerStrideArray(iter); npy_intp* size_ptr = NpyIter_GetInnerLoopSizePtr(iter), size; npy_intp iop, nop = NpyIter_GetNOp(iter); do { size = *size_ptr; while (size--) { /* use the addresses dataptr[0], ... dataptr[nop-1] */ for (iop = 0; iop < nop; ++iop) { dataptr[iop] += stride[iop]; } } } while (iternext());
Observe that we are using the dataptr array inside the iterator, not copying the values to a local temporary. This is possible because when

`iternext()`
is called, these pointers will be overwritten with fresh values, not incrementally updated.If a compile-time fixed buffer is being used (both flags

and`NPY_ITER_BUFFERED`
), the inner size may be used as a signal as well. The size is guaranteed to become zero when`NPY_ITER_EXTERNAL_LOOP`
`iternext()`
returns false, enabling the following loop construct. Note that if you use this construct, you should not passas a flag, because it will cause larger sizes under some circumstances.`NPY_ITER_GROWINNER`
/* The constructor should have buffersize passed as this value */ #define FIXED_BUFFER_SIZE 1024 NpyIter_IterNextFunc *iternext = NpyIter_GetIterNext(iter, NULL); char **dataptr = NpyIter_GetDataPtrArray(iter); npy_intp *stride = NpyIter_GetInnerStrideArray(iter); npy_intp *size_ptr = NpyIter_GetInnerLoopSizePtr(iter), size; npy_intp i, iop, nop = NpyIter_GetNOp(iter); /* One loop with a fixed inner size */ size = *size_ptr; while (size == FIXED_BUFFER_SIZE) { /* * This loop could be manually unrolled by a factor * which divides into FIXED_BUFFER_SIZE */ for (i = 0; i < FIXED_BUFFER_SIZE; ++i) { /* use the addresses dataptr[0], ... dataptr[nop-1] */ for (iop = 0; iop < nop; ++iop) { dataptr[iop] += stride[iop]; } } iternext(); size = *size_ptr; } /* Finish-up loop with variable inner size */ if (size > 0) do { size = *size_ptr; while (size--) { /* use the addresses dataptr[0], ... dataptr[nop-1] */ for (iop = 0; iop < nop; ++iop) { dataptr[iop] += stride[iop]; } } } while (iternext());
[NpyIter_GetMultiIndexFunc](#c.NpyIter_GetMultiIndexFunc)*NpyIter_GetGetMultiIndex([NpyIter](#c.NpyIter)*iter, char **errmsg)[#](#c.NpyIter_GetGetMultiIndex)
-
Returns a function pointer for getting the current multi-index of the iterator. Returns NULL if the iterator is not tracking a multi-index. It is recommended that this function pointer be cached in a local variable before the iteration loop.

Returns NULL if there is an error. If errmsg is non-NULL, no Python exception is set when

`NPY_FAIL`
is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL.
char **NpyIter_GetDataPtrArray([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetDataPtrArray)
-
This gives back a pointer to the

`nop`
data pointers. Ifwas not specified, each data pointer points to the current data item of the iterator. If no inner iteration was specified, it points to the first data item of the inner loop.`NPY_ITER_EXTERNAL_LOOP`
This pointer may be cached before the iteration loop, calling

`iternext`
will not change it. This function may be safely called without holding the Python GIL.
char **NpyIter_GetInitialDataPtrArray([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetInitialDataPtrArray)
-
Gets the array of data pointers directly into the arrays (never into the buffers), corresponding to iteration index 0.

These pointers are different from the pointers accepted by

`NpyIter_ResetBasePointers`
, because the direction along some axes may have been reversed.This function may be safely called without holding the Python GIL.

[npy_intp](dtype.html#c.npy_intp)*NpyIter_GetIndexPtr([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetIndexPtr)
-
This gives back a pointer to the index being tracked, or NULL if no index is being tracked. It is only usable if one of the flags

or`NPY_ITER_C_INDEX`
were specified during construction.`NPY_ITER_F_INDEX`
When the flag [ NPY_ITER_EXTERNAL_LOOP](#c.NPY_ITER_EXTERNAL_LOOP) is used, the code
needs to know the parameters for doing the inner loop. These
functions provide that information.

[npy_intp](dtype.html#c.npy_intp)*NpyIter_GetInnerStrideArray([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetInnerStrideArray)
-
Returns a pointer to an array of the

`nop`
strides, one for each iterated object, to be used by the inner loop.This pointer may be cached before the iteration loop, calling

`iternext`
will not change it. This function may be safely called without holding the Python GIL.**WARNING**: While the pointer may be cached, its values may change if the iterator is buffered.
[npy_intp](dtype.html#c.npy_intp)*NpyIter_GetInnerLoopSizePtr([NpyIter](#c.NpyIter)*iter)[#](#c.NpyIter_GetInnerLoopSizePtr)
-
Returns a pointer to the number of iterations the inner loop should execute.

This address may be cached before the iteration loop, calling

`iternext`
will not change it. The value itself may change during iteration, in particular if buffering is enabled. This function may be safely called without holding the Python GIL.
void NpyIter_GetInnerFixedStrideArray([NpyIter](#c.NpyIter)*iter,[npy_intp](dtype.html#c.npy_intp)*out_strides)[#](#c.NpyIter_GetInnerFixedStrideArray)
-
Gets an array of strides which are fixed, or will not change during the entire iteration. For strides that may change, the value NPY_MAX_INTP is placed in the stride.

Once the iterator is prepared for iteration (after a reset if

was used), call this to get the strides which may be used to select a fast inner loop function. For example, if the stride is 0, that means the inner loop can always load its value into a variable once, then use the variable throughout the loop, or if the stride equals the itemsize, a contiguous version for that operand may be used.`NPY_ITER_DELAY_BUFALLOC`
This function may be safely called without holding the Python GIL.

## Converting from Previous NumPy Iterators[#](#converting-from-previous-numpy-iterators)
The old iterator API includes functions like PyArrayIter_Check, PyArray_Iter* and PyArray_ITER_*. The multi-iterator array includes PyArray_MultiIter*, PyArray_Broadcast, and PyArray_RemoveSmallest. The new iterator design replaces all of this functionality with a single object and associated API. One goal of the new API is that all uses of the existing iterator should be replaceable with the new iterator without significant effort. In 1.6, the major exception to this is the neighborhood iterator, which does not have corresponding features in this iterator.

Here is a conversion table for which functions to use with the new iterator:

|
`axes`
parameter or
Iterator flag
`NPY_ITER_EXTERNAL_LOOP`
|
|
Will need to add this in Python exposure

|
Function pointer from

|
Return value of

|
|
Function pointer from

|
|
Return value of

|
Handled by

|
Iterator flag

|
|
Iterator flag

|# NumPy core libraries[#](#numpy-core-libraries)
Starting from numpy 1.3.0, we are working on separating the pure C, “computational” code from the python dependent code. The goal is twofolds: making the code cleaner, and enabling code reuse by other extensions outside numpy (scipy, etc…).

## NumPy core math library[#](#numpy-core-math-library)
The numpy core math library (‘npymath’) is a first step in this direction. This
library contains most math-related C99 functionality, which can be used on
platforms where C99 is not well supported. The core math functions have the
same API as the C99 ones, except for the `npy_*`
prefix.

The available functions are defined in `<numpy/npy_math.h>`
- please refer to
this header when in doubt.

Note

An effort is underway to make `npymath`
smaller (since C99 compatibility
of compilers has improved over time) and more easily vendorable or usable as
a header-only dependency. That will avoid problems with shipping a static
library built with a compiler which may not match the compiler used by a
downstream package or end user. See
[gh-20880](https://github.com/numpy/numpy/issues/20880) for details.

### Floating point classification[#](#floating-point-classification)
NPY_NAN[#](#c.NPY_NAN)
-
This macro is defined to a NaN (Not a Number), and is guaranteed to have the signbit unset (‘positive’ NaN). The corresponding single and extension precision macro are available with the suffix F and L.

NPY_INFINITY[#](#c.NPY_INFINITY)
-
This macro is defined to a positive inf. The corresponding single and extension precision macro are available with the suffix F and L.

NPY_PZERO[#](#c.NPY_PZERO)
-
This macro is defined to positive zero. The corresponding single and extension precision macro are available with the suffix F and L.

NPY_NZERO[#](#c.NPY_NZERO)
-
This macro is defined to negative zero (that is with the sign bit set). The corresponding single and extension precision macro are available with the suffix F and L.

npy_isnan(x)[#](#c.npy_isnan)
-
This is an alias for C99 isnan: works for single, double and extended precision, and return a non 0 value if x is a NaN.

npy_isfinite(x)[#](#c.npy_isfinite)
-
This is an alias for C99 isfinite: works for single, double and extended precision, and return a non 0 value if x is neither a NaN nor an infinity.

npy_isinf(x)[#](#c.npy_isinf)
-
This is an alias for C99 isinf: works for single, double and extended precision, and return a non 0 value if x is infinite (positive and negative).

npy_signbit(x)[#](#c.npy_signbit)
-
This is an alias for C99 signbit: works for single, double and extended precision, and return a non 0 value if x has the signbit set (that is the number is negative).

npy_copysign(x, y)[#](#c.npy_copysign)
-
This is an alias for C99 copysign: return x with the same sign as y. Works for any value, including inf and nan. Single and extended precisions are available with suffix f and l.

### Useful math constants[#](#useful-math-constants)
The following math constants are available in `npy_math.h`
. Single
and extended precision are also available by adding the `f`
and
`l`
suffixes respectively.

NPY_E[#](#c.NPY_E)
-
Base of natural logarithm (\(e\))

NPY_LOG2E[#](#c.NPY_LOG2E)
-
Logarithm to base 2 of the Euler constant (\(\frac{\ln(e)}{\ln(2)}\))

NPY_LOG10E[#](#c.NPY_LOG10E)
-
Logarithm to base 10 of the Euler constant (\(\frac{\ln(e)}{\ln(10)}\))

NPY_LOGE2[#](#c.NPY_LOGE2)
-
Natural logarithm of 2 (\(\ln(2)\))

NPY_LOGE10[#](#c.NPY_LOGE10)
-
Natural logarithm of 10 (\(\ln(10)\))

NPY_PI[#](#c.NPY_PI)
-
Pi (\(\pi\))

NPY_PI_2[#](#c.NPY_PI_2)
-
Pi divided by 2 (\(\frac{\pi}{2}\))

NPY_PI_4[#](#c.NPY_PI_4)
-
Pi divided by 4 (\(\frac{\pi}{4}\))

NPY_1_PI[#](#c.NPY_1_PI)
-
Reciprocal of pi (\(\frac{1}{\pi}\))

NPY_2_PI[#](#c.NPY_2_PI)
-
Two times the reciprocal of pi (\(\frac{2}{\pi}\))

NPY_EULER[#](#c.NPY_EULER)
-
The Euler constant
-
\(\lim_{n\rightarrow\infty}({\sum_{k=1}^n{\frac{1}{k}}-\ln n})\)

### Low-level floating point manipulation[#](#low-level-floating-point-manipulation)
Those can be useful for precise floating point comparison.

double npy_nextafter(double x, double y)[#](#c.npy_nextafter)
-
This is an alias to C99 nextafter: return next representable floating point value from x in the direction of y. Single and extended precisions are available with suffix f and l.

double npy_spacing(double x)[#](#c.npy_spacing)
-
This is a function equivalent to Fortran intrinsic. Return distance between x and next representable floating point value from x, e.g. spacing(1) == eps. spacing of nan and +/- inf return nan. Single and extended precisions are available with suffix f and l.

void npy_set_floatstatus_divbyzero()[#](#c.npy_set_floatstatus_divbyzero)
-
Set the divide by zero floating point exception

void npy_set_floatstatus_overflow()[#](#c.npy_set_floatstatus_overflow)
-
Set the overflow floating point exception

void npy_set_floatstatus_underflow()[#](#c.npy_set_floatstatus_underflow)
-
Set the underflow floating point exception

void npy_set_floatstatus_invalid()[#](#c.npy_set_floatstatus_invalid)
-
Set the invalid floating point exception

int npy_get_floatstatus()[#](#c.npy_get_floatstatus)
-
Get floating point status. Returns a bitmask with following possible flags:

NPY_FPE_DIVIDEBYZERO

NPY_FPE_OVERFLOW

NPY_FPE_UNDERFLOW

NPY_FPE_INVALID

Note that

is preferable as it prevents aggressive compiler optimizations reordering the call relative to the code setting the status, which could lead to incorrect results.`npy_get_floatstatus_barrier`
int npy_get_floatstatus_barrier(char*)[#](#c.npy_get_floatstatus_barrier)
-
Get floating point status. A pointer to a local variable is passed in to prevent aggressive compiler optimizations from reordering this function call relative to the code setting the status, which could lead to incorrect results.

Returns a bitmask with following possible flags:

NPY_FPE_DIVIDEBYZERO

NPY_FPE_OVERFLOW

NPY_FPE_UNDERFLOW

NPY_FPE_INVALID

New in version 1.15.0.

int npy_clear_floatstatus()[#](#c.npy_clear_floatstatus)
-
Clears the floating point status. Returns the previous status mask.

Note that

is preferable as it prevents aggressive compiler optimizations reordering the call relative to the code setting the status, which could lead to incorrect results.`npy_clear_floatstatus_barrier`
int npy_clear_floatstatus_barrier(char*)[#](#c.npy_clear_floatstatus_barrier)
-
Clears the floating point status. A pointer to a local variable is passed in to prevent aggressive compiler optimizations from reordering this function call. Returns the previous status mask.

New in version 1.15.0.

### Complex functions[#](#complex-functions)
C99-like complex functions have been added. Those can be used if you wish to implement portable C extensions. Since we still support platforms without C99 complex type (most importantly Windows, where MSVC doesn’t support C99 complex types as of Nov 2022), you need to restrict to C90-compatible syntax, e.g.:

```
/* a = 1 + 2i \*/
npy_complex a = npy_cpack(1, 2);
npy_complex b;
b = npy_log(a);
```
### Linking against the core math library in an extension[#](#linking-against-the-core-math-library-in-an-extension)
To use the core math library that NumPy ships as a static library in your own Python extension, you need to add the npymath compile and link options to your extension. The exact steps to take will depend on the build system you are using. The generic steps to take are:

Add the numpy include directory (= the value of

`np.get_include()`
) to your include directories,
The

`npymath`
static library resides in the`lib`
directory right next to numpy’s include directory (i.e.,`pathlib.Path(np.get_include()) / '..' / 'lib'`
). Add that to your library search directories,
Link with

`libnpymath`
and`libm`
.
Note

Keep in mind that when you are cross compiling, you must use the `numpy`
for the platform you are building for, not the native one for the build
machine. Otherwise you pick up a static library built for the wrong
architecture.

When you build with `numpy.distutils`
(deprecated), then use this in your `setup.py`
:

>>> from numpy.distutils.misc_util import get_info >>> info = get_info('npymath') >>> _ = config.add_extension('foo', sources=['foo.c'], extra_info=info)
In other words, the usage of `info`
is exactly the same as when using
`blas_info`
and co.

When you are building with [Meson](https://mesonbuild.com), use:

```
# Note that this will get easier in the future, when Meson has
# support for numpy built in; most of this can then be replaced
# by `dependency('numpy')`.
incdir_numpy = run_command(py3,
[
'-c',
'import os; os.chdir(".."); import numpy; print(numpy.get_include())'
],
check: true
).stdout().strip()
inc_np = include_directories(incdir_numpy)
cc = meson.get_compiler('c')
npymath_path = incdir_numpy / '..' / 'lib'
npymath_lib = cc.find_library('npymath', dirs: npymath_path)
py3.extension_module('module_name',
...
include_directories: inc_np,
dependencies: [npymath_lib],
```
### Half-precision functions[#](#half-precision-functions)
The header file `<numpy/halffloat.h>`
provides functions to work with
IEEE 754-2008 16-bit floating point values. While this format is
not typically used for numerical computations, it is useful for
storing values which require floating point but do not need much precision.
It can also be used as an educational tool to understand the nature
of floating point round-off error.

Like for other types, NumPy includes a typedef npy_half for the 16 bit float. Unlike for most of the other types, you cannot use this as a normal type in C, since it is a typedef for npy_uint16. For example, 1.0 looks like 0x3c00 to C, and if you do an equality comparison between the different signed zeros, you will get -0.0 != 0.0 (0x8000 != 0x0000), which is incorrect.

For these reasons, NumPy provides an API to work with npy_half values
accessible by including `<numpy/halffloat.h>`
and linking to `npymath`
.
For functions that are not provided directly, such as the arithmetic
operations, the preferred method is to convert to float
or double and back again, as in the following example.

```
npy_half sum(int n, npy_half *array) {
float ret = 0;
while(n--) {
ret += npy_half_to_float(*array++);
}
return npy_float_to_half(ret);
}
```
External Links:

NPY_HALF_ZERO[#](#c.NPY_HALF_ZERO)
-
This macro is defined to positive zero.

NPY_HALF_PZERO[#](#c.NPY_HALF_PZERO)
-
This macro is defined to positive zero.

NPY_HALF_NZERO[#](#c.NPY_HALF_NZERO)
-
This macro is defined to negative zero.

NPY_HALF_ONE[#](#c.NPY_HALF_ONE)
-
This macro is defined to 1.0.

NPY_HALF_NEGONE[#](#c.NPY_HALF_NEGONE)
-
This macro is defined to -1.0.

NPY_HALF_PINF[#](#c.NPY_HALF_PINF)
-
This macro is defined to +inf.

NPY_HALF_NINF[#](#c.NPY_HALF_NINF)
-
This macro is defined to -inf.

NPY_HALF_NAN[#](#c.NPY_HALF_NAN)
-
This macro is defined to a NaN value, guaranteed to have its sign bit unset.

[npy_half](dtype.html#c.npy_half)npy_float_to_half(float f)[#](#c.npy_float_to_half)
-
Converts a single-precision float to a half-precision float. The value is rounded to the nearest representable half, with ties going to the nearest even. If the value is too small or too big, the system’s floating point underflow or overflow bit will be set.

[npy_half](dtype.html#c.npy_half)npy_double_to_half(double d)[#](#c.npy_double_to_half)
-
Converts a double-precision float to a half-precision float. The value is rounded to the nearest representable half, with ties going to the nearest even. If the value is too small or too big, the system’s floating point underflow or overflow bit will be set.

int npy_half_eq_nonan([npy_half](dtype.html#c.npy_half)h1,[npy_half](dtype.html#c.npy_half)h2)[#](#c.npy_half_eq_nonan)
-
Compares two half-precision floats that are known to not be NaN (h1 == h2). If a value is NaN, the result is undefined.

int npy_half_lt_nonan([npy_half](dtype.html#c.npy_half)h1,[npy_half](dtype.html#c.npy_half)h2)[#](#c.npy_half_lt_nonan)
-
Compares two half-precision floats that are known to not be NaN (h1 < h2). If a value is NaN, the result is undefined.

int npy_half_le_nonan([npy_half](dtype.html#c.npy_half)h1,[npy_half](dtype.html#c.npy_half)h2)[#](#c.npy_half_le_nonan)
-
Compares two half-precision floats that are known to not be NaN (h1 <= h2). If a value is NaN, the result is undefined.

int npy_half_iszero([npy_half](dtype.html#c.npy_half)h)[#](#c.npy_half_iszero)
-
Tests whether the half-precision float has a value equal to zero. This may be slightly faster than calling npy_half_eq(h, NPY_ZERO).

int npy_half_isfinite([npy_half](dtype.html#c.npy_half)h)[#](#c.npy_half_isfinite)
-
Tests whether the half-precision float is finite (not NaN or Inf).

[npy_half](dtype.html#c.npy_half)npy_half_copysign([npy_half](dtype.html#c.npy_half)x,[npy_half](dtype.html#c.npy_half)y)[#](#c.npy_half_copysign)
-
Returns the value of x with the sign bit copied from y. Works for any value, including Inf and NaN.

[npy_half](dtype.html#c.npy_half)npy_half_spacing([npy_half](dtype.html#c.npy_half)h)[#](#c.npy_half_spacing)
-
This is the same for half-precision float as npy_spacing and npy_spacingf described in the low-level floating point section.

[npy_half](dtype.html#c.npy_half)npy_half_nextafter([npy_half](dtype.html#c.npy_half)x,[npy_half](dtype.html#c.npy_half)y)[#](#c.npy_half_nextafter)
-
This is the same for half-precision float as npy_nextafter and npy_nextafterf described in the low-level floating point section.

[npy_uint16](dtype.html#c.npy_uint16)npy_floatbits_to_halfbits([npy_uint32](dtype.html#c.npy_uint32)f)[#](#c.npy_floatbits_to_halfbits)
-
Low-level function which converts a 32-bit single-precision float, stored as a uint32, into a 16-bit half-precision float.

[npy_uint16](dtype.html#c.npy_uint16)npy_doublebits_to_halfbits([npy_uint64](dtype.html#c.npy_uint64)d)[#](#c.npy_doublebits_to_halfbits)
-
Low-level function which converts a 64-bit double-precision float, stored as a uint64, into a 16-bit half-precision float.

[npy_uint32](dtype.html#c.npy_uint32)npy_halfbits_to_floatbits([npy_uint16](dtype.html#c.npy_uint16)h)[#](#c.npy_halfbits_to_floatbits)
-
Low-level function which converts a 16-bit half-precision float into a 32-bit single-precision float, stored as a uint32.

[npy_uint64](dtype.html#c.npy_uint64)npy_halfbits_to_doublebits([npy_uint16](dtype.html#c.npy_uint16)h)[#](#c.npy_halfbits_to_doublebits)
-
Low-level function which converts a 16-bit half-precision float into a 64-bit double-precision float, stored as a uint64.# Datetimes and Timedeltas[#](#datetimes-and-timedeltas)
New in version 1.7.0.

Starting in NumPy 1.7, there are core array data types which natively
support datetime functionality. The data type is called [ datetime64](arrays.scalars.html#numpy.datetime64),
so named because

[is already taken by the Python standard library.](https://docs.python.org/3/library/datetime.html#datetime.datetime)
`datetime`
## Datetime64 Conventions and Assumptions[#](#datetime64-conventions-and-assumptions)
Similar to the Python [ date](https://docs.python.org/3/library/datetime.html#datetime.date) class, dates are expressed in the current
Gregorian Calendar, indefinitely extended both in the future and in the past.

[[1]](#id3)Contrary to Python
[, which supports only years in the 1 AD — 9999 AD range,](https://docs.python.org/3/library/datetime.html#datetime.date)
`date`
[allows also for dates BC; years BC follow the](arrays.scalars.html#numpy.datetime64)
`datetime64`
[Astronomical year numbering](https://en.wikipedia.org/wiki/Astronomical_year_numbering)convention, i.e. year 2 BC is numbered −1, year 1 BC is numbered 0, year 1 AD is numbered 1.
Time instants, say 16:23:32.234, are represented counting hours, minutes,
seconds and fractions from midnight: i.e. 00:00:00.000 is midnight, 12:00:00.000
is noon, etc. Each calendar day has exactly 86400 seconds. This is a “naive”
time, with no explicit notion of timezones or specific time scales (UT1, UTC, TAI,
etc.). [[2]](#id4)

## Basic Datetimes[#](#basic-datetimes)
The most basic way to create datetimes is from strings in ISO 8601 date
or datetime format. It is also possible to create datetimes from an integer by
offset relative to the Unix epoch (00:00:00 UTC on 1 January 1970).
The unit for internal storage is automatically selected from the
form of the string, and can be either a [date unit](#arrays-dtypes-dateunits) or a
[time unit](#arrays-dtypes-timeunits). The date units are years (‘Y’),
months (‘M’), weeks (‘W’), and days (‘D’), while the time units are
hours (‘h’), minutes (‘m’), seconds (‘s’), milliseconds (‘ms’), and
some additional SI-prefix seconds-based units. The [ datetime64](arrays.scalars.html#numpy.datetime64) data type
also accepts the string “NAT”, in any combination of lowercase/uppercase
letters, for a “Not A Time” value.

Example

A simple ISO date:

```
>>> np.datetime64('2005-02-25')
numpy.datetime64('2005-02-25')
```
From an integer and a date unit, 1 year since the UNIX epoch:

```
>>> np.datetime64(1, 'Y')
numpy.datetime64('1971')
```
Using months for the unit:

```
>>> np.datetime64('2005-02')
numpy.datetime64('2005-02')
```
Specifying just the month, but forcing a ‘days’ unit:

```
>>> np.datetime64('2005-02', 'D')
numpy.datetime64('2005-02-01')
```
From a date and time:

```
>>> np.datetime64('2005-02-25T03:30')
numpy.datetime64('2005-02-25T03:30')
```
NAT (not a time):

```
>>> np.datetime64('nat')
numpy.datetime64('NaT')
```
When creating an array of datetimes from a string, it is still possible to automatically select the unit from the inputs, by using the datetime type with generic units.

Example

```
>>> np.array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64')
array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64[D]')
```
```
>>> np.array(['2001-01-01T12:00', '2002-02-03T13:56:03.172'], dtype='datetime64')
array(['2001-01-01T12:00:00.000', '2002-02-03T13:56:03.172'],
dtype='datetime64[ms]')
```
An array of datetimes can be constructed from integers representing POSIX timestamps with the given unit.

Example

```
>>> np.array([0, 1577836800], dtype='datetime64[s]')
array(['1970-01-01T00:00:00', '2020-01-01T00:00:00'],
dtype='datetime64[s]')
```
```
>>> np.array([0, 1577836800000]).astype('datetime64[ms]')
array(['1970-01-01T00:00:00.000', '2020-01-01T00:00:00.000'],
dtype='datetime64[ms]')
```
The datetime type works with many common NumPy functions, for
example [ arange](generated/numpy.arange.html#numpy.arange) can be used to generate ranges of dates.

Example

All the dates for one month:

```
>>> np.arange('2005-02', '2005-03', dtype='datetime64[D]')
array(['2005-02-01', '2005-02-02', '2005-02-03', '2005-02-04',
'2005-02-05', '2005-02-06', '2005-02-07', '2005-02-08',
'2005-02-09', '2005-02-10', '2005-02-11', '2005-02-12',
'2005-02-13', '2005-02-14', '2005-02-15', '2005-02-16',
'2005-02-17', '2005-02-18', '2005-02-19', '2005-02-20',
'2005-02-21', '2005-02-22', '2005-02-23', '2005-02-24',
'2005-02-25', '2005-02-26', '2005-02-27', '2005-02-28'],
dtype='datetime64[D]')
```
The datetime object represents a single moment in time. If two datetimes have different units, they may still be representing the same moment of time, and converting from a bigger unit like months to a smaller unit like days is considered a ‘safe’ cast because the moment of time is still being represented exactly.

Example

```
>>> np.datetime64('2005') == np.datetime64('2005-01-01')
True
```
```
>>> np.datetime64('2010-03-14T15') == np.datetime64('2010-03-14T15:00:00.00')
True
```
Deprecated since version 1.11.0: NumPy does not store timezone information. For backwards compatibility, datetime64 still parses timezone offsets, which it handles by converting to UTC±00:00 (Zulu time). This behaviour is deprecated and will raise an error in the future.

## Datetime and Timedelta Arithmetic[#](#datetime-and-timedelta-arithmetic)
NumPy allows the subtraction of two datetime values, an operation which
produces a number with a time unit. Because NumPy doesn’t have a physical
quantities system in its core, the [ timedelta64](arrays.scalars.html#numpy.timedelta64) data type was created
to complement

[. The arguments for](arrays.scalars.html#numpy.datetime64)
`datetime64`
[are a number, to represent the number of units, and a date/time unit, such as (D)ay, (M)onth, (Y)ear, (h)ours, (m)inutes, or (s)econds. The](arrays.scalars.html#numpy.timedelta64)
`timedelta64`
[data type also accepts the string “NAT” in place of the number for a “Not A Time” value.](arrays.scalars.html#numpy.timedelta64)
`timedelta64`
Example

```
>>> np.timedelta64(1, 'D')
numpy.timedelta64(1,'D')
```
```
>>> np.timedelta64(4, 'h')
numpy.timedelta64(4,'h')
```
```
>>> np.timedelta64('nAt')
numpy.timedelta64('NaT')
```
Datetimes and Timedeltas work together to provide ways for simple datetime calculations.

Example

```
>>> np.datetime64('2009-01-01') - np.datetime64('2008-01-01')
numpy.timedelta64(366,'D')
```
```
>>> np.datetime64('2009') + np.timedelta64(20, 'D')
numpy.datetime64('2009-01-21')
```
```
>>> np.datetime64('2011-06-15T00:00') + np.timedelta64(12, 'h')
numpy.datetime64('2011-06-15T12:00')
```
```
>>> np.timedelta64(1,'W') / np.timedelta64(1,'D')
7.0
```
```
>>> np.timedelta64(1,'W') % np.timedelta64(10,'D')
numpy.timedelta64(7,'D')
```
```
>>> np.datetime64('nat') - np.datetime64('2009-01-01')
numpy.timedelta64('NaT','D')
```
```
>>> np.datetime64('2009-01-01') + np.timedelta64('nat')
numpy.datetime64('NaT')
```
There are two Timedelta units (‘Y’, years and ‘M’, months) which are treated specially, because how much time they represent changes depending on when they are used. While a timedelta day unit is equivalent to 24 hours, there is no way to convert a month unit into days, because different months have different numbers of days.

Example

```
>>> a = np.timedelta64(1, 'Y')
```
```
>>> np.timedelta64(a, 'M')
numpy.timedelta64(12,'M')
```
```
>>> np.timedelta64(a, 'D')
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
TypeError: Cannot cast NumPy timedelta64 scalar from metadata [Y] to [D] according to the rule 'same_kind'
```
## Datetime Units[#](#datetime-units)
The Datetime and Timedelta data types support a large number of time units, as well as generic units which can be coerced into any of the other units based on input data.

Datetimes are always stored with an epoch of 1970-01-01T00:00. This means the supported dates are always a symmetric interval around the epoch, called “time span” in the table below.

The length of the span is the range of a 64-bit integer times the length of the date or unit. For example, the time span for ‘W’ (week) is exactly 7 times longer than the time span for ‘D’ (day), and the time span for ‘D’ (day) is exactly 24 times longer than the time span for ‘h’ (hour).

Here are the date units:

Code

|
Meaning

|
Time span (relative)

|
Time span (absolute)

|
---|---|---|---|
Y

|
year

|
+/- 9.2e18 years

|
[9.2e18 BC, 9.2e18 AD]

|
M

|
month

|
+/- 7.6e17 years

|
[7.6e17 BC, 7.6e17 AD]

|
W

|
week

|
+/- 1.7e17 years

|
[1.7e17 BC, 1.7e17 AD]

|
D

|
day

|
+/- 2.5e16 years

|
[2.5e16 BC, 2.5e16 AD]

|
And here are the time units:

Code

|
Meaning

|
Time span (relative)

|
Time span (absolute)

|
---|---|---|---|
h

|
hour

|
+/- 1.0e15 years

|
[1.0e15 BC, 1.0e15 AD]

|
m

|
minute

|
+/- 1.7e13 years

|
[1.7e13 BC, 1.7e13 AD]

|
s

|
second

|
+/- 2.9e11 years

|
[2.9e11 BC, 2.9e11 AD]

|
ms

|
millisecond

|
+/- 2.9e8 years

|
[ 2.9e8 BC, 2.9e8 AD]

|
us / μs

|
microsecond

|
+/- 2.9e5 years

|
[290301 BC, 294241 AD]

|
ns

|
nanosecond

|
+/- 292 years

|
[ 1678 AD, 2262 AD]

|
ps

|
picosecond

|
+/- 106 days

|
[ 1969 AD, 1970 AD]

|
fs

|
femtosecond

|
+/- 2.6 hours

|
[ 1969 AD, 1970 AD]

|
as

|
attosecond

|
+/- 9.2 seconds

|
[ 1969 AD, 1970 AD]

|
## Business Day Functionality[#](#business-day-functionality)
To allow the datetime to be used in contexts where only certain days of the week are valid, NumPy includes a set of “busday” (business day) functions.

The default for busday functions is that the only valid days are Monday through Friday (the usual business days). The implementation is based on a “weekmask” containing 7 Boolean flags to indicate valid days; custom weekmasks are possible that specify other sets of valid days.

The “busday” functions can additionally check a list of “holiday” dates, specific dates that are not valid days.

The function [ busday_offset](generated/numpy.busday_offset.html#numpy.busday_offset) allows you to apply offsets
specified in business days to datetimes with a unit of ‘D’ (day).

Example

```
>>> np.busday_offset('2011-06-23', 1)
numpy.datetime64('2011-06-24')
```
```
>>> np.busday_offset('2011-06-23', 2)
numpy.datetime64('2011-06-27')
```
When an input date falls on the weekend or a holiday,
[ busday_offset](generated/numpy.busday_offset.html#numpy.busday_offset) first applies a rule to roll the
date to a valid business day, then applies the offset. The
default rule is ‘raise’, which simply raises an exception.
The rules most typically used are ‘forward’ and ‘backward’.

Example

```
>>> np.busday_offset('2011-06-25', 2)
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
ValueError: Non-business day date in busday_offset
```
```
>>> np.busday_offset('2011-06-25', 0, roll='forward')
numpy.datetime64('2011-06-27')
```
```
>>> np.busday_offset('2011-06-25', 2, roll='forward')
numpy.datetime64('2011-06-29')
```
```
>>> np.busday_offset('2011-06-25', 0, roll='backward')
numpy.datetime64('2011-06-24')
```
```
>>> np.busday_offset('2011-06-25', 2, roll='backward')
numpy.datetime64('2011-06-28')
```
In some cases, an appropriate use of the roll and the offset is necessary to get a desired answer.

Example

The first business day on or after a date:

```
>>> np.busday_offset('2011-03-20', 0, roll='forward')
numpy.datetime64('2011-03-21')
>>> np.busday_offset('2011-03-22', 0, roll='forward')
numpy.datetime64('2011-03-22')
```
The first business day strictly after a date:

```
>>> np.busday_offset('2011-03-20', 1, roll='backward')
numpy.datetime64('2011-03-21')
>>> np.busday_offset('2011-03-22', 1, roll='backward')
numpy.datetime64('2011-03-23')
```
The function is also useful for computing some kinds of days like holidays. In Canada and the U.S., Mother’s day is on the second Sunday in May, which can be computed with a custom weekmask.

Example

```
>>> np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')
numpy.datetime64('2012-05-13')
```
When performance is important for manipulating many business dates
with one particular choice of weekmask and holidays, there is
an object [ busdaycalendar](generated/numpy.busdaycalendar.html#numpy.busdaycalendar) which stores the data necessary
in an optimized form.

### np.is_busday():[#](#np-is-busday)
To test a [ datetime64](arrays.scalars.html#numpy.datetime64) value to see if it is a valid day, use

[.](generated/numpy.is_busday.html#numpy.is_busday)
`is_busday`
Example

```
>>> np.is_busday(np.datetime64('2011-07-15')) # a Friday
True
>>> np.is_busday(np.datetime64('2011-07-16')) # a Saturday
False
>>> np.is_busday(np.datetime64('2011-07-16'), weekmask="Sat Sun")
True
>>> a = np.arange(np.datetime64('2011-07-11'), np.datetime64('2011-07-18'))
>>> np.is_busday(a)
array([ True, True, True, True, True, False, False])
```
### np.busday_count():[#](#np-busday-count)
To find how many valid days there are in a specified range of datetime64
dates, use [ busday_count](generated/numpy.busday_count.html#numpy.busday_count):

Example

```
>>> np.busday_count(np.datetime64('2011-07-11'), np.datetime64('2011-07-18'))
5
>>> np.busday_count(np.datetime64('2011-07-18'), np.datetime64('2011-07-11'))
-5
```
If you have an array of datetime64 day values, and you want a count of how many of them are valid dates, you can do this:

Example

```
>>> a = np.arange(np.datetime64('2011-07-11'), np.datetime64('2011-07-18'))
>>> np.count_nonzero(np.is_busday(a))
5
```
### Custom Weekmasks[#](#custom-weekmasks)
Here are several examples of custom weekmask values. These examples specify the “busday” default of Monday through Friday being valid days.

Some examples:

```
# Positional sequences; positions are Monday through Sunday.
# Length of the sequence must be exactly 7.
weekmask = [1, 1, 1, 1, 1, 0, 0]
# list or other sequence; 0 == invalid day, 1 == valid day
weekmask = "1111100"
# string '0' == invalid day, '1' == valid day
# string abbreviations from this list: Mon Tue Wed Thu Fri Sat Sun
weekmask = "Mon Tue Wed Thu Fri"
# any amount of whitespace is allowed; abbreviations are case-sensitive.
weekmask = "MonTue Wed Thu\tFri"
```
## Datetime64 shortcomings[#](#datetime64-shortcomings)
The assumption that all days are exactly 86400 seconds long makes [ datetime64](arrays.scalars.html#numpy.datetime64)
largely compatible with Python

[and “POSIX time” semantics; therefore they all share the same well known shortcomings with respect to the UTC timescale and historical time determination. A brief non exhaustive summary is given below.](https://docs.python.org/3/library/datetime.html#module-datetime)
`datetime`
It is impossible to parse valid UTC timestamps occurring during a positive leap second.

Example

“2016-12-31 23:59:60 UTC” was a leap second, therefore “2016-12-31 23:59:60.450 UTC” is a valid timestamp which is not parseable by

:`datetime64`
>>> np.datetime64("2016-12-31 23:59:60.450") Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: Seconds out of range in datetime string "2016-12-31 23:59:60.450"
Timedelta64 computations between two UTC dates can be wrong by an integer number of SI seconds.

Example

Compute the number of SI seconds between “2021-01-01 12:56:23.423 UTC” and “2001-01-01 00:00:00.000 UTC”:

>>> ( ... np.datetime64("2021-01-01 12:56:23.423") ... - np.datetime64("2001-01-01") ... ) / np.timedelta64(1, "s") 631198583.423
however correct answer is

*631198588.423*SI seconds because there were 5 leap seconds between 2001 and 2021.
Timedelta64 computations for dates in the past do not return SI seconds, as one would expect.

Example

Compute the number of seconds between “000-01-01 UT” and “1600-01-01 UT”, where UT is

[universal time](https://en.wikipedia.org/wiki/Universal_Time):>>> a = np.datetime64("0000-01-01", "us") >>> b = np.datetime64("1600-01-01", "us") >>> b - a numpy.timedelta64(50491123200000000,'us')
The computed results,

*50491123200*seconds, is obtained as the elapsed number of days (*584388*) times*86400*seconds; this is the number of seconds of a clock in sync with earth rotation. The exact value in SI seconds can only be estimated, e.g using data published in[Measurement of the Earth’s rotation: 720 BC to AD 2015, 2016, Royal Society’s Proceedings A 472, by Stephenson et.al.](https://doi.org/10.1098/rspa.2016.0404). A sensible estimate is*50491112870 ± 90*seconds, with a difference of 10330 seconds.# Miscellaneous routines[#](#miscellaneous-routines)
## Performance tuning[#](#performance-tuning)
|
Set the size of the buffer used in ufuncs.

|
Return the size of the buffer used in ufuncs.

|
## Memory ranges[#](#memory-ranges)
|
Determine if two arrays share memory.

|
|
Determine if two arrays might share memory

|
|
Returns pointers to the end-points of an array.

|
## Array mixins[#](#array-mixins)
Mixin defining all operator special methods using __array_ufunc__.

|
## NumPy version comparison[#](#numpy-version-comparison)
|
Parse and compare numpy version strings.

|
## Utility[#](#utility)
Return the directory that contains the NumPy *.h header files.

|
|
Show libraries and system information on which NumPy was built and is being used

|
Print information about various resources in the system including available intrinsic support and BLAS/LAPACK library in use

|
|
Issues a DeprecationWarning, adds warning to

|
|
Deprecates a function and includes the deprecation in its docstring.

|
|
Broadcast the input shapes into a single shape.

|
## Matlab-like Functions[#](#matlab-like-functions)
|
Print the NumPy arrays in the given dictionary.

|
|
Display a message on a device.

|
### Exceptions and Warnings (`numpy.exceptions`
)[#](#exceptions-and-warnings-numpy-exceptions)
`numpy.exceptions`
General exceptions used by NumPy. Note that some exceptions may be module specific, such as linear algebra errors.

New in version NumPy: 1.25

The exceptions module is new in NumPy 1.25. Older exceptions remain available through the main NumPy namespace for compatibility.

#### Warnings[#](#warnings)
The warning raised when casting a complex dtype to a real dtype.

|
Visible deprecation warning.

|
#### Exceptions[#](#exceptions)
|
Axis supplied was invalid.

|
Multiple DTypes could not be converted to a common one.

|
max_work was exceeded.

|
### DType classes and utility (`numpy.dtypes`
)[#](#dtype-classes-and-utility-numpy-dtypes)
`numpy.dtypes`
This module is home to specific dtypes related functionality and their classes.
For more general information about dtypes, also see [ numpy.dtype](generated/numpy.dtype.html#numpy.dtype) and

[Data type objects (dtype)](arrays.dtypes.html#arrays-dtypes).
Similar to the builtin `types`
module, this submodule defines types (classes)
that are not widely used directly.

New in version NumPy: 1.25

The dtypes module is new in NumPy 1.25. Previously DType classes were only accessible indirectly.

#### DType classes[#](#dtype-classes)
The following are the classes of the corresponding NumPy dtype instances and
NumPy scalar types. The classes can be used in `isinstance`
checks and can
also be instantiated or used directly. Direct use of these classes is not
typical, since their scalar counterparts (e.g. `np.float64`
) or strings
like `"float64"`
can be used.

Group

|
DType class

|
---|---|
Boolean

|
|
Bit-sized integers

|
|
C-named integers (may be aliases)

|
|
Floating point

|
|
Complex

|
|
Strings

|
|
Times

|
|
Others

|
|# NumPy 1.15.0 Release Notes[#](#numpy-1-15-0-release-notes)
NumPy 1.15.0 is a release with an unusual number of cleanups, many deprecations of old functions, and improvements to many existing functions. Please read the detailed descriptions below to see if you are affected.

For testing, we have switched to pytest as a replacement for the no longer maintained nose framework. The old nose based interface remains for downstream projects who may still be using it.

The Python versions supported by this release are 2.7, 3.4-3.7. The wheels are linked with OpenBLAS v0.3.0, which should fix some of the linalg problems reported for NumPy 1.14.

## Highlights[#](#highlights)
NumPy has switched to pytest for testing.

A new

context manager.`numpy.printoptions`
Many improvements to the histogram functions.

Support for unicode field names in python 2.7.

Improved support for PyPy.

Fixes and improvements to

.`numpy.einsum`
## New functions[#](#new-functions)
and`numpy.gcd`
, to compute the greatest common divisor and least common multiple.`numpy.lcm`
, the`numpy.ma.stack`
array-joining function generalized to masked arrays.`numpy.stack`
function, an interface to`numpy.quantile`
`percentile`
without factors of 100
function, an interface to`numpy.nanquantile`
`nanpercentile`
without factors of 100
, a context manager that sets print options temporarily for the scope of the`numpy.printoptions`
`with`
block:>>> with np.printoptions(precision=2): ... print(np.array([2.0]) / 3) [0.67]
, a function to get the edges of the bins used by a histogram without needing to calculate the histogram.`numpy.histogram_bin_edges`
C functions

*npy_get_floatstatus_barrier*and*npy_clear_floatstatus_barrier*have been added to deal with compiler optimization changing the order of operations. See below for details.
## Deprecations[#](#deprecations)
Aliases of builtin

functions are deprecated, in favor of their unaliased`pickle`
`pickle.<func>`
names:*numpy.loads*
*numpy.core.numeric.load*
*numpy.core.numeric.loads*
*numpy.ma.loads*,*numpy.ma.dumps*
*numpy.ma.load*,*numpy.ma.dump*- these functions already failed on python 3 when called with a string.
Multidimensional indexing with anything but a tuple is deprecated. This means that the index list in

`ind = [slice(None), 0]; arr[ind]`
should be changed to a tuple, e.g.,`ind = [slice(None), 0]; arr[tuple(ind)]`
or`arr[(slice(None), 0)]`
. That change is necessary to avoid ambiguity in expressions such as`arr[[[0, 1], [0, 1]]]`
, currently interpreted as`arr[array([0, 1]), array([0, 1])]`
, that will be interpreted as`arr[array([[0, 1], [0, 1]])]`
in the future.
Imports from the following sub-modules are deprecated, they will be removed at some future date.

*numpy.testing.utils*
*numpy.testing.decorators*
*numpy.testing.nosetester*
*numpy.testing.noseclasses*
*numpy.core.umath_tests*
Giving a generator to

is now deprecated. This was undocumented behavior, but worked. Previously, it would calculate the sum of the generator expression. In the future, it might return a different result. Use`numpy.sum`
`np.sum(np.from_iter(generator))`
or the built-in Python`sum`
instead.
Users of the C-API should call

`PyArrayResolveWriteBackIfCopy`
or`PyArray_DiscardWritebackIfCopy`
on any array with the`WRITEBACKIFCOPY`
flag set, before deallocating the array. A deprecation warning will be emitted if those calls are not used when needed.
Users of

`nditer`
should use the nditer object as a context manager anytime one of the iterator operands is writeable, so that numpy can manage writeback semantics, or should call`it.close()`
. A*RuntimeWarning*may be emitted otherwise in these cases.
The

`normed`
argument of`np.histogram`
, deprecated long ago in 1.6.0, now emits a`DeprecationWarning`
.
## Future Changes[#](#future-changes)
NumPy 1.16 will drop support for Python 3.4.

NumPy 1.17 will drop support for Python 2.7.

## Compatibility notes[#](#compatibility-notes)
### Compiled testing modules renamed and made private[#](#compiled-testing-modules-renamed-and-made-private)
The following compiled modules have been renamed and made private:

`umath_tests`
->`_umath_tests`
`test_rational`
->`_rational_tests`
`multiarray_tests`
->`_multiarray_tests`
`struct_ufunc_test`
->`_struct_ufunc_tests`
`operand_flag_tests`
->`_operand_flag_tests`
The `umath_tests`
module is still available for backwards compatibility, but
will be removed in the future.

### The `NpzFile`
returned by `np.savez`
is now a `collections.abc.Mapping`
[#](#the-npzfile-returned-by-np-savez-is-now-a-collections-abc-mapping)
This means it behaves like a readonly dictionary, and has a new `.values()`
method and `len()`
implementation.

For python 3, this means that `.iteritems()`
, `.iterkeys()`
have been
deprecated, and `.keys()`
and `.items()`
now return views and not lists.
This is consistent with how the builtin `dict`
type changed between python 2
and python 3.

### Under certain conditions, `nditer`
must be used in a context manager[#](#under-certain-conditions-nditer-must-be-used-in-a-context-manager)
When using an [ numpy.nditer](../reference/generated/numpy.nditer.html#numpy.nditer) with the

`"writeonly"`
or `"readwrite"`
flags, there
are some circumstances where nditer doesn’t actually give you a view of the
writable array. Instead, it gives you a copy, and if you make changes to the
copy, nditer later writes those changes back into your actual array. Currently,
this writeback occurs when the array objects are garbage collected, which makes
this API error-prone on CPython and entirely broken on PyPy. Therefore,
`nditer`
should now be used as a context manager whenever it is used
with writeable arrays, e.g., `with np.nditer(...) as it: ...`
. You may also
explicitly call `it.close()`
for cases where a context manager is unusable,
for instance in generator expressions.### Numpy has switched to using pytest instead of nose for testing[#](#numpy-has-switched-to-using-pytest-instead-of-nose-for-testing)
The last nose release was 1.3.7 in June, 2015, and development of that tool has
ended, consequently NumPy has now switched to using pytest. The old decorators
and nose tools that were previously used by some downstream projects remain
available, but will not be maintained. The standard testing utilities,
`assert_almost_equal`
and such, are not be affected by this change except for
the nose specific functions `import_nose`
and `raises`
. Those functions are
not used in numpy, but are kept for downstream compatibility.

### Numpy no longer monkey-patches `ctypes`
with `__array_interface__`
[#](#numpy-no-longer-monkey-patches-ctypes-with-array-interface)
Previously numpy added `__array_interface__`
attributes to all the integer
types from `ctypes`
.

`np.ma.notmasked_contiguous`
and `np.ma.flatnotmasked_contiguous`
always return lists[#](#np-ma-notmasked-contiguous-and-np-ma-flatnotmasked-contiguous-always-return-lists)
This is the documented behavior, but previously the result could be any of slice, None, or list.

All downstream users seem to check for the `None`
result from
`flatnotmasked_contiguous`
and replace it with `[]`
. Those callers will
continue to work as before.

`np.squeeze`
restores old behavior of objects that cannot handle an `axis`
argument[#](#np-squeeze-restores-old-behavior-of-objects-that-cannot-handle-an-axis-argument)
Prior to version `1.7.0`
, [ numpy.squeeze](../reference/generated/numpy.squeeze.html#numpy.squeeze) did not have an

`axis`
argument and
all empty axes were removed by default. The incorporation of an `axis`
argument made it possible to selectively squeeze single or multiple empty axes,
but the old API expectation was not respected because axes could still be
selectively removed (silent success) from an object expecting all empty axes to
be removed. That silent, selective removal of empty axes for objects expecting
the old behavior has been fixed and the old behavior restored.### unstructured void array’s `.item`
method now returns a bytes object[#](#unstructured-void-array-s-item-method-now-returns-a-bytes-object)
`.item`
now returns a `bytes`
object instead of a buffer or byte array.
This may affect code which assumed the return value was mutable, which is no
longer the case.
`copy.copy`
and `copy.deepcopy`
no longer turn `masked`
into an array[#](#copy-copy-and-copy-deepcopy-no-longer-turn-masked-into-an-array)
Since `np.ma.masked`
is a readonly scalar, copying should be a no-op. These
functions now behave consistently with `np.copy()`
.

### Multifield Indexing of Structured Arrays will still return a copy[#](#multifield-indexing-of-structured-arrays-will-still-return-a-copy)
The change that multi-field indexing of structured arrays returns a view
instead of a copy is pushed back to 1.16. A new method
`numpy.lib.recfunctions.repack_fields`
has been introduced to help mitigate
the effects of this change, which can be used to write code compatible with
both numpy 1.15 and 1.16. For more information on how to update code to account
for this future change see the “accessing multiple fields” section of the
[user guide](https://docs.scipy.org/doc/numpy/user/basics.rec.html).

## C API changes[#](#c-api-changes)
### New functions `npy_get_floatstatus_barrier`
and `npy_clear_floatstatus_barrier`
[#](#new-functions-npy-get-floatstatus-barrier-and-npy-clear-floatstatus-barrier)
Functions `npy_get_floatstatus_barrier`
and `npy_clear_floatstatus_barrier`
have been added and should be used in place of the ```
npy_get_floatstatus``and
``npy_clear_status
```
functions. Optimizing compilers like GCC 8.1 and Clang
were rearranging the order of operations when the previous functions were used
in the ufunc SIMD functions, resulting in the floatstatus flags being checked
before the operation whose status we wanted to check was run. See [#10339](https://github.com/numpy/numpy/issues/10370).

### Changes to `PyArray_GetDTypeTransferFunction`
[#](#changes-to-pyarray-getdtypetransferfunction)
`PyArray_GetDTypeTransferFunction`
now defaults to using user-defined
`copyswapn`
/ `copyswap`
for user-defined dtypes. If this causes a
significant performance hit, consider implementing `copyswapn`
to reflect the
implementation of `PyArray_GetStridedCopyFn`
. See [#10898](https://github.com/numpy/numpy/pull/10898).
## New Features[#](#new-features)
`np.gcd`
and `np.lcm`
ufuncs added for integer and objects types[#](#np-gcd-and-np-lcm-ufuncs-added-for-integer-and-objects-types)
These compute the greatest common divisor, and lowest common multiple,
respectively. These work on all the numpy integer types, as well as the
builtin arbitrary-precision `Decimal`
and `long`
types.

### Support for cross-platform builds for iOS[#](#support-for-cross-platform-builds-for-ios)
The build system has been modified to add support for the
`_PYTHON_HOST_PLATFORM`
environment variable, used by `distutils`
when
compiling on one platform for another platform. This makes it possible to
compile NumPy for iOS targets.

This only enables you to compile NumPy for one specific platform at a time. Creating a full iOS-compatible NumPy package requires building for the 5 architectures supported by iOS (i386, x86_64, armv7, armv7s and arm64), and combining these 5 compiled builds products into a single “fat” binary.

`return_indices`
keyword added for `np.intersect1d`
[#](#return-indices-keyword-added-for-np-intersect1d)
New keyword `return_indices`
returns the indices of the two input arrays
that correspond to the common elements.

`np.quantile`
and `np.nanquantile`
[#](#np-quantile-and-np-nanquantile)
Like `np.percentile`
and `np.nanpercentile`
, but takes quantiles in [0, 1]
rather than percentiles in [0, 100]. `np.percentile`
is now a thin wrapper
around `np.quantile`
with the extra step of dividing by 100.

### Build system[#](#build-system)
Added experimental support for the 64-bit RISC-V architecture.

## Improvements[#](#improvements)
`np.einsum`
updates[#](#np-einsum-updates)
Syncs einsum path optimization tech between [ numpy](../reference/index.html#module-numpy) and

*opt_einsum*. In particular, the
*greedy*path has received many enhancements by @jcmgray. A full list of issues fixed are:
Arbitrary memory can be passed into the

*greedy*path. Fixes gh-11210.
The greedy path has been updated to contain more dynamic programming ideas preventing a large number of duplicate (and expensive) calls that figure out the actual pair contraction that takes place. Now takes a few seconds on several hundred input tensors. Useful for matrix product state theories.

Reworks the broadcasting dot error catching found in gh-11218 gh-10352 to be a bit earlier in the process.

Enhances the

*can_dot*functionality that previous missed an edge case (part of gh-11308).
`np.flip`
can operate over multiple axes[#](#np-flip-can-operate-over-multiple-axes)
`np.flip`
now accepts None, or tuples of int, in its `axis`
argument. If
axis is None, it will flip over all the axes.
`histogram`
and `histogramdd`
functions have moved to `np.lib.histograms`
[#](#histogram-and-histogramdd-functions-have-moved-to-np-lib-histograms)
These were originally found in `np.lib.function_base`
. They are still
available under their un-scoped `np.histogram(dd)`
names, and
to maintain compatibility, aliased at `np.lib.function_base.histogram(dd)`
.

Code that does `from np.lib.function_base import *`
will need to be updated
with the new location, and should consider not using `import *`
in future.

`histogram`
will accept NaN values when explicit bins are given[#](#histogram-will-accept-nan-values-when-explicit-bins-are-given)
Previously it would fail when trying to compute a finite range for the data. Since the range is ignored anyway when the bins are given explicitly, this error was needless.

Note that calling `histogram`
on NaN values continues to raise the
`RuntimeWarning`
s typical of working with nan values, which can be silenced
as usual with `errstate`
.

`histogram`
works on datetime types, when explicit bin edges are given[#](#histogram-works-on-datetime-types-when-explicit-bin-edges-are-given)
Dates, times, and timedeltas can now be histogrammed. The bin edges must be passed explicitly, and are not yet computed automatically.

`histogram`
“auto” estimator handles limited variance better[#](#histogram-auto-estimator-handles-limited-variance-better)
No longer does an IQR of 0 result in `n_bins=1`
, rather the number of bins
chosen is related to the data size in this situation.

### The edges returned by *histogram`* and `histogramdd`
now match the data float type[#](#the-edges-returned-by-histogram-and-histogramdd-now-match-the-data-float-type)
When passed `np.float16`
, `np.float32`
, or `np.longdouble`
data, the
returned edges are now of the same dtype. Previously, `histogram`
would only
return the same type if explicit bins were given, and `histogram`
would
produce `float64`
bins no matter what the inputs.

`histogramdd`
allows explicit ranges to be given in a subset of axes[#](#histogramdd-allows-explicit-ranges-to-be-given-in-a-subset-of-axes)
The `range`
argument of [ numpy.histogramdd](../reference/generated/numpy.histogramdd.html#numpy.histogramdd) can now contain

`None`
values to
indicate that the range for the corresponding axis should be computed from the
data. Previously, this could not be specified on a per-axis basis.### The normed arguments of `histogramdd`
and `histogram2d`
have been renamed[#](#the-normed-arguments-of-histogramdd-and-histogram2d-have-been-renamed)
These arguments are now called `density`
, which is consistent with
`histogram`
. The old argument continues to work, but the new name should be
preferred.

`np.r_`
works with 0d arrays, and `np.ma.mr_`
works with `np.ma.masked`
[#](#np-r-works-with-0d-arrays-and-np-ma-mr-works-with-np-ma-masked)
0d arrays passed to the *r_* and *mr_* concatenation helpers are now treated as
though they are arrays of length 1. Previously, passing these was an error.
As a result, [ numpy.ma.mr_](../reference/generated/numpy.ma.mr_.html#numpy.ma.mr_) now works correctly on the

`masked`
constant.`np.ptp`
accepts a `keepdims`
argument, and extended axis tuples[#](#np-ptp-accepts-a-keepdims-argument-and-extended-axis-tuples)
`np.ptp`
(peak-to-peak) can now work over multiple axes, just like `np.max`
and `np.min`
.
`MaskedArray.astype`
now is identical to `ndarray.astype`
[#](#maskedarray-astype-now-is-identical-to-ndarray-astype)
This means it takes all the same arguments, making more code written for ndarray work for masked array too.

### Enable AVX2/AVX512 at compile time[#](#enable-avx2-avx512-at-compile-time)
Change to simd.inc.src to allow use of AVX2 or AVX512 at compile time. Previously compilation for avx2 (or 512) with -march=native would still use the SSE code for the simd functions even when the rest of the code got AVX2.

`nan_to_num`
always returns scalars when receiving scalar or 0d inputs[#](#nan-to-num-always-returns-scalars-when-receiving-scalar-or-0d-inputs)
Previously an array was returned for integer scalar inputs, which is inconsistent with the behavior for float inputs, and that of ufuncs in general. For all types of scalar or 0d input, the result is now a scalar.

`np.flatnonzero`
works on numpy-convertible types[#](#np-flatnonzero-works-on-numpy-convertible-types)
`np.flatnonzero`
now uses `np.ravel(a)`
instead of `a.ravel()`
, so it
works for lists, tuples, etc.
`np.interp`
returns numpy scalars rather than builtin scalars[#](#np-interp-returns-numpy-scalars-rather-than-builtin-scalars)
Previously `np.interp(0.5, [0, 1], [10, 20])`
would return a `float`
, but
now it returns a `np.float64`
object, which more closely matches the behavior
of other functions.

Additionally, the special case of `np.interp(object_array_0d, ...)`
is no
longer supported, as `np.interp(object_array_nd)`
was never supported anyway.

As a result of this change, the `period`
argument can now be used on 0d
arrays.

### Allow dtype field names to be unicode in Python 2[#](#allow-dtype-field-names-to-be-unicode-in-python-2)
Previously `np.dtype([(u'name', float)])`
would raise a `TypeError`
in
Python 2, as only bytestrings were allowed in field names. Now any unicode
string field names will be encoded with the `ascii`
codec, raising a
`UnicodeEncodeError`
upon failure.

This change makes it easier to write Python 2/3 compatible code using
`from __future__ import unicode_literals`
, which previously would cause
string literal field names to raise a TypeError in Python 2.

### Comparison ufuncs accept `dtype=object`
, overriding the default `bool`
[#](#comparison-ufuncs-accept-dtype-object-overriding-the-default-bool)
This allows object arrays of symbolic types, which override `==`
and other
operators to return expressions, to be compared elementwise with
`np.equal(a, b, dtype=object)`
.

`sort`
functions accept `kind='stable'`
[#](#sort-functions-accept-kind-stable)
Up until now, to perform a stable sort on the data, the user must do:

```
>>> np.sort([5, 2, 6, 2, 1], kind='mergesort')
[1, 2, 2, 5, 6]
```
because merge sort is the only stable sorting algorithm available in NumPy. However, having kind=’mergesort’ does not make it explicit that the user wants to perform a stable sort thus harming the readability.

This change allows the user to specify kind=’stable’ thus clarifying the intent.

### Do not make temporary copies for in-place accumulation[#](#do-not-make-temporary-copies-for-in-place-accumulation)
When ufuncs perform accumulation they no longer make temporary copies because of the overlap between input an output, that is, the next element accumulated is added before the accumulated result is stored in its place, hence the overlap is safe. Avoiding the copy results in faster execution.

`linalg.matrix_power`
can now handle stacks of matrices[#](#linalg-matrix-power-can-now-handle-stacks-of-matrices)
Like other functions in `linalg`
, `matrix_power`
can now deal with arrays
of dimension larger than 2, which are treated as stacks of matrices. As part
of the change, to further improve consistency, the name of the first argument
has been changed to `a`
(from `M`
), and the exceptions for non-square
matrices have been changed to `LinAlgError`
(from `ValueError`
).

### Increased performance in `random.permutation`
for multidimensional arrays[#](#increased-performance-in-random-permutation-for-multidimensional-arrays)
`permutation`
uses the fast path in `random.shuffle`
for all input
array dimensions. Previously the fast path was only used for 1-d arrays.
### Generalized ufuncs now accept `axes`
, `axis`
and `keepdims`
arguments[#](#generalized-ufuncs-now-accept-axes-axis-and-keepdims-arguments)
One can control over which axes a generalized ufunc operates by passing in an
`axes`
argument, a list of tuples with indices of particular axes. For
instance, for a signature of `(i,j),(j,k)->(i,k)`
appropriate for matrix
multiplication, the base elements are two-dimensional matrices and these are
taken to be stored in the two last axes of each argument. The corresponding
axes keyword would be `[(-2, -1), (-2, -1), (-2, -1)]`
. If one wanted to
use leading dimensions instead, one would pass in `[(0, 1), (0, 1), (0, 1)]`
.

For simplicity, for generalized ufuncs that operate on 1-dimensional arrays
(vectors), a single integer is accepted instead of a single-element tuple, and
for generalized ufuncs for which all outputs are scalars, the (empty) output
tuples can be omitted. Hence, for a signature of `(i),(i)->()`
appropriate
for an inner product, one could pass in `axes=[0, 0]`
to indicate that the
vectors are stored in the first dimensions of the two inputs arguments.

As a short-cut for generalized ufuncs that are similar to reductions, i.e.,
that act on a single, shared core dimension such as the inner product example
above, one can pass an `axis`
argument. This is equivalent to passing in
`axes`
with identical entries for all arguments with that core dimension
(e.g., for the example above, `axes=[(axis,), (axis,)]`
).

Furthermore, like for reductions, for generalized ufuncs that have inputs that
all have the same number of core dimensions and outputs with no core dimension,
one can pass in `keepdims`
to leave a dimension with size 1 in the outputs,
thus allowing proper broadcasting against the original inputs. The location of
the extra dimension can be controlled with `axes`
. For instance, for the
inner-product example, `keepdims=True, axes=[-2, -2, -2]`
would act on the
inner-product example, `keepdims=True, axis=-2`
would act on the
one-but-last dimension of the input arguments, and leave a size 1 dimension in
that place in the output.

### float128 values now print correctly on ppc systems[#](#float128-values-now-print-correctly-on-ppc-systems)
Previously printing float128 values was buggy on ppc, since the special double-double floating-point-format on these systems was not accounted for. float128s now print with correct rounding and uniqueness.

Warning to ppc users: You should upgrade glibc if it is version <=2.23, especially if using float128. On ppc, glibc’s malloc in these version often misaligns allocated memory which can crash numpy when using float128 values.

### New `np.take_along_axis`
and `np.put_along_axis`
functions[#](#new-np-take-along-axis-and-np-put-along-axis-functions)
When used on multidimensional arrays, `argsort`
, `argmin`
, `argmax`
, and
`argpartition`
return arrays that are difficult to use as indices.
`take_along_axis`
provides an easy way to use these indices to lookup values
within an array, so that:

```
np.take_along_axis(a, np.argsort(a, axis=axis), axis=axis)
```
is the same as:

```
np.sort(a, axis=axis)
```
`np.put_along_axis`
acts as the dual operation for writing to these indices
within an array.# C-Types foreign function interface (`numpy.ctypeslib`
)[#](#c-types-foreign-function-interface-numpy-ctypeslib)
`numpy.ctypeslib`
numpy.ctypeslib.as_array(*obj*,*shape=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ctypeslib.py#L506-L524)[#](#numpy.ctypeslib.as_array)
-
Create a numpy array from a ctypes array or POINTER.

The numpy array shares the memory with the ctypes object.

The shape parameter must be given if converting from a ctypes POINTER. The shape parameter is ignored if converting from a ctypes array

numpy.ctypeslib.as_ctypes(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ctypeslib.py#L527-L545)[#](#numpy.ctypeslib.as_ctypes)
-
Create and return a ctypes object from a numpy array. Actually anything that exposes the __array_interface__ is accepted.

numpy.ctypeslib.as_ctypes_type(*dtype*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ctypeslib.py#L465-L503)[#](#numpy.ctypeslib.as_ctypes_type)
-
Convert a dtype into a ctypes type.

Parameters:
-
**dtype**dtype
The dtype to convert

Returns:
-
ctype
-
A ctype scalar, union, array, or struct

Raises:
-
NotImplementedError
-
If the conversion is not possible

Notes

This function does not losslessly round-trip in either direction.

`np.dtype(as_ctypes_type(dt))`
will:insert padding fields

reorder fields to be sorted by offset

discard field titles

`as_ctypes_type(np.dtype(ctype))`
will:discard the class names of

s and`ctypes.Structure`
s`ctypes.Union`
convert single-element

s into single-element`ctypes.Union`
s`ctypes.Structure`
insert padding fields

numpy.ctypeslib.load_library(*libname*,*loader_path*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ctypeslib.py#L90-L161)[#](#numpy.ctypeslib.load_library)
-
It is possible to load a library using

>>> lib = ctypes.cdll[<full_path_name>]
But there are cross-platform considerations, such as library file extensions, plus the fact Windows will just load the first library it finds with that name. NumPy supplies the load_library function as a convenience.

Changed in version 1.20.0: Allow libname and loader_path to take any

[path-like object](https://docs.python.org/3/glossary.html#term-path-like-object).Parameters:
-
**libname**path-like
Name of the library, which can have ‘lib’ as a prefix, but without an extension.

**loader_path**path-like
Where the library can be found.

Returns:
-
**ctypes.cdll[libpath]**library object
A ctypes library object

Raises:
-
OSError
-
If there is no library with the expected extension, or the library is defective and cannot be loaded.

numpy.ctypeslib.ndpointer(*dtype=None*,*ndim=None*,*shape=None*,*flags=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ctypeslib.py#L233-L347)[#](#numpy.ctypeslib.ndpointer)
-
Array-checking restype/argtypes.

An ndpointer instance is used to describe an ndarray in restypes and argtypes specifications. This approach is more flexible than using, for example,

`POINTER(c_double)`
, since several restrictions can be specified, which are verified upon calling the ctypes function. These include data type, number of dimensions, shape and flags. If a given array does not satisfy the specified restrictions, a`TypeError`
is raised.Parameters:
-
**dtype**data-type, optional
Array data-type.

**ndim**int, optional
Number of array dimensions.

**shape**tuple of ints, optional
Array shape.

**flags**str or tuple of str
Array flags; may be one or more of:

C_CONTIGUOUS / C / CONTIGUOUS

F_CONTIGUOUS / F / FORTRAN

OWNDATA / O

WRITEABLE / W

ALIGNED / A

WRITEBACKIFCOPY / X

Returns:
-
**klass**ndpointer type object
A type object, which is an

`_ndtpr`
instance containing dtype, ndim, shape and flags information.
Raises:
-
TypeError
-
If a given array does not satisfy the specified restrictions.

Examples

>>> clib.somefunc.argtypes = [np.ctypeslib.ndpointer(dtype=np.float64, ... ndim=1, ... flags='C_CONTIGUOUS')] ... >>> clib.somefunc(np.array([1, 2, 3], dtype=np.float64)) ...
*class*numpy.ctypeslib.c_intp[#](#numpy.ctypeslib.c_intp)
-
A

signed integer type of the same size as`ctypes`
.`numpy.intp`
Depending on the platform, it can be an alias for either

,`c_int`
or`c_long`
.`c_longlong`# NumPy 1.15.3 Release Notes[#](#numpy-1-15-3-release-notes)
This is a bugfix release for bugs and regressions reported following the 1.15.2 release. The Python versions supported by this release are 2.7, 3.4-3.7. The wheels are linked with OpenBLAS v0.3.0, which should fix some of the linalg problems reported for NumPy 1.14.

## Compatibility Note[#](#compatibility-note)
The NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit
binaries. That will also be the case in future releases. See
[#11625](https://github.com/numpy/numpy/issues/11625) for the related
discussion. Those needing 32-bit support should look elsewhere or build
from source.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Charles Harris

Jeroen Demeyer

Kevin Sheppard

Matthew Bowden +

Matti Picus

Tyler Reddy

## Pull requests merged[#](#pull-requests-merged)
A total of 12 pull requests were merged for this release.

[#12080](https://github.com/numpy/numpy/pull/12080): MAINT: Blacklist some MSVC complex functions.
[#12083](https://github.com/numpy/numpy/pull/12083): TST: Add azure CI testing to 1.15.x branch.
[#12084](https://github.com/numpy/numpy/pull/12084): BUG: test_path() now uses Path.resolve()
[#12085](https://github.com/numpy/numpy/pull/12085): TST, MAINT: Fix some failing tests on azure-pipelines mac and…
[#12187](https://github.com/numpy/numpy/pull/12187): BUG: Fix memory leak in mapping.c
[#12188](https://github.com/numpy/numpy/pull/12188): BUG: Allow boolean subtract in histogram
[#12189](https://github.com/numpy/numpy/pull/12189): BUG: Fix in-place permutation
[#12190](https://github.com/numpy/numpy/pull/12190): BUG: limit default for get_num_build_jobs() to 8
[#12191](https://github.com/numpy/numpy/pull/12191): BUG: OBJECT_to_* should check for errors
[#12192](https://github.com/numpy/numpy/pull/12192): DOC: Prepare for NumPy 1.15.3 release.
[#12237](https://github.com/numpy/numpy/pull/12237): BUG: Fix MaskedArray fill_value type conversion.
[#12238](https://github.com/numpy/numpy/pull/12238): TST: Backport azure-pipeline testing fixes for Mac# NumPy 1.13.0 Release Notes[#](#numpy-1-13-0-release-notes)
This release supports Python 2.7 and 3.4 - 3.6.

## Highlights[#](#highlights)
-
Operations like

`a + b + c`
will reuse temporaries on some platforms, resulting in less memory use and faster execution.
-
Inplace operations check if inputs overlap outputs and create temporaries to avoid problems.

-
New

`__array_ufunc__`
attribute provides improved ability for classes to override default ufunc behavior.
-
New

`np.block`
function for creating blocked arrays.
## New functions[#](#new-functions)
New

`np.positive`
ufunc.
New

`np.divmod`
ufunc provides more efficient divmod.
New

`np.isnat`
ufunc tests for NaT special values.
New

`np.heaviside`
ufunc computes the Heaviside function.
New

`np.isin`
function, improves on`in1d`
.
New

`np.block`
function for creating blocked arrays.
New

`PyArray_MapIterArrayCopyIfOverlap`
added to NumPy C-API.
See below for details.

## Deprecations[#](#deprecations)
Calling

`np.fix`
,`np.isposinf`
, and`np.isneginf`
with`f(x, y=out)`
is deprecated - the argument should be passed as`f(x, out=out)`
, which matches other ufunc-like interfaces.
Use of the C-API

`NPY_CHAR`
type number deprecated since version 1.7 will now raise deprecation warnings at runtime. Extensions built with older f2py versions need to be recompiled to remove the warning.
`np.ma.argsort`
,`np.ma.minimum.reduce`
, and`np.ma.maximum.reduce`
should be called with an explicit*axis*argument when applied to arrays with more than 2 dimensions, as the default value of this argument (`None`
) is inconsistent with the rest of numpy (`-1`
,`0`
, and`0`
, respectively).
`np.ma.MaskedArray.mini`
is deprecated, as it almost duplicates the functionality of`np.MaskedArray.min`
. Exactly equivalent behaviour can be obtained with`np.ma.minimum.reduce`
.
The single-argument form of

`np.ma.minimum`
and`np.ma.maximum`
is deprecated.`np.maximum`
.`np.ma.minimum(x)`
should now be spelt`np.ma.minimum.reduce(x)`
, which is consistent with how this would be done with`np.minimum`
.
Calling

`ndarray.conjugate`
on non-numeric dtypes is deprecated (it should match the behavior of`np.conjugate`
, which throws an error).
Calling

`expand_dims`
when the`axis`
keyword does not satisfy`-a.ndim - 1 <= axis <= a.ndim`
, where`a`
is the array being reshaped, is deprecated.
## Future Changes[#](#future-changes)
Assignment between structured arrays with different field names will change in NumPy 1.14. Previously, fields in the dst would be set to the value of the identically-named field in the src. In numpy 1.14 fields will instead be assigned ‘by position’: The n-th field of the dst will be set to the n-th field of the src array. Note that the

`FutureWarning`
raised in NumPy 1.12 incorrectly reported this change as scheduled for NumPy 1.13 rather than NumPy 1.14.
## Build System Changes[#](#build-system-changes)
`numpy.distutils`
now automatically determines C-file dependencies with GCC compatible compilers.
## Compatibility notes[#](#compatibility-notes)
### Error type changes[#](#error-type-changes)
`numpy.hstack()`
now throws`ValueError`
instead of`IndexError`
when input is empty.
Functions taking an axis argument, when that argument is out of range, now throw

`np.AxisError`
instead of a mixture of`IndexError`
and`ValueError`
. For backwards compatibility,`AxisError`
subclasses both of these.
### Tuple object dtypes[#](#tuple-object-dtypes)
Support has been removed for certain obscure dtypes that were unintentionally
allowed, of the form `(old_dtype, new_dtype)`
, where either of the dtypes
is or contains the `object`
dtype. As an exception, dtypes of the form
`(object, [('name', object)])`
are still supported due to evidence of
existing use.

### DeprecationWarning to error[#](#deprecationwarning-to-error)
See Changes section for more detail.

`partition`
, TypeError when non-integer partition index is used.
`NpyIter_AdvancedNew`
, ValueError when`oa_ndim == 0`
and`op_axes`
is NULL
`negative(bool_)`
, TypeError when negative applied to booleans.
`subtract(bool_, bool_)`
, TypeError when subtracting boolean from boolean.
`np.equal, np.not_equal`
, object identity doesn’t override failed comparison.
`np.equal, np.not_equal`
, object identity doesn’t override non-boolean comparison.
Deprecated boolean indexing behavior dropped. See Changes below for details.

Deprecated

`np.alterdot()`
and`np.restoredot()`
removed.
### FutureWarning to changed behavior[#](#futurewarning-to-changed-behavior)
See Changes section for more detail.

`numpy.average`
preserves subclasses
`array == None`
and`array != None`
do element-wise comparison.
`np.equal, np.not_equal`
, object identity doesn’t override comparison result.
### dtypes are now always true[#](#dtypes-are-now-always-true)
Previously `bool(dtype)`
would fall back to the default python
implementation, which checked if `len(dtype) > 0`
. Since `dtype`
objects
implement `__len__`
as the number of record fields, `bool`
of scalar dtypes
would evaluate to `False`
, which was unintuitive. Now `bool(dtype) == True`
for all dtypes.

`__getslice__`
and `__setslice__`
are no longer needed in `ndarray`
subclasses[#](#getslice-and-setslice-are-no-longer-needed-in-ndarray-subclasses)
When subclassing np.ndarray in Python 2.7, it is no longer _necessary_ to
implement `__*slice__`
on the derived class, as `__*item__`
will intercept
these calls correctly.

Any code that did implement these will work exactly as before. Code that
invokes``ndarray.__getslice__`` (e.g. through `super(...).__getslice__`
) will
now issue a DeprecationWarning - `.__getitem__(slice(start, end))`
should be
used instead.

### Indexing MaskedArrays/Constants with `...`
(ellipsis) now returns MaskedArray[#](#indexing-maskedarrays-constants-with-ellipsis-now-returns-maskedarray)
This behavior mirrors that of np.ndarray, and accounts for nested arrays in MaskedArrays of object dtype, and ellipsis combined with other forms of indexing.

## C API changes[#](#c-api-changes)
### GUfuncs on empty arrays and NpyIter axis removal[#](#gufuncs-on-empty-arrays-and-npyiter-axis-removal)
It is now allowed to remove a zero-sized axis from NpyIter. Which may mean that code removing axes from NpyIter has to add an additional check when accessing the removed dimensions later on.

The largest followup change is that gufuncs are now allowed to have zero-sized inner dimensions. This means that a gufunc now has to anticipate an empty inner dimension, while this was never possible and an error raised instead.

For most gufuncs no change should be necessary. However, it is now possible
for gufuncs with a signature such as `(..., N, M) -> (..., M)`
to return
a valid result if `N=0`
without further wrapping code.

`PyArray_MapIterArrayCopyIfOverlap`
added to NumPy C-API[#](#pyarray-mapiterarraycopyifoverlap-added-to-numpy-c-api)
Similar to `PyArray_MapIterArray`
but with an additional `copy_if_overlap`
argument. If `copy_if_overlap != 0`
, checks if input has memory overlap with
any of the other arrays and make copies as appropriate to avoid problems if the
input is modified during the iteration. See the documentation for more complete
documentation.

## New Features[#](#new-features)
`__array_ufunc__`
added[#](#array-ufunc-added)
This is the renamed and redesigned `__numpy_ufunc__`
. Any class, ndarray
subclass or not, can define this method or set it to `None`
in order to
override the behavior of NumPy’s ufuncs. This works quite similarly to Python’s
`__mul__`
and other binary operation routines. See the documentation for a
more detailed description of the implementation and behavior of this new
option. The API is provisional, we do not yet guarantee backward compatibility
as modifications may be made pending feedback. See [NEP 13](http://www.numpy.org/neps/nep-0013-ufunc-overrides.html) and
[documentation](https://github.com/numpy/numpy/blob/master/doc/source/reference/arrays.classes.rst) for more details.

### New `positive`
ufunc[#](#new-positive-ufunc)
This ufunc corresponds to unary *+*, but unlike *+* on an ndarray it will raise
an error if array values do not support numeric operations.

### New `divmod`
ufunc[#](#new-divmod-ufunc)
This ufunc corresponds to the Python builtin *divmod*, and is used to implement
*divmod* when called on numpy arrays. `np.divmod(x, y)`
calculates a result
equivalent to `(np.floor_divide(x, y), np.remainder(x, y))`
but is
approximately twice as fast as calling the functions separately.

`np.isnat`
ufunc tests for NaT special datetime and timedelta values[#](#np-isnat-ufunc-tests-for-nat-special-datetime-and-timedelta-values)
The new ufunc `np.isnat`
finds the positions of special NaT values
within datetime and timedelta arrays. This is analogous to `np.isnan`
.

`np.heaviside`
ufunc computes the Heaviside function[#](#np-heaviside-ufunc-computes-the-heaviside-function)
The new function `np.heaviside(x, h0)`
(a ufunc) computes the Heaviside
function:

```
{ 0 if x < 0,
heaviside(x, h0) = { h0 if x == 0,
{ 1 if x > 0.
```
`np.block`
function for creating blocked arrays[#](#np-block-function-for-creating-blocked-arrays)
Add a new `block`
function to the current stacking functions `vstack`
,
`hstack`
, and `stack`
. This allows concatenation across multiple axes
simultaneously, with a similar syntax to array creation, but where elements
can themselves be arrays. For instance:

```
>>> A = np.eye(2) * 2
>>> B = np.eye(3) * 3
>>> np.block([
... [A, np.zeros((2, 3))],
... [np.ones((3, 2)), B ]
... ])
array([[ 2., 0., 0., 0., 0.],
[ 0., 2., 0., 0., 0.],
[ 1., 1., 3., 0., 0.],
[ 1., 1., 0., 3., 0.],
[ 1., 1., 0., 0., 3.]])
```
While primarily useful for block matrices, this works for arbitrary dimensions of arrays.

It is similar to Matlab’s square bracket notation for creating block matrices.

`isin`
function, improving on `in1d`
[#](#isin-function-improving-on-in1d)
The new function `isin`
tests whether each element of an N-dimensional
array is present anywhere within a second array. It is an enhancement
of `in1d`
that preserves the shape of the first array.

### Temporary elision[#](#temporary-elision)
On platforms providing the `backtrace`
function NumPy will try to avoid
creating temporaries in expression involving basic numeric types.
For example `d = a + b + c`
is transformed to `d = a + b; d += c`
which can
improve performance for large arrays as less memory bandwidth is required to
perform the operation.

`axes`
argument for `unique`
[#](#axes-argument-for-unique)
In an N-dimensional array, the user can now choose the axis along which to look
for duplicate N-1-dimensional elements using `numpy.unique`
. The original
behaviour is recovered if `axis=None`
(default).

`np.gradient`
now supports unevenly spaced data[#](#np-gradient-now-supports-unevenly-spaced-data)
Users can now specify a not-constant spacing for data.
In particular `np.gradient`
can now take:

A single scalar to specify a sample distance for all dimensions.

N scalars to specify a constant sample distance for each dimension. i.e.

`dx`
,`dy`
,`dz`
, …
N arrays to specify the coordinates of the values along each dimension of F. The length of the array must match the size of the corresponding dimension

Any combination of N scalars/arrays with the meaning of 2. and 3.

This means that, e.g., it is now possible to do the following:

```
>>> f = np.array([[1, 2, 6], [3, 4, 5]], dtype=np.float_)
>>> dx = 2.
>>> y = [1., 1.5, 3.5]
>>> np.gradient(f, dx, y)
[array([[ 1. , 1. , -0.5], [ 1. , 1. , -0.5]]),
array([[ 2. , 2. , 2. ], [ 2. , 1.7, 0.5]])]
```
### Support for returning arrays of arbitrary dimensions in `apply_along_axis`
[#](#support-for-returning-arrays-of-arbitrary-dimensions-in-apply-along-axis)
Previously, only scalars or 1D arrays could be returned by the function passed
to `apply_along_axis`
. Now, it can return an array of any dimensionality
(including 0D), and the shape of this array replaces the axis of the array
being iterated over.

`.ndim`
property added to `dtype`
to complement `.shape`
[#](#ndim-property-added-to-dtype-to-complement-shape)
For consistency with `ndarray`
and `broadcast`
, `d.ndim`
is a shorthand
for `len(d.shape)`
.

### Support for tracemalloc in Python 3.6[#](#support-for-tracemalloc-in-python-3-6)
NumPy now supports memory tracing with [tracemalloc](https://docs.python.org/3/library/tracemalloc.html) module of Python 3.6 or
newer. Memory allocations from NumPy are placed into the domain defined by
`numpy.lib.tracemalloc_domain`
.
Note that NumPy allocation will not show up in [tracemalloc](https://docs.python.org/3/library/tracemalloc.html) of earlier Python
versions.

### NumPy may be built with relaxed stride checking debugging[#](#numpy-may-be-built-with-relaxed-stride-checking-debugging)
Setting NPY_RELAXED_STRIDES_DEBUG=1 in the environment when relaxed stride checking is enabled will cause NumPy to be compiled with the affected strides set to the maximum value of npy_intp in order to help detect invalid usage of the strides in downstream projects. When enabled, invalid usage often results in an error being raised, but the exact type of error depends on the details of the code. TypeError and OverflowError have been observed in the wild.

It was previously the case that this option was disabled for releases and enabled in master and changing between the two required editing the code. It is now disabled by default but can be enabled for test builds.

## Improvements[#](#improvements)
### Ufunc behavior for overlapping inputs[#](#ufunc-behavior-for-overlapping-inputs)
Operations where ufunc input and output operands have memory overlap produced undefined results in previous NumPy versions, due to data dependency issues. In NumPy 1.13.0, results from such operations are now defined to be the same as for equivalent operations where there is no memory overlap.

Operations affected now make temporary copies, as needed to eliminate data dependency. As detecting these cases is computationally expensive, a heuristic is used, which may in rare cases result to needless temporary copies. For operations where the data dependency is simple enough for the heuristic to analyze, temporary copies will not be made even if the arrays overlap, if it can be deduced copies are not necessary. As an example,``np.add(a, b, out=a)`` will not involve copies.

To illustrate a previously undefined operation:

```
>>> x = np.arange(16).astype(float)
>>> np.add(x[1:], x[:-1], out=x[1:])
```
In NumPy 1.13.0 the last line is guaranteed to be equivalent to:

```
>>> np.add(x[1:].copy(), x[:-1].copy(), out=x[1:])
```
A similar operation with simple non-problematic data dependence is:

```
>>> x = np.arange(16).astype(float)
>>> np.add(x[1:], x[:-1], out=x[:-1])
```
It will continue to produce the same results as in previous NumPy versions, and will not involve unnecessary temporary copies.

The change applies also to in-place binary operations, for example:

```
>>> x = np.random.rand(500, 500)
>>> x += x.T
```
This statement is now guaranteed to be equivalent to `x[...] = x + x.T`
,
whereas in previous NumPy versions the results were undefined.

### Partial support for 64-bit f2py extensions with MinGW[#](#partial-support-for-64-bit-f2py-extensions-with-mingw)
Extensions that incorporate Fortran libraries can now be built using the free
[MinGW](https://sf.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/6.2.0/threads-win32/seh/) toolset, also under Python 3.5. This works best for extensions that only
do calculations and uses the runtime modestly (reading and writing from files,
for instance). Note that this does not remove the need for Mingwpy; if you make
extensive use of the runtime, you will most likely run into [issues](https://mingwpy.github.io/issues.html). Instead,
it should be regarded as a band-aid until Mingwpy is fully functional.

Extensions can also be compiled using the MinGW toolset using the runtime library from the (moveable) WinPython 3.4 distribution, which can be useful for programs with a PySide1/Qt4 front-end.

### Performance improvements for `packbits`
and `unpackbits`
[#](#performance-improvements-for-packbits-and-unpackbits)
The functions `numpy.packbits`
with boolean input and `numpy.unpackbits`
have
been optimized to be a significantly faster for contiguous data.

### Fix for PPC long double floating point information[#](#fix-for-ppc-long-double-floating-point-information)
In previous versions of NumPy, the `finfo`
function returned invalid
information about the [double double](https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format#Double-double_arithmetic) format of the `longdouble`
float type
on Power PC (PPC). The invalid values resulted from the failure of the NumPy
algorithm to deal with the variable number of digits in the significand
that are a feature of *PPC long doubles*. This release by-passes the failing
algorithm by using heuristics to detect the presence of the PPC double double
format. A side-effect of using these heuristics is that the `finfo`
function is faster than previous releases.

### Better default repr for `ndarray`
subclasses[#](#better-default-repr-for-ndarray-subclasses)
Subclasses of ndarray with no `repr`
specialization now correctly indent
their data and type lines.

### More reliable comparisons of masked arrays[#](#more-reliable-comparisons-of-masked-arrays)
Comparisons of masked arrays were buggy for masked scalars and failed for
structured arrays with dimension higher than one. Both problems are now
solved. In the process, it was ensured that in getting the result for a
structured array, masked fields are properly ignored, i.e., the result is equal
if all fields that are non-masked in both are equal, thus making the behaviour
identical to what one gets by comparing an unstructured masked array and then
doing `.all()`
over some axis.

### np.matrix with booleans elements can now be created using the string syntax[#](#np-matrix-with-booleans-elements-can-now-be-created-using-the-string-syntax)
`np.matrix`
failed whenever one attempts to use it with booleans, e.g.,
`np.matrix('True')`
. Now, this works as expected.
### More `linalg`
operations now accept empty vectors and matrices[#](#more-linalg-operations-now-accept-empty-vectors-and-matrices)
All of the following functions in `np.linalg`
now work when given input
arrays with a 0 in the last two dimensions: `det`
, `slogdet`
, `pinv`
,
`eigvals`
, `eigvalsh`
, `eig`
, `eigh`
.

### Bundled version of LAPACK is now 3.2.2[#](#bundled-version-of-lapack-is-now-3-2-2)
NumPy comes bundled with a minimal implementation of lapack for systems without
a lapack library installed, under the name of `lapack_lite`
. This has been
upgraded from LAPACK 3.0.0 (June 30, 1999) to LAPACK 3.2.2 (June 30, 2010). See
the [LAPACK changelogs](http://www.netlib.org/lapack/release_notes.html#_4_history_of_lapack_releases) for details on the all the changes this entails.

While no new features are exposed through `numpy`
, this fixes some bugs
regarding “workspace” sizes, and in some places may use faster algorithms.

`reduce`
of `np.hypot.reduce`
and `np.logical_xor`
allowed in more cases[#](#reduce-of-np-hypot-reduce-and-np-logical-xor-allowed-in-more-cases)
This now works on empty arrays, returning 0, and can reduce over multiple axes.
Previously, a `ValueError`
was thrown in these cases.

### Better `repr`
of object arrays[#](#better-repr-of-object-arrays)
Object arrays that contain themselves no longer cause a recursion error.

Object arrays that contain `list`
objects are now printed in a way that makes
clear the difference between a 2d object array, and a 1d object array of lists.

## Changes[#](#changes)
`argsort`
on masked arrays takes the same default arguments as `sort`
[#](#argsort-on-masked-arrays-takes-the-same-default-arguments-as-sort)
By default, `argsort`
now places the masked values at the end of the sorted
array, in the same way that `sort`
already did. Additionally, the
`end_with`
argument is added to `argsort`
, for consistency with `sort`
.
Note that this argument is not added at the end, so breaks any code that
passed `fill_value`
as a positional argument.

`average`
now preserves subclasses[#](#average-now-preserves-subclasses)
For ndarray subclasses, `numpy.average`
will now return an instance of the
subclass, matching the behavior of most other NumPy functions such as `mean`
.
As a consequence, also calls that returned a scalar may now return a subclass
array scalar.

`array == None`
and `array != None`
do element-wise comparison[#](#array-none-and-array-none-do-element-wise-comparison)
Previously these operations returned scalars `False`
and `True`
respectively.

`np.equal, np.not_equal`
for object arrays ignores object identity[#](#np-equal-np-not-equal-for-object-arrays-ignores-object-identity)
Previously, these functions always treated identical objects as equal. This had the effect of overriding comparison failures, comparison of objects that did not return booleans, such as np.arrays, and comparison of objects where the results differed from object identity, such as NaNs.

### Boolean indexing changes[#](#boolean-indexing-changes)
Boolean array-likes (such as lists of python bools) are always treated as boolean indexes.

Boolean scalars (including python

`True`
) are legal boolean indexes and never treated as integers.
Boolean indexes must match the dimension of the axis that they index.

Boolean indexes used on the lhs of an assignment must match the dimensions of the rhs.

Boolean indexing into scalar arrays return a new 1-d array. This means that

`array(1)[array(True)]`
gives`array([1])`
and not the original array.
`np.random.multivariate_normal`
behavior with bad covariance matrix[#](#np-random-multivariate-normal-behavior-with-bad-covariance-matrix)
It is now possible to adjust the behavior the function will have when dealing with the covariance matrix by using two new keyword arguments:

`tol`
can be used to specify a tolerance to use when checking that the covariance matrix is positive semidefinite.
`check_valid`
can be used to configure what the function will do in the presence of a matrix that is not positive semidefinite. Valid options are`ignore`
,`warn`
and`raise`
. The default value,`warn`
keeps the the behavior used on previous releases.
`assert_array_less`
compares `np.inf`
and `-np.inf`
now[#](#assert-array-less-compares-np-inf-and-np-inf-now)
Previously, `np.testing.assert_array_less`
ignored all infinite values. This
is not the expected behavior both according to documentation and intuitively.
Now, -inf < x < inf is considered `True`
for any real number x and all
other cases fail.

`assert_array_`
and masked arrays `assert_equal`
hide less warnings[#](#assert-array-and-masked-arrays-assert-equal-hide-less-warnings)
Some warnings that were previously hidden by the `assert_array_`
functions are not hidden anymore. In most cases the warnings should be
correct and, should they occur, will require changes to the tests using
these functions.
For the masked array `assert_equal`
version, warnings may occur when
comparing NaT. The function presently does not handle NaT or NaN
specifically and it may be best to avoid it at this time should a warning
show up due to this change.

`offset`
attribute value in `memmap`
objects[#](#offset-attribute-value-in-memmap-objects)
The `offset`
attribute in a `memmap`
object is now set to the
offset into the file. This is a behaviour change only for offsets
greater than `mmap.ALLOCATIONGRANULARITY`
.

`np.real`
and `np.imag`
return scalars for scalar inputs[#](#np-real-and-np-imag-return-scalars-for-scalar-inputs)
Previously, `np.real`
and `np.imag`
used to return array objects when
provided a scalar input, which was inconsistent with other functions like
`np.angle`
and `np.conj`
.

### The polynomial convenience classes cannot be passed to ufuncs[#](#the-polynomial-convenience-classes-cannot-be-passed-to-ufuncs)
The ABCPolyBase class, from which the convenience classes are derived, sets
`__array_ufun__ = None`
in order of opt out of ufuncs. If a polynomial
convenience class instance is passed as an argument to a ufunc, a `TypeError`
will now be raised.

### Output arguments to ufuncs can be tuples also for ufunc methods[#](#output-arguments-to-ufuncs-can-be-tuples-also-for-ufunc-methods)
For calls to ufuncs, it was already possible, and recommended, to use an
`out`
argument with a tuple for ufuncs with multiple outputs. This has now
been extended to output arguments in the `reduce`
, `accumulate`
, and
`reduceat`
methods. This is mostly for compatibility with `__array_ufunc`
;
there are no ufuncs yet that have more than one output.# NumPy 1.18.0 Release Notes[#](#numpy-1-18-0-release-notes)
In addition to the usual bug fixes, this NumPy release cleans up and documents the new random C-API, expires a large number of old deprecations, and improves the appearance of the documentation. The Python versions supported are 3.5-3.8. This is the last NumPy release series that will support Python 3.5.

Downstream developers should use Cython >= 0.29.14 for Python 3.8 support and OpenBLAS >= 3.7 to avoid problems on the Skylake architecture.

## Highlights[#](#highlights)
The C-API for

`numpy.random`
has been defined and documented.
Basic infrastructure for linking with 64 bit BLAS and LAPACK libraries.

Many documentation improvements.

## New functions[#](#new-functions)
### Multivariate hypergeometric distribution added to `numpy.random`
[#](#multivariate-hypergeometric-distribution-added-to-numpy-random)
The method `multivariate_hypergeometric`
has been added to the class
[ numpy.random.Generator](../reference/random/generator.html#numpy.random.Generator). This method generates random variates from
the multivariate hypergeometric probability distribution.
(

[gh-13794](https://github.com/numpy/numpy/pull/13794))
## Deprecations[#](#deprecations)
`np.fromfile`
and `np.fromstring`
will error on bad data[#](#np-fromfile-and-np-fromstring-will-error-on-bad-data)
In future numpy releases, the functions `np.fromfile`
and `np.fromstring`
will throw an error when parsing bad data.
This will now give a `DeprecationWarning`
where previously partial or
even invalid data was silently returned. This deprecation also affects
the C defined functions `PyArray_FromString`
and `PyArray_FromFile`
([gh-13605](https://github.com/numpy/numpy/pull/13605))

### Deprecate non-scalar arrays as fill values in `ma.fill_value`
[#](#deprecate-non-scalar-arrays-as-fill-values-in-ma-fill-value)
Setting a `MaskedArray.fill_value`
to a non-scalar array is deprecated
since the logic to broadcast the fill value to the array is fragile,
especially when slicing.
([gh-13698](https://github.com/numpy/numpy/pull/13698))

### Deprecate `PyArray_As1D`
, `PyArray_As2D`
[#](#deprecate-pyarray-as1d-pyarray-as2d)
`PyArray_As1D`
, `PyArray_As2D`
are deprecated, use
`PyArray_AsCArray`
instead
([gh-14036](https://github.com/numpy/numpy/pull/14036))
### Deprecate `np.alen`
[#](#deprecate-np-alen)
`np.alen`
was deprecated. Use `len`
instead.
([gh-14181](https://github.com/numpy/numpy/pull/14181))
### Deprecate the financial functions[#](#deprecate-the-financial-functions)
In accordance with
[NEP-32](https://numpy.org/neps/nep-0032-remove-financial-functions.html),
the financial functions `fv`
`ipmt`
, `irr`
, `mirr`
, `nper`
,
`npv`
, `pmt`
, `ppmt`
, `pv`
and `rate`
are deprecated, and will be
removed from NumPy 1.20.The replacement for these functions is the Python package
[numpy-financial](https://pypi.org/project/numpy-financial).
([gh-14720](https://github.com/numpy/numpy/pull/14720))

### The `axis`
argument to `numpy.ma.mask_cols`
and `numpy.ma.mask_row`
is deprecated[#](#the-axis-argument-to-numpy-ma-mask-cols-and-numpy-ma-mask-row-is-deprecated)
This argument was always ignored.
([gh-14996](https://github.com/numpy/numpy/pull/14996))

## Expired deprecations[#](#expired-deprecations)
`PyArray_As1D`
and`PyArray_As2D`
have been removed in favor of`PyArray_AsCArray`
([gh-14036](https://github.com/numpy/numpy/pull/14036))
`np.rank`
has been removed. This was deprecated in NumPy 1.10 and has been replaced by`np.ndim`
. ([gh-14039](https://github.com/numpy/numpy/pull/14039))
The deprecation of

`expand_dims`
out-of-range axes in 1.13.0 has expired. ([gh-14051](https://github.com/numpy/numpy/pull/14051))
`PyArray_FromDimsAndDataAndDescr`
and`PyArray_FromDims`
have been removed (they will always raise an error). Use`PyArray_NewFromDescr`
and`PyArray_SimpleNew`
instead. ([gh-14100](https://github.com/numpy/numpy/pull/14100))
`numeric.loads`
,`numeric.load`
,`np.ma.dump`
,`np.ma.dumps`
,`np.ma.load`
,`np.ma.loads`
are removed, use`pickle`
methods instead ([gh-14256](https://github.com/numpy/numpy/pull/14256))
`arrayprint.FloatFormat`
,`arrayprint.LongFloatFormat`
has been removed, use`FloatingFormat`
instead
`arrayprint.ComplexFormat`
,`arrayprint.LongComplexFormat`
has been removed, use`ComplexFloatingFormat`
instead
`arrayprint.StructureFormat`
has been removed, use`StructureVoidFormat`
instead ([gh-14259](https://github.com/numpy/numpy/pull/14259))
`np.testing.rand`
has been removed. This was deprecated in NumPy 1.11 and has been replaced by`np.random.rand`
. ([gh-14325](https://github.com/numpy/numpy/pull/14325))
Class

`SafeEval`
in`numpy/lib/utils.py`
has been removed. This was deprecated in NumPy 1.10. Use`np.safe_eval`
instead. ([gh-14335](https://github.com/numpy/numpy/pull/14335))
Remove deprecated support for boolean and empty condition lists in

`np.select`
([gh-14583](https://github.com/numpy/numpy/pull/14583))
Array order only accepts ‘C’, ‘F’, ‘A’, and ‘K’. More permissive options were deprecated in NumPy 1.11. (

[gh-14596](https://github.com/numpy/numpy/pull/14596))
np.linspace parameter

`num`
must be an integer. Deprecated in NumPy 1.12. ([gh-14620](https://github.com/numpy/numpy/pull/14620))
UFuncs with multiple outputs must use a tuple for the

`out`
kwarg. This finishes a deprecation started in NumPy 1.10. ([gh-14682](https://github.com/numpy/numpy/pull/14682))
The files `numpy/testing/decorators.py`
, `numpy/testing/noseclasses.py`
and `numpy/testing/nosetester.py`
have been removed. They were never
meant to be public (all relevant objects are present in the
`numpy.testing`
namespace), and importing them has given a deprecation
warning since NumPy 1.15.0
([gh-14567](https://github.com/numpy/numpy/pull/14567))

## Compatibility notes[#](#compatibility-notes)
`numpy.lib.recfunctions.drop_fields`
can no longer return None[#](#numpy-lib-recfunctions-drop-fields-can-no-longer-return-none)
`numpy.lib.recfunctions.drop_fields`
If `drop_fields`
is used to drop all fields, previously the array would
be completely discarded and None returned. Now it returns an array of the
same shape as the input, but with no fields. The old behavior can be retained
with:

```
dropped_arr = drop_fields(arr, ['a', 'b'])
if dropped_arr.dtype.names == ():
dropped_arr = None
```
converting the empty recarray to None
([gh-14510](https://github.com/numpy/numpy/pull/14510))

`numpy.argmin/argmax/min/max`
returns `NaT`
if it exists in array[#](#numpy-argmin-argmax-min-max-returns-nat-if-it-exists-in-array)
`numpy.argmin`
, `numpy.argmax`
, `numpy.min`
, and `numpy.max`
will return
`NaT`
if it exists in the array.
([gh-14717](https://github.com/numpy/numpy/pull/14717))
`np.can_cast(np.uint64, np.timedelta64, casting='safe')`
is now `False`
[#](#np-can-cast-np-uint64-np-timedelta64-casting-safe-is-now-false)
Previously this was `True`
- however, this was inconsistent with `uint64`
not being safely castable to `int64`
, and resulting in strange type
resolution.

If this impacts your code, cast `uint64`
to `int64`
first.
([gh-14718](https://github.com/numpy/numpy/pull/14718))

### Changed random variate stream from `numpy.random.Generator.integers`
[#](#changed-random-variate-stream-from-numpy-random-generator-integers)
There was a bug in `numpy.random.Generator.integers`
that caused biased
sampling of 8 and 16 bit integer types. Fixing that bug has changed the
output stream from what it was in previous releases.
([gh-14777](https://github.com/numpy/numpy/pull/14777))

### Add more ufunc loops for `datetime64`
, `timedelta64`
[#](#add-more-ufunc-loops-for-datetime64-timedelta64)
`np.datetime('NaT')`
should behave more like `float('Nan')`
. Add needed
infrastructure so `np.isinf(a)`
and `np.isnan(a)`
will run on
`datetime64`
and `timedelta64`
dtypes. Also added specific loops for
`numpy.fmin`
and `numpy.fmax`
that mask `NaT`
. This may require
adjustment to user- facing code. Specifically, code that either disallowed the
calls to `numpy.isinf`
or `numpy.isnan`
or checked that they raised an
exception will require adaptation, and code that mistakenly called
`numpy.fmax`
and `numpy.fmin`
instead of `numpy.maximum`
or
`numpy.minimum`
respectively will require adjustment. This also affects
`numpy.nanmax`
and `numpy.nanmin`
.
([gh-14841](https://github.com/numpy/numpy/pull/14841))
### Moved modules in `numpy.random`
[#](#moved-modules-in-numpy-random)
As part of the API cleanup, the submodules in `numpy.random`
`bit_generator`
, `philox`
, `pcg64`
, `sfc64, ``common`
, `generator`
,
and `bounded_integers`
were moved to `_bit_generator`
, `_philox`
,
`_pcg64`
, `_sfc64, ``_common`
, `_generator`
, and `_bounded_integers`
respectively to indicate that they are not part of the public interface.
([gh-14608](https://github.com/numpy/numpy/pull/14608))

## C API changes[#](#c-api-changes)
`PyDataType_ISUNSIZED(descr)`
now returns False for structured datatypes[#](#pydatatype-isunsized-descr-now-returns-false-for-structured-datatypes)
Previously this returned True for any datatype of itemsize 0, but now this
returns false for the non-flexible datatype with itemsize 0, `np.dtype([])`
.
([gh-14393](https://github.com/numpy/numpy/pull/14393))

## New Features[#](#new-features)
### Add our own `*.pxd`
cython import file[#](#add-our-own-pxd-cython-import-file)
Added a `numpy/__init__.pxd`
file. It will be used for `cimport numpy`
([gh-12284](https://github.com/numpy/numpy/pull/12284))

### A tuple of axes can now be input to `expand_dims`
[#](#a-tuple-of-axes-can-now-be-input-to-expand-dims)
The `numpy.expand_dims`
`axis`
keyword can now accept a tuple of
axes. Previously, `axis`
was required to be an integer.
([gh-14051](https://github.com/numpy/numpy/pull/14051))

### Support for 64-bit OpenBLAS[#](#support-for-64-bit-openblas)
Added support for 64-bit (ILP64) OpenBLAS. See `site.cfg.example`
for details.
([gh-15012](https://github.com/numpy/numpy/pull/15012))

### Add `--f2cmap`
option to F2PY[#](#add-f2cmap-option-to-f2py)
Allow specifying a file to load Fortran-to-C type map
customizations from.
([gh-15113](https://github.com/numpy/numpy/pull/15113))

## Improvements[#](#improvements)
### Different C numeric types of the same size have unique names[#](#different-c-numeric-types-of-the-same-size-have-unique-names)
On any given platform, two of `np.intc`
, `np.int_`
, and `np.longlong`
would previously appear indistinguishable through their `repr`
, despite
their corresponding `dtype`
having different properties.
A similar problem existed for the unsigned counterparts to these types, and on
some platforms for `np.double`
and `np.longdouble`

These types now always print with a unique `__name__`
.
([gh-10151](https://github.com/numpy/numpy/pull/10151))

`argwhere`
now produces a consistent result on 0d arrays[#](#argwhere-now-produces-a-consistent-result-on-0d-arrays)
On N-d arrays, `numpy.argwhere`
now always produces an array of shape
`(n_non_zero, arr.ndim)`
, even when `arr.ndim == 0`
. Previously, the
last axis would have a dimension of 1 in this case.
([gh-13610](https://github.com/numpy/numpy/pull/13610))

### Add `axis`
argument for `random.permutation`
and `random.shuffle`
[#](#add-axis-argument-for-random-permutation-and-random-shuffle)
Previously the `random.permutation`
and `random.shuffle`
functions
can only shuffle an array along the first axis; they now have a
new argument `axis`
which allows shuffle along a specified axis.
([gh-13829](https://github.com/numpy/numpy/pull/13829))

`method`
keyword argument for `np.random.multivariate_normal`
[#](#method-keyword-argument-for-np-random-multivariate-normal)
A `method`
keyword argument is now available for
`np.random.multivariate_normal`
with possible values
`{'svd', 'eigh', 'cholesky'}`
. To use it, write
`np.random.multivariate_normal(..., method=<method>)`
.
([gh-14197](https://github.com/numpy/numpy/pull/14197))

### Add complex number support for `numpy.fromstring`
[#](#add-complex-number-support-for-numpy-fromstring)
Now `numpy.fromstring`
can read complex numbers.
([gh-14227](https://github.com/numpy/numpy/pull/14227))

`numpy.unique`
has consistent axes order when `axis`
is not None[#](#numpy-unique-has-consistent-axes-order-when-axis-is-not-none)
Using `moveaxis`
instead of `swapaxes`
in `numpy.unique`
, so that the ordering of axes
except the axis in arguments will not be broken.
([gh-14255](https://github.com/numpy/numpy/pull/14255))

`numpy.matmul`
with boolean output now converts to boolean values[#](#numpy-matmul-with-boolean-output-now-converts-to-boolean-values)
Calling `numpy.matmul`
where the output is a boolean array would fill the array
with uint8 equivalents of the result, rather than 0/1. Now it forces the output
to 0 or 1 (`NPY_TRUE`
or `NPY_FALSE`
).
([gh-14464](https://github.com/numpy/numpy/pull/14464))

`numpy.random.randint`
produced incorrect value when the range was `2**32`
[#](#numpy-random-randint-produced-incorrect-value-when-the-range-was-2-32)
The implementation introduced in 1.17.0 had an incorrect check when
determining whether to use the 32-bit path or the full 64-bit
path that incorrectly redirected random integer generation with a high - low
range of `2**32`
to the 64-bit generator.
([gh-14501](https://github.com/numpy/numpy/pull/14501))

### Add complex number support for `numpy.fromfile`
[#](#add-complex-number-support-for-numpy-fromfile)
Now `numpy.fromfile`
can read complex numbers.
([gh-14730](https://github.com/numpy/numpy/pull/14730))

`std=c99`
added if compiler is named `gcc`
[#](#std-c99-added-if-compiler-is-named-gcc)
GCC before version 5 requires the `-std=c99`
command line argument. Newer
compilers automatically turn on C99 mode. The compiler setup code will
automatically add the code if the compiler name has `gcc`
in it.
([gh-14771](https://github.com/numpy/numpy/pull/14771))

## Changes[#](#changes)
`NaT`
now sorts to the end of arrays[#](#nat-now-sorts-to-the-end-of-arrays)
`NaT`
is now effectively treated as the largest integer for sorting
purposes, so that it sorts to the end of arrays. This change is for consistency
with `NaN`
sorting behavior.
([gh-12658](https://github.com/numpy/numpy/pull/12658))
([gh-15068](https://github.com/numpy/numpy/pull/15068))
### Incorrect `threshold`
in `np.set_printoptions`
raises `TypeError`
or `ValueError`
[#](#incorrect-threshold-in-np-set-printoptions-raises-typeerror-or-valueerror)
Previously an incorrect `threshold`
raised `ValueError`
; it now raises `TypeError`
for non-numeric types and `ValueError`
for `nan`
values.
([gh-13899](https://github.com/numpy/numpy/pull/13899))

### Warn when saving a dtype with metadata[#](#warn-when-saving-a-dtype-with-metadata)
A `UserWarning`
will be emitted when saving an array via `numpy.save`
with
`metadata`
. Saving such an array may not preserve metadata, and if metadata
is preserved, loading it will cause a `ValueError`
. This shortcoming in save
and load will be addressed in a future release.
([gh-14142](https://github.com/numpy/numpy/pull/14142))

`numpy.distutils`
append behavior changed for LDFLAGS and similar[#](#numpy-distutils-append-behavior-changed-for-ldflags-and-similar)
[ numpy.distutils](../reference/distutils.html#module-numpy.distutils) has always overridden rather than appended to
`LDFLAGS`
and
other similar such environment variables for compiling Fortran extensions. Now
the default behavior has changed to appending - which is the expected behavior
in most situations. To preserve the old (overwriting) behavior, set the
`NPY_DISTUTILS_APPEND_FLAGS`
environment variable to 0. This applies to:
`LDFLAGS`
, `F77FLAGS`
, `F90FLAGS`
, `FREEFLAGS`
, `FOPT`
, `FDEBUG`
,
and `FFLAGS`
. NumPy 1.16 and 1.17 gave build warnings in situations where this
change in behavior would have affected the compile flags used.
([gh-14248](https://github.com/numpy/numpy/pull/14248))
### Remove `numpy.random.entropy`
without a deprecation[#](#remove-numpy-random-entropy-without-a-deprecation)
`numpy.random.entropy`
was added to the `numpy.random`
namespace in 1.17.0.
It was meant to be a private c-extension module, but was exposed as public.
It has been replaced by `numpy.random.SeedSequence`
so the module was
completely removed.
([gh-14498](https://github.com/numpy/numpy/pull/14498))
### Add options to quiet build configuration and build with `-Werror`
[#](#add-options-to-quiet-build-configuration-and-build-with-werror)
Added two new configuration options. During the `build_src`
subcommand, as
part of configuring NumPy, the files `_numpyconfig.h`
and `config.h`
are
created by probing support for various runtime functions and routines.
Previously, the very verbose compiler output during this stage clouded more
important information. By default the output is silenced. Running
`runtests.py --debug-info`
will add `--verbose-cfg`
to the `build_src`
subcommand,which will restore the previous behaviour.

Adding `CFLAGS=-Werror`
to turn warnings into errors would trigger errors
during the configuration. Now `runtests.py --warn-error`
will add
`--warn-error`
to the `build`
subcommand, which will percolate to the
`build_ext`
and `build_lib`
subcommands. This will add the compiler flag
to those stages and turn compiler warnings into errors while actually building
NumPy itself, avoiding the `build_src`
subcommand compiler calls.# System configuration[#](#system-configuration)
When NumPy is built, information about system configuration is
recorded, and is made available for extension modules using NumPy’s C
API. These are mostly defined in `numpyconfig.h`
(included in
`ndarrayobject.h`
). The public symbols are prefixed by `NPY_*`
.
NumPy also offers some functions for querying information about the
platform in use.

For private use, NumPy also constructs a `config.h`
in the NumPy
include directory, which is not exported by NumPy (that is a python
extension which use the numpy C API will not see those symbols), to
avoid namespace pollution.

## Data type sizes[#](#data-type-sizes)
The `NPY_SIZEOF_{CTYPE}`
constants are defined so that sizeof
information is available to the pre-processor.

NPY_SIZEOF_SHORT[#](#c.NPY_SIZEOF_SHORT)
-
sizeof(short)

NPY_SIZEOF_INT[#](#c.NPY_SIZEOF_INT)
-
sizeof(int)

NPY_SIZEOF_LONG[#](#c.NPY_SIZEOF_LONG)
-
sizeof(long)

NPY_SIZEOF_LONGLONG[#](#c.NPY_SIZEOF_LONGLONG)
-
sizeof(longlong) where longlong is defined appropriately on the platform.

NPY_SIZEOF_PY_LONG_LONG[#](#c.NPY_SIZEOF_PY_LONG_LONG)
-
NPY_SIZEOF_FLOAT[#](#c.NPY_SIZEOF_FLOAT)
-
sizeof(float)

NPY_SIZEOF_DOUBLE[#](#c.NPY_SIZEOF_DOUBLE)
-
sizeof(double)

NPY_SIZEOF_LONG_DOUBLE[#](#c.NPY_SIZEOF_LONG_DOUBLE)
-
NPY_SIZEOF_LONGDOUBLE[#](#c.NPY_SIZEOF_LONGDOUBLE)
-
sizeof(longdouble)

NPY_SIZEOF_PY_INTPTR_T[#](#c.NPY_SIZEOF_PY_INTPTR_T)
-
NPY_SIZEOF_INTP[#](#c.NPY_SIZEOF_INTP)
-
Size of a pointer on this platform (sizeof(void *))

## Platform information[#](#platform-information)
NPY_CPU_X86[#](#c.NPY_CPU_X86)
-
NPY_CPU_AMD64[#](#c.NPY_CPU_AMD64)
-
NPY_CPU_IA64[#](#c.NPY_CPU_IA64)
-
NPY_CPU_PPC[#](#c.NPY_CPU_PPC)
-
NPY_CPU_PPC64[#](#c.NPY_CPU_PPC64)
-
NPY_CPU_SPARC[#](#c.NPY_CPU_SPARC)
-
NPY_CPU_SPARC64[#](#c.NPY_CPU_SPARC64)
-
NPY_CPU_S390[#](#c.NPY_CPU_S390)
-
NPY_CPU_PARISC[#](#c.NPY_CPU_PARISC)
-
New in version 1.3.0.

CPU architecture of the platform; only one of the above is defined.

Defined in

`numpy/npy_cpu.h`
NPY_LITTLE_ENDIAN[#](#c.NPY_LITTLE_ENDIAN)
-
NPY_BIG_ENDIAN[#](#c.NPY_BIG_ENDIAN)
-
NPY_BYTE_ORDER[#](#c.NPY_BYTE_ORDER)
-
New in version 1.3.0.

Portable alternatives to the

`endian.h`
macros of GNU Libc. If big endian,==`NPY_BYTE_ORDER`
, and similarly for little endian architectures.`NPY_BIG_ENDIAN`
Defined in

`numpy/npy_endian.h`
.
int PyArray_GetEndianness()[#](#c.PyArray_GetEndianness)
-
New in version 1.3.0.

Returns the endianness of the current platform. One of

,`NPY_CPU_BIG`
, or`NPY_CPU_LITTLE`
.`NPY_CPU_UNKNOWN_ENDIAN`
NPY_CPU_BIG[#](#c.PyArray_GetEndianness.NPY_CPU_BIG)
-
NPY_CPU_LITTLE[#](#c.PyArray_GetEndianness.NPY_CPU_LITTLE)
-
NPY_CPU_UNKNOWN_ENDIAN[#](#c.PyArray_GetEndianness.NPY_CPU_UNKNOWN_ENDIAN)
-
NPY_CPU_BIG
-
## Compiler directives[#](#compiler-directives)
NPY_LIKELY[#](#c.NPY_LIKELY)
-
NPY_UNLIKELY[#](#c.NPY_UNLIKELY)
-
NPY_UNUSED[#](#c.NPY_UNUSED)
-# NumPy 1.25.0 Release Notes[#](#numpy-1-25-0-release-notes)
The NumPy 1.25.0 release continues the ongoing work to improve the handling and promotion of dtypes, increase the execution speed, and clarify the documentation. There has also been work to prepare for the future NumPy 2.0.0 release, resulting in a large number of new and expired deprecation. Highlights are:

Support for MUSL, there are now MUSL wheels.

Support the Fujitsu C/C++ compiler.

Object arrays are now supported in einsum

Support for inplace matrix multiplication (

`@=`
).
We will be releasing a NumPy 1.26 when Python 3.12 comes out. That is needed because distutils has been dropped by Python 3.12 and we will be switching to using meson for future builds. The next mainline release will be NumPy 2.0.0. We plan that the 2.0 series will still support downstream projects built against earlier versions of NumPy.

The Python versions supported in this release are 3.9-3.11.

## Deprecations[#](#deprecations)
`np.core.MachAr`
is deprecated. It is private API. In names defined in`np.core`
should generally be considered private.(

[gh-22638](https://github.com/numpy/numpy/pull/22638))
`np.finfo(None)`
is deprecated.(

[gh-23011](https://github.com/numpy/numpy/pull/23011))
`np.round_`
is deprecated. Use*np.round*instead.(

[gh-23302](https://github.com/numpy/numpy/pull/23302))
`np.product`
is deprecated. Use*np.prod*instead.(

[gh-23314](https://github.com/numpy/numpy/pull/23314))
`np.cumproduct`
is deprecated. Use*np.cumprod*instead.(

[gh-23314](https://github.com/numpy/numpy/pull/23314))
`np.sometrue`
is deprecated. Use*np.any*instead.(

[gh-23314](https://github.com/numpy/numpy/pull/23314))
`np.alltrue`
is deprecated. Use*np.all*instead.(

[gh-23314](https://github.com/numpy/numpy/pull/23314))
Only ndim-0 arrays are treated as scalars. NumPy used to treat all arrays of size 1 (e.g.,

`np.array([3.14])`
) as scalars. In the future, this will be limited to arrays of ndim 0 (e.g.,`np.array(3.14)`
). The following expressions will report a deprecation warning:a = np.array([3.14]) float(a) # better: a[0] to get the numpy.float or a.item() b = np.array([[3.14]]) c = numpy.random.rand(10) c[0] = b # better: c[0] = b[0, 0]
(

[gh-10615](https://github.com/numpy/numpy/pull/10615))
`np.find_common_type`
is deprecated.is now deprecated and its use should be replaced with either`numpy.find_common_type`
or`numpy.result_type`
. Most users leave the second`numpy.promote_types`
`scalar_types`
argument to`find_common_type`
as`[]`
in which case`np.result_type`
and`np.promote_types`
are both faster and more robust. When not using`scalar_types`
the main difference is that the replacement intentionally converts non-native byte-order to native byte order. Further,`find_common_type`
returns`object`
dtype rather than failing promotion. This leads to differences when the inputs are not all numeric. Importantly, this also happens for e.g. timedelta/datetime for which NumPy promotion rules are currently sometimes surprising.When the

`scalar_types`
argument is not`[]`
things are more complicated. In most cases, using`np.result_type`
and passing the Python values`0`
,`0.0`
, or`0j`
has the same result as using`int`
,`float`
, or`complex`
in*scalar_types*.When

`scalar_types`
is constructed,`np.result_type`
is the correct replacement and it may be passed scalar values like`np.float32(0.0)`
. Passing values other than 0, may lead to value-inspecting behavior (which`np.find_common_type`
never used and NEP 50 may change in the future). The main possible change in behavior in this case, is when the array types are signed integers and scalar types are unsigned.If you are unsure about how to replace a use of

`scalar_types`
or when non-numeric dtypes are likely, please do not hesitate to open a NumPy issue to ask for help.(

[gh-22539](https://github.com/numpy/numpy/pull/22539))
## Expired deprecations[#](#expired-deprecations)
`np.core.machar`
and`np.finfo.machar`
have been removed.(

[gh-22638](https://github.com/numpy/numpy/pull/22638))
`+arr`
will now raise an error when the dtype is not numeric (and positive is undefined).(

[gh-22998](https://github.com/numpy/numpy/pull/22998))
A sequence must now be passed into the stacking family of functions (

`stack`
,`vstack`
,`hstack`
,`dstack`
and`column_stack`
).(

[gh-23019](https://github.com/numpy/numpy/pull/23019))
`np.clip`
now defaults to same-kind casting. Falling back to unsafe casting was deprecated in NumPy 1.17.(

[gh-23403](https://github.com/numpy/numpy/pull/23403))
`np.clip`
will now propagate`np.nan`
values passed as`min`
or`max`
. Previously, a scalar NaN was usually ignored. This was deprecated in NumPy 1.17.(

[gh-23403](https://github.com/numpy/numpy/pull/23403))
The

`np.dual`
submodule has been removed.(

[gh-23480](https://github.com/numpy/numpy/pull/23480))
NumPy now always ignores sequence behavior for an array-like (defining one of the array protocols). (Deprecation started NumPy 1.20)

(

[gh-23660](https://github.com/numpy/numpy/pull/23660))
The niche

`FutureWarning`
when casting to a subarray dtype in`astype`
or the array creation functions such as`asarray`
is now finalized. The behavior is now always the same as if the subarray dtype was wrapped into a single field (which was the workaround, previously). (FutureWarning since NumPy 1.20)(

[gh-23666](https://github.com/numpy/numpy/pull/23666))
`==`
and`!=`
warnings have been finalized. The`==`
and`!=`
operators on arrays now always:raise errors that occur during comparisons such as when the arrays have incompatible shapes (

`np.array([1, 2]) == np.array([1, 2, 3])`
).
return an array of all

`True`
or all`False`
when values are fundamentally not comparable (e.g. have different dtypes). An example is`np.array(["a"]) == np.array([1])`
.This mimics the Python behavior of returning

`False`
and`True`
when comparing incompatible types like`"a" == 1`
and`"a" != 1`
. For a long time these gave`DeprecationWarning`
or`FutureWarning`
.
(

[gh-22707](https://github.com/numpy/numpy/pull/22707))
Nose support has been removed. NumPy switched to using pytest in 2018 and nose has been unmaintained for many years. We have kept NumPy’s nose support to avoid breaking downstream projects who might have been using it and not yet switched to pytest or some other testing framework. With the arrival of Python 3.12, unpatched nose will raise an error. It is time to move on.

*Decorators removed*:raises

slow

setastest

skipif

knownfailif

deprecated

parametrize

_needs_refcount

These are not to be confused with pytest versions with similar names, e.g., pytest.mark.slow, pytest.mark.skipif, pytest.mark.parametrize.

*Functions removed*:Tester

import_nose

run_module_suite

(

[gh-23041](https://github.com/numpy/numpy/pull/23041))
The

`numpy.testing.utils`
shim has been removed. Importing from the`numpy.testing.utils`
shim has been deprecated since 2019, the shim has now been removed. All imports should be made directly from`numpy.testing`
.(

[gh-23060](https://github.com/numpy/numpy/pull/23060))
The environment variable to disable dispatching has been removed. Support for the

`NUMPY_EXPERIMENTAL_ARRAY_FUNCTION`
environment variable has been removed. This variable disabled dispatching with`__array_function__`
.(

[gh-23376](https://github.com/numpy/numpy/pull/23376))
Support for

`y=`
as an alias of`out=`
has been removed. The`fix`
,`isposinf`
and`isneginf`
functions allowed using`y=`
as a (deprecated) alias for`out=`
. This is no longer supported.(

[gh-23376](https://github.com/numpy/numpy/pull/23376))
## Compatibility notes[#](#compatibility-notes)
The

`busday_count`
method now correctly handles cases where the`begindates`
is later in time than the`enddates`
. Previously, the`enddates`
was included, even though the documentation states it is always excluded.(

[gh-23229](https://github.com/numpy/numpy/pull/23229))
When comparing datetimes and timedelta using

`np.equal`
or`np.not_equal`
numpy previously allowed the comparison with`casting="unsafe"`
. This operation now fails. Forcing the output dtype using the`dtype`
kwarg can make the operation succeed, but we do not recommend it.(

[gh-22707](https://github.com/numpy/numpy/pull/22707))
When loading data from a file handle using

`np.load`
, if the handle is at the end of file, as can happen when reading multiple arrays by calling`np.load`
repeatedly, numpy previously raised`ValueError`
if`allow_pickle=False`
, and`OSError`
if`allow_pickle=True`
. Now it raises`EOFError`
instead, in both cases.(

[gh-23105](https://github.com/numpy/numpy/pull/23105))
`np.pad`
with `mode=wrap`
pads with strict multiples of original data[#](#np-pad-with-mode-wrap-pads-with-strict-multiples-of-original-data)
Code based on earlier version of `pad`
that uses `mode="wrap"`
will return
different results when the padding size is larger than initial array.

`np.pad`
with `mode=wrap`
now always fills the space with
strict multiples of original data even if the padding size is larger than the
initial array.
([gh-22575](https://github.com/numpy/numpy/pull/22575))

### Cython `long_t`
and `ulong_t`
removed[#](#cython-long-t-and-ulong-t-removed)
`long_t`
and `ulong_t`
were aliases for `longlong_t`
and `ulonglong_t`
and confusing (a remainder from of Python 2). This change may lead to the errors:
```
'long_t' is not a type identifier
'ulong_t' is not a type identifier
```
We recommend use of bit-sized types such as `cnp.int64_t`
or the use of
`cnp.intp_t`
which is 32 bits on 32 bit systems and 64 bits on 64 bit
systems (this is most compatible with indexing).
If C `long`
is desired, use plain `long`
or `npy_long`
.
`cnp.int_t`
is also `long`
(NumPy’s default integer). However, `long`
is 32 bit on 64 bit windows and we may wish to adjust this even in NumPy.
(Please do not hesitate to contact NumPy developers if you are curious about this.)

([gh-22637](https://github.com/numpy/numpy/pull/22637))

### Changed error message and type for bad `axes`
argument to `ufunc`
[#](#changed-error-message-and-type-for-bad-axes-argument-to-ufunc)
The error message and type when a wrong `axes`
value is passed to
`ufunc(..., axes=[...])``
has changed. The message is now more indicative of
the problem, and if the value is mismatched an `AxisError`
will be raised.
A `TypeError`
will still be raised for invalid input types.

([gh-22675](https://github.com/numpy/numpy/pull/22675))

### Array-likes that define `__array_ufunc__`
can now override ufuncs if used as `where`
[#](#array-likes-that-define-array-ufunc-can-now-override-ufuncs-if-used-as-where)
If the `where`
keyword argument of a [ numpy.ufunc](../reference/generated/numpy.ufunc.html#numpy.ufunc) is a subclass of

[or is a duck type that defines](../reference/generated/numpy.ndarray.html#numpy.ndarray)
`numpy.ndarray`
[it can override the behavior of the ufunc using the same mechanism as the input and output arguments. Note that for this to work properly, the](../reference/arrays.classes.html#numpy.class.__array_ufunc__)
`numpy.class.__array_ufunc__`
`where.__array_ufunc__`
implementation will have to unwrap the `where`
argument to pass it into the
default implementation of the `ufunc`
or, for [subclasses before using](../reference/generated/numpy.ndarray.html#numpy.ndarray)
`numpy.ndarray`
`super().__array_ufunc__`
.([gh-23240](https://github.com/numpy/numpy/pull/23240))

### Compiling against the NumPy C API is now backwards compatible by default[#](#compiling-against-the-numpy-c-api-is-now-backwards-compatible-by-default)
NumPy now defaults to exposing a backwards compatible subset of the C-API.
This makes the use of `oldest-supported-numpy`
unnecessary.
Libraries can override the default minimal version to be compatible with
using:

```
#define NPY_TARGET_VERSION NPY_1_22_API_VERSION
```
before including NumPy or by passing the equivalent `-D`
option to the
compiler.
The NumPy 1.25 default is `NPY_1_19_API_VERSION`
. Because the NumPy 1.19
C API was identical to the NumPy 1.16 one resulting programs will be compatible
with NumPy 1.16 (from a C-API perspective).
This default will be increased in future non-bugfix releases.
You can still compile against an older NumPy version and run on a newer one.

For more details please see [For downstream package authors](../dev/depending_on_numpy.html#for-downstream-package-authors).

([gh-23528](https://github.com/numpy/numpy/pull/23528))

## New Features[#](#new-features)
`np.einsum`
now accepts arrays with `object`
dtype[#](#np-einsum-now-accepts-arrays-with-object-dtype)
The code path will call python operators on object dtype arrays, much
like `np.dot`
and `np.matmul`
.

([gh-18053](https://github.com/numpy/numpy/pull/18053))

### Add support for inplace matrix multiplication[#](#add-support-for-inplace-matrix-multiplication)
It is now possible to perform inplace matrix multiplication
via the `@=`
operator.

```
>>> import numpy as np
>>> a = np.arange(6).reshape(3, 2)
>>> print(a)
[[0 1]
[2 3]
[4 5]]
>>> b = np.ones((2, 2), dtype=int)
>>> a @= b
>>> print(a)
[[1 1]
[5 5]
[9 9]]
```
([gh-21120](https://github.com/numpy/numpy/pull/21120))

### Added `NPY_ENABLE_CPU_FEATURES`
environment variable[#](#added-npy-enable-cpu-features-environment-variable)
Users may now choose to enable only a subset of the built CPU features at
runtime by specifying the *NPY_ENABLE_CPU_FEATURES* environment variable.
Note that these specified features must be outside the baseline, since those
are always assumed. Errors will be raised if attempting to enable a feature
that is either not supported by your CPU, or that NumPy was not built with.

([gh-22137](https://github.com/numpy/numpy/pull/22137))

### NumPy now has an `np.exceptions`
namespace[#](#numpy-now-has-an-np-exceptions-namespace)
NumPy now has a dedicated namespace making most exceptions and warnings available. All of these remain available in the main namespace, although some may be moved slowly in the future. The main reason for this is to increase discoverability and add future exceptions.

([gh-22644](https://github.com/numpy/numpy/pull/22644))

`np.linalg`
functions return NamedTuples[#](#np-linalg-functions-return-namedtuples)
`np.linalg`
functions that return tuples now return namedtuples. These
functions are `eig()`
, `eigh()`
, `qr()`
, `slogdet()`
, and `svd()`
.
The return type is unchanged in instances where these functions return
non-tuples with certain keyword arguments (like `svd(compute_uv=False)`
).
([gh-22786](https://github.com/numpy/numpy/pull/22786))

### String functions in `np.char`
are compatible with NEP 42 custom dtypes[#](#string-functions-in-np-char-are-compatible-with-nep-42-custom-dtypes)
Custom dtypes that represent unicode strings or byte strings can now be
passed to the string functions in `np.char`
.

([gh-22863](https://github.com/numpy/numpy/pull/22863))

### String dtype instances can be created from the string abstract dtype classes[#](#string-dtype-instances-can-be-created-from-the-string-abstract-dtype-classes)
It is now possible to create a string dtype instance with a size without
using the string name of the dtype. For example, `type(np.dtype('U'))(8)`
will create a dtype that is equivalent to `np.dtype('U8')`
. This feature
is most useful when writing generic code dealing with string dtype
classes.

([gh-22963](https://github.com/numpy/numpy/pull/22963))

### Fujitsu C/C++ compiler is now supported[#](#fujitsu-c-c-compiler-is-now-supported)
Support for Fujitsu compiler has been added. To build with Fujitsu compiler, run:

python setup.py build -c fujitsu

### SSL2 is now supported[#](#ssl2-is-now-supported)
Support for SSL2 has been added. SSL2 is a library that provides OpenBLAS compatible GEMM functions. To enable SSL2, it need to edit site.cfg and build with Fujitsu compiler. See site.cfg.example.

([gh-22982](https://github.com/numpy/numpy/pull/22982))

## Improvements[#](#improvements)
`NDArrayOperatorsMixin`
specifies that it has no `__slots__`
[#](#ndarrayoperatorsmixin-specifies-that-it-has-no-slots)
The `NDArrayOperatorsMixin`
class now specifies that it contains no
`__slots__`
, ensuring that subclasses can now make use of this feature in
Python.

([gh-23113](https://github.com/numpy/numpy/pull/23113))

### Fix power of complex zero[#](#fix-power-of-complex-zero)
`np.power`
now returns a different result for `0^{non-zero}`
for complex numbers. Note that the value is only defined when
the real part of the exponent is larger than zero.
Previously, NaN was returned unless the imaginary part was strictly
zero. The return value is either `0+0j`
or `0-0j`
.
([gh-18535](https://github.com/numpy/numpy/pull/18535))

### New `DTypePromotionError`
[#](#new-dtypepromotionerror)
NumPy now has a new `DTypePromotionError`
which is used when two
dtypes cannot be promoted to a common one, for example:

```
np.result_type("M8[s]", np.complex128)
```
raises this new exception.

([gh-22707](https://github.com/numpy/numpy/pull/22707))

*np.show_config* uses information from Meson[#](#np-show-config-uses-information-from-meson)
Build and system information now contains information from Meson.
*np.show_config* now has a new optional parameter `mode`
to help
customize the output.

([gh-22769](https://github.com/numpy/numpy/pull/22769))

### Fix `np.ma.diff`
not preserving the mask when called with arguments prepend/append.[#](#fix-np-ma-diff-not-preserving-the-mask-when-called-with-arguments-prepend-append)
Calling `np.ma.diff`
with arguments prepend and/or append now returns a
`MaskedArray`
with the input mask preserved.

Previously, a `MaskedArray`
without the mask was returned.

([gh-22776](https://github.com/numpy/numpy/pull/22776))

### Corrected error handling for NumPy C-API in Cython[#](#corrected-error-handling-for-numpy-c-api-in-cython)
Many NumPy C functions defined for use in Cython were lacking the
correct error indicator like `except -1`
or `except *`
.
These have now been added.

([gh-22997](https://github.com/numpy/numpy/pull/22997))

### Ability to directly spawn random number generators[#](#ability-to-directly-spawn-random-number-generators)
[ numpy.random.Generator.spawn](../reference/random/generated/numpy.random.Generator.spawn.html#numpy.random.Generator.spawn) now allows to directly spawn new
independent child generators via the
[mechanism.](../reference/random/bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn)
`numpy.random.SeedSequence.spawn`
[does the same for the underlying bit generator.](../reference/random/bit_generators/generated/numpy.random.BitGenerator.spawn.html#numpy.random.BitGenerator.spawn)
`numpy.random.BitGenerator.spawn`
Additionally, [ numpy.random.BitGenerator.seed_seq](../reference/random/bit_generators/generated/numpy.random.BitGenerator.seed_seq.html#numpy.random.BitGenerator.seed_seq) now gives direct
access to the seed sequence used for initializing the bit generator.
This allows for example:

```
seed = 0x2e09b90939db40c400f8f22dae617151
rng = np.random.default_rng(seed)
child_rng1, child_rng2 = rng.spawn(2)
# safely use rng, child_rng1, and child_rng2
```
Previously, this was hard to do without passing the `SeedSequence`
explicitly. Please see [ numpy.random.SeedSequence](../reference/random/bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) for more information.

([gh-23195](https://github.com/numpy/numpy/pull/23195))

`numpy.logspace`
now supports a non-scalar `base`
argument[#](#numpy-logspace-now-supports-a-non-scalar-base-argument)
The `base`
argument of `numpy.logspace`
can now be array-like if it is
broadcastable against the `start`
and `stop`
arguments.

([gh-23275](https://github.com/numpy/numpy/pull/23275))

`np.ma.dot()`
now supports for non-2d arrays[#](#np-ma-dot-now-supports-for-non-2d-arrays)
Previously `np.ma.dot()`
only worked if `a`
and `b`
were both 2d.
Now it works for non-2d arrays as well as `np.dot()`
.

([gh-23322](https://github.com/numpy/numpy/pull/23322))

### Explicitly show keys of .npz file in repr[#](#explicitly-show-keys-of-npz-file-in-repr)
`NpzFile`
shows keys of loaded .npz file when printed.
```
>>> npzfile = np.load('arr.npz')
>>> npzfile
NpzFile 'arr.npz' with keys arr_0, arr_1, arr_2, arr_3, arr_4...
```
([gh-23357](https://github.com/numpy/numpy/pull/23357))

### NumPy now exposes DType classes in `np.dtypes`
[#](#numpy-now-exposes-dtype-classes-in-np-dtypes)
The new `numpy.dtypes`
module now exposes DType classes and
will contain future dtype related functionality.
Most users should have no need to use these classes directly.

([gh-23358](https://github.com/numpy/numpy/pull/23358))

### Drop dtype metadata before saving in .npy or .npz files[#](#drop-dtype-metadata-before-saving-in-npy-or-npz-files)
Currently, a `*.npy`
file containing a table with a dtype with
metadata cannot be read back.
Now, *np.save* and *np.savez* drop metadata before saving.

([gh-23371](https://github.com/numpy/numpy/pull/23371))

`numpy.lib.recfunctions.structured_to_unstructured`
returns views in more cases[#](#numpy-lib-recfunctions-structured-to-unstructured-returns-views-in-more-cases)
`structured_to_unstructured`
now returns a view, if the stride between the
fields is constant. Prior, padding between the fields or a reversed field
would lead to a copy.
This change only applies to `ndarray`
, `memmap`
and `recarray`
. For all
other array subclasses, the behavior remains unchanged.
([gh-23652](https://github.com/numpy/numpy/pull/23652))

### Signed and unsigned integers always compare correctly[#](#signed-and-unsigned-integers-always-compare-correctly)
When `uint64`
and `int64`
are mixed in NumPy, NumPy typically
promotes both to `float64`
. This behavior may be argued about
but is confusing for comparisons `==`
, `<=`
, since the results
returned can be incorrect but the conversion is hidden since the
result is a boolean.
NumPy will now return the correct results for these by avoiding
the cast to float.

([gh-23713](https://github.com/numpy/numpy/pull/23713))

## Performance improvements and changes[#](#performance-improvements-and-changes)
### Faster `np.argsort`
on AVX-512 enabled processors[#](#faster-np-argsort-on-avx-512-enabled-processors)
32-bit and 64-bit quicksort algorithm for np.argsort gain up to 6x speed up on processors that support AVX-512 instruction set.

Thanks to [Intel corporation](https://open.intel.com/) for sponsoring this
work.

([gh-23707](https://github.com/numpy/numpy/pull/23707))

### Faster `np.sort`
on AVX-512 enabled processors[#](#faster-np-sort-on-avx-512-enabled-processors)
Quicksort for 16-bit and 64-bit dtypes gain up to 15x and 9x speed up on processors that support AVX-512 instruction set.

Thanks to [Intel corporation](https://open.intel.com/) for sponsoring this
work.

([gh-22315](https://github.com/numpy/numpy/pull/22315))

`__array_function__`
machinery is now much faster[#](#array-function-machinery-is-now-much-faster)
The overhead of the majority of functions in NumPy is now smaller especially when keyword arguments are used. This change significantly speeds up many simple function calls.

([gh-23020](https://github.com/numpy/numpy/pull/23020))

`ufunc.at`
can be much faster[#](#ufunc-at-can-be-much-faster)
Generic `ufunc.at`
can be up to 9x faster. The conditions for this speedup:

operands are aligned

no casting

If ufuncs with appropriate indexed loops on 1d arguments with the above
conditions, `ufunc.at`
can be up to 60x faster (an additional 7x speedup).
Appropriate indexed loops have been added to `add`
, `subtract`
,
`multiply`
, `floor_divide`
, `maximum`
, `minimum`
, `fmax`
, and
`fmin`
.

The internal logic is similar to the logic used for regular ufuncs, which also have fast paths.

Thanks to the [D. E. Shaw group](https://deshaw.com/) for sponsoring this
work.

([gh-23136](https://github.com/numpy/numpy/pull/23136))

### Faster membership test on `NpzFile`
[#](#faster-membership-test-on-npzfile)
Membership test on `NpzFile`
will no longer
decompress the archive if it is successful.

([gh-23661](https://github.com/numpy/numpy/pull/23661))

## Changes[#](#changes)
`np.r_[]`
and `np.c_[]`
with certain scalar values[#](#np-r-and-np-c-with-certain-scalar-values)
In rare cases, using mainly `np.r_`
with scalars can lead to different
results. The main potential changes are highlighted by the following:

```
>>> np.r_[np.arange(5, dtype=np.uint8), -1].dtype
int16 # rather than the default integer (int64 or int32)
>>> np.r_[np.arange(5, dtype=np.int8), 255]
array([ 0, 1, 2, 3, 4, 255], dtype=int16)
```
Where the second example returned:

```
array([ 0, 1, 2, 3, 4, -1], dtype=int8)
```
The first one is due to a signed integer scalar with an unsigned integer
array, while the second is due to `255`
not fitting into `int8`
and
NumPy currently inspecting values to make this work.
(Note that the second example is expected to change in the future due to
[NEP 50](https://numpy.org/neps/nep-0050-scalar-promotion.html#nep50); it will then raise an error.)

([gh-22539](https://github.com/numpy/numpy/pull/22539))

### Most NumPy functions are wrapped into a C-callable[#](#most-numpy-functions-are-wrapped-into-a-c-callable)
To speed up the `__array_function__`
dispatching, most NumPy functions
are now wrapped into C-callables and are not proper Python functions or
C methods.
They still look and feel the same as before (like a Python function), and this
should only improve performance and user experience (cleaner tracebacks).
However, please inform the NumPy developers if this change confuses your
program for some reason.

([gh-23020](https://github.com/numpy/numpy/pull/23020))

### C++ standard library usage[#](#c-standard-library-usage)
NumPy builds now depend on the C++ standard library, because
the `numpy.core._multiarray_umath`
extension is linked with
the C++ linker.

([gh-23601](https://github.com/numpy/numpy/pull/23601))# NumPy 1.23.0 Release Notes[#](#numpy-1-23-0-release-notes)
The NumPy 1.23.0 release continues the ongoing work to improve the handling and promotion of dtypes, increase the execution speed, clarify the documentation, and expire old deprecations. The highlights are:

Implementation of

`loadtxt`
in C, greatly improving its performance.
Exposing DLPack at the Python level for easy data exchange.

Changes to the promotion and comparisons of structured dtypes.

Improvements to f2py.

See below for the details,

## New functions[#](#new-functions)
A masked array specialization of

`ndenumerate`
is now available as`numpy.ma.ndenumerate`
. It provides an alternative to`numpy.ndenumerate`
and skips masked values by default.(

[gh-20020](https://github.com/numpy/numpy/pull/20020))
`numpy.from_dlpack`
has been added to allow easy exchange of data using the DLPack protocol. It accepts Python objects that implement the`__dlpack__`
and`__dlpack_device__`
methods and returns a ndarray object which is generally the view of the data of the input object.(

[gh-21145](https://github.com/numpy/numpy/pull/21145))
## Deprecations[#](#deprecations)
Setting

`__array_finalize__`
to`None`
is deprecated. It must now be a method and may wish to call`super().__array_finalize__(obj)`
after checking for`None`
or if the NumPy version is sufficiently new.(

[gh-20766](https://github.com/numpy/numpy/pull/20766))
Using

`axis=32`
(`axis=np.MAXDIMS`
) in many cases had the same meaning as`axis=None`
. This is deprecated and`axis=None`
must be used instead.(

[gh-20920](https://github.com/numpy/numpy/pull/20920))
The hook function

`PyDataMem_SetEventHook`
has been deprecated and the demonstration of its use in tool/allocation_tracking has been removed. The ability to track allocations is now built-in to python via`tracemalloc`
.(

[gh-20394](https://github.com/numpy/numpy/pull/20394))
`numpy.distutils`
has been deprecated, as a result of`distutils`
itself being deprecated. It will not be present in NumPy for Python >= 3.12, and will be removed completely 2 years after the release of Python 3.12 For more details, see[Status of numpy.distutils and migration advice](../reference/distutils_status_migration.html#distutils-status-migration).(

[gh-20875](https://github.com/numpy/numpy/pull/20875))
`numpy.loadtxt`
will now give a`DeprecationWarning`
when an integer`dtype`
is requested but the value is formatted as a floating point number.(

[gh-21663](https://github.com/numpy/numpy/pull/21663))
## Expired deprecations[#](#expired-deprecations)
The

`NpzFile.iteritems()`
and`NpzFile.iterkeys()`
methods have been removed as part of the continued removal of Python 2 compatibility. This concludes the deprecation from 1.15.(

[gh-16830](https://github.com/numpy/numpy/pull/16830))
The

`alen`
and`asscalar`
functions have been removed.(

[gh-20414](https://github.com/numpy/numpy/pull/20414))
The

`UPDATEIFCOPY`
array flag has been removed together with the enum`NPY_ARRAY_UPDATEIFCOPY`
. The associated (and deprecated)`PyArray_XDECREF_ERR`
was also removed. These were all deprecated in 1.14. They are replaced by`NPY_ARRAY_WRITEBACKIFCOPY`
, that requires calling`PyArray_ResolveWritebackIfCopy`
before the array is deallocated.(

[gh-20589](https://github.com/numpy/numpy/pull/20589))
Exceptions will be raised during array-like creation. When an object raised an exception during access of the special attributes

`__array__`
or`__array_interface__`
, this exception was usually ignored. This behaviour was deprecated in 1.21, and the exception will now be raised.(

[gh-20835](https://github.com/numpy/numpy/pull/20835))
Multidimensional indexing with non-tuple values is not allowed. Previously, code such as

`arr[ind]`
where`ind = [[0, 1], [0, 1]]`
produced a`FutureWarning`
and was interpreted as a multidimensional index (i.e.,`arr[tuple(ind)]`
). Now this example is treated like an array index over a single dimension (`arr[array(ind)]`
). Multidimensional indexing with anything but a tuple was deprecated in NumPy 1.15.(

[gh-21029](https://github.com/numpy/numpy/pull/21029))
Changing to a dtype of different size in F-contiguous arrays is no longer permitted. Deprecated since Numpy 1.11.0. See below for an extended explanation of the effects of this change.

(

[gh-20722](https://github.com/numpy/numpy/pull/20722))
## New Features[#](#new-features)
### crackfortran has support for operator and assignment overloading[#](#crackfortran-has-support-for-operator-and-assignment-overloading)
`crackfortran`
parser now understands operator and assignment
definitions in a module. They are added in the `body`
list of the
module which contains a new key `implementedby`
listing the names
of the subroutines or functions implementing the operator or
assignment.
([gh-15006](https://github.com/numpy/numpy/pull/15006))

### f2py supports reading access type attributes from derived type statements[#](#f2py-supports-reading-access-type-attributes-from-derived-type-statements)
As a result, one does not need to use `public`
or `private`
statements to
specify derived type access properties.

([gh-15844](https://github.com/numpy/numpy/pull/15844))

### New parameter `ndmin`
added to `genfromtxt`
[#](#new-parameter-ndmin-added-to-genfromtxt)
This parameter behaves the same as `ndmin`
from `numpy.loadtxt`
.

([gh-20500](https://github.com/numpy/numpy/pull/20500))

`np.loadtxt`
now supports quote character and single converter function[#](#np-loadtxt-now-supports-quote-character-and-single-converter-function)
`numpy.loadtxt`
now supports an additional `quotechar`
keyword argument
which is not set by default. Using `quotechar='"'`
will read quoted fields
as used by the Excel CSV dialect.
Further, it is now possible to pass a single callable rather than a dictionary
for the `converters`
argument.

([gh-20580](https://github.com/numpy/numpy/pull/20580))

### Changing to dtype of a different size now requires contiguity of only the last axis[#](#changing-to-dtype-of-a-different-size-now-requires-contiguity-of-only-the-last-axis)
Previously, viewing an array with a dtype of a different item size required that the entire array be C-contiguous. This limitation would unnecessarily force the user to make contiguous copies of non-contiguous arrays before being able to change the dtype.

This change affects not only `ndarray.view`
, but other construction
mechanisms, including the discouraged direct assignment to `ndarray.dtype`
.

This change expires the deprecation regarding the viewing of F-contiguous arrays, described elsewhere in the release notes.

([gh-20722](https://github.com/numpy/numpy/pull/20722))

### Deterministic output files for F2PY[#](#deterministic-output-files-for-f2py)
For F77 inputs, `f2py`
will generate `modname-f2pywrappers.f`
unconditionally, though these may be empty. For free-form inputs,
`modname-f2pywrappers.f`
, `modname-f2pywrappers2.f90`
will both be generated
unconditionally, and may be empty. This allows writing generic output rules in
`cmake`
or `meson`
and other build systems. Older behavior can be restored
by passing `--skip-empty-wrappers`
to `f2py`
. [Using via meson](../f2py/buildtools/meson.html#f2py-meson) details usage.

([gh-21187](https://github.com/numpy/numpy/pull/21187))

`keepdims`
parameter for `average`
[#](#keepdims-parameter-for-average)
The parameter `keepdims`
was added to the functions `numpy.average`
and `numpy.ma.average`
. The parameter has the same meaning as it
does in reduction functions such as `numpy.sum`
or `numpy.mean`
.

([gh-21485](https://github.com/numpy/numpy/pull/21485))

### New parameter `equal_nan`
added to `np.unique`
[#](#new-parameter-equal-nan-added-to-np-unique)
`np.unique`
was changed in 1.21 to treat all `NaN`
values as equal and return
a single `NaN`
. Setting `equal_nan=False`
will restore pre-1.21 behavior
to treat `NaNs`
as unique. Defaults to `True`
.
([gh-21623](https://github.com/numpy/numpy/pull/21623))

## Compatibility notes[#](#compatibility-notes)
### 1D `np.linalg.norm`
preserves float input types, even for scalar results[#](#d-np-linalg-norm-preserves-float-input-types-even-for-scalar-results)
Previously, this would promote to `float64`
when the `ord`
argument was
not one of the explicitly listed values, e.g. `ord=3`
:

```
>>> f32 = np.float32([1, 2])
>>> np.linalg.norm(f32, 2).dtype
dtype('float32')
>>> np.linalg.norm(f32, 3)
dtype('float64') # numpy 1.22
dtype('float32') # numpy 1.23
```
This change affects only `float32`
and `float16`
vectors with `ord`
other than `-Inf`
, `0`
, `1`
, `2`
, and `Inf`
.

([gh-17709](https://github.com/numpy/numpy/pull/17709))

### Changes to structured (void) dtype promotion and comparisons[#](#changes-to-structured-void-dtype-promotion-and-comparisons)
In general, NumPy now defines correct, but slightly limited, promotion for structured dtypes by promoting the subtypes of each field instead of raising an exception:

```
>>> np.result_type(np.dtype("i,i"), np.dtype("i,d"))
dtype([('f0', '<i4'), ('f1', '<f8')])
```
For promotion matching field names, order, and titles are enforced, however
padding is ignored.
Promotion involving structured dtypes now always ensures native byte-order for
all fields (which may change the result of `np.concatenate`
)
and ensures that the result will be “packed”, i.e. all fields are ordered
contiguously and padding is removed.
See [Structure Comparison and Promotion](../user/basics.rec.html#structured-dtype-comparison-and-promotion) for further details.

The `repr`
of aligned structures will now never print the long form including
`offsets`
and `itemsize`
unless the structure includes padding not
guaranteed by `align=True`
.

In alignment with the above changes to the promotion logic, the casting safety has been updated:

`"equiv"`
enforces matching names and titles. The itemsize is allowed to differ due to padding.
`"safe"`
allows mismatching field names and titles
The cast safety is limited by the cast safety of each included field.

The order of fields is used to decide cast safety of each individual field. Previously, the field names were used and only unsafe casts were possible when names mismatched.

The main important change here is that name mismatches are now considered “safe” casts.

([gh-19226](https://github.com/numpy/numpy/pull/19226))

`NPY_RELAXED_STRIDES_CHECKING`
has been removed[#](#npy-relaxed-strides-checking-has-been-removed)
NumPy cannot be compiled with `NPY_RELAXED_STRIDES_CHECKING=0`
anymore. Relaxed strides have been the default for many years and
the option was initially introduced to allow a smoother transition.

([gh-20220](https://github.com/numpy/numpy/pull/20220))

`np.loadtxt`
has recieved several changes[#](#np-loadtxt-has-recieved-several-changes)
The row counting of `numpy.loadtxt`
was fixed. `loadtxt`
ignores fully
empty lines in the file, but counted them towards `max_rows`
.
When `max_rows`
is used and the file contains empty lines, these will now
not be counted. Previously, it was possible that the result contained fewer
than `max_rows`
rows even though more data was available to be read.
If the old behaviour is required, `itertools.islice`
may be used:

```
import itertools
lines = itertools.islice(open("file"), 0, max_rows)
result = np.loadtxt(lines, ...)
```
While generally much faster and improved, `numpy.loadtxt`
may now fail to
converter certain strings to numbers that were previously successfully read.
The most important cases for this are:

Parsing floating point values such as

`1.0`
into integers is now deprecated.
Parsing hexadecimal floats such as

`0x3p3`
will fail
An

`_`
was previously accepted as a thousands delimiter`100_000`
. This will now result in an error.
If you experience these limitations, they can all be worked around by passing
appropriate `converters=`
. NumPy now supports passing a single converter
to be used for all columns to make this more convenient.
For example, `converters=float.fromhex`
can read hexadecimal float numbers
and `converters=int`
will be able to read `100_000`
.

Further, the error messages have been generally improved. However, this means
that error types may differ. In particularly, a `ValueError`
is now always
raised when parsing of a single entry fails.

([gh-20580](https://github.com/numpy/numpy/pull/20580))

## Improvements[#](#improvements)
`ndarray.__array_finalize__`
is now callable[#](#ndarray-array-finalize-is-now-callable)
This means subclasses can now use `super().__array_finalize__(obj)`
without worrying whether `ndarray`
is their superclass or not.
The actual call remains a no-op.

([gh-20766](https://github.com/numpy/numpy/pull/20766))

### Add support for VSX4/Power10[#](#add-support-for-vsx4-power10)
With VSX4/Power10 enablement, the new instructions available in Power ISA 3.1 can be used to accelerate some NumPy operations, e.g., floor_divide, modulo, etc.

([gh-20821](https://github.com/numpy/numpy/pull/20821))

`np.fromiter`
now accepts objects and subarrays[#](#np-fromiter-now-accepts-objects-and-subarrays)
The `numpy.fromiter`
function now supports object and
subarray dtypes. Please see he function documentation for
examples.

([gh-20993](https://github.com/numpy/numpy/pull/20993))

### Math C library feature detection now uses correct signatures[#](#math-c-library-feature-detection-now-uses-correct-signatures)
Compiling is preceded by a detection phase to determine whether the
underlying libc supports certain math operations. Previously this code
did not respect the proper signatures. Fixing this enables compilation
for the `wasm-ld`
backend (compilation for web assembly) and reduces
the number of warnings.

([gh-21154](https://github.com/numpy/numpy/pull/21154))

`np.kron`
now maintains subclass information[#](#np-kron-now-maintains-subclass-information)
`np.kron`
maintains subclass information now such as masked arrays
while computing the Kronecker product of the inputs
```
>>> x = ma.array([[1, 2], [3, 4]], mask=[[0, 1], [1, 0]])
>>> np.kron(x,x)
masked_array(
data=[[1, --, --, --],
[--, 4, --, --],
[--, --, 4, --],
[--, --, --, 16]],
mask=[[False, True, True, True],
[ True, False, True, True],
[ True, True, False, True],
[ True, True, True, False]],
fill_value=999999)
```
Warning

`np.kron`
output now follows `ufunc`
ordering (`multiply`
)
to determine the output class type
```
>>> class myarr(np.ndarray):
>>> __array_priority__ = -1
>>> a = np.ones([2, 2])
>>> ma = myarray(a.shape, a.dtype, a.data)
>>> type(np.kron(a, ma)) == np.ndarray
False # Before it was True
>>> type(np.kron(a, ma)) == myarr
True
```
([gh-21262](https://github.com/numpy/numpy/pull/21262))

## Performance improvements and changes[#](#performance-improvements-and-changes)
### Faster `np.loadtxt`
[#](#faster-np-loadtxt)
`numpy.loadtxt`
is now generally much faster than previously as most of it
is now implemented in C.
([gh-20580](https://github.com/numpy/numpy/pull/20580))

### Faster reduction operators[#](#faster-reduction-operators)
Reduction operations like `numpy.sum`
, `numpy.prod`
, `numpy.add.reduce`
,
`numpy.logical_and.reduce`
on contiguous integer-based arrays are now
much faster.

([gh-21001](https://github.com/numpy/numpy/pull/21001))

### Faster `np.where`
[#](#faster-np-where)
`numpy.where`
is now much faster than previously on unpredictable/random
input data.
([gh-21130](https://github.com/numpy/numpy/pull/21130))

### Faster operations on NumPy scalars[#](#faster-operations-on-numpy-scalars)
Many operations on NumPy scalars are now significantly faster, although
rare operations (e.g. with 0-D arrays rather than scalars) may be slower
in some cases.
However, even with these improvements users who want the best performance
for their scalars, may want to convert a known NumPy scalar into a Python
one using `scalar.item()`
.

([gh-21188](https://github.com/numpy/numpy/pull/21188))

### Faster `np.kron`
[#](#faster-np-kron)
`numpy.kron`
is about 80% faster as the product is now computed
using broadcasting.
([gh-21354](https://github.com/numpy/numpy/pull/21354))# NumPy 1.16.3 Release Notes[#](#numpy-1-16-3-release-notes)
The NumPy 1.16.3 release fixes bugs reported against the 1.16.2 release, and also backports several enhancements from master that seem appropriate for a release series that is the last to support Python 2.7. The wheels on PyPI are linked with OpenBLAS v0.3.4+, which should fix the known threading issues found in previous OpenBLAS versions.

Downstream developers building this release should use Cython >= 0.29.2 and, if using OpenBLAS, OpenBLAS > v0.3.4.

The most noticeable change in this release is that unpickling object arrays
when loading `*.npy`
or `*.npz`
files now requires an explicit opt-in.
This backwards incompatible change was made in response to
[CVE-2019-6446](https://nvd.nist.gov/vuln/detail/CVE-2019-6446).

## Compatibility notes[#](#compatibility-notes)
### Unpickling while loading requires explicit opt-in[#](#unpickling-while-loading-requires-explicit-opt-in)
The functions `np.load`
, and `np.lib.format.read_array`
take an
*allow_pickle* keyword which now defaults to `False`
in response to
[CVE-2019-6446](https://nvd.nist.gov/vuln/detail/CVE-2019-6446).

## Improvements[#](#improvements)
### Covariance in *random.mvnormal* cast to double[#](#covariance-in-random-mvnormal-cast-to-double)
This should make the tolerance used when checking the singular values of the covariance matrix more meaningful.

## Changes[#](#changes)
`__array_interface__`
offset now works as documented[#](#array-interface-offset-now-works-as-documented)
The interface may use an `offset`
value that was previously mistakenly
ignored.# NumPy 1.13.2 Release Notes[#](#numpy-1-13-2-release-notes)
This is a bugfix release for some problems found since 1.13.1. The most important fixes are for CVE-2017-12852 and temporary elision. Users of earlier versions of 1.13 should upgrade.

The Python versions supported are 2.7 and 3.4 - 3.6. The Python 3.6 wheels available from PIP are built with Python 3.6.2 and should be compatible with all previous versions of Python 3.6. The Windows wheels are now built with OpenBlas instead ATLAS, which should improve the performance of the linear algebra functions.

## Contributors[#](#contributors)
A total of 12 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Brandon Carter

Charles Harris

Eric Wieser

Iryna Shcherbina +

James Bourbeau +

Jonathan Helmus

Julian Taylor

Matti Picus

Michael Lamparski +

Michael Seifert

Ralf Gommers

## Pull requests merged[#](#pull-requests-merged)
A total of 20 pull requests were merged for this release.

#9390 BUG: Return the poly1d coefficients array directly

#9555 BUG: Fix regression in 1.13.x in distutils.mingw32ccompiler.

#9556 BUG: Fix true_divide when dtype=np.float64 specified.

#9557 DOC: Fix some rst markup in numpy/doc/basics.py.

#9558 BLD: Remove -xhost flag from IntelFCompiler.

#9559 DOC: Removes broken docstring example (source code, png, pdf)…

#9580 BUG: Add hypot and cabs functions to WIN32 blacklist.

#9732 BUG: Make scalar function elision check if temp is writeable.

#9736 BUG: Various fixes to np.gradient

#9742 BUG: Fix np.pad for CVE-2017-12852

#9744 BUG: Check for exception in sort functions, add tests

#9745 DOC: Add whitespace after “versionadded::” directive so it actually…

#9746 BUG: Memory leak in np.dot of size 0

#9747 BUG: Adjust gfortran version search regex

#9757 BUG: Cython 0.27 breaks NumPy on Python 3.

#9764 BUG: Ensure

*_npy_scaled_cexp{,f,l}*is defined when needed.
#9765 BUG: PyArray_CountNonzero does not check for exceptions

#9766 BUG: Fixes histogram monotonicity check for unsigned bin values

#9767 BUG: Ensure consistent result dtype of count_nonzero

#9771 BUG, MAINT: Fix mtrand for Cython 0.27.# NumPy 1.13.1 Release Notes[#](#numpy-1-13-1-release-notes)
This is a bugfix release for problems found in 1.13.0. The major changes are
fixes for the new memory overlap detection and temporary elision as well as
reversion of the removal of the boolean binary `-`
operator. Users of 1.13.0
should upgrade.

Thr Python versions supported are 2.7 and 3.4 - 3.6. Note that the Python 3.6
wheels available from PIP are built against 3.6.1, hence will not work when
used with 3.6.0 due to Python bug [29943](https://bugs.python.org/issue29943). NumPy 1.13.2 will be released shortly
after Python 3.6.2 is out to fix that problem. If you are using 3.6.0 the
workaround is to upgrade to 3.6.1 or use an earlier Python version.

## Pull requests merged[#](#pull-requests-merged)
A total of 19 pull requests were merged for this release.

#9240 DOC: BLD: fix lots of Sphinx warnings/errors.

#9255 Revert “DEP: Raise TypeError for subtract(bool, bool).”

#9261 BUG: don’t elide into readonly and updateifcopy temporaries for…

#9262 BUG: fix missing keyword rename for common block in numpy.f2py

#9263 BUG: handle resize of 0d array

#9267 DOC: update f2py front page and some doc build metadata.

#9299 BUG: Fix Intel compilation on Unix.

#9317 BUG: fix wrong ndim used in empty where check

#9319 BUG: Make extensions compilable with MinGW on Py2.7

#9339 BUG: Prevent crash if ufunc doc string is null

#9340 BUG: umath: un-break ufunc where= when no out= is given

#9371 DOC: Add isnat/positive ufunc to documentation

#9372 BUG: Fix error in fromstring function from numpy.core.records…

#9373 BUG: ‘)’ is printed at the end pointer of the buffer in numpy.f2py.

#9374 DOC: Create NumPy 1.13.1 release notes.

#9376 BUG: Prevent hang traversing ufunc userloop linked list

#9377 DOC: Use x1 and x2 in the heaviside docstring.

#9378 DOC: Add $PARAMS to the isnat docstring

#9379 DOC: Update the 1.13.1 release notes

## Contributors[#](#contributors)
A total of 12 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Andras Deak +

Bob Eldering +

Charles Harris

Daniel Hrisca +

Eric Wieser

Joshua Leahy +

Julian Taylor

Michael Seifert

Pauli Virtanen

Ralf Gommers

Roland Kaufmann

Warren Weckesser# NumPy 1.6.2 Release Notes[#](#numpy-1-6-2-release-notes)
This is a bugfix release in the 1.6.x series. Due to the delay of the NumPy 1.7.0 release, this release contains far more fixes than a regular NumPy bugfix release. It also includes a number of documentation and build improvements.

## Issues fixed[#](#issues-fixed)
`numpy.core`
[#](#numpy-core)
#2063: make unique() return consistent index

#1138: allow creating arrays from empty buffers or empty slices

#1446: correct note about correspondence vstack and concatenate

#1149: make argmin() work for datetime

#1672: fix allclose() to work for scalar inf

#1747: make np.median() work for 0-D arrays

#1776: make complex division by zero to yield inf properly

#1675: add scalar support for the format() function

#1905: explicitly check for NaNs in allclose()

#1952: allow floating ddof in std() and var()

#1948: fix regression for indexing chararrays with empty list

#2017: fix type hashing

#2046: deleting array attributes causes segfault

#2033: a**2.0 has incorrect type

#2045: make attribute/iterator_element deletions not segfault

#2021: fix segfault in searchsorted()

#2073: fix float16 __array_interface__ bug

`numpy.lib`
[#](#numpy-lib)
#2048: break reference cycle in NpzFile

#1573: savetxt() now handles complex arrays

#1387: allow bincount() to accept empty arrays

#1899: fixed histogramdd() bug with empty inputs

#1793: fix failing npyio test under py3k

#1936: fix extra nesting for subarray dtypes

#1848: make tril/triu return the same dtype as the original array

#1918: use Py_TYPE to access ob_type, so it works also on Py3

`numpy.distutils`
[#](#numpy-distutils)
#1261: change compile flag on AIX from -O5 to -O3

#1377: update HP compiler flags

#1383: provide better support for C++ code on HPUX

#1857: fix build for py3k + pip

BLD: raise a clearer warning in case of building without cleaning up first

BLD: follow build_ext coding convention in build_clib

BLD: fix up detection of Intel CPU on OS X in system_info.py

BLD: add support for the new X11 directory structure on Ubuntu & co.

BLD: add ufsparse to the libraries search path.

BLD: add ‘pgfortran’ as a valid compiler in the Portland Group

BLD: update version match regexp for IBM AIX Fortran compilers.

`numpy.random`
[#](#numpy-random)
BUG: Use npy_intp instead of long in mtrand

## Changes[#](#changes)
`numpy.f2py`
[#](#numpy-f2py)
ENH: Introduce new options extra_f77_compiler_args and extra_f90_compiler_args

BLD: Improve reporting of fcompiler value

BUG: Fix f2py test_kind.py test

`numpy.poly`
[#](#numpy-poly)
ENH: Add some tests for polynomial printing

ENH: Add companion matrix functions

DOC: Rearrange the polynomial documents

BUG: Fix up links to classes

DOC: Add version added to some of the polynomial package modules

DOC: Document xxxfit functions in the polynomial package modules

BUG: The polynomial convenience classes let different types interact

DOC: Document the use of the polynomial convenience classes

DOC: Improve numpy reference documentation of polynomial classes

ENH: Improve the computation of polynomials from roots

STY: Code cleanup in polynomial [*]fromroots functions

DOC: Remove references to cast and NA, which were added in 1.7# NumPy 1.19.3 Release Notes[#](#numpy-1-19-3-release-notes)
NumPy 1.19.3 is a small maintenance release with two major improvements:

Python 3.9 binary wheels on all supported platforms.

OpenBLAS fixes for Windows 10 version 2004 fmod bug.

This release supports Python 3.6-3.9 and is linked with OpenBLAS 0.3.12 to avoid some of the fmod problems on Windows 10 version 2004. Microsoft is aware of the problem and users should upgrade when the fix becomes available, the fix here is limited in scope.

## Contributors[#](#contributors)
A total of 8 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Chris Brown +

Daniel Vanzo +

Madison Bray +

Hugo van Kemenade +

Ralf Gommers

Sebastian Berg

@danbeibei +

## Pull requests merged[#](#pull-requests-merged)
A total of 10 pull requests were merged for this release.

[#17298](https://github.com/numpy/numpy/pull/17298): BLD: set upper versions for build dependencies
[#17336](https://github.com/numpy/numpy/pull/17336): BUG: Set deprecated fields to null in PyArray_InitArrFuncs
[#17446](https://github.com/numpy/numpy/pull/17446): ENH: Warn on unsupported Python 3.10+
[#17450](https://github.com/numpy/numpy/pull/17450): MAINT: Update test_requirements.txt.
[#17522](https://github.com/numpy/numpy/pull/17522): ENH: Support for the NVIDIA HPC SDK nvfortran compiler
[#17568](https://github.com/numpy/numpy/pull/17568): BUG: Cygwin Workaround for #14787 on affected platforms
[#17647](https://github.com/numpy/numpy/pull/17647): BUG: Fix memory leak of buffer-info cache due to relaxed strides
[#17652](https://github.com/numpy/numpy/pull/17652): MAINT: Backport openblas_support from master.
[#17653](https://github.com/numpy/numpy/pull/17653): TST: Add Python 3.9 to the CI testing on Windows, Mac.
[#17660](https://github.com/numpy/numpy/pull/17660): TST: Simplify source path names in test_extending.# NumPy 1.14.1 Release Notes[#](#numpy-1-14-1-release-notes)
This is a bugfix release for some problems reported following the 1.14.0 release. The major problems fixed are the following.

Problems with the new array printing, particularly the printing of complex values, Please report any additional problems that may turn up.

Problems with

`np.einsum`
due to the new`optimized=True`
default. Some fixes for optimization have been applied and`optimize=False`
is now the default.
The sort order in

`np.unique`
when`axis=<some-number>`
will now always be lexicographic in the subarray elements. In previous NumPy versions there was an optimization that could result in sorting the subarrays as unsigned byte strings.
The change in 1.14.0 that multi-field indexing of structured arrays returns a view instead of a copy has been reverted but remains on track for NumPy 1.15. Affected users should read the 1.14.1 Numpy User Guide section “basics/structured arrays/accessing multiple fields” for advice on how to manage this transition.

The Python versions supported in this release are 2.7 and 3.4 - 3.6. The Python
3.6 wheels available from PIP are built with Python 3.6.2 and should be
compatible with all previous versions of Python 3.6. The source releases were
cythonized with Cython 0.26.1, which is known to **not** support the upcoming
Python 3.7 release. People who wish to run Python 3.7 should check out the
NumPy repo and try building with the, as yet, unreleased master branch of
Cython.

## Contributors[#](#contributors)
A total of 14 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Charles Harris

Daniel Smith

Dennis Weyland +

Eric Larson

Eric Wieser

Jarrod Millman

Kenichi Maehashi +

Marten van Kerkwijk

Mathieu Lamarre

Sebastian Berg

Simon Conseil

Simon Gibbons

xoviat

## Pull requests merged[#](#pull-requests-merged)
A total of 36 pull requests were merged for this release.

[#10339](https://github.com/numpy/numpy/pull/10339): BUG: restrict the __config__ modifications to win32
[#10368](https://github.com/numpy/numpy/pull/10368): MAINT: Adjust type promotion in linalg.norm
[#10375](https://github.com/numpy/numpy/pull/10375): BUG: add missing paren and remove quotes from repr of fieldless…
[#10395](https://github.com/numpy/numpy/pull/10395): MAINT: Update download URL in setup.py.
[#10396](https://github.com/numpy/numpy/pull/10396): BUG: fix einsum issue with unicode input and py2
[#10397](https://github.com/numpy/numpy/pull/10397): BUG: fix error message not formatted in einsum
[#10398](https://github.com/numpy/numpy/pull/10398): DOC: add documentation about how to handle new array printing
[#10403](https://github.com/numpy/numpy/pull/10403): BUG: Set einsum optimize parameter default to*False*.
[#10424](https://github.com/numpy/numpy/pull/10424): ENH: Fix repr of np.record objects to match np.void types #10412
[#10425](https://github.com/numpy/numpy/pull/10425): MAINT: Update zesty to artful for i386 testing
[#10431](https://github.com/numpy/numpy/pull/10431): REL: Add 1.14.1 release notes template
[#10435](https://github.com/numpy/numpy/pull/10435): MAINT: Use ValueError for duplicate field names in lookup (backport)
[#10534](https://github.com/numpy/numpy/pull/10534): BUG: Provide a better error message for out-of-order fields
[#10536](https://github.com/numpy/numpy/pull/10536): BUG: Resize bytes columns in genfromtxt (backport of #10401)
[#10537](https://github.com/numpy/numpy/pull/10537): BUG: multifield-indexing adds padding bytes: revert for 1.14.1
[#10539](https://github.com/numpy/numpy/pull/10539): BUG: fix np.save issue with python 2.7.5
[#10540](https://github.com/numpy/numpy/pull/10540): BUG: Add missing DECREF in Py2 int() cast
[#10541](https://github.com/numpy/numpy/pull/10541): TST: Add circleci document testing to maintenance/1.14.x
[#10542](https://github.com/numpy/numpy/pull/10542): BUG: complex repr has extra spaces, missing + (1.14 backport)
[#10550](https://github.com/numpy/numpy/pull/10550): BUG: Set missing exception after malloc
[#10557](https://github.com/numpy/numpy/pull/10557): BUG: In numpy.i, clear CARRAY flag if wrapped buffer is not C_CONTIGUOUS.
[#10558](https://github.com/numpy/numpy/pull/10558): DEP: Issue FutureWarning when malformed records detected.
[#10559](https://github.com/numpy/numpy/pull/10559): BUG: Fix einsum optimize logic for singleton dimensions
[#10560](https://github.com/numpy/numpy/pull/10560): BUG: Fix calling ufuncs with a positional output argument.
[#10561](https://github.com/numpy/numpy/pull/10561): BUG: Fix various Big-Endian test failures (ppc64)
[#10562](https://github.com/numpy/numpy/pull/10562): BUG: Make dtype.descr error for out-of-order fields.
[#10563](https://github.com/numpy/numpy/pull/10563): BUG: arrays not being flattened in*union1d*
[#10607](https://github.com/numpy/numpy/pull/10607): MAINT: Update sphinxext submodule hash.
[#10608](https://github.com/numpy/numpy/pull/10608): BUG: Revert sort optimization in np.unique.
[#10609](https://github.com/numpy/numpy/pull/10609): BUG: infinite recursion in str of 0d subclasses
[#10610](https://github.com/numpy/numpy/pull/10610): BUG: Align type definition with generated lapack
[#10612](https://github.com/numpy/numpy/pull/10612): BUG/ENH: Improve output for structured non-void types
[#10622](https://github.com/numpy/numpy/pull/10622): BUG: deallocate recursive closure in arrayprint.py (1.14 backport)
[#10624](https://github.com/numpy/numpy/pull/10624): BUG: Correctly identify comma separated dtype strings
[#10629](https://github.com/numpy/numpy/pull/10629): BUG: deallocate recursive closure in arrayprint.py (backport…
[#10630](https://github.com/numpy/numpy/pull/10630): REL: Prepare for 1.14.1 release.# NumPy 1.19.5 Release Notes[#](#numpy-1-19-5-release-notes)
NumPy 1.19.5 is a short bugfix release. Apart from fixing several bugs, the main improvement is the update to OpenBLAS 0.3.13 that works around the windows 2004 bug while not breaking execution on other platforms. This release supports Python 3.6-3.9 and is planned to be the last release in the 1.19.x cycle.

## Contributors[#](#contributors)
A total of 8 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Christoph Gohlke

Matti Picus

Raghuveer Devulapalli

Sebastian Berg

Simon Graham +

Veniamin Petrenko +

Bernie Gray +

## Pull requests merged[#](#pull-requests-merged)
A total of 11 pull requests were merged for this release.

[#17756](https://github.com/numpy/numpy/pull/17756): BUG: Fix segfault due to out of bound pointer in floatstatus…
[#17774](https://github.com/numpy/numpy/pull/17774): BUG: fix np.timedelta64(‘nat’).__format__ throwing an exception
[#17775](https://github.com/numpy/numpy/pull/17775): BUG: Fixed file handle leak in array_tofile.
[#17786](https://github.com/numpy/numpy/pull/17786): BUG: Raise recursion error during dimension discovery
[#17917](https://github.com/numpy/numpy/pull/17917): BUG: Fix subarray dtype used with too large count in fromfile
[#17918](https://github.com/numpy/numpy/pull/17918): BUG: ‘bool’ object has no attribute ‘ndim’
[#17919](https://github.com/numpy/numpy/pull/17919): BUG: ensure _UFuncNoLoopError can be pickled
[#17924](https://github.com/numpy/numpy/pull/17924): BLD: use BUFFERSIZE=20 in OpenBLAS
[#18026](https://github.com/numpy/numpy/pull/18026): BLD: update to OpenBLAS 0.3.13
[#18036](https://github.com/numpy/numpy/pull/18036): BUG: make a variable volatile to work around clang compiler bug
[#18114](https://github.com/numpy/numpy/pull/18114): REL: Prepare for the NumPy 1.19.5 release.# NumPy 1.21.4 Release Notes[#](#numpy-1-21-4-release-notes)
The NumPy 1.21.4 is a maintenance release that fixes a few bugs discovered after 1.21.3. The most important fix here is a fix for the NumPy header files to make them work for both x86_64 and M1 hardware when included in the Mac universal2 wheels. Previously, the header files only worked for M1 and this caused problems for folks building x86_64 extensions. This problem was not seen before Python 3.10 because there were thin wheels for x86_64 that had precedence. This release also provides thin x86_64 Mac wheels for Python 3.10.

The Python versions supported in this release are 3.7-3.10. If you want to compile your own version using gcc-11, you will need to use gcc-11.2+ to avoid problems.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Bas van Beek

Charles Harris

Isuru Fernando

Matthew Brett

Sayed Adel

Sebastian Berg

傅立业（Chris Fu） +

## Pull requests merged[#](#pull-requests-merged)
A total of 9 pull requests were merged for this release.

[#20278](https://github.com/numpy/numpy/pull/20278): BUG: Fix shadowed reference of`dtype`
in type stub
[#20293](https://github.com/numpy/numpy/pull/20293): BUG: Fix headers for universal2 builds
[#20294](https://github.com/numpy/numpy/pull/20294): BUG:`VOID_nonzero`
could sometimes mutate alignment flag
[#20295](https://github.com/numpy/numpy/pull/20295): BUG: Do not use nonzero fastpath on unaligned arrays
[#20296](https://github.com/numpy/numpy/pull/20296): BUG: Distutils patch to allow for 2 as a minor version (!)
[#20297](https://github.com/numpy/numpy/pull/20297): BUG, SIMD: Fix 64-bit/8-bit integer division by a scalar
[#20298](https://github.com/numpy/numpy/pull/20298): BUG, SIMD: Workaround broadcasting SIMD 64-bit integers on MSVC…
[#20300](https://github.com/numpy/numpy/pull/20300): REL: Prepare for the NumPy 1.21.4 release.
[#20302](https://github.com/numpy/numpy/pull/20302): TST: Fix a`Arrayterator`
typing test failure# NumPy 1.10.4 Release Notes[#](#numpy-1-10-4-release-notes)
This release is a bugfix source release motivated by a segfault regression. No windows binaries are provided for this release, as there appear to be bugs in the toolchain we use to generate those files. Hopefully that problem will be fixed for the next release. In the meantime, we suggest using one of the providers of windows binaries.

## Compatibility notes[#](#compatibility-notes)
The trace function now calls the trace method on subclasses of ndarray, except for matrix, for which the current behavior is preserved. This is to help with the units package of AstroPy and hopefully will not cause problems.

## Issues Fixed[#](#issues-fixed)
gh-6922 BUG: numpy.recarray.sort segfaults on Windows.

gh-6937 BUG: busday_offset does the wrong thing with modifiedpreceding roll.

gh-6949 BUG: Type is lost when slicing a subclass of recarray.

## Merged PRs[#](#merged-prs)
The following PRs have been merged into 1.10.4. When the PR is a backport, the PR number for the original PR against master is listed.

gh-6840 TST: Update travis testing script in 1.10.x

gh-6843 BUG: Fix use of python 3 only FileNotFoundError in test_f2py.

gh-6884 REL: Update pavement.py and setup.py to reflect current version.

gh-6916 BUG: Fix test_f2py so it runs correctly in runtests.py.

gh-6924 BUG: Fix segfault gh-6922.

gh-6942 Fix datetime roll=’modifiedpreceding’ bug.

gh-6943 DOC,BUG: Fix some latex generation problems.

gh-6950 BUG trace is not subclass aware, np.trace(ma) != ma.trace().

gh-6952 BUG recarray slices should preserve subclass.# NumPy 1.8.1 Release Notes[#](#numpy-1-8-1-release-notes)
This is a bugfix only release in the 1.8.x series.

## Issues fixed[#](#issues-fixed)
gh-4276: Fix mean, var, std methods for object arrays

gh-4262: remove insecure mktemp usage

gh-2385: absolute(complex(inf)) raises invalid warning in python3

gh-4024: Sequence assignment doesn’t raise exception on shape mismatch

gh-4027: Fix chunked reading of strings longer than BUFFERSIZE

gh-4109: Fix object scalar return type of 0-d array indices

gh-4018: fix missing check for memory allocation failure in ufuncs

gh-4156: high order linalg.norm discards imaginary elements of complex arrays

gh-4144: linalg: norm fails on longdouble, signed int

gh-4094: fix NaT handling in _strided_to_strided_string_to_datetime

gh-4051: fix uninitialized use in _strided_to_strided_string_to_datetime

gh-4093: Loading compressed .npz file fails under Python 2.6.6

gh-4138: segfault with non-native endian memoryview in python 3.4

gh-4123: Fix missing NULL check in lexsort

gh-4170: fix native-only long long check in memoryviews

gh-4187: Fix large file support on 32 bit

gh-4152: fromfile: ensure file handle positions are in sync in python3

gh-4176: clang compatibility: Typos in conversion_utils

gh-4223: Fetching a non-integer item caused array return

gh-4197: fix minor memory leak in memoryview failure case

gh-4206: fix build with single-threaded python

gh-4220: add versionadded:: 1.8.0 to ufunc.at docstring

gh-4267: improve handling of memory allocation failure

gh-4267: fix use of capi without gil in ufunc.at

gh-4261: Detect vendor versions of GNU Compilers

gh-4253: IRR was returning nan instead of valid negative answer

gh-4254: fix unnecessary byte order flag change for byte arrays

gh-3263: numpy.random.shuffle clobbers mask of a MaskedArray

gh-4270: np.random.shuffle not work with flexible dtypes

gh-3173: Segmentation fault when ‘size’ argument to random.multinomial

gh-2799: allow using unique with lists of complex

gh-3504: fix linspace truncation for integer array scalar

gh-4191: get_info(‘openblas’) does not read libraries key

gh-3348: Access violation in _descriptor_from_pep3118_format

gh-3175: segmentation fault with numpy.array() from bytearray

gh-4266: histogramdd - wrong result for entries very close to last boundary

gh-4408: Fix stride_stricks.as_strided function for object arrays

gh-4225: fix log1p and exmp1 return for np.inf on windows compiler builds

gh-4359: Fix infinite recursion in str.format of flex arrays

gh-4145: Incorrect shape of broadcast result with the exponent operator

gh-4483: Fix commutativity of {dot,multiply,inner}(scalar, matrix_of_objs)

gh-4466: Delay npyiter size check when size may change

gh-4485: Buffered stride was erroneously marked fixed

gh-4354: byte_bounds fails with datetime dtypes

gh-4486: segfault/error converting from/to high-precision datetime64 objects

gh-4428: einsum(None, None, None, None) causes segfault

gh-4134: uninitialized use for for size 1 object reductions

## Changes[#](#changes)
### NDIter[#](#nditer)
When `NpyIter_RemoveAxis`
is now called, the iterator range will be reset.

When a multi index is being tracked and an iterator is not buffered, it is
possible to use `NpyIter_RemoveAxis`
. In this case an iterator can shrink
in size. Because the total size of an iterator is limited, the iterator
may be too large before these calls. In this case its size will be set to `-1`
and an error issued not at construction time but when removing the multi
index, setting the iterator range, or getting the next function.

This has no effect on currently working code, but highlights the necessity of checking for an error return if these conditions can occur. In most cases the arrays being iterated are as large as the iterator so that such a problem cannot occur.

### Optional reduced verbosity for np.distutils[#](#optional-reduced-verbosity-for-np-distutils)
Set `numpy.distutils.system_info.system_info.verbosity = 0`
and then
calls to `numpy.distutils.system_info.get_info('blas_opt')`
will not
print anything on the output. This is mostly for other packages using
numpy.distutils.

## Deprecations[#](#deprecations)
### C-API[#](#c-api)
The utility function npy_PyFile_Dup and npy_PyFile_DupClose are broken by the internal buffering python 3 applies to its file objects. To fix this two new functions npy_PyFile_Dup2 and npy_PyFile_DupClose2 are declared in npy_3kcompat.h and the old functions are deprecated. Due to the fragile nature of these functions it is recommended to instead use the python API when possible.# NumPy 1.14.2 Release Notes[#](#numpy-1-14-2-release-notes)
This is a bugfix release for some bugs reported following the 1.14.1 release. The major problems dealt with are as follows.

Residual bugs in the new array printing functionality.

Regression resulting in a relocation problem with shared library.

Improved PyPy compatibility.

The Python versions supported in this release are 2.7 and 3.4 - 3.6. The Python
3.6 wheels available from PIP are built with Python 3.6.2 and should be
compatible with all previous versions of Python 3.6. The source releases were
cythonized with Cython 0.26.1, which is known to **not** support the upcoming
Python 3.7 release. People who wish to run Python 3.7 should check out the
NumPy repo and try building with the, as yet, unreleased master branch of
Cython.

## Contributors[#](#contributors)
A total of 4 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Charles Harris

Eric Wieser

Pauli Virtanen

## Pull requests merged[#](#pull-requests-merged)
A total of 5 pull requests were merged for this release.

[#10674](https://github.com/numpy/numpy/pull/10674): BUG: Further back-compat fix for subclassed array repr
[#10725](https://github.com/numpy/numpy/pull/10725): BUG: dragon4 fractional output mode adds too many trailing zeros
[#10726](https://github.com/numpy/numpy/pull/10726): BUG: Fix f2py generated code to work on PyPy
[#10727](https://github.com/numpy/numpy/pull/10727): BUG: Fix missing NPY_VISIBILITY_HIDDEN on npy_longdouble_to_PyLong
[#10729](https://github.com/numpy/numpy/pull/10729): DOC: Create 1.14.2 notes and changelog.# NumPy 1.25.2 Release Notes[#](#numpy-1-25-2-release-notes)
NumPy 1.25.2 is a maintenance release that fixes bugs and regressions discovered after the 1.25.1 release. This is the last planned release in the 1.25.x series, the next release will be 1.26.0, which will use the meson build system and support Python 3.12. The Python versions supported by this release are 3.9-3.11.

## Contributors[#](#contributors)
A total of 13 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Aaron Meurer

Andrew Nelson

Charles Harris

Kevin Sheppard

Matti Picus

Nathan Goldbaum

Peter Hawkins

Ralf Gommers

Randy Eckenrode +

Sam James +

Sebastian Berg

Tyler Reddy

dependabot[bot]

## Pull requests merged[#](#pull-requests-merged)
A total of 19 pull requests were merged for this release.

[#24148](https://github.com/numpy/numpy/pull/24148): MAINT: prepare 1.25.x for further development
[#24174](https://github.com/numpy/numpy/pull/24174): ENH: Improve clang-cl compliance
[#24179](https://github.com/numpy/numpy/pull/24179): MAINT: Upgrade various build dependencies.
[#24182](https://github.com/numpy/numpy/pull/24182): BLD: use`-ftrapping-math`
with Clang on macOS
[#24183](https://github.com/numpy/numpy/pull/24183): BUG: properly handle negative indexes in ufunc_at fast path
[#24184](https://github.com/numpy/numpy/pull/24184): BUG: PyObject_IsTrue and PyObject_Not error handling in setflags
[#24185](https://github.com/numpy/numpy/pull/24185): BUG: histogram small range robust
[#24186](https://github.com/numpy/numpy/pull/24186): MAINT: Update meson.build files from main branch
[#24234](https://github.com/numpy/numpy/pull/24234): MAINT: exclude min, max and round from`np.__all__`
[#24241](https://github.com/numpy/numpy/pull/24241): MAINT: Dependabot updates
[#24242](https://github.com/numpy/numpy/pull/24242): BUG: Fix the signature for np.array_api.take
[#24243](https://github.com/numpy/numpy/pull/24243): BLD: update OpenBLAS to an intermeidate commit
[#24244](https://github.com/numpy/numpy/pull/24244): BUG: Fix reference count leak in str(scalar).
[#24245](https://github.com/numpy/numpy/pull/24245): BUG: fix invalid function pointer conversion error
[#24255](https://github.com/numpy/numpy/pull/24255): BUG: Factor out slow`getenv`
call used for memory policy warning
[#24292](https://github.com/numpy/numpy/pull/24292): CI: correct URL in cirrus.star [skip cirrus]
[#24293](https://github.com/numpy/numpy/pull/24293): BUG: Fix C types in scalartypes
[#24294](https://github.com/numpy/numpy/pull/24294): BUG: do not modify the input to ufunc_at
[#24295](https://github.com/numpy/numpy/pull/24295): BUG: Further fixes to indexing loop and added tests# NumPy 1.15.1 Release Notes[#](#numpy-1-15-1-release-notes)
This is a bugfix release for bugs and regressions reported following the 1.15.0 release.

The annoying but harmless RuntimeWarning that “numpy.dtype size changed” has been suppressed. The long standing suppression was lost in the transition to pytest.

The update to Cython 0.28.3 exposed a problematic use of a gcc attribute used to prefer code size over speed in module initialization, possibly resulting in incorrect compiled code. This has been fixed in latest Cython but has been disabled here for safety.

Support for big-endian and ARMv8 architectures has been improved.

The Python versions supported by this release are 2.7, 3.4-3.7. The wheels are linked with OpenBLAS v0.3.0, which should fix some of the linalg problems reported for NumPy 1.14.

## Compatibility Note[#](#compatibility-note)
The NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit
binaries. That will also be the case in future releases. See
[#11625](https://github.com/numpy/numpy/issues/11625) for the related
discussion. Those needing 32-bit support should look elsewhere or build
from source.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Chris Billington

Elliott Sales de Andrade +

Eric Wieser

Jeremy Manning +

Matti Picus

Ralf Gommers

## Pull requests merged[#](#pull-requests-merged)
A total of 24 pull requests were merged for this release.

[#11647](https://github.com/numpy/numpy/pull/11647): MAINT: Filter Cython warnings in`__init__.py`
[#11648](https://github.com/numpy/numpy/pull/11648): BUG: Fix doc source links to unwrap decorators
[#11657](https://github.com/numpy/numpy/pull/11657): BUG: Ensure singleton dimensions are not dropped when converting…
[#11661](https://github.com/numpy/numpy/pull/11661): BUG: Warn on Nan in minimum,maximum for scalars
[#11665](https://github.com/numpy/numpy/pull/11665): BUG: cython sometimes emits invalid gcc attribute
[#11682](https://github.com/numpy/numpy/pull/11682): BUG: Fix regression in void_getitem
[#11698](https://github.com/numpy/numpy/pull/11698): BUG: Make matrix_power again work for object arrays.
[#11700](https://github.com/numpy/numpy/pull/11700): BUG: Add missing PyErr_NoMemory after failing malloc
[#11719](https://github.com/numpy/numpy/pull/11719): BUG: Fix undefined functions on big-endian systems.
[#11720](https://github.com/numpy/numpy/pull/11720): MAINT: Make einsum optimize default to False.
[#11746](https://github.com/numpy/numpy/pull/11746): BUG: Fix regression in loadtxt for bz2 text files in Python 2.
[#11757](https://github.com/numpy/numpy/pull/11757): BUG: Revert use of*console_scripts*.
[#11758](https://github.com/numpy/numpy/pull/11758): BUG: Fix Fortran kind detection for aarch64 & s390x.
[#11759](https://github.com/numpy/numpy/pull/11759): BUG: Fix printing of longdouble on ppc64le.
[#11760](https://github.com/numpy/numpy/pull/11760): BUG: Fixes for unicode field names in Python 2
[#11761](https://github.com/numpy/numpy/pull/11761): BUG: Increase required cython version on python 3.7
[#11763](https://github.com/numpy/numpy/pull/11763): BUG: check return value of _buffer_format_string
[#11775](https://github.com/numpy/numpy/pull/11775): MAINT: Make assert_array_compare more generic.
[#11776](https://github.com/numpy/numpy/pull/11776): TST: Fix urlopen stubbing.
[#11777](https://github.com/numpy/numpy/pull/11777): BUG: Fix regression in intersect1d.
[#11779](https://github.com/numpy/numpy/pull/11779): BUG: Fix test sensitive to platform byte order.
[#11781](https://github.com/numpy/numpy/pull/11781): BUG: Avoid signed overflow in histogram
[#11785](https://github.com/numpy/numpy/pull/11785): BUG: Fix pickle and memoryview for datetime64, timedelta64 scalars
[#11786](https://github.com/numpy/numpy/pull/11786): BUG: Deprecation triggers segfault# NumPy 1.15.4 Release Notes[#](#numpy-1-15-4-release-notes)
This is a bugfix release for bugs and regressions reported following the 1.15.3 release. The Python versions supported by this release are 2.7, 3.4-3.7. The wheels are linked with OpenBLAS v0.3.0, which should fix some of the linalg problems reported for NumPy 1.14.

## Compatibility Note[#](#compatibility-note)
The NumPy 1.15.x OS X wheels released on PyPI no longer contain 32-bit
binaries. That will also be the case in future releases. See
[#11625](https://github.com/numpy/numpy/issues/11625) for the related
discussion. Those needing 32-bit support should look elsewhere or build
from source.

## Contributors[#](#contributors)
A total of 4 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Matti Picus

Sebastian Berg

bbbbbbbbba +

## Pull requests merged[#](#pull-requests-merged)
A total of 4 pull requests were merged for this release.

[#12296](https://github.com/numpy/numpy/pull/12296): BUG: Dealloc cached buffer info
[#12297](https://github.com/numpy/numpy/pull/12297): BUG: Fix fill value in masked array ‘==’ and ‘!=’ ops.
[#12307](https://github.com/numpy/numpy/pull/12307): DOC: Correct the default value of*optimize*in`numpy.einsum`
[#12320](https://github.com/numpy/numpy/pull/12320): REL: Prepare for the NumPy 1.15.4 release# NumPy 1.11.2 Release Notes[#](#numpy-1-11-2-release-notes)
Numpy 1.11.2 supports Python 2.6 - 2.7 and 3.2 - 3.5. It fixes bugs and regressions found in Numpy 1.11.1 and includes several build related improvements. Wheels for Linux, Windows, and OS X can be found on PyPI.

## Pull Requests Merged[#](#pull-requests-merged)
Fixes overridden by later merges and release notes updates are omitted.

#7736 BUG: Many functions silently drop ‘keepdims’ kwarg.

#7738 ENH: Add extra kwargs and update doc of many MA methods.

#7778 DOC: Update Numpy 1.11.1 release notes.

#7793 BUG: MaskedArray.count treats negative axes incorrectly.

#7816 BUG: Fix array too big error for wide dtypes.

#7821 BUG: Make sure npy_mul_with_overflow_<type> detects overflow.

#7824 MAINT: Allocate fewer bytes for empty arrays.

#7847 MAINT,DOC: Fix some imp module uses and update f2py.compile docstring.

#7849 MAINT: Fix remaining uses of deprecated Python imp module.

#7851 BLD: Fix ATLAS version detection.

#7896 BUG: Construct ma.array from np.array which contains padding.

#7904 BUG: Fix float16 type not being called due to wrong ordering.

#7917 BUG: Production install of numpy should not require nose.

#7919 BLD: Fixed MKL detection for recent versions of this library.

#7920 BUG: Fix for issue #7835 (ma.median of 1d).

#7932 BUG: Monkey-patch _msvccompile.gen_lib_option like other compilers.

#7939 BUG: Check for HAVE_LDOUBLE_DOUBLE_DOUBLE_LE in npy_math_complex.

#7953 BUG: Guard against buggy comparisons in generic quicksort.

#7954 BUG: Use keyword arguments to initialize Extension base class.

#7955 BUG: Make sure numpy globals keep identity after reload.

#7972 BUG: MSVCCompiler grows ‘lib’ & ‘include’ env strings exponentially.

#8005 BLD: Remove __NUMPY_SETUP__ from builtins at end of setup.py.

#8010 MAINT: Remove leftover imp module imports.

#8020 BUG: Fix return of np.ma.count if keepdims is True and axis is None.

#8024 BUG: Fix numpy.ma.median.

#8031 BUG: Fix np.ma.median with only one non-masked value.

#8044 BUG: Fix bug in NpyIter buffering with discontinuous arrays.# NumPy 1.17.2 Release Notes[#](#numpy-1-17-2-release-notes)
This release contains fixes for bugs reported against NumPy 1.17.1 along with a some documentation improvements. The most important fix is for lexsort when the keys are of type (u)int8 or (u)int16. If you are currently using 1.17 you should upgrade.

The Python versions supported in this release are 3.5-3.7, Python 2.7 has been dropped. Python 3.8b4 should work with the released source packages, but there are no future guarantees.

Downstream developers should use Cython >= 0.29.13 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture. The NumPy wheels on PyPI are built from the OpenBLAS development branch in order to avoid those errors.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

CakeWithSteak +

Charles Harris

Dan Allan

Hameer Abbasi

Lars Grueter

Matti Picus

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 8 pull requests were merged for this release.

[#14418](https://github.com/numpy/numpy/pull/14418): BUG: Fix aradixsort indirect indexing.
[#14420](https://github.com/numpy/numpy/pull/14420): DOC: Fix a minor typo in dispatch documentation.
[#14421](https://github.com/numpy/numpy/pull/14421): BUG: test, fix regression in converting to ctypes
[#14430](https://github.com/numpy/numpy/pull/14430): BUG: Do not show Override module in private error classes.
[#14432](https://github.com/numpy/numpy/pull/14432): BUG: Fixed maximum relative error reporting in assert_allclose.
[#14433](https://github.com/numpy/numpy/pull/14433): BUG: Fix uint-overflow if padding with linear_ramp and negative…
[#14436](https://github.com/numpy/numpy/pull/14436): BUG: Update 1.17.x with 1.18.0-dev pocketfft.py.
[#14446](https://github.com/numpy/numpy/pull/14446): REL: Prepare for NumPy 1.17.2 release.# NumPy 1.17.1 Release Notes[#](#numpy-1-17-1-release-notes)
This release contains a number of fixes for bugs reported against NumPy 1.17.0 along with a few documentation and build improvements. The Python versions supported are 3.5-3.7, note that Python 2.7 has been dropped. Python 3.8b3 should work with the released source packages, but there are no future guarantees.

Downstream developers should use Cython >= 0.29.13 for Python 3.8 support and OpenBLAS >= 3.7 to avoid problems on the Skylake architecture. The NumPy wheels on PyPI are built from the OpenBLAS development branch in order to avoid those problems.

## Contributors[#](#contributors)
A total of 17 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Alexander Jung +

Allan Haldane

Charles Harris

Eric Wieser

Giuseppe Cuccu +

Hiroyuki V. Yamazaki

Jérémie du Boisberranger

Kmol Yuan +

Matti Picus

Max Bolingbroke +

Maxwell Aladago +

Oleksandr Pavlyk

Peter Andreas Entschev

Sergei Lebedev

Seth Troisi +

Vladimir Pershin +

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 24 pull requests were merged for this release.

[#14156](https://github.com/numpy/numpy/pull/14156): TST: Allow fuss in testing strided/non-strided exp/log loops
[#14157](https://github.com/numpy/numpy/pull/14157): BUG: avx2_scalef_ps must be static
[#14158](https://github.com/numpy/numpy/pull/14158): BUG: Remove stray print that causes a SystemError on python 3.7.
[#14159](https://github.com/numpy/numpy/pull/14159): BUG: Fix DeprecationWarning in python 3.8.
[#14160](https://github.com/numpy/numpy/pull/14160): BLD: Add missing gcd/lcm definitions to npy_math.h
[#14161](https://github.com/numpy/numpy/pull/14161): DOC, BUILD: cleanups and fix (again) ‘build dist’
[#14166](https://github.com/numpy/numpy/pull/14166): TST: Add 3.8-dev to travisCI testing.
[#14194](https://github.com/numpy/numpy/pull/14194): BUG: Remove the broken clip wrapper (Backport)
[#14198](https://github.com/numpy/numpy/pull/14198): DOC: Fix hermitian argument docs in svd.
[#14199](https://github.com/numpy/numpy/pull/14199): MAINT: Workaround for Intel compiler bug leading to failing test
[#14200](https://github.com/numpy/numpy/pull/14200): TST: Clean up of test_pocketfft.py
[#14201](https://github.com/numpy/numpy/pull/14201): BUG: Make advanced indexing result on read-only subclass writeable…
[#14236](https://github.com/numpy/numpy/pull/14236): BUG: Fixed default BitGenerator name
[#14237](https://github.com/numpy/numpy/pull/14237): ENH: add c-imported modules for freeze analysis in np.random
[#14296](https://github.com/numpy/numpy/pull/14296): TST: Pin pytest version to 5.0.1
[#14301](https://github.com/numpy/numpy/pull/14301): BUG: Fix leak in the f2py-generated module init and*PyMem_Del*…
[#14302](https://github.com/numpy/numpy/pull/14302): BUG: Fix formatting error in exception message
[#14307](https://github.com/numpy/numpy/pull/14307): MAINT: random: Match type of SeedSequence.pool_size to DEFAULT_POOL_SIZE.
[#14308](https://github.com/numpy/numpy/pull/14308): BUG: Fix numpy.random bug in platform detection
[#14309](https://github.com/numpy/numpy/pull/14309): ENH: Enable huge pages in all Linux builds
[#14330](https://github.com/numpy/numpy/pull/14330): BUG: Fix segfault in*random.permutation(x)*when x is a string.
[#14338](https://github.com/numpy/numpy/pull/14338): BUG: don’t fail when lexsorting some empty arrays (#14228)
[#14339](https://github.com/numpy/numpy/pull/14339): BUG: Fix misuse of .names and .fields in various places (backport…
[#14345](https://github.com/numpy/numpy/pull/14345): BUG: fix behavior of structured_to_unstructured on non-trivial…
[#14350](https://github.com/numpy/numpy/pull/14350): REL: Prepare 1.17.1 release# NumPy 1.19.1 Release Notes[#](#numpy-1-19-1-release-notes)
NumPy 1.19.1 fixes several bugs found in the 1.19.0 release, replaces several functions deprecated in the upcoming Python-3.9 release, has improved support for AIX, and has a number of development related updates to keep CI working with recent upstream changes.

This release supports Python 3.6-3.8. Cython >= 0.29.21 needs to be used when building with Python 3.9 for testing purposes.

## Contributors[#](#contributors)
A total of 15 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Abhinav Reddy +

Anirudh Subramanian

Antonio Larrosa +

Charles Harris

Chunlin Fang

Eric Wieser

Etienne Guesnet +

Kevin Sheppard

Matti Picus

Raghuveer Devulapalli

Roman Yurchak

Ross Barnowski

Sayed Adel

Sebastian Berg

Tyler Reddy

## Pull requests merged[#](#pull-requests-merged)
A total of 25 pull requests were merged for this release.

[#16649](https://github.com/numpy/numpy/pull/16649): MAINT, CI: disable Shippable cache
[#16652](https://github.com/numpy/numpy/pull/16652): MAINT: Replace*PyUString_GET_SIZE*with*PyUnicode_GetLength*.
[#16654](https://github.com/numpy/numpy/pull/16654): REL: Fix outdated docs link
[#16656](https://github.com/numpy/numpy/pull/16656): BUG: raise IEEE exception on AIX
[#16672](https://github.com/numpy/numpy/pull/16672): BUG: Fix bug in AVX complex absolute while processing array of…
[#16693](https://github.com/numpy/numpy/pull/16693): TST: Add extra debugging information to CPU features detection
[#16703](https://github.com/numpy/numpy/pull/16703): BLD: Add CPU entry for Emscripten / WebAssembly
[#16705](https://github.com/numpy/numpy/pull/16705): TST: Disable Python 3.9-dev testing.
[#16714](https://github.com/numpy/numpy/pull/16714): MAINT: Disable use_hugepages in case of ValueError
[#16724](https://github.com/numpy/numpy/pull/16724): BUG: Fix PyArray_SearchSorted signature.
[#16768](https://github.com/numpy/numpy/pull/16768): MAINT: Fixes for deprecated functions in scalartypes.c.src
[#16772](https://github.com/numpy/numpy/pull/16772): MAINT: Remove unneeded call to PyUnicode_READY
[#16776](https://github.com/numpy/numpy/pull/16776): MAINT: Fix deprecated functions in scalarapi.c
[#16779](https://github.com/numpy/numpy/pull/16779): BLD, ENH: Add RPATH support for AIX
[#16780](https://github.com/numpy/numpy/pull/16780): BUG: Fix default fallback in genfromtxt
[#16784](https://github.com/numpy/numpy/pull/16784): BUG: Added missing return after raising error in methods.c
[#16795](https://github.com/numpy/numpy/pull/16795): BLD: update cython to 0.29.21
[#16832](https://github.com/numpy/numpy/pull/16832): MAINT: setuptools 49.2.0 emits a warning, avoid it
[#16872](https://github.com/numpy/numpy/pull/16872): BUG: Validate output size in bin- and multinomial
[#16875](https://github.com/numpy/numpy/pull/16875): BLD, MAINT: Pin setuptools
[#16904](https://github.com/numpy/numpy/pull/16904): DOC: Reconstruct Testing Guideline.
[#16905](https://github.com/numpy/numpy/pull/16905): TST, BUG: Re-raise MemoryError exception in test_large_zip’s…
[#16906](https://github.com/numpy/numpy/pull/16906): BUG,DOC: Fix bad MPL kwarg.
[#16916](https://github.com/numpy/numpy/pull/16916): BUG: Fix string/bytes to complex assignment
[#16922](https://github.com/numpy/numpy/pull/16922): REL: Prepare for NumPy 1.19.1 releaseSearch Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.numpy.exceptions.TooHardError# exception exceptions.TooHardError[source]# max_work was exceeded. This is raised whenever the maximum number of candidate solutions to consider specified by the max_work parameter is exceeded. Assigning a finite number to max_work may have caused the operation to fail.# Using Python as glue[#](#using-python-as-glue)
*Michel de Montaigne*
*Carl Zwanzig*
Many people like to say that Python is a fantastic glue language. Hopefully, this Chapter will convince you that this is true. The first adopters of Python for science were typically people who used it to glue together large application codes running on super-computers. Not only was it much nicer to code in Python than in a shell script or Perl, in addition, the ability to easily extend Python made it relatively easy to create new classes and types specifically adapted to the problems being solved. From the interactions of these early contributors, Numeric emerged as an array-like object that could be used to pass data between these applications.

As Numeric has matured and developed into NumPy, people have been able to write more code directly in NumPy. Often this code is fast-enough for production use, but there are still times that there is a need to access compiled code. Either to get that last bit of efficiency out of the algorithm or to make it easier to access widely-available codes written in C/C++ or Fortran.

This chapter will review many of the tools that are available for the purpose of accessing code written in other compiled languages. There are many resources available for learning to call other compiled libraries from Python and the purpose of this Chapter is not to make you an expert. The main goal is to make you aware of some of the possibilities so that you will know what to “Google” in order to learn more.

## Calling other compiled libraries from Python[#](#calling-other-compiled-libraries-from-python)
While Python is a great language and a pleasure to code in, its
dynamic nature results in overhead that can cause some code ( *i.e.*
raw computations inside of for loops) to be up 10-100 times slower
than equivalent code written in a static compiled language. In
addition, it can cause memory usage to be larger than necessary as
temporary arrays are created and destroyed during computation. For
many types of computing needs, the extra slow-down and memory
consumption can often not be spared (at least for time- or memory-
critical portions of your code). Therefore one of the most common
needs is to call out from Python code to a fast, machine-code routine
(e.g. compiled using C/C++ or Fortran). The fact that this is
relatively easy to do is a big reason why Python is such an excellent
high-level language for scientific and engineering programming.

There are two basic approaches to calling compiled code: writing an
extension module that is then imported to Python using the import
command, or calling a shared-library subroutine directly from Python
using the [ctypes](https://docs.python.org/3/library/ctypes.html)
module. Writing an extension module is the most common method.

Warning

Calling C-code from Python can result in Python crashes if you are not careful. None of the approaches in this chapter are immune. You have to know something about the way data is handled by both NumPy and by the third-party library being used.

## Hand-generated wrappers[#](#hand-generated-wrappers)
Extension modules were discussed in [Writing an extension module](c-info.how-to-extend.html#writing-an-extension).
The most basic way to interface with compiled code is to write
an extension module and construct a module method that calls
the compiled code. For improved readability, your method should
take advantage of the `PyArg_ParseTuple`
call to convert between
Python objects and C data-types. For standard C data-types there
is probably already a built-in converter. For others you may need
to write your own converter and use the `"O&"`
format string which
allows you to specify a function that will be used to perform the
conversion from the Python object to whatever C-structures are needed.

Once the conversions to the appropriate C-structures and C data-types have been performed, the next step in the wrapper is to call the underlying function. This is straightforward if the underlying function is in C or C++. However, in order to call Fortran code you must be familiar with how Fortran subroutines are called from C/C++ using your compiler and platform. This can vary somewhat platforms and compilers (which is another reason f2py makes life much simpler for interfacing Fortran code) but generally involves underscore mangling of the name and the fact that all variables are passed by reference (i.e. all arguments are pointers).

The advantage of the hand-generated wrapper is that you have complete control over how the C-library gets used and called which can lead to a lean and tight interface with minimal over-head. The disadvantage is that you have to write, debug, and maintain C-code, although most of it can be adapted using the time-honored technique of “cutting-pasting-and-modifying” from other extension modules. Because the procedure of calling out to additional C-code is fairly regimented, code-generation procedures have been developed to make this process easier. One of these code-generation techniques is distributed with NumPy and allows easy integration with Fortran and (simple) C code. This package, f2py, will be covered briefly in the next section.

## f2py[#](#f2py)
F2py allows you to automatically construct an extension module that interfaces to routines in Fortran 77/90/95 code. It has the ability to parse Fortran 77/90/95 code and automatically generate Python signatures for the subroutines it encounters, or you can guide how the subroutine interfaces with Python by constructing an interface-definition-file (or modifying the f2py-produced one).

See the [F2PY documentation](../f2py/index.html#f2py) for more information and examples.

The f2py method of linking compiled code is currently the most sophisticated and integrated approach. It allows clean separation of Python with compiled code while still allowing for separate distribution of the extension module. The only draw-back is that it requires the existence of a Fortran compiler in order for a user to install the code. However, with the existence of the free-compilers g77, gfortran, and g95, as well as high-quality commercial compilers, this restriction is not particularly onerous. In our opinion, Fortran is still the easiest way to write fast and clear code for scientific computing. It handles complex numbers, and multi-dimensional indexing in the most straightforward way. Be aware, however, that some Fortran compilers will not be able to optimize code as well as good hand- written C-code.

## Cython[#](#cython)
[Cython](http://cython.org) is a compiler for a Python dialect that adds
(optional) static typing for speed, and allows mixing C or C++ code
into your modules. It produces C or C++ extensions that can be compiled
and imported in Python code.
If you are writing an extension module that will include quite a bit of your own algorithmic code as well, then Cython is a good match. Among its features is the ability to easily and quickly work with multidimensional arrays.

Notice that Cython is an extension-module generator only. Unlike f2py,
it includes no automatic facility for compiling and linking
the extension module (which must be done in the usual fashion). It
does provide a modified distutils class called `build_ext`
which lets
you build an extension module from a `.pyx`
source. Thus, you could
write in a `setup.py`
file:

```
from Cython.Distutils import build_ext
from distutils.extension import Extension
from distutils.core import setup
import numpy
setup(name='mine', description='Nothing',
ext_modules=[Extension('filter', ['filter.pyx'],
include_dirs=[numpy.get_include()])],
cmdclass = {'build_ext':build_ext})
```
Adding the NumPy include directory is, of course, only necessary if
you are using NumPy arrays in the extension module (which is what we
assume you are using Cython for). The distutils extensions in NumPy
also include support for automatically producing the extension-module
and linking it from a `.pyx`
file. It works so that if the user does
not have Cython installed, then it looks for a file with the same
file-name but a `.c`
extension which it then uses instead of trying
to produce the `.c`
file again.

If you just use Cython to compile a standard Python module, then you
will get a C extension module that typically runs a bit faster than the
equivalent Python module. Further speed increases can be gained by using
the `cdef`
keyword to statically define C variables.

Let’s look at two examples we’ve seen before to see how they might be implemented using Cython. These examples were compiled into extension modules using Cython 0.21.1.

### Complex addition in Cython[#](#complex-addition-in-cython)
Here is part of a Cython module named `add.pyx`
which implements the
complex addition functions we previously implemented using f2py:

```
cimport cython
cimport numpy as np
import numpy as np
# We need to initialize NumPy.
np.import_array()
#@cython.boundscheck(False)
def zadd(in1, in2):
cdef double complex[:] a = in1.ravel()
cdef double complex[:] b = in2.ravel()
out = np.empty(a.shape[0], np.complex64)
cdef double complex[:] c = out.ravel()
for i in range(c.shape[0]):
c[i].real = a[i].real + b[i].real
c[i].imag = a[i].imag + b[i].imag
return out
```
This module shows use of the `cimport`
statement to load the definitions
from the `numpy.pxd`
header that ships with Cython. It looks like NumPy is
imported twice; `cimport`
only makes the NumPy C-API available, while the
regular `import`
causes a Python-style import at runtime and makes it
possible to call into the familiar NumPy Python API.

The example also demonstrates Cython’s “typed memoryviews”, which are like
NumPy arrays at the C level, in the sense that they are shaped and strided
arrays that know their own extent (unlike a C array addressed through a bare
pointer). The syntax `double complex[:]`
denotes a one-dimensional array
(vector) of doubles, with arbitrary strides. A contiguous array of ints would
be `int[::1]`
, while a matrix of floats would be `float[:, :]`
.

Shown commented is the `cython.boundscheck`
decorator, which turns
bounds-checking for memory view accesses on or off on a per-function basis.
We can use this to further speed up our code, at the expense of safety
(or a manual check prior to entering the loop).

Other than the view syntax, the function is immediately readable to a Python
programmer. Static typing of the variable `i`
is implicit. Instead of the
view syntax, we could also have used Cython’s special NumPy array syntax,
but the view syntax is preferred.

### Image filter in Cython[#](#image-filter-in-cython)
The two-dimensional example we created using Fortran is just as easy to write in Cython:

```
cimport numpy as np
import numpy as np
np.import_array()
def filter(img):
cdef double[:, :] a = np.asarray(img, dtype=np.double)
out = np.zeros(img.shape, dtype=np.double)
cdef double[:, ::1] b = out
cdef np.npy_intp i, j
for i in range(1, a.shape[0] - 1):
for j in range(1, a.shape[1] - 1):
b[i, j] = (a[i, j]
+ .5 * ( a[i-1, j] + a[i+1, j]
+ a[i, j-1] + a[i, j+1])
+ .25 * ( a[i-1, j-1] + a[i-1, j+1]
+ a[i+1, j-1] + a[i+1, j+1]))
return out
```
This 2-d averaging filter runs quickly because the loop is in C and
the pointer computations are done only as needed. If the code above is
compiled as a module `image`
, then a 2-d image, `img`
, can be filtered
using this code very quickly using:

```
import image
out = image.filter(img)
```
Regarding the code, two things are of note: firstly, it is impossible to
return a memory view to Python. Instead, a NumPy array `out`
is first
created, and then a view `b`
onto this array is used for the computation.
Secondly, the view `b`
is typed `double[:, ::1]`
. This means 2-d array
with contiguous rows, i.e., C matrix order. Specifying the order explicitly
can speed up some algorithms since they can skip stride computations.

### Conclusion[#](#conclusion)
Cython is the extension mechanism of choice for several scientific Python libraries, including Scipy, Pandas, SAGE, scikit-image and scikit-learn, as well as the XML processing library LXML. The language and compiler are well-maintained.

There are several disadvantages of using Cython:

When coding custom algorithms, and sometimes when wrapping existing C libraries, some familiarity with C is required. In particular, when using C memory management (

`malloc`
and friends), it’s easy to introduce memory leaks. However, just compiling a Python module renamed to`.pyx`
can already speed it up, and adding a few type declarations can give dramatic speedups in some code.
It is easy to lose a clean separation between Python and C which makes re-using your C-code for other non-Python-related projects more difficult.

The C-code generated by Cython is hard to read and modify (and typically compiles with annoying but harmless warnings).

One big advantage of Cython-generated extension modules is that they are easy to distribute. In summary, Cython is a very capable tool for either gluing C code or generating an extension module quickly and should not be over-looked. It is especially useful for people that can’t or won’t write C or Fortran code.

## ctypes[#](#index-2)
[Ctypes](https://docs.python.org/3/library/ctypes.html)
is a Python extension module, included in the stdlib, that
allows you to call an arbitrary function in a shared library directly
from Python. This approach allows you to interface with C-code directly
from Python. This opens up an enormous number of libraries for use from
Python. The drawback, however, is that coding mistakes can lead to ugly
program crashes very easily (just as can happen in C) because there is
little type or bounds checking done on the parameters. This is especially
true when array data is passed in as a pointer to a raw memory
location. The responsibility is then on you that the subroutine will
not access memory outside the actual array area. But, if you don’t
mind living a little dangerously ctypes can be an effective tool for
quickly taking advantage of a large shared library (or writing
extended functionality in your own shared library).
Because the ctypes approach exposes a raw interface to the compiled code it is not always tolerant of user mistakes. Robust use of the ctypes module typically involves an additional layer of Python code in order to check the data types and array bounds of objects passed to the underlying subroutine. This additional layer of checking (not to mention the conversion from ctypes objects to C-data-types that ctypes itself performs), will make the interface slower than a hand-written extension-module interface. However, this overhead should be negligible if the C-routine being called is doing any significant amount of work. If you are a great Python programmer with weak C skills, ctypes is an easy way to write a useful interface to a (shared) library of compiled code.

To use ctypes you must

Have a shared library.

Load the shared library.

Convert the Python objects to ctypes-understood arguments.

Call the function from the library with the ctypes arguments.

### Converting arguments[#](#converting-arguments)
Python ints/longs, strings, and unicode objects are automatically converted as needed to equivalent ctypes arguments The None object is also converted automatically to a NULL pointer. All other Python objects must be converted to ctypes-specific types. There are two ways around this restriction that allow ctypes to integrate with other objects.

Don’t set the argtypes attribute of the function object and define an

`_as_parameter_`
method for the object you want to pass in. The`_as_parameter_`
method must return a Python int which will be passed directly to the function.
Set the argtypes attribute to a list whose entries contain objects with a classmethod named from_param that knows how to convert your object to an object that ctypes can understand (an int/long, string, unicode, or object with the

`_as_parameter_`
attribute).
NumPy uses both methods with a preference for the second method
because it can be safer. The ctypes attribute of the ndarray returns
an object that has an `_as_parameter_`
attribute which returns an
integer representing the address of the ndarray to which it is
associated. As a result, one can pass this ctypes attribute object
directly to a function expecting a pointer to the data in your
ndarray. The caller must be sure that the ndarray object is of the
correct type, shape, and has the correct flags set or risk nasty
crashes if the data-pointer to inappropriate arrays are passed in.

To implement the second method, NumPy provides the class-factory
function [ ndpointer](#ndpointer) in the

[module. This class-factory function produces an appropriate class that can be placed in an argtypes attribute entry of a ctypes function. The class will contain a from_param method which ctypes will use to convert any ndarray passed in to the function to a ctypes-recognized object. In the process, the conversion will perform checking on any properties of the ndarray that were specified by the user in the call to](../reference/routines.ctypeslib.html#module-numpy.ctypeslib)
`numpy.ctypeslib`
[. Aspects of the ndarray that can be checked include the data-type, the number-of-dimensions, the shape, and/or the state of the flags on any array passed. The return value of the from_param method is the ctypes attribute of the array which (because it contains the](#ndpointer)
`ndpointer`
`_as_parameter_`
attribute pointing to the array data area) can be used by ctypes
directly.The ctypes attribute of an ndarray is also endowed with additional
attributes that may be convenient when passing additional information
about the array into a ctypes function. The attributes **data**,
**shape**, and **strides** can provide ctypes compatible types
corresponding to the data-area, the shape, and the strides of the
array. The data attribute returns a `c_void_p`
representing a
pointer to the data area. The shape and strides attributes each return
an array of ctypes integers (or None representing a NULL pointer, if a
0-d array). The base ctype of the array is a ctype integer of the same
size as a pointer on the platform. There are also methods
`data_as({ctype})`
, `shape_as(<base ctype>)`
, and ```
strides_as(<base
ctype>)
```
. These return the data as a ctype object of your choice and
the shape/strides arrays using an underlying base type of your choice.
For convenience, the `ctypeslib`
module also contains `c_intp`
as
a ctypes integer data-type whose size is the same as the size of
`c_void_p`
on the platform (its value is None if ctypes is not
installed).

### Calling the function[#](#calling-the-function)
The function is accessed as an attribute of or an item from the loaded
shared-library. Thus, if `./mylib.so`
has a function named
`cool_function1`
, it may be accessed either as:

```
lib = numpy.ctypeslib.load_library('mylib','.')
func1 = lib.cool_function1 # or equivalently
func1 = lib['cool_function1']
```
In ctypes, the return-value of a function is set to be ‘int’ by default. This behavior can be changed by setting the restype attribute of the function. Use None for the restype if the function has no return value (‘void’):

```
func1.restype = None
```
As previously discussed, you can also set the argtypes attribute of
the function in order to have ctypes check the types of the input
arguments when the function is called. Use the [ ndpointer](#ndpointer) factory
function to generate a ready-made class for data-type, shape, and
flags checking on your new function. The

[function has the signature](#ndpointer)
`ndpointer`
ndpointer(*dtype=None*,*ndim=None*,*shape=None*,*flags=None*)[#](#ndpointer)
-
Keyword arguments with the value

`None`
are not checked. Specifying a keyword enforces checking of that aspect of the ndarray on conversion to a ctypes-compatible object. The dtype keyword can be any object understood as a data-type object. The ndim keyword should be an integer, and the shape keyword should be an integer or a sequence of integers. The flags keyword specifies the minimal flags that are required on any array passed in. This can be specified as a string of comma separated requirements, an integer indicating the requirement bits OR’d together, or a flags object returned from the flags attribute of an array with the necessary requirements.
Using an ndpointer class in the argtypes method can make it
significantly safer to call a C function using ctypes and the data-
area of an ndarray. You may still want to wrap the function in an
additional Python wrapper to make it user-friendly (hiding some
obvious arguments and making some arguments output arguments). In this
process, the `requires`
function in NumPy may be useful to return the right
kind of array from a given input.

### Complete example[#](#complete-example)
In this example, we will demonstrate how the addition function and the filter
function implemented previously using the other approaches can be
implemented using ctypes. First, the C code which implements the
algorithms contains the functions `zadd`
, `dadd`
, `sadd`
, `cadd`
,
and `dfilter2d`
. The `zadd`
function is:

```
/* Add arrays of contiguous data */
typedef struct {double real; double imag;} cdouble;
typedef struct {float real; float imag;} cfloat;
void zadd(cdouble *a, cdouble *b, cdouble *c, long n)
{
while (n--) {
c->real = a->real + b->real;
c->imag = a->imag + b->imag;
a++; b++; c++;
}
}
```
with similar code for `cadd`
, `dadd`
, and `sadd`
that handles complex
float, double, and float data-types, respectively:

```
void cadd(cfloat *a, cfloat *b, cfloat *c, long n)
{
while (n--) {
c->real = a->real + b->real;
c->imag = a->imag + b->imag;
a++; b++; c++;
}
}
void dadd(double *a, double *b, double *c, long n)
{
while (n--) {
*c++ = *a++ + *b++;
}
}
void sadd(float *a, float *b, float *c, long n)
{
while (n--) {
*c++ = *a++ + *b++;
}
}
```
The `code.c`
file also contains the function `dfilter2d`
:

```
/*
* Assumes b is contiguous and has strides that are multiples of
* sizeof(double)
*/
void
dfilter2d(double *a, double *b, ssize_t *astrides, ssize_t *dims)
{
ssize_t i, j, M, N, S0, S1;
ssize_t r, c, rm1, rp1, cp1, cm1;
M = dims[0]; N = dims[1];
S0 = astrides[0]/sizeof(double);
S1 = astrides[1]/sizeof(double);
for (i = 1; i < M - 1; i++) {
r = i*S0;
rp1 = r + S0;
rm1 = r - S0;
for (j = 1; j < N - 1; j++) {
c = j*S1;
cp1 = j + S1;
cm1 = j - S1;
b[i*N + j] = a[r + c] +
(a[rp1 + c] + a[rm1 + c] +
a[r + cp1] + a[r + cm1])*0.5 +
(a[rp1 + cp1] + a[rp1 + cm1] +
a[rm1 + cp1] + a[rm1 + cp1])*0.25;
}
}
}
```
A possible advantage this code has over the Fortran-equivalent code is
that it takes arbitrarily strided (i.e. non-contiguous arrays) and may
also run faster depending on the optimization capability of your
compiler. But, it is an obviously more complicated than the simple code
in `filter.f`
. This code must be compiled into a shared library. On my
Linux system this is accomplished using:

```
gcc -o code.so -shared code.c
```
Which creates a shared_library named code.so in the current directory.
On Windows don’t forget to either add `__declspec(dllexport)`
in front
of void on the line preceding each function definition, or write a
`code.def`
file that lists the names of the functions to be exported.

A suitable Python interface to this shared library should be constructed. To do this create a file named interface.py with the following lines at the top:

```
__all__ = ['add', 'filter2d']
import numpy as np
import os
_path = os.path.dirname('__file__')
lib = np.ctypeslib.load_library('code', _path)
_typedict = {'zadd' : complex, 'sadd' : np.single,
'cadd' : np.csingle, 'dadd' : float}
for name in _typedict.keys():
val = getattr(lib, name)
val.restype = None
_type = _typedict[name]
val.argtypes = [np.ctypeslib.ndpointer(_type,
flags='aligned, contiguous'),
np.ctypeslib.ndpointer(_type,
flags='aligned, contiguous'),
np.ctypeslib.ndpointer(_type,
flags='aligned, contiguous,'\
'writeable'),
np.ctypeslib.c_intp]
```
This code loads the shared library named `code.{ext}`
located in the
same path as this file. It then adds a return type of void to the
functions contained in the library. It also adds argument checking to
the functions in the library so that ndarrays can be passed as the
first three arguments along with an integer (large enough to hold a
pointer on the platform) as the fourth argument.

Setting up the filtering function is similar and allows the filtering function to be called with ndarray arguments as the first two arguments and with pointers to integers (large enough to handle the strides and shape of an ndarray) as the last two arguments.:

```
lib.dfilter2d.restype=None
lib.dfilter2d.argtypes = [np.ctypeslib.ndpointer(float, ndim=2,
flags='aligned'),
np.ctypeslib.ndpointer(float, ndim=2,
flags='aligned, contiguous,'\
'writeable'),
ctypes.POINTER(np.ctypeslib.c_intp),
ctypes.POINTER(np.ctypeslib.c_intp)]
```
Next, define a simple selection function that chooses which addition function to call in the shared library based on the data-type:

```
def select(dtype):
if dtype.char in ['?bBhHf']:
return lib.sadd, single
elif dtype.char in ['F']:
return lib.cadd, csingle
elif dtype.char in ['DG']:
return lib.zadd, complex
else:
return lib.dadd, float
return func, ntype
```
Finally, the two functions to be exported by the interface can be written simply as:

```
def add(a, b):
requires = ['CONTIGUOUS', 'ALIGNED']
a = np.asanyarray(a)
func, dtype = select(a.dtype)
a = np.require(a, dtype, requires)
b = np.require(b, dtype, requires)
c = np.empty_like(a)
func(a,b,c,a.size)
return c
```
and:

```
def filter2d(a):
a = np.require(a, float, ['ALIGNED'])
b = np.zeros_like(a)
lib.dfilter2d(a, b, a.ctypes.strides, a.ctypes.shape)
return b
```
### Conclusion[#](#id4)
Using ctypes is a powerful way to connect Python with arbitrary C-code. Its advantages for extending Python include

clean separation of C code from Python code

no need to learn a new syntax except Python and C

allows re-use of C code

functionality in shared libraries written for other purposes can be obtained with a simple Python wrapper and search for the library.

easy integration with NumPy through the ctypes attribute

full argument checking with the ndpointer class factory

Its disadvantages include

It is difficult to distribute an extension module made using ctypes because of a lack of support for building shared libraries in distutils.

You must have shared-libraries of your code (no static libraries).

Very little support for C++ code and its different library-calling conventions. You will probably need a C wrapper around C++ code to use with ctypes (or just use Boost.Python instead).

Because of the difficulty in distributing an extension module made using ctypes, f2py and Cython are still the easiest ways to extend Python for package creation. However, ctypes is in some cases a useful alternative. This should bring more features to ctypes that should eliminate the difficulty in extending Python and distributing the extension using ctypes.

## Additional tools you may find useful[#](#additional-tools-you-may-find-useful)
These tools have been found useful by others using Python and so are included here. They are discussed separately because they are either older ways to do things now handled by f2py, Cython, or ctypes (SWIG, PyFort) or because of a lack of reasonable documentation (SIP, Boost). Links to these methods are not included since the most relevant can be found using Google or some other search engine, and any links provided here would be quickly dated. Do not assume that inclusion in this list means that the package deserves attention. Information about these packages are collected here because many people have found them useful and we’d like to give you as many options as possible for tackling the problem of easily integrating your code.

### SWIG[#](#swig)
Simplified Wrapper and Interface Generator (SWIG) is an old and fairly
stable method for wrapping C/C++-libraries to a large variety of other
languages. It does not specifically understand NumPy arrays but can be
made usable with NumPy through the use of typemaps. There are some
sample typemaps in the numpy/tools/swig directory under numpy.i together
with an example module that makes use of them. SWIG excels at wrapping
large C/C++ libraries because it can (almost) parse their headers and
auto-produce an interface. Technically, you need to generate a `.i`
file that defines the interface. Often, however, this `.i`
file can
be parts of the header itself. The interface usually needs a bit of
tweaking to be very useful. This ability to parse C/C++ headers and
auto-generate the interface still makes SWIG a useful approach to
adding functionalilty from C/C++ into Python, despite the other
methods that have emerged that are more targeted to Python. SWIG can
actually target extensions for several languages, but the typemaps
usually have to be language-specific. Nonetheless, with modifications
to the Python-specific typemaps, SWIG can be used to interface a
library with other languages such as Perl, Tcl, and Ruby.

My experience with SWIG has been generally positive in that it is relatively easy to use and quite powerful. It has been used often before becoming more proficient at writing C-extensions. However, writing custom interfaces with SWIG is often troublesome because it must be done using the concept of typemaps which are not Python specific and are written in a C-like syntax. Therefore, other gluing strategies are preferred and SWIG would be probably considered only to wrap a very-large C/C++ library. Nonetheless, there are others who use SWIG quite happily.

### SIP[#](#sip)
SIP is another tool for wrapping C/C++ libraries that is Python specific and appears to have very good support for C++. Riverbank Computing developed SIP in order to create Python bindings to the QT library. An interface file must be written to generate the binding, but the interface file looks a lot like a C/C++ header file. While SIP is not a full C++ parser, it understands quite a bit of C++ syntax as well as its own special directives that allow modification of how the Python binding is accomplished. It also allows the user to define mappings between Python types and C/C++ structures and classes.

### Boost Python[#](#boost-python)
Boost is a repository of C++ libraries and Boost.Python is one of those libraries which provides a concise interface for binding C++ classes and functions to Python. The amazing part of the Boost.Python approach is that it works entirely in pure C++ without introducing a new syntax. Many users of C++ report that Boost.Python makes it possible to combine the best of both worlds in a seamless fashion. Using Boost to wrap simple C-subroutines is usually over-kill. Its primary purpose is to make C++ classes available in Python. So, if you have a set of C++ classes that need to be integrated cleanly into Python, consider learning about and using Boost.Python.

### PyFort[#](#pyfort)
PyFort is a nice tool for wrapping Fortran and Fortran-like C-code into Python with support for Numeric arrays. It was written by Paul Dubois, a distinguished computer scientist and the very first maintainer of Numeric (now retired). It is worth mentioning in the hopes that somebody will update PyFort to work with NumPy arrays as well which now support either Fortran or C-style contiguous arrays.# numpy.result_type[#](#numpy-result-type)
numpy.result_type(**arrays_and_dtypes*)[#](#numpy.result_type)
-
Returns the type that results from applying the NumPy type promotion rules to the arguments.

Type promotion in NumPy works similarly to the rules in languages like C++, with some slight differences. When both scalars and arrays are used, the array’s type takes precedence and the actual value of the scalar is taken into account.

For example, calculating 3*a, where a is an array of 32-bit floats, intuitively should result in a 32-bit float output. If the 3 is a 32-bit integer, the NumPy rules indicate it can’t convert losslessly into a 32-bit float, so a 64-bit float should be the result type. By examining the value of the constant, ‘3’, we see that it fits in an 8-bit integer, which can be cast losslessly into the 32-bit float.

Parameters:
-
**arrays_and_dtypes**list of arrays and dtypes
The operands of some operation whose result type is needed.

Returns:
-
**out**dtype
The result type.

See also

Notes

New in version 1.6.0.

The specific algorithm used is as follows.

Categories are determined by first checking which of boolean, integer (int/uint), or floating point (float/complex) the maximum kind of all the arrays and the scalars are.

If there are only scalars or the maximum category of the scalars is higher than the maximum category of the arrays, the data types are combined with

to produce the return value.`promote_types`
Otherwise,

is called on each scalar, and the resulting data types are all combined with`min_scalar_type`
to produce the return value.`promote_types`
The set of int values is not a subset of the uint values for types with the same number of bits, something not reflected in

, but handled as a special case in`min_scalar_type`
.`result_type`
Examples

>>> np.result_type(3, np.arange(7, dtype='i1')) dtype('int8')
>>> np.result_type('i4', 'c8') dtype('complex128')
>>> np.result_type(3.0, -2) dtype('float64')# numpy.ma.masked_array.copy[#](#numpy-ma-masked-array-copy)
method

ma.masked_array.copy(*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2571-L2581)[#](#numpy.ma.masked_array.copy)
-
Return a copy of the array.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout of the copy. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*a*as closely as possible. (Note that this function andare very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)`numpy.copy`
See also

`numpy.copy`
Similar function with different default behavior

`numpy.copyto`
Notes

This function is the preferred method for creating an array copy. The function

is similar, but it defaults to using order ‘K’, and will not pass sub-classes through by default.`numpy.copy`
Examples

>>> x = np.array([[1,2,3],[4,5,6]], order='F')
>>> y = x.copy()
>>> x.fill(0)
>>> x array([[0, 0, 0], [0, 0, 0]])
>>> y array([[1, 2, 3], [4, 5, 6]])
>>> y.flags['C_CONTIGUOUS'] True# numpy.random.hypergeometric[#](#numpy-random-hypergeometric)
random.hypergeometric(*ngood*,*nbad*,*nsample*,*size=None*)[#](#numpy.random.hypergeometric)
-
Draw samples from a Hypergeometric distribution.

Samples are drawn from a hypergeometric distribution with specified parameters,

*ngood*(ways to make a good selection),*nbad*(ways to make a bad selection), and*nsample*(number of items sampled, which is less than or equal to the sum`ngood + nbad`
).Note

New code should use the

method of a`hypergeometric`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**ngood**int or array_like of ints
Number of ways to make a good selection. Must be nonnegative.

**nbad**int or array_like of ints
Number of ways to make a bad selection. Must be nonnegative.

**nsample**int or array_like of ints
Number of items sampled. Must be at least 1 and at most

`ngood + nbad`
.
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if*ngood*,*nbad*, and*nsample*are all scalars. Otherwise,`np.broadcast(ngood, nbad, nsample).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized hypergeometric distribution. Each sample is the number of good items within a randomly selected subset of size

*nsample*taken from a set of*ngood*good items and*nbad*bad items.
See also

`scipy.stats.hypergeom`
probability density function, distribution or cumulative density function, etc.

`random.Generator.hypergeometric`
which should be used for new code.

Notes

The probability density for the Hypergeometric distribution is

\[P(x) = \frac{\binom{g}{x}\binom{b}{n-x}}{\binom{g+b}{n}},\]where \(0 \le x \le n\) and \(n-b \le x \le g\)

for P(x) the probability of

`x`
good results in the drawn sample, g =*ngood*, b =*nbad*, and n =*nsample*.Consider an urn with black and white marbles in it,

*ngood*of them are black and*nbad*are white. If you draw*nsample*balls without replacement, then the hypergeometric distribution describes the distribution of black balls in the drawn sample.Note that this distribution is very similar to the binomial distribution, except that in this case, samples are drawn without replacement, whereas in the Binomial case samples are drawn with replacement (or the sample space is infinite). As the sample space becomes large, this distribution approaches the binomial.

References

[1]Lentner, Marvin, “Elementary Applied Statistics”, Bogden and Quigley, 1972.

[2]Weisstein, Eric W. “Hypergeometric Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/HypergeometricDistribution.html](http://mathworld.wolfram.com/HypergeometricDistribution.html)[3]Wikipedia, “Hypergeometric distribution”,

[https://en.wikipedia.org/wiki/Hypergeometric_distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution)Examples

Draw samples from the distribution:

>>> ngood, nbad, nsamp = 100, 2, 10 # number of good, number of bad, and number of samples >>> s = np.random.hypergeometric(ngood, nbad, nsamp, 1000) >>> from matplotlib.pyplot import hist >>> hist(s) # note that it is very unlikely to grab both bad items
Suppose you have an urn with 15 white and 15 black marbles. If you pull 15 marbles at random, how likely is it that 12 or more of them are one color?

>>> s = np.random.hypergeometric(15, 15, 15, 100000) >>> sum(s>=12)/100000. + sum(s<=3)/100000. # answer = 0.003 ... pretty unlikely!# numpy.random.standard_cauchy[#](#numpy-random-standard-cauchy)
random.standard_cauchy(*size=None*)[#](#numpy.random.standard_cauchy)
-
Draw samples from a standard Cauchy distribution with mode = 0.

Also known as the Lorentz distribution.

Note

New code should use the

method of a`standard_cauchy`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**samples**ndarray or scalar
The drawn samples.

See also

`random.Generator.standard_cauchy`
which should be used for new code.

Notes

The probability density function for the full Cauchy distribution is

\[P(x; x_0, \gamma) = \frac{1}{\pi \gamma \bigl[ 1+ (\frac{x-x_0}{\gamma})^2 \bigr] }\]and the Standard Cauchy distribution just sets \(x_0=0\) and \(\gamma=1\)

The Cauchy distribution arises in the solution to the driven harmonic oscillator problem, and also describes spectral line broadening. It also describes the distribution of values at which a line tilted at a random angle will cut the x axis.

When studying hypothesis tests that assume normality, seeing how the tests perform on data from a Cauchy distribution is a good indicator of their sensitivity to a heavy-tailed distribution, since the Cauchy looks very much like a Gaussian distribution, but with heavier tails.

References

[1]NIST/SEMATECH e-Handbook of Statistical Methods, “Cauchy Distribution”,

[https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm)[2]Weisstein, Eric W. “Cauchy Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/CauchyDistribution.html](http://mathworld.wolfram.com/CauchyDistribution.html)[3]Wikipedia, “Cauchy distribution”

[https://en.wikipedia.org/wiki/Cauchy_distribution](https://en.wikipedia.org/wiki/Cauchy_distribution)Examples

Draw samples and plot the distribution:

>>> import matplotlib.pyplot as plt >>> s = np.random.standard_cauchy(1000000) >>> s = s[(s>-25) & (s<25)] # truncate distribution so it plots well >>> plt.hist(s, bins=100) >>> plt.show()# numpy.polynomial.legendre.legone[#](#numpy-polynomial-legendre-legone)
polynomial.legendre.legone*= array([1])*[#](#numpy.polynomial.legendre.legone)
-
An array object represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)

Arrays should be constructed using

,`array`
or`zeros`
(refer to the See Also section below). The parameters given here refer to a low-level method (`empty`
*ndarray(…)*) for instantiating an array.For more information, refer to the

module and examine the methods and attributes of an array.`numpy`
Parameters:
-
**(for the __new__ method; see Notes below)**
**shape**tuple of ints
Shape of created array.

**dtype**data-type, optional
Any object that can be interpreted as a numpy data type.

**buffer**object exposing buffer interface, optional
Used to fill the array with data.

**offset**int, optional
Offset of array data in buffer.

**strides**tuple of ints, optional
Strides of data in memory.

**order**{‘C’, ‘F’}, optional
Row-major (C-style) or column-major (Fortran-style) order.

See also

`array`
Construct an array.

`zeros`
Create an array, each element of which is zero.

`empty`
Create an array, but leave its allocated memory unchanged (i.e., it contains “garbage”).

`dtype`
Create a data-type.

`numpy.typing.NDArray`
An ndarray alias

[generic](https://docs.python.org/3/glossary.html#term-generic-type)w.r.t. its.`dtype.type`
Notes

There are two modes of creating an array using

`__new__`
:If

*buffer*is None, then only,`shape`
, and`dtype`
*order*are used.
If

*buffer*is an object exposing the buffer interface, then all keywords are interpreted.
No

`__init__`
method is needed because the array is fully initialized after the`__new__`
method.Examples

These examples illustrate the low-level

constructor. Refer to the`ndarray`
*See Also*section above for easier ways of constructing an ndarray.First mode,

*buffer*is None:>>> np.ndarray(shape=(2,2), dtype=float, order='F') array([[0.0e+000, 0.0e+000], # random [ nan, 2.5e-323]])
Second mode:

>>> np.ndarray((2,), buffer=np.array([1,2,3]), ... offset=np.int_().itemsize, ... dtype=int) # offset = 1*itemsize, i.e. skip first element array([2, 3])
Attributes:
-
**T**ndarray
Transpose of the array.

**data**buffer
The array’s elements, in memory.

**dtype**dtype object
Describes the format of the elements in the array.

**flags**dict
Dictionary containing information related to memory use, e.g., ‘C_CONTIGUOUS’, ‘OWNDATA’, ‘WRITEABLE’, etc.

**flat**numpy.flatiter object
Flattened version of the array as an iterator. The iterator allows assignments, e.g.,

`x.flat = 3`
(Seefor assignment examples; TODO).`ndarray.flat`
**imag**ndarray
Imaginary part of the array.

**real**ndarray
Real part of the array.

**size**int
Number of elements in the array.

**itemsize**int
The memory use of each array element in bytes.

**nbytes**int
The total number of bytes required to store the array data, i.e.,

`itemsize * size`
.
**ndim**int
The array’s number of dimensions.

**shape**tuple of ints
Shape of the array.

**strides**tuple of ints
The step-size required to move from one element to the next in memory. For example, a contiguous

`(3, 4)`
array of type`int16`
in C-order has strides`(8, 2)`
. This implies that to move from element to element in memory requires jumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time (`2 * 4`
).
**ctypes**ctypes object
Class containing properties of the array needed for interaction with ctypes.

**base**ndarray
If the array is a view into another array, that array is its

*base*(unless that array is also a view). The*base*array is where the array data is actually stored.# numpy.polynomial.chebyshev.chebsub[#](#numpy-polynomial-chebyshev-chebsub)
polynomial.chebyshev.chebsub(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L611-L652)[#](#numpy.polynomial.chebyshev.chebsub)
-
Subtract one Chebyshev series from another.

Returns the difference of two Chebyshev series

*c1*-*c2*. The sequences of coefficients are from lowest order term to highest, i.e., [1,2,3] represents the series`T_0 + 2*T_1 + 3*T_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Chebyshev series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Of Chebyshev series coefficients representing their difference.

Notes

Unlike multiplication, division, etc., the difference of two Chebyshev series is a Chebyshev series (without having to “reproject” the result onto the basis set) so subtraction, just like that of “standard” polynomials, is simply “component-wise.”

Examples

>>> from numpy.polynomial import chebyshev as C >>> c1 = (1,2,3) >>> c2 = (3,2,1) >>> C.chebsub(c1,c2) array([-2., 0., 2.]) >>> C.chebsub(c2,c1) # -C.chebsub(c1,c2) array([ 2., 0., -2.])# numpy.dtype.flags[#](#numpy-dtype-flags)
attribute

dtype.flags[#](#numpy.dtype.flags)
-
Bit-flags describing how this data type is to be interpreted.

Bit-masks are in

`numpy.core.multiarray`
as the constants*ITEM_HASOBJECT*,*LIST_PICKLE*,*ITEM_IS_POINTER*,*NEEDS_INIT*,*NEEDS_PYAPI*,*USE_GETITEM*,*USE_SETITEM*. A full explanation of these flags is in C-API documentation; they are largely useful for user-defined data-types.The following example demonstrates that operations on this particular dtype requires Python C-API.

Examples

>>> x = np.dtype([('a', np.int32, 8), ('b', np.float64, 6)]) >>> x.flags 16 >>> np.core.multiarray.NEEDS_PYAPI 16# numpy.random.RandomState.zipf[#](#numpy-random-randomstate-zipf)
method

random.RandomState.zipf(*a*,*size=None*)[#](#numpy.random.RandomState.zipf)
-
Draw samples from a Zipf distribution.

Samples are drawn from a Zipf distribution with specified parameter

*a*> 1.The Zipf distribution (also known as the zeta distribution) is a discrete probability distribution that satisfies Zipf’s law: the frequency of an item is inversely proportional to its rank in a frequency table.

Note

New code should use the

method of a`zipf`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**a**float or array_like of floats
Distribution parameter. Must be greater than 1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`a`
is a scalar. Otherwise,`np.array(a).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Zipf distribution.

See also

`scipy.stats.zipf`
probability density function, distribution, or cumulative density function, etc.

`random.Generator.zipf`
which should be used for new code.

Notes

The probability density for the Zipf distribution is

\[p(k) = \frac{k^{-a}}{\zeta(a)},\]for integers \(k \geq 1\), where \(\zeta\) is the Riemann Zeta function.

It is named for the American linguist George Kingsley Zipf, who noted that the frequency of any word in a sample of a language is inversely proportional to its rank in the frequency table.

References

[1]Zipf, G. K., “Selected Studies of the Principle of Relative Frequency in Language,” Cambridge, MA: Harvard Univ. Press, 1932.

Examples

Draw samples from the distribution:

>>> a = 4.0 >>> n = 20000 >>> s = np.random.zipf(a, n)
Display the histogram of the samples, along with the expected histogram based on the probability density function:

>>> import matplotlib.pyplot as plt >>> from scipy.special import zeta
provides a fast histogram for small integers.`bincount`
>>> count = np.bincount(s) >>> k = np.arange(1, s.max() + 1)
>>> plt.bar(k, count[1:], alpha=0.5, label='sample count') >>> plt.plot(k, n*(k**-a)/zeta(a), 'k.-', alpha=0.5, ... label='expected count') >>> plt.semilogy() >>> plt.grid(alpha=0.4) >>> plt.legend() >>> plt.title(f'Zipf sample, a={a}, size={n}') >>> plt.show()# numpy.recarray.itemset[#](#numpy-recarray-itemset)
method

recarray.itemset(**args*)[#](#numpy.recarray.itemset)
-
Insert scalar into an array (scalar is cast to array’s dtype, if possible)

There must be at least 1 argument, and define the last argument as

*item*. Then,`a.itemset(*args)`
is equivalent to but faster than`a[args] = item`
. The item should be a scalar value and*args*must select a single item in the array*a*.Parameters:
-
***args**Arguments
If one argument: a scalar, only used in case

*a*is of size 1. If two arguments: the last argument is the value to be set and must be a scalar, the first argument specifies a single array element location. It is either an int or a tuple.
Notes

Compared to indexing syntax,

provides some speed increase for placing a scalar into a particular location in an`itemset`
, if you must do this. However, generally this is discouraged: among other problems, it complicates the appearance of the code. Also, when using`ndarray`
(and`itemset`
) inside a loop, be sure to assign the methods to a local variable to avoid the attribute look-up at each loop iteration.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.itemset(4, 0) >>> x.itemset((2, 2), 9) >>> x array([[2, 2, 6], [1, 0, 6], [1, 0, 9]])# Constants of the `numpy.ma`
module[#](#constants-of-the-numpy-ma-module)
`numpy.ma`
In addition to the [ MaskedArray](#numpy.ma.MaskedArray) class, the

[module defines several constants.](maskedarray.generic.html#module-numpy.ma)
`numpy.ma`
numpy.ma.masked[#](#numpy.ma.masked)
-
The

constant is a special case of`masked`
, with a float datatype and a null shape. It is used to test whether a specific entry of a masked array is masked, or to mask one or several entries of a masked array:`MaskedArray`
>>> x = ma.array([1, 2, 3], mask=[0, 1, 0]) >>> x[1] is ma.masked True >>> x[-1] = ma.masked >>> x masked_array(data=[1, --, --], mask=[False, True, True], fill_value=999999)
numpy.ma.nomask[#](#numpy.ma.nomask)
-
Value indicating that a masked array has no invalid entry.

is used internally to speed up computations when the mask is not needed. It is represented internally as`nomask`
`np.False_`
.
numpy.ma.masked_print_option[#](#numpy.ma.masked_print_option)
-
String used in lieu of missing data when a masked array is printed. By default, this string is

`'--'`
.Use

`set_display()`
to change the default string. Example usage:`numpy.ma.masked_print_option.set_display('X')`
replaces missing data with`'X'`
.
# The `MaskedArray`
class[#](#the-maskedarray-class)
`MaskedArray`
A subclass of [ ndarray](generated/numpy.ndarray.html#numpy.ndarray) designed to manipulate numerical arrays with missing data.

An instance of [ MaskedArray](#numpy.ma.MaskedArray) can be thought as the combination of several elements:

The

, as a regular`data`
of any shape or datatype (the data).`numpy.ndarray`
A boolean

with the same shape as the data, where a`mask`
`True`
value indicates that the corresponding element of the data is invalid. The special valueis also acceptable for arrays without named fields, and indicates that no data is invalid.`nomask`
A

, a value that may be used to replace the invalid entries in order to return a standard`fill_value`
.`numpy.ndarray`
## Attributes and properties of masked arrays[#](#attributes-and-properties-of-masked-arrays)
See also

ma.MaskedArray.data[#](#numpy.ma.MaskedArray.data)
-
Returns the underlying data, as a view of the masked array.

If the underlying data is a subclass of

, it is returned as such.`numpy.ndarray`
>>> x = np.ma.array(np.matrix([[1, 2], [3, 4]]), mask=[[0, 1], [1, 0]]) >>> x.data matrix([[1, 2], [3, 4]])
The type of the data can be accessed through the

attribute.`baseclass`
ma.MaskedArray.mask[#](#numpy.ma.MaskedArray.mask)
-
Current mask.

ma.MaskedArray.recordmask[#](#numpy.ma.MaskedArray.recordmask)
-
Get or set the mask of the array if it has no named fields. For structured arrays, returns a ndarray of booleans where entries are

`True`
if**all**the fields are masked,`False`
otherwise:>>> x = np.ma.array([(1, 1), (2, 2), (3, 3), (4, 4), (5, 5)], ... mask=[(0, 0), (1, 0), (1, 1), (0, 1), (0, 0)], ... dtype=[('a', int), ('b', int)]) >>> x.recordmask array([False, False, True, False, False])
ma.MaskedArray.fill_value[#](#numpy.ma.MaskedArray.fill_value)
-
The filling value of the masked array is a scalar. When setting, None will set to a default based on the data type.

Examples

>>> for dt in [np.int32, np.int64, np.float64, np.complex128]: ... np.ma.array([0, 1], dtype=dt).get_fill_value() ... 999999 999999 1e+20 (1e+20+0j)
>>> x = np.ma.array([0, 1.], fill_value=-np.inf) >>> x.fill_value -inf >>> x.fill_value = np.pi >>> x.fill_value 3.1415926535897931 # may vary
Reset to default:

>>> x.fill_value = None >>> x.fill_value 1e+20
ma.MaskedArray.baseclass[#](#numpy.ma.MaskedArray.baseclass)
-
Class of the underlying data (read-only).

Share status of the mask (read-only).

ma.MaskedArray.hardmask[#](#numpy.ma.MaskedArray.hardmask)
-
Specifies whether values can be unmasked through assignments.

By default, assigning definite values to masked array entries will unmask them. When

is`hardmask`
`True`
, the mask will not change through assignments.Examples

>>> x = np.arange(10) >>> m = np.ma.masked_array(x, x>5) >>> assert not m.hardmask
Since

*m*has a soft mask, assigning an element value unmasks that element:>>> m[8] = 42 >>> m masked_array(data=[0, 1, 2, 3, 4, 5, --, --, 42, --], mask=[False, False, False, False, False, False, True, True, False, True], fill_value=999999)
After hardening, the mask is not affected by assignments:

>>> hardened = np.ma.harden_mask(m) >>> assert m.hardmask and hardened is m >>> m[:] = 23 >>> m masked_array(data=[23, 23, 23, 23, 23, 23, --, --, 23, --], mask=[False, False, False, False, False, False, True, True, False, True], fill_value=999999)
As [ MaskedArray](#numpy.ma.MaskedArray) is a subclass of

[, a masked array also inherits all the attributes and properties of a](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
[instance.](generated/numpy.ndarray.html#numpy.ndarray)
`ndarray`
Base object if memory is from some other object.

|
An object to simplify the interaction of the array with the ctypes module.

|
Data-type of the array's elements.

|
Information about the memory layout of the array.

|
Length of one array element in bytes.

|
Total bytes consumed by the elements of the array.

|
Number of array dimensions.

|
Tuple of array dimensions.

|
Number of elements in the array.

|
Tuple of bytes to step in each dimension when traversing an array.

|
The imaginary part of the masked array.

|
The real part of the masked array.

|
Return a flat iterator, or set a flattened version of self to value.

|
`MaskedArray`
methods[#](#maskedarray-methods)
`MaskedArray`
See also

## Conversion[#](#conversion)
Convert to float.

|
Convert to int.

|
|
Return a view of the MaskedArray data.

|
|
Copy of the array, cast to a specified type.

|
|
Swap the bytes of the array elements

|
Return all the non-masked data as a 1-D array.

|
|
Return a copy of self, with masked values filled with a given value.

|
|
Save a masked array to a file in binary format.

|
Transforms a masked array into a flexible-type array.

|
|
Return the data portion of the masked array as a hierarchical Python list.

|
Transforms a masked array into a flexible-type array.

|
|
A compatibility alias for

|
|
Return the array data as a string containing the raw bytes in the array.

|
## Shape manipulation[#](#shape-manipulation)
For reshape, resize, and transpose, the single tuple argument may be
replaced with `n`
integers which will be interpreted as an n-tuple.

|
Return a copy of the array collapsed into one dimension.

|
|
Returns a 1D version of self, as a view.

|
|
Give a new shape to the array without changing its data.

|
|
|
Remove axes of length one from

|
|
Return a view of the array with

|
|
Returns a view of the array with axes transposed.

|
View of the transposed array.

|
## Item selection and manipulation[#](#item-selection-and-manipulation)
For array methods that take an `axis`
keyword, it defaults to None.
If axis is None, then the array is treated as a 1-D array.
Any other value for `axis`
represents the dimension along which
the operation should proceed.

|
Returns array of indices of the maximum values along the given axis.

|
|
Return array of indices to the minimum values along the given axis.

|
|
Return an ndarray of indices that sort the array along the specified axis.

|
|
Use an index array to construct a new array from a set of choices.

|
|
Return

|
|
Return specified diagonals.

|
|
Fill the array with a scalar value.

|
|
Copy an element of an array to a standard Python scalar and return it.

|
Return the indices of unmasked elements that are not zero.

|
|
Set storage-indexed locations to corresponding values.

|
|
Repeat elements of an array.

|
|
Find indices where elements of v should be inserted in a to maintain order.

|
|
Sort the array, in-place

|
|
## Pickling and copy[#](#pickling-and-copy)
|
Return a copy of the array.

|
|
Dump a pickle of the array to the specified file.

|
Returns the pickle of the array as a string.

|
## Calculations[#](#calculations)
|
Returns True if all elements evaluate to True.

|
|
Compute the anomalies (deviations from the arithmetic mean) along the given axis.

|
|
Returns True if any of the elements of

|
|
Return an array whose values are limited to

|
Complex-conjugate all elements.

|
Return the complex conjugate, element-wise.

|
|
Return the cumulative product of the array elements over the given axis.

|
|
Return the cumulative sum of the array elements over the given axis.

|
|
Return the maximum along a given axis.

|
|
Returns the average of the array elements along given axis.

|
|
Return the minimum along a given axis.

|
|
Return the product of the array elements over the given axis.

|
|
Return the product of the array elements over the given axis.

|
|
Return (maximum - minimum) along the given dimension (i.e.

|
|
Return each element rounded to the given number of decimals.

|
|
Returns the standard deviation of the array elements along given axis.

|
|
Return the sum of the array elements over the given axis.

|
|
Return the sum along diagonals of the array.

|
|
Compute the variance along the specified axis.

|
## Arithmetic and comparison operations[#](#arithmetic-and-comparison-operations)
### Comparison operators:[#](#comparison-operators)
|
Return self<value.

|
|
Return self<=value.

|
|
Return self>value.

|
|
Return self>=value.

|
|
Check whether other equals self elementwise.

|
|
Check whether other does not equal self elementwise.

|
### Truth value of an array (`bool()`
):[#](#truth-value-of-an-array-bool)
`bool()`
True if self else False

|
### Arithmetic:[#](#arithmetic)
|
|
Add self to other, and return a new masked array.

|
|
Add other to self, and return a new masked array.

|
|
Subtract other from self, and return a new masked array.

|
|
Subtract self from other, and return a new masked array.

|
|
Multiply self by other, and return a new masked array.

|
|
Multiply other by self, and return a new masked array.

|
|
Divide other into self, and return a new masked array.

|
|
Divide other into self, and return a new masked array.

|
|
Divide self into other, and return a new masked array.

|
|
Divide other into self, and return a new masked array.

|
|
Divide self into other, and return a new masked array.

|
|
Return self%value.

|
|
Return value%self.

|
|
Return divmod(self, value).

|
|
Return divmod(value, self).

|
|
Raise self to the power other, masking the potential NaNs/Infs

|
|
Raise other to the power self, masking the potential NaNs/Infs

|
|
Return self<<value.

|
|
Return value<<self.

|
|
Return self>>value.

|
|
Return value>>self.

|
|
Return self&value.

|
|
Return value&self.

|
|
Return self|value.

|
|
Return value|self.

|
|
Return self^value.

|
|
Return value^self.

|
### Arithmetic, in-place:[#](#arithmetic-in-place)
|
Add other to self in-place.

|
|
Subtract other from self in-place.

|
|
Multiply self by other in-place.

|
|
Divide self by other in-place.

|
|
True divide self by other in-place.

|
|
Floor divide self by other in-place.

|
|
Return self%=value.

|
|
Raise self to the power other, in place.

|
|
Return self<<=value.

|
|
Return self>>=value.

|
|
Return self&=value.

|
|
Return self|=value.

|
|
Return self^=value.

|
## Representation[#](#representation)
Literal string representation.

|
Return str(self).

|
Return the addresses of the data and mask areas.

|
Return a boolean indicating whether the data is contiguous.

|
## Special methods[#](#special-methods)
For standard library functions:

Used if

|
|
Used if

|
Return the internal state of the masked array, for pickling purposes.

|
Return a 3-tuple for pickling a MaskedArray.

|
|
Restore the internal state of the masked array, for pickling purposes.

|
Basic customization:

|
Create a new masked array from scratch.

|
|
Returns either a new reference to self if dtype is not given or a new array of provided data type if dtype is different from the current dtype of the array.

|
|
Special hook for ufuncs.

|
Container customization: (see [Indexing](arrays.indexing.html#arrays-indexing))

Return len(self).

|
|
x.__getitem__(y) <==> x[y]

|
|
x.__setitem__(i, y) <==> x[i]=y

|
|
Delete self[key].

|
|
Return key in self.

|
## Specific methods[#](#specific-methods)
### Handling the mask[#](#handling-the-mask)
The following methods can be used to access information about the mask or to manipulate the mask.

|
Set the mask.

|
Force the mask to hard, preventing unmasking by assignment.

|
Force the mask to soft (default), allowing unmasking by assignment.

|
Copy the mask and set the

|
Reduce a mask to nomask when possible.

|
### Handling the *fill_value*[#](#handling-the-fill-value)
The filling value of the masked array is a scalar.

|
|
### Counting the missing elements[#](#counting-the-missing-elements)
|
Count the non-masked elements of the array along the given axis.

|# numpy.polynomial.legendre.legroots[#](#numpy-polynomial-legendre-legroots)
polynomial.legendre.legroots(*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L1459-L1517)[#](#numpy.polynomial.legendre.legroots)
-
Compute the roots of a Legendre series.

Return the roots (a.k.a. “zeros”) of the polynomial

\[p(x) = \sum_i c[i] * L_i(x).\]Parameters:
-
**c**1-D array_like
1-D array of coefficients.

Returns:
-
**out**ndarray
Array of the roots of the series. If all the roots are real, then

*out*is also real, otherwise it is complex.
See also

Notes

The root estimates are obtained as the eigenvalues of the companion matrix, Roots far from the origin of the complex plane may have large errors due to the numerical instability of the series for such values. Roots with multiplicity greater than 1 will also show larger errors as the value of the series near such points is relatively insensitive to errors in the roots. Isolated roots near the origin can be improved by a few iterations of Newton’s method.

The Legendre series basis polynomials aren’t powers of

`x`
so the results of this function may seem unintuitive.Examples

>>> import numpy.polynomial.legendre as leg >>> leg.legroots((1, 2, 3, 4)) # 4L_3 + 3L_2 + 2L_1 + 1L_0, all real roots array([-0.85099543, -0.11407192, 0.51506735]) # may vary# numpy.random.Generator.gamma[#](#numpy-random-generator-gamma)
method

random.Generator.gamma(*shape*,*scale=1.0*,*size=None*)[#](#numpy.random.Generator.gamma)
-
Draw samples from a Gamma distribution.

Samples are drawn from a Gamma distribution with specified parameters,

(sometimes designated “k”) and`shape`
*scale*(sometimes designated “theta”), where both parameters are > 0.Parameters:
-
**shape**float or array_like of floats
The shape of the gamma distribution. Must be non-negative.

**scale**float or array_like of floats, optional
The scale of the gamma distribution. Must be non-negative. Default is equal to 1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`shape`
and`scale`
are both scalars. Otherwise,`np.broadcast(shape, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized gamma distribution.

See also

`scipy.stats.gamma`
probability density function, distribution or cumulative density function, etc.

Notes

The probability density for the Gamma distribution is

\[p(x) = x^{k-1}\frac{e^{-x/\theta}}{\theta^k\Gamma(k)},\]where \(k\) is the shape and \(\theta\) the scale, and \(\Gamma\) is the Gamma function.

The Gamma distribution is often used to model the times to failure of electronic components, and arises naturally in processes for which the waiting times between Poisson distributed events are relevant.

References

[1]Weisstein, Eric W. “Gamma Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/GammaDistribution.html](http://mathworld.wolfram.com/GammaDistribution.html)[2]Wikipedia, “Gamma distribution”,

[https://en.wikipedia.org/wiki/Gamma_distribution](https://en.wikipedia.org/wiki/Gamma_distribution)Examples

Draw samples from the distribution:

>>> shape, scale = 2., 2. # mean=4, std=2*sqrt(2) >>> s = np.random.default_rng().gamma(shape, scale, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> import scipy.special as sps >>> count, bins, ignored = plt.hist(s, 50, density=True) >>> y = bins**(shape-1)*(np.exp(-bins/scale) / ... (sps.gamma(shape)*scale**shape)) >>> plt.plot(bins, y, linewidth=2, color='r') >>> plt.show()# numpy.random.binomial[#](#numpy-random-binomial)
random.binomial(*n*,*p*,*size=None*)[#](#numpy.random.binomial)
-
Draw samples from a binomial distribution.

Samples are drawn from a binomial distribution with specified parameters, n trials and p probability of success where n an integer >= 0 and p is in the interval [0,1]. (n may be input as a float, but it is truncated to an integer in use)

Note

New code should use the

method of a`binomial`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**n**int or array_like of ints
Parameter of the distribution, >= 0. Floats are also accepted, but they will be truncated to integers.

**p**float or array_like of floats
Parameter of the distribution, >= 0 and <=1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`n`
and`p`
are both scalars. Otherwise,`np.broadcast(n, p).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized binomial distribution, where each sample is equal to the number of successes over the n trials.

See also

`scipy.stats.binom`
probability density function, distribution or cumulative density function, etc.

`random.Generator.binomial`
which should be used for new code.

Notes

The probability density for the binomial distribution is

\[P(N) = \binom{n}{N}p^N(1-p)^{n-N},\]where \(n\) is the number of trials, \(p\) is the probability of success, and \(N\) is the number of successes.

When estimating the standard error of a proportion in a population by using a random sample, the normal distribution works well unless the product p*n <=5, where p = population proportion estimate, and n = number of samples, in which case the binomial distribution is used instead. For example, a sample of 15 people shows 4 who are left handed, and 11 who are right handed. Then p = 4/15 = 27%. 0.27*15 = 4, so the binomial distribution should be used in this case.

References

[1]Dalgaard, Peter, “Introductory Statistics with R”, Springer-Verlag, 2002.

[2]Glantz, Stanton A. “Primer of Biostatistics.”, McGraw-Hill, Fifth Edition, 2002.

[3]Lentner, Marvin, “Elementary Applied Statistics”, Bogden and Quigley, 1972.

[4]Weisstein, Eric W. “Binomial Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/BinomialDistribution.html](http://mathworld.wolfram.com/BinomialDistribution.html)[5]Wikipedia, “Binomial distribution”,

[https://en.wikipedia.org/wiki/Binomial_distribution](https://en.wikipedia.org/wiki/Binomial_distribution)Examples

Draw samples from the distribution:

>>> n, p = 10, .5 # number of trials, probability of each trial >>> s = np.random.binomial(n, p, 1000) # result of flipping a coin 10 times, tested 1000 times.
A real world example. A company drills 9 wild-cat oil exploration wells, each with an estimated probability of success of 0.1. All nine wells fail. What is the probability of that happening?

Let’s do 20,000 trials of the model, and count the number that generate zero positive results.

>>> sum(np.random.binomial(9, 0.1, 20000) == 0)/20000. # answer = 0.38885, or 38%.# numpy.random.wald[#](#numpy-random-wald)
random.wald(*mean*,*scale*,*size=None*)[#](#numpy.random.wald)
-
Draw samples from a Wald, or inverse Gaussian, distribution.

As the scale approaches infinity, the distribution becomes more like a Gaussian. Some references claim that the Wald is an inverse Gaussian with mean equal to 1, but this is by no means universal.

The inverse Gaussian distribution was first studied in relationship to Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian because there is an inverse relationship between the time to cover a unit distance and distance covered in unit time.

Note

New code should use the

method of a`wald`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**mean**float or array_like of floats
Distribution mean, must be > 0.

**scale**float or array_like of floats
Scale parameter, must be > 0.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`mean`
and`scale`
are both scalars. Otherwise,`np.broadcast(mean, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Wald distribution.

See also

`random.Generator.wald`
which should be used for new code.

Notes

The probability density function for the Wald distribution is

\[P(x;mean,scale) = \sqrt{\frac{scale}{2\pi x^3}}e^ \frac{-scale(x-mean)^2}{2\cdotp mean^2x}\]As noted above the inverse Gaussian distribution first arise from attempts to model Brownian motion. It is also a competitor to the Weibull for use in reliability modeling and modeling stock returns and interest rate processes.

References

[1]Brighton Webs Ltd., Wald Distribution,

[https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp](https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp)[2]Chhikara, Raj S., and Folks, J. Leroy, “The Inverse Gaussian Distribution: Theory : Methodology, and Applications”, CRC Press, 1988.

[3]Wikipedia, “Inverse Gaussian distribution”

[https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution](https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution)Examples

Draw values from the distribution and plot the histogram:

>>> import matplotlib.pyplot as plt >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True) >>> plt.show()# numpy.polynomial.hermite_e.HermiteE.cutdeg[#](#numpy-polynomial-hermite-e-hermitee-cutdeg)
method

polynomial.hermite_e.HermiteE.cutdeg(*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L710-L733)[#](#numpy.polynomial.hermite_e.HermiteE.cutdeg)
-
Truncate series to the given degree.

Reduce the degree of the series to

*deg*by discarding the high order terms. If*deg*is greater than the current degree a copy of the current series is returned. This can be useful in least squares where the coefficients of the high degree terms may be very small.New in version 1.5.0.

Parameters:
-
**deg**non-negative int
The series is reduced to degree

*deg*by discarding the high order terms. The value of*deg*must be a non-negative integer.
Returns:
-
**new_series**series
New instance of series with reduced degree.A sub-package for efficiently dealing with polynomials.

Within the documentation for this sub-package, a “finite power series,”
i.e., a polynomial (also referred to simply as a “series”) is represented
by a 1-D numpy array of the polynomial’s coefficients, ordered from lowest
order term to highest. For example, array([1,2,3]) represents
`P_0 + 2*P_1 + 3*P_2`
, where P_n is the n-th order basis polynomial
applicable to the specific module in question, e.g., [ polynomial](routines.polynomials.polynomial.html#module-numpy.polynomial.polynomial) (which
“wraps” the “standard” basis) or

[. For optimal performance, all operations on polynomials, including evaluation at an argument, are implemented as operations on the coefficients. Additional (module-specific) information can be found in the docstring for the module of interest.](routines.polynomials.chebyshev.html#module-numpy.polynomial.chebyshev)
`chebyshev`
This package provides *convenience classes* for each of six different kinds
of polynomials:

These *convenience classes* provide a consistent interface for creating,
manipulating, and fitting data with polynomials of different bases.
The convenience classes are the preferred interface for the [ polynomial](#module-numpy.polynomial)
package, and are available from the

`numpy.polynomial`
namespace.
This eliminates the need to navigate to the corresponding submodules, e.g.
`np.polynomial.Polynomial`
or `np.polynomial.Chebyshev`
instead of
`np.polynomial.polynomial.Polynomial`
or
`np.polynomial.chebyshev.Chebyshev`
, respectively.
The classes provide a more consistent and concise interface than the
type-specific functions defined in the submodules for each type of polynomial.
For example, to fit a Chebyshev polynomial with degree `1`
to data given
by arrays `xdata`
and `ydata`
, the
[class method:](generated/numpy.polynomial.chebyshev.Chebyshev.fit.html#numpy.polynomial.chebyshev.Chebyshev.fit)
`fit`
```
>>> from numpy.polynomial import Chebyshev
>>> c = Chebyshev.fit(xdata, ydata, deg=1)
```
is preferred over the [ chebyshev.chebfit](generated/numpy.polynomial.chebyshev.chebfit.html#numpy.polynomial.chebyshev.chebfit) function from the

`np.polynomial.chebyshev`
module:```
>>> from numpy.polynomial.chebyshev import chebfit
>>> c = chebfit(xdata, ydata, deg=1)
```
See [Using the Convenience Classes](routines.polynomials.classes.html) for more details.

# Convenience Classes[#](#convenience-classes)
The following lists the various constants and methods common to all of
the classes representing the various kinds of polynomials. In the following,
the term `Poly`
represents any one of the convenience classes (e.g.
[ Polynomial](generated/numpy.polynomial.polynomial.Polynomial.html#numpy.polynomial.polynomial.Polynomial),

[,](generated/numpy.polynomial.chebyshev.Chebyshev.html#numpy.polynomial.chebyshev.Chebyshev)
`Chebyshev`
[, etc.) while the lowercase](generated/numpy.polynomial.hermite.Hermite.html#numpy.polynomial.hermite.Hermite)
`Hermite`
`p`
represents an **instance**of a polynomial class.
## Constants[#](#constants)
`Poly.domain`
– Default domain
`Poly.window`
– Default window
`Poly.basis_name`
– String used to represent the basis
`Poly.maxpower`
– Maximum value`n`
such that`p**n`
is allowed
`Poly.nickname`
– String used in printing
## Creation[#](#creation)
Methods for creating polynomial instances.

`Poly.basis(degree)`
– Basis polynomial of given degree
`Poly.identity()`
–`p`
where`p(x) = x`
for all`x`
`Poly.fit(x, y, deg)`
–`p`
of degree`deg`
with coefficients determined by the least-squares fit to the data`x`
,`y`
`Poly.fromroots(roots)`
–`p`
with specified roots
`p.copy()`
– Create a copy of`p`
## Conversion[#](#conversion)
Methods for converting a polynomial instance of one kind to another.

`p.cast(Poly)`
– Convert`p`
to instance of kind`Poly`
`p.convert(Poly)`
– Convert`p`
to instance of kind`Poly`
or map between`domain`
and`window`
## Calculus[#](#calculus)
`p.deriv()`
– Take the derivative of`p`
`p.integ()`
– Integrate`p`
## Validation[#](#validation)
`Poly.has_samecoef(p1, p2)`
– Check if coefficients match
`Poly.has_samedomain(p1, p2)`
– Check if domains match
`Poly.has_sametype(p1, p2)`
– Check if types match
`Poly.has_samewindow(p1, p2)`
– Check if windows match
## Misc[#](#misc)
`p.linspace()`
– Return`x, p(x)`
at equally-spaced points in`domain`
`p.mapparms()`
– Return the parameters for the linear mapping between`domain`
and`window`
.
`p.roots()`
– Return the roots of*p*.
`p.trim()`
– Remove trailing coefficients.
`p.cutdeg(degree)`
– Truncate p to given degree
`p.truncate(size)`
– Truncate p to given size
# Configuration[#](#configuration)
Set the default format for the string representation of polynomials.

|# numpy.ma.copy[#](#numpy-ma-copy)
ma.copy(*self*,**args*,***params) a.copy(order='C'*)*= <numpy.ma.core._frommethod object>*[#](#numpy.ma.copy)
-
Return a copy of the array.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout of the copy. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*a*as closely as possible. (Note that this function andare very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)`numpy.copy`
See also

`numpy.copy`
Similar function with different default behavior

`numpy.copyto`
Notes

This function is the preferred method for creating an array copy. The function

is similar, but it defaults to using order ‘K’, and will not pass sub-classes through by default.`numpy.copy`
Examples

>>> x = np.array([[1,2,3],[4,5,6]], order='F')
>>> y = x.copy()
>>> x.fill(0)
>>> x array([[0, 0, 0], [0, 0, 0]])
>>> y array([[1, 2, 3], [4, 5, 6]])
>>> y.flags['C_CONTIGUOUS'] True# numpy.ndarray.reshape[#](#numpy-ndarray-reshape)
method

ndarray.reshape(*shape*,*order='C'*)[#](#numpy.ndarray.reshape)
-
Returns an array containing the same data with a new shape.

Refer to

for full documentation.`numpy.reshape`
See also

`numpy.reshape`
equivalent function

Notes

Unlike the free function

, this method on`numpy.reshape`
allows the elements of the shape parameter to be passed in as separate arguments. For example,`ndarray`
`a.reshape(10, 11)`
is equivalent to`a.reshape((10, 11))`
.# numpy.random.RandomState.normal[#](#numpy-random-randomstate-normal)
method

random.RandomState.normal(*loc=0.0*,*scale=1.0*,*size=None*)[#](#numpy.random.RandomState.normal)
-
Draw random samples from a normal (Gaussian) distribution.

The probability density function of the normal distribution, first derived by De Moivre and 200 years later by both Gauss and Laplace independently

[[2]](#ra2e838c5ea87-2), is often called the bell curve because of its characteristic shape (see the example below).The normal distributions occurs often in nature. For example, it describes the commonly occurring distribution of samples influenced by a large number of tiny, random disturbances, each with its own unique distribution

[[2]](#ra2e838c5ea87-2).Note

New code should use the

method of a`normal`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**loc**float or array_like of floats
Mean (“centre”) of the distribution.

**scale**float or array_like of floats
Standard deviation (spread or “width”) of the distribution. Must be non-negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`loc`
and`scale`
are both scalars. Otherwise,`np.broadcast(loc, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized normal distribution.

See also

`scipy.stats.norm`
probability density function, distribution or cumulative density function, etc.

`random.Generator.normal`
which should be used for new code.

Notes

The probability density for the Gaussian distribution is

\[p(x) = \frac{1}{\sqrt{ 2 \pi \sigma^2 }} e^{ - \frac{ (x - \mu)^2 } {2 \sigma^2} },\]where \(\mu\) is the mean and \(\sigma\) the standard deviation. The square of the standard deviation, \(\sigma^2\), is called the variance.

The function has its peak at the mean, and its “spread” increases with the standard deviation (the function reaches 0.607 times its maximum at \(x + \sigma\) and \(x - \sigma\)

[[2]](#ra2e838c5ea87-2)). This implies that normal is more likely to return samples lying close to the mean, rather than those far away.References

[1]Wikipedia, “Normal distribution”,

[https://en.wikipedia.org/wiki/Normal_distribution](https://en.wikipedia.org/wiki/Normal_distribution)Examples

Draw samples from the distribution:

>>> mu, sigma = 0, 0.1 # mean and standard deviation >>> s = np.random.normal(mu, sigma, 1000)
Verify the mean and the variance:

>>> abs(mu - np.mean(s)) 0.0 # may vary
>>> abs(sigma - np.std(s, ddof=1)) 0.1 # may vary
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 30, density=True) >>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * ... np.exp( - (bins - mu)**2 / (2 * sigma**2) ), ... linewidth=2, color='r') >>> plt.show()
Two-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:

>>> np.random.normal(3, 2.5, size=(2, 4)) array([[-4.49401501, 4.00950034, -1.81814867, 7.29718677], # random [ 0.39924804, 4.68456316, 4.99394529, 4.84057254]]) # random# numpy.seterrobj[#](#numpy-seterrobj)
numpy.seterrobj(*errobj*,*/*)[#](#numpy.seterrobj)
-
Set the object that defines floating-point error handling.

The error object contains all information that defines the error handling behavior in NumPy.

is used internally by the other functions that set error handling behavior (`seterrobj`
,`seterr`
).`seterrcall`
Parameters:
-
**errobj**list
The error object, a list containing three elements: [internal numpy buffer size, error mask, error callback function].

The error mask is a single integer that holds the treatment information on all four floating point errors. The information for each error type is contained in three bits of the integer. If we print it in base 8, we can see what treatment is set for “invalid”, “under”, “over”, and “divide” (in that order). The printed string can be interpreted with

0 : ‘ignore’

1 : ‘warn’

2 : ‘raise’

3 : ‘call’

4 : ‘print’

5 : ‘log’

See also

Notes

For complete documentation of the types of floating-point exceptions and treatment options, see

.`seterr`
Examples

>>> old_errobj = np.geterrobj() # first get the defaults >>> old_errobj [8192, 521, None]
>>> def err_handler(type, flag): ... print("Floating point error (%s), with flag %s" % (type, flag)) ... >>> new_errobj = [20000, 12, err_handler] >>> np.seterrobj(new_errobj) >>> np.base_repr(12, 8) # int for divide=4 ('print') and over=1 ('warn') '14' >>> np.geterr() {'over': 'warn', 'divide': 'print', 'invalid': 'ignore', 'under': 'ignore'} >>> np.geterrcall() is err_handler True# numpy.random.Generator.poisson[#](#numpy-random-generator-poisson)
method

random.Generator.poisson(*lam=1.0*,*size=None*)[#](#numpy.random.Generator.poisson)
-
Draw samples from a Poisson distribution.

The Poisson distribution is the limit of the binomial distribution for large N.

Parameters:
-
**lam**float or array_like of floats
Expected number of events occurring in a fixed-time interval, must be >= 0. A sequence must be broadcastable over the requested size.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`lam`
is a scalar. Otherwise,`np.array(lam).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Poisson distribution.

Notes

The Poisson distribution

\[f(k; \lambda)=\frac{\lambda^k e^{-\lambda}}{k!}\]For events with an expected separation \(\lambda\) the Poisson distribution \(f(k; \lambda)\) describes the probability of \(k\) events occurring within the observed interval \(\lambda\).

Because the output is limited to the range of the C int64 type, a ValueError is raised when

*lam*is within 10 sigma of the maximum representable value.References

[1]Weisstein, Eric W. “Poisson Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/PoissonDistribution.html](http://mathworld.wolfram.com/PoissonDistribution.html)[2]Wikipedia, “Poisson distribution”,

[https://en.wikipedia.org/wiki/Poisson_distribution](https://en.wikipedia.org/wiki/Poisson_distribution)Examples

Draw samples from the distribution:

>>> import numpy as np >>> rng = np.random.default_rng() >>> s = rng.poisson(5, 10000)
Display histogram of the sample:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 14, density=True) >>> plt.show()
Draw each 100 values for lambda 100 and 500:

>>> s = rng.poisson(lam=(100., 500.), size=(100, 2))# numpy.ma.row_stack[#](#numpy-ma-row-stack)
ma.row_stack*= <numpy.ma.extras._fromnxfunction_seq object>*[#](#numpy.ma.row_stack)
-
vstack

Stack arrays in sequence vertically (row wise).

This is equivalent to concatenation along the first axis after 1-D arrays of shape

*(N,)*have been reshaped to*(1,N)*. Rebuilds arrays divided by.`vsplit`
This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions

,`concatenate`
and`stack`
provide more general stacking and concatenation operations.`block`
`np.row_stack`
is an alias for. They are the same function.`vstack`
Parameters:
-
**tup**sequence of ndarrays
The arrays must have the same shape along all but the first axis. 1-D arrays must have the same length.

**dtype**str or dtype
If provided, the destination array will have this dtype. Cannot be provided together with

*out*.
**.. versionadded:: 1.24**
**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘same_kind’.

**.. versionadded:: 1.24**
Returns:
-
**stacked**ndarray
The array formed by stacking the given arrays, will be at least 2-D.

See also

`concatenate`
Join a sequence of arrays along an existing axis.

`stack`
Join a sequence of arrays along a new axis.

`block`
Assemble an nd-array from nested lists of blocks.

`hstack`
Stack arrays in sequence horizontally (column wise).

`dstack`
Stack arrays in sequence depth wise (along third axis).

`column_stack`
Stack 1-D arrays as columns into a 2-D array.

`vsplit`
Split an array into multiple sub-arrays vertically (row-wise).

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> a = np.array([1, 2, 3]) >>> b = np.array([4, 5, 6]) >>> np.vstack((a,b)) array([[1, 2, 3], [4, 5, 6]])
>>> a = np.array([[1], [2], [3]]) >>> b = np.array([[4], [5], [6]]) >>> np.vstack((a,b)) array([[1], [2], [3], [4], [5], [6]])# distutils.misc_util[#](#module-numpy.distutils.misc_util)
numpy.distutils.misc_util.all_strings(*lst*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L490-L495)[#](#numpy.distutils.misc_util.all_strings)
-
Return True if all items in lst are string objects.

numpy.distutils.misc_util.allpath(*name*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L129-L132)[#](#numpy.distutils.misc_util.allpath)
-
Convert a /-separated pathname to one using the OS’s path separator.

numpy.distutils.misc_util.cyg2win32(*path:*)[str](https://docs.python.org/3/library/stdtypes.html#str)[str](https://docs.python.org/3/library/stdtypes.html#str)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L386-L420)[#](#numpy.distutils.misc_util.cyg2win32)
-
Convert a path from Cygwin-native to Windows-native.

Uses the cygpath utility (part of the Base install) to do the actual conversion. Falls back to returning the original path if this fails.

Handles the default

`/cygdrive`
mount prefix as well as the`/proc/cygdrive`
portable prefix, custom cygdrive prefixes such as`/`
or`/mnt`
, and absolute paths such as`/usr/src/`
or`/home/username`
Parameters:
-
**path**str
The path to convert

Returns:
-
**converted_path**str
The converted path

Notes

Documentation for cygpath utility:

[https://cygwin.com/cygwin-ug-net/cygpath.html](https://cygwin.com/cygwin-ug-net/cygpath.html)Documentation for the C function it wraps:[https://cygwin.com/cygwin-api/func-cygwin-conv-path.html](https://cygwin.com/cygwin-api/func-cygwin-conv-path.html)
numpy.distutils.misc_util.default_config_dict(*name=None*,*parent_name=None*,*local_path=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2282-L2293)[#](#numpy.distutils.misc_util.default_config_dict)
-
Return a configuration dictionary for usage in configuration() function defined in file setup_<name>.py.

numpy.distutils.misc_util.exec_mod_from_location(*modname*,*modfile*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2484-L2493)[#](#numpy.distutils.misc_util.exec_mod_from_location)
-
Use importlib machinery to import a module

*modname*from the file*modfile*. Depending on the*spec.loader*, the module may not be registered in sys.modules.
numpy.distutils.misc_util.filter_sources(*sources*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L542-L562)[#](#numpy.distutils.misc_util.filter_sources)
-
Return four lists of filenames containing C, C++, Fortran, and Fortran 90 module sources, respectively.

numpy.distutils.misc_util.generate_config_py(*target*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2328-L2457)[#](#numpy.distutils.misc_util.generate_config_py)
-
Generate config.py file containing system_info information used during building the package.

Usage:
-
config[‘py_modules’].append((packagename, ‘__config__’,generate_config_py))

numpy.distutils.misc_util.get_frame(*level=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L745-L754)[#](#numpy.distutils.misc_util.get_frame)
-
Return frame object from call stack with given level.

numpy.distutils.misc_util.get_info(*pkgname*,*dirs=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2210-L2268)[#](#numpy.distutils.misc_util.get_info)
-
Return an info dict for a given C library.

The info dict contains the necessary options to use the C library.

Parameters:
-
**pkgname**str
Name of the package (should match the name of the .ini file, without the extension, e.g. foo for the file foo.ini).

**dirs**sequence, optional
If given, should be a sequence of additional directories where to look for npy-pkg-config files. Those directories are searched prior to the NumPy directory.

Returns:
-
**info**dict
The dictionary with build information.

Raises:
-
PkgNotFound
-
If the package is not found.

Examples

To get the necessary information for the npymath library from NumPy:

>>> npymath_info = np.distutils.misc_util.get_info('npymath') >>> npymath_info {'define_macros': [], 'libraries': ['npymath'], 'library_dirs': ['.../numpy/core/lib'], 'include_dirs': ['.../numpy/core/include']}
This info dict can then be used as input to a

instance:`Configuration`
config.add_extension('foo', sources=['foo.c'], extra_info=npymath_info)
numpy.distutils.misc_util.get_language(*sources*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L515-L526)[#](#numpy.distutils.misc_util.get_language)
-
Determine language value (c,f77,f90) from sources

numpy.distutils.misc_util.get_mathlibs(*path=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L205-L230)[#](#numpy.distutils.misc_util.get_mathlibs)
-
Return the MATHLIB line from numpyconfig.h

numpy.distutils.misc_util.get_num_build_jobs()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L76-L110)[#](#numpy.distutils.misc_util.get_num_build_jobs)
-
Get number of parallel build jobs set by the –parallel command line argument of setup.py If the command did not receive a setting the environment variable NPY_NUM_BUILD_JOBS is checked. If that is unset, return the number of processors on the system, with a maximum of 8 (to prevent overloading the system if there a lot of CPUs).

Returns:
-
**out**int
number of parallel jobs that can be run

numpy.distutils.misc_util.get_pkg_info(*pkgname*,*dirs=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2172-L2208)[#](#numpy.distutils.misc_util.get_pkg_info)
-
Return library info for the given package.

Parameters:
-
**pkgname**str
Name of the package (should match the name of the .ini file, without the extension, e.g. foo for the file foo.ini).

**dirs**sequence, optional
If given, should be a sequence of additional directories where to look for npy-pkg-config files. Those directories are searched prior to the NumPy directory.

Returns:
-
**pkginfo**class instance
The

*LibraryInfo*instance containing the build information.
Raises:
-
PkgNotFound
-
If the package is not found.

numpy.distutils.misc_util.gpaths(*paths*,*local_path=''*,*include_non_existing=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L303-L308)[#](#numpy.distutils.misc_util.gpaths)
-
Apply glob to paths and prepend local_path if needed.

numpy.distutils.misc_util.has_cxx_sources(*sources*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L535-L540)[#](#numpy.distutils.misc_util.has_cxx_sources)
-
Return True if sources contains C++ files

numpy.distutils.misc_util.has_f_sources(*sources*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L528-L533)[#](#numpy.distutils.misc_util.has_f_sources)
-
Return True if sources contains Fortran files

numpy.distutils.misc_util.is_local_src_dir(*directory*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L598-L611)[#](#numpy.distutils.misc_util.is_local_src_dir)
-
Return true if directory is local directory.

numpy.distutils.misc_util.njoin(**path*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L178-L203)[#](#numpy.distutils.misc_util.njoin)
-
Join two or more pathname components + - convert a /-separated pathname to one using the OS’s path separator. - resolve and from path.

Either passing n arguments as in njoin(‘a’,’b’), or a sequence of n names as in njoin([‘a’,’b’]) is handled, or a mixture of such arguments.

numpy.distutils.misc_util.sanitize_cxx_flags(*cxxflags*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/misc_util.py#L2477-L2481)[#](#numpy.distutils.misc_util.sanitize_cxx_flags)
-
Some flags are valid for C but not C++. Prune them.# numpy.random.rayleigh[#](#numpy-random-rayleigh)
random.rayleigh(*scale=1.0*,*size=None*)[#](#numpy.random.rayleigh)
-
Draw samples from a Rayleigh distribution.

The \(\chi\) and Weibull distributions are generalizations of the Rayleigh.

Note

New code should use the

method of a`rayleigh`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**scale**float or array_like of floats, optional
Scale, also equals the mode. Must be non-negative. Default is 1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`scale`
is a scalar. Otherwise,`np.array(scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Rayleigh distribution.

See also

`random.Generator.rayleigh`
which should be used for new code.

Notes

The probability density function for the Rayleigh distribution is

\[P(x;scale) = \frac{x}{scale^2}e^{\frac{-x^2}{2 \cdotp scale^2}}\]The Rayleigh distribution would arise, for example, if the East and North components of the wind velocity had identical zero-mean Gaussian distributions. Then the wind speed would have a Rayleigh distribution.

References

[1]Brighton Webs Ltd., “Rayleigh Distribution,”

[https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp](https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp)[2]Wikipedia, “Rayleigh distribution”

[https://en.wikipedia.org/wiki/Rayleigh_distribution](https://en.wikipedia.org/wiki/Rayleigh_distribution)Examples

Draw values from the distribution and plot the histogram

>>> from matplotlib.pyplot import hist >>> values = hist(np.random.rayleigh(3, 100000), bins=200, density=True)
Wave heights tend to follow a Rayleigh distribution. If the mean wave height is 1 meter, what fraction of waves are likely to be larger than 3 meters?

>>> meanvalue = 1 >>> modevalue = np.sqrt(2 / np.pi) * meanvalue >>> s = np.random.rayleigh(modevalue, 1000000)
The percentage of waves larger than 3 meters is:

>>> 100.*sum(s>3)/1000000. 0.087300000000000003 # random# numpy.random.RandomState.gamma[#](#numpy-random-randomstate-gamma)
method

random.RandomState.gamma(*shape*,*scale=1.0*,*size=None*)[#](#numpy.random.RandomState.gamma)
-
Draw samples from a Gamma distribution.

Samples are drawn from a Gamma distribution with specified parameters,

(sometimes designated “k”) and`shape`
*scale*(sometimes designated “theta”), where both parameters are > 0.Note

New code should use the

method of a`gamma`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**shape**float or array_like of floats
The shape of the gamma distribution. Must be non-negative.

**scale**float or array_like of floats, optional
The scale of the gamma distribution. Must be non-negative. Default is equal to 1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`shape`
and`scale`
are both scalars. Otherwise,`np.broadcast(shape, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized gamma distribution.

See also

`scipy.stats.gamma`
probability density function, distribution or cumulative density function, etc.

`random.Generator.gamma`
which should be used for new code.

Notes

The probability density for the Gamma distribution is

\[p(x) = x^{k-1}\frac{e^{-x/\theta}}{\theta^k\Gamma(k)},\]where \(k\) is the shape and \(\theta\) the scale, and \(\Gamma\) is the Gamma function.

The Gamma distribution is often used to model the times to failure of electronic components, and arises naturally in processes for which the waiting times between Poisson distributed events are relevant.

References

[1]Weisstein, Eric W. “Gamma Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/GammaDistribution.html](http://mathworld.wolfram.com/GammaDistribution.html)[2]Wikipedia, “Gamma distribution”,

[https://en.wikipedia.org/wiki/Gamma_distribution](https://en.wikipedia.org/wiki/Gamma_distribution)Examples

Draw samples from the distribution:

>>> shape, scale = 2., 2. # mean=4, std=2*sqrt(2) >>> s = np.random.gamma(shape, scale, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> import scipy.special as sps >>> count, bins, ignored = plt.hist(s, 50, density=True) >>> y = bins**(shape-1)*(np.exp(-bins/scale) / ... (sps.gamma(shape)*scale**shape)) >>> plt.plot(bins, y, linewidth=2, color='r') >>> plt.show()# numpy.polynomial.hermite_e.hermevander2d[#](#numpy-polynomial-hermite-e-hermevander2d)
polynomial.hermite_e.hermevander2d(*x*,*y*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L1159-L1209)[#](#numpy.polynomial.hermite_e.hermevander2d)
-
Pseudo-Vandermonde matrix of given degrees.

Returns the pseudo-Vandermonde matrix of degrees

*deg*and sample points*(x, y)*. The pseudo-Vandermonde matrix is defined by\[V[..., (deg[1] + 1)*i + j] = He_i(x) * He_j(y),\]where

*0 <= i <= deg[0]*and*0 <= j <= deg[1]*. The leading indices of*V*index the points*(x, y)*and the last index encodes the degrees of the HermiteE polynomials.If

`V = hermevander2d(x, y, [xdeg, ydeg])`
, then the columns of*V*correspond to the elements of a 2-D coefficient array*c*of shape (xdeg + 1, ydeg + 1) in the order\[c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...\]and

`np.dot(V, c.flat)`
and`hermeval2d(x, y, c)`
will be the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of 2-D HermiteE series of the same degrees and sample points.Parameters:
-
**x, y**array_like
Arrays of point coordinates, all of the same shape. The dtypes will be converted to either float64 or complex128 depending on whether any of the elements are complex. Scalars are converted to 1-D arrays.

**deg**list of ints
List of maximum degrees of the form [x_deg, y_deg].

Returns:
-
**vander2d**ndarray
The shape of the returned matrix is

`x.shape + (order,)`
, where \(order = (deg[0]+1)*(deg[1]+1)\). The dtype will be the same as the converted*x*and*y*.
See also

Notes

New in version 1.7.0.# numpy.isnat[#](#numpy-isnat)
numpy.isnat(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'isnat'>*[#](#numpy.isnat)
-
Test element-wise for NaT (not a time) and return result as a boolean array.

New in version 1.13.0.

Parameters:
-
**x**array_like
Input array with datetime or timedelta data type.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray or bool
True where

`x`
is NaT, false otherwise. This is a scalar if*x*is a scalar.
Examples

>>> np.isnat(np.datetime64("NaT")) True >>> np.isnat(np.datetime64("2016-01-01")) False >>> np.isnat(np.array(["NaT", "2016-01-01"], dtype="datetime64[ns]")) array([ True, False])# numpy.char.expandtabs[#](#numpy-char-expandtabs)
char.expandtabs(*a*,*tabsize=8*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L706-L739)[#](#numpy.char.expandtabs)
-
Return a copy of each string element where all tab characters are replaced by one or more spaces.

Calls

*str.expandtabs*element-wise.Return a copy of each string element where all tab characters are replaced by one or more spaces, depending on the current column and the given

*tabsize*. The column number is reset to zero after each newline occurring in the string. This doesn’t understand other non-printing characters or escape sequences.Parameters:
-
**a**array_like of str or unicode
Input array

**tabsize**int, optional
Replace tabs with

*tabsize*number of spaces. If not given defaults to 8 spaces.
Returns:
-
**out**ndarray
Output array of str or unicode, depending on input type

See also# numpy.polynomial.chebyshev.Chebyshev.linspace[#](#numpy-polynomial-chebyshev-chebyshev-linspace)
method

polynomial.chebyshev.Chebyshev.linspace(*n=100*,*domain=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L923-L953)[#](#numpy.polynomial.chebyshev.Chebyshev.linspace)
-
Return x, y values at equally spaced points in domain.

Returns the x, y values at

*n*linearly spaced points across the domain. Here y is the value of the polynomial at the points x. By default the domain is the same as that of the series instance. This method is intended mostly as a plotting aid.New in version 1.5.0.

Parameters:
-
**n**int, optional
Number of point pairs to return. The default value is 100.

**domain**{None, array_like}, optional
If not None, the specified domain is used instead of that of the calling instance. It should be of the form

`[beg,end]`
. The default is None which case the class domain is used.
Returns:
-
**x, y**ndarray
x is equal to linspace(self.domain[0], self.domain[1], n) and y is the series evaluated at element of x.# numpy.random.multinomial[#](#numpy-random-multinomial)
random.multinomial(*n*,*pvals*,*size=None*)[#](#numpy.random.multinomial)
-
Draw samples from a multinomial distribution.

The multinomial distribution is a multivariate generalization of the binomial distribution. Take an experiment with one of

`p`
possible outcomes. An example of such an experiment is throwing a dice, where the outcome can be 1 through 6. Each sample drawn from the distribution represents*n*such experiments. Its values,`X_i = [X_0, X_1, ..., X_p]`
, represent the number of times the outcome was`i`
.Note

New code should use the

method of a`multinomial`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**n**int
Number of experiments.

**pvals**sequence of floats, length p
Probabilities of each of the

`p`
different outcomes. These must sum to 1 (however, the last element is always assumed to account for the remaining probability, as long as`sum(pvals[:-1]) <= 1)`
.
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**out**ndarray
The drawn samples, of shape

*size*, if that was provided. If not, the shape is`(N,)`
.In other words, each entry

`out[i,j,...,:]`
is an N-dimensional value drawn from the distribution.
See also

`random.Generator.multinomial`
which should be used for new code.

Examples

Throw a dice 20 times:

>>> np.random.multinomial(20, [1/6.]*6, size=1) array([[4, 1, 7, 5, 2, 1]]) # random
It landed 4 times on 1, once on 2, etc.

Now, throw the dice 20 times, and 20 times again:

>>> np.random.multinomial(20, [1/6.]*6, size=2) array([[3, 4, 3, 3, 4, 3], # random [2, 4, 3, 4, 0, 7]])
For the first run, we threw 3 times 1, 4 times 2, etc. For the second, we threw 2 times 1, 4 times 2, etc.

A loaded die is more likely to land on number 6:

>>> np.random.multinomial(100, [1/7.]*5 + [2/7.]) array([11, 16, 14, 17, 16, 26]) # random
The probability inputs should be normalized. As an implementation detail, the value of the last entry is ignored and assumed to take up any leftover probability mass, but this should not be relied on. A biased coin which has twice as much weight on one side as on the other should be sampled like so:

>>> np.random.multinomial(100, [1.0 / 3, 2.0 / 3]) # RIGHT array([38, 62]) # random
not like:

>>> np.random.multinomial(100, [1.0, 2.0]) # WRONG Traceback (most recent call last): ValueError: pvals < 0, pvals > 1 or pvals contains NaNs# numpy.polynomial.polynomial.Polynomial.integ[#](#numpy-polynomial-polynomial-polynomial-integ)
method

polynomial.polynomial.Polynomial.integ(*m=1*,*k=[]*,*lbnd=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L853-L884)[#](#numpy.polynomial.polynomial.Polynomial.integ)
-
Integrate.

Return a series instance that is the definite integral of the current series.

Parameters:
-
**m**non-negative int
The number of integrations to perform.

**k**array_like
Integration constants. The first constant is applied to the first integration, the second to the second, and so on. The list of values must less than or equal to

*m*in length and any missing values are set to zero.
**lbnd**Scalar
The lower bound of the definite integral.

Returns:
-
**new_series**series
A new series representing the integral. The domain is the same as the domain of the integrated series.# numpy.random.laplace[#](#numpy-random-laplace)
random.laplace(*loc=0.0*,*scale=1.0*,*size=None*)[#](#numpy.random.laplace)
-
Draw samples from the Laplace or double exponential distribution with specified location (or mean) and scale (decay).

The Laplace distribution is similar to the Gaussian/normal distribution, but is sharper at the peak and has fatter tails. It represents the difference between two independent, identically distributed exponential random variables.

Note

New code should use the

method of a`laplace`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**loc**float or array_like of floats, optional
The position, \(\mu\), of the distribution peak. Default is 0.

**scale**float or array_like of floats, optional
\(\lambda\), the exponential decay. Default is 1. Must be non- negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`loc`
and`scale`
are both scalars. Otherwise,`np.broadcast(loc, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Laplace distribution.

See also

`random.Generator.laplace`
which should be used for new code.

Notes

It has the probability density function

\[f(x; \mu, \lambda) = \frac{1}{2\lambda} \exp\left(-\frac{|x - \mu|}{\lambda}\right).\]The first law of Laplace, from 1774, states that the frequency of an error can be expressed as an exponential function of the absolute magnitude of the error, which leads to the Laplace distribution. For many problems in economics and health sciences, this distribution seems to model the data better than the standard Gaussian distribution.

References

[1]Abramowitz, M. and Stegun, I. A. (Eds.). “Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables, 9th printing,” New York: Dover, 1972.

[2]Kotz, Samuel, et. al. “The Laplace Distribution and Generalizations, “ Birkhauser, 2001.

[3]Weisstein, Eric W. “Laplace Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/LaplaceDistribution.html](http://mathworld.wolfram.com/LaplaceDistribution.html)[4]Wikipedia, “Laplace distribution”,

[https://en.wikipedia.org/wiki/Laplace_distribution](https://en.wikipedia.org/wiki/Laplace_distribution)Examples

Draw samples from the distribution

>>> loc, scale = 0., 1. >>> s = np.random.laplace(loc, scale, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 30, density=True) >>> x = np.arange(-8., 8., .01) >>> pdf = np.exp(-abs(x-loc)/scale)/(2.*scale) >>> plt.plot(x, pdf)
Plot Gaussian for comparison:

>>> g = (1/(scale * np.sqrt(2 * np.pi)) * ... np.exp(-(x - loc)**2 / (2 * scale**2))) >>> plt.plot(x,g)# numpy.char.chararray.strides[#](#numpy-char-chararray-strides)
attribute

char.chararray.strides[#](#numpy.char.chararray.strides)
-
Tuple of bytes to step in each dimension when traversing an array.

The byte offset of element

`(i[0], i[1], ..., i[n])`
in an array*a*is:offset = sum(np.array(i) * a.strides)
A more detailed explanation of strides can be found in the “ndarray.rst” file in the NumPy reference guide.

Warning

Setting

`arr.strides`
is discouraged and may be deprecated in the future.should be preferred to create a new view of the same data in a safer way.`numpy.lib.stride_tricks.as_strided`
See also

Notes

Imagine an array of 32-bit integers (each 4 bytes):

x = np.array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], dtype=np.int32)
This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array

*x*will be`(20, 4)`
.Examples

>>> y = np.reshape(np.arange(2*3*4), (2,3,4)) >>> y array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) >>> y.strides (48, 16, 4) >>> y[1,1,1] 17 >>> offset=sum(y.strides * np.array((1,1,1))) >>> offset/y.itemsize 17
>>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0) >>> x.strides (32, 4, 224, 1344) >>> i = np.array([3,5,2,2]) >>> offset = sum(i * x.strides) >>> x[3,5,2,2] 813 >>> offset / x.itemsize 813# numpy.ndarray.itemset[#](#numpy-ndarray-itemset)
method

ndarray.itemset(**args*)[#](#numpy.ndarray.itemset)
-
Insert scalar into an array (scalar is cast to array’s dtype, if possible)

There must be at least 1 argument, and define the last argument as

*item*. Then,`a.itemset(*args)`
is equivalent to but faster than`a[args] = item`
. The item should be a scalar value and*args*must select a single item in the array*a*.Parameters:
-
***args**Arguments
If one argument: a scalar, only used in case

*a*is of size 1. If two arguments: the last argument is the value to be set and must be a scalar, the first argument specifies a single array element location. It is either an int or a tuple.
Notes

Compared to indexing syntax,

provides some speed increase for placing a scalar into a particular location in an`itemset`
, if you must do this. However, generally this is discouraged: among other problems, it complicates the appearance of the code. Also, when using`ndarray`
(and`itemset`
) inside a loop, be sure to assign the methods to a local variable to avoid the attribute look-up at each loop iteration.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.itemset(4, 0) >>> x.itemset((2, 2), 9) >>> x array([[2, 2, 6], [1, 0, 6], [1, 0, 9]])# numpy.memmap.partition[#](#numpy-memmap-partition)
method

memmap.partition(*kth*,*axis=-1*,*kind='introselect'*,*order=None*)[#](#numpy.memmap.partition)
-
Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array. All elements smaller than the kth element are moved before this element and all equal or greater are moved behind it. The ordering of the elements in the two partitions is undefined.

New in version 1.8.0.

Parameters:
-
**kth**int or sequence of ints
Element index to partition by. The kth element value will be in its final sorted position and all smaller elements will be moved before it and all equal or greater elements behind it. The order of all elements in the partitions is undefined. If provided with a sequence of kth it will partition all elements indexed by kth of them into their sorted position at once.

Deprecated since version 1.22.0: Passing booleans as index is deprecated.

**axis**int, optional
Axis along which to sort. Default is -1, which means sort along the last axis.

**kind**{‘introselect’}, optional
Selection algorithm. Default is ‘introselect’.

**order**str or list of str, optional
When

*a*is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need to be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.
See also

`numpy.partition`
Return a partitioned copy of an array.

`argpartition`
Indirect partition.

`sort`
Full sort.

Notes

See

`np.partition`
for notes on the different algorithms.Examples

>>> a = np.array([3, 4, 2, 1]) >>> a.partition(3) >>> a array([2, 1, 3, 4])
>>> a.partition((1, 3)) >>> a array([1, 2, 3, 4])# numpy.random.RandomState.choice[#](#numpy-random-randomstate-choice)
method

random.RandomState.choice(*a*,*size=None*,*replace=True*,*p=None*)[#](#numpy.random.RandomState.choice)
-
Generates a random sample from a given 1-D array

New in version 1.7.0.

Note

New code should use the

method of a`choice`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**a**1-D array-like or int
If an ndarray, a random sample is generated from its elements. If an int, the random sample is generated as if it were

`np.arange(a)`
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
**replace**boolean, optional
Whether the sample is with or without replacement. Default is True, meaning that a value of

`a`
can be selected multiple times.
**p**1-D array-like, optional
The probabilities associated with each entry in a. If not given, the sample assumes a uniform distribution over all entries in

`a`
.
Returns:
-
**samples**single item or ndarray
The generated random samples

Raises:
-
ValueError
-
If a is an int and less than zero, if a or p are not 1-dimensional, if a is an array-like of size 0, if p is not a vector of probabilities, if a and p have different lengths, or if replace=False and the sample size is greater than the population size

See also

,`randint`
,`shuffle`
`permutation`
`random.Generator.choice`
which should be used in new code

Notes

Setting user-specified probabilities through

`p`
uses a more general but less efficient sampler than the default. The general sampler produces a different sample than the optimized sampler even if each element of`p`
is 1 / len(a).Sampling random rows from a 2-D array is not possible with this function, but is possible with

*Generator.choice*through its`axis`
keyword.Examples

Generate a uniform random sample from np.arange(5) of size 3:

>>> np.random.choice(5, 3) array([0, 3, 4]) # random >>> #This is equivalent to np.random.randint(0,5,3)
Generate a non-uniform random sample from np.arange(5) of size 3:

>>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0]) array([3, 3, 0]) # random
Generate a uniform random sample from np.arange(5) of size 3 without replacement:

>>> np.random.choice(5, 3, replace=False) array([3,1,0]) # random >>> #This is equivalent to np.random.permutation(np.arange(5))[:3]
Generate a non-uniform random sample from np.arange(5) of size 3 without replacement:

>>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0]) array([2, 3, 0]) # random
Any of the above can be repeated with an arbitrary array-like instead of just integers. For instance:

>>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher'] >>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3]) array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random dtype='<U11')# numpy.memmap.astype[#](#numpy-memmap-astype)
method

memmap.astype(*dtype*,*order='K'*,*casting='unsafe'*,*subok=True*,*copy=True*)[#](#numpy.memmap.astype)
-
Copy of the array, cast to a specified type.

Parameters:
-
**dtype**str or dtype
Typecode or data-type to which the array is cast.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout order of the result. ‘C’ means C order, ‘F’ means Fortran order, ‘A’ means ‘F’ order if all the arrays are Fortran contiguous, ‘C’ order otherwise, and ‘K’ means as close to the order the array elements appear in memory as possible. Default is ‘K’.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘unsafe’ for backwards compatibility.

‘no’ means the data types should not be cast at all.

‘equiv’ means only byte-order changes are allowed.

‘safe’ means only casts which can preserve values are allowed.

‘same_kind’ means only safe casts or casts within a kind, like float64 to float32, are allowed.

‘unsafe’ means any data conversions may be done.

**subok**bool, optional
If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.

**copy**bool, optional
By default, astype always returns a newly allocated array. If this is set to false, and the

,`dtype`
*order*, and*subok*requirements are satisfied, the input array is returned instead of a copy.
Returns:
-
Raises:
-
ComplexWarning
-
When casting from complex to float or int. To avoid this, one should use

`a.real.astype(t)`
.
Notes

Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for “unsafe” casting. Casting to multiple fields is allowed, but casting from multiple fields is not.

Changed in version 1.9.0: Casting from numeric to string types in ‘safe’ casting mode requires that the string dtype length is long enough to store the max integer/float value converted.

Examples

>>> x = np.array([1, 2, 2.5]) >>> x array([1. , 2. , 2.5])
>>> x.astype(int) array([1, 2, 2])# numpy.random.Generator.multivariate_normal[#](#numpy-random-generator-multivariate-normal)
method

random.Generator.multivariate_normal(*mean*,*cov*,*size=None*,*check_valid='warn'*,*tol=1e-8*,***,*method='svd'*)[#](#numpy.random.Generator.multivariate_normal)
-
Draw random samples from a multivariate normal distribution.

The multivariate normal, multinormal or Gaussian distribution is a generalization of the one-dimensional normal distribution to higher dimensions. Such a distribution is specified by its mean and covariance matrix. These parameters are analogous to the mean (average or “center”) and variance (the squared standard deviation, or “width”) of the one-dimensional normal distribution.

Parameters:
-
**mean**1-D array_like, of length N
Mean of the N-dimensional distribution.

**cov**2-D array_like, of shape (N, N)
Covariance matrix of the distribution. It must be symmetric and positive-semidefinite for proper sampling.

**size**int or tuple of ints, optional
Given a shape of, for example,

`(m,n,k)`
,`m*n*k`
samples are generated, and packed in an*m*-by-*n*-by-*k*arrangement. Because each sample is*N*-dimensional, the output shape is`(m,n,k,N)`
. If no shape is specified, a single (*N*-D) sample is returned.
**check_valid**{ ‘warn’, ‘raise’, ‘ignore’ }, optional
Behavior when the covariance matrix is not positive semidefinite.

**tol**float, optional
Tolerance when checking the singular values in covariance matrix. cov is cast to double before the check.

**method**{ ‘svd’, ‘eigh’, ‘cholesky’}, optional
The cov input is used to compute a factor matrix A such that

`A @ A.T = cov`
. This argument is used to select the method used to compute the factor matrix A. The default method ‘svd’ is the slowest, while ‘cholesky’ is the fastest but less robust than the slowest method. The method*eigh*uses eigen decomposition to compute A and is faster than svd but slower than cholesky.New in version 1.18.0.

Returns:
-
**out**ndarray
The drawn samples, of shape

*size*, if that was provided. If not, the shape is`(N,)`
.In other words, each entry

`out[i,j,...,:]`
is an N-dimensional value drawn from the distribution.
Notes

The mean is a coordinate in N-dimensional space, which represents the location where samples are most likely to be generated. This is analogous to the peak of the bell curve for the one-dimensional or univariate normal distribution.

Covariance indicates the level to which two variables vary together. From the multivariate normal distribution, we draw N-dimensional samples, \(X = [x_1, x_2, ... x_N]\). The covariance matrix element \(C_{ij}\) is the covariance of \(x_i\) and \(x_j\). The element \(C_{ii}\) is the variance of \(x_i\) (i.e. its “spread”).

Instead of specifying the full covariance matrix, popular approximations include:

This geometrical property can be seen in two dimensions by plotting generated data-points:

>>> mean = [0, 0] >>> cov = [[1, 0], [0, 100]] # diagonal covariance
Diagonal covariance means that points are oriented along x or y-axis:

>>> import matplotlib.pyplot as plt >>> x, y = np.random.default_rng().multivariate_normal(mean, cov, 5000).T >>> plt.plot(x, y, 'x') >>> plt.axis('equal') >>> plt.show()
Note that the covariance matrix must be positive semidefinite (a.k.a. nonnegative-definite). Otherwise, the behavior of this method is undefined and backwards compatibility is not guaranteed.

This function internally uses linear algebra routines, and thus results may not be identical (even up to precision) across architectures, OSes, or even builds. For example, this is likely if

`cov`
has multiple equal singular values and`method`
is`'svd'`
(default). In this case,`method='cholesky'`
may be more robust.References

[1]Papoulis, A., “Probability, Random Variables, and Stochastic Processes,” 3rd ed., New York: McGraw-Hill, 1991.

[2]Duda, R. O., Hart, P. E., and Stork, D. G., “Pattern Classification,” 2nd ed., New York: Wiley, 2001.

Examples

>>> mean = (1, 2) >>> cov = [[1, 0], [0, 1]] >>> rng = np.random.default_rng() >>> x = rng.multivariate_normal(mean, cov, (3, 3)) >>> x.shape (3, 3, 2)
We can use a different method other than the default to factorize cov:

>>> y = rng.multivariate_normal(mean, cov, (3, 3), method='cholesky') >>> y.shape (3, 3, 2)
Here we generate 800 samples from the bivariate normal distribution with mean [0, 0] and covariance matrix [[6, -3], [-3, 3.5]]. The expected variances of the first and second components of the sample are 6 and 3.5, respectively, and the expected correlation coefficient is -3/sqrt(6*3.5) ≈ -0.65465.

>>> cov = np.array([[6, -3], [-3, 3.5]]) >>> pts = rng.multivariate_normal([0, 0], cov, size=800)
Check that the mean, covariance, and correlation coefficient of the sample are close to the expected values:

>>> pts.mean(axis=0) array([ 0.0326911 , -0.01280782]) # may vary >>> np.cov(pts.T) array([[ 5.96202397, -2.85602287], [-2.85602287, 3.47613949]]) # may vary >>> np.corrcoef(pts.T)[0, 1] -0.6273591314603949 # may vary
We can visualize this data with a scatter plot. The orientation of the point cloud illustrates the negative correlation of the components of this sample.

>>> import matplotlib.pyplot as plt >>> plt.plot(pts[:, 0], pts[:, 1], '.', alpha=0.5) >>> plt.axis('equal') >>> plt.grid() >>> plt.show()# numpy.polynomial.hermite_e.HermiteE.linspace[#](#numpy-polynomial-hermite-e-hermitee-linspace)
method

polynomial.hermite_e.HermiteE.linspace(*n=100*,*domain=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L923-L953)[#](#numpy.polynomial.hermite_e.HermiteE.linspace)
-
Return x, y values at equally spaced points in domain.

Returns the x, y values at

*n*linearly spaced points across the domain. Here y is the value of the polynomial at the points x. By default the domain is the same as that of the series instance. This method is intended mostly as a plotting aid.New in version 1.5.0.

Parameters:
-
**n**int, optional
Number of point pairs to return. The default value is 100.

**domain**{None, array_like}, optional
If not None, the specified domain is used instead of that of the calling instance. It should be of the form

`[beg,end]`
. The default is None which case the class domain is used.
Returns:
-
**x, y**ndarray
x is equal to linspace(self.domain[0], self.domain[1], n) and y is the series evaluated at element of x.# numpy.ma.apply_over_axes[#](#numpy-ma-apply-over-axes)
ma.apply_over_axes(*func*,*a*,*axes*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L453-L475)[#](#numpy.ma.apply_over_axes)
-
Apply a function repeatedly over multiple axes.

*func*is called as*res = func(a, axis)*, where*axis*is the first element of*axes*. The result*res*of the function call must have either the same dimensions as*a*or one less dimension. If*res*has one less dimension than*a*, a dimension is inserted before*axis*. The call to*func*is then repeated for each axis in*axes*, with*res*as the first argument.Parameters:
-
**func**function
This function must take two arguments,

*func(a, axis)*.
**a**array_like
Input array.

**axes**array_like
Axes over which

*func*is applied; the elements must be integers.
Returns:
-
**apply_over_axis**ndarray
The output array. The number of dimensions is the same as

*a*, but the shape can be different. This depends on whether*func*changes the shape of its output with respect to its input.
See also

`apply_along_axis`
Apply a function to 1-D slices of an array along the given axis.

Examples

>>> a = np.ma.arange(24).reshape(2,3,4) >>> a[:,0,1] = np.ma.masked >>> a[:,1,:] = np.ma.masked >>> a masked_array( data=[[[0, --, 2, 3], [--, --, --, --], [8, 9, 10, 11]], [[12, --, 14, 15], [--, --, --, --], [20, 21, 22, 23]]], mask=[[[False, True, False, False], [ True, True, True, True], [False, False, False, False]], [[False, True, False, False], [ True, True, True, True], [False, False, False, False]]], fill_value=999999) >>> np.ma.apply_over_axes(np.ma.sum, a, [0,2]) masked_array( data=[[[46], [--], [124]]], mask=[[[False], [ True], [False]]], fill_value=999999)
Tuple axis arguments to ufuncs are equivalent:

>>> np.ma.sum(a, axis=(0,2)).reshape((1,-1,1)) masked_array( data=[[[46], [--], [124]]], mask=[[[False], [ True], [False]]], fill_value=999999)# numpy.polynomial.hermite_e.HermiteE.trim[#](#numpy-polynomial-hermite-e-hermitee-trim)
method

polynomial.hermite_e.HermiteE.trim(*tol=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L735-L756)[#](#numpy.polynomial.hermite_e.HermiteE.trim)
-
Remove trailing coefficients

Remove trailing coefficients until a coefficient is reached whose absolute value greater than

*tol*or the beginning of the series is reached. If all the coefficients would be removed the series is set to`[0]`
. A new series instance is returned with the new coefficients. The current instance remains unchanged.Parameters:
-
**tol**non-negative number.
All trailing coefficients less than

*tol*will be removed.
Returns:
-
**new_series**series
New instance of series with trimmed coefficients.# numpy.diag_indices[#](#numpy-diag-indices)
numpy.diag_indices(*n*,*ndim=2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/index_tricks.py#L919-L985)[#](#numpy.diag_indices)
-
Return the indices to access the main diagonal of an array.

This returns a tuple of indices that can be used to access the main diagonal of an array

*a*with`a.ndim >= 2`
dimensions and shape (n, n, …, n). For`a.ndim = 2`
this is the usual diagonal, for`a.ndim > 2`
this is the set of indices to access`a[i, i, ..., i]`
for`i = [0..n-1]`
.Parameters:
-
**n**int
The size, along each dimension, of the arrays for which the returned indices can be used.

**ndim**int, optional
The number of dimensions.

See also

Notes

New in version 1.4.0.

Examples

Create a set of indices to access the diagonal of a (4, 4) array:

>>> di = np.diag_indices(4) >>> di (array([0, 1, 2, 3]), array([0, 1, 2, 3])) >>> a = np.arange(16).reshape(4, 4) >>> a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]]) >>> a[di] = 100 >>> a array([[100, 1, 2, 3], [ 4, 100, 6, 7], [ 8, 9, 100, 11], [ 12, 13, 14, 100]])
Now, we create indices to manipulate a 3-D array:

>>> d3 = np.diag_indices(2, 3) >>> d3 (array([0, 1]), array([0, 1]), array([0, 1]))
And use it to set the diagonal of an array of zeros to 1:

>>> a = np.zeros((2, 2, 2), dtype=int) >>> a[d3] = 1 >>> a array([[[1, 0], [0, 0]], [[0, 0], [0, 1]]])# numpy.fromfile[#](#numpy-fromfile)
numpy.fromfile(*file*,*dtype=float*,*count=-1*,*sep=''*,*offset=0*,***,*like=None*)[#](#numpy.fromfile)
-
Construct an array from data in a text or binary file.

A highly efficient way of reading binary data with a known data-type, as well as parsing simply formatted text files. Data written using the

*tofile*method can be read using this function.Parameters:
-
**file**file or str or Path
Open file object or filename.

Changed in version 1.17.0:

objects are now accepted.`pathlib.Path`
**dtype**data-type
Data type of the returned array. For binary files, it is used to determine the size and byte-order of the items in the file. Most builtin numeric types are supported and extension types may be supported.

New in version 1.18.0: Complex dtypes.

**count**int
Number of items to read.

`-1`
means all items (i.e., the complete file).
**sep**str
Separator between items if file is a text file. Empty (“”) separator means the file should be treated as binary. Spaces (” “) in the separator match zero or more whitespace characters. A separator consisting only of spaces must match at least one whitespace.

**offset**int
The offset (in bytes) from the file’s current position. Defaults to 0. Only permitted for binary files.

New in version 1.17.0.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

See also

,`load`
`save`
`ndarray.tofile`
`loadtxt`
More flexible way of loading data from a text file.

Notes

Do not rely on the combination of

*tofile*andfor data storage, as the binary files generated are not platform independent. In particular, no byte-order or data-type information is saved. Data can be stored in the platform independent`fromfile`
`.npy`
format usingand`save`
instead.`load`
Examples

Construct an ndarray:

>>> dt = np.dtype([('time', [('min', np.int64), ('sec', np.int64)]), ... ('temp', float)]) >>> x = np.zeros((1,), dtype=dt) >>> x['time']['min'] = 10; x['temp'] = 98.25 >>> x array([((10, 0), 98.25)], dtype=[('time', [('min', '<i8'), ('sec', '<i8')]), ('temp', '<f8')])
Save the raw data to disk:

>>> import tempfile >>> fname = tempfile.mkstemp()[1] >>> x.tofile(fname)
Read the raw data from disk:

>>> np.fromfile(fname, dtype=dt) array([((10, 0), 98.25)], dtype=[('time', [('min', '<i8'), ('sec', '<i8')]), ('temp', '<f8')])
The recommended way to store and load data:

>>> np.save(fname, x) >>> np.load(fname + '.npy') array([((10, 0), 98.25)], dtype=[('time', [('min', '<i8'), ('sec', '<i8')]), ('temp', '<f8')])# numpy.recarray.tofile[#](#numpy-recarray-tofile)
method

recarray.tofile(*fid*,*sep=''*,*format='%s'*)[#](#numpy.recarray.tofile)
-
Write array to a file as text or binary (default).

Data is always written in ‘C’ order, independent of the order of

*a*. The data produced by this method can be recovered using the function fromfile().Parameters:
-
**fid**file or str or Path
An open file object, or a string containing a filename.

Changed in version 1.17.0:

objects are now accepted.`pathlib.Path`
**sep**str
Separator between array items for text output. If “” (empty), a binary file is written, equivalent to

`file.write(a.tobytes())`
.
**format**str
Format string for text file output. Each entry in the array is formatted to text by first converting it to the closest Python type, and then using “format” % item.

Notes

This is a convenience function for quick storage of array data. Information on endianness and precision is lost, so this method is not a good choice for files intended to archive data or transport data between machines with different endianness. Some of these problems can be overcome by outputting the data as text files, at the expense of speed and file size.

When fid is a file object, array contents are directly written to the file, bypassing the file object’s

`write`
method. As a result, tofile cannot be used with files objects supporting compression (e.g., GzipFile) or file-like objects that do not support`fileno()`
(e.g., BytesIO).# numpy.isclose[#](#numpy-isclose)
numpy.isclose(*a*,*b*,*rtol=1e-05*,*atol=1e-08*,*equal_nan=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L2249-L2371)[#](#numpy.isclose)
-
Returns a boolean array where two arrays are element-wise equal within a tolerance.

The tolerance values are positive, typically very small numbers. The relative difference (

*rtol** abs(*b*)) and the absolute difference*atol*are added together to compare against the absolute difference between*a*and*b*.Warning

The default

*atol*is not appropriate for comparing numbers that are much smaller than one (see Notes).Parameters:
-
**a, b**array_like
Input arrays to compare.

**rtol**float
The relative tolerance parameter (see Notes).

**atol**float
The absolute tolerance parameter (see Notes).

**equal_nan**bool
Whether to compare NaN’s as equal. If True, NaN’s in

*a*will be considered equal to NaN’s in*b*in the output array.
Returns:
-
**y**array_like
Returns a boolean array of where

*a*and*b*are equal within the given tolerance. If both*a*and*b*are scalars, returns a single boolean value.
See also

Notes

New in version 1.7.0.

For finite values, isclose uses the following equation to test whether two floating point values are equivalent.

absolute(

*a*-*b*) <= (*atol*+*rtol** absolute(*b*))Unlike the built-in

, the above equation is not symmetric in`math.isclose`
*a*and*b*– it assumes*b*is the reference value – so that*isclose(a, b)*might be different from*isclose(b, a)*. Furthermore, the default value of atol is not zero, and is used to determine what small values should be considered close to zero. The default value is appropriate for expected values of order unity: if the expected values are significantly smaller than one, it can result in false positives.*atol*should be carefully selected for the use case at hand. A zero value for*atol*will result in*False*if either*a*or*b*is zero.is not defined for non-numeric data types.`isclose`
*bool*is considered a numeric data-type for this purpose.Examples

>>> np.isclose([1e10,1e-7], [1.00001e10,1e-8]) array([ True, False]) >>> np.isclose([1e10,1e-8], [1.00001e10,1e-9]) array([ True, True]) >>> np.isclose([1e10,1e-8], [1.0001e10,1e-9]) array([False, True]) >>> np.isclose([1.0, np.nan], [1.0, np.nan]) array([ True, False]) >>> np.isclose([1.0, np.nan], [1.0, np.nan], equal_nan=True) array([ True, True]) >>> np.isclose([1e-8, 1e-7], [0.0, 0.0]) array([ True, False]) >>> np.isclose([1e-100, 1e-7], [0.0, 0.0], atol=0.0) array([False, False]) >>> np.isclose([1e-10, 1e-10], [1e-20, 0.0]) array([ True, True]) >>> np.isclose([1e-10, 1e-10], [1e-20, 0.999999e-10], atol=0.0) array([False, True])# numpy.emath.log2[#](#numpy-emath-log2)
emath.log2(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/scimath.py#L389-L434)[#](#numpy.emath.log2)
-
Compute the logarithm base 2 of

*x*.Return the “principal value” (for a description of this, see

) of \(log_2(x)\). For real`numpy.log2`
*x > 0*, this is a real number (`log2(0)`
returns`-inf`
and`log2(np.inf)`
returns`inf`
). Otherwise, the complex principle value is returned.Parameters:
-
**x**array_like
The value(s) whose log base 2 is (are) required.

Returns:
-
**out**ndarray or scalar
The log base 2 of the

*x*value(s). If*x*was a scalar, so is*out*, otherwise an array is returned.
See also

Notes

For a log2() that returns

`NAN`
when real*x < 0*, use(note, however, that otherwise`numpy.log2`
and this`numpy.log2`
are identical, i.e., both return`log2`
`-inf`
for*x = 0*,`inf`
for*x = inf*, and, notably, the complex principle value if`x.imag != 0`
).Examples

We set the printing precision so the example can be auto-tested:

>>> np.set_printoptions(precision=4)
>>> np.emath.log2(8) 3.0 >>> np.emath.log2([-4, -8, 8]) array([2.+4.5324j, 3.+4.5324j, 3.+0.j ])# numpy.emath.arctanh[#](#numpy-emath-arctanh)
emath.arctanh(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/scimath.py#L577-L625)[#](#numpy.emath.arctanh)
-
Compute the inverse hyperbolic tangent of

*x*.Return the “principal value” (for a description of this, see

) of`numpy.arctanh`
`arctanh(x)`
. For real*x*such that`abs(x) < 1`
, this is a real number. If*abs(x) > 1*, or if*x*is complex, the result is complex. Finally,*x = 1*returns``inf`` and`x=-1`
returns`-inf`
.Parameters:
-
**x**array_like
The value(s) whose arctanh is (are) required.

Returns:
-
**out**ndarray or scalar
The inverse hyperbolic tangent(s) of the

*x*value(s). If*x*was a scalar so is*out*, otherwise an array is returned.
See also

Notes

For an arctanh() that returns

`NAN`
when real*x*is not in the interval`(-1,1)`
, use(this latter, however, does return +/-inf for`numpy.arctanh`
`x = +/-1`
).Examples

>>> np.set_printoptions(precision=4)
>>> from numpy.testing import suppress_warnings >>> with suppress_warnings() as sup: ... sup.filter(RuntimeWarning) ... np.emath.arctanh(np.eye(2)) array([[inf, 0.], [ 0., inf]]) >>> np.emath.arctanh([1j]) array([0.+0.7854j])# numpy.testing.assert_allclose[#](#numpy-testing-assert-allclose)
testing.assert_allclose(*actual*,*desired*,*rtol=1e-07*,*atol=0*,*equal_nan=True*,*err_msg=''*,*verbose=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/_private/utils.py#L1438-L1505)[#](#numpy.testing.assert_allclose)
-
Raises an AssertionError if two objects are not equal up to desired tolerance.

Given two array_like objects, check that their shapes and all elements are equal (but see the Notes for the special handling of a scalar). An exception is raised if the shapes mismatch or any values conflict. In contrast to the standard usage in numpy, NaNs are compared like numbers, no assertion is raised if both objects have NaNs in the same positions.

The test is equivalent to

`allclose(actual, desired, rtol, atol)`
(note that`allclose`
has different default values). It compares the difference between*actual*and*desired*to`atol + rtol * abs(desired)`
.New in version 1.5.0.

Parameters:
-
**actual**array_like
Array obtained.

**desired**array_like
Array desired.

**rtol**float, optional
Relative tolerance.

**atol**float, optional
Absolute tolerance.

**equal_nan**bool, optional.
If True, NaNs will compare equal.

**err_msg**str, optional
The error message to be printed in case of failure.

**verbose**bool, optional
If True, the conflicting values are appended to the error message.

Raises:
-
AssertionError
-
If actual and desired are not equal up to specified precision.

Notes

When one of

*actual*and*desired*is a scalar and the other is array_like, the function checks that each element of the array_like object is equal to the scalar.Examples

>>> x = [1e-5, 1e-3, 1e-1] >>> y = np.arccos(np.cos(x)) >>> np.testing.assert_allclose(x, y, rtol=1e-5, atol=0)# numpy.fft.fftfreq[#](#numpy-fft-fftfreq)
fft.fftfreq(*n*,*d=1.0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/fft/helper.py#L123-L169)[#](#numpy.fft.fftfreq)
-
Return the Discrete Fourier Transform sample frequencies.

The returned float array

*f*contains the frequency bin centers in cycles per unit of the sample spacing (with zero at the start). For instance, if the sample spacing is in seconds, then the frequency unit is cycles/second.Given a window length

*n*and a sample spacing*d*:f = [0, 1, ..., n/2-1, -n/2, ..., -1] / (d*n) if n is even f = [0, 1, ..., (n-1)/2, -(n-1)/2, ..., -1] / (d*n) if n is odd
Parameters:
-
**n**int
Window length.

**d**scalar, optional
Sample spacing (inverse of the sampling rate). Defaults to 1.

Returns:
-
**f**ndarray
Array of length

*n*containing the sample frequencies.
Examples

>>> signal = np.array([-2, 8, 6, 4, 1, 0, 3, 5], dtype=float) >>> fourier = np.fft.fft(signal) >>> n = signal.size >>> timestep = 0.1 >>> freq = np.fft.fftfreq(n, d=timestep) >>> freq array([ 0. , 1.25, 2.5 , ..., -3.75, -2.5 , -1.25])# numpy.polynomial.hermite.hermcompanion[#](#numpy-polynomial-hermite-hermcompanion)
polynomial.hermite.hermcompanion(*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L1407-L1449)[#](#numpy.polynomial.hermite.hermcompanion)
-
Return the scaled companion matrix of c.

The basis polynomials are scaled so that the companion matrix is symmetric when

*c*is an Hermite basis polynomial. This provides better eigenvalue estimates than the unscaled case and for basis polynomials the eigenvalues are guaranteed to be real ifis used to obtain them.`numpy.linalg.eigvalsh`
Parameters:
-
**c**array_like
1-D array of Hermite series coefficients ordered from low to high degree.

Returns:
-
**mat**ndarray
Scaled companion matrix of dimensions (deg, deg).

Notes

New in version 1.7.0.# numpy.format_parser[#](#numpy-format-parser)
*class*numpy.format_parser(*formats*,*names*,*titles*,*aligned=False*,*byteorder=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/__init__.py)[#](#numpy.format_parser)
-
Class to convert formats, names, titles description to a dtype.

After constructing the format_parser object, the dtype attribute is the converted data-type:

`dtype = format_parser(formats, names, titles).dtype`
Parameters:
-
**formats**str or list of str
The format description, either specified as a string with comma-separated format descriptions in the form

`'f8, i4, a5'`
, or a list of format description strings in the form`['f8', 'i4', 'a5']`
.
**names**str or list/tuple of str
The field names, either specified as a comma-separated string in the form

`'col1, col2, col3'`
, or as a list or tuple of strings in the form`['col1', 'col2', 'col3']`
. An empty list can be used, in that case default field names (‘f0’, ‘f1’, …) are used.
**titles**sequence
Sequence of title strings. An empty list can be used to leave titles out.

**aligned**bool, optional
If True, align the fields by padding as the C-compiler would. Default is False.

**byteorder**str, optional
If specified, all the fields will be changed to the provided byte-order. Otherwise, the default byte-order is used. For all available string specifiers, see

.`dtype.newbyteorder`
See also

Examples

>>> np.format_parser(['<f8', '<i4', '<a5'], ['col1', 'col2', 'col3'], ... ['T1', 'T2', 'T3']).dtype dtype([(('T1', 'col1'), '<f8'), (('T2', 'col2'), '<i4'), (('T3', 'col3'), 'S5')])
*names*and/or*titles*can be empty lists. If*titles*is an empty list, titles will simply not appear. If*names*is empty, default field names will be used.>>> np.format_parser(['f8', 'i4', 'a5'], ['col1', 'col2', 'col3'], ... []).dtype dtype([('col1', '<f8'), ('col2', '<i4'), ('col3', '<S5')]) >>> np.format_parser(['<f8', '<i4', '<a5'], [], []).dtype dtype([('f0', '<f8'), ('f1', '<i4'), ('f2', 'S5')])
Attributes:
-
**dtype**dtype
The converted data-type.# numpy.polynomial.laguerre.lagfit[#](#numpy-polynomial-laguerre-lagfit)
polynomial.laguerre.lagfit(*x*,*y*,*deg*,*rcond=None*,*full=False*,*w=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L1272-L1401)[#](#numpy.polynomial.laguerre.lagfit)
-
Least squares fit of Laguerre series to data.

Return the coefficients of a Laguerre series of degree

*deg*that is the least squares fit to the data values*y*given at points*x*. If*y*is 1-D the returned coefficients will also be 1-D. If*y*is 2-D multiple fits are done, one for each column of*y*, and the resulting coefficients are stored in the corresponding columns of a 2-D return. The fitted polynomial(s) are in the form\[p(x) = c_0 + c_1 * L_1(x) + ... + c_n * L_n(x),\]where

`n`
is*deg*.Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,) or (M, K)
y-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.

**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (*M*,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.
Returns:
-
**coef**ndarray, shape (M,) or (M, K)
Laguerre coefficients ordered from low to high. If

*y*was 2-D, the coefficients for the data in column*k*of*y*are in column*k*.
**[residuals, rank, singular_values, rcond]**list
These values are only returned if

`full == True`
residuals – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

singular_values – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`numpy.linalg.lstsq`
Warns:
-
RankWarning
-
The rank of the coefficient matrix in the least-squares fit is deficient. The warning is only raised if

`full == False`
. The warnings can be turned off by>>> import warnings >>> warnings.simplefilter('ignore', np.RankWarning)
See also

`numpy.polynomial.polynomial.polyfit`
`numpy.polynomial.legendre.legfit`
`numpy.polynomial.chebyshev.chebfit`
`numpy.polynomial.hermite.hermfit`
`numpy.polynomial.hermite_e.hermefit`
`lagval`
Evaluates a Laguerre series.

`lagvander`
pseudo Vandermonde matrix of Laguerre series.

`lagweight`
Laguerre weight function.

`numpy.linalg.lstsq`
Computes a least-squares fit from the matrix.

`scipy.interpolate.UnivariateSpline`
Computes spline fits.

Notes

The solution is the coefficients of the Laguerre series

`p`
that minimizes the sum of the weighted squared errors\[E = \sum_j w_j^2 * |y_j - p(x_j)|^2,\]where the \(w_j\) are the weights. This problem is solved by setting up as the (typically) overdetermined matrix equation

\[V(x) * c = w * y,\]where

`V`
is the weighted pseudo Vandermonde matrix of*x*,`c`
are the coefficients to be solved for,*w*are the weights, and*y*are the observed values. This equation is then solved using the singular value decomposition of`V`
.If some of the singular values of

*V*are so small that they are neglected, then awill be issued. This means that the coefficient values may be poorly determined. Using a lower order fit will usually get rid of the warning. The`RankWarning`
*rcond*parameter can also be set to a value smaller than its default, but the resulting fit may be spurious and have large contributions from roundoff error.Fits using Laguerre series are probably most useful when the data can be approximated by

`sqrt(w(x)) * p(x)`
, where`w(x)`
is the Laguerre weight. In that case the weight`sqrt(w(x[i]))`
should be used together with data values`y[i]/sqrt(w(x[i]))`
. The weight function is available as.`lagweight`
References

[1]Wikipedia, “Curve fitting”,

[https://en.wikipedia.org/wiki/Curve_fitting](https://en.wikipedia.org/wiki/Curve_fitting)Examples

>>> from numpy.polynomial.laguerre import lagfit, lagval >>> x = np.linspace(0, 10) >>> err = np.random.randn(len(x))/10 >>> y = lagval(x, [1, 2, 3]) + err >>> lagfit(x, y, 2) array([ 0.96971004, 2.00193749, 3.00288744]) # may vary# numpy.random.RandomState.rayleigh[#](#numpy-random-randomstate-rayleigh)
method

random.RandomState.rayleigh(*scale=1.0*,*size=None*)[#](#numpy.random.RandomState.rayleigh)
-
Draw samples from a Rayleigh distribution.

The \(\chi\) and Weibull distributions are generalizations of the Rayleigh.

Note

New code should use the

method of a`rayleigh`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**scale**float or array_like of floats, optional
Scale, also equals the mode. Must be non-negative. Default is 1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`scale`
is a scalar. Otherwise,`np.array(scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Rayleigh distribution.

See also

`random.Generator.rayleigh`
which should be used for new code.

Notes

The probability density function for the Rayleigh distribution is

\[P(x;scale) = \frac{x}{scale^2}e^{\frac{-x^2}{2 \cdotp scale^2}}\]The Rayleigh distribution would arise, for example, if the East and North components of the wind velocity had identical zero-mean Gaussian distributions. Then the wind speed would have a Rayleigh distribution.

References

[1]Brighton Webs Ltd., “Rayleigh Distribution,”

[https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp](https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp)[2]Wikipedia, “Rayleigh distribution”

[https://en.wikipedia.org/wiki/Rayleigh_distribution](https://en.wikipedia.org/wiki/Rayleigh_distribution)Examples

Draw values from the distribution and plot the histogram

>>> from matplotlib.pyplot import hist >>> values = hist(np.random.rayleigh(3, 100000), bins=200, density=True)
Wave heights tend to follow a Rayleigh distribution. If the mean wave height is 1 meter, what fraction of waves are likely to be larger than 3 meters?

>>> meanvalue = 1 >>> modevalue = np.sqrt(2 / np.pi) * meanvalue >>> s = np.random.rayleigh(modevalue, 1000000)
The percentage of waves larger than 3 meters is:

>>> 100.*sum(s>3)/1000000. 0.087300000000000003 # random# numpy.isinf[#](#numpy-isinf)
numpy.isinf(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'isinf'>*[#](#numpy.isinf)
-
Test element-wise for positive or negative infinity.

Returns a boolean array of the same shape as

*x*, True where`x == +/-inf`
, otherwise False.Parameters:
-
**x**array_like
Input values

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**bool (scalar) or boolean ndarray
True where

`x`
is positive or negative infinity, false otherwise. This is a scalar if*x*is a scalar.
Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754).

Errors result if the second argument is supplied when the first argument is a scalar, or if the first and second arguments have different shapes.

Examples

>>> np.isinf(np.inf) True >>> np.isinf(np.nan) False >>> np.isinf(np.NINF) True >>> np.isinf([np.inf, -np.inf, 1.0, np.nan]) array([ True, True, False, False])
>>> x = np.array([-np.inf, 0., np.inf]) >>> y = np.array([2, 2, 2]) >>> np.isinf(x, y) array([1, 0, 1]) >>> y array([1, 0, 1])# numpy.s_[#](#numpy-s)
numpy.s_*= <numpy.lib.index_tricks.IndexExpression object>*[#](#numpy.s_)
-
A nicer way to build up index tuples for arrays.

Note

Use one of the two predefined instances

`index_exp`
orrather than directly using`s_`
*IndexExpression*.For any index combination, including slicing and axis insertion,

`a[indices]`
is the same as`a[np.index_exp[indices]]`
for any array*a*. However,`np.index_exp[indices]`
can be used anywhere in Python code and returns a tuple of slice objects that can be used in the construction of complex index expressions.Parameters:
-
**maketuple**bool
If True, always returns a tuple.

See also

`index_exp`
Predefined instance that always returns a tuple:

*index_exp = IndexExpression(maketuple=True)*.
`s_`
Predefined instance without tuple conversion:

*s_ = IndexExpression(maketuple=False)*.
Notes

You can do all this with

*slice()*plus a few special objects, but there’s a lot to remember and this version is simpler because it uses the standard array indexing syntax.Examples

>>> np.s_[2::2] slice(2, None, 2) >>> np.index_exp[2::2] (slice(2, None, 2),)
>>> np.array([0, 1, 2, 3, 4])[np.s_[2::2]] array([2, 4])# numpy.degrees[#](#numpy-degrees)
numpy.degrees(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'degrees'>*[#](#numpy.degrees)
-
Convert angles from radians to degrees.

Parameters:
-
**x**array_like
Input array in radians.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray of floats
The corresponding degree values; if

*out*was supplied this is a reference to it. This is a scalar if*x*is a scalar.
See also

`rad2deg`
equivalent function

Examples

Convert a radian array to degrees

>>> rad = np.arange(12.)*np.pi/6 >>> np.degrees(rad) array([ 0., 30., 60., 90., 120., 150., 180., 210., 240., 270., 300., 330.])
>>> out = np.zeros((rad.shape)) >>> r = np.degrees(rad, out) >>> np.all(r == out) True# numpy.polynomial.laguerre.lagint[#](#numpy-polynomial-laguerre-lagint)
polynomial.laguerre.lagint(*c*,*m=1*,*k=[]*,*lbnd=0*,*scl=1*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L677-L798)[#](#numpy.polynomial.laguerre.lagint)
-
Integrate a Laguerre series.

Returns the Laguerre series coefficients

*c*integrated*m*times from*lbnd*along*axis*. At each iteration the resulting series is**multiplied**by*scl*and an integration constant,*k*, is added. The scaling factor is for use in a linear change of variable. (“Buyer beware”: note that, depending on what one is doing, one may want*scl*to be the reciprocal of what one might expect; for more information, see the Notes section below.) The argument*c*is an array of coefficients from low to high degree along each axis, e.g., [1,2,3] represents the series`L_0 + 2*L_1 + 3*L_2`
while [[1,2],[1,2]] represents`1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)`
if axis=0 is`x`
and axis=1 is`y`
.Parameters:
-
**c**array_like
Array of Laguerre series coefficients. If

*c*is multidimensional the different axis correspond to different variables with the degree in each axis given by the corresponding index.
**m**int, optional
Order of integration, must be positive. (Default: 1)

**k**{[], list, scalar}, optional
Integration constant(s). The value of the first integral at

`lbnd`
is the first value in the list, the value of the second integral at`lbnd`
is the second value, etc. If`k == []`
(the default), all constants are set to zero. If`m == 1`
, a single scalar can be given instead of a list.
**lbnd**scalar, optional
The lower bound of the integral. (Default: 0)

**scl**scalar, optional
Following each integration the result is

*multiplied*by*scl*before the integration constant is added. (Default: 1)
**axis**int, optional
Axis over which the integral is taken. (Default: 0).

New in version 1.7.0.

Returns:
-
**S**ndarray
Laguerre series coefficients of the integral.

Raises:
-
ValueError
-
If

`m < 0`
,`len(k) > m`
,`np.ndim(lbnd) != 0`
, or`np.ndim(scl) != 0`
.
See also

Notes

Note that the result of each integration is

*multiplied*by*scl*. Why is this important to note? Say one is making a linear change of variable \(u = ax + b\) in an integral relative to*x*. Then \(dx = du/a\), so one will need to set*scl*equal to \(1/a\) - perhaps not what one would have first thought.Also note that, in general, the result of integrating a C-series needs to be “reprojected” onto the C-series basis set. Thus, typically, the result of this function is “unintuitive,” albeit correct; see Examples section below.

Examples

>>> from numpy.polynomial.laguerre import lagint >>> lagint([1,2,3]) array([ 1., 1., 1., -3.]) >>> lagint([1,2,3], m=2) array([ 1., 0., 0., -4., 3.]) >>> lagint([1,2,3], k=1) array([ 2., 1., 1., -3.]) >>> lagint([1,2,3], lbnd=-1) array([11.5, 1. , 1. , -3. ]) >>> lagint([1,2], m=2, k=[1,2], lbnd=-1) array([ 11.16666667, -5. , -3. , 2. ]) # may vary# numpy.fromregex[#](#numpy-fromregex)
numpy.fromregex(*file*,*regexp*,*dtype*,*encoding=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/npyio.py#L1638-L1734)[#](#numpy.fromregex)
-
Construct an array from a text file, using regular expression parsing.

The returned array is always a structured array, and is constructed from all matches of the regular expression in the file. Groups in the regular expression are converted to fields of the structured array.

Parameters:
-
**file**path or file
Filename or file object to read.

Changed in version 1.22.0: Now accepts

implementations.`os.PathLike`
**regexp**str or regexp
Regular expression used to parse the file. Groups in the regular expression correspond to fields in the dtype.

**dtype**dtype or list of dtypes
Dtype for the structured array; must be a structured datatype.

**encoding**str, optional
Encoding used to decode the inputfile. Does not apply to input streams.

New in version 1.14.0.

Returns:
-
**output**ndarray
The output array, containing the part of the content of

*file*that was matched by*regexp*.*output*is always a structured array.
Raises:
-
TypeError
-
When

is not a valid dtype for a structured array.`dtype`
See also

Notes

Dtypes for structured arrays can be specified in several forms, but all forms specify at least the data type and field name. For details see

*basics.rec*.Examples

>>> from io import StringIO >>> text = StringIO("1312 foo\n1534 bar\n444 qux")
>>> regexp = r"(\d+)\s+(...)" # match [digits, whitespace, anything] >>> output = np.fromregex(text, regexp, ... [('num', np.int64), ('key', 'S3')]) >>> output array([(1312, b'foo'), (1534, b'bar'), ( 444, b'qux')], dtype=[('num', '<i8'), ('key', 'S3')]) >>> output['num'] array([1312, 1534, 444])# numpy.ma.masked_array.ctypes[#](#numpy-ma-masked-array-ctypes)
attribute

ma.masked_array.ctypes[#](#numpy.ma.masked_array.ctypes)
-
An object to simplify the interaction of the array with the ctypes module.

This attribute creates an object that makes it easier to use arrays when calling shared libraries with the ctypes module. The returned object has, among others, data, shape, and strides attributes (see Notes below) which themselves return ctypes objects that can be used as arguments to a shared library.

Parameters:
-
**None**
Returns:
-
**c**Python object
Possessing attributes data, shape, strides, etc.

See also

Notes

Below are the public attributes of this object which were documented in “Guide to NumPy” (we have omitted undocumented public attributes, as well as documented private attributes):

_ctypes.data
-
A pointer to the memory area of the array as a Python integer. This memory area may contain data that is not aligned, or not in correct byte-order. The memory area may not even be writeable. The array flags and data-type of this array should be respected when passing this attribute to arbitrary C-code to avoid trouble that can include Python crashing. User Beware! The value of this attribute is exactly the same as

`self._array_interface_['data'][0]`
.Note that unlike

`data_as`
, a reference will not be kept to the array: code like`ctypes.c_void_p((a + b).ctypes.data)`
will result in a pointer to a deallocated array, and should be spelt`(a + b).ctypes.data_as(ctypes.c_void_p)`
_ctypes.shape
-
(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the C-integer corresponding to

`dtype('p')`
on this platform (see). This base-type could be`c_intp`
,`ctypes.c_int`
, or`ctypes.c_long`
depending on the platform. The ctypes array contains the shape of the underlying array.`ctypes.c_longlong`
_ctypes.strides
-
(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the same as for the shape attribute. This ctypes array contains the strides information from the underlying array. This strides information is important for showing how many bytes must be jumped to get to the next element in the array.

_ctypes.data_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L267-L284)
-
Return the data pointer cast to a particular c-types object. For example, calling

`self._as_parameter_`
is equivalent to`self.data_as(ctypes.c_void_p)`
. Perhaps you want to use the data as a pointer to a ctypes array of floating-point data:`self.data_as(ctypes.POINTER(ctypes.c_double))`
.The returned pointer will keep a reference to the array.

_ctypes.shape_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L286-L293)
-
Return the shape tuple as an array of some other c-types type. For example:

`self.shape_as(ctypes.c_short)`
.
_ctypes.strides_as(*obj*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_internal.py#L295-L302)
-
Return the strides tuple as an array of some other c-types type. For example:

`self.strides_as(ctypes.c_longlong)`
.
If the ctypes module is not available, then the ctypes attribute of array objects still returns something useful, but ctypes objects are not returned and errors may be raised instead. In particular, the object will still have the

`as_parameter`
attribute which will return an integer equal to the data attribute.Examples

>>> import ctypes >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32) >>> x array([[0, 1], [2, 3]], dtype=int32) >>> x.ctypes.data 31962608 # may vary >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)) <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents c_uint(0) >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents c_ulong(4294967296) >>> x.ctypes.shape <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary >>> x.ctypes.strides <numpy.core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary# numpy.polynomial.chebyshev.chebvander[#](#numpy-polynomial-chebyshev-chebvander)
polynomial.chebyshev.chebvander(*x*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L1387-L1437)[#](#numpy.polynomial.chebyshev.chebvander)
-
Pseudo-Vandermonde matrix of given degree.

Returns the pseudo-Vandermonde matrix of degree

*deg*and sample points*x*. The pseudo-Vandermonde matrix is defined by\[V[..., i] = T_i(x),\]where

*0 <= i <= deg*. The leading indices of*V*index the elements of*x*and the last index is the degree of the Chebyshev polynomial.If

*c*is a 1-D array of coefficients of length*n + 1*and*V*is the matrix`V = chebvander(x, n)`
, then`np.dot(V, c)`
and`chebval(x, c)`
are the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of Chebyshev series of the same degree and sample points.Parameters:
-
**x**array_like
Array of points. The dtype is converted to float64 or complex128 depending on whether any of the elements are complex. If

*x*is scalar it is converted to a 1-D array.
**deg**int
Degree of the resulting matrix.

Returns:
-
**vander**ndarray
The pseudo Vandermonde matrix. The shape of the returned matrix is

`x.shape + (deg + 1,)`
, where The last index is the degree of the corresponding Chebyshev polynomial. The dtype will be the same as the converted*x*.# numpy.polynomial.hermite_e.hermefit[#](#numpy-polynomial-hermite-e-hermefit)
polynomial.hermite_e.hermefit(*x*,*y*,*deg*,*rcond=None*,*full=False*,*w=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L1266-L1396)[#](#numpy.polynomial.hermite_e.hermefit)
-
Least squares fit of Hermite series to data.

Return the coefficients of a HermiteE series of degree

*deg*that is the least squares fit to the data values*y*given at points*x*. If*y*is 1-D the returned coefficients will also be 1-D. If*y*is 2-D multiple fits are done, one for each column of*y*, and the resulting coefficients are stored in the corresponding columns of a 2-D return. The fitted polynomial(s) are in the form\[p(x) = c_0 + c_1 * He_1(x) + ... + c_n * He_n(x),\]where

*n*is*deg*.Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,) or (M, K)
y-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.

**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (*M*,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.
Returns:
-
**coef**ndarray, shape (M,) or (M, K)
Hermite coefficients ordered from low to high. If

*y*was 2-D, the coefficients for the data in column k of*y*are in column*k*.
**[residuals, rank, singular_values, rcond]**list
These values are only returned if

`full == True`
residuals – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

singular_values – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`numpy.linalg.lstsq`
Warns:
-
RankWarning
-
The rank of the coefficient matrix in the least-squares fit is deficient. The warning is only raised if

`full = False`
. The warnings can be turned off by>>> import warnings >>> warnings.simplefilter('ignore', np.RankWarning)
See also

`numpy.polynomial.chebyshev.chebfit`
`numpy.polynomial.legendre.legfit`
`numpy.polynomial.polynomial.polyfit`
`numpy.polynomial.hermite.hermfit`
`numpy.polynomial.laguerre.lagfit`
`hermeval`
Evaluates a Hermite series.

`hermevander`
pseudo Vandermonde matrix of Hermite series.

`hermeweight`
HermiteE weight function.

`numpy.linalg.lstsq`
Computes a least-squares fit from the matrix.

`scipy.interpolate.UnivariateSpline`
Computes spline fits.

Notes

The solution is the coefficients of the HermiteE series

*p*that minimizes the sum of the weighted squared errors\[E = \sum_j w_j^2 * |y_j - p(x_j)|^2,\]where the \(w_j\) are the weights. This problem is solved by setting up the (typically) overdetermined matrix equation

\[V(x) * c = w * y,\]where

*V*is the pseudo Vandermonde matrix of*x*, the elements of*c*are the coefficients to be solved for, and the elements of*y*are the observed values. This equation is then solved using the singular value decomposition of*V*.If some of the singular values of

*V*are so small that they are neglected, then awill be issued. This means that the coefficient values may be poorly determined. Using a lower order fit will usually get rid of the warning. The`RankWarning`
*rcond*parameter can also be set to a value smaller than its default, but the resulting fit may be spurious and have large contributions from roundoff error.Fits using HermiteE series are probably most useful when the data can be approximated by

`sqrt(w(x)) * p(x)`
, where*w(x)*is the HermiteE weight. In that case the weight`sqrt(w(x[i]))`
should be used together with data values`y[i]/sqrt(w(x[i]))`
. The weight function is available as.`hermeweight`
References

[1]Wikipedia, “Curve fitting”,

[https://en.wikipedia.org/wiki/Curve_fitting](https://en.wikipedia.org/wiki/Curve_fitting)Examples

>>> from numpy.polynomial.hermite_e import hermefit, hermeval >>> x = np.linspace(-10, 10) >>> np.random.seed(123) >>> err = np.random.randn(len(x))/10 >>> y = hermeval(x, [1, 2, 3]) + err >>> hermefit(x, y, 2) array([ 1.01690445, 1.99951418, 2.99948696]) # may vary# numpy.random.Generator.logseries[#](#numpy-random-generator-logseries)
method

random.Generator.logseries(*p*,*size=None*)[#](#numpy.random.Generator.logseries)
-
Draw samples from a logarithmic series distribution.

Samples are drawn from a log series distribution with specified shape parameter, 0 <=

`p`
< 1.Parameters:
-
**p**float or array_like of floats
Shape parameter for the distribution. Must be in the range [0, 1).

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`p`
is a scalar. Otherwise,`np.array(p).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized logarithmic series distribution.

See also

`scipy.stats.logser`
probability density function, distribution or cumulative density function, etc.

Notes

The probability mass function for the Log Series distribution is

\[P(k) = \frac{-p^k}{k \ln(1-p)},\]where p = probability.

The log series distribution is frequently used to represent species richness and occurrence, first proposed by Fisher, Corbet, and Williams in 1943 [2]. It may also be used to model the numbers of occupants seen in cars [3].

References

[1]Buzas, Martin A.; Culver, Stephen J., Understanding regional species diversity through the log series distribution of occurrences: BIODIVERSITY RESEARCH Diversity & Distributions, Volume 5, Number 5, September 1999 , pp. 187-195(9).

[2]Fisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The relation between the number of species and the number of individuals in a random sample of an animal population. Journal of Animal Ecology, 12:42-58.

[3]D. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small Data Sets, CRC Press, 1994.

[4]Wikipedia, “Logarithmic distribution”,

[https://en.wikipedia.org/wiki/Logarithmic_distribution](https://en.wikipedia.org/wiki/Logarithmic_distribution)Examples

Draw samples from the distribution:

>>> a = .6 >>> s = np.random.default_rng().logseries(a, 10000) >>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s)
# plot against distribution

>>> def logseries(k, p): ... return -p**k/(k*np.log(1-p)) >>> plt.plot(bins, logseries(bins, a) * count.max()/ ... logseries(bins, a).max(), 'r') >>> plt.show()# numpy.random.Generator.choice[#](#numpy-random-generator-choice)
method

random.Generator.choice(*a*,*size=None*,*replace=True*,*p=None*,*axis=0*,*shuffle=True*)[#](#numpy.random.Generator.choice)
-
Generates a random sample from a given array

Parameters:
-
**a**{array_like, int}
If an ndarray, a random sample is generated from its elements. If an int, the random sample is generated from np.arange(a).

**size**{int, tuple[int]}, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn from the 1-d*a*. If*a*has more than one dimension, the`size`
shape will be inserted into the*axis*dimension, so the output`ndim`
will be`a.ndim - 1 + len(size)`
. Default is None, in which case a single value is returned.
**replace**bool, optional
Whether the sample is with or without replacement. Default is True, meaning that a value of

`a`
can be selected multiple times.
**p**1-D array_like, optional
The probabilities associated with each entry in a. If not given, the sample assumes a uniform distribution over all entries in

`a`
.
**axis**int, optional
The axis along which the selection is performed. The default, 0, selects by row.

**shuffle**bool, optional
Whether the sample is shuffled when sampling without replacement. Default is True, False provides a speedup.

Returns:
-
**samples**single item or ndarray
The generated random samples

Raises:
-
ValueError
-
If a is an int and less than zero, if p is not 1-dimensional, if a is array-like with a size 0, if p is not a vector of probabilities, if a and p have different lengths, or if replace=False and the sample size is greater than the population size.

See also

Notes

Setting user-specified probabilities through

`p`
uses a more general but less efficient sampler than the default. The general sampler produces a different sample than the optimized sampler even if each element of`p`
is 1 / len(a).Examples

Generate a uniform random sample from np.arange(5) of size 3:

>>> rng = np.random.default_rng() >>> rng.choice(5, 3) array([0, 3, 4]) # random >>> #This is equivalent to rng.integers(0,5,3)
Generate a non-uniform random sample from np.arange(5) of size 3:

>>> rng.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0]) array([3, 3, 0]) # random
Generate a uniform random sample from np.arange(5) of size 3 without replacement:

>>> rng.choice(5, 3, replace=False) array([3,1,0]) # random >>> #This is equivalent to rng.permutation(np.arange(5))[:3]
Generate a uniform random sample from a 2-D array along the first axis (the default), without replacement:

>>> rng.choice([[0, 1, 2], [3, 4, 5], [6, 7, 8]], 2, replace=False) array([[3, 4, 5], # random [0, 1, 2]])
Generate a non-uniform random sample from np.arange(5) of size 3 without replacement:

>>> rng.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0]) array([2, 3, 0]) # random
Any of the above can be repeated with an arbitrary array-like instead of just integers. For instance:

>>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher'] >>> rng.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3]) array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random dtype='<U11')# numpy.char.chararray.item[#](#numpy-char-chararray-item)
method

char.chararray.item(**args*)[#](#numpy.char.chararray.item)
-
Copy an element of an array to a standard Python scalar and return it.

Parameters:
-
***args**Arguments (variable number and type)
none: in this case, the method only works for arrays with one element (

*a.size == 1*), which element is copied into a standard Python scalar object and returned.
int_type: this argument is interpreted as a flat index into the array, specifying which element to copy and return.

tuple of int_types: functions as does a single int_type argument, except that the argument is interpreted as an nd-index into the array.

Returns:
-
**z**Standard Python scalar object
A copy of the specified element of the array as a suitable Python scalar

Notes

When the data type of

*a*is longdouble or clongdouble, item() returns a scalar array object because there is no available Python scalar that would not lose information. Void arrays return a buffer object for item(), unless fields are defined, in which case a tuple is returned.is very similar to a[args], except, instead of an array scalar, a standard Python scalar is returned. This can be useful for speeding up access to elements of the array and doing arithmetic on elements of the array using Python’s optimized math.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.item(3) 1 >>> x.item(7) 0 >>> x.item((0, 1)) 2 >>> x.item((2, 2)) 1# numpy.ma.vander[#](#numpy-ma-vander)
ma.vander(*x*,*n=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L2085-L2094)[#](#numpy.ma.vander)
-
Generate a Vandermonde matrix.

The columns of the output matrix are powers of the input vector. The order of the powers is determined by the

*increasing*boolean argument. Specifically, when*increasing*is False, the*i*-th output column is the input vector raised element-wise to the power of`N - i - 1`
. Such a matrix with a geometric progression in each row is named for Alexandre- Theophile Vandermonde.Parameters:
-
**x**array_like
1-D input array.

**N**int, optional
Number of columns in the output. If

*N*is not specified, a square array is returned (`N = len(x)`
).
**increasing**bool, optional
Order of the powers of the columns. If True, the powers increase from left to right, if False (the default) they are reversed.

New in version 1.9.0.

Returns:
-
**out**ndarray
Vandermonde matrix. If

*increasing*is False, the first column is`x^(N-1)`
, the second`x^(N-2)`
and so forth. If*increasing*is True, the columns are`x^0, x^1, ..., x^(N-1)`
.
See also

Notes

Masked values in the input array result in rows of zeros.

Examples

>>> x = np.array([1, 2, 3, 5]) >>> N = 3 >>> np.vander(x, N) array([[ 1, 1, 1], [ 4, 2, 1], [ 9, 3, 1], [25, 5, 1]])
>>> np.column_stack([x**(N-1-i) for i in range(N)]) array([[ 1, 1, 1], [ 4, 2, 1], [ 9, 3, 1], [25, 5, 1]])
>>> x = np.array([1, 2, 3, 5]) >>> np.vander(x) array([[ 1, 1, 1, 1], [ 8, 4, 2, 1], [ 27, 9, 3, 1], [125, 25, 5, 1]]) >>> np.vander(x, increasing=True) array([[ 1, 1, 1, 1], [ 1, 2, 4, 8], [ 1, 3, 9, 27], [ 1, 5, 25, 125]])
The determinant of a square Vandermonde matrix is the product of the differences between the values of the input vector:

>>> np.linalg.det(np.vander(x)) 48.000000000000043 # may vary >>> (5-3)*(5-2)*(5-1)*(3-2)*(3-1)*(2-1) 48# numpy.ndarray.setflags[#](#numpy-ndarray-setflags)
method

ndarray.setflags(*write=None*,*align=None*,*uic=None*)[#](#numpy.ndarray.setflags)
-
Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY, respectively.

These Boolean-valued flags affect how numpy interprets the memory area used by

*a*(see Notes below). The ALIGNED flag can only be set to True if the data is actually aligned according to the type. The WRITEBACKIFCOPY and flag can never be set to True. The flag WRITEABLE can only be set to True if the array owns its own memory, or the ultimate owner of the memory exposes a writeable buffer interface, or is a string. (The exception for string is made so that unpickling can be done without copying memory.)Parameters:
-
**write**bool, optional
Describes whether or not

*a*can be written to.
**align**bool, optional
Describes whether or not

*a*is aligned properly for its type.
**uic**bool, optional
Describes whether or not

*a*is a copy of another “base” array.
Notes

Array flags provide information about how the memory area used for the array is to be interpreted. There are 7 Boolean flags in use, only four of which can be changed by the user: WRITEBACKIFCOPY, WRITEABLE, and ALIGNED.

WRITEABLE (W) the data area can be written to;

ALIGNED (A) the data and strides are aligned appropriately for the hardware (as determined by the compiler);

WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by .base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the base array will be updated with the contents of this array.

All flags can be accessed using the single (upper case) letter as well as the full name.

Examples

>>> y = np.array([[3, 1, 7], ... [2, 0, 0], ... [8, 5, 9]]) >>> y array([[3, 1, 7], [2, 0, 0], [8, 5, 9]]) >>> y.flags C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False >>> y.setflags(write=0, align=0) >>> y.flags C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : False ALIGNED : False WRITEBACKIFCOPY : False >>> y.setflags(uic=1) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: cannot set WRITEBACKIFCOPY flag to True# numpy.exceptions.DTypePromotionError[#](#numpy-exceptions-dtypepromotionerror)
*exception*exceptions.DTypePromotionError[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/exceptions.py#L189-L231)[#](#numpy.exceptions.DTypePromotionError)
-
Multiple DTypes could not be converted to a common one.

This exception derives from

`TypeError`
and is raised whenever dtypes cannot be converted to a single common one. This can be because they are of a different category/class or incompatible instances of the same one (see Examples).Notes

Many functions will use promotion to find the correct result and implementation. For these functions the error will typically be chained with a more specific error indicating that no implementation was found for the input dtypes.

Typically promotion should be considered “invalid” between the dtypes of two arrays when

*arr1 == arr2*can safely return all`False`
because the dtypes are fundamentally different.Examples

Datetimes and complex numbers are incompatible classes and cannot be promoted:

>>> np.result_type(np.dtype("M8[s]"), np.complex128) DTypePromotionError: The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[complex128]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[complex128]'>)
For example for structured dtypes, the structure can mismatch and the same

`DTypePromotionError`
is given when two structured dtypes with a mismatch in their number of fields is given:>>> dtype1 = np.dtype([("field1", np.float64), ("field2", np.int64)]) >>> dtype2 = np.dtype([("field1", np.float64)]) >>> np.promote_types(dtype1, dtype2) DTypePromotionError: field names `('field1', 'field2')` and `('field1',)` mismatch.# numpy.greater[#](#numpy-greater)
numpy.greater(*x1*,*x2*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'greater'>*[#](#numpy.greater)
-
Return the truth value of (x1 > x2) element-wise.

Parameters:
-
**x1, x2**array_like
Input arrays. If

`x1.shape != x2.shape`
, they must be broadcastable to a common shape (which becomes the shape of the output).
**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**out**ndarray or scalar
Output array, element-wise comparison of

*x1*and*x2*. Typically of type bool, unless`dtype=object`
is passed. This is a scalar if both*x1*and*x2*are scalars.
See also

Examples

>>> np.greater([4,2],[2,2]) array([ True, False])
The

`>`
operator can be used as a shorthand for`np.greater`
on ndarrays.>>> a = np.array([4, 2]) >>> b = np.array([2, 2]) >>> a > b array([ True, False])# numpy.polynomial.hermite.hermsub[#](#numpy-polynomial-hermite-hermsub)
polynomial.hermite.hermsub(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L353-L390)[#](#numpy.polynomial.hermite.hermsub)
-
Subtract one Hermite series from another.

Returns the difference of two Hermite series

*c1*-*c2*. The sequences of coefficients are from lowest order term to highest, i.e., [1,2,3] represents the series`P_0 + 2*P_1 + 3*P_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Hermite series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Of Hermite series coefficients representing their difference.

Notes

Unlike multiplication, division, etc., the difference of two Hermite series is a Hermite series (without having to “reproject” the result onto the basis set) so subtraction, just like that of “standard” polynomials, is simply “component-wise.”

Examples

>>> from numpy.polynomial.hermite import hermsub >>> hermsub([1, 2, 3, 4], [1, 2, 3]) array([0., 0., 0., 4.])# numpy.polynomial.laguerre.lagvander3d[#](#numpy-polynomial-laguerre-lagvander3d)
polynomial.laguerre.lagvander3d(*x*,*y*,*z*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L1218-L1269)[#](#numpy.polynomial.laguerre.lagvander3d)
-
Pseudo-Vandermonde matrix of given degrees.

Returns the pseudo-Vandermonde matrix of degrees

*deg*and sample points*(x, y, z)*. If*l, m, n*are the given degrees in*x, y, z*, then The pseudo-Vandermonde matrix is defined by\[V[..., (m+1)(n+1)i + (n+1)j + k] = L_i(x)*L_j(y)*L_k(z),\]where

*0 <= i <= l*,*0 <= j <= m*, and*0 <= j <= n*. The leading indices of*V*index the points*(x, y, z)*and the last index encodes the degrees of the Laguerre polynomials.If

`V = lagvander3d(x, y, z, [xdeg, ydeg, zdeg])`
, then the columns of*V*correspond to the elements of a 3-D coefficient array*c*of shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order\[c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...\]and

`np.dot(V, c.flat)`
and`lagval3d(x, y, z, c)`
will be the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of 3-D Laguerre series of the same degrees and sample points.Parameters:
-
**x, y, z**array_like
Arrays of point coordinates, all of the same shape. The dtypes will be converted to either float64 or complex128 depending on whether any of the elements are complex. Scalars are converted to 1-D arrays.

**deg**list of ints
List of maximum degrees of the form [x_deg, y_deg, z_deg].

Returns:
-
**vander3d**ndarray
The shape of the returned matrix is

`x.shape + (order,)`
, where \(order = (deg[0]+1)*(deg[1]+1)*(deg[2]+1)\). The dtype will be the same as the converted*x*,*y*, and*z*.
See also

Notes

New in version 1.7.0.# numpy.polynomial.hermite.Hermite.linspace[#](#numpy-polynomial-hermite-hermite-linspace)
method

polynomial.hermite.Hermite.linspace(*n=100*,*domain=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L923-L953)[#](#numpy.polynomial.hermite.Hermite.linspace)
-
Return x, y values at equally spaced points in domain.

Returns the x, y values at

*n*linearly spaced points across the domain. Here y is the value of the polynomial at the points x. By default the domain is the same as that of the series instance. This method is intended mostly as a plotting aid.New in version 1.5.0.

Parameters:
-
**n**int, optional
Number of point pairs to return. The default value is 100.

**domain**{None, array_like}, optional
If not None, the specified domain is used instead of that of the calling instance. It should be of the form

`[beg,end]`
. The default is None which case the class domain is used.
Returns:
-
**x, y**ndarray
x is equal to linspace(self.domain[0], self.domain[1], n) and y is the series evaluated at element of x.# numpy.ma.MaskedArray.shape[#](#numpy-ma-maskedarray-shape)
property

*property*ma.MaskedArray.shape[#](#numpy.ma.MaskedArray.shape)
-
Tuple of array dimensions.

The shape property is usually used to get the current shape of an array, but may also be used to reshape the array in-place by assigning a tuple of array dimensions to it. As with

, one of the new shape dimensions can be -1, in which case its value is inferred from the size of the array and the remaining dimensions. Reshaping an array in-place will fail if a copy is required.`numpy.reshape`
Warning

Setting

`arr.shape`
is discouraged and may be deprecated in the future. Usingis the preferred approach.`ndarray.reshape`
See also

`numpy.shape`
Equivalent getter function.

`numpy.reshape`
Function similar to setting

`shape`
.
`ndarray.reshape`
Method similar to setting

`shape`
.
Examples

>>> x = np.array([1, 2, 3, 4]) >>> x.shape (4,) >>> y = np.zeros((2, 3, 4)) >>> y.shape (2, 3, 4) >>> y.shape = (3, 8) >>> y array([[ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.]]) >>> y.shape = (3, 6) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: total size of new array must be unchanged >>> np.zeros((4,2))[::2].shape = (-1,) Traceback (most recent call last): File "<stdin>", line 1, in <module> AttributeError: Incompatible shape for in-place modification. Use `.reshape()` to make a copy with the desired shape.# numpy.polynomial.polynomial.polyvander[#](#numpy-polynomial-polynomial-polyvander)
polynomial.polynomial.polyvander(*x*,*deg*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L1058-L1109)[#](#numpy.polynomial.polynomial.polyvander)
-
Vandermonde matrix of given degree.

Returns the Vandermonde matrix of degree

*deg*and sample points*x*. The Vandermonde matrix is defined by\[V[..., i] = x^i,\]where

*0 <= i <= deg*. The leading indices of*V*index the elements of*x*and the last index is the power of*x*.If

*c*is a 1-D array of coefficients of length*n + 1*and*V*is the matrix`V = polyvander(x, n)`
, then`np.dot(V, c)`
and`polyval(x, c)`
are the same up to roundoff. This equivalence is useful both for least squares fitting and for the evaluation of a large number of polynomials of the same degree and sample points.Parameters:
-
**x**array_like
Array of points. The dtype is converted to float64 or complex128 depending on whether any of the elements are complex. If

*x*is scalar it is converted to a 1-D array.
**deg**int
Degree of the resulting matrix.

Returns:
-
**vander**ndarray.
The Vandermonde matrix. The shape of the returned matrix is

`x.shape + (deg + 1,)`
, where the last index is the power of*x*. The dtype will be the same as the converted*x*.
See also# numpy.random.RandomState.negative_binomial[#](#numpy-random-randomstate-negative-binomial)
method

random.RandomState.negative_binomial(*n*,*p*,*size=None*)[#](#numpy.random.RandomState.negative_binomial)
-
Draw samples from a negative binomial distribution.

Samples are drawn from a negative binomial distribution with specified parameters,

*n*successes and*p*probability of success where*n*is > 0 and*p*is in the interval [0, 1].Note

New code should use the

method of a`negative_binomial`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**n**float or array_like of floats
Parameter of the distribution, > 0.

**p**float or array_like of floats
Parameter of the distribution, >= 0 and <=1.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`n`
and`p`
are both scalars. Otherwise,`np.broadcast(n, p).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized negative binomial distribution, where each sample is equal to N, the number of failures that occurred before a total of n successes was reached.

See also

`random.Generator.negative_binomial`
which should be used for new code.

Notes

The probability mass function of the negative binomial distribution is

\[P(N;n,p) = \frac{\Gamma(N+n)}{N!\Gamma(n)}p^{n}(1-p)^{N},\]where \(n\) is the number of successes, \(p\) is the probability of success, \(N+n\) is the number of trials, and \(\Gamma\) is the gamma function. When \(n\) is an integer, \(\frac{\Gamma(N+n)}{N!\Gamma(n)} = \binom{N+n-1}{N}\), which is the more common form of this term in the pmf. The negative binomial distribution gives the probability of N failures given n successes, with a success on the last trial.

If one throws a die repeatedly until the third time a “1” appears, then the probability distribution of the number of non-“1”s that appear before the third “1” is a negative binomial distribution.

References

[1]Weisstein, Eric W. “Negative Binomial Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/NegativeBinomialDistribution.html](http://mathworld.wolfram.com/NegativeBinomialDistribution.html)[2]Wikipedia, “Negative binomial distribution”,

[https://en.wikipedia.org/wiki/Negative_binomial_distribution](https://en.wikipedia.org/wiki/Negative_binomial_distribution)Examples

Draw samples from the distribution:

A real world example. A company drills wild-cat oil exploration wells, each with an estimated probability of success of 0.1. What is the probability of having one success for each successive well, that is what is the probability of a single success after drilling 5 wells, after 6 wells, etc.?

>>> s = np.random.negative_binomial(1, 0.1, 100000) >>> for i in range(1, 11): ... probability = sum(s<i) / 100000. ... print(i, "wells drilled, probability of one success =", probability)# numpy.geterrcall[#](#numpy-geterrcall)
numpy.geterrcall()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/_ufunc_config.py#L314-L357)[#](#numpy.geterrcall)
-
Return the current callback function used on floating-point errors.

When the error handling for a floating-point error (one of “divide”, “over”, “under”, or “invalid”) is set to ‘call’ or ‘log’, the function that is called or the log instance that is written to is returned by

. This function or log instance has been set with`geterrcall`
.`seterrcall`
Returns:
-
**errobj**callable, log instance or None
The current error handler. If no handler was set through

,`seterrcall`
`None`
is returned.
See also

Notes

For complete documentation of the types of floating-point exceptions and treatment options, see

.`seterr`
Examples

>>> np.geterrcall() # we did not yet set a handler, returns None
>>> oldsettings = np.seterr(all='call') >>> def err_handler(type, flag): ... print("Floating point error (%s), with flag %s" % (type, flag)) >>> oldhandler = np.seterrcall(err_handler) >>> np.array([1, 2, 3]) / 0.0 Floating point error (divide by zero), with flag 1 array([inf, inf, inf])
>>> cur_handler = np.geterrcall() >>> cur_handler is err_handler True# numpy.ndarray.size[#](#numpy-ndarray-size)
attribute

ndarray.size[#](#numpy.ndarray.size)
-
Number of elements in the array.

Equal to

`np.prod(a.shape)`
, i.e., the product of the array’s dimensions.Notes

*a.size*returns a standard arbitrary precision Python integer. This may not be the case with other methods of obtaining the same value (like the suggested`np.prod(a.shape)`
, which returns an instance of`np.int_`
), and may be relevant if the value is used further in calculations that may overflow a fixed size integer type.Examples

>>> x = np.zeros((3, 5, 2), dtype=np.complex128) >>> x.size 30 >>> np.prod(x.shape) 30# numpy.ma.masked_array.flatten[#](#numpy-ma-masked-array-flatten)
method

ma.masked_array.flatten(*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2571-L2581)[#](#numpy.ma.masked_array.flatten)
-
Return a copy of the array collapsed into one dimension.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
‘C’ means to flatten in row-major (C-style) order. ‘F’ means to flatten in column-major (Fortran- style) order. ‘A’ means to flatten in column-major order if

*a*is Fortran*contiguous*in memory, row-major order otherwise. ‘K’ means to flatten*a*in the order the elements occur in memory. The default is ‘C’.
Returns:
-
**y**ndarray
A copy of the input array, flattened to one dimension.

Examples

>>> a = np.array([[1,2], [3,4]]) >>> a.flatten() array([1, 2, 3, 4]) >>> a.flatten('F') array([1, 3, 2, 4])# numpy.broadcast_arrays[#](#numpy-broadcast-arrays)
numpy.broadcast_arrays(**args*,*subok=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/stride_tricks.py#L480-L547)[#](#numpy.broadcast_arrays)
-
Broadcast any number of arrays against each other.

Parameters:
-
**`*args`**array_likes
The arrays to broadcast.

**subok**bool, optional
If True, then sub-classes will be passed-through, otherwise the returned arrays will be forced to be a base-class array (default).

Returns:
-
**broadcasted**list of arrays
These arrays are views on the original arrays. They are typically not contiguous. Furthermore, more than one element of a broadcasted array may refer to a single memory location. If you need to write to the arrays, make copies first. While you can set the

`writable`
flag True, writing to a single output value may end up changing more than one location in the output array.Deprecated since version 1.17: The output is currently marked so that if written to, a deprecation warning will be emitted. A future version will set the

`writable`
flag False so writing to it will raise an error.
See also

Examples

>>> x = np.array([[1,2,3]]) >>> y = np.array([[4],[5]]) >>> np.broadcast_arrays(x, y) [array([[1, 2, 3], [1, 2, 3]]), array([[4, 4, 4], [5, 5, 5]])]
Here is a useful idiom for getting contiguous copies instead of non-contiguous views.

>>> [np.array(a) for a in np.broadcast_arrays(x, y)] [array([[1, 2, 3], [1, 2, 3]]), array([[4, 4, 4], [5, 5, 5]])]# How to extend NumPy[#](#how-to-extend-numpy)
*John A. Locke*
*Alan Turing*
## Writing an extension module[#](#writing-an-extension-module)
While the ndarray object is designed to allow rapid computation in Python, it is also designed to be general-purpose and satisfy a wide- variety of computational needs. As a result, if absolute speed is essential, there is no replacement for a well-crafted, compiled loop specific to your application and hardware. This is one of the reasons that numpy includes f2py so that an easy-to-use mechanisms for linking (simple) C/C++ and (arbitrary) Fortran code directly into Python are available. You are encouraged to use and improve this mechanism. The purpose of this section is not to document this tool but to document the more basic steps to writing an extension module that this tool depends on.

When an extension module is written, compiled, and installed to
somewhere in the Python path (sys.path), the code can then be imported
into Python as if it were a standard python file. It will contain
objects and methods that have been defined and compiled in C code. The
basic steps for doing this in Python are well-documented and you can
find more information in the documentation for Python itself available
online at [www.python.org](https://www.python.org) .

In addition to the Python C-API, there is a full and rich C-API for NumPy allowing sophisticated manipulations on a C-level. However, for most applications, only a few API calls will typically be used. For example, if you need to just extract a pointer to memory along with some shape information to pass to another calculation routine, then you will use very different calls than if you are trying to create a new array-like type or add a new data type for ndarrays. This chapter documents the API calls and macros that are most commonly used.

## Required subroutine[#](#required-subroutine)
There is exactly one function that must be defined in your C-code in
order for Python to use it as an extension module. The function must
be called init{name} where {name} is the name of the module from
Python. This function must be declared so that it is visible to code
outside of the routine. Besides adding the methods and constants you
desire, this subroutine must also contain calls like `import_array()`
and/or `import_ufunc()`
depending on which C-API is needed. Forgetting
to place these commands will show itself as an ugly segmentation fault
(crash) as soon as any C-API subroutine is actually called. It is
actually possible to have multiple init{name} functions in a single
file in which case multiple modules will be defined by that file.
However, there are some tricks to get that to work correctly and it is
not covered here.

A minimal `init{name}`
method looks like:

```
PyMODINIT_FUNC
init{name}(void)
{
(void)Py_InitModule({name}, mymethods);
import_array();
}
```
The mymethods must be an array (usually statically declared) of PyMethodDef structures which contain method names, actual C-functions, a variable indicating whether the method uses keyword arguments or not, and docstrings. These are explained in the next section. If you want to add constants to the module, then you store the returned value from Py_InitModule which is a module object. The most general way to add items to the module is to get the module dictionary using PyModule_GetDict(module). With the module dictionary, you can add whatever you like to the module manually. An easier way to add objects to the module is to use one of three additional Python C-API calls that do not require a separate extraction of the module dictionary. These are documented in the Python documentation, but repeated here for convenience:

int PyModule_AddStringConstant([PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)*module, char *name, char *value)[#](#c.PyModule_AddStringConstant)
-
All three of these functions require the

*module*object (the return value of Py_InitModule). The*name*is a string that labels the value in the module. Depending on which function is called, the*value*argument is either a general object (steals a reference to it), an integer constant, or a string constant.`PyModule_AddObject`
## Defining functions[#](#defining-functions)
The second argument passed in to the Py_InitModule function is a structure that makes it easy to define functions in the module. In the example given above, the mymethods structure would have been defined earlier in the file (usually right before the init{name} subroutine) to:

```
static PyMethodDef mymethods[] = {
{ nokeywordfunc,nokeyword_cfunc,
METH_VARARGS,
Doc string},
{ keywordfunc, keyword_cfunc,
METH_VARARGS|METH_KEYWORDS,
Doc string},
{NULL, NULL, 0, NULL} /* Sentinel */
}
```
Each entry in the mymethods array is a [ PyMethodDef](https://docs.python.org/3/c-api/structures.html#c.PyMethodDef) structure
containing 1) the Python name, 2) the C-function that implements the
function, 3) flags indicating whether or not keywords are accepted for
this function, and 4) The docstring for the function. Any number of
functions may be defined for a single module by adding more entries to
this table. The last entry must be all NULL as shown to act as a
sentinel. Python looks for this entry to know that all of the
functions for the module have been defined.

The last thing that must be done to finish the extension module is to actually write the code that performs the desired functions. There are two kinds of functions: those that don’t accept keyword arguments, and those that do.

### Functions without keyword arguments[#](#functions-without-keyword-arguments)
Functions that don’t accept keyword arguments should be written as:

```
static PyObject*
nokeyword_cfunc (PyObject *dummy, PyObject *args)
{
/* convert Python arguments */
/* do function */
/* return something */
}
```
The dummy argument is not used in this context and can be safely
ignored. The *args* argument contains all of the arguments passed in
to the function as a tuple. You can do anything you want at this
point, but usually the easiest way to manage the input arguments is to
call [ PyArg_ParseTuple](https://docs.python.org/3/c-api/arg.html#c.PyArg_ParseTuple) (args, format_string,
addresses_to_C_variables…) or

[(tuple, “name”, min, max, …). A good description of how to use the first function is contained in the Python C-API reference manual under section 5.5 (Parsing arguments and building values). You should pay particular attention to the “O&” format which uses converter functions to go between the Python object and the C object. All of the other format functions can be (mostly) thought of as special cases of this general rule. There are several converter functions defined in the NumPy C-API that may be of use. In particular, the](https://docs.python.org/3/c-api/arg.html#c.PyArg_UnpackTuple)
`PyArg_UnpackTuple`
[function is very useful to support arbitrary data-type specification. This function transforms any valid data-type Python object into a](../reference/c-api/array.html#c.PyArray_DescrConverter)
`PyArray_DescrConverter`
[PyArray_Descr](../reference/c-api/types-and-structures.html#c.PyArray_Descr)* object. Remember to pass in the address of the C-variables that should be filled in.
There are lots of examples of how to use [ PyArg_ParseTuple](https://docs.python.org/3/c-api/arg.html#c.PyArg_ParseTuple)
throughout the NumPy source code. The standard usage is like this:

```
PyObject *input;
PyArray_Descr *dtype;
if (!PyArg_ParseTuple(args, "OO&", &input,
PyArray_DescrConverter,
&dtype)) return NULL;
```
It is important to keep in mind that you get a *borrowed* reference to
the object when using the “O” format string. However, the converter
functions usually require some form of memory handling. In this
example, if the conversion is successful, *dtype* will hold a new
reference to a [PyArray_Descr](../reference/c-api/types-and-structures.html#c.PyArray_Descr)* object, while *input* will hold a
borrowed reference. Therefore, if this conversion were mixed with
another conversion (say to an integer) and the data-type conversion
was successful but the integer conversion failed, then you would need
to release the reference count to the data-type object before
returning. A typical way to do this is to set *dtype* to `NULL`
before calling [ PyArg_ParseTuple](https://docs.python.org/3/c-api/arg.html#c.PyArg_ParseTuple) and then use

[on](https://docs.python.org/3/c-api/refcounting.html#c.Py_XDECREF)
`Py_XDECREF`
*dtype*before returning.
After the input arguments are processed, the code that actually does
the work is written (likely calling other functions as needed). The
final step of the C-function is to return something. If an error is
encountered then `NULL`
should be returned (making sure an error has
actually been set). If nothing should be returned then increment
[ Py_None](https://docs.python.org/3/c-api/none.html#c.Py_None) and return it. If a single object should be returned then
it is returned (ensuring that you own a reference to it first). If
multiple objects should be returned then you need to return a tuple.
The

[(format_string, c_variables…) function makes it easy to build tuples of Python objects from C variables. Pay special attention to the difference between ‘N’ and ‘O’ in the format string or you can easily create memory leaks. The ‘O’ format string increments the reference count of the](https://docs.python.org/3/c-api/arg.html#c.Py_BuildValue)
`Py_BuildValue`
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)* C-variable it corresponds to, while the ‘N’ format string steals a reference to the corresponding
[PyObject](https://docs.python.org/3/c-api/structures.html#c.PyObject)* C-variable. You should use ‘N’ if you have already created a reference for the object and just want to give that reference to the tuple. You should use ‘O’ if you only have a borrowed reference to an object and need to create one to provide for the tuple.
### Functions with keyword arguments[#](#functions-with-keyword-arguments)
These functions are very similar to functions without keyword arguments. The only difference is that the function signature is:

```
static PyObject*
keyword_cfunc (PyObject *dummy, PyObject *args, PyObject *kwds)
{
...
}
```
The kwds argument holds a Python dictionary whose keys are the names
of the keyword arguments and whose values are the corresponding
keyword-argument values. This dictionary can be processed however you
see fit. The easiest way to handle it, however, is to replace the
[ PyArg_ParseTuple](https://docs.python.org/3/c-api/arg.html#c.PyArg_ParseTuple) (args, format_string, addresses…) function with
a call to

[(args, kwds, format_string, char *kwlist[], addresses…). The kwlist parameter to this function is a](https://docs.python.org/3/c-api/arg.html#c.PyArg_ParseTupleAndKeywords)
`PyArg_ParseTupleAndKeywords`
`NULL`
-terminated array of strings providing the expected
keyword arguments. There should be one string for each entry in the
format_string. Using this function will raise a TypeError if invalid
keyword arguments are passed in.For more help on this function please see section 1.8 (Keyword Parameters for Extension Functions) of the Extending and Embedding tutorial in the Python documentation.

### Reference counting[#](#reference-counting)
The biggest difficulty when writing extension modules is reference
counting. It is an important reason for the popularity of f2py, weave,
Cython, ctypes, etc…. If you mis-handle reference counts you can get
problems from memory-leaks to segmentation faults. The only strategy I
know of to handle reference counts correctly is blood, sweat, and
tears. First, you force it into your head that every Python variable
has a reference count. Then, you understand exactly what each function
does to the reference count of your objects, so that you can properly
use DECREF and INCREF when you need them. Reference counting can
really test the amount of patience and diligence you have towards your
programming craft. Despite the grim depiction, most cases of reference
counting are quite straightforward with the most common difficulty
being not using DECREF on objects before exiting early from a routine
due to some error. In second place, is the common error of not owning
the reference on an object that is passed to a function or macro that
is going to steal the reference ( *e.g.* [ PyTuple_SET_ITEM](https://docs.python.org/3/c-api/tuple.html#c.PyTuple_SET_ITEM), and
most functions that take

[objects).](../reference/c-api/types-and-structures.html#c.PyArray_Descr)
`PyArray_Descr`
Typically you get a new reference to a variable when it is created or
is the return value of some function (there are some prominent
exceptions, however — such as getting an item out of a tuple or a
dictionary). When you own the reference, you are responsible to make
sure that [ Py_DECREF](https://docs.python.org/3/c-api/refcounting.html#c.Py_DECREF) (var) is called when the variable is no
longer necessary (and no other function has “stolen” its
reference). Also, if you are passing a Python object to a function
that will “steal” the reference, then you need to make sure you own it
(or use

[to get your own reference). You will also encounter the notion of borrowing a reference. A function that borrows a reference does not alter the reference count of the object and does not expect to “hold on “to the reference. It’s just going to use the object temporarily. When you use](https://docs.python.org/3/c-api/refcounting.html#c.Py_INCREF)
`Py_INCREF`
[or](https://docs.python.org/3/c-api/arg.html#c.PyArg_ParseTuple)
`PyArg_ParseTuple`
[you receive a borrowed reference to the objects in the tuple and should not alter their reference count inside your function. With practice, you can learn to get reference counting right, but it can be frustrating at first.](https://docs.python.org/3/c-api/arg.html#c.PyArg_UnpackTuple)
`PyArg_UnpackTuple`
One common source of reference-count errors is the [ Py_BuildValue](https://docs.python.org/3/c-api/arg.html#c.Py_BuildValue)
function. Pay careful attention to the difference between the ‘N’
format character and the ‘O’ format character. If you create a new
object in your subroutine (such as an output array), and you are
passing it back in a tuple of return values, then you should most-
likely use the ‘N’ format character in

[. The ‘O’ character will increase the reference count by one. This will leave the caller with two reference counts for a brand-new array. When the variable is deleted and the reference count decremented by one, there will still be that extra reference count, and the array will never be deallocated. You will have a reference-counting induced memory leak. Using the ‘N’ character will avoid this situation as it will return to the caller an object (inside the tuple) with a single reference count.](https://docs.python.org/3/c-api/arg.html#c.Py_BuildValue)
`Py_BuildValue`
## Dealing with array objects[#](#dealing-with-array-objects)
Most extension modules for NumPy will need to access the memory for an ndarray object (or one of it’s sub-classes). The easiest way to do this doesn’t require you to know much about the internals of NumPy. The method is to

Ensure you are dealing with a well-behaved array (aligned, in machine byte-order and single-segment) of the correct type and number of dimensions.

By converting it from some Python object using

or a macro built on it.`PyArray_FromAny`
By constructing a new ndarray of your desired shape and type using

or a simpler macro or function based on it.`PyArray_NewFromDescr`
Get the shape of the array and a pointer to its actual data.

Pass the data and shape information on to a subroutine or other section of code that actually performs the computation.

If you are writing the algorithm, then I recommend that you use the stride information contained in the array to access the elements of the array (the

macros make this painless). Then, you can relax your requirements so as not to force a single-segment array and the data-copying that might result.`PyArray_GetPtr`
Each of these sub-topics is covered in the following sub-sections.

### Converting an arbitrary sequence object[#](#converting-an-arbitrary-sequence-object)
The main routine for obtaining an array from any Python object that
can be converted to an array is [ PyArray_FromAny](../reference/c-api/array.html#c.PyArray_FromAny). This
function is very flexible with many input arguments. Several macros
make it easier to use the basic function.

[is arguably the most useful of these macros for the most common uses. It allows you to convert an arbitrary Python object to an array of a specific builtin data-type (](../reference/c-api/array.html#c.PyArray_FROM_OTF)
`PyArray_FROM_OTF`
*e.g.*float), while specifying a particular set of requirements (
*e.g.*contiguous, aligned, and writeable). The syntax is
`PyArray_FROM_OTF`
Return an ndarray from any Python object,

*obj*, that can be converted to an array. The number of dimensions in the returned array is determined by the object. The desired data-type of the returned array is provided in*typenum*which should be one of the enumerated types. The*requirements*for the returned array can be any combination of standard array flags. Each of these arguments is explained in more detail below. You receive a new reference to the array on success. On failure,`NULL`
is returned and an exception is set.*obj*
The object can be any Python object convertible to an ndarray. If the object is already (a subclass of) the ndarray that satisfies the requirements then a new reference is returned. Otherwise, a new array is constructed. The contents of

*obj*are copied to the new array unless the array interface is used so that data does not have to be copied. Objects that can be converted to an array include: 1) any nested sequence object, 2) any object exposing the array interface, 3) any object with anmethod (which should return an ndarray), and 4) any scalar object (becomes a zero-dimensional array). Sub-classes of the ndarray that otherwise fit the requirements will be passed through. If you want to ensure a base-class ndarray, then use`__array__`
in the requirements flag. A copy is made only if necessary. If you want to guarantee a copy, then pass in`NPY_ARRAY_ENSUREARRAY`
to the requirements flag.`NPY_ARRAY_ENSURECOPY`
*typenum*
One of the enumerated types or

if the data-type should be determined from the object itself. The C-based names can be used:`NPY_NOTYPE`
Alternatively, the bit-width names can be used as supported on the platform. For example:

The object will be converted to the desired type only if it can be done without losing precision. Otherwise

`NULL`
will be returned and an error raised. Usein the requirements flag to override this behavior.`NPY_ARRAY_FORCECAST`
*requirements*
The memory model for an ndarray admits arbitrary strides in each dimension to advance to the next element of the array. Often, however, you need to interface with code that expects a C-contiguous or a Fortran-contiguous memory layout. In addition, an ndarray can be misaligned (the address of an element is not at an integral multiple of the size of the element) which can cause your program to crash (or at least work more slowly) if you try and dereference a pointer into the array data. Both of these problems can be solved by converting the Python object into an array that is more “well-behaved” for your specific usage.

The requirements flag allows specification of what kind of array is acceptable. If the object passed in does not satisfy this requirements then a copy is made so that the returned object will satisfy the requirements. these ndarray can use a very generic pointer to memory. This flag allows specification of the desired properties of the returned array object. All of the flags are explained in the detailed API chapter. The flags most commonly needed are

,`NPY_ARRAY_IN_ARRAY`
, and`NPY_OUT_ARRAY`
:`NPY_ARRAY_INOUT_ARRAY`
`NPY_ARRAY_IN_ARRAY`
This flag is useful for arrays that must be in C-contiguous order and aligned. These kinds of arrays are usually input arrays for some algorithm.

`NPY_ARRAY_OUT_ARRAY`
This flag is useful to specify an array that is in C-contiguous order, is aligned, and can be written to as well. Such an array is usually returned as output (although normally such output arrays are created from scratch).

`NPY_ARRAY_INOUT_ARRAY`
This flag is useful to specify an array that will be used for both input and output.

must be called before`PyArray_ResolveWritebackIfCopy`
at the end of the interface routine to write back the temporary data into the original array passed in. Use of the`Py_DECREF`
flag requires that the input object is already an array (because other objects cannot be automatically updated in this fashion). If an error occurs use`NPY_ARRAY_WRITEBACKIFCOPY`
(obj) on an array with these flags set. This will set the underlying base array writable without causing the contents to be copied back into the original array.`PyArray_DiscardWritebackIfCopy`
Other useful flags that can be OR’d as additional requirements are:

`NPY_ARRAY_FORCECAST`
Cast to the desired type, even if it can’t be done without losing information.

`NPY_ARRAY_ENSURECOPY`
Make sure the resulting array is a copy of the original.

`NPY_ARRAY_ENSUREARRAY`
Make sure the resulting object is an actual ndarray and not a sub- class.

Note

Whether or not an array is byte-swapped is determined by the
data-type of the array. Native byte-order arrays are always
requested by [ PyArray_FROM_OTF](../reference/c-api/array.html#c.PyArray_FROM_OTF) and so there is no need for
a

[flag in the requirements argument. There is also no way to get a byte-swapped array from this routine.](../reference/c-api/array.html#c.NPY_ARRAY_NOTSWAPPED)
`NPY_ARRAY_NOTSWAPPED`
### Creating a brand-new ndarray[#](#creating-a-brand-new-ndarray)
Quite often, new arrays must be created from within extension-module
code. Perhaps an output array is needed and you don’t want the caller
to have to supply it. Perhaps only a temporary array is needed to hold
an intermediate calculation. Whatever the need there are simple ways
to get an ndarray object of whatever data-type is needed. The most
general function for doing this is [ PyArray_NewFromDescr](../reference/c-api/array.html#c.PyArray_NewFromDescr). All array
creation functions go through this heavily re-used code. Because of
its flexibility, it can be somewhat confusing to use. As a result,
simpler forms exist that are easier to use. These forms are part of the

[family of functions, which simplify the interface by providing default values for common use cases.](../reference/c-api/array.html#c.PyArray_SimpleNew)
`PyArray_SimpleNew`
### Getting at ndarray memory and accessing elements of the ndarray[#](#getting-at-ndarray-memory-and-accessing-elements-of-the-ndarray)
If obj is an ndarray ([PyArrayObject](../reference/c-api/types-and-structures.html#c.PyArrayObject)*), then the data-area of the
ndarray is pointed to by the void* pointer [ PyArray_DATA](../reference/c-api/array.html#c.PyArray_DATA) (obj) or
the char* pointer

[(obj). Remember that (in general) this data-area may not be aligned according to the data-type, it may represent byte-swapped data, and/or it may not be writeable. If the data area is aligned and in native byte-order, then how to get at a specific element of the array is determined only by the array of npy_intp variables,](../reference/c-api/array.html#c.PyArray_BYTES)
`PyArray_BYTES`
[(obj). In particular, this c-array of integers shows how many](../reference/c-api/array.html#c.PyArray_STRIDES)
`PyArray_STRIDES`
**bytes**must be added to the current element pointer to get to the next element in each dimension. For arrays less than 4-dimensions there are
`PyArray_GETPTR{k}`
(obj, …) macros where {k} is the integer 1, 2, 3, or 4 that make
using the array strides easier. The arguments …. represent {k} non-
negative integer indices into the array. For example, suppose `E`
is
a 3-dimensional ndarray. A (void*) pointer to the element `E[i,j,k]`
is obtained as [(E, i, j, k).](../reference/c-api/array.html#c.PyArray_GETPTR3)
`PyArray_GETPTR3`
As explained previously, C-style contiguous arrays and Fortran-style
contiguous arrays have particular striding patterns. Two array flags
([ NPY_ARRAY_C_CONTIGUOUS](../reference/c-api/array.html#c.NPY_ARRAY_C_CONTIGUOUS) and

[) indicate whether or not the striding pattern of a particular array matches the C-style contiguous or Fortran-style contiguous or neither. Whether or not the striding pattern matches a standard C or Fortran one can be tested Using](../reference/c-api/array.html#c.NPY_ARRAY_F_CONTIGUOUS)
`NPY_ARRAY_F_CONTIGUOUS`
[(obj) and](../reference/c-api/array.html#c.PyArray_IS_C_CONTIGUOUS)
`PyArray_IS_C_CONTIGUOUS`
[(obj) respectively. Most third-party libraries expect contiguous arrays. But, often it is not difficult to support general-purpose striding. I encourage you to use the striding information in your own code whenever possible, and reserve single-segment requirements for wrapping third-party code. Using the striding information provided with the ndarray rather than requiring a contiguous striding reduces copying that otherwise must be made.](../reference/c-api/array.html#c.PyArray_ISFORTRAN)
`PyArray_ISFORTRAN`
## Example[#](#example)
The following example shows how you might write a wrapper that accepts two input arguments (that will be converted to an array) and an output argument (that must be an array). The function returns None and updates the output array. Note the updated use of WRITEBACKIFCOPY semantics for NumPy v1.14 and above

```
static PyObject *
example_wrapper(PyObject *dummy, PyObject *args)
{
PyObject *arg1=NULL, *arg2=NULL, *out=NULL;
PyObject *arr1=NULL, *arr2=NULL, *oarr=NULL;
if (!PyArg_ParseTuple(args, "OOO!", &arg1, &arg2,
&PyArray_Type, &out)) return NULL;
arr1 = PyArray_FROM_OTF(arg1, NPY_DOUBLE, NPY_ARRAY_IN_ARRAY);
if (arr1 == NULL) return NULL;
arr2 = PyArray_FROM_OTF(arg2, NPY_DOUBLE, NPY_ARRAY_IN_ARRAY);
if (arr2 == NULL) goto fail;
#if NPY_API_VERSION >= 0x0000000c
oarr = PyArray_FROM_OTF(out, NPY_DOUBLE, NPY_ARRAY_INOUT_ARRAY2);
#else
oarr = PyArray_FROM_OTF(out, NPY_DOUBLE, NPY_ARRAY_INOUT_ARRAY);
#endif
if (oarr == NULL) goto fail;
/* code that makes use of arguments */
/* You will probably need at least
nd = PyArray_NDIM(<..>) -- number of dimensions
dims = PyArray_DIMS(<..>) -- npy_intp array of length nd
showing length in each dim.
dptr = (double *)PyArray_DATA(<..>) -- pointer to data.
If an error occurs goto fail.
*/
Py_DECREF(arr1);
Py_DECREF(arr2);
#if NPY_API_VERSION >= 0x0000000c
PyArray_ResolveWritebackIfCopy(oarr);
#endif
Py_DECREF(oarr);
Py_INCREF(Py_None);
return Py_None;
fail:
Py_XDECREF(arr1);
Py_XDECREF(arr2);
#if NPY_API_VERSION >= 0x0000000c
PyArray_DiscardWritebackIfCopy(oarr);
#endif
Py_XDECREF(oarr);
return NULL;
}
```# numpy.copy[#](#numpy-copy)
numpy.copy(*a*,*order='K'*,*subok=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L873-L962)[#](#numpy.copy)
-
Return an array copy of the given object.

Parameters:
-
**a**array_like
Input data.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Controls the memory layout of the copy. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*a*as closely as possible. (Note that this function andare very similar, but have different default values for their order= arguments.)`ndarray.copy`
**subok**bool, optional
If True, then sub-classes will be passed-through, otherwise the returned array will be forced to be a base-class array (defaults to False).

New in version 1.19.0.

Returns:
-
**arr**ndarray
Array interpretation of

*a*.
See also

`ndarray.copy`
Preferred method for creating an array copy

Notes

This is equivalent to:

>>> np.array(a, copy=True)
Examples

Create an array x, with a reference y and a copy z:

>>> x = np.array([1, 2, 3]) >>> y = x >>> z = np.copy(x)
Note that, when we modify x, y changes, but not z:

>>> x[0] = 10 >>> x[0] == y[0] True >>> x[0] == z[0] False
Note that, np.copy clears previously set WRITEABLE=False flag.

>>> a = np.array([1, 2, 3]) >>> a.flags["WRITEABLE"] = False >>> b = np.copy(a) >>> b.flags["WRITEABLE"] True >>> b[0] = 3 >>> b array([3, 2, 3])
Note that np.copy is a shallow copy and will not copy object elements within arrays. This is mainly important for arrays containing Python objects. The new array will contain the same object which may lead to surprises if that object can be modified (is mutable):

>>> a = np.array([1, 'm', [2, 3, 4]], dtype=object) >>> b = np.copy(a) >>> b[2][0] = 10 >>> a array([1, 'm', list([10, 3, 4])], dtype=object)
To ensure all elements within an

`object`
array are copied, use:`copy.deepcopy`
>>> import copy >>> a = np.array([1, 'm', [2, 3, 4]], dtype=object) >>> c = copy.deepcopy(a) >>> c[2][0] = 10 >>> c array([1, 'm', list([10, 3, 4])], dtype=object) >>> a array([1, 'm', list([2, 3, 4])], dtype=object)# numpy.memmap.strides[#](#numpy-memmap-strides)
attribute

memmap.strides[#](#numpy.memmap.strides)
-
Tuple of bytes to step in each dimension when traversing an array.

The byte offset of element

`(i[0], i[1], ..., i[n])`
in an array*a*is:offset = sum(np.array(i) * a.strides)
A more detailed explanation of strides can be found in the “ndarray.rst” file in the NumPy reference guide.

Warning

Setting

`arr.strides`
is discouraged and may be deprecated in the future.should be preferred to create a new view of the same data in a safer way.`numpy.lib.stride_tricks.as_strided`
See also

Notes

Imagine an array of 32-bit integers (each 4 bytes):

x = np.array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], dtype=np.int32)
This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array

*x*will be`(20, 4)`
.Examples

>>> y = np.reshape(np.arange(2*3*4), (2,3,4)) >>> y array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) >>> y.strides (48, 16, 4) >>> y[1,1,1] 17 >>> offset=sum(y.strides * np.array((1,1,1))) >>> offset/y.itemsize 17
>>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0) >>> x.strides (32, 4, 224, 1344) >>> i = np.array([3,5,2,2]) >>> offset = sum(i * x.strides) >>> x[3,5,2,2] 813 >>> offset / x.itemsize 813# numpy.ones[#](#numpy-ones)
numpy.ones(*shape*,*dtype=None*,*order='C'*,***,*like=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L136-L193)[#](#numpy.ones)
-
Return a new array of given shape and type, filled with ones.

Parameters:
-
**shape**int or sequence of ints
Shape of the new array, e.g.,

`(2, 3)`
or`2`
.
**dtype**data-type, optional
The desired data-type for the array, e.g.,

. Default is`numpy.int8`
.`numpy.float64`
**order**{‘C’, ‘F’}, optional, default: C
Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.

**like**array_like, optional
Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as

`like`
supports the`__array_function__`
protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.New in version 1.20.0.

Returns:
-
**out**ndarray
Array of ones with the given shape, dtype, and order.

See also

Examples

>>> np.ones(5) array([1., 1., 1., 1., 1.])
>>> np.ones((5,), dtype=int) array([1, 1, 1, 1, 1])
>>> np.ones((2, 1)) array([[1.], [1.]])
>>> s = (2,2) >>> np.ones(s) array([[1., 1.], [1., 1.]])# numpy.char.rstrip[#](#numpy-char-rstrip)
char.rstrip(*a*,*chars=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1463-L1505)[#](#numpy.char.rstrip)
-
For each element in

*a*, return a copy with the trailing characters removed.Calls

*str.rstrip*element-wise.Parameters:
-
**a**array-like of str or unicode
**chars**str or unicode, optional
The

*chars*argument is a string specifying the set of characters to be removed. If omitted or None, the*chars*argument defaults to removing whitespace. The*chars*argument is not a suffix; rather, all combinations of its values are stripped.
Returns:
-
**out**ndarray
Output array of str or unicode, depending on input type

See also

Examples

>>> c = np.array(['aAaAaA', 'abBABba'], dtype='S7'); c array(['aAaAaA', 'abBABba'], dtype='|S7') >>> np.char.rstrip(c, b'a') array(['aAaAaA', 'abBABb'], dtype='|S7') >>> np.char.rstrip(c, b'A') array(['aAaAa', 'abBABba'], dtype='|S7')# Using F2PY[#](#using-f2py)
This page contains a reference to all command-line options for the `f2py`
command, as well as a reference to internal functions of the `numpy.f2py`
module.

## Using `f2py`
as a command-line tool[#](#using-f2py-as-a-command-line-tool)
When used as a command-line tool, `f2py`
has three major modes, distinguished
by the usage of `-c`
and `-h`
switches.

### 1. Signature file generation[#](#signature-file-generation)
To scan Fortran sources and generate a signature file, use

```
f2py -h <filename.pyf> <options> <fortran files> \
[[ only: <fortran functions> : ] \
[ skip: <fortran functions> : ]]... \
[<fortran files> ...]
```
Note

A Fortran source file can contain many routines, and it is often not
necessary to allow all routines to be usable from Python. In such cases,
either specify which routines should be wrapped (in the `only: .. :`
part)
or which routines F2PY should ignore (in the `skip: .. :`
part).

If `<filename.pyf>`
is specified as `stdout`
, then signatures are written to
standard output instead of a file.

Among other options (see below), the following can be used in this mode:

`--overwrite-signature`
-
Overwrites an existing signature file.

### 2. Extension module construction[#](#extension-module-construction)
To construct an extension module, use

```
f2py -m <modulename> <options> <fortran files> \
[[ only: <fortran functions> : ] \
[ skip: <fortran functions> : ]]... \
[<fortran files> ...]
```
The constructed extension module is saved as `<modulename>module.c`
to the
current directory.

Here `<fortran files>`
may also contain signature files. Among other options
(see below), the following options can be used in this mode:

`--debug-capi`
-
Adds debugging hooks to the extension module. When using this extension module, various diagnostic information about the wrapper is written to the standard output, for example, the values of variables, the steps taken, etc.

`-include'<includefile>'`
-
Add a CPP

`#include`
statement to the extension module source.`<includefile>`
should be given in one of the following forms"filename.ext" <filename.ext>The include statement is inserted just before the wrapper functions. This feature enables using arbitrary C functions (defined in

`<includefile>`
) in F2PY generated wrappers.Note

This option is deprecated. Use

`usercode`
statement to specify C code snippets directly in signature files.
`--[no-]wrap-functions`
-
Create Fortran subroutine wrappers to Fortran functions.

`--wrap-functions`
is default because it ensures maximum portability and compiler independence.
`--include-paths <path1>:<path2>:..`
-
Search include files from given directories.

`--help-link [<list of resources names>]`
-
List system resources found by

`numpy_distutils/system_info.py`
. For example, try`f2py --help-link lapack_opt`
.
### 3. Building a module[#](#building-a-module)
To build an extension module, use

```
f2py -c <options> <fortran files> \
[[ only: <fortran functions> : ] \
[ skip: <fortran functions> : ]]... \
[ <fortran/c source files> ] [ <.o, .a, .so files> ]
```
If `<fortran files>`
contains a signature file, then the source for an
extension module is constructed, all Fortran and C sources are compiled, and
finally all object and library files are linked to the extension module
`<modulename>.so`
which is saved into the current directory.

If `<fortran files>`
does not contain a signature file, then an extension
module is constructed by scanning all Fortran source codes for routine
signatures, before proceeding to build the extension module.

Among other options (see below) and options described for previous modes, the following options can be used in this mode:

`--help-fcompiler`
-
List the available Fortran compilers.

`--help-compiler`
[depreciated]
-
List the available Fortran compilers.

`--fcompiler=<Vendor>`
-
Specify a Fortran compiler type by vendor.

`--f77exec=<path>`
-
Specify the path to a F77 compiler

`--fcompiler-exec=<path>`
[depreciated]
-
Specify the path to a F77 compiler

`--f90exec=<path>`
-
Specify the path to a F90 compiler

`--f90compiler-exec=<path>`
[depreciated]
-
Specify the path to a F90 compiler

`--f77flags=<string>`
-
Specify F77 compiler flags

`--f90flags=<string>`
-
Specify F90 compiler flags

`--opt=<string>`
-
Specify optimization flags

`--arch=<string>`
-
Specify architecture specific optimization flags

`--noopt`
-
Compile without optimization flags

`--noarch`
-
Compile without arch-dependent optimization flags

`--debug`
-
Compile with debugging information

`-l<libname>`
-
Use the library

`<libname>`
when linking.
`-D<macro>[=<defn=1>]`
-
Define macro

`<macro>`
as`<defn>`
.
`-U<macro>`
-
Define macro

`<macro>`
`-I<dir>`
-
Append directory

`<dir>`
to the list of directories searched for include files.
`-L<dir>`
-
Add directory

`<dir>`
to the list of directories to be searched for`-l`
.
`link-<resource>`
-
Link the extension module with <resource> as defined by

`numpy_distutils/system_info.py`
. E.g. to link with optimized LAPACK libraries (vecLib on MacOSX, ATLAS elsewhere), use`--link-lapack_opt`
. See also`--help-link`
switch.
Note

The `f2py -c`
option must be applied either to an existing `.pyf`
file
(plus the source/object/library files) or one must specify the
`-m <modulename>`
option (plus the sources/object/library files). Use one of
the following options:

```
f2py -c -m fib1 fib1.f
```
or

```
f2py -m fib1 fib1.f -h fib1.pyf
f2py -c fib1.pyf fib1.f
```
For more information, see the [Building C and C++ Extensions](https://docs.python.org/3/extending/building.html) Python
documentation for details.

When building an extension module, a combination of the following macros may be required for non-gcc Fortran compilers:

```
-DPREPEND_FORTRAN
-DNO_APPEND_FORTRAN
-DUPPERCASE_FORTRAN
```
To test the performance of F2PY generated interfaces, use
`-DF2PY_REPORT_ATEXIT`
. Then a report of various timings is printed out at the
exit of Python. This feature may not work on all platforms, and currently only
Linux is supported.

To see whether F2PY generated interface performs copies of array arguments, use
`-DF2PY_REPORT_ON_ARRAY_COPY=<int>`
. When the size of an array argument is
larger than `<int>`
, a message about the copying is sent to `stderr`
.

### Other options[#](#other-options)
`-m <modulename>`
-
Name of an extension module. Default is

`untitled`
.Warning

Don’t use this option if a signature file (

`*.pyf`
) is used.
`--[no-]lower`
-
Do [not] lower the cases in

`<fortran files>`
. By default,`--lower`
is assumed with`-h`
switch, and`--no-lower`
without the`-h`
switch.
`-include<header>`
-
Writes additional headers in the C wrapper, can be passed multiple times, generates #include <header> each time. Note that this is meant to be passed in single quotes and without spaces, for example

`'-include<stdbool.h>'`
`--build-dir <dirname>`
-
All F2PY generated files are created in

`<dirname>`
. Default is`tempfile.mkdtemp()`
.
`--f2cmap <filename>`
-
Load Fortran-to-C

`KIND`
specifications from the given file.
`--quiet`
-
Run quietly.

`--verbose`
-
Run with extra verbosity.

`--skip-empty-wrappers`
-
Do not generate wrapper files unless required by the inputs. This is a backwards compatibility flag to restore pre 1.22.4 behavior.

`-v`
-
Print the F2PY version and exit.

Execute `f2py`
without any options to get an up-to-date list of available
options.

## Python module `numpy.f2py`
[#](#python-module-numpy-f2py)
The f2py program is written in Python and can be run from inside your code to compile Fortran code at runtime, as follows:

```
from numpy import f2py
with open("add.f") as sourcefile:
sourcecode = sourcefile.read()
f2py.compile(sourcecode, modulename='add')
import add
```
The source string can be any valid Fortran code. If you want to save
the extension-module source code then a suitable file-name can be
provided by the `source_fn`
keyword to the compile function.

When using `numpy.f2py`
as a module, the following functions can be invoked.

Warning

The current Python interface to the `f2py`
module is not mature and may
change in the future.

Fortran to Python Interface Generator.

numpy.f2py.compile(*source*,*modulename='untitled'*,*extra_args=''*,*verbose=True*,*source_fn=None*,*extension='.f'*,*full_output=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/f2py/__init__.py#L18-L121)[#](#numpy.f2py.compile)
-
Build extension module from a Fortran 77 source string with f2py.

Parameters:
-
**source**str or bytes
Fortran source of module / subroutine to compile

Changed in version 1.16.0: Accept str as well as bytes

**modulename**str, optional
The name of the compiled python module

**extra_args**str or list, optional
Additional parameters passed to f2py

Changed in version 1.16.0: A list of args may also be provided.

**verbose**bool, optional
Print f2py output to screen

**source_fn**str, optional
Name of the file where the fortran source is written. The default is to use a temporary file with the extension provided by the

`extension`
parameter
**extension**`{'.f', '.f90'}`
, optional
Filename extension if

*source_fn*is not provided. The extension tells which fortran standard is used. The default is`.f`
, which implies F77 standard.New in version 1.11.0.

**full_output**bool, optional
If True, return a

containing the stdout and stderr of the compile process, instead of just the status code.`subprocess.CompletedProcess`
New in version 1.20.0.

Returns:
-
**result**int or`subprocess.CompletedProcess`
0 on success, or a

if`subprocess.CompletedProcess`
`full_output=True`
Examples

>>> import numpy.f2py >>> fsource = ''' ... subroutine foo ... print*, "Hello world!" ... end ... ''' >>> numpy.f2py.compile(fsource, modulename='hello', verbose=0) 0 >>> import hello >>> hello.foo() Hello world!
numpy.f2py.get_include()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/f2py/__init__.py#L124-L168)[#](#numpy.f2py.get_include)
-
Return the directory that contains the

`fortranobject.c`
and`.h`
files.Note

This function is not needed when building an extension with

directly from`numpy.distutils`
`.f`
and/or`.pyf`
files in one go.Python extension modules built with f2py-generated code need to use

`fortranobject.c`
as a source file, and include the`fortranobject.h`
header. This function can be used to obtain the directory containing both of these files.Returns:
-
**include_path**str
Absolute path to the directory containing

`fortranobject.c`
and`fortranobject.h`
.
See also

`numpy.get_include`
function that returns the numpy include directory

Notes

New in version 1.21.1.

Unless the build system you are using has specific support for f2py, building a Python extension using a

`.pyf`
signature file is a two-step process. For a module`mymod`
:Step 1: run

`python -m numpy.f2py mymod.pyf --quiet`
. This generates`_mymodmodule.c`
and (if needed)`_fblas-f2pywrappers.f`
files next to`mymod.pyf`
.
Step 2: build your Python extension module. This requires the following source files:

`_mymodmodule.c`
`_mymod-f2pywrappers.f`
(if it was generated in Step 1)
`fortranobject.c`
numpy.f2py.run_main(*comline_list*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/f2py/f2py2e.py#L432-L500)[#](#numpy.f2py.run_main)
-
Equivalent to running:

f2py <args>
where

`<args>=string.join(<list>,' ')`
, but in Python. Unless`-h`
is used, this function returns a dictionary containing information on generated modules and their dependencies on source files.You cannot build extension modules with this function, that is, using

`-c`
is not allowed. Use the`compile`
command instead.Examples

The command

`f2py -m scalar scalar.f`
can be executed from Python as follows.>>> import numpy.f2py >>> r = numpy.f2py.run_main(['-m','scalar','doc/source/f2py/scalar.f']) Reading fortran codes... Reading file 'doc/source/f2py/scalar.f' (format:fix,strict) Post-processing... Block: scalar Block: FOO Building modules... Building module "scalar"... Wrote C/API module "scalar" to file "./scalarmodule.c" >>> print(r) {'scalar': {'h': ['/home/users/pearu/src_cvs/f2py/src/fortranobject.h'], 'csrc': ['./scalarmodule.c', '/home/users/pearu/src_cvs/f2py/src/fortranobject.c']}}
## Automatic extension module generation[#](#automatic-extension-module-generation)
If you want to distribute your f2py extension module, then you only
need to include the .pyf file and the Fortran code. The distutils
extensions in NumPy allow you to define an extension module entirely
in terms of this interface file. A valid `setup.py`
file allowing
distribution of the `add.f`
module (as part of the package
`f2py_examples`
so that it would be loaded as `f2py_examples.add`
) is:

```
def configuration(parent_package='', top_path=None)
from numpy.distutils.misc_util import Configuration
config = Configuration('f2py_examples',parent_package, top_path)
config.add_extension('add', sources=['add.pyf','add.f'])
return config
if __name__ == '__main__':
from numpy.distutils.core import setup
setup(**configuration(top_path='').todict())
```
Installation of the new package is easy using:

```
pip install .
```
assuming you have the proper permissions to write to the main site-
packages directory for the version of Python you are using. For the
resulting package to work, you need to create a file named `__init__.py`
(in the same directory as `add.pyf`
). Notice the extension module is
defined entirely in terms of the `add.pyf`
and `add.f`
files. The
conversion of the .pyf file to a .c file is handled by [ numpy.distutils](../reference/distutils.html#module-numpy.distutils).# numpy.isin[#](#numpy-isin)
numpy.isin(*element*,*test_elements*,*assume_unique=False*,*invert=False*,***,*kind=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/arraysetops.py#L766-L891)[#](#numpy.isin)
-
Calculates

`element in test_elements`
, broadcasting over*element*only. Returns a boolean array of the same shape as*element*that is True where an element of*element*is in*test_elements*and False otherwise.Parameters:
-
**element**array_like
Input array.

**test_elements**array_like
The values against which to test each value of

*element*. This argument is flattened if it is an array or array_like. See notes for behavior with non-array-like parameters.
**assume_unique**bool, optional
If True, the input arrays are both assumed to be unique, which can speed up the calculation. Default is False.

**invert**bool, optional
If True, the values in the returned array are inverted, as if calculating

*element not in test_elements*. Default is False.`np.isin(a, b, invert=True)`
is equivalent to (but faster than)`np.invert(np.isin(a, b))`
.
**kind**{None, ‘sort’, ‘table’}, optional
The algorithm to use. This will not affect the final result, but will affect the speed and memory use. The default, None, will select automatically based on memory considerations.

If ‘sort’, will use a mergesort-based approach. This will have a memory usage of roughly 6 times the sum of the sizes of

*ar1*and*ar2*, not accounting for size of dtypes.
If ‘table’, will use a lookup table approach similar to a counting sort. This is only available for boolean and integer arrays. This will have a memory usage of the size of

*ar1*plus the max-min value of*ar2*.*assume_unique*has no effect when the ‘table’ option is used.
If None, will automatically choose ‘table’ if the required memory allocation is less than or equal to 6 times the sum of the sizes of

*ar1*and*ar2*, otherwise will use ‘sort’. This is done to not use a large amount of memory by default, even though ‘table’ may be faster in most cases. If ‘table’ is chosen,*assume_unique*will have no effect.
Returns:
-
**isin**ndarray, bool
Has the same shape as

*element*. The values*element[isin]*are in*test_elements*.
See also

`in1d`
Flattened version of this function.

`numpy.lib.arraysetops`
Module with a number of other functions for performing set operations on arrays.

Notes

is an element-wise function version of the python keyword`isin`
*in*.`isin(a, b)`
is roughly equivalent to`np.array([item in b for item in a])`
if*a*and*b*are 1-D sequences.*element*and*test_elements*are converted to arrays if they are not already. If*test_elements*is a set (or other non-sequence collection) it will be converted to an object array with one element, rather than an array of the values contained in*test_elements*. This is a consequence of theconstructor’s way of handling non-sequence collections. Converting the set to a list usually gives the desired behavior.`array`
Using

`kind='table'`
tends to be faster than*kind=’sort’*if the following relationship is true:`log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927`
, but may use greater memory. The default value for*kind*will be automatically selected based only on memory usage, so one may manually set`kind='table'`
if memory constraints can be relaxed.New in version 1.13.0.

Examples

>>> element = 2*np.arange(4).reshape((2, 2)) >>> element array([[0, 2], [4, 6]]) >>> test_elements = [1, 2, 4, 8] >>> mask = np.isin(element, test_elements) >>> mask array([[False, True], [ True, False]]) >>> element[mask] array([2, 4])
The indices of the matched values can be obtained with

:`nonzero`
>>> np.nonzero(mask) (array([0, 1]), array([1, 0]))
The test can also be inverted:

>>> mask = np.isin(element, test_elements, invert=True) >>> mask array([[ True, False], [False, True]]) >>> element[mask] array([0, 6])
Because of how

handles sets, the following does not work as expected:`array`
>>> test_set = {1, 2, 4, 8} >>> np.isin(element, test_set) array([[False, False], [False, False]])
Casting the set to a list gives the expected result:

>>> np.isin(element, list(test_set)) array([[False, True], [ True, False]])# numpy.random.Generator.multinomial[#](#numpy-random-generator-multinomial)
method

random.Generator.multinomial(*n*,*pvals*,*size=None*)[#](#numpy.random.Generator.multinomial)
-
Draw samples from a multinomial distribution.

The multinomial distribution is a multivariate generalization of the binomial distribution. Take an experiment with one of

`p`
possible outcomes. An example of such an experiment is throwing a dice, where the outcome can be 1 through 6. Each sample drawn from the distribution represents*n*such experiments. Its values,`X_i = [X_0, X_1, ..., X_p]`
, represent the number of times the outcome was`i`
.Parameters:
-
**n**int or array-like of ints
Number of experiments.

**pvals**array-like of floats
Probabilities of each of the

`p`
different outcomes with shape`(k0, k1, ..., kn, p)`
. Each element`pvals[i,j,...,:]`
must sum to 1 (however, the last element is always assumed to account for the remaining probability, as long as`sum(pvals[..., :-1], axis=-1) <= 1.0`
. Must have at least 1 dimension where pvals.shape[-1] > 0.
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn each with`p`
elements. Default is None where the output size is determined by the broadcast shape of`n`
and all by the final dimension of`pvals`
, which is denoted as`b=(b0, b1, ..., bq)`
. If size is not None, then it must be compatible with the broadcast shape`b`
. Specifically, size must have`q`
or more elements and size[-(q-j):] must equal`bj`
.
Returns:
-
**out**ndarray
The drawn samples, of shape size, if provided. When size is provided, the output shape is size + (p,) If not specified, the shape is determined by the broadcast shape of

`n`
and`pvals`
,`(b0, b1, ..., bq)`
augmented with the dimension of the multinomial,`p`
, so that that output shape is`(b0, b1, ..., bq, p)`
.Each entry

`out[i,j,...,:]`
is a`p`
-dimensional value drawn from the distribution.Changed in version 1.22.0: Added support for broadcasting

*pvals*against*n*
Examples

Throw a dice 20 times:

>>> rng = np.random.default_rng() >>> rng.multinomial(20, [1/6.]*6, size=1) array([[4, 1, 7, 5, 2, 1]]) # random
It landed 4 times on 1, once on 2, etc.

Now, throw the dice 20 times, and 20 times again:

>>> rng.multinomial(20, [1/6.]*6, size=2) array([[3, 4, 3, 3, 4, 3], [2, 4, 3, 4, 0, 7]]) # random
For the first run, we threw 3 times 1, 4 times 2, etc. For the second, we threw 2 times 1, 4 times 2, etc.

Now, do one experiment throwing the dice 10 time, and 10 times again, and another throwing the dice 20 times, and 20 times again:

>>> rng.multinomial([[10], [20]], [1/6.]*6, size=(2, 2)) array([[[2, 4, 0, 1, 2, 1], [1, 3, 0, 3, 1, 2]], [[1, 4, 4, 4, 4, 3], [3, 3, 2, 5, 5, 2]]]) # random
The first array shows the outcomes of throwing the dice 10 times, and the second shows the outcomes from throwing the dice 20 times.

A loaded die is more likely to land on number 6:

>>> rng.multinomial(100, [1/7.]*5 + [2/7.]) array([11, 16, 14, 17, 16, 26]) # random
Simulate 10 throws of a 4-sided die and 20 throws of a 6-sided die

>>> rng.multinomial([10, 20],[[1/4]*4 + [0]*2, [1/6]*6]) array([[2, 1, 4, 3, 0, 0], [3, 3, 3, 6, 1, 4]], dtype=int64) # random
Generate categorical random variates from two categories where the first has 3 outcomes and the second has 2.

>>> rng.multinomial(1, [[.1, .5, .4 ], [.3, .7, .0]]) array([[0, 0, 1], [0, 1, 0]], dtype=int64) # random
`argmax(axis=-1)`
is then used to return the categories.>>> pvals = [[.1, .5, .4 ], [.3, .7, .0]] >>> rvs = rng.multinomial(1, pvals, size=(4,2)) >>> rvs.argmax(axis=-1) array([[0, 1], [2, 0], [2, 1], [2, 0]], dtype=int64) # random
The same output dimension can be produced using broadcasting.

>>> rvs = rng.multinomial([[1]] * 4, pvals) >>> rvs.argmax(axis=-1) array([[0, 1], [2, 0], [2, 1], [2, 0]], dtype=int64) # random
The probability inputs should be normalized. As an implementation detail, the value of the last entry is ignored and assumed to take up any leftover probability mass, but this should not be relied on. A biased coin which has twice as much weight on one side as on the other should be sampled like so:

>>> rng.multinomial(100, [1.0 / 3, 2.0 / 3]) # RIGHT array([38, 62]) # random
not like:

>>> rng.multinomial(100, [1.0, 2.0]) # WRONG Traceback (most recent call last): ValueError: pvals < 0, pvals > 1 or pvals contains NaNs# numpy.random.random_integers[#](#numpy-random-random-integers)
random.random_integers(*low*,*high=None*,*size=None*)[#](#numpy.random.random_integers)
-
Random integers of type

*np.int_*between*low*and*high*, inclusive.Return random integers of type

*np.int_*from the “discrete uniform” distribution in the closed interval [*low*,*high*]. If*high*is None (the default), then results are from [1,*low*]. The*np.int_*type translates to the C long integer type and its precision is platform dependent.This function has been deprecated. Use randint instead.

Deprecated since version 1.11.0.

Parameters:
-
**low**int
Lowest (signed) integer to be drawn from the distribution (unless

`high=None`
, in which case this parameter is the*highest*such integer).
**high**int, optional
If provided, the largest (signed) integer to be drawn from the distribution (see above for behavior if

`high=None`
).
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**out**int or ndarray of ints
`size`
-shaped array of random integers from the appropriate distribution, or a single such random int if`size`
not provided.
See also

`randint`
Similar to

, only for the half-open interval [`random_integers`
*low*,*high*), and 0 is the lowest value if*high*is omitted.
Notes

To sample from N evenly spaced floating-point numbers between a and b, use:

a + (b - a) * (np.random.random_integers(N) - 1) / (N - 1.)
Examples

>>> np.random.random_integers(5) 4 # random >>> type(np.random.random_integers(5)) <class 'numpy.int64'> >>> np.random.random_integers(5, size=(3,2)) array([[5, 4], # random [3, 3], [4, 5]])
Choose five random numbers from the set of five evenly-spaced numbers between 0 and 2.5, inclusive (

*i.e.*, from the set \({0, 5/8, 10/8, 15/8, 20/8}\)):>>> 2.5 * (np.random.random_integers(5, size=(5,)) - 1) / 4. array([ 0.625, 1.25 , 0.625, 0.625, 2.5 ]) # random
Roll two six sided dice 1000 times and sum the results:

>>> d1 = np.random.random_integers(1, 6, 1000) >>> d2 = np.random.random_integers(1, 6, 1000) >>> dsums = d1 + d2
Display results as a histogram:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(dsums, 11, density=True) >>> plt.show()# numpy.set_string_function[#](#numpy-set-string-function)
numpy.set_string_function(*f*,*repr=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/arrayprint.py#L1668-L1725)[#](#numpy.set_string_function)
-
Set a Python function to be used when pretty printing arrays.

Parameters:
-
**f**function or None
Function to be used to pretty print arrays. The function should expect a single array argument and return a string of the representation of the array. If None, the function is reset to the default NumPy function to print arrays.

**repr**bool, optional
If True (default), the function for pretty printing (

`__repr__`
) is set, if False the function that returns the default string representation (`__str__`
) is set.
See also

Examples

>>> def pprint(arr): ... return 'HA! - What are you going to do now?' ... >>> np.set_string_function(pprint) >>> a = np.arange(10) >>> a HA! - What are you going to do now? >>> _ = a >>> # [0 1 2 3 4 5 6 7 8 9]
We can reset the function to the default:

>>> np.set_string_function(None) >>> a array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
*repr*affects either pretty printing or normal string representation. Note that`__repr__`
is still affected by setting`__str__`
because the width of each array element in the returned string becomes equal to the length of the result of`__str__()`
.>>> x = np.arange(4) >>> np.set_string_function(lambda x:'random', repr=False) >>> x.__str__() 'random' >>> x.__repr__() 'array([0, 1, 2, 3])'# numpy.linalg.tensorinv[#](#numpy-linalg-tensorinv)
linalg.tensorinv(*a*,*ind=2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L418-L483)[#](#numpy.linalg.tensorinv)
-
Compute the ‘inverse’ of an N-dimensional array.

The result is an inverse for

*a*relative to the tensordot operation`tensordot(a, b, ind)`
, i. e., up to floating-point accuracy,`tensordot(tensorinv(a), a, ind)`
is the “identity” tensor for the tensordot operation.Parameters:
-
**a**array_like
Tensor to ‘invert’. Its shape must be ‘square’, i. e.,

`prod(a.shape[:ind]) == prod(a.shape[ind:])`
.
**ind**int, optional
Number of first indices that are involved in the inverse sum. Must be a positive integer, default is 2.

Returns:
-
**b**ndarray
*a*’s tensordot inverse, shape`a.shape[ind:] + a.shape[:ind]`
.
Raises:
-
LinAlgError
-
If

*a*is singular or not ‘square’ (in the above sense).
See also

Examples

>>> a = np.eye(4*6) >>> a.shape = (4, 6, 8, 3) >>> ainv = np.linalg.tensorinv(a, ind=2) >>> ainv.shape (8, 3, 4, 6) >>> b = np.random.randn(4, 6) >>> np.allclose(np.tensordot(ainv, b), np.linalg.tensorsolve(a, b)) True
>>> a = np.eye(4*6) >>> a.shape = (24, 8, 3) >>> ainv = np.linalg.tensorinv(a, ind=1) >>> ainv.shape (8, 3, 24) >>> b = np.random.randn(24) >>> np.allclose(np.tensordot(ainv, b, 1), np.linalg.tensorsolve(a, b)) True# numpy.hstack[#](#numpy-hstack)
numpy.hstack(*tup*,***,*dtype=None*,*casting='same_kind'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/shape_base.py#L292-L359)[#](#numpy.hstack)
-
Stack arrays in sequence horizontally (column wise).

This is equivalent to concatenation along the second axis, except for 1-D arrays where it concatenates along the first axis. Rebuilds arrays divided by

.`hsplit`
This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions

,`concatenate`
and`stack`
provide more general stacking and concatenation operations.`block`
Parameters:
-
**tup**sequence of ndarrays
The arrays must have the same shape along all but the second axis, except 1-D arrays which can be any length.

**dtype**str or dtype
If provided, the destination array will have this dtype. Cannot be provided together with

*out*.
**.. versionadded:: 1.24**
**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘same_kind’.

**.. versionadded:: 1.24**
Returns:
-
**stacked**ndarray
The array formed by stacking the given arrays.

See also

`concatenate`
Join a sequence of arrays along an existing axis.

`stack`
Join a sequence of arrays along a new axis.

`block`
Assemble an nd-array from nested lists of blocks.

`vstack`
Stack arrays in sequence vertically (row wise).

`dstack`
Stack arrays in sequence depth wise (along third axis).

`column_stack`
Stack 1-D arrays as columns into a 2-D array.

`hsplit`
Split an array into multiple sub-arrays horizontally (column-wise).

Examples

>>> a = np.array((1,2,3)) >>> b = np.array((4,5,6)) >>> np.hstack((a,b)) array([1, 2, 3, 4, 5, 6]) >>> a = np.array([[1],[2],[3]]) >>> b = np.array([[4],[5],[6]]) >>> np.hstack((a,b)) array([[1, 4], [2, 5], [3, 6]])# numpy.memmap.sort[#](#numpy-memmap-sort)
method

memmap.sort(*axis=-1*,*kind=None*,*order=None*)[#](#numpy.memmap.sort)
-
Sort an array in-place. Refer to

for full documentation.`numpy.sort`
Parameters:
-
**axis**int, optional
Axis along which to sort. Default is -1, which means sort along the last axis.

**kind**{‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, optional
Sorting algorithm. The default is ‘quicksort’. Note that both ‘stable’ and ‘mergesort’ use timsort under the covers and, in general, the actual implementation will vary with datatype. The ‘mergesort’ option is retained for backwards compatibility.

Changed in version 1.15.0: The ‘stable’ option was added.

**order**str or list of str, optional
When

*a*is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.
See also

`numpy.sort`
Return a sorted copy of an array.

`numpy.argsort`
Indirect sort.

`numpy.lexsort`
Indirect stable sort on multiple keys.

`numpy.searchsorted`
Find elements in sorted array.

`numpy.partition`
Partial sort.

Notes

See

for notes on the different sorting algorithms.`numpy.sort`
Examples

>>> a = np.array([[1,4], [3,1]]) >>> a.sort(axis=1) >>> a array([[1, 4], [1, 3]]) >>> a.sort(axis=0) >>> a array([[1, 3], [1, 4]])
Use the

*order*keyword to specify a field to use when sorting a structured array:>>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)]) >>> a.sort(order='y') >>> a array([(b'c', 1), (b'a', 2)], dtype=[('x', 'S1'), ('y', '<i8')])# numpy.polynomial.hermite.hermfit[#](#numpy-polynomial-hermite-hermfit)
polynomial.hermite.hermfit(*x*,*y*,*deg*,*rcond=None*,*full=False*,*w=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L1275-L1404)[#](#numpy.polynomial.hermite.hermfit)
-
Least squares fit of Hermite series to data.

Return the coefficients of a Hermite series of degree

*deg*that is the least squares fit to the data values*y*given at points*x*. If*y*is 1-D the returned coefficients will also be 1-D. If*y*is 2-D multiple fits are done, one for each column of*y*, and the resulting coefficients are stored in the corresponding columns of a 2-D return. The fitted polynomial(s) are in the form\[p(x) = c_0 + c_1 * H_1(x) + ... + c_n * H_n(x),\]where

*n*is*deg*.Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,) or (M, K)
y-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.

**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (*M*,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.
Returns:
-
**coef**ndarray, shape (M,) or (M, K)
Hermite coefficients ordered from low to high. If

*y*was 2-D, the coefficients for the data in column k of*y*are in column*k*.
**[residuals, rank, singular_values, rcond]**list
These values are only returned if

`full == True`
residuals – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

singular_values – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`numpy.linalg.lstsq`
Warns:
-
RankWarning
-
The rank of the coefficient matrix in the least-squares fit is deficient. The warning is only raised if

`full == False`
. The warnings can be turned off by>>> import warnings >>> warnings.simplefilter('ignore', np.RankWarning)
See also

`numpy.polynomial.chebyshev.chebfit`
`numpy.polynomial.legendre.legfit`
`numpy.polynomial.laguerre.lagfit`
`numpy.polynomial.polynomial.polyfit`
`numpy.polynomial.hermite_e.hermefit`
`hermval`
Evaluates a Hermite series.

`hermvander`
Vandermonde matrix of Hermite series.

`hermweight`
Hermite weight function

`numpy.linalg.lstsq`
Computes a least-squares fit from the matrix.

`scipy.interpolate.UnivariateSpline`
Computes spline fits.

Notes

The solution is the coefficients of the Hermite series

*p*that minimizes the sum of the weighted squared errors\[E = \sum_j w_j^2 * |y_j - p(x_j)|^2,\]where the \(w_j\) are the weights. This problem is solved by setting up the (typically) overdetermined matrix equation

\[V(x) * c = w * y,\]where

*V*is the weighted pseudo Vandermonde matrix of*x*,*c*are the coefficients to be solved for,*w*are the weights,*y*are the observed values. This equation is then solved using the singular value decomposition of*V*.If some of the singular values of

*V*are so small that they are neglected, then awill be issued. This means that the coefficient values may be poorly determined. Using a lower order fit will usually get rid of the warning. The`RankWarning`
*rcond*parameter can also be set to a value smaller than its default, but the resulting fit may be spurious and have large contributions from roundoff error.Fits using Hermite series are probably most useful when the data can be approximated by

`sqrt(w(x)) * p(x)`
, where*w(x)*is the Hermite weight. In that case the weight`sqrt(w(x[i]))`
should be used together with data values`y[i]/sqrt(w(x[i]))`
. The weight function is available as.`hermweight`
References

[1]Wikipedia, “Curve fitting”,

[https://en.wikipedia.org/wiki/Curve_fitting](https://en.wikipedia.org/wiki/Curve_fitting)Examples

>>> from numpy.polynomial.hermite import hermfit, hermval >>> x = np.linspace(-10, 10) >>> err = np.random.randn(len(x))/10 >>> y = hermval(x, [1, 2, 3]) + err >>> hermfit(x, y, 2) array([1.0218, 1.9986, 2.9999]) # may vary# numpy.polynomial.hermite_e.hermesub[#](#numpy-polynomial-hermite-e-hermesub)
polynomial.hermite_e.hermesub(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L352-L389)[#](#numpy.polynomial.hermite_e.hermesub)
-
Subtract one Hermite series from another.

Returns the difference of two Hermite series

*c1*-*c2*. The sequences of coefficients are from lowest order term to highest, i.e., [1,2,3] represents the series`P_0 + 2*P_1 + 3*P_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Hermite series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Of Hermite series coefficients representing their difference.

Notes

Unlike multiplication, division, etc., the difference of two Hermite series is a Hermite series (without having to “reproject” the result onto the basis set) so subtraction, just like that of “standard” polynomials, is simply “component-wise.”

Examples

>>> from numpy.polynomial.hermite_e import hermesub >>> hermesub([1, 2, 3, 4], [1, 2, 3]) array([0., 0., 0., 4.])# numpy.sinh[#](#numpy-sinh)
numpy.sinh(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'sinh'>*[#](#numpy.sinh)
-
Hyperbolic sine, element-wise.

Equivalent to

`1/2 * (np.exp(x) - np.exp(-x))`
or`-1j * np.sin(1j*x)`
.Parameters:
-
**x**array_like
Input array.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray
The corresponding hyperbolic sine values. This is a scalar if

*x*is a scalar.
Notes

If

*out*is provided, the function writes the result into it, and returns a reference to*out*. (See Examples)References

M. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions. New York, NY: Dover, 1972, pg. 83.

Examples

>>> np.sinh(0) 0.0 >>> np.sinh(np.pi*1j/2) 1j >>> np.sinh(np.pi*1j) # (exact value is 0) 1.2246063538223773e-016j >>> # Discrepancy due to vagaries of floating point arithmetic.
>>> # Example of providing the optional output parameter >>> out1 = np.array([0], dtype='d') >>> out2 = np.sinh([0.1], out1) >>> out2 is out1 True
>>> # Example of ValueError due to provision of shape mis-matched `out` >>> np.sinh(np.zeros((3,3)),np.zeros((2,2))) Traceback (most recent call last): File "<stdin>", line 1, in <module> ValueError: operands could not be broadcast together with shapes (3,3) (2,2)# numpy.any[#](#numpy-any)
numpy.any(*a*,*axis=None*,*out=None*,*keepdims=<no value>*,***,*where=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L2322-L2413)[#](#numpy.any)
-
Test whether any array element along a given axis evaluates to True.

Returns single boolean if

*axis*is`None`
Parameters:
-
**a**array_like
Input array or object that can be converted to an array.

**axis**None or int or tuple of ints, optional
Axis or axes along which a logical OR reduction is performed. The default (

`axis=None`
) is to perform a logical OR over all the dimensions of the input array.*axis*may be negative, in which case it counts from the last to the first axis.New in version 1.7.0.

If this is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before.

**out**ndarray, optional
Alternate output array in which to place the result. It must have the same shape as the expected output and its type is preserved (e.g., if it is of type float, then it will remain so, returning 1.0 for True and 0.0 for False, regardless of the type of

*a*). See[Output type determination](../../user/basics.ufuncs.html#ufuncs-output-type)for more details.
**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.

If the default value is passed, then

*keepdims*will not be passed through to themethod of sub-classes of`any`
, however any non-default value will be. If the sub-class’ method does not implement`ndarray`
*keepdims*any exceptions will be raised.
**where**array_like of bool, optional
Elements to include in checking for any

*True*values. Seefor details.`reduce`
New in version 1.20.0.

Returns:
-
**any**bool or ndarray
A new boolean or

is returned unless`ndarray`
*out*is specified, in which case a reference to*out*is returned.
See also

`ndarray.any`
equivalent method

`all`
Test whether all elements along a given axis evaluate to True.

Notes

Not a Number (NaN), positive infinity and negative infinity evaluate to

*True*because these are not equal to zero.Examples

>>> np.any([[True, False], [True, True]]) True
>>> np.any([[True, False], [False, False]], axis=0) array([ True, False])
>>> np.any([-1, 0, 5]) True
>>> np.any(np.nan) True
>>> np.any([[True, False], [False, False]], where=[[False], [True]]) False
>>> o=np.array(False) >>> z=np.any([-1, 4, 5], out=o) >>> z, o (array(True), array(True)) >>> # Check now that z is a reference to o >>> z is o True >>> id(z), id(o) # identity of z and o (191614240, 191614240)# numpy.conj[#](#numpy-conj)
numpy.conj(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'conjugate'>*[#](#numpy.conj)
-
Return the complex conjugate, element-wise.

The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.

Parameters:
-
**x**array_like
Input value.

**out**ndarray, None, or tuple of ndarray and None, optional
A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.

**where**array_like, optional
This condition is broadcast over the input. At locations where the condition is True, the

*out*array will be set to the ufunc result. Elsewhere, the*out*array will retain its original value. Note that if an uninitialized*out*array is created via the default`out=None`
, locations within it where the condition is False will remain uninitialized.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).
Returns:
-
**y**ndarray
The complex conjugate of

*x*, with same dtype as*y*. This is a scalar if*x*is a scalar.
Notes

is an alias for`conj`
:`conjugate`
>>> np.conj is np.conjugate True
Examples

>>> np.conjugate(1+2j) (1-2j)
>>> x = np.eye(2) + 1j * np.eye(2) >>> np.conjugate(x) array([[ 1.-1.j, 0.-0.j], [ 0.-0.j, 1.-1.j]])# numpy.ma.masked_array.item[#](#numpy-ma-masked-array-item)
method

ma.masked_array.item(**args*)[#](#numpy.ma.masked_array.item)
-
Copy an element of an array to a standard Python scalar and return it.

Parameters:
-
***args**Arguments (variable number and type)
none: in this case, the method only works for arrays with one element (

*a.size == 1*), which element is copied into a standard Python scalar object and returned.
int_type: this argument is interpreted as a flat index into the array, specifying which element to copy and return.

tuple of int_types: functions as does a single int_type argument, except that the argument is interpreted as an nd-index into the array.

Returns:
-
**z**Standard Python scalar object
A copy of the specified element of the array as a suitable Python scalar

Notes

When the data type of

*a*is longdouble or clongdouble, item() returns a scalar array object because there is no available Python scalar that would not lose information. Void arrays return a buffer object for item(), unless fields are defined, in which case a tuple is returned.is very similar to a[args], except, instead of an array scalar, a standard Python scalar is returned. This can be useful for speeding up access to elements of the array and doing arithmetic on elements of the array using Python’s optimized math.`item`
Examples

>>> np.random.seed(123) >>> x = np.random.randint(9, size=(3, 3)) >>> x array([[2, 2, 6], [1, 3, 6], [1, 0, 1]]) >>> x.item(3) 1 >>> x.item(7) 0 >>> x.item((0, 1)) 2 >>> x.item((2, 2)) 1# numpy.fft.irfft[#](#numpy-fft-irfft)
fft.irfft(*a*,*n=None*,*axis=-1*,*norm=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/fft/_pocketfft.py#L413-L514)[#](#numpy.fft.irfft)
-
Computes the inverse of

.`rfft`
This function computes the inverse of the one-dimensional

*n*-point discrete Fourier Transform of real input computed by. In other words,`rfft`
`irfft(rfft(a), len(a)) == a`
to within numerical accuracy. (See Notes below for why`len(a)`
is necessary here.)The input is expected to be in the form returned by

, i.e. the real zero-frequency term followed by the complex positive frequency terms in order of increasing frequency. Since the discrete Fourier Transform of real input is Hermitian-symmetric, the negative frequency terms are taken to be the complex conjugates of the corresponding positive frequency terms.`rfft`
Parameters:
-
**a**array_like
The input array.

**n**int, optional
Length of the transformed axis of the output. For

*n*output points,`n//2+1`
input points are necessary. If the input is longer than this, it is cropped. If it is shorter than this, it is padded with zeros. If*n*is not given, it is taken to be`2*(m-1)`
where`m`
is the length of the input along the axis specified by*axis*.
**axis**int, optional
Axis over which to compute the inverse FFT. If not given, the last axis is used.

**norm**{“backward”, “ortho”, “forward”}, optional
New in version 1.10.0.

Normalization mode (see

). Default is “backward”. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.`numpy.fft`
New in version 1.20.0: The “backward”, “forward” values were added.

Returns:
-
**out**ndarray
The truncated or zero-padded input, transformed along the axis indicated by

*axis*, or the last one if*axis*is not specified. The length of the transformed axis is*n*, or, if*n*is not given,`2*(m-1)`
where`m`
is the length of the transformed axis of the input. To get an odd number of output points,*n*must be specified.
Raises:
-
IndexError
-
If

*axis*is not a valid axis of*a*.
See also

Notes

Returns the real valued

*n*-point inverse discrete Fourier transform of*a*, where*a*contains the non-negative frequency terms of a Hermitian-symmetric sequence.*n*is the length of the result, not the input.If you specify an

*n*such that*a*must be zero-padded or truncated, the extra/removed values will be added/removed at high frequencies. One can thus resample a series to*m*points via Fourier interpolation by:`a_resamp = irfft(rfft(a), m)`
.The correct interpretation of the hermitian input depends on the length of the original data, as given by

*n*. This is because each input shape could correspond to either an odd or even length signal. By default,assumes an even output length which puts the last entry at the Nyquist frequency; aliasing with its symmetric counterpart. By Hermitian symmetry, the value is thus treated as purely real. To avoid losing information, the correct length of the real input`irfft`
**must**be given.Examples

>>> np.fft.ifft([1, -1j, -1, 1j]) array([0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]) # may vary >>> np.fft.irfft([1, -1j, -1]) array([0., 1., 0., 0.])
Notice how the last term in the input to the ordinary

is the complex conjugate of the second term, and the output has zero imaginary part everywhere. When calling`ifft`
, the negative frequencies are not specified, and the output array is purely real.`irfft`# numpy.nan_to_num[#](#numpy-nan-to-num)
numpy.nan_to_num(*x*,*copy=True*,*nan=0.0*,*posinf=None*,*neginf=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/type_check.py#L403-L520)[#](#numpy.nan_to_num)
-
Replace NaN with zero and infinity with large finite numbers (default behaviour) or with the numbers defined by the user using the

,`nan`
*posinf*and/or*neginf*keywords.If

*x*is inexact, NaN is replaced by zero or by the user defined value inkeyword, infinity is replaced by the largest finite floating point values representable by`nan`
`x.dtype`
or by the user defined value in*posinf*keyword and -infinity is replaced by the most negative finite floating point values representable by`x.dtype`
or by the user defined value in*neginf*keyword.For complex dtypes, the above is applied to each of the real and imaginary components of

*x*separately.If

*x*is not inexact, then no replacements are made.Parameters:
-
**x**scalar or array_like
Input data.

**copy**bool, optional
Whether to create a copy of

*x*(True) or to replace values in-place (False). The in-place operation only occurs if casting to an array does not require a copy. Default is True.New in version 1.13.

**nan**int, float, optional
Value to be used to fill NaN values. If no value is passed then NaN values will be replaced with 0.0.

New in version 1.17.

**posinf**int, float, optional
Value to be used to fill positive infinity values. If no value is passed then positive infinity values will be replaced with a very large number.

New in version 1.17.

**neginf**int, float, optional
Value to be used to fill negative infinity values. If no value is passed then negative infinity values will be replaced with a very small (or negative) number.

New in version 1.17.

Returns:
-
**out**ndarray
*x*, with the non-finite values replaced. Ifis False, this may be`copy`
*x*itself.
See also

Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). This means that Not a Number is not equivalent to infinity.

Examples

>>> np.nan_to_num(np.inf) 1.7976931348623157e+308 >>> np.nan_to_num(-np.inf) -1.7976931348623157e+308 >>> np.nan_to_num(np.nan) 0.0 >>> x = np.array([np.inf, -np.inf, np.nan, -128, 128]) >>> np.nan_to_num(x) array([ 1.79769313e+308, -1.79769313e+308, 0.00000000e+000, # may vary -1.28000000e+002, 1.28000000e+002]) >>> np.nan_to_num(x, nan=-9999, posinf=33333333, neginf=33333333) array([ 3.3333333e+07, 3.3333333e+07, -9.9990000e+03, -1.2800000e+02, 1.2800000e+02]) >>> y = np.array([complex(np.inf, np.nan), np.nan, complex(np.nan, np.inf)]) array([ 1.79769313e+308, -1.79769313e+308, 0.00000000e+000, # may vary -1.28000000e+002, 1.28000000e+002]) >>> np.nan_to_num(y) array([ 1.79769313e+308 +0.00000000e+000j, # may vary 0.00000000e+000 +0.00000000e+000j, 0.00000000e+000 +1.79769313e+308j]) >>> np.nan_to_num(y, nan=111111, posinf=222222) array([222222.+111111.j, 111111. +0.j, 111111.+222222.j])# numpy.linalg.LinAlgError[#](#numpy-linalg-linalgerror)
*exception*linalg.LinAlgError[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/__init__.py)[#](#numpy.linalg.LinAlgError)
-
Generic Python-exception-derived object raised by linalg functions.

General purpose exception class, derived from Python’s ValueError class, programmatically raised in linalg functions when a Linear Algebra-related condition would prevent further correct execution of the function.

Parameters:
-
**None**
Examples

>>> from numpy import linalg as LA >>> LA.inv(np.zeros((2,2))) Traceback (most recent call last): File "<stdin>", line 1, in <module> File "...linalg.py", line 350, in inv return wrap(solve(a, identity(a.shape[0], dtype=a.dtype))) File "...linalg.py", line 249, in solve raise LinAlgError('Singular matrix') numpy.linalg.LinAlgError: Singular matrix# numpy.cumprod[#](#numpy-cumprod)
numpy.cumprod(*a*,*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L3108-L3169)[#](#numpy.cumprod)
-
Return the cumulative product of elements along a given axis.

Parameters:
-
**a**array_like
Input array.

**axis**int, optional
Axis along which the cumulative product is computed. By default the input is flattened.

**dtype**dtype, optional
Type of the returned array, as well as of the accumulator in which the elements are multiplied. If

*dtype*is not specified, it defaults to the dtype of*a*, unless*a*has an integer dtype with a precision less than that of the default platform integer. In that case, the default platform integer is used instead.
**out**ndarray, optional
Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type of the resulting values will be cast if necessary.

Returns:
-
**cumprod**ndarray
A new array holding the result is returned unless

*out*is specified, in which case a reference to out is returned.
See also

Notes

Arithmetic is modular when using integer types, and no error is raised on overflow.

Examples

>>> a = np.array([1,2,3]) >>> np.cumprod(a) # intermediate results 1, 1*2 ... # total product 1*2*3 = 6 array([1, 2, 6]) >>> a = np.array([[1, 2, 3], [4, 5, 6]]) >>> np.cumprod(a, dtype=float) # specify type of output array([ 1., 2., 6., 24., 120., 720.])
The cumulative product for each column (i.e., over the rows) of

*a*:>>> np.cumprod(a, axis=0) array([[ 1, 2, 3], [ 4, 10, 18]])
The cumulative product for each row (i.e. over the columns) of

*a*:>>> np.cumprod(a,axis=1) array([[ 1, 2, 6], [ 4, 20, 120]])# numpy.ma.masked_array.nonzero[#](#numpy-ma-masked-array-nonzero)
method

ma.masked_array.nonzero()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4978-L5074)[#](#numpy.ma.masked_array.nonzero)
-
Return the indices of unmasked elements that are not zero.

Returns a tuple of arrays, one for each dimension, containing the indices of the non-zero elements in that dimension. The corresponding non-zero values can be obtained with:

a[a.nonzero()]
To group the indices by element, rather than dimension, use instead:

np.transpose(a.nonzero())
The result of this is always a 2d array, with a row for each non-zero element.

Parameters:
-
**None**
Returns:
-
**tuple_of_arrays**tuple
Indices of elements that are non-zero.

See also

`numpy.nonzero`
Function operating on ndarrays.

`flatnonzero`
Return indices that are non-zero in the flattened version of the input array.

`numpy.ndarray.nonzero`
Equivalent ndarray method.

`count_nonzero`
Counts the number of non-zero elements in the input array.

Examples

>>> import numpy.ma as ma >>> x = ma.array(np.eye(3)) >>> x masked_array( data=[[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], mask=False, fill_value=1e+20) >>> x.nonzero() (array([0, 1, 2]), array([0, 1, 2]))
Masked elements are ignored.

>>> x[1, 1] = ma.masked >>> x masked_array( data=[[1.0, 0.0, 0.0], [0.0, --, 0.0], [0.0, 0.0, 1.0]], mask=[[False, False, False], [False, True, False], [False, False, False]], fill_value=1e+20) >>> x.nonzero() (array([0, 2]), array([0, 2]))
Indices can also be grouped by element.

>>> np.transpose(x.nonzero()) array([[0, 0], [2, 2]])
A common use for

`nonzero`
is to find the indices of an array, where a condition is True. Given an array*a*, the condition*a*> 3 is a boolean array and since False is interpreted as 0, ma.nonzero(a > 3) yields the indices of the*a*where the condition is true.>>> a = ma.array([[1,2,3],[4,5,6],[7,8,9]]) >>> a > 3 masked_array( data=[[False, False, False], [ True, True, True], [ True, True, True]], mask=False, fill_value=True) >>> ma.nonzero(a > 3) (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))
The

`nonzero`
method of the condition array can also be called.>>> (a > 3).nonzero() (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))# numpy.polynomial.hermite.Hermite.fit[#](#numpy-polynomial-hermite-hermite-fit)
method

*classmethod*polynomial.hermite.Hermite.fit(*x*,*y*,*deg*,*domain=None*,*rcond=None*,*full=False*,*w=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L955-L1045)[#](#numpy.polynomial.hermite.Hermite.fit)
-
Least squares fit to data.

Return a series instance that is the least squares fit to the data

*y*sampled at*x*. The domain of the returned instance can be specified and this will often result in a superior fit with less chance of ill conditioning.Parameters:
-
**x**array_like, shape (M,)
x-coordinates of the M sample points

`(x[i], y[i])`
.
**y**array_like, shape (M,)
y-coordinates of the M sample points

`(x[i], y[i])`
.
**deg**int or 1-D array_like
Degree(s) of the fitting polynomials. If

*deg*is a single integer all terms up to and including the*deg*’th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.
**domain**{None, [beg, end], []}, optional
Domain to use for the returned series. If

`None`
, then a minimal domain that covers the points*x*is chosen. If`[]`
the class domain is used. The default value was the class domain in NumPy 1.4 and`None`
in later versions. The`[]`
option was added in numpy 1.5.0.
**rcond**float, optional
Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.

**full**bool, optional
Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.

**w**array_like, shape (M,), optional
Weights. If not None, the weight

`w[i]`
applies to the unsquared residual`y[i] - y_hat[i]`
at`x[i]`
. Ideally the weights are chosen so that the errors of the products`w[i]*y[i]`
all have the same variance. When using inverse-variance weighting, use`w[i] = 1/sigma(y[i])`
. The default value is None.New in version 1.5.0.

**window**{[beg, end]}, optional
Window to use for the returned series. The default value is the default class domain

New in version 1.6.0.

**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
A series that represents the least squares fit to the data and has the domain and window specified in the call. If the coefficients for the unscaled and unshifted basis polynomials are of interest, do

`new_series.convert().coef`
.
**[resid, rank, sv, rcond]**list
These values are only returned if

`full == True`
resid – sum of squared residuals of the least squares fit

rank – the numerical rank of the scaled Vandermonde matrix

sv – singular values of the scaled Vandermonde matrix

rcond – value of

*rcond*.
For more details, see

.`linalg.lstsq`# numpy.distutils.ccompiler_opt[#](#module-numpy.distutils.ccompiler_opt)
Provides the [ CCompilerOpt](numpy.distutils.ccompiler_opt.CCompilerOpt.html#numpy.distutils.ccompiler_opt.CCompilerOpt) class, used for handling the CPU/hardware
optimization, starting from parsing the command arguments, to managing the
relation between the CPU baseline and dispatch-able features,
also generating the required C headers and ending with compiling
the sources with proper compiler’s flags.

[ CCompilerOpt](numpy.distutils.ccompiler_opt.CCompilerOpt.html#numpy.distutils.ccompiler_opt.CCompilerOpt) doesn’t provide runtime detection for the CPU features,
instead only focuses on the compiler side, but it creates abstract C headers
that can be used later for the final runtime dispatching process.
Functions

|
Create a new instance of 'CCompilerOpt' and generate the dispatch header which contains the #definitions and headers of platform-specific instruction-sets for the enabled CPU baseline and dispatch-able features.

|
Classes

|
A helper class for

|# numpy.random.logseries[#](#numpy-random-logseries)
random.logseries(*p*,*size=None*)[#](#numpy.random.logseries)
-
Draw samples from a logarithmic series distribution.

Samples are drawn from a log series distribution with specified shape parameter, 0 <=

`p`
< 1.Note

New code should use the

method of a`logseries`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**p**float or array_like of floats
Shape parameter for the distribution. Must be in the range [0, 1).

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`p`
is a scalar. Otherwise,`np.array(p).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized logarithmic series distribution.

See also

`scipy.stats.logser`
probability density function, distribution or cumulative density function, etc.

`random.Generator.logseries`
which should be used for new code.

Notes

The probability density for the Log Series distribution is

\[P(k) = \frac{-p^k}{k \ln(1-p)},\]where p = probability.

The log series distribution is frequently used to represent species richness and occurrence, first proposed by Fisher, Corbet, and Williams in 1943 [2]. It may also be used to model the numbers of occupants seen in cars [3].

References

[1]Buzas, Martin A.; Culver, Stephen J., Understanding regional species diversity through the log series distribution of occurrences: BIODIVERSITY RESEARCH Diversity & Distributions, Volume 5, Number 5, September 1999 , pp. 187-195(9).

[2]Fisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The relation between the number of species and the number of individuals in a random sample of an animal population. Journal of Animal Ecology, 12:42-58.

[3]D. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small Data Sets, CRC Press, 1994.

[4]Wikipedia, “Logarithmic distribution”,

[https://en.wikipedia.org/wiki/Logarithmic_distribution](https://en.wikipedia.org/wiki/Logarithmic_distribution)Examples

Draw samples from the distribution:

>>> a = .6 >>> s = np.random.logseries(a, 10000) >>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s)
# plot against distribution

>>> def logseries(k, p): ... return -p**k/(k*np.log(1-p)) >>> plt.plot(bins, logseries(bins, a)*count.max()/ ... logseries(bins, a).max(), 'r') >>> plt.show()# numpy.random.RandomState.gumbel[#](#numpy-random-randomstate-gumbel)
method

random.RandomState.gumbel(*loc=0.0*,*scale=1.0*,*size=None*)[#](#numpy.random.RandomState.gumbel)
-
Draw samples from a Gumbel distribution.

Draw samples from a Gumbel distribution with specified location and scale. For more information on the Gumbel distribution, see Notes and References below.

Note

New code should use the

method of a`gumbel`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**loc**float or array_like of floats, optional
The location of the mode of the distribution. Default is 0.

**scale**float or array_like of floats, optional
The scale parameter of the distribution. Default is 1. Must be non- negative.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`loc`
and`scale`
are both scalars. Otherwise,`np.broadcast(loc, scale).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized Gumbel distribution.

See also

`scipy.stats.gumbel_l`
`scipy.stats.gumbel_r`
`scipy.stats.genextreme`
`weibull`
`random.Generator.gumbel`
which should be used for new code.

Notes

The Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme Value Type I) distribution is one of a class of Generalized Extreme Value (GEV) distributions used in modeling extreme value problems. The Gumbel is a special case of the Extreme Value Type I distribution for maximums from distributions with “exponential-like” tails.

The probability density for the Gumbel distribution is

\[p(x) = \frac{e^{-(x - \mu)/ \beta}}{\beta} e^{ -e^{-(x - \mu)/ \beta}},\]where \(\mu\) is the mode, a location parameter, and \(\beta\) is the scale parameter.

The Gumbel (named for German mathematician Emil Julius Gumbel) was used very early in the hydrology literature, for modeling the occurrence of flood events. It is also used for modeling maximum wind speed and rainfall rates. It is a “fat-tailed” distribution - the probability of an event in the tail of the distribution is larger than if one used a Gaussian, hence the surprisingly frequent occurrence of 100-year floods. Floods were initially modeled as a Gaussian process, which underestimated the frequency of extreme events.

It is one of a class of extreme value distributions, the Generalized Extreme Value (GEV) distributions, which also includes the Weibull and Frechet.

The function has a mean of \(\mu + 0.57721\beta\) and a variance of \(\frac{\pi^2}{6}\beta^2\).

References

[1]Gumbel, E. J., “Statistics of Extremes,” New York: Columbia University Press, 1958.

[2]Reiss, R.-D. and Thomas, M., “Statistical Analysis of Extreme Values from Insurance, Finance, Hydrology and Other Fields,” Basel: Birkhauser Verlag, 2001.

Examples

Draw samples from the distribution:

>>> mu, beta = 0, 0.1 # location and scale >>> s = np.random.gumbel(mu, beta, 1000)
Display the histogram of the samples, along with the probability density function:

>>> import matplotlib.pyplot as plt >>> count, bins, ignored = plt.hist(s, 30, density=True) >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta) ... * np.exp( -np.exp( -(bins - mu) /beta) ), ... linewidth=2, color='r') >>> plt.show()
Show how an extreme value distribution can arise from a Gaussian process and compare to a Gaussian:

>>> means = [] >>> maxima = [] >>> for i in range(0,1000) : ... a = np.random.normal(mu, beta, 1000) ... means.append(a.mean()) ... maxima.append(a.max()) >>> count, bins, ignored = plt.hist(maxima, 30, density=True) >>> beta = np.std(maxima) * np.sqrt(6) / np.pi >>> mu = np.mean(maxima) - 0.57721*beta >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta) ... * np.exp(-np.exp(-(bins - mu)/beta)), ... linewidth=2, color='r') >>> plt.plot(bins, 1/(beta * np.sqrt(2 * np.pi)) ... * np.exp(-(bins - mu)**2 / (2 * beta**2)), ... linewidth=2, color='g') >>> plt.show()# numpy.polynomial.hermite.Hermite.trim[#](#numpy-polynomial-hermite-hermite-trim)
method

polynomial.hermite.Hermite.trim(*tol=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L735-L756)[#](#numpy.polynomial.hermite.Hermite.trim)
-
Remove trailing coefficients

Remove trailing coefficients until a coefficient is reached whose absolute value greater than

*tol*or the beginning of the series is reached. If all the coefficients would be removed the series is set to`[0]`
. A new series instance is returned with the new coefficients. The current instance remains unchanged.Parameters:
-
**tol**non-negative number.
All trailing coefficients less than

*tol*will be removed.
Returns:
-
**new_series**series
New instance of series with trimmed coefficients.# numpy.ndarray.view[#](#numpy-ndarray-view)
method

ndarray.view(*[dtype][, type]*)[#](#numpy.ndarray.view)
-
New view of array with the same data.

Note

Passing None for

`dtype`
is different from omitting the parameter, since the former invokes`dtype(None)`
which is an alias for`dtype('float_')`
.Parameters:
-
**dtype**data-type or ndarray sub-class, optional
Data-type descriptor of the returned view, e.g., float32 or int16. Omitting it results in the view having the same data-type as

*a*. This argument can also be specified as an ndarray sub-class, which then specifies the type of the returned object (this is equivalent to setting the`type`
parameter).
**type**Python type, optional
Type of the returned view, e.g., ndarray or matrix. Again, omission of the parameter results in type preservation.

Notes

`a.view()`
is used two different ways:`a.view(some_dtype)`
or`a.view(dtype=some_dtype)`
constructs a view of the array’s memory with a different data-type. This can cause a reinterpretation of the bytes of memory.`a.view(ndarray_subclass)`
or`a.view(type=ndarray_subclass)`
just returns an instance of*ndarray_subclass*that looks at the same array (same shape, dtype, etc.) This does not cause a reinterpretation of the memory.For

`a.view(some_dtype)`
, if`some_dtype`
has a different number of bytes per entry than the previous dtype (for example, converting a regular array to a structured array), then the last axis of`a`
must be contiguous. This axis will be resized in the result.Changed in version 1.23.0: Only the last axis needs to be contiguous. Previously, the entire array had to be C-contiguous.

Examples

>>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])
Viewing array data using a different type and dtype:

>>> y = x.view(dtype=np.int16, type=np.matrix) >>> y matrix([[513]], dtype=int16) >>> print(type(y)) <class 'numpy.matrix'>
Creating a view on a structured array so it can be used in calculations

>>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)]) >>> xv = x.view(dtype=np.int8).reshape(-1,2) >>> xv array([[1, 2], [3, 4]], dtype=int8) >>> xv.mean(0) array([2., 3.])
Making changes to the view changes the underlying array

>>> xv[0,1] = 20 >>> x array([(1, 20), (3, 4)], dtype=[('a', 'i1'), ('b', 'i1')])
Using a view to convert an array to a recarray:

>>> z = x.view(np.recarray) >>> z.a array([1, 3], dtype=int8)
Views share data:

>>> x[0] = (9, 10) >>> z[0] (9, 10)
Views that change the dtype size (bytes per entry) should normally be avoided on arrays defined by slices, transposes, fortran-ordering, etc.:

>>> x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int16) >>> y = x[:, ::2] >>> y array([[1, 3], [4, 6]], dtype=int16) >>> y.view(dtype=[('width', np.int16), ('length', np.int16)]) Traceback (most recent call last): ... ValueError: To change to a dtype of a different size, the last axis must be contiguous >>> z = y.copy() >>> z.view(dtype=[('width', np.int16), ('length', np.int16)]) array([[(1, 3)], [(4, 6)]], dtype=[('width', '<i2'), ('length', '<i2')])
However, views that change dtype are totally fine for arrays with a contiguous last axis, even if the rest of the axes are not C-contiguous:

>>> x = np.arange(2 * 3 * 4, dtype=np.int8).reshape(2, 3, 4) >>> x.transpose(1, 0, 2).view(np.int16) array([[[ 256, 770], [3340, 3854]], [[1284, 1798], [4368, 4882]], [[2312, 2826], [5396, 5910]]], dtype=int16)# numpy.polynomial.laguerre.lagval3d[#](#numpy-polynomial-laguerre-lagval3d)
polynomial.laguerre.lagval3d(*x*,*y*,*z*,*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L998-L1046)[#](#numpy.polynomial.laguerre.lagval3d)
-
Evaluate a 3-D Laguerre series at points (x, y, z).

This function returns the values:

\[p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * L_i(x) * L_j(y) * L_k(z)\]The parameters

*x*,*y*, and*z*are converted to arrays only if they are tuples or a lists, otherwise they are treated as a scalars and they must have the same shape after conversion. In either case, either*x*,*y*, and*z*or their elements must support multiplication and addition both with themselves and with the elements of*c*.If

*c*has fewer than 3 dimensions, ones are implicitly appended to its shape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape.Parameters:
-
**x, y, z**array_like, compatible object
The three dimensional series is evaluated at the points

*(x, y, z)*, where*x*,*y*, and*z*must have the same shape. If any of*x*,*y*, or*z*is a list or tuple, it is first converted to an ndarray, otherwise it is left unchanged and if it isn’t an ndarray it is treated as a scalar.
**c**array_like
Array of coefficients ordered so that the coefficient of the term of multi-degree i,j,k is contained in

`c[i,j,k]`
. If*c*has dimension greater than 3 the remaining indices enumerate multiple sets of coefficients.
Returns:
-
**values**ndarray, compatible object
The values of the multidimensional polynomial on points formed with triples of corresponding values from

*x*,*y*, and*z*.
Notes

New in version 1.7.0.# numpy.vdot[#](#numpy-vdot)
numpy.vdot(*a*,*b*,*/*)[#](#numpy.vdot)
-
Return the dot product of two vectors.

The vdot(

*a*,*b*) function handles complex numbers differently than dot(*a*,*b*). If the first argument is complex the complex conjugate of the first argument is used for the calculation of the dot product.Note that

handles multidimensional arrays differently than`vdot`
: it does`dot`
*not*perform a matrix product, but flattens input arguments to 1-D vectors first. Consequently, it should only be used for vectors.Parameters:
-
**a**array_like
If

*a*is complex the complex conjugate is taken before calculation of the dot product.
**b**array_like
Second argument to the dot product.

Returns:
-
**output**ndarray
Dot product of

*a*and*b*. Can be an int, float, or complex depending on the types of*a*and*b*.
See also

`dot`
Return the dot product without using the complex conjugate of the first argument.

Examples

>>> a = np.array([1+2j,3+4j]) >>> b = np.array([5+6j,7+8j]) >>> np.vdot(a, b) (70-8j) >>> np.vdot(b, a) (70+8j)
Note that higher-dimensional arrays are flattened!

>>> a = np.array([[1, 4], [5, 6]]) >>> b = np.array([[4, 1], [2, 2]]) >>> np.vdot(a, b) 30 >>> np.vdot(b, a) 30 >>> 1*4 + 4*1 + 5*2 + 6*2 30# numpy.distutils.ccompiler_opt.CCompilerOpt.try_dispatch[#](#numpy-distutils-ccompiler-opt-ccompileropt-try-dispatch)
method

distutils.ccompiler_opt.CCompilerOpt.try_dispatch(*sources*,*src_dir=None*,*ccompiler=None*,***kwargs*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/ccompiler_opt.py#L2268-L2353)[#](#numpy.distutils.ccompiler_opt.CCompilerOpt.try_dispatch)
-
Compile one or more dispatch-able sources and generates object files, also generates abstract C config headers and macros that used later for the final runtime dispatching process.

The mechanism behind it is to takes each source file that specified in ‘sources’ and branching it into several files depend on special configuration statements that must be declared in the top of each source which contains targeted CPU features, then it compiles every branched source with the proper compiler flags.

Parameters:
-
**sources**list
Must be a list of dispatch-able sources file paths, and configuration statements must be declared inside each file.

**src_dir**str
Path of parent directory for the generated headers and wrapped sources. If None(default) the files will generated in-place.

**ccompiler**CCompiler
Distutils

*CCompiler*instance to be used for compilation. If None (default), the provided instance during the initialization will be used instead.
****kwargs**any
Arguments to pass on to the

*CCompiler.compile()*
Returns:
-
**list**generated object files
Raises:
-
CompileError
-
Raises by

*CCompiler.compile()*on compiling failure.
DistutilsError
-
Some errors during checking the sanity of configuration statements.

See also

`parse_targets`
Parsing the configuration statements of dispatch-able sources.# numpy.lookfor[#](#numpy-lookfor)
numpy.lookfor(*what*,*module=None*,*import_modules=True*,*regenerate=False*,*output=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/utils.py#L754-L876)[#](#numpy.lookfor)
-
Do a keyword search on docstrings.

A list of objects that matched the search is displayed, sorted by relevance. All given keywords need to be found in the docstring for it to be returned as a result, but the order does not matter.

Parameters:
-
**what**str
String containing words to look for.

**module**str or list, optional
Name of module(s) whose docstrings to go through.

**import_modules**bool, optional
Whether to import sub-modules in packages. Default is True.

**regenerate**bool, optional
Whether to re-generate the docstring cache. Default is False.

**output**file-like, optional
File-like object to write the output to. If omitted, use a pager.

Notes

Relevance is determined only roughly, by checking if the keywords occur in the function name, at the start of a docstring, etc.

Examples

>>> np.lookfor('binary representation') Search results for 'binary representation' ------------------------------------------ numpy.binary_repr Return the binary representation of the input number as a string. numpy.core.setup_common.long_double_representation Given a binary dump as given by GNU od -b, look for long double numpy.base_repr Return a string representation of a number in the given base system. ...# numpy.ma.dstack[#](#numpy-ma-dstack)
ma.dstack*= <numpy.ma.extras._fromnxfunction_seq object>*[#](#numpy.ma.dstack)
-
dstack

Stack arrays in sequence depth wise (along third axis).

This is equivalent to concatenation along the third axis after 2-D arrays of shape

*(M,N)*have been reshaped to*(M,N,1)*and 1-D arrays of shape*(N,)*have been reshaped to*(1,N,1)*. Rebuilds arrays divided by.`dsplit`
This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions

,`concatenate`
and`stack`
provide more general stacking and concatenation operations.`block`
Parameters:
-
**tup**sequence of arrays
The arrays must have the same shape along all but the third axis. 1-D or 2-D arrays must have the same shape.

Returns:
-
**stacked**ndarray
The array formed by stacking the given arrays, will be at least 3-D.

See also

`concatenate`
Join a sequence of arrays along an existing axis.

`stack`
Join a sequence of arrays along a new axis.

`block`
Assemble an nd-array from nested lists of blocks.

`vstack`
Stack arrays in sequence vertically (row wise).

`hstack`
Stack arrays in sequence horizontally (column wise).

`column_stack`
Stack 1-D arrays as columns into a 2-D array.

`dsplit`
Split array along third axis.

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> a = np.array((1,2,3)) >>> b = np.array((2,3,4)) >>> np.dstack((a,b)) array([[[1, 2], [2, 3], [3, 4]]])
>>> a = np.array([[1],[2],[3]]) >>> b = np.array([[2],[3],[4]]) >>> np.dstack((a,b)) array([[[1, 2]], [[2, 3]], [[3, 4]]])# numpy.ma.masked_invalid[#](#numpy-ma-masked-invalid)
ma.masked_invalid(*a*,*copy=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2332-L2365)[#](#numpy.ma.masked_invalid)
-
Mask an array where invalid values occur (NaNs or infs).

This function is a shortcut to

`masked_where`
, with*condition*= ~(np.isfinite(a)). Any pre-existing mask is conserved. Only applies to arrays with a dtype where NaNs or infs make sense (i.e. floating point types), but accepts any array_like object.See also

`masked_where`
Mask where a condition is met.

Examples

>>> import numpy.ma as ma >>> a = np.arange(5, dtype=float) >>> a[2] = np.NaN >>> a[3] = np.PINF >>> a array([ 0., 1., nan, inf, 4.]) >>> ma.masked_invalid(a) masked_array(data=[0.0, 1.0, --, --, 4.0], mask=[False, False, True, True, False], fill_value=1e+20)New in version 1.4.0.

# Chebyshev Series (`numpy.polynomial.chebyshev`
)[#](#chebyshev-series-numpy-polynomial-chebyshev)
`numpy.polynomial.chebyshev`
This module provides a number of objects (mostly functions) useful for
dealing with Chebyshev series, including a [ Chebyshev](generated/numpy.polynomial.chebyshev.Chebyshev.html#numpy.polynomial.chebyshev.Chebyshev) class that
encapsulates the usual arithmetic operations. (General information
on how this module represents and works with such polynomials is in the
docstring for its “parent” sub-package,

[).](routines.polynomials.package.html#module-numpy.polynomial)
`numpy.polynomial`
## Classes[#](#classes)
|
A Chebyshev series class.

|
## Constants[#](#constants)
An array object represents a multidimensional, homogeneous array of fixed-size items.

|
An array object represents a multidimensional, homogeneous array of fixed-size items.

|
An array object represents a multidimensional, homogeneous array of fixed-size items.

|
An array object represents a multidimensional, homogeneous array of fixed-size items.

|
## Arithmetic[#](#arithmetic)
|
Add one Chebyshev series to another.

|
|
Subtract one Chebyshev series from another.

|
|
Multiply a Chebyshev series by x.

|
|
Multiply one Chebyshev series by another.

|
|
Divide one Chebyshev series by another.

|
|
Raise a Chebyshev series to a power.

|
|
Evaluate a Chebyshev series at points x.

|
|
Evaluate a 2-D Chebyshev series at points (x, y).

|
|
Evaluate a 3-D Chebyshev series at points (x, y, z).

|
|
Evaluate a 2-D Chebyshev series on the Cartesian product of x and y.

|
|
Evaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.

|
## Calculus[#](#calculus)
|
Differentiate a Chebyshev series.

|
|
Integrate a Chebyshev series.

|
## Misc Functions[#](#misc-functions)
|
Generate a Chebyshev series with given roots.

|
|
Compute the roots of a Chebyshev series.

|
|
Pseudo-Vandermonde matrix of given degree.

|
|
Pseudo-Vandermonde matrix of given degrees.

|
|
Pseudo-Vandermonde matrix of given degrees.

|
|
Gauss-Chebyshev quadrature.

|
|
The weight function of the Chebyshev polynomials.

|
Return the scaled companion matrix of c.

|
|
Least squares fit of Chebyshev series to data.

|
|
Chebyshev points of the first kind.

|
|
Chebyshev points of the second kind.

|
|
Remove "small" "trailing" coefficients from a polynomial.

|
|
Chebyshev series whose graph is a straight line.

|
|
Convert a Chebyshev series to a polynomial.

|
|
Convert a polynomial to a Chebyshev series.

|
|
Interpolate a function at the Chebyshev points of the first kind.

|
## See also[#](#see-also)
## Notes[#](#notes)
The implementations of multiplication, division, integration, and
differentiation use the algebraic identities [[1]](#r3f3efff98d00-1):

where

These identities allow a Chebyshev series to be expressed as a finite, symmetric Laurent series. In this module, this sort of Laurent series is referred to as a “z-series.”

## References[#](#references)
[1](#id1)]
A. T. Benjamin, et al., “Combinatorial Trigonometry with Chebyshev
Polynomials,” *Journal of Statistical Planning and Inference 14*, 2008
([https://web.archive.org/web/20080221202153/https://www.math.hmc.edu/~benjamin/papers/CombTrig.pdf](https://web.archive.org/web/20080221202153/https://www.math.hmc.edu/~benjamin/papers/CombTrig.pdf), pg. 4)# numpy.nanmin[#](#numpy-nanmin)
numpy.nanmin(*a*,*axis=None*,*out=None*,*keepdims=<no value>*,*initial=<no value>*,*where=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L236-L361)[#](#numpy.nanmin)
-
Return minimum of an array or minimum along an axis, ignoring any NaNs. When all-NaN slices are encountered a

`RuntimeWarning`
is raised and Nan is returned for that slice.Parameters:
-
**a**array_like
Array containing numbers whose minimum is desired. If

*a*is not an array, a conversion is attempted.
**axis**{int, tuple of int, None}, optional
Axis or axes along which the minimum is computed. The default is to compute the minimum of the flattened array.

**out**ndarray, optional
Alternate output array in which to place the result. The default is

`None`
; if provided, it must have the same shape as the expected output, but the type will be cast if necessary. See[Output type determination](../../user/basics.ufuncs.html#ufuncs-output-type)for more details.New in version 1.8.0.

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original

*a*.If the value is anything but the default, then

*keepdims*will be passed through to themethod of sub-classes of`min`
. If the sub-classes methods does not implement`ndarray`
*keepdims*any exceptions will be raised.New in version 1.8.0.

**initial**scalar, optional
The maximum value of an output element. Must be present to allow computation on empty slice. See

for details.`reduce`
New in version 1.22.0.

**where**array_like of bool, optional
Elements to compare for the minimum. See

for details.`reduce`
New in version 1.22.0.

Returns:
-
**nanmin**ndarray
An array with the same shape as

*a*, with the specified axis removed. If*a*is a 0-d array, or if axis is None, an ndarray scalar is returned. The same dtype as*a*is returned.
See also

`nanmax`
The maximum value of an array along a given axis, ignoring any NaNs.

`amin`
The minimum value of an array along a given axis, propagating any NaNs.

`fmin`
Element-wise minimum of two arrays, ignoring any NaNs.

`minimum`
Element-wise minimum of two arrays, propagating any NaNs.

`isnan`
Shows which elements are Not a Number (NaN).

`isfinite`
Shows which elements are neither NaN nor infinity.

,`amax`
,`fmax`
`maximum`
Notes

NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754). This means that Not a Number is not equivalent to infinity. Positive infinity is treated as a very large number and negative infinity is treated as a very small (i.e. negative) number.

If the input has a integer type the function is equivalent to np.min.

Examples

>>> a = np.array([[1, 2], [3, np.nan]]) >>> np.nanmin(a) 1.0 >>> np.nanmin(a, axis=0) array([1., 2.]) >>> np.nanmin(a, axis=1) array([1., 3.])
When positive infinity and negative infinity are present:

>>> np.nanmin([1, 2, np.nan, np.inf]) 1.0 >>> np.nanmin([1, 2, np.nan, np.NINF]) -inf# numpy.polynomial.hermite.hermadd[#](#numpy-polynomial-hermite-hermadd)
polynomial.hermite.hermadd(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L313-L350)[#](#numpy.polynomial.hermite.hermadd)
-
Add one Hermite series to another.

Returns the sum of two Hermite series

*c1*+*c2*. The arguments are sequences of coefficients ordered from lowest order term to highest, i.e., [1,2,3] represents the series`P_0 + 2*P_1 + 3*P_2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of Hermite series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Array representing the Hermite series of their sum.

Notes

Unlike multiplication, division, etc., the sum of two Hermite series is a Hermite series (without having to “reproject” the result onto the basis set) so addition, just like that of “standard” polynomials, is simply “component-wise.”

Examples

>>> from numpy.polynomial.hermite import hermadd >>> hermadd([1, 2, 3], [1, 2, 3, 4]) array([2., 4., 6., 4.])# numpy.random.noncentral_f[#](#numpy-random-noncentral-f)
random.noncentral_f(*dfnum*,*dfden*,*nonc*,*size=None*)[#](#numpy.random.noncentral_f)
-
Draw samples from the noncentral F distribution.

Samples are drawn from an F distribution with specified parameters,

*dfnum*(degrees of freedom in numerator) and*dfden*(degrees of freedom in denominator), where both parameters > 1.*nonc*is the non-centrality parameter.Note

New code should use the

method of a`noncentral_f`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**dfnum**float or array_like of floats
Numerator degrees of freedom, must be > 0.

Changed in version 1.14.0: Earlier NumPy versions required dfnum > 1.

**dfden**float or array_like of floats
Denominator degrees of freedom, must be > 0.

**nonc**float or array_like of floats
Non-centrality parameter, the sum of the squares of the numerator means, must be >= 0.

**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. If size is`None`
(default), a single value is returned if`dfnum`
,`dfden`
, and`nonc`
are all scalars. Otherwise,`np.broadcast(dfnum, dfden, nonc).size`
samples are drawn.
Returns:
-
**out**ndarray or scalar
Drawn samples from the parameterized noncentral Fisher distribution.

See also

`random.Generator.noncentral_f`
which should be used for new code.

Notes

When calculating the power of an experiment (power = probability of rejecting the null hypothesis when a specific alternative is true) the non-central F statistic becomes important. When the null hypothesis is true, the F statistic follows a central F distribution. When the null hypothesis is not true, then it follows a non-central F statistic.

References

[1]Weisstein, Eric W. “Noncentral F-Distribution.” From MathWorld–A Wolfram Web Resource.

[http://mathworld.wolfram.com/NoncentralF-Distribution.html](http://mathworld.wolfram.com/NoncentralF-Distribution.html)[2]Wikipedia, “Noncentral F-distribution”,

[https://en.wikipedia.org/wiki/Noncentral_F-distribution](https://en.wikipedia.org/wiki/Noncentral_F-distribution)Examples

In a study, testing for a specific alternative to the null hypothesis requires use of the Noncentral F distribution. We need to calculate the area in the tail of the distribution that exceeds the value of the F distribution for the null hypothesis. We’ll plot the two probability distributions for comparison.

>>> dfnum = 3 # between group deg of freedom >>> dfden = 20 # within groups degrees of freedom >>> nonc = 3.0 >>> nc_vals = np.random.noncentral_f(dfnum, dfden, nonc, 1000000) >>> NF = np.histogram(nc_vals, bins=50, density=True) >>> c_vals = np.random.f(dfnum, dfden, 1000000) >>> F = np.histogram(c_vals, bins=50, density=True) >>> import matplotlib.pyplot as plt >>> plt.plot(F[1][1:], F[0]) >>> plt.plot(NF[1][1:], NF[0]) >>> plt.show()# numpy.random.PCG64DXSM.advance[#](#numpy-random-pcg64dxsm-advance)
method

random.PCG64DXSM.advance(*delta*)[#](#numpy.random.PCG64DXSM.advance)
-
Advance the underlying RNG as-if delta draws have occurred.

Parameters:
-
**delta**integer, positive
Number of draws to advance the RNG. Must be less than the size state variable in the underlying RNG.

Returns:
-
**self**PCG64
RNG advanced delta steps

Notes

Advancing a RNG updates the underlying RNG state as-if a given number of calls to the underlying RNG have been made. In general there is not a one-to-one relationship between the number output random values from a particular distribution and the number of draws from the core RNG. This occurs for two reasons:

The random values are simulated using a rejection-based method and so, on average, more than one value from the underlying RNG is required to generate an single draw.

The number of bits required to generate a simulated value differs from the number of bits generated by the underlying RNG. For example, two 16-bit integer values can be simulated from a single draw of a 32-bit RNG.

Advancing the RNG state resets any pre-computed random numbers. This is required to ensure exact reproducibility.# Miscellaneous[#](#miscellaneous)
## IEEE 754 Floating Point Special Values[#](#ieee-754-floating-point-special-values)
Special values defined in numpy: nan, inf,

NaNs can be used as a poor-man’s mask (if you don’t care what the original value was)

Note: cannot use equality to test NaNs. E.g.:

```
>>> myarr = np.array([1., 0., np.nan, 3.])
>>> np.nonzero(myarr == np.nan)
(array([], dtype=int64),)
>>> np.nan == np.nan # is always False! Use special numpy functions instead.
False
>>> myarr[myarr == np.nan] = 0. # doesn't work
>>> myarr
array([ 1., 0., nan, 3.])
>>> myarr[np.isnan(myarr)] = 0. # use this instead find
>>> myarr
array([1., 0., 0., 3.])
```
Other related special value functions:

```
isinf(): True if value is inf
isfinite(): True if not nan or inf
nan_to_num(): Map nan to 0, inf to max float, -inf to min float
```
The following corresponds to the usual functions except that nans are excluded from the results:

```
nansum()
nanmax()
nanmin()
nanargmax()
nanargmin()
>>> x = np.arange(10.)
>>> x[3] = np.nan
>>> x.sum()
nan
>>> np.nansum(x)
42.0
```
## How numpy handles numerical exceptions[#](#how-numpy-handles-numerical-exceptions)
The default is to `'warn'`
for `invalid`
, `divide`
, and `overflow`
and `'ignore'`
for `underflow`
. But this can be changed, and it can be
set individually for different kinds of exceptions. The different behaviors
are:

-
‘ignore’ : Take no action when the exception occurs.

-
‘warn’ : Print a

RuntimeWarning(via the Python[module).]`warnings`
-
‘raise’ : Raise a

FloatingPointError.
-
‘call’ : Call a function specified using the

seterrcallfunction.
-
‘print’ : Print a warning directly to

`stdout`
.
-
‘log’ : Record error in a Log object specified by

seterrcall.
These behaviors can be set for all kinds of errors or specific ones:

-
all : apply to all numeric exceptions

-
invalid : when NaNs are generated

-
divide : divide by zero (for integers as well!)

-
overflow : floating point overflows

-
underflow : floating point underflows

Note that integer divide-by-zero is handled by the same machinery. These behaviors are set on a per-thread basis.

## Examples[#](#examples)
```
>>> oldsettings = np.seterr(all='warn')
>>> np.zeros(5,dtype=np.float32)/0.
Traceback (most recent call last):
...
RuntimeWarning: invalid value encountered in divide
>>> j = np.seterr(under='ignore')
>>> np.array([1.e-100])**10
array([0.])
>>> j = np.seterr(invalid='raise')
>>> np.sqrt(np.array([-1.]))
Traceback (most recent call last):
...
FloatingPointError: invalid value encountered in sqrt
>>> def errorhandler(errstr, errflag):
... print("saw stupid error!")
>>> np.seterrcall(errorhandler)
>>> j = np.seterr(all='call')
>>> np.zeros(5, dtype=np.int32)/0
saw stupid error!
array([nan, nan, nan, nan, nan])
>>> j = np.seterr(**oldsettings) # restore previous
... # error-handling settings
```
## Interfacing to C[#](#interfacing-to-c)
Only a survey of the choices. Little detail on how each works.

Bare metal, wrap your own C-code manually.

-
Plusses:

-
Efficient

-
No dependencies on other tools

-
Minuses:

-
Lots of learning overhead:

-
need to learn basics of Python C API

-
need to learn basics of numpy C API

-
need to learn how to handle reference counting and love it.

-
Reference counting often difficult to get right.

-
getting it wrong leads to memory leaks, and worse, segfaults

Cython

-
Plusses:

-
avoid learning C API’s

-
no dealing with reference counting

-
can code in pseudo python and generate C code

-
can also interface to existing C code

-
should shield you from changes to Python C api

-
has become the de-facto standard within the scientific Python community

-
fast indexing support for arrays

-
Minuses:

-
Can write code in non-standard form which may become obsolete

-
Not as flexible as manual wrapping

ctypes

-
Plusses:

-
part of Python standard library

-
good for interfacing to existing shareable libraries, particularly Windows DLLs

-
avoids API/reference counting issues

-
good numpy support: arrays have all these in their ctypes attribute:

a.ctypes.data a.ctypes.data_as a.ctypes.shape a.ctypes.shape_as a.ctypes.strides a.ctypes.strides_as
-
Minuses:

-
can’t use for writing code to be turned into C extensions, only a wrapper tool.

SWIG (automatic wrapper generator)

-
Plusses:

-
around a long time

-
multiple scripting language support

-
C++ support

-
Good for wrapping large (many functions) existing C libraries

-
Minuses:

-
generates lots of code between Python and the C code

-
can cause performance problems that are nearly impossible to optimize out

-
interface files can be hard to write

-
doesn’t necessarily avoid reference counting issues or needing to know API’s

Psyco

-
Plusses:

-
Turns pure python into efficient machine code through jit-like optimizations

-
very fast when it optimizes well

-
Minuses:

-
Only on intel (windows?)

-
Doesn’t do much for numpy?

## Interfacing to Fortran:[#](#interfacing-to-fortran)
The clear choice to wrap Fortran code is
[f2py](https://docs.scipy.org/doc/numpy/f2py/).

Pyfort is an older alternative, but not supported any longer. Fwrap is a newer project that looked promising but isn’t being developed any longer.

## Interfacing to C++:[#](#id1)
-
Cython

-
CXX

-
Boost.python

-
SWIG

-
SIP (used mainly in PyQT)The location of this document has been changed , if you are not redirected in few seconds, click here.# F2PY and Build Systems[#](#f2py-and-build-systems)
In this section we will cover the various popular build systems and their usage
with `f2py`
.

Note

**As of November 2021**
The default build system for `F2PY`
has traditionally been through the
enhanced `numpy.distutils`
module. This module is based on `distutils`
which
will be removed in `Python 3.12.0`
in **October 2023**; `setuptools`
does not
have support for Fortran or `F2PY`
and it is unclear if it will be supported
in the future. Alternative methods are thus increasingly more important.

## Basic Concepts[#](#basic-concepts)
Building an extension module which includes Python and Fortran consists of:

Fortran source(s)

One or more generated files from

`f2py`
A

`C`
wrapper file is always created
Code with modules require an additional

`.f90`
wrapper
Code with functions generate an additional

`.f`
wrapper
`fortranobject.{c,h}`
Distributed with

`numpy`
Can be queried via

`python -c "import numpy.f2py; print(numpy.f2py.get_include())"`
NumPy headers

Can be queried via

`python -c "import numpy; print(numpy.get_include())"`
Python libraries and development headers

Broadly speaking there are three cases which arise when considering the outputs of `f2py`
:

Fortran 77 programs
-
Input file

`blah.f`
Generates

`blahmodule.c`
`blah-f2pywrappers.f`
When no

`COMMON`
blocks are present only a`C`
wrapper file is generated. Wrappers are also generated to rewrite assumed shape arrays as automatic arrays.
Fortran 90 programs
-
Input file

`blah.f90`
Generates:

`blahmodule.c`
`blah-f2pywrappers.f`
`blah-f2pywrappers2.f90`
The

`f90`
wrapper is used to handle code which is subdivided into modules. The`f`
wrapper makes`subroutines`
for`functions`
. It rewrites assumed shape arrays as automatic arrays.
Signature files
-
Input file

`blah.pyf`
Generates:

`blahmodule.c`
`blah-f2pywrappers2.f90`
(occasionally)
`blah-f2pywrappers.f`
(occasionally)
Signature files

`.pyf`
do not signal their language standard via the file extension, they may generate the F90 and F77 specific wrappers depending on their contents; which shifts the burden of checking for generated files onto the build system.
Note

From NumPy `1.22.4`
onwards, `f2py`
will deterministically generate
wrapper files based on the input file Fortran standard (F77 or greater).
`--skip-empty-wrappers`
can be passed to `f2py`
to restore the previous
behaviour of only generating wrappers when needed by the input .

In theory keeping the above requirements in hand, any build system can be
adapted to generate `f2py`
extension modules. Here we will cover a subset of
the more popular systems.

Note

`make`
has no place in a modern multi-language setup, and so is not
discussed further.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Upgrading `PCG64`
with `PCG64DXSM`
[#](#upgrading-pcg64-with-pcg64dxsm)
Uses of the `PCG64`
[ BitGenerator](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator) in a massively-parallel context have been
shown to have statistical weaknesses that were not apparent at the first
release in numpy 1.17. Most users will never observe this weakness and are
safe to continue to use

[. We have introduced a new](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
`PCG64DXSM`
[that will eventually become the new default](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
[implementation used by](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
[in future releases.](generator.html#numpy.random.default_rng)
`default_rng`
[solves the statistical weakness while preserving the performance and the features of](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM)
`PCG64DXSM`
[.](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
## Does this affect me?[#](#does-this-affect-me)
If you

-
only use a single

[instance,]`Generator`
-
only use

[or the functions in]`RandomState`
[,]`numpy.random`
-
only use the

[method to generate parallel streams,]`PCG64.jumped`
-
explicitly use a

[other than]`BitGenerator`
[,]`PCG64`
then this weakness does not affect you at all. Carry on.

If you use moderate numbers of parallel streams created with [ default_rng](generator.html#numpy.random.default_rng) or

[, in the 1000s, then the chance of observing this weakness is negligibly small. You can continue to use](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn)
`SeedSequence.spawn`
[comfortably.](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
If you use very large numbers of parallel streams, in the millions, and draw
large amounts of numbers from each, then the chance of observing this weakness
can become non-negligible, if still small. An example of such a use case would
be a very large distributed reinforcement learning problem with millions of
long Monte Carlo playouts each generating billions of random number draws. Such
use cases should consider using [ PCG64DXSM](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM) explicitly or another
modern

[like](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
[or](bit_generators/sfc64.html#numpy.random.SFC64)
`SFC64`
[, but it is unlikely that any old results you may have calculated are invalid. In any case, the weakness is a kind of](bit_generators/philox.html#numpy.random.Philox)
`Philox`
[Birthday Paradox](https://en.wikipedia.org/wiki/Birthday_problem)collision. That is, a single pair of parallel streams out of the millions, considered together, might fail a stringent set of statistical tests of randomness. The remaining millions of streams would all be perfectly fine, and the effect of the bad pair in the whole calculation is very likely to be swamped by the remaining streams in most applications.
## Technical Details[#](#technical-details)
Like many PRNG algorithms, [ PCG64](bit_generators/pcg64.html#numpy.random.PCG64) is constructed from a transition function,
which advances a 128-bit state, and an output function, that mixes the 128-bit
state into a 64-bit integer to be output. One of the guiding design principles
of the PCG family of PRNGs is to balance the computational cost (and
pseudorandomness strength) between the transition function and the output
function. The transition function is a 128-bit linear congruential generator
(LCG), which consists of multiplying the 128-bit state with a fixed
multiplication constant and then adding a user-chosen increment, in 128-bit
modular arithmetic. LCGs are well-analyzed PRNGs with known weaknesses, though
128-bit LCGs are large enough to pass stringent statistical tests on their own,
with only the trivial output function. The output function of

[is intended to patch up some of those known weaknesses by doing “just enough” scrambling of the bits to assist in the statistical properties without adding too much computational cost.](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
One of these known weaknesses is that advancing the state of the LCG by steps
numbering a power of two (`bg.advance(2**N)`
) will leave the lower `N`
bits
identical to the state that was just left. For a single stream drawn from
sequentially, this is of little consequence. The remaining \(128-N\) bits provide
plenty of pseudorandomness that will be mixed in for any practical `N`
that can
be observed in a single stream, which is why one does not need to worry about
this if you only use a single stream in your application. Similarly, the
[ PCG64.jumped](bit_generators/generated/numpy.random.PCG64.jumped.html#numpy.random.PCG64.jumped) method uses a carefully chosen number of steps to avoid creating
these collisions. However, once you start creating “randomly-initialized”
parallel streams, either using OS entropy by calling

[repeatedly or using](generator.html#numpy.random.default_rng)
`default_rng`
[, then we need to consider how many lower bits need to “collide” in order to create a bad pair of streams, and then evaluate the probability of creating such a collision.](bit_generators/generated/numpy.random.SeedSequence.spawn.html#numpy.random.SeedSequence.spawn)
`SeedSequence.spawn`
[Empirically](https://github.com/numpy/numpy/issues/16313), it has been determined that if one shares the lower 58 bits of state and shares an increment, then the pair of streams, when interleaved, will fail
[PractRand](http://pracrand.sourceforge.net/)in a reasonable amount of time, after drawing a few gigabytes of data. Following the standard Birthday Paradox calculations for a collision of 58 bits, we can see that we can create \(2^{29}\), or about half a billion, streams which is when the probability of such a collision becomes high. Half a billion streams is quite high, and the amount of data each stream needs to draw before the statistical correlations become apparent to even the strict
`PractRand`
tests
is in the gigabytes. But this is on the horizon for very large applications
like distributed reinforcement learning. There are reasons to expect that even
in these applications a collision probably will not have a practical effect in
the total result, since the statistical problem is constrained to just the
colliding pair.Now, let us consider the case when the increment is not constrained to be the
same. Our implementation of [ PCG64](bit_generators/pcg64.html#numpy.random.PCG64) seeds both the state and the increment;
that is, two calls to

[(almost certainly) have different states and increments. Upon our first release, we believed that having the seeded increment would provide a certain amount of extra protection, that one would have to be “close” in both the state space and increment space in order to observe correlations (](generator.html#numpy.random.default_rng)
`default_rng`
`PractRand`
failures) in a pair of streams. If that were
true, then the “bottleneck” for collisions would be the 128-bit entropy pool
size inside of [(and 128-bit collisions are in the “preposterously unlikely” category). Unfortunately, this is not true.](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
One of the known properties of an LCG is that different increments create
*distinct* streams, but with a known relationship. Each LCG has an orbit that
traverses all \(2^{128}\) different 128-bit states. Two LCGs with different
increments are related in that one can “rotate” the orbit of the first LCG
(advance it by a number of steps that we can compute from the two increments)
such that then both LCGs will always then have the same state, up to an
additive constant and maybe an inversion of the bits. If you then iterate both
streams in lockstep, then the states will *always* remain related by that same
additive constant (and the inversion, if present). Recall that [ PCG64](bit_generators/pcg64.html#numpy.random.PCG64) is
constructed from both a transition function (the LCG) and an output function.
It was expected that the scrambling effect of the output function would have
been strong enough to make the distinct streams practically independent (i.e.
“passing the

`PractRand`
tests”) unless the two increments were
pathologically related to each other (e.g. 1 and 3). The output function XSL-RR
of the then-standard PCG algorithm that we implemented in [turns out to be too weak to cover up for the 58-bit collision of the underlying LCG that we described above. For any given pair of increments, the size of the “colliding” space of states is the same, so for this weakness, the extra distinctness provided by the increments does not translate into extra protection from statistical correlations that](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
`PractRand`
can detect.Fortunately, strengthening the output function is able to correct this weakness
and *does* turn the extra distinctness provided by differing increments into
additional protection from these low-bit collisions. To the [PCG author’s
credit](https://github.com/numpy/numpy/issues/13635#issuecomment-506088698),
she had developed a stronger output function in response to related discussions
during the long birth of the new [ BitGenerator](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator) system. We NumPy developers
chose to be “conservative” and use the XSL-RR variant that had undergone
a longer period of testing at that time. The DXSM output function adopts
a “xorshift-multiply” construction used in strong integer hashes that has much
better avalanche properties than the XSL-RR output function. While there are
“pathological” pairs of increments that induce “bad” additive constants that
relate the two streams, the vast majority of pairs induce “good” additive
constants that make the merely-distinct streams of LCG states into
practically-independent output streams. Indeed, now the claim we once made
about

[is actually true of](bit_generators/pcg64.html#numpy.random.PCG64)
`PCG64`
[: collisions are possible, but both streams have to simultaneously be both “close” in the 128 bit state space](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM)
`PCG64DXSM`
*and*“close” in the 127-bit increment space, so that would be less likely than the negligible chance of colliding in the 128-bit internal
[pool. The DXSM output function is more computationally intensive than XSL-RR, but some optimizations in the LCG more than make up for the performance hit on most machines, so](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
[is a good, safe upgrade. There are, of course, an infinite number of stronger output functions that one could consider, but most will have a greater computational cost, and the DXSM output function has now received many CPU cycles of testing via](bit_generators/pcg64dxsm.html#numpy.random.PCG64DXSM)
`PCG64DXSM`
`PractRand`
at this time.# Using F2PY bindings in Python[#](#using-f2py-bindings-in-python)
In this page, you can find a full description and a few examples of common usage
patterns for F2PY with Python and different argument types. For more examples
and use cases, see [F2PY examples](f2py-examples.html#f2py-examples).

## Fortran type objects[#](#fortran-type-objects)
All wrappers for Fortran/C routines, common blocks, or for Fortran 90 module
data generated by F2PY are exposed to Python as `fortran`
type objects.
Routine wrappers are callable `fortran`
type objects while wrappers to Fortran
data have attributes referring to data objects.

All `fortran`
type objects have an attribute `_cpointer`
that contains a
[ PyCapsule](https://docs.python.org/3/c-api/capsule.html#c.PyCapsule) referring to the C pointer of the corresponding Fortran/C function
or variable at the C level. Such

`PyCapsule`
objects can be used as callback
arguments for F2PY generated functions to bypass the Python C/API layer for
calling Python functions from Fortran or C. This can be useful when the
computational aspects of such functions are implemented in C or Fortran and
wrapped with F2PY (or any other tool capable of providing the `PyCapsule`
containing a function).Consider a Fortran 77 file ``ftype.f`
:

```
C FILE: FTYPE.F
SUBROUTINE FOO(N)
INTEGER N
Cf2py integer optional,intent(in) :: n = 13
REAL A,X
COMMON /DATA/ A,X(3)
C PRINT*, "IN FOO: N=",N," A=",A," X=[",X(1),X(2),X(3),"]"
END
C END OF FTYPE.F
```
and a wrapper built using `f2py -c ftype.f -m ftype`
.

In Python, you can observe the types of `foo`
and `data`
, and how to access
individual objects of the wrapped Fortran code.

```
>>> import ftype
>>> print(ftype.__doc__)
This module 'ftype' is auto-generated with f2py (version:2).
Functions:
foo(n=13)
COMMON blocks:
/data/ a,x(3)
.
>>> type(ftype.foo), type(ftype.data)
(<class 'fortran'>, <class 'fortran'>)
>>> ftype.foo()
IN FOO: N= 13 A= 0. X=[ 0. 0. 0.]
>>> ftype.data.a = 3
>>> ftype.data.x = [1,2,3]
>>> ftype.foo()
IN FOO: N= 13 A= 3. X=[ 1. 2. 3.]
>>> ftype.data.x[1] = 45
>>> ftype.foo(24)
IN FOO: N= 24 A= 3. X=[ 1. 45. 3.]
>>> ftype.data.x
array([ 1., 45., 3.], dtype=float32)
```
## Scalar arguments[#](#scalar-arguments)
In general, a scalar argument for a F2PY generated wrapper function can be an ordinary Python scalar (integer, float, complex number) as well as an arbitrary sequence object (list, tuple, array, string) of scalars. In the latter case, the first element of the sequence object is passed to the Fortran routine as a scalar argument.

Note

When type-casting is required and there is possible loss of information via narrowing e.g. when type-casting float to integer or complex to float, F2PY

*does not*raise an exception.For complex to real type-casting only the real part of a complex number is used.

`intent(inout)`
scalar arguments are assumed to be array objects in order to have*in situ*changes be effective. It is recommended to use arrays with proper type but also other types work.[Read more about the intent attribute](signature-file.html#f2py-attributes).
Consider the following Fortran 77 code:

```
C FILE: SCALAR.F
SUBROUTINE FOO(A,B)
REAL*8 A, B
Cf2py intent(in) a
Cf2py intent(inout) b
PRINT*, " A=",A," B=",B
PRINT*, "INCREMENT A AND B"
A = A + 1D0
B = B + 1D0
PRINT*, "NEW A=",A," B=",B
END
C END OF FILE SCALAR.F
```
and wrap it using `f2py -c -m scalar scalar.f`
.

In Python:

```
>>> import scalar
>>> print(scalar.foo.__doc__)
foo(a,b)
Wrapper for ``foo``.
Parameters
----------
a : input float
b : in/output rank-0 array(float,'d')
>>> scalar.foo(2, 3)
A= 2. B= 3.
INCREMENT A AND B
NEW A= 3. B= 4.
>>> import numpy
>>> a = numpy.array(2) # these are integer rank-0 arrays
>>> b = numpy.array(3)
>>> scalar.foo(a, b)
A= 2. B= 3.
INCREMENT A AND B
NEW A= 3. B= 4.
>>> print(a, b) # note that only b is changed in situ
2 4
```
## String arguments[#](#string-arguments)
F2PY generated wrapper functions accept almost any Python object as a string
argument, since `str`
is applied for non-string objects. Exceptions are NumPy
arrays that must have type code `'S1'`
or `'b'`
(corresponding to the
outdated `'c'`
or `'1'`
typecodes, respectively) when used as string
arguments. See [Scalars](../reference/arrays.scalars.html#arrays-scalars) for more information on these typecodes.

A string can have an arbitrary length when used as a string argument for an F2PY
generated wrapper function. If the length is greater than expected, the string
is truncated silently. If the length is smaller than expected, additional memory
is allocated and filled with `\0`
.

Because Python strings are immutable, an `intent(inout)`
argument expects an
array version of a string in order to have *in situ* changes be effective.

Consider the following Fortran 77 code:

```
C FILE: STRING.F
SUBROUTINE FOO(A,B,C,D)
CHARACTER*5 A, B
CHARACTER*(*) C,D
Cf2py intent(in) a,c
Cf2py intent(inout) b,d
PRINT*, "A=",A
PRINT*, "B=",B
PRINT*, "C=",C
PRINT*, "D=",D
PRINT*, "CHANGE A,B,C,D"
A(1:1) = 'A'
B(1:1) = 'B'
C(1:1) = 'C'
D(1:1) = 'D'
PRINT*, "A=",A
PRINT*, "B=",B
PRINT*, "C=",C
PRINT*, "D=",D
END
C END OF FILE STRING.F
```
and wrap it using `f2py -c -m mystring string.f`
.

Python session:

```
>>> import mystring
>>> print(mystring.foo.__doc__)
foo(a,b,c,d)
Wrapper for ``foo``.
Parameters
----------
a : input string(len=5)
b : in/output rank-0 array(string(len=5),'c')
c : input string(len=-1)
d : in/output rank-0 array(string(len=-1),'c')
>>> from numpy import array
>>> a = array(b'123\0\0')
>>> b = array(b'123\0\0')
>>> c = array(b'123')
>>> d = array(b'123')
>>> mystring.foo(a, b, c, d)
A=123
B=123
C=123
D=123
CHANGE A,B,C,D
A=A23
B=B23
C=C23
D=D23
>>> a[()], b[()], c[()], d[()]
(b'123', b'B23', b'123', b'D2')
```
## Array arguments[#](#array-arguments)
In general, array arguments for F2PY generated wrapper functions accept arbitrary sequences that can be transformed to NumPy array objects. There are two notable exceptions:

`intent(inout)`
array arguments must always be[proper-contiguous](../glossary.html#term-contiguous)and have a compatible`dtype`
, otherwise an exception is raised.
`intent(inplace)`
array arguments will be changed*in situ*if the argument has a different type than expected (see the`intent(inplace)`
[attribute](signature-file.html#f2py-attributes)for more information).
In general, if a NumPy array is [proper-contiguous](../glossary.html#term-contiguous) and has
a proper type then it is directly passed to the wrapped Fortran/C function.
Otherwise, an element-wise copy of the input array is made and the copy, being
proper-contiguous and with proper type, is used as the array argument.

Usually there is no need to worry about how the arrays are stored in memory and whether the wrapped functions, being either Fortran or C functions, assume one or another storage order. F2PY automatically ensures that wrapped functions get arguments with the proper storage order; the underlying algorithm is designed to make copies of arrays only when absolutely necessary. However, when dealing with very large multidimensional input arrays with sizes close to the size of the physical memory in your computer, then care must be taken to ensure the usage of proper-contiguous and proper type arguments.

To transform input arrays to column major storage order before passing
them to Fortran routines, use the function [ numpy.asfortranarray](../reference/generated/numpy.asfortranarray.html#numpy.asfortranarray).

Consider the following Fortran 77 code:

```
C FILE: ARRAY.F
SUBROUTINE FOO(A,N,M)
C
C INCREMENT THE FIRST ROW AND DECREMENT THE FIRST COLUMN OF A
C
INTEGER N,M,I,J
REAL*8 A(N,M)
Cf2py intent(in,out,copy) a
Cf2py integer intent(hide),depend(a) :: n=shape(a,0), m=shape(a,1)
DO J=1,M
A(1,J) = A(1,J) + 1D0
ENDDO
DO I=1,N
A(I,1) = A(I,1) - 1D0
ENDDO
END
C END OF FILE ARRAY.F
```
and wrap it using `f2py -c -m arr array.f -DF2PY_REPORT_ON_ARRAY_COPY=1`
.

In Python:

```
>>> import arr
>>> from numpy import asfortranarray
>>> print(arr.foo.__doc__)
a = foo(a,[overwrite_a])
Wrapper for ``foo``.
Parameters
----------
a : input rank-2 array('d') with bounds (n,m)
Other Parameters
----------------
overwrite_a : input int, optional
Default: 0
Returns
-------
a : rank-2 array('d') with bounds (n,m)
>>> a = arr.foo([[1, 2, 3],
... [4, 5, 6]])
created an array from object
>>> print(a)
[[ 1. 3. 4.]
[ 3. 5. 6.]]
>>> a.flags.c_contiguous
False
>>> a.flags.f_contiguous
True
# even if a is proper-contiguous and has proper type,
# a copy is made forced by intent(copy) attribute
# to preserve its original contents
>>> b = arr.foo(a)
copied an array: size=6, elsize=8
>>> print(a)
[[ 1. 3. 4.]
[ 3. 5. 6.]]
>>> print(b)
[[ 1. 4. 5.]
[ 2. 5. 6.]]
>>> b = arr.foo(a, overwrite_a = 1) # a is passed directly to Fortran
... # routine and its contents is discarded
...
>>> print(a)
[[ 1. 4. 5.]
[ 2. 5. 6.]]
>>> print(b)
[[ 1. 4. 5.]
[ 2. 5. 6.]]
>>> a is b # a and b are actually the same objects
True
>>> print(arr.foo([1, 2, 3])) # different rank arrays are allowed
created an array from object
[ 1. 1. 2.]
>>> print(arr.foo([[[1], [2], [3]]]))
created an array from object
[[[ 1.]
[ 1.]
[ 2.]]]
>>>
>>> # Creating arrays with column major data storage order:
...
>>> s = asfortranarray([[1, 2, 3], [4, 5, 6]])
>>> s.flags.f_contiguous
True
>>> print(s)
[[1 2 3]
[4 5 6]]
>>> print(arr.foo(s))
>>> s2 = asfortranarray(s)
>>> s2 is s # an array with column major storage order
# is returned immediately
True
>>> # Note that arr.foo returns a column major data storage order array:
...
>>> s3 = ascontiguousarray(s)
>>> s3.flags.f_contiguous
False
>>> s3.flags.c_contiguous
True
>>> s3 = arr.foo(s3)
copied an array: size=6, elsize=8
>>> s3.flags.f_contiguous
True
>>> s3.flags.c_contiguous
False
```
## Call-back arguments[#](#call-back-arguments)
F2PY supports calling Python functions from Fortran or C codes.

Consider the following Fortran 77 code:

```
C FILE: CALLBACK.F
SUBROUTINE FOO(FUN,R)
EXTERNAL FUN
INTEGER I
REAL*8 R, FUN
Cf2py intent(out) r
R = 0D0
DO I=-5,5
R = R + FUN(I)
ENDDO
END
C END OF FILE CALLBACK.F
```
and wrap it using `f2py -c -m callback callback.f`
.

In Python:

```
>>> import callback
>>> print(callback.foo.__doc__)
r = foo(fun,[fun_extra_args])
Wrapper for ``foo``.
Parameters
----------
fun : call-back function
Other Parameters
----------------
fun_extra_args : input tuple, optional
Default: ()
Returns
-------
r : float
Notes
-----
Call-back functions::
def fun(i): return r
Required arguments:
i : input int
Return objects:
r : float
>>> def f(i): return i*i
...
>>> print(callback.foo(f))
110.0
>>> print(callback.foo(lambda i:1))
11.0
```
In the above example F2PY was able to guess accurately the signature of the call-back function. However, sometimes F2PY cannot establish the appropriate signature; in these cases the signature of the call-back function must be explicitly defined in the signature file.

To facilitate this, signature files may contain special modules (the names of
these modules contain the special `__user__`
sub-string) that define the
various signatures for call-back functions. Callback arguments in routine
signatures have the `external`
attribute (see also the `intent(callback)`
[attribute](signature-file.html#f2py-attributes)). To relate a callback argument with its
signature in a `__user__`
module block, a `use`
statement can be utilized as
illustrated below. The same signature for a callback argument can be referred to
in different routine signatures.

We use the same Fortran 77 code as in the previous example but now
we will pretend that F2PY was not able to guess the signatures of
call-back arguments correctly. First, we create an initial signature
file `callback2.pyf`
using F2PY:

```
f2py -m callback2 -h callback2.pyf callback.f
```
Then modify it as follows

```
! -*- f90 -*-
python module __user__routines
interface
function fun(i) result (r)
integer :: i
real*8 :: r
end function fun
end interface
end python module __user__routines
python module callback2
interface
subroutine foo(f,r)
use __user__routines, f=>fun
external f
real*8 intent(out) :: r
end subroutine foo
end interface
end python module callback2
```
Finally, we build the extension module using
`f2py -c callback2.pyf callback.f`
.

An example Python session for this snippet would be identical to the previous example except that the argument names would differ.

Sometimes a Fortran package may require that users provide routines that the package will use. F2PY can construct an interface to such routines so that Python functions can be called from Fortran.

Consider the following Fortran 77 subroutine that takes an array as its input
and applies a function `func`
to its elements.

```
subroutine calculate(x,n)
cf2py intent(callback) func
external func
c The following lines define the signature of func for F2PY:
cf2py real*8 y
cf2py y = func(y)
c
cf2py intent(in,out,copy) x
integer n,i
real*8 x(n), func
do i=1,n
x(i) = func(x(i))
end do
end
```
The Fortran code expects that the function `func`
has been defined externally.
In order to use a Python function for `func`
, it must have an attribute
`intent(callback)`
and it must be specified before the `external`
statement.

Finally, build an extension module using `f2py -c -m foo calculate.f`

In Python:

```
>>> import foo
>>> foo.calculate(range(5), lambda x: x*x)
array([ 0., 1., 4., 9., 16.])
>>> import math
>>> foo.calculate(range(5), math.exp)
array([ 1. , 2.71828183, 7.3890561, 20.08553692, 54.59815003])
```
The function is included as an argument to the python function call to the
Fortran subroutine even though it was *not* in the Fortran subroutine argument
list. The “external” keyword refers to the C function generated by f2py, not the
Python function itself. The python function is essentially being supplied to the
C function.

The callback function may also be explicitly set in the module. Then it is not necessary to pass the function in the argument list to the Fortran function. This may be desired if the Fortran function calling the Python callback function is itself called by another Fortran function.

Consider the following Fortran 77 subroutine:

```
subroutine f1()
print *, "in f1, calling f2 twice.."
call f2()
call f2()
return
end
subroutine f2()
cf2py intent(callback, hide) fpy
external fpy
print *, "in f2, calling f2py.."
call fpy()
return
end
```
and wrap it using `f2py -c -m pfromf extcallback.f`
.

In Python:

```
>>> import pfromf
>>> pfromf.f2()
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
pfromf.error: Callback fpy not defined (as an argument or module pfromf attribute).
>>> def f(): print("python f")
...
>>> pfromf.fpy = f
>>> pfromf.f2()
in f2, calling f2py..
python f
>>> pfromf.f1()
in f1, calling f2 twice..
in f2, calling f2py..
python f
in f2, calling f2py..
python f
>>>
```
### Resolving arguments to call-back functions[#](#resolving-arguments-to-call-back-functions)
F2PY generated interfaces are very flexible with respect to call-back arguments. For each call-back argument an additional optional
argument `<name>_extra_args`
is introduced by F2PY. This argument can be used
to pass extra arguments to user provided call-back functions.

If a F2PY generated wrapper function expects the following call-back argument:

```
def fun(a_1,...,a_n):
...
return x_1,...,x_k
```
but the following Python function

```
def gun(b_1,...,b_m):
...
return y_1,...,y_l
```
is provided by a user, and in addition,

```
fun_extra_args = (e_1,...,e_p)
```
is used, then the following rules are applied when a Fortran or C function
evaluates the call-back argument `gun`
:

If

`p == 0`
then`gun(a_1, ..., a_q)`
is called, here`q = min(m, n)`
.
If

`n + p <= m`
then`gun(a_1, ..., a_n, e_1, ..., e_p)`
is called.
If

`p <= m < n + p`
then`gun(a_1, ..., a_q, e_1, ..., e_p)`
is called, and here`q=m-p`
.
If

`p > m`
then`gun(e_1, ..., e_m)`
is called.
If

`n + p`
is less than the number of required arguments to`gun`
then an exception is raised.
If the function `gun`
may return any number of objects as a tuple; then the
following rules are applied:

If

`k < l`
, then`y_{k + 1}, ..., y_l`
are ignored.
If

`k > l`
, then only`x_1, ..., x_l`
are set.
## Common blocks[#](#common-blocks)
F2PY generates wrappers to `common`
blocks defined in a routine signature
block. Common blocks are visible to all Fortran codes linked to the current
extension module, but not to other extension modules (this restriction is due to
the way Python imports shared libraries). In Python, the F2PY wrappers to
`common`
blocks are `fortran`
type objects that have (dynamic) attributes
related to the data members of the common blocks. When accessed, these
attributes return as NumPy array objects (multidimensional arrays are
Fortran-contiguous) which directly link to data members in common blocks. Data
members can be changed by direct assignment or by in-place changes to the
corresponding array objects.

Consider the following Fortran 77 code:

```
C FILE: COMMON.F
SUBROUTINE FOO
INTEGER I,X
REAL A
COMMON /DATA/ I,X(4),A(2,3)
PRINT*, "I=",I
PRINT*, "X=[",X,"]"
PRINT*, "A=["
PRINT*, "[",A(1,1),",",A(1,2),",",A(1,3),"]"
PRINT*, "[",A(2,1),",",A(2,2),",",A(2,3),"]"
PRINT*, "]"
END
C END OF COMMON.F
```
and wrap it using `f2py -c -m common common.f`
.

In Python:

```
>>> import common
>>> print(common.data.__doc__)
i : 'i'-scalar
x : 'i'-array(4)
a : 'f'-array(2,3)
>>> common.data.i = 5
>>> common.data.x[1] = 2
>>> common.data.a = [[1,2,3],[4,5,6]]
>>> common.foo()
>>> common.foo()
I= 5
X=[ 0 2 0 0 ]
A=[
[ 1.00000000 , 2.00000000 , 3.00000000 ]
[ 4.00000000 , 5.00000000 , 6.00000000 ]
]
>>> common.data.a[1] = 45
>>> common.foo()
I= 5
X=[ 0 2 0 0 ]
A=[
[ 1.00000000 , 2.00000000 , 3.00000000 ]
[ 45.0000000 , 45.0000000 , 45.0000000 ]
]
>>> common.data.a # a is Fortran-contiguous
array([[ 1., 2., 3.],
[ 45., 45., 45.]], dtype=float32)
>>> common.data.a.flags.f_contiguous
True
```
## Fortran 90 module data[#](#fortran-90-module-data)
The F2PY interface to Fortran 90 module data is similar to the handling of Fortran 77 common blocks.

Consider the following Fortran 90 code:

```
module mod
integer i
integer :: x(4)
real, dimension(2,3) :: a
real, allocatable, dimension(:,:) :: b
contains
subroutine foo
integer k
print*, "i=",i
print*, "x=[",x,"]"
print*, "a=["
print*, "[",a(1,1),",",a(1,2),",",a(1,3),"]"
print*, "[",a(2,1),",",a(2,2),",",a(2,3),"]"
print*, "]"
print*, "Setting a(1,2)=a(1,2)+3"
a(1,2) = a(1,2)+3
end subroutine foo
end module mod
```
and wrap it using `f2py -c -m moddata moddata.f90`
.

In Python:

```
>>> import moddata
>>> print(moddata.mod.__doc__)
i : 'i'-scalar
x : 'i'-array(4)
a : 'f'-array(2,3)
b : 'f'-array(-1,-1), not allocated
foo()
Wrapper for ``foo``.
>>> moddata.mod.i = 5
>>> moddata.mod.x[:2] = [1,2]
>>> moddata.mod.a = [[1,2,3],[4,5,6]]
>>> moddata.mod.foo()
i= 5
x=[ 1 2 0 0 ]
a=[
[ 1.000000 , 2.000000 , 3.000000 ]
[ 4.000000 , 5.000000 , 6.000000 ]
]
Setting a(1,2)=a(1,2)+3
>>> moddata.mod.a # a is Fortran-contiguous
array([[ 1., 5., 3.],
[ 4., 5., 6.]], dtype=float32)
>>> moddata.mod.a.flags.f_contiguous
True
```
## Allocatable arrays[#](#allocatable-arrays)
F2PY has basic support for Fortran 90 module allocatable arrays.

Consider the following Fortran 90 code:

```
module mod
real, allocatable, dimension(:,:) :: b
contains
subroutine foo
integer k
if (allocated(b)) then
print*, "b=["
do k = 1,size(b,1)
print*, b(k,1:size(b,2))
enddo
print*, "]"
else
print*, "b is not allocated"
endif
end subroutine foo
end module mod
```
and wrap it using `f2py -c -m allocarr allocarr.f90`
.

In Python:

```
>>> import allocarr
>>> print(allocarr.mod.__doc__)
b : 'f'-array(-1,-1), not allocated
foo()
Wrapper for ``foo``.
>>> allocarr.mod.foo()
b is not allocated
>>> allocarr.mod.b = [[1, 2, 3], [4, 5, 6]] # allocate/initialize b
>>> allocarr.mod.foo()
b=[
1.000000 2.000000 3.000000
4.000000 5.000000 6.000000
]
>>> allocarr.mod.b # b is Fortran-contiguous
array([[ 1., 2., 3.],
[ 4., 5., 6.]], dtype=float32)
>>> allocarr.mod.b.flags.f_contiguous
True
>>> allocarr.mod.b = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] # reallocate/initialize b
>>> allocarr.mod.foo()
b=[
1.000000 2.000000 3.000000
4.000000 5.000000 6.000000
7.000000 8.000000 9.000000
]
>>> allocarr.mod.b = None # deallocate array
>>> allocarr.mod.foo()
b is not allocated
```# F2PY test suite[#](#f2py-test-suite)
F2PY’s test suite is present in the directory `numpy/f2py/tests`
. Its aim
is to ensure that Fortran language features are correctly translated to Python.
For example, the user can specify starting and ending indices of arrays in
Fortran. This behaviour is translated to the generated CPython library where
the arrays strictly start from 0 index.

The directory of the test suite looks like the following:

```
./tests/
├── __init__.py
├── src
│ ├── abstract_interface
│ ├── array_from_pyobj
│ ├── // ... several test folders
│ └── string
├── test_abstract_interface.py
├── test_array_from_pyobj.py
├── // ... several test files
├── test_symbolic.py
└── util.py
```
Files starting with `test_`
contain tests for various aspects of f2py from parsing
Fortran files to checking modules’ documentation. `src`
directory contains the
Fortran source files upon which we do the testing. `util.py`
contains utility
functions for building and importing Fortran modules during test time using a
temporary location.

## Adding a test[#](#adding-a-test)
F2PY’s current test suite predates `pytest`
and therefore does not use fixtures.
Instead, the test files contain test classes that inherit from `F2PyTest`
class present in `util.py`
.

```
1 cmd = [sys.executable, script, "build_ext", "-i"]
2 p = subprocess.Popen(cmd,
3 stdout=subprocess.PIPE,
4 stderr=subprocess.STDOUT)
5 out, err = p.communicate()
6 if p.returncode != 0:
7 raise RuntimeError("Running distutils build failed: %s\n%s" %
8 (cmd[4:], asstr(out)))
9 finally:
10 os.chdir(cwd)
```
This class many helper functions for parsing and compiling test source files. Its child
classes can override its `sources`
data member to provide their own source files.
This superclass will then compile the added source files upon object creation andtheir
functions will be appended to `self.module`
data member. Thus, the child classes will
be able to access the fortran functions specified in source file by calling
`self.module.[fortran_function_name]`
.

### Example[#](#example)
Consider the following subroutines, contained in a file named `add-test.f`

```
subroutine addb(k)
real(8), intent(inout) :: k(:)
k=k+1
endsubroutine
subroutine addc(w,k)
real(8), intent(in) :: w(:)
real(8), intent(out) :: k(size(w))
k=w+1
endsubroutine
```
The first routine *addb* simply takes an array and increases its elements by 1.
The second subroutine *addc* assigns a new array *k* with elements greater that
the elements of the input array *w* by 1.

A test can be implemented as follows:

```
class TestAdd(util.F2PyTest):
sources = [util.getpath("add-test.f")]
def test_module(self):
k = np.array([1, 2, 3], dtype=np.float64)
w = np.array([1, 2, 3], dtype=np.float64)
self.module.subb(k)
assert np.allclose(k, w + 1)
self.module.subc([w, k])
assert np.allclose(k, w + 1)
```
We override the `sources`
data member to provide the source file. The source files
are compiled and subroutines are attached to module data member when the class object
is created. The `test_module`
function calls the subroutines and tests their results.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Extending[#](#extending)
The BitGenerators have been designed to be extendable using standard tools for
high-performance Python – numba and Cython. The [ Generator](generator.html#numpy.random.Generator) object can also
be used with user-provided BitGenerators as long as these export a small set of
required functions.

## Numba[#](#numba)
Numba can be used with either CTypes or CFFI. The current iteration of the BitGenerators all export a small set of functions through both interfaces.

This example shows how numba can be used to produce gaussian samples using
a pure Python implementation which is then compiled. The random numbers are
provided by `ctypes.next_double`
.

```
import numpy as np
import numba as nb
from numpy.random import PCG64
from timeit import timeit
bit_gen = PCG64()
next_d = bit_gen.cffi.next_double
state_addr = bit_gen.cffi.state_address
def normals(n, state):
out = np.empty(n)
for i in range((n + 1) // 2):
x1 = 2.0 * next_d(state) - 1.0
x2 = 2.0 * next_d(state) - 1.0
r2 = x1 * x1 + x2 * x2
while r2 >= 1.0 or r2 == 0.0:
x1 = 2.0 * next_d(state) - 1.0
x2 = 2.0 * next_d(state) - 1.0
r2 = x1 * x1 + x2 * x2
f = np.sqrt(-2.0 * np.log(r2) / r2)
out[2 * i] = f * x1
if 2 * i + 1 < n:
out[2 * i + 1] = f * x2
return out
# Compile using Numba
normalsj = nb.jit(normals, nopython=True)
# Must use state address not state with numba
n = 10000
def numbacall():
return normalsj(n, state_addr)
rg = np.random.Generator(PCG64())
def numpycall():
return rg.normal(size=n)
# Check that the functions work
r1 = numbacall()
r2 = numpycall()
assert r1.shape == (n,)
assert r1.shape == r2.shape
t1 = timeit(numbacall, number=1000)
print(f'{t1:.2f} secs for {n} PCG64 (Numba/PCG64) gaussian randoms')
t2 = timeit(numpycall, number=1000)
print(f'{t2:.2f} secs for {n} PCG64 (NumPy/PCG64) gaussian randoms')
```
Both CTypes and CFFI allow the more complicated distributions to be used
directly in Numba after compiling the file distributions.c into a `DLL`
or
`so`
. An example showing the use of a more complicated distribution is in
the [Examples](#examples) section below.

## Cython[#](#cython)
Cython can be used to unpack the `PyCapsule`
provided by a BitGenerator.
This example uses [ PCG64](bit_generators/pcg64.html#numpy.random.PCG64) and the example from above. The usual caveats
for writing high-performance code using Cython – removing bounds checks and
wrap around, providing array alignment information – still apply.

```
#!/usr/bin/env python3
#cython: language_level=3
"""
This file shows how the to use a BitGenerator to create a distribution.
"""
import numpy as np
cimport numpy as np
cimport cython
from cpython.pycapsule cimport PyCapsule_IsValid, PyCapsule_GetPointer
from libc.stdint cimport uint16_t, uint64_t
from numpy.random cimport bitgen_t
from numpy.random import PCG64
from numpy.random.c_distributions cimport (
random_standard_uniform_fill, random_standard_uniform_fill_f)
@cython.boundscheck(False)
@cython.wraparound(False)
def uniforms(Py_ssize_t n):
"""
Create an array of `n` uniformly distributed doubles.
A 'real' distribution would want to process the values into
some non-uniform distribution
"""
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef const char *capsule_name = "BitGenerator"
cdef double[::1] random_values
x = PCG64()
capsule = x.capsule
# Optional check that the capsule if from a BitGenerator
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
# Cast the pointer
rng = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)
random_values = np.empty(n, dtype='float64')
with x.lock, nogil:
for i in range(n):
# Call the function
random_values[i] = rng.next_double(rng.state)
randoms = np.asarray(random_values)
return randoms
```
The BitGenerator can also be directly accessed using the members of the `bitgen_t`
struct.

```
@cython.boundscheck(False)
@cython.wraparound(False)
def uint10_uniforms(Py_ssize_t n):
"""Uniform 10 bit integers stored as 16-bit unsigned integers"""
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef const char *capsule_name = "BitGenerator"
cdef uint16_t[::1] random_values
cdef int bits_remaining
cdef int width = 10
cdef uint64_t buff, mask = 0x3FF
x = PCG64()
capsule = x.capsule
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
rng = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)
random_values = np.empty(n, dtype='uint16')
# Best practice is to release GIL and acquire the lock
bits_remaining = 0
with x.lock, nogil:
for i in range(n):
if bits_remaining < width:
buff = rng.next_uint64(rng.state)
random_values[i] = buff & mask
buff >>= width
randoms = np.asarray(random_values)
return randoms
```
Cython can be used to directly access the functions in
`numpy/random/c_distributions.pxd`
. This requires linking with the
`npyrandom`
library located in `numpy/random/lib`
.

```
def uniforms_ex(bit_generator, Py_ssize_t n, dtype=np.float64):
"""
Create an array of `n` uniformly distributed doubles via a "fill" function.
A 'real' distribution would want to process the values into
some non-uniform distribution
Parameters
----------
bit_generator: BitGenerator instance
n: int
Output vector length
dtype: {str, dtype}, optional
Desired dtype, either 'd' (or 'float64') or 'f' (or 'float32'). The
default dtype value is 'd'
"""
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef const char *capsule_name = "BitGenerator"
cdef np.ndarray randoms
capsule = bit_generator.capsule
# Optional check that the capsule if from a BitGenerator
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
# Cast the pointer
rng = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)
_dtype = np.dtype(dtype)
randoms = np.empty(n, dtype=_dtype)
if _dtype == np.float32:
with bit_generator.lock:
random_standard_uniform_fill_f(rng, n, <float*>np.PyArray_DATA(randoms))
elif _dtype == np.float64:
with bit_generator.lock:
random_standard_uniform_fill(rng, n, <double*>np.PyArray_DATA(randoms))
else:
raise TypeError('Unsupported dtype %r for random' % _dtype)
return randoms
```
See [Extending numpy.random via Cython](examples/cython/index.html#extending-cython-example) for the complete listings of these examples
and a minimal `setup.py`
to build the c-extension modules.

## CFFI[#](#cffi)
CFFI can be used to directly access the functions in
`include/numpy/random/distributions.h`
. Some “massaging” of the header
file is required:

```
"""
Use cffi to access any of the underlying C functions from distributions.h
"""
import os
import numpy as np
import cffi
from .parse import parse_distributions_h
ffi = cffi.FFI()
inc_dir = os.path.join(np.get_include(), 'numpy')
# Basic numpy types
ffi.cdef('''
typedef intptr_t npy_intp;
typedef unsigned char npy_bool;
''')
parse_distributions_h(ffi, inc_dir)
```
Once the header is parsed by `ffi.cdef`
, the functions can be accessed
directly from the `_generator`
shared object, using the [ BitGenerator.cffi](bit_generators/generated/numpy.random.BitGenerator.cffi.html#numpy.random.BitGenerator.cffi) interface.

```
# Compare the distributions.h random_standard_normal_fill to
# Generator.standard_random
bit_gen = np.random.PCG64()
rng = np.random.Generator(bit_gen)
state = bit_gen.state
interface = rng.bit_generator.cffi
n = 100
vals_cffi = ffi.new('double[%d]' % n)
lib.random_standard_normal_fill(interface.bit_generator, n, vals_cffi)
# reset the state
bit_gen.state = state
vals = rng.standard_normal(n)
for i in range(n):
assert vals[i] == vals_cffi[i]
```
## New Bit Generators[#](#new-bit-generators)
[ Generator](generator.html#numpy.random.Generator) can be used with user-provided
[s. The simplest way to write a new BitGenerator is to examine the pyx file of one of the existing BitGenerators. The key structure that must be provided is the](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
`capsule`
which contains a `PyCapsule`
to a struct pointer of type
`bitgen_t`
,```
typedef struct bitgen {
void *state;
uint64_t (*next_uint64)(void *st);
uint32_t (*next_uint32)(void *st);
double (*next_double)(void *st);
uint64_t (*next_raw)(void *st);
} bitgen_t;
```
which provides 5 pointers. The first is an opaque pointer to the data structure
used by the BitGenerators. The next three are function pointers which return
the next 64- and 32-bit unsigned integers, the next random double and the next
raw value. This final function is used for testing and so can be set to
the next 64-bit unsigned integer function if not needed. Functions inside
`Generator`
use this structure as in

```
bitgen_state->next_uint64(bitgen_state->state)
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Importing data with `genfromtxt`
[#](#importing-data-with-genfromtxt)
`genfromtxt`
NumPy provides several functions to create arrays from tabular data.
We focus here on the [ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) function.

In a nutshell, [ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) runs two main loops. The first
loop converts each line of the file in a sequence of strings. The second
loop converts each string to the appropriate data type. This mechanism is
slower than a single loop, but gives more flexibility. In particular,

[is able to take missing data into account, when other faster and simpler functions like](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)
`genfromtxt`
[cannot.](../reference/generated/numpy.loadtxt.html#numpy.loadtxt)
`loadtxt`
Note

When giving examples, we will use the following conventions:

```
>>> import numpy as np
>>> from io import StringIO
```
## Defining the input[#](#defining-the-input)
The only mandatory argument of [ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) is the source of
the data. It can be a string, a list of strings, a generator or an open
file-like object with a

`read`
method, for example, a file or
[object. If a single string is provided, it is assumed to be the name of a local or remote file. If a list of strings or a generator returning strings is provided, each string is treated as one line in a file. When the URL of a remote file is passed, the file is automatically downloaded to the current directory and opened.](https://docs.python.org/3/library/io.html#io.StringIO)
`io.StringIO`
Recognized file types are text files and archives. Currently, the function
recognizes `gzip`
and `bz2`
(`bzip2`
) archives. The type of
the archive is determined from the extension of the file: if the filename
ends with `'.gz'`
, a `gzip`
archive is expected; if it ends with
`'bz2'`
, a `bzip2`
archive is assumed.

## Splitting the lines into columns[#](#splitting-the-lines-into-columns)
### The `delimiter`
argument[#](#the-delimiter-argument)
Once the file is defined and open for reading, [ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)
splits each non-empty line into a sequence of strings. Empty or commented
lines are just skipped. The

`delimiter`
keyword is used to define
how the splitting should take place.Quite often, a single character marks the separation between columns. For
example, comma-separated files (CSV) use a comma (`,`
) or a semicolon
(`;`
) as delimiter:

```
>>> data = u"1, 2, 3\n4, 5, 6"
>>> np.genfromtxt(StringIO(data), delimiter=",")
array([[1., 2., 3.],
[4., 5., 6.]])
```
Another common separator is `"\t"`
, the tabulation character. However,
we are not limited to a single character, any string will do. By default,
[ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) assumes

`delimiter=None`
, meaning that the line
is split along white spaces (including tabs) and that consecutive white
spaces are considered as a single white space.Alternatively, we may be dealing with a fixed-width file, where columns are
defined as a given number of characters. In that case, we need to set
`delimiter`
to a single integer (if all the columns have the same
size) or to a sequence of integers (if columns can have different sizes):

```
>>> data = u" 1 2 3\n 4 5 67\n890123 4"
>>> np.genfromtxt(StringIO(data), delimiter=3)
array([[ 1., 2., 3.],
[ 4., 5., 67.],
[890., 123., 4.]])
>>> data = u"123456789\n 4 7 9\n 4567 9"
>>> np.genfromtxt(StringIO(data), delimiter=(4, 3, 2))
array([[1234., 567., 89.],
[ 4., 7., 9.],
[ 4., 567., 9.]])
```
### The `autostrip`
argument[#](#the-autostrip-argument)
By default, when a line is decomposed into a series of strings, the
individual entries are not stripped of leading nor trailing white spaces.
This behavior can be overwritten by setting the optional argument
`autostrip`
to a value of `True`
:

```
>>> data = u"1, abc , 2\n 3, xxx, 4"
>>> # Without autostrip
>>> np.genfromtxt(StringIO(data), delimiter=",", dtype="|U5")
array([['1', ' abc ', ' 2'],
['3', ' xxx', ' 4']], dtype='<U5')
>>> # With autostrip
>>> np.genfromtxt(StringIO(data), delimiter=",", dtype="|U5", autostrip=True)
array([['1', 'abc', '2'],
['3', 'xxx', '4']], dtype='<U5')
```
### The `comments`
argument[#](#the-comments-argument)
The optional argument `comments`
is used to define a character
string that marks the beginning of a comment. By default,
[ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) assumes

`comments='#'`
. The comment marker may
occur anywhere on the line. Any character present after the comment
marker(s) is simply ignored:```
>>> data = u"""#
... # Skip me !
... # Skip me too !
... 1, 2
... 3, 4
... 5, 6 #This is the third line of the data
... 7, 8
... # And here comes the last line
... 9, 0
... """
>>> np.genfromtxt(StringIO(data), comments="#", delimiter=",")
array([[1., 2.],
[3., 4.],
[5., 6.],
[7., 8.],
[9., 0.]])
```
New in version 1.7.0: When `comments`
is set to `None`
, no lines are treated as comments.

Note

There is one notable exception to this behavior: if the optional argument
`names=True`
, the first commented line will be examined for names.

## Skipping lines and choosing columns[#](#skipping-lines-and-choosing-columns)
### The `usecols`
argument[#](#the-usecols-argument)
In some cases, we are not interested in all the columns of the data but
only a few of them. We can select which columns to import with the
`usecols`
argument. This argument accepts a single integer or a
sequence of integers corresponding to the indices of the columns to import.
Remember that by convention, the first column has an index of 0. Negative
integers behave the same as regular Python negative indexes.

For example, if we want to import only the first and the last columns, we
can use `usecols=(0, -1)`
:

```
>>> data = u"1 2 3\n4 5 6"
>>> np.genfromtxt(StringIO(data), usecols=(0, -1))
array([[1., 3.],
[4., 6.]])
```
If the columns have names, we can also select which columns to import by
giving their name to the `usecols`
argument, either as a sequence
of strings or a comma-separated string:

```
>>> data = u"1 2 3\n4 5 6"
>>> np.genfromtxt(StringIO(data),
... names="a, b, c", usecols=("a", "c"))
array([(1., 3.), (4., 6.)], dtype=[('a', '<f8'), ('c', '<f8')])
>>> np.genfromtxt(StringIO(data),
... names="a, b, c", usecols=("a, c"))
array([(1., 3.), (4., 6.)], dtype=[('a', '<f8'), ('c', '<f8')])
```
## Choosing the data type[#](#choosing-the-data-type)
The main way to control how the sequences of strings we have read from the
file are converted to other types is to set the `dtype`
argument.
Acceptable values for this argument are:

a single type, such as

`dtype=float`
. The output will be 2D with the given dtype, unless a name has been associated with each column with the use of the`names`
argument (see below). Note that`dtype=float`
is the default for.`genfromtxt`
a sequence of types, such as

`dtype=(int, float, float)`
.
a comma-separated string, such as

`dtype="i4,f8,|U3"`
.
a dictionary with two keys

`'names'`
and`'formats'`
.
a sequence of tuples

`(name, type)`
, such as`dtype=[('A', int), ('B', float)]`
.
an existing

object.`numpy.dtype`
the special value

`None`
. In that case, the type of the columns will be determined from the data itself (see below).
In all the cases but the first one, the output will be a 1D array with a
structured dtype. This dtype has as many fields as items in the sequence.
The field names are defined with the `names`
keyword.

When `dtype=None`
, the type of each column is determined iteratively from
its data. We start by checking whether a string can be converted to a
boolean (that is, if the string matches `true`
or `false`
in lower
cases); then whether it can be converted to an integer, then to a float,
then to a complex and eventually to a string.

The option `dtype=None`
is provided for convenience. However, it is
significantly slower than setting the dtype explicitly.

## Setting the names[#](#setting-the-names)
### The `names`
argument[#](#the-names-argument)
A natural approach when dealing with tabular data is to allocate a name to each column. A first possibility is to use an explicit structured dtype, as mentioned previously:

```
>>> data = StringIO("1 2 3\n 4 5 6")
>>> np.genfromtxt(data, dtype=[(_, int) for _ in "abc"])
array([(1, 2, 3), (4, 5, 6)],
dtype=[('a', '<i8'), ('b', '<i8'), ('c', '<i8')])
```
Another simpler possibility is to use the `names`
keyword with a
sequence of strings or a comma-separated string:

```
>>> data = StringIO("1 2 3\n 4 5 6")
>>> np.genfromtxt(data, names="A, B, C")
array([(1., 2., 3.), (4., 5., 6.)],
dtype=[('A', '<f8'), ('B', '<f8'), ('C', '<f8')])
```
In the example above, we used the fact that by default, `dtype=float`
.
By giving a sequence of names, we are forcing the output to a structured
dtype.

We may sometimes need to define the column names from the data itself. In
that case, we must use the `names`
keyword with a value of
`True`
. The names will then be read from the first line (after the
`skip_header`
ones), even if the line is commented out:

```
>>> data = StringIO("So it goes\n#a b c\n1 2 3\n 4 5 6")
>>> np.genfromtxt(data, skip_header=1, names=True)
array([(1., 2., 3.), (4., 5., 6.)],
dtype=[('a', '<f8'), ('b', '<f8'), ('c', '<f8')])
```
The default value of `names`
is `None`
. If we give any other
value to the keyword, the new names will overwrite the field names we may
have defined with the dtype:

```
>>> data = StringIO("1 2 3\n 4 5 6")
>>> ndtype=[('a',int), ('b', float), ('c', int)]
>>> names = ["A", "B", "C"]
>>> np.genfromtxt(data, names=names, dtype=ndtype)
array([(1, 2., 3), (4, 5., 6)],
dtype=[('A', '<i8'), ('B', '<f8'), ('C', '<i8')])
```
### The `defaultfmt`
argument[#](#the-defaultfmt-argument)
If `names=None`
but a structured dtype is expected, names are defined
with the standard NumPy default of `"f%i"`
, yielding names like `f0`
,
`f1`
and so forth:

```
>>> data = StringIO("1 2 3\n 4 5 6")
>>> np.genfromtxt(data, dtype=(int, float, int))
array([(1, 2., 3), (4, 5., 6)],
dtype=[('f0', '<i8'), ('f1', '<f8'), ('f2', '<i8')])
```
In the same way, if we don’t give enough names to match the length of the dtype, the missing names will be defined with this default template:

```
>>> data = StringIO("1 2 3\n 4 5 6")
>>> np.genfromtxt(data, dtype=(int, float, int), names="a")
array([(1, 2., 3), (4, 5., 6)],
dtype=[('a', '<i8'), ('f0', '<f8'), ('f1', '<i8')])
```
We can overwrite this default with the `defaultfmt`
argument, that
takes any format string:

```
>>> data = StringIO("1 2 3\n 4 5 6")
>>> np.genfromtxt(data, dtype=(int, float, int), defaultfmt="var_%02i")
array([(1, 2., 3), (4, 5., 6)],
dtype=[('var_00', '<i8'), ('var_01', '<f8'), ('var_02', '<i8')])
```
Note

We need to keep in mind that `defaultfmt`
is used only if some names
are expected but not defined.

### Validating names[#](#validating-names)
NumPy arrays with a structured dtype can also be viewed as
[ recarray](../reference/generated/numpy.recarray.html#numpy.recarray), where a field can be accessed as if it were an
attribute. For that reason, we may need to make sure that the field name
doesn’t contain any space or invalid character, or that it does not
correspond to the name of a standard attribute (like

`size`
or
`shape`
), which would confuse the interpreter. [accepts three optional arguments that provide a finer control on the names:](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)
`genfromtxt`
`deletechars`
-
Gives a string combining all the characters that must be deleted from the name. By default, invalid characters are

`~!@#$%^&*()-=+~\|]}[{';: /?.>,<`
.
`excludelist`
-
Gives a list of the names to exclude, such as

`return`
,`file`
,`'_'`
) will be appended to it.
`case_sensitive`
-
Whether the names should be case-sensitive (

`case_sensitive=True`
), converted to upper case (`case_sensitive=False`
or`case_sensitive='upper'`
) or to lower case (`case_sensitive='lower'`
).
## Tweaking the conversion[#](#tweaking-the-conversion)
### The `converters`
argument[#](#the-converters-argument)
Usually, defining a dtype is sufficient to define how the sequence of
strings must be converted. However, some additional control may sometimes
be required. For example, we may want to make sure that a date in a format
`YYYY/MM/DD`
is converted to a [ datetime](https://docs.python.org/3/library/datetime.html#datetime.datetime) object, or that
a string like

`xx%`
is properly converted to a float between 0 and 1. In
such cases, we should define conversion functions with the `converters`
arguments.The value of this argument is typically a dictionary with column indices or column names as keys and a conversion functions as values. These conversion functions can either be actual functions or lambda functions. In any case, they should accept only a string as input and output only a single element of the wanted type.

In the following example, the second column is converted from as string representing a percentage to a float between 0 and 1:

```
>>> convertfunc = lambda x: float(x.strip(b"%"))/100.
>>> data = u"1, 2.3%, 45.\n6, 78.9%, 0"
>>> names = ("i", "p", "n")
>>> # General case .....
>>> np.genfromtxt(StringIO(data), delimiter=",", names=names)
array([(1., nan, 45.), (6., nan, 0.)],
dtype=[('i', '<f8'), ('p', '<f8'), ('n', '<f8')])
```
We need to keep in mind that by default, `dtype=float`
. A float is
therefore expected for the second column. However, the strings `' 2.3%'`
and `' 78.9%'`
cannot be converted to float and we end up having
`np.nan`
instead. Let’s now use a converter:

```
>>> # Converted case ...
>>> np.genfromtxt(StringIO(data), delimiter=",", names=names,
... converters={1: convertfunc})
array([(1., 0.023, 45.), (6., 0.789, 0.)],
dtype=[('i', '<f8'), ('p', '<f8'), ('n', '<f8')])
```
The same results can be obtained by using the name of the second column
(`"p"`
) as key instead of its index (1):

```
>>> # Using a name for the converter ...
>>> np.genfromtxt(StringIO(data), delimiter=",", names=names,
... converters={"p": convertfunc})
array([(1., 0.023, 45.), (6., 0.789, 0.)],
dtype=[('i', '<f8'), ('p', '<f8'), ('n', '<f8')])
```
Converters can also be used to provide a default for missing entries. In
the following example, the converter `convert`
transforms a stripped
string into the corresponding float or into -999 if the string is empty.
We need to explicitly strip the string from white spaces as it is not done
by default:

```
>>> data = u"1, , 3\n 4, 5, 6"
>>> convert = lambda x: float(x.strip() or -999)
>>> np.genfromtxt(StringIO(data), delimiter=",",
... converters={1: convert})
array([[ 1., -999., 3.],
[ 4., 5., 6.]])
```
### Using missing and filling values[#](#using-missing-and-filling-values)
Some entries may be missing in the dataset we are trying to import. In a previous example, we used a converter to transform an empty string into a float. However, user-defined converters may rapidly become cumbersome to manage.

The [ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) function provides two other complementary
mechanisms: the

`missing_values`
argument is used to recognize
missing data and a second argument, `filling_values`
, is used to
process these missing data.`missing_values`
[#](#missing-values)
By default, any empty string is marked as missing. We can also consider
more complex strings, such as `"N/A"`
or `"???"`
to represent missing
or invalid data. The `missing_values`
argument accepts three kinds
of values:

a string or a comma-separated string
-
-
This string will be used as the marker for missing data for all the columns

a sequence of strings
-
-
In that case, each item is associated to a column, in order.

a dictionary
-
-
Values of the dictionary are strings or sequence of strings. The corresponding keys can be column indices (integers) or column names (strings). In addition, the special key

`None`
can be used to define a default applicable to all columns.
`filling_values`
[#](#filling-values)
We know how to recognize missing data, but we still need to provide a value for these missing entries. By default, this value is determined from the expected dtype according to this table:

Expected type

|
Default

|
---|---|
|
|
|
|
|
|
|
|
|
|
We can get a finer control on the conversion of missing values with the
`filling_values`
optional argument. Like
`missing_values`
, this argument accepts different kind of values:

a single value
-
-
This will be the default for all columns

a sequence of values
-
-
Each entry will be the default for the corresponding column

a dictionary
-
-
Each key can be a column index or a column name, and the corresponding value should be a single object. We can use the special key

`None`
to define a default for all columns.
In the following example, we suppose that the missing values are flagged
with `"N/A"`
in the first column and by `"???"`
in the third column.
We wish to transform these missing values to 0 if they occur in the first
and second column, and to -999 if they occur in the last column:

```
>>> data = u"N/A, 2, 3\n4, ,???"
>>> kwargs = dict(delimiter=",",
... dtype=int,
... names="a,b,c",
... missing_values={0:"N/A", 'b':" ", 2:"???"},
... filling_values={0:0, 'b':0, 2:-999})
>>> np.genfromtxt(StringIO(data), **kwargs)
array([(0, 2, 3), (4, 0, -999)],
dtype=[('a', '<i8'), ('b', '<i8'), ('c', '<i8')])
```
`usemask`
[#](#usemask)
We may also want to keep track of the occurrence of missing data by
constructing a boolean mask, with `True`
entries where data was missing
and `False`
otherwise. To do that, we just have to set the optional
argument `usemask`
to `True`
(the default is `False`
). The
output array will then be a [ MaskedArray](../reference/maskedarray.baseclass.html#numpy.ma.MaskedArray).

## Shortcut functions[#](#shortcut-functions)
In addition to [ genfromtxt](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt), the

`numpy.lib.npyio`
module
provides several convenience functions derived from
[. These functions work the same way as the original, but they have different default values.](../reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)
`genfromtxt`
`numpy.lib.npyio.recfromtxt`
Returns a standard

(if`numpy.recarray`
`usemask=False`
) or a`numpy.ma.mrecords.MaskedRecords`
array (if`usemaske=True`
). The default dtype is`dtype=None`
, meaning that the types of each column will be automatically determined.
`numpy.lib.npyio.recfromcsv`
Like

`numpy.lib.npyio.recfromtxt`
, but with a default`delimiter=","`
.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Using the Convenience Classes[#](#using-the-convenience-classes)
The convenience classes provided by the polynomial package are:

Name

Provides

Polynomial

Power series

Chebyshev

Chebyshev series

Legendre

Legendre series

Laguerre

Laguerre series

Hermite

Hermite series

HermiteE

HermiteE series

The series in this context are finite sums of the corresponding polynomial basis functions multiplied by coefficients. For instance, a power series looks like

and has coefficients \([1, 2, 3]\). The Chebyshev series with the same coefficients looks like

and more generally

where in this case the \(T_n\) are the Chebyshev functions of degree \(n\), but could just as easily be the basis functions of any of the other classes. The convention for all the classes is that the coefficient \(c[i]\) goes with the basis function of degree i.

All of the classes are immutable and have the same methods, and especially they implement the Python numeric operators +, -, *, //, %, divmod, **, ==, and !=. The last two can be a bit problematic due to floating point roundoff errors. We now give a quick demonstration of the various operations using NumPy version 1.7.0.

## Basics[#](#basics)
First we need a polynomial class and a polynomial instance to play with. The classes can be imported directly from the polynomial package or from the module of the relevant type. Here we import from the package and use the conventional Polynomial class because of its familiarity:

```
>>> from numpy.polynomial import Polynomial as P
>>> p = P([1,2,3])
>>> p
Polynomial([1., 2., 3.], domain=[-1, 1], window=[-1, 1], symbol='x')
```
Note that there are three parts to the long version of the printout. The first is the coefficients, the second is the domain, and the third is the window:

```
>>> p.coef
array([1., 2., 3.])
>>> p.domain
array([-1, 1])
>>> p.window
array([-1, 1])
```
Printing a polynomial yields the polynomial expression in a more familiar format:

```
>>> print(p)
1.0 + 2.0·x + 3.0·x²
```
Note that the string representation of polynomials uses Unicode characters
by default (except on Windows) to express powers and subscripts. An ASCII-based
representation is also available (default on Windows). The polynomial string
format can be toggled at the package-level with the
[ set_default_printstyle](generated/numpy.polynomial.set_default_printstyle.html#numpy.polynomial.set_default_printstyle) function:

```
>>> np.polynomial.set_default_printstyle('ascii')
>>> print(p)
1.0 + 2.0 x + 3.0 x**2
```
or controlled for individual polynomial instances with string formatting:

```
>>> print(f"{p:unicode}")
1.0 + 2.0·x + 3.0·x²
```
We will deal with the domain and window when we get to fitting, for the moment we ignore them and run through the basic algebraic and arithmetic operations.

Addition and Subtraction:

```
>>> p + p
Polynomial([2., 4., 6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p - p
Polynomial([0.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Multiplication:

```
>>> p * p
Polynomial([ 1., 4., 10., 12., 9.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Powers:

```
>>> p**2
Polynomial([ 1., 4., 10., 12., 9.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Division:

Floor division, ‘//’, is the division operator for the polynomial classes, polynomials are treated like integers in this regard. For Python versions < 3.x the ‘/’ operator maps to ‘//’, as it does for Python, for later versions the ‘/’ will only work for division by scalars. At some point it will be deprecated:

```
>>> p // P([-1, 1])
Polynomial([5., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Remainder:

```
>>> p % P([-1, 1])
Polynomial([6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Divmod:

```
>>> quo, rem = divmod(p, P([-1, 1]))
>>> quo
Polynomial([5., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> rem
Polynomial([6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Evaluation:

```
>>> x = np.arange(5)
>>> p(x)
array([ 1., 6., 17., 34., 57.])
>>> x = np.arange(6).reshape(3,2)
>>> p(x)
array([[ 1., 6.],
[17., 34.],
[57., 86.]])
```
Substitution:

Substitute a polynomial for x and expand the result. Here we substitute p in itself leading to a new polynomial of degree 4 after expansion. If the polynomials are regarded as functions this is composition of functions:

```
>>> p(p)
Polynomial([ 6., 16., 36., 36., 27.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Roots:

```
>>> p.roots()
array([-0.33333333-0.47140452j, -0.33333333+0.47140452j])
```
It isn’t always convenient to explicitly use Polynomial instances, so tuples, lists, arrays, and scalars are automatically cast in the arithmetic operations:

```
>>> p + [1, 2, 3]
Polynomial([2., 4., 6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> [1, 2, 3] * p
Polynomial([ 1., 4., 10., 12., 9.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p / 2
Polynomial([0.5, 1. , 1.5], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Polynomials that differ in domain, window, or class can’t be mixed in arithmetic:

```
>>> from numpy.polynomial import Chebyshev as T
>>> p + P([1], domain=[0,1])
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "<string>", line 213, in __add__
TypeError: Domains differ
>>> p + P([1], window=[0,1])
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "<string>", line 215, in __add__
TypeError: Windows differ
>>> p + T([1])
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "<string>", line 211, in __add__
TypeError: Polynomial types differ
```
But different types can be used for substitution. In fact, this is how conversion of Polynomial classes among themselves is done for type, domain, and window casting:

```
>>> p(T([0, 1]))
Chebyshev([2.5, 2. , 1.5], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Which gives the polynomial *p* in Chebyshev form. This works because
\(T_1(x) = x\) and substituting \(x\) for \(x\) doesn’t change
the original polynomial. However, all the multiplications and divisions
will be done using Chebyshev series, hence the type of the result.

It is intended that all polynomial instances are immutable, therefore
augmented operations (`+=`
, `-=`
, etc.) and any other functionality that
would violate the immutablity of a polynomial instance are intentionally
unimplemented.

## Calculus[#](#calculus)
Polynomial instances can be integrated and differentiated.:

```
>>> from numpy.polynomial import Polynomial as P
>>> p = P([2, 6])
>>> p.integ()
Polynomial([0., 2., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.integ(2)
Polynomial([0., 0., 1., 1.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
The first example integrates *p* once, the second example integrates it
twice. By default, the lower bound of the integration and the integration
constant are 0, but both can be specified.:

```
>>> p.integ(lbnd=-1)
Polynomial([-1., 2., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.integ(lbnd=-1, k=1)
Polynomial([0., 2., 3.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
In the first case the lower bound of the integration is set to -1 and the integration constant is 0. In the second the constant of integration is set to 1 as well. Differentiation is simpler since the only option is the number of times the polynomial is differentiated:

```
>>> p = P([1, 2, 3])
>>> p.deriv(1)
Polynomial([2., 6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.deriv(2)
Polynomial([6.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
## Other Polynomial Constructors[#](#other-polynomial-constructors)
Constructing polynomials by specifying coefficients is just one way of obtaining a polynomial instance, they may also be created by specifying their roots, by conversion from other polynomial types, and by least squares fits. Fitting is discussed in its own section, the other methods are demonstrated below:

```
>>> from numpy.polynomial import Polynomial as P
>>> from numpy.polynomial import Chebyshev as T
>>> p = P.fromroots([1, 2, 3])
>>> p
Polynomial([-6., 11., -6., 1.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> p.convert(kind=T)
Chebyshev([-9. , 11.75, -3. , 0.25], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
The convert method can also convert domain and window:

```
>>> p.convert(kind=T, domain=[0, 1])
Chebyshev([-2.4375 , 2.96875, -0.5625 , 0.03125], domain=[0., 1.], window=[-1., 1.], symbol='x')
>>> p.convert(kind=P, domain=[0, 1])
Polynomial([-1.875, 2.875, -1.125, 0.125], domain=[0., 1.], window=[-1., 1.], symbol='x')
```
In numpy versions >= 1.7.0 the *basis* and *cast* class methods are also
available. The cast method works like the convert method while the basis
method returns the basis polynomial of given degree:

```
>>> P.basis(3)
Polynomial([0., 0., 0., 1.], domain=[-1., 1.], window=[-1., 1.], symbol='x')
>>> T.cast(p)
Chebyshev([-9. , 11.75, -3. , 0.25], domain=[-1., 1.], window=[-1., 1.], symbol='x')
```
Conversions between types can be useful, but it is *not* recommended
for routine use. The loss of numerical precision in passing from a
Chebyshev series of degree 50 to a Polynomial series of the same degree
can make the results of numerical evaluation essentially random.

## Fitting[#](#fitting)
Fitting is the reason that the *domain* and *window* attributes are part of
the convenience classes. To illustrate the problem, the values of the Chebyshev
polynomials up to degree 5 are plotted below.

```
>>> import matplotlib.pyplot as plt
>>> from numpy.polynomial import Chebyshev as T
>>> x = np.linspace(-1, 1, 100)
>>> for i in range(6):
... ax = plt.plot(x, T.basis(i)(x), lw=2, label=f"$T_{i}$")
...
>>> plt.legend(loc="upper left")
>>> plt.show()
```
In the range -1 <= *x* <= 1 they are nice, equiripple functions lying between +/- 1.
The same plots over the range -2 <= *x* <= 2 look very different:

```
>>> import matplotlib.pyplot as plt
>>> from numpy.polynomial import Chebyshev as T
>>> x = np.linspace(-2, 2, 100)
>>> for i in range(6):
... ax = plt.plot(x, T.basis(i)(x), lw=2, label=f"$T_{i}$")
...
>>> plt.legend(loc="lower right")
>>> plt.show()
```
As can be seen, the “good” parts have shrunk to insignificance. In using
Chebyshev polynomials for fitting we want to use the region where *x* is
between -1 and 1 and that is what the *window* specifies. However, it is
unlikely that the data to be fit has all its data points in that interval,
so we use *domain* to specify the interval where the data points lie. When
the fit is done, the domain is first mapped to the window by a linear
transformation and the usual least squares fit is done using the mapped
data points. The window and domain of the fit are part of the returned series
and are automatically used when computing values, derivatives, and such. If
they aren’t specified in the call the fitting routine will use the default
window and the smallest domain that holds all the data points. This is
illustrated below for a fit to a noisy sine curve.

```
>>> import numpy as np
>>> import matplotlib.pyplot as plt
>>> from numpy.polynomial import Chebyshev as T
>>> np.random.seed(11)
>>> x = np.linspace(0, 2*np.pi, 20)
>>> y = np.sin(x) + np.random.normal(scale=.1, size=x.shape)
>>> p = T.fit(x, y, 5)
>>> plt.plot(x, y, 'o')
>>> xx, yy = p.linspace()
>>> plt.plot(xx, yy, lw=2)
>>> p.domain
array([0. , 6.28318531])
>>> p.window
array([-1., 1.])
>>> plt.show()
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Byte-swapping[#](#byte-swapping)
## Introduction to byte ordering and ndarrays[#](#introduction-to-byte-ordering-and-ndarrays)
The `ndarray`
is an object that provides a python array interface to data
in memory.

It often happens that the memory that you want to view with an array is not of the same byte ordering as the computer on which you are running Python.

For example, I might be working on a computer with a little-endian CPU - such as an Intel Pentium, but I have loaded some data from a file written by a computer that is big-endian. Let’s say I have loaded 4 bytes from a file written by a Sun (big-endian) computer. I know that these 4 bytes represent two 16-bit integers. On a big-endian machine, a two-byte integer is stored with the Most Significant Byte (MSB) first, and then the Least Significant Byte (LSB). Thus the bytes are, in memory order:

MSB integer 1

LSB integer 1

MSB integer 2

LSB integer 2

Let’s say the two integers were in fact 1 and 770. Because 770 = 256 * 3 + 2, the 4 bytes in memory would contain respectively: 0, 1, 3, 2. The bytes I have loaded from the file would have these contents:

```
>>> big_end_buffer = bytearray([0,1,3,2])
>>> big_end_buffer
bytearray(b'\x00\x01\x03\x02')
```
We might want to use an `ndarray`
to access these integers. In that
case, we can create an array around this memory, and tell numpy that
there are two integers, and that they are 16 bit and big-endian:

```
>>> import numpy as np
>>> big_end_arr = np.ndarray(shape=(2,),dtype='>i2', buffer=big_end_buffer)
>>> big_end_arr[0]
1
>>> big_end_arr[1]
770
```
Note the array `dtype`
above of `>i2`
. The `>`
means ‘big-endian’
(`<`
is little-endian) and `i2`
means ‘signed 2-byte integer’. For
example, if our data represented a single unsigned 4-byte little-endian
integer, the dtype string would be `<u4`
.

In fact, why don’t we try that?

```
>>> little_end_u4 = np.ndarray(shape=(1,),dtype='<u4', buffer=big_end_buffer)
>>> little_end_u4[0] == 1 * 256**1 + 3 * 256**2 + 2 * 256**3
True
```
Returning to our `big_end_arr`
- in this case our underlying data is
big-endian (data endianness) and we’ve set the dtype to match (the dtype
is also big-endian). However, sometimes you need to flip these around.

Warning

Scalars do not include byte order information, so extracting a scalar from an array will return an integer in native byte order. Hence:

```
>>> big_end_arr[0].dtype.byteorder == little_end_u4[0].dtype.byteorder
True
```
NumPy intentionally does not attempt to always preserve byte-order
and for example converts to native byte-order in [ numpy.concatenate](../reference/generated/numpy.concatenate.html#numpy.concatenate).

## Changing byte ordering[#](#changing-byte-ordering)
As you can imagine from the introduction, there are two ways you can affect the relationship between the byte ordering of the array and the underlying memory it is looking at:

Change the byte-ordering information in the array dtype so that it interprets the underlying data as being in a different byte order. This is the role of

`arr.newbyteorder()`
Change the byte-ordering of the underlying data, leaving the dtype interpretation as it was. This is what

`arr.byteswap()`
does.
The common situations in which you need to change byte ordering are:

Your data and dtype endianness don’t match, and you want to change the dtype so that it matches the data.

Your data and dtype endianness don’t match, and you want to swap the data so that they match the dtype

Your data and dtype endianness match, but you want the data swapped and the dtype to reflect this

### Data and dtype endianness don’t match, change dtype to match data[#](#data-and-dtype-endianness-don-t-match-change-dtype-to-match-data)
We make something where they don’t match:

```
>>> wrong_end_dtype_arr = np.ndarray(shape=(2,),dtype='<i2', buffer=big_end_buffer)
>>> wrong_end_dtype_arr[0]
256
```
The obvious fix for this situation is to change the dtype so it gives the correct endianness:

```
>>> fixed_end_dtype_arr = wrong_end_dtype_arr.newbyteorder()
>>> fixed_end_dtype_arr[0]
1
```
Note the array has not changed in memory:

```
>>> fixed_end_dtype_arr.tobytes() == big_end_buffer
True
```
### Data and type endianness don’t match, change data to match dtype[#](#data-and-type-endianness-don-t-match-change-data-to-match-dtype)
You might want to do this if you need the data in memory to be a certain ordering. For example you might be writing the memory out to a file that needs a certain byte ordering.

```
>>> fixed_end_mem_arr = wrong_end_dtype_arr.byteswap()
>>> fixed_end_mem_arr[0]
1
```
Now the array *has* changed in memory:

```
>>> fixed_end_mem_arr.tobytes() == big_end_buffer
False
```
### Data and dtype endianness match, swap data and dtype[#](#data-and-dtype-endianness-match-swap-data-and-dtype)
You may have a correctly specified array dtype, but you need the array to have the opposite byte order in memory, and you want the dtype to match so the array values make sense. In this case you just do both of the previous operations:

```
>>> swapped_end_arr = big_end_arr.byteswap().newbyteorder()
>>> swapped_end_arr[0]
1
>>> swapped_end_arr.tobytes() == big_end_buffer
False
```
An easier way of casting the data to a specific dtype and byte ordering can be achieved with the ndarray astype method:

```
>>> swapped_end_arr = big_end_arr.astype('<i2')
>>> swapped_end_arr[0]
1
>>> swapped_end_arr.tobytes() == big_end_buffer
False
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# How to index `ndarrays`
[#](#how-to-index-ndarrays)
`ndarrays`
See also

This page tackles common examples. For an in-depth look into indexing, refer
to [Indexing on ndarrays](basics.indexing.html#basics-indexing).

## Access specific/arbitrary rows and columns[#](#access-specific-arbitrary-rows-and-columns)
Use [Basic indexing](basics.indexing.html#basic-indexing) features like [Slicing and striding](basics.indexing.html#slicing-and-striding), and
[Dimensional indexing tools](basics.indexing.html#dimensional-indexing-tools).

```
>>> a = np.arange(30).reshape(2, 3, 5)
>>> a
array([[[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9],
[10, 11, 12, 13, 14]],
[[15, 16, 17, 18, 19],
[20, 21, 22, 23, 24],
[25, 26, 27, 28, 29]]])
>>> a[0, 2, :]
array([10, 11, 12, 13, 14])
>>> a[0, :, 3]
array([ 3, 8, 13])
```
Note that the output from indexing operations can have different shape from the
original object. To preserve the original dimensions after indexing, you can
use [ newaxis](../reference/constants.html#numpy.newaxis). To use other such tools, refer to

[Dimensional indexing tools](basics.indexing.html#dimensional-indexing-tools).
```
>>> a[0, :, 3].shape
(3,)
>>> a[0, :, 3, np.newaxis].shape
(3, 1)
>>> a[0, :, 3, np.newaxis, np.newaxis].shape
(3, 1, 1)
```
Variables can also be used to index:

```
>>> y = 0
>>> a[y, :, y+3]
array([ 3, 8, 13])
```
Refer to [Dealing with variable numbers of indices within programs](basics.indexing.html#dealing-with-variable-indices) to see how to use
[slice](https://docs.python.org/3/glossary.html#term-slice) and [ Ellipsis](https://docs.python.org/3/library/constants.html#Ellipsis) in your index variables.

### Index columns[#](#index-columns)
To index columns, you have to index the last axis. Use
[Dimensional indexing tools](basics.indexing.html#dimensional-indexing-tools) to get the desired number of dimensions:

```
>>> a = np.arange(24).reshape(2, 3, 4)
>>> a
array([[[ 0, 1, 2, 3],
[ 4, 5, 6, 7],
[ 8, 9, 10, 11]],
[[12, 13, 14, 15],
[16, 17, 18, 19],
[20, 21, 22, 23]]])
>>> a[..., 3]
array([[ 3, 7, 11],
[15, 19, 23]])
```
To index specific elements in each column, make use of [Advanced indexing](basics.indexing.html#advanced-indexing)
as below:

```
>>> arr = np.arange(3*4).reshape(3, 4)
>>> arr
array([[ 0, 1, 2, 3],
[ 4, 5, 6, 7],
[ 8, 9, 10, 11]])
>>> column_indices = [[1, 3], [0, 2], [2, 2]]
>>> np.arange(arr.shape[0])
array([0, 1, 2])
>>> row_indices = np.arange(arr.shape[0])[:, np.newaxis]
>>> row_indices
array([[0],
[1],
[2]])
```
Use the `row_indices`
and `column_indices`
for advanced
indexing:

```
>>> arr[row_indices, column_indices]
array([[ 1, 3],
[ 4, 6],
[10, 10]])
```
### Index along a specific axis[#](#index-along-a-specific-axis)
Use [ take](../reference/generated/numpy.take.html#numpy.take). See also

[and](../reference/generated/numpy.take_along_axis.html#numpy.take_along_axis)
`take_along_axis`
[.](../reference/generated/numpy.put_along_axis.html#numpy.put_along_axis)
`put_along_axis`
```
>>> a = np.arange(30).reshape(2, 3, 5)
>>> a
array([[[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9],
[10, 11, 12, 13, 14]],
[[15, 16, 17, 18, 19],
[20, 21, 22, 23, 24],
[25, 26, 27, 28, 29]]])
>>> np.take(a, [2, 3], axis=2)
array([[[ 2, 3],
[ 7, 8],
[12, 13]],
[[17, 18],
[22, 23],
[27, 28]]])
>>> np.take(a, [2], axis=1)
array([[[10, 11, 12, 13, 14]],
[[25, 26, 27, 28, 29]]])
```
## Create subsets of larger matrices[#](#create-subsets-of-larger-matrices)
Use [Slicing and striding](basics.indexing.html#slicing-and-striding) to access chunks of a large array:

```
>>> a = np.arange(100).reshape(10, 10)
>>> a
array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
[20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
[30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
[40, 41, 42, 43, 44, 45, 46, 47, 48, 49],
[50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
[60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
[70, 71, 72, 73, 74, 75, 76, 77, 78, 79],
[80, 81, 82, 83, 84, 85, 86, 87, 88, 89],
[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])
>>> a[2:5, 2:5]
array([[22, 23, 24],
[32, 33, 34],
[42, 43, 44]])
>>> a[2:5, 1:3]
array([[21, 22],
[31, 32],
[41, 42]])
>>> a[:5, :5]
array([[ 0, 1, 2, 3, 4],
[10, 11, 12, 13, 14],
[20, 21, 22, 23, 24],
[30, 31, 32, 33, 34],
[40, 41, 42, 43, 44]])
```
The same thing can be done with advanced indexing in a slightly more complex
way. Remember that
[advanced indexing creates a copy](basics.copies.html#indexing-operations):

```
>>> a[np.arange(5)[:, None], np.arange(5)[None, :]]
array([[ 0, 1, 2, 3, 4],
[10, 11, 12, 13, 14],
[20, 21, 22, 23, 24],
[30, 31, 32, 33, 34],
[40, 41, 42, 43, 44]])
```
You can also use [ mgrid](../reference/generated/numpy.mgrid.html#numpy.mgrid) to generate indices:

```
>>> indices = np.mgrid[0:6:2]
>>> indices
array([0, 2, 4])
>>> a[:, indices]
array([[ 0, 2, 4],
[10, 12, 14],
[20, 22, 24],
[30, 32, 34],
[40, 42, 44],
[50, 52, 54],
[60, 62, 64],
[70, 72, 74],
[80, 82, 84],
[90, 92, 94]])
```
## Filter values[#](#filter-values)
### Non-zero elements[#](#non-zero-elements)
Use [ nonzero](../reference/generated/numpy.nonzero.html#numpy.nonzero) to get a tuple of array indices of non-zero elements
corresponding to every dimension:

```
>>> z = np.array([[1, 2, 3, 0], [0, 0, 5, 3], [4, 6, 0, 0]])
>>> z
array([[1, 2, 3, 0],
[0, 0, 5, 3],
[4, 6, 0, 0]])
>>> np.nonzero(z)
(array([0, 0, 0, 1, 1, 2, 2]), array([0, 1, 2, 2, 3, 0, 1]))
```
Use [ flatnonzero](../reference/generated/numpy.flatnonzero.html#numpy.flatnonzero) to fetch indices of elements that are non-zero in
the flattened version of the ndarray:

```
>>> np.flatnonzero(z)
array([0, 1, 2, 6, 7, 8, 9])
```
### Arbitrary conditions[#](#arbitrary-conditions)
Use [ where](../reference/generated/numpy.where.html#numpy.where) to generate indices based on conditions and then
use

[Advanced indexing](basics.indexing.html#advanced-indexing).
```
>>> a = np.arange(30).reshape(2, 3, 5)
>>> indices = np.where(a % 2 == 0)
>>> indices
(array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),
array([0, 0, 0, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 2, 2]),
array([0, 2, 4, 1, 3, 0, 2, 4, 1, 3, 0, 2, 4, 1, 3]))
>>> a[indices]
array([ 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28])
```
Or, use [Boolean array indexing](basics.indexing.html#boolean-indexing):

```
>>> a > 14
array([[[False, False, False, False, False],
[False, False, False, False, False],
[False, False, False, False, False]],
[[ True, True, True, True, True],
[ True, True, True, True, True],
[ True, True, True, True, True]]])
>>> a[a > 14]
array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])
```
### Replace values after filtering[#](#replace-values-after-filtering)
Use assignment with filtering to replace desired values:

```
>>> p = np.arange(-10, 10).reshape(2, 2, 5)
>>> p
array([[[-10, -9, -8, -7, -6],
[ -5, -4, -3, -2, -1]],
[[ 0, 1, 2, 3, 4],
[ 5, 6, 7, 8, 9]]])
>>> q = p < 0
>>> q
array([[[ True, True, True, True, True],
[ True, True, True, True, True]],
[[False, False, False, False, False],
[False, False, False, False, False]]])
>>> p[q] = 0
>>> p
array([[[0, 0, 0, 0, 0],
[0, 0, 0, 0, 0]],
[[0, 1, 2, 3, 4],
[5, 6, 7, 8, 9]]])
```
## Fetch indices of max/min values[#](#fetch-indices-of-max-min-values)
```
>>> a = np.arange(30).reshape(2, 3, 5)
>>> np.argmax(a)
29
>>> np.argmin(a)
0
```
Use the `axis`
keyword to get the indices of maximum and minimum
values along a specific axis:

```
>>> np.argmax(a, axis=0)
array([[1, 1, 1, 1, 1],
[1, 1, 1, 1, 1],
[1, 1, 1, 1, 1]])
>>> np.argmax(a, axis=1)
array([[2, 2, 2, 2, 2],
[2, 2, 2, 2, 2]])
>>> np.argmax(a, axis=2)
array([[4, 4, 4],
[4, 4, 4]])
>>> np.argmin(a, axis=1)
array([[0, 0, 0, 0, 0],
[0, 0, 0, 0, 0]])
>>> np.argmin(a, axis=2)
array([[0, 0, 0],
[0, 0, 0]])
```
Set `keepdims`
to `True`
to keep the axes which are reduced in the
result as dimensions with size one:

```
>>> np.argmin(a, axis=2, keepdims=True)
array([[[0],
[0],
[0]],
[[0],
[0],
[0]]])
>>> np.argmax(a, axis=1, keepdims=True)
array([[[2, 2, 2, 2, 2]],
[[2, 2, 2, 2, 2]]])
```
To get the indices of each maximum or minimum value for each
(N-1)-dimensional array in an N-dimensional array, use [ reshape](../reference/generated/numpy.reshape.html#numpy.reshape)
to reshape the array to a 2D array, apply

[or](../reference/generated/numpy.argmax.html#numpy.argmax)
`argmax`
[along](../reference/generated/numpy.argmin.html#numpy.argmin)
`argmin`
`axis=1`
and use [to recover the index of the values per slice:](../reference/generated/numpy.unravel_index.html#numpy.unravel_index)
`unravel_index`
```
>>> x = np.arange(2*2*3).reshape(2, 2, 3) % 7 # 3D example array
>>> x
array([[[0, 1, 2],
[3, 4, 5]],
[[6, 0, 1],
[2, 3, 4]]])
>>> x_2d = np.reshape(x, (x.shape[0], -1))
>>> indices_2d = np.argmax(x_2d, axis=1)
>>> indices_2d
array([5, 0])
>>> np.unravel_index(indices_2d, x.shape[1:])
(array([1, 0]), array([2, 0]))
```
The first array returned contains the indices along axis 1 in the original
array, the second array contains the indices along axis 2. The highest
value in `x[0]`
is therefore `x[0, 1, 2]`
.

## Index the same ndarray multiple times efficiently[#](#index-the-same-ndarray-multiple-times-efficiently)
It must be kept in mind that basic indexing produces [views](../glossary.html#term-view)
and advanced indexing produces [copies](../glossary.html#term-copy), which are
computationally less efficient. Hence, you should take care to use basic
indexing wherever possible instead of advanced indexing.

## Further reading[#](#further-reading)
Nicolas Rougier’s [100 NumPy exercises](https://github.com/rougier/numpy-100)
provide a good insight into how indexing is combined with other operations.
Exercises [6](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#6-create-a-null-vector-of-size-10-but-the-fifth-value-which-is-1-), [8](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#8-reverse-a-vector-first-element-becomes-last-), [10](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#10-find-indices-of-non-zero-elements-from-120040-), [15](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#15-create-a-2d-array-with-1-on-the-border-and-0-inside-), [16](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#16-how-to-add-a-border-filled-with-0s-around-an-existing-array-), [19](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#19-create-a-8x8-matrix-and-fill-it-with-a-checkerboard-pattern-), [20](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#20-consider-a-678-shape-array-what-is-the-index-xyz-of-the-100th-element-), [45](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#45-create-random-vector-of-size-10-and-replace-the-maximum-value-by-0-), [59](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#59-how-to-sort-an-array-by-the-nth-column-),
[64](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#64-consider-a-given-vector-how-to-add-1-to-each-element-indexed-by-a-second-vector-be-careful-with-repeated-indices-), [65](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#65-how-to-accumulate-elements-of-a-vector-x-to-an-array-f-based-on-an-index-list-i-), [70](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#70-consider-the-vector-1-2-3-4-5-how-to-build-a-new-vector-with-3-consecutive-zeros-interleaved-between-each-value-), [71](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#71-consider-an-array-of-dimension-553-how-to-mulitply-it-by-an-array-with-dimensions-55-), [72](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#72-how-to-swap-two-rows-of-an-array-), [76](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#76-consider-a-one-dimensional-array-z-build-a-two-dimensional-array-whose-first-row-is-z0z1z2-and-each-subsequent-row-is--shifted-by-1-last-row-should-be-z-3z-2z-1-), [80](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#80-consider-an-arbitrary-array-write-a-function-that-extract-a-subpart-with-a-fixed-shape-and-centered-on-a-given-element-pad-with-a-fill-value-when-necessary-), [81](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#81-consider-an-array-z--1234567891011121314-how-to-generate-an-array-r--1234-2345-3456--11121314-), [84](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#84-extract-all-the-contiguous-3x3-blocks-from-a-random-10x10-matrix-), [87](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#87-consider-a-16x16-array-how-to-get-the-block-sum-block-size-is-4x4-), [90](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#90-given-an-arbitrary-number-of-vectors-build-the-cartesian-product-every-combinations-of-every-item-),
[93](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#93-consider-two-arrays-a-and-b-of-shape-83-and-22-how-to-find-rows-of-a-that-contain-elements-of-each-row-of-b-regardless-of-the-order-of-the-elements-in-b-), [94](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#94-considering-a-10x3-matrix-extract-rows-with-unequal-values-eg-223-) are specially focused on indexing.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Parallel Random Number Generation[#](#parallel-random-number-generation)
There are four main strategies implemented that can be used to produce repeatable pseudo-random numbers across multiple processes (local or distributed).

`SeedSequence`
spawning[#](#seedsequence-spawning)
`SeedSequence`
NumPy allows you to spawn new (with very high probability) independent
[ BitGenerator](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator) and

[instances via their](generator.html#numpy.random.Generator)
`Generator`
`spawn()`
method.
This spawning is implemented by the [used for initializing the bit generators random stream.](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
`SeedSequence`
[implements an algorithm](http://www.pcg-random.org/posts/developing-a-seed_seq-alternative.html) to process a user-provided seed,
typically as an integer of some size, and to convert it into an initial state for
a [ BitGenerator](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator). It uses hashing techniques to ensure that low-quality seeds
are turned into high quality initial states (at least, with very high
probability).
For example, [ MT19937](bit_generators/mt19937.html#numpy.random.MT19937) has a state consisting of 624

*uint32*integers. A naive way to take a 32-bit integer seed would be to just set the last element of the state to the 32-bit seed and leave the rest 0s. This is a valid state for
[, but not a good one. The Mersenne Twister algorithm](bit_generators/mt19937.html#numpy.random.MT19937)
`MT19937`
[suffers if there are too many 0s](http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/MT2002/emt19937ar.html). Similarly, two adjacent 32-bit integer seeds (i.e.
`12345`
and `12346`
) would produce very similar
streams.[ SeedSequence](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) avoids these problems by using successions of integer hashes
with good
[avalanche properties](https://en.wikipedia.org/wiki/Avalanche_effect)to ensure that flipping any bit in the input has about a 50% chance of flipping any bit in the output. Two input seeds that are very close to each other will produce initial states that are very far from each other (with very high probability). It is also constructed in such a way that you can provide arbitrary-sized integers or lists of integers.
[will take all of the bits that you provide and mix them together to produce however many bits the consuming](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
[needs to initialize itself.](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
`BitGenerator`
These properties together mean that we can safely mix together the usual
user-provided seed with simple incrementing counters to get [ BitGenerator](bit_generators/generated/numpy.random.BitGenerator.html#numpy.random.BitGenerator)
states that are (to very high probability) independent of each other. We can
wrap this together into an API that is easy to use and difficult to misuse.

```
from numpy.random import SeedSequence, default_rng
ss = SeedSequence(12345)
# Spawn off 10 child SeedSequences to pass to child processes.
child_seeds = ss.spawn(10)
streams = [default_rng(s) for s in child_seeds]
```
For convenience the direct use of [ SeedSequence](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) is not necessary.
The above

`streams`
can be spawned directly from a parent generator
via [:](generated/numpy.random.Generator.spawn.html#numpy.random.Generator.spawn)
`spawn`
```
parent_rng = default_rng(12345)
streams = parent_rng.spawn(10)
```
Child objects can also spawn to make grandchildren, and so on.
Each child has a [ SeedSequence](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) with its position in the tree of spawned
child objects mixed in with the user-provided seed to generate independent
(with very high probability) streams.

```
grandchildren = streams[0].spawn(4)
```
This feature lets you make local decisions about when and how to split up
streams without coordination between processes. You do not have to preallocate
space to avoid overlapping or request streams from a common global service. This
general “tree-hashing” scheme is [not unique to numpy](https://www.iro.umontreal.ca/~lecuyer/myftp/papers/parallel-rng-imacs.pdf) but not yet widespread.
Python has increasingly-flexible mechanisms for parallelization available, and
this scheme fits in very well with that kind of use.

Using this scheme, an upper bound on the probability of a collision can be
estimated if one knows the number of streams that you derive. [ SeedSequence](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
hashes its inputs, both the seed and the spawn-tree-path, down to a 128-bit
pool by default. The probability that there is a collision in
that pool, pessimistically-estimated (

[[1]](#id3)), will be about \(n^2*2^{-128}\) where
*n*is the number of streams spawned. If a program uses an aggressive million streams, about \(2^{20}\), then the probability that at least one pair of them are identical is about \(2^{-88}\), which is in solidly-ignorable territory (
[[2]](#id4)).
## Sequence of Integer Seeds[#](#sequence-of-integer-seeds)
As discussed in the previous section, [ SeedSequence](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence) can not only take an
integer seed, it can also take an arbitrary-length sequence of (non-negative)
integers. If one exercises a little care, one can use this feature to design

*ad hoc*schemes for getting safe parallel PRNG streams with similar safety guarantees as spawning.
For example, one common use case is that a worker process is passed one root seed integer for the whole calculation and also an integer worker ID (or something more granular like a job ID, batch ID, or something similar). If these IDs are created deterministically and uniquely, then one can derive reproducible parallel PRNG streams by combining the ID and the root seed integer in a list.

```
# default_rng() and each of the BitGenerators use SeedSequence underneath, so
# they all accept sequences of integers as seeds the same way.
from numpy.random import default_rng
def worker(root_seed, worker_id):
rng = default_rng([worker_id, root_seed])
# Do work ...
root_seed = 0x8c3c010cb4754c905776bdac5ee7501
results = [worker(root_seed, worker_id) for worker_id in range(10)]
```
This can be used to replace a number of unsafe strategies that have been used
in the past which try to combine the root seed and the ID back into a single
integer seed value. For example, it is common to see users add the worker ID to
the root seed, especially with the legacy [ RandomState](legacy.html#numpy.random.RandomState) code.

```
# UNSAFE! Do not do this!
worker_seed = root_seed + worker_id
rng = np.random.RandomState(worker_seed)
```
It is true that for any one run of a parallel program constructed this way, each worker will have distinct streams. However, it is quite likely that multiple invocations of the program with different seeds will get overlapping sets of worker seeds. It is not uncommon (in the author’s self-experience) to change the root seed merely by an increment or two when doing these repeat runs. If the worker seeds are also derived by small increments of the worker ID, then subsets of the workers will return identical results, causing a bias in the overall ensemble of results.

Combining the worker ID and the root seed as a list of integers eliminates this risk. Lazy seeding practices will still be fairly safe.

This scheme does require that the extra IDs be unique and deterministically
created. This may require coordination between the worker processes. It is
recommended to place the varying IDs *before* the unvarying root seed.
`spawn`
*appends* integers after the user-provided seed, so if
you might be mixing both this *ad hoc* mechanism and spawning, or passing your
objects down to library code that might be spawning, then it is a little bit
safer to prepend your worker IDs rather than append them to avoid a collision.

```
# Good.
worker_seed = [worker_id, root_seed]
# Less good. It will *work*, but it's less flexible.
worker_seed = [root_seed, worker_id]
```
With those caveats in mind, the safety guarantees against collision are about the same as with spawning, discussed in the previous section. The algorithmic mechanisms are the same.

## Independent Streams[#](#independent-streams)
[ Philox](bit_generators/philox.html#numpy.random.Philox) is a counter-based RNG based which generates values by
encrypting an incrementing counter using weak cryptographic primitives. The
seed determines the key that is used for the encryption. Unique keys create
unique, independent streams.
[lets you bypass the seeding algorithm to directly set the 128-bit key. Similar, but different, keys will still create independent streams.](bit_generators/philox.html#numpy.random.Philox)
`Philox`
```
import secrets
from numpy.random import Philox
# 128-bit number as a seed
root_seed = secrets.getrandbits(128)
streams = [Philox(key=root_seed + stream_id) for stream_id in range(10)]
```
This scheme does require that you avoid reusing stream IDs. This may require coordination between the parallel processes.

## Jumping the BitGenerator state[#](#jumping-the-bitgenerator-state)
`jumped`
advances the state of the BitGenerator *as-if* a large number of
random numbers have been drawn, and returns a new instance with this state.
The specific number of draws varies by BitGenerator, and ranges from
\(2^{64}\) to \(2^{128}\). Additionally, the *as-if* draws also depend
on the size of the default random number produced by the specific BitGenerator.
The BitGenerators that support `jumped`
, along with the period of the
BitGenerator, the size of the jump and the bits in the default unsigned random
are listed below.
BitGenerator

|
Period

|
Jump Size

|
Bits per Draw

|
---|---|---|---|
MT19937

|
\(2^{19937}-1\)

|
\(2^{128}\)

|
32

|
PCG64

|
\(2^{128}\)

|
\(~2^{127}\) (

|
64

|
PCG64DXSM

|
\(2^{128}\)

|
\(~2^{127}\) (

|
64

|
Philox

|
\(2^{256}\)

|
\(2^{128}\)

|
64

|
[1](#id6),
[2](#id7))
The jump size is \((\phi-1)*2^{128}\) where \(\phi\) is the golden ratio. As the jumps wrap around the period, the actual distances between neighboring streams will slowly grow smaller than the jump size, but using the golden ratio this way is a classic method of constructing a low-discrepancy sequence that spreads out the states around the period optimally. You will not be able to jump enough to make those distances small enough to overlap in your lifetime.

`jumped`
can be used to produce long blocks which should be long enough to not
overlap.
```
import secrets
from numpy.random import PCG64
seed = secrets.getrandbits(128)
blocked_rng = []
rng = PCG64(seed)
for i in range(10):
blocked_rng.append(rng.jumped(i))
```
When using `jumped`
, one does have to take care not to jump to a stream that
was already used. In the above example, one could not later use
`blocked_rng[0].jumped()`
as it would overlap with `blocked_rng[1]`
. Like
with the independent streams, if the main process here wants to split off 10
more streams by jumping, then it needs to start with `range(10, 20)`
,
otherwise it would recreate the same streams. On the other hand, if you
carefully construct the streams, then you are guaranteed to have streams that
do not overlap.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Subclassing ndarray[#](#subclassing-ndarray)
## Introduction[#](#introduction)
Subclassing ndarray is relatively simple, but it has some complications compared to other Python objects. On this page we explain the machinery that allows you to subclass ndarray, and the implications for implementing a subclass.

### ndarrays and object creation[#](#ndarrays-and-object-creation)
Subclassing ndarray is complicated by the fact that new instances of ndarray classes can come about in three different ways. These are:

Explicit constructor call - as in

`MySubClass(params)`
. This is the usual route to Python instance creation.
View casting - casting an existing ndarray as a given subclass

New from template - creating a new instance from a template instance. Examples include returning slices from a subclassed array, creating return types from ufuncs, and copying arrays. See

[Creating new from template](#new-from-template)for more details
The last two are characteristics of ndarrays - in order to support things like array slicing. The complications of subclassing ndarray are due to the mechanisms numpy has to support these latter two routes of instance creation.

### When to use subclassing[#](#when-to-use-subclassing)
Besides the additional complexities of subclassing a NumPy array, subclasses can run into unexpected behaviour because some functions may convert the subclass to a baseclass and “forget” any additional information associated with the subclass. This can result in surprising behavior if you use NumPy methods or functions you have not explicitly tested.

On the other hand, compared to other interoperability approaches, subclassing can be a useful because many thing will “just work”.

This means that subclassing can be a convenient approach and for a long time
it was also often the only available approach.
However, NumPy now provides additional interoperability protocols described
in “[Interoperability with NumPy](basics.interoperability.html#basics-interoperability)”.
For many use-cases these interoperability protocols may now be a better fit
or supplement the use of subclassing.

Subclassing can be a good fit if:

you are less worried about maintainability or users other than yourself: Subclass will be faster to implement and additional interoperability can be added “as-needed”. And with few users, possible surprises are not an issue.

you do not think it is problematic if the subclass information is ignored or lost silently. An example is

`np.memmap`
where “forgetting” about data being memory mapped cannot lead to a wrong result. An example of a subclass that sometimes confuses users are NumPy’s masked arrays. When they were introduced, subclassing was the only approach for implementation. However, today we would possibly try to avoid subclassing and rely only on interoperability protocols.
Note that also subclass authors may wish to study
[Interoperability with NumPy](basics.interoperability.html#basics-interoperability)
to support more complex use-cases or work around the surprising behavior.

`astropy.units.Quantity`
and `xarray`
are examples for array-like objects
that interoperate well with NumPy. Astropy’s `Quantity`
is an example
which uses a dual approach of both subclassing and interoperability protocols.
## View casting[#](#view-casting)
*View casting* is the standard ndarray mechanism by which you take an
ndarray of any subclass, and return a view of the array as another
(specified) subclass:
```
>>> import numpy as np
>>> # create a completely useless ndarray subclass
>>> class C(np.ndarray): pass
>>> # create a standard ndarray
>>> arr = np.zeros((3,))
>>> # take a view of it, as our useless subclass
>>> c_arr = arr.view(C)
>>> type(c_arr)
<class '__main__.C'>
```
## Creating new from template[#](#creating-new-from-template)
New instances of an ndarray subclass can also come about by a very
similar mechanism to [View casting](#view-casting), when numpy finds it needs to
create a new instance from a template instance. The most obvious place
this has to happen is when you are taking slices of subclassed arrays.
For example:

```
>>> v = c_arr[1:]
>>> type(v) # the view is of type 'C'
<class '__main__.C'>
>>> v is c_arr # but it's a new instance
False
```
The slice is a *view* onto the original `c_arr`
data. So, when we
take a view from the ndarray, we return a new ndarray, of the same
class, that points to the data in the original.

There are other points in the use of ndarrays where we need such views,
such as copying arrays (`c_arr.copy()`
), creating ufunc output arrays
(see also [__array_wrap__ for ufuncs and other functions](#array-wrap)), and reducing methods (like
`c_arr.mean()`
).

## Relationship of view casting and new-from-template[#](#relationship-of-view-casting-and-new-from-template)
These paths both use the same machinery. We make the distinction here,
because they result in different input to your methods. Specifically,
[View casting](#view-casting) means you have created a new instance of your array
type from any potential subclass of ndarray. [Creating new from template](#new-from-template)
means you have created a new instance of your class from a pre-existing
instance, allowing you - for example - to copy across attributes that
are particular to your subclass.

## Implications for subclassing[#](#implications-for-subclassing)
If we subclass ndarray, we need to deal not only with explicit
construction of our array type, but also [View casting](#view-casting) or
[Creating new from template](#new-from-template). NumPy has the machinery to do this, and it is
this machinery that makes subclassing slightly non-standard.

There are two aspects to the machinery that ndarray uses to support views and new-from-template in subclasses.

The first is the use of the `ndarray.__new__`
method for the main work
of object initialization, rather then the more usual `__init__`
method. The second is the use of the `__array_finalize__`
method to
allow subclasses to clean up after the creation of views and new
instances from templates.

### A brief Python primer on `__new__`
and `__init__`
[#](#a-brief-python-primer-on-new-and-init)
`__new__`
is a standard Python method, and, if present, is called
before `__init__`
when we create a class instance. See the [python
__new__ documentation](https://docs.python.org/reference/datamodel.html#object.__new__) for more detail.
For example, consider the following Python code:

```
>>> class C:
>>> def __new__(cls, *args):
>>> print('Cls in __new__:', cls)
>>> print('Args in __new__:', args)
>>> # The `object` type __new__ method takes a single argument.
>>> return object.__new__(cls)
>>> def __init__(self, *args):
>>> print('type(self) in __init__:', type(self))
>>> print('Args in __init__:', args)
```
meaning that we get:

```
>>> c = C('hello')
Cls in __new__: <class 'C'>
Args in __new__: ('hello',)
type(self) in __init__: <class 'C'>
Args in __init__: ('hello',)
```
When we call `C('hello')`
, the `__new__`
method gets its own class
as first argument, and the passed argument, which is the string
`'hello'`
. After python calls `__new__`
, it usually (see below)
calls our `__init__`
method, with the output of `__new__`
as the
first argument (now a class instance), and the passed arguments
following.

As you can see, the object can be initialized in the `__new__`
method or the `__init__`
method, or both, and in fact ndarray does
not have an `__init__`
method, because all the initialization is
done in the `__new__`
method.

Why use `__new__`
rather than just the usual `__init__`
? Because
in some cases, as for ndarray, we want to be able to return an object
of some other class. Consider the following:

```
class D(C):
def __new__(cls, *args):
print('D cls is:', cls)
print('D args in __new__:', args)
return C.__new__(C, *args)
def __init__(self, *args):
# we never get here
print('In D __init__')
```
meaning that:

```
>>> obj = D('hello')
D cls is: <class 'D'>
D args in __new__: ('hello',)
Cls in __new__: <class 'C'>
Args in __new__: ('hello',)
>>> type(obj)
<class 'C'>
```
The definition of `C`
is the same as before, but for `D`
, the
`__new__`
method returns an instance of class `C`
rather than
`D`
. Note that the `__init__`
method of `D`
does not get
called. In general, when the `__new__`
method returns an object of
class other than the class in which it is defined, the `__init__`
method of that class is not called.

This is how subclasses of the ndarray class are able to return views that preserve the class type. When taking a view, the standard ndarray machinery creates the new ndarray object with something like:

```
obj = ndarray.__new__(subtype, shape, ...
```
where `subdtype`
is the subclass. Thus the returned view is of the
same class as the subclass, rather than being of class `ndarray`
.

That solves the problem of returning views of the same type, but now
we have a new problem. The machinery of ndarray can set the class
this way, in its standard methods for taking views, but the ndarray
`__new__`
method knows nothing of what we have done in our own
`__new__`
method in order to set attributes, and so on. (Aside -
why not call `obj = subdtype.__new__(...`
then? Because we may not
have a `__new__`
method with the same call signature).

### The role of `__array_finalize__`
[#](#the-role-of-array-finalize)
`__array_finalize__`
is the mechanism that numpy provides to allow
subclasses to handle the various ways that new instances get created.
Remember that subclass instances can come about in these three ways:

explicit constructor call (

`obj = MySubClass(params)`
). This will call the usual sequence of`MySubClass.__new__`
then (if it exists)`MySubClass.__init__`
.
Our `MySubClass.__new__`
method only gets called in the case of the
explicit constructor call, so we can’t rely on `MySubClass.__new__`
or
`MySubClass.__init__`
to deal with the view casting and
new-from-template. It turns out that `MySubClass.__array_finalize__`
*does* get called for all three methods of object creation, so this is
where our object creation housekeeping usually goes.

For the explicit constructor call, our subclass will need to create a new ndarray instance of its own class. In practice this means that we, the authors of the code, will need to make a call to

`ndarray.__new__(MySubClass,...)`
, a class-hierarchy prepared call to`super().__new__(cls, ...)`
, or do view casting of an existing array (see below)
For view casting and new-from-template, the equivalent of

`ndarray.__new__(MySubClass,...`
is called, at the C level.
The arguments that `__array_finalize__`
receives differ for the three
methods of instance creation above.

The following code allows us to look at the call sequences and arguments:

```
import numpy as np
class C(np.ndarray):
def __new__(cls, *args, **kwargs):
print('In __new__ with class %s' % cls)
return super().__new__(cls, *args, **kwargs)
def __init__(self, *args, **kwargs):
# in practice you probably will not need or want an __init__
# method for your subclass
print('In __init__ with class %s' % self.__class__)
def __array_finalize__(self, obj):
print('In array_finalize:')
print(' self type is %s' % type(self))
print(' obj type is %s' % type(obj))
```
Now:

```
>>> # Explicit constructor
>>> c = C((10,))
In __new__ with class <class 'C'>
In array_finalize:
self type is <class 'C'>
obj type is <type 'NoneType'>
In __init__ with class <class 'C'>
>>> # View casting
>>> a = np.arange(10)
>>> cast_a = a.view(C)
In array_finalize:
self type is <class 'C'>
obj type is <type 'numpy.ndarray'>
>>> # Slicing (example of new-from-template)
>>> cv = c[:1]
In array_finalize:
self type is <class 'C'>
obj type is <class 'C'>
```
The signature of `__array_finalize__`
is:

```
def __array_finalize__(self, obj):
```
One sees that the `super`
call, which goes to
`ndarray.__new__`
, passes `__array_finalize__`
the new object, of our
own class (`self`
) as well as the object from which the view has been
taken (`obj`
). As you can see from the output above, the `self`
is
always a newly created instance of our subclass, and the type of `obj`
differs for the three instance creation methods:

When called from the explicit constructor,

`obj`
is`None`
When called from view casting,

`obj`
can be an instance of any subclass of ndarray, including our own.
When called in new-from-template,

`obj`
is another instance of our own subclass, that we might use to update the new`self`
instance.
Because `__array_finalize__`
is the only method that always sees new
instances being created, it is the sensible place to fill in instance
defaults for new object attributes, among other tasks.

This may be clearer with an example.

## Simple example - adding an extra attribute to ndarray[#](#simple-example-adding-an-extra-attribute-to-ndarray)
```
import numpy as np
class InfoArray(np.ndarray):
def __new__(subtype, shape, dtype=float, buffer=None, offset=0,
strides=None, order=None, info=None):
# Create the ndarray instance of our type, given the usual
# ndarray input arguments. This will call the standard
# ndarray constructor, but return an object of our type.
# It also triggers a call to InfoArray.__array_finalize__
obj = super().__new__(subtype, shape, dtype,
buffer, offset, strides, order)
# set the new 'info' attribute to the value passed
obj.info = info
# Finally, we must return the newly created object:
return obj
def __array_finalize__(self, obj):
# ``self`` is a new object resulting from
# ndarray.__new__(InfoArray, ...), therefore it only has
# attributes that the ndarray.__new__ constructor gave it -
# i.e. those of a standard ndarray.
#
# We could have got to the ndarray.__new__ call in 3 ways:
# From an explicit constructor - e.g. InfoArray():
# obj is None
# (we're in the middle of the InfoArray.__new__
# constructor, and self.info will be set when we return to
# InfoArray.__new__)
if obj is None: return
# From view casting - e.g arr.view(InfoArray):
# obj is arr
# (type(obj) can be InfoArray)
# From new-from-template - e.g infoarr[:3]
# type(obj) is InfoArray
#
# Note that it is here, rather than in the __new__ method,
# that we set the default value for 'info', because this
# method sees all creation of default objects - with the
# InfoArray.__new__ constructor, but also with
# arr.view(InfoArray).
self.info = getattr(obj, 'info', None)
# We do not need to return anything
```
Using the object looks like this:

```
>>> obj = InfoArray(shape=(3,)) # explicit constructor
>>> type(obj)
<class 'InfoArray'>
>>> obj.info is None
True
>>> obj = InfoArray(shape=(3,), info='information')
>>> obj.info
'information'
>>> v = obj[1:] # new-from-template - here - slicing
>>> type(v)
<class 'InfoArray'>
>>> v.info
'information'
>>> arr = np.arange(10)
>>> cast_arr = arr.view(InfoArray) # view casting
>>> type(cast_arr)
<class 'InfoArray'>
>>> cast_arr.info is None
True
```
This class isn’t very useful, because it has the same constructor as the
bare ndarray object, including passing in buffers and shapes and so on.
We would probably prefer the constructor to be able to take an already
formed ndarray from the usual numpy calls to `np.array`
and return an
object.

## Slightly more realistic example - attribute added to existing array[#](#slightly-more-realistic-example-attribute-added-to-existing-array)
Here is a class that takes a standard ndarray that already exists, casts as our type, and adds an extra attribute.

```
import numpy as np
class RealisticInfoArray(np.ndarray):
def __new__(cls, input_array, info=None):
# Input array is an already formed ndarray instance
# We first cast to be our class type
obj = np.asarray(input_array).view(cls)
# add the new attribute to the created instance
obj.info = info
# Finally, we must return the newly created object:
return obj
def __array_finalize__(self, obj):
# see InfoArray.__array_finalize__ for comments
if obj is None: return
self.info = getattr(obj, 'info', None)
```
So:

```
>>> arr = np.arange(5)
>>> obj = RealisticInfoArray(arr, info='information')
>>> type(obj)
<class 'RealisticInfoArray'>
>>> obj.info
'information'
>>> v = obj[1:]
>>> type(v)
<class 'RealisticInfoArray'>
>>> v.info
'information'
```
`__array_ufunc__`
for ufuncs[#](#array-ufunc-for-ufuncs)
New in version 1.13.

A subclass can override what happens when executing numpy ufuncs on it by
overriding the default `ndarray.__array_ufunc__`
method. This method is
executed *instead* of the ufunc and should return either the result of the
operation, or [ NotImplemented](https://docs.python.org/3/library/constants.html#NotImplemented) if the operation requested is not
implemented.

The signature of `__array_ufunc__`
is:

```
def __array_ufunc__(ufunc, method, *inputs, **kwargs):
- *ufunc* is the ufunc object that was called.
- *method* is a string indicating how the Ufunc was called, either
``"__call__"`` to indicate it was called directly, or one of its
:ref:`methods<ufuncs.methods>`: ``"reduce"``, ``"accumulate"``,
``"reduceat"``, ``"outer"``, or ``"at"``.
- *inputs* is a tuple of the input arguments to the ``ufunc``
- *kwargs* contains any optional or keyword arguments passed to the
function. This includes any ``out`` arguments, which are always
contained in a tuple.
```
A typical implementation would convert any inputs or outputs that are
instances of one’s own class, pass everything on to a superclass using
`super()`
, and finally return the results after possible
back-conversion. An example, taken from the test case
`test_ufunc_override_with_super`
in `core/tests/test_umath.py`
, is the
following.

```
input numpy as np
class A(np.ndarray):
def __array_ufunc__(self, ufunc, method, *inputs, out=None, **kwargs):
args = []
in_no = []
for i, input_ in enumerate(inputs):
if isinstance(input_, A):
in_no.append(i)
args.append(input_.view(np.ndarray))
else:
args.append(input_)
outputs = out
out_no = []
if outputs:
out_args = []
for j, output in enumerate(outputs):
if isinstance(output, A):
out_no.append(j)
out_args.append(output.view(np.ndarray))
else:
out_args.append(output)
kwargs['out'] = tuple(out_args)
else:
outputs = (None,) * ufunc.nout
info = {}
if in_no:
info['inputs'] = in_no
if out_no:
info['outputs'] = out_no
results = super().__array_ufunc__(ufunc, method, *args, **kwargs)
if results is NotImplemented:
return NotImplemented
if method == 'at':
if isinstance(inputs[0], A):
inputs[0].info = info
return
if ufunc.nout == 1:
results = (results,)
results = tuple((np.asarray(result).view(A)
if output is None else output)
for result, output in zip(results, outputs))
if results and isinstance(results[0], A):
results[0].info = info
return results[0] if len(results) == 1 else results
```
So, this class does not actually do anything interesting: it just
converts any instances of its own to regular ndarray (otherwise, we’d
get infinite recursion!), and adds an `info`
dictionary that tells
which inputs and outputs it converted. Hence, e.g.,

```
>>> a = np.arange(5.).view(A)
>>> b = np.sin(a)
>>> b.info
{'inputs': [0]}
>>> b = np.sin(np.arange(5.), out=(a,))
>>> b.info
{'outputs': [0]}
>>> a = np.arange(5.).view(A)
>>> b = np.ones(1).view(A)
>>> c = a + b
>>> c.info
{'inputs': [0, 1]}
>>> a += b
>>> a.info
{'inputs': [0, 1], 'outputs': [0]}
```
Note that another approach would be to use ```
getattr(ufunc,
methods)(*inputs, **kwargs)
```
instead of the `super`
call. For this example,
the result would be identical, but there is a difference if another operand
also defines `__array_ufunc__`
. E.g., lets assume that we evalulate
`np.add(a, b)`
, where `b`
is an instance of another class `B`
that has
an override. If you use `super`
as in the example,
`ndarray.__array_ufunc__`
will notice that `b`
has an override, which
means it cannot evaluate the result itself. Thus, it will return
*NotImplemented* and so will our class `A`
. Then, control will be passed
over to `b`
, which either knows how to deal with us and produces a result,
or does not and returns *NotImplemented*, raising a `TypeError`
.

If instead, we replace our `super`
call with `getattr(ufunc, method)`
, we
effectively do `np.add(a.view(np.ndarray), b)`
. Again, `B.__array_ufunc__`
will be called, but now it sees an `ndarray`
as the other argument. Likely,
it will know how to handle this, and return a new instance of the `B`
class
to us. Our example class is not set up to handle this, but it might well be
the best approach if, e.g., one were to re-implement `MaskedArray`
using
`__array_ufunc__`
.

As a final note: if the `super`
route is suited to a given class, an
advantage of using it is that it helps in constructing class hierarchies.
E.g., suppose that our other class `B`
also used the `super`
in its
`__array_ufunc__`
implementation, and we created a class `C`
that depended
on both, i.e., `class C(A, B)`
(with, for simplicity, not another
`__array_ufunc__`
override). Then any ufunc on an instance of `C`
would
pass on to `A.__array_ufunc__`
, the `super`
call in `A`
would go to
`B.__array_ufunc__`
, and the `super`
call in `B`
would go to
`ndarray.__array_ufunc__`
, thus allowing `A`
and `B`
to collaborate.

`__array_wrap__`
for ufuncs and other functions[#](#array-wrap-for-ufuncs-and-other-functions)
Prior to numpy 1.13, the behaviour of ufuncs could only be tuned using
`__array_wrap__`
and `__array_prepare__`
. These two allowed one to
change the output type of a ufunc, but, in contrast to
`__array_ufunc__`
, did not allow one to make any changes to the inputs.
It is hoped to eventually deprecate these, but `__array_wrap__`
is also
used by other numpy functions and methods, such as `squeeze`
, so at the
present time is still needed for full functionality.

Conceptually, `__array_wrap__`
“wraps up the action” in the sense of
allowing a subclass to set the type of the return value and update
attributes and metadata. Let’s show how this works with an example. First
we return to the simpler example subclass, but with a different name and
some print statements:

```
import numpy as np
class MySubClass(np.ndarray):
def __new__(cls, input_array, info=None):
obj = np.asarray(input_array).view(cls)
obj.info = info
return obj
def __array_finalize__(self, obj):
print('In __array_finalize__:')
print(' self is %s' % repr(self))
print(' obj is %s' % repr(obj))
if obj is None: return
self.info = getattr(obj, 'info', None)
def __array_wrap__(self, out_arr, context=None):
print('In __array_wrap__:')
print(' self is %s' % repr(self))
print(' arr is %s' % repr(out_arr))
# then just call the parent
return super().__array_wrap__(self, out_arr, context)
```
We run a ufunc on an instance of our new array:

```
>>> obj = MySubClass(np.arange(5), info='spam')
In __array_finalize__:
self is MySubClass([0, 1, 2, 3, 4])
obj is array([0, 1, 2, 3, 4])
>>> arr2 = np.arange(5)+1
>>> ret = np.add(arr2, obj)
In __array_wrap__:
self is MySubClass([0, 1, 2, 3, 4])
arr is array([1, 3, 5, 7, 9])
In __array_finalize__:
self is MySubClass([1, 3, 5, 7, 9])
obj is MySubClass([0, 1, 2, 3, 4])
>>> ret
MySubClass([1, 3, 5, 7, 9])
>>> ret.info
'spam'
```
Note that the ufunc (`np.add`
) has called the `__array_wrap__`
method
with arguments `self`
as `obj`
, and `out_arr`
as the (ndarray) result
of the addition. In turn, the default `__array_wrap__`
(`ndarray.__array_wrap__`
) has cast the result to class `MySubClass`
,
and called `__array_finalize__`
- hence the copying of the `info`
attribute. This has all happened at the C level.

But, we could do anything we wanted:

```
class SillySubClass(np.ndarray):
def __array_wrap__(self, arr, context=None):
return 'I lost your data'
```
```
>>> arr1 = np.arange(5)
>>> obj = arr1.view(SillySubClass)
>>> arr2 = np.arange(5)
>>> ret = np.multiply(obj, arr2)
>>> ret
'I lost your data'
```
So, by defining a specific `__array_wrap__`
method for our subclass,
we can tweak the output from ufuncs. The `__array_wrap__`
method
requires `self`
, then an argument - which is the result of the ufunc -
and an optional parameter *context*. This parameter is returned by
ufuncs as a 3-element tuple: (name of the ufunc, arguments of the ufunc,
domain of the ufunc), but is not set by other numpy functions. Though,
as seen above, it is possible to do otherwise, `__array_wrap__`
should
return an instance of its containing class. See the masked array
subclass for an implementation.

In addition to `__array_wrap__`
, which is called on the way out of the
ufunc, there is also an `__array_prepare__`
method which is called on
the way into the ufunc, after the output arrays are created but before any
computation has been performed. The default implementation does nothing
but pass through the array. `__array_prepare__`
should not attempt to
access the array data or resize the array, it is intended for setting the
output array type, updating attributes and metadata, and performing any
checks based on the input that may be desired before computation begins.
Like `__array_wrap__`
, `__array_prepare__`
must return an ndarray or
subclass thereof or raise an error.

## Extra gotchas - custom `__del__`
methods and ndarray.base[#](#extra-gotchas-custom-del-methods-and-ndarray-base)
One of the problems that ndarray solves is keeping track of memory
ownership of ndarrays and their views. Consider the case where we have
created an ndarray, `arr`
and have taken a slice with `v = arr[1:]`
.
The two objects are looking at the same memory. NumPy keeps track of
where the data came from for a particular array or view, with the
`base`
attribute:

```
>>> # A normal ndarray, that owns its own data
>>> arr = np.zeros((4,))
>>> # In this case, base is None
>>> arr.base is None
True
>>> # We take a view
>>> v1 = arr[1:]
>>> # base now points to the array that it derived from
>>> v1.base is arr
True
>>> # Take a view of a view
>>> v2 = v1[1:]
>>> # base points to the original array that it was derived from
>>> v2.base is arr
True
```
In general, if the array owns its own memory, as for `arr`
in this
case, then `arr.base`
will be None - there are some exceptions to this
- see the numpy book for more details.

The `base`
attribute is useful in being able to tell whether we have
a view or the original array. This in turn can be useful if we need
to know whether or not to do some specific cleanup when the subclassed
array is deleted. For example, we may only want to do the cleanup if
the original array is deleted, but not the views. For an example of
how this can work, have a look at the `memmap`
class in
`numpy.core`
.

## Subclassing and Downstream Compatibility[#](#subclassing-and-downstream-compatibility)
When sub-classing `ndarray`
or creating duck-types that mimic the `ndarray`
interface, it is your responsibility to decide how aligned your APIs will be
with those of numpy. For convenience, many numpy functions that have a corresponding
`ndarray`
method (e.g., `sum`
, `mean`
, `take`
, `reshape`
) work by checking
if the first argument to a function has a method of the same name. If it exists, the
method is called instead of coercing the arguments to a numpy array.

For example, if you want your sub-class or duck-type to be compatible with
numpy’s `sum`
function, the method signature for this object’s `sum`
method
should be the following:

```
def sum(self, axis=None, dtype=None, out=None, keepdims=False):
...
```
This is the exact same method signature for `np.sum`
, so now if a user calls
`np.sum`
on this object, numpy will call the object’s own `sum`
method and
pass in these arguments enumerated above in the signature, and no errors will
be raised because the signatures are completely compatible with each other.

If, however, you decide to deviate from this signature and do something like this:

```
def sum(self, axis=None, dtype=None):
...
```
This object is no longer compatible with `np.sum`
because if you call `np.sum`
,
it will pass in unexpected arguments `out`
and `keepdims`
, causing a TypeError
to be raised.

If you wish to maintain compatibility with numpy and its subsequent versions (which
might add new keyword arguments) but do not want to surface all of numpy’s arguments,
your function’s signature should accept `**kwargs`
. For example:

```
def sum(self, axis=None, dtype=None, **unused_kwargs):
...
```
This object is now compatible with `np.sum`
again because any extraneous arguments
(i.e. keywords that are not `axis`
or `dtype`
) will be hidden away in the
`**unused_kwargs`
parameter.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Multithreaded Generation[#](#multithreaded-generation)
The four core distributions ([ random](generated/numpy.random.Generator.random.html#numpy.random.Generator.random),

[,](generated/numpy.random.Generator.standard_normal.html#numpy.random.Generator.standard_normal)
`standard_normal`
[, and](generated/numpy.random.Generator.standard_exponential.html#numpy.random.Generator.standard_exponential)
`standard_exponential`
[) all allow existing arrays to be filled using the](generated/numpy.random.Generator.standard_gamma.html#numpy.random.Generator.standard_gamma)
`standard_gamma`
`out`
keyword argument. Existing arrays need to be contiguous and
well-behaved (writable and aligned). Under normal circumstances, arrays
created using the common constructors such as [will satisfy these requirements.](../generated/numpy.empty.html#numpy.empty)
`numpy.empty`
This example makes use of Python 3 [ concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures) to fill an array
using multiple threads. Threads are long-lived so that repeated calls do not
require any additional overheads from thread creation.

The random numbers generated are reproducible in the sense that the same seed will produce the same outputs, given that the number of threads does not change.

```
from numpy.random import default_rng, SeedSequence
import multiprocessing
import concurrent.futures
import numpy as np
class MultithreadedRNG:
def __init__(self, n, seed=None, threads=None):
if threads is None:
threads = multiprocessing.cpu_count()
self.threads = threads
seq = SeedSequence(seed)
self._random_generators = [default_rng(s)
for s in seq.spawn(threads)]
self.n = n
self.executor = concurrent.futures.ThreadPoolExecutor(threads)
self.values = np.empty(n)
self.step = np.ceil(n / threads).astype(np.int_)
def fill(self):
def _fill(random_state, out, first, last):
random_state.standard_normal(out=out[first:last])
futures = {}
for i in range(self.threads):
args = (_fill,
self._random_generators[i],
self.values,
i * self.step,
(i + 1) * self.step)
futures[self.executor.submit(*args)] = i
concurrent.futures.wait(futures)
def __del__(self):
self.executor.shutdown(False)
```
The multithreaded random number generator can be used to fill an array.
The `values`
attributes shows the zero-value before the fill and the
random value after.

```
In [2]: mrng = MultithreadedRNG(10000000, seed=12345)
...: print(mrng.values[-1])
Out[2]: 0.0
In [3]: mrng.fill()
...: print(mrng.values[-1])
Out[3]: 2.4545724517479104
```
The time required to produce using multiple threads can be compared to the time required to generate using a single thread.

```
In [4]: print(mrng.threads)
...: %timeit mrng.fill()
Out[4]: 4
...: 32.8 ms ± 2.71 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
```
The single threaded call directly uses the BitGenerator.

```
In [5]: values = np.empty(10000000)
...: rg = default_rng()
...: %timeit rg.standard_normal(out=values)
Out[5]: 99.6 ms ± 222 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
```
The gains are substantial and the scaling is reasonable even for arrays that are only moderately large. The gains are even larger when compared to a call that does not use an existing array due to array creation overhead.

```
In [6]: rg = default_rng()
...: %timeit rg.standard_normal(10000000)
Out[6]: 125 ms ± 309 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
```
Note that if *threads* is not set by the user, it will be determined by
*multiprocessing.cpu_count()*.

```
In [7]: # simulate the behavior for `threads=None`, if the machine had only one thread
...: mrng = MultithreadedRNG(10000000, seed=12345, threads=1)
...: print(mrng.values[-1])
Out[7]: 1.1800150052158556
```Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# What’s New or Different[#](#what-s-new-or-different)
NumPy 1.17.0 introduced [ Generator](generator.html#numpy.random.Generator) as an improved replacement for
the

[legacy](legacy.html#legacy)
[. Here is a quick comparison of the two implementations.](legacy.html#numpy.random.RandomState)
`RandomState`
Feature

|
Older Equivalent

|
Notes

|
`RandomState`
uses
the Mersenne Twister
`MT19937`
|
|
|
Access the values in a BitGenerator,
convert them to

Many other distributions are also supported.

|
|
|
Use the

|
The normal, exponential and gamma generators use 256-step Ziggurat methods which are 2-10 times faster than NumPy’s default implementation in

,`standard_normal`
or`standard_exponential`
. Because of the change in algorithms, it is not possible to reproduce the exact random values using`standard_gamma`
`Generator`
for these distributions or any distribution method that relies on them.
```
In [1]: import numpy.random
In [2]: rng = np.random.default_rng()
In [3]: %timeit -n 1 rng.standard_normal(100000)
...: %timeit -n 1 numpy.random.standard_normal(100000)
...:
1.22 ms +- 17.9 us per loop (mean +- std. dev. of 7 runs, 1 loop each)
2.19 ms +- 12.5 us per loop (mean +- std. dev. of 7 runs, 1 loop each)
```
```
In [4]: %timeit -n 1 rng.standard_exponential(100000)
...: %timeit -n 1 numpy.random.standard_exponential(100000)
...:
670 us +- 16.2 us per loop (mean +- std. dev. of 7 runs, 1 loop each)
1.62 ms +- 17.8 us per loop (mean +- std. dev. of 7 runs, 1 loop each)
```
```
In [5]: %timeit -n 1 rng.standard_gamma(3.0, 100000)
...: %timeit -n 1 numpy.random.standard_gamma(3.0, 100000)
...:
2.46 ms +- 13 us per loop (mean +- std. dev. of 7 runs, 1 loop each)
4.42 ms +- 7.76 us per loop (mean +- std. dev. of 7 runs, 1 loop each)
```
is now the canonical way to generate integer random numbers from a discrete uniform distribution. This replaces both`integers`
`randint`
and the deprecated`random_integers`
.
The

`rand`
and`randn`
methods are only available through the legacy.`RandomState`
is now the canonical way to generate floating-point random numbers, which replaces`Generator.random`
,`RandomState.random_sample`
, and`sample`
, all of which were aliases. This is consistent with Python’s`ranf`
.`random.random`
All bit generators can produce doubles, uint64s and uint32s via CTypes (

) and CFFI (`ctypes`
). This allows these bit generators to be used in numba.`cffi`
The bit generators can be used in downstream projects via Cython.

All bit generators use

to`SeedSequence`
[convert seed integers to initialized states](bit_generators/index.html#seeding-and-entropy).
Optional

`dtype`
argument that accepts`np.float32`
or`np.float64`
to produce either single or double precision uniform random variables for select distributions.accepts a`integers`
`dtype`
argument with any signed or unsigned integer dtype.
Normals (

)`standard_normal`
Standard Gammas (

)`standard_gamma`
Standard Exponentials (

)`standard_exponential`
```
In [6]: rng = np.random.default_rng()
In [7]: rng.random(3, dtype=np.float64)
Out[7]: array([0.32742445, 0.00929327, 0.97225134])
In [8]: rng.random(3, dtype=np.float32)
Out[8]: array([0.67851496, 0.9865629 , 0.23022616], dtype=float32)
In [9]: rng.integers(0, 256, size=3, dtype=np.uint8)
Out[9]: array([164, 54, 133], dtype=uint8)
```
Optional

`out`
argument that allows existing arrays to be filled for select distributionsUniforms (

)`random`
Normals (

)`standard_normal`
Standard Gammas (

)`standard_gamma`
Standard Exponentials (

)`standard_exponential`
This allows multithreading to fill large arrays in chunks using suitable BitGenerators in parallel.

```
In [10]: rng = np.random.default_rng()
In [11]: existing = np.zeros(4)
In [12]: rng.random(out=existing[:2])
Out[12]: array([0.83108158, 0.52678072])
In [13]: print(existing)
[0.83108158 0.52678072 0. 0. ]
```
Optional

`axis`
argument for methods like,`choice`
and`permutation`
that controls which axis an operation is performed over for multi-dimensional arrays.`shuffle`
```
In [14]: rng = np.random.default_rng()
In [15]: a = np.arange(12).reshape((3, 4))
In [16]: a
Out[16]:
array([[ 0, 1, 2, 3],
[ 4, 5, 6, 7],
[ 8, 9, 10, 11]])
In [17]: rng.choice(a, axis=1, size=5)
Out[17]:
array([[ 1, 1, 0, 3, 3],
[ 5, 5, 4, 7, 7],
[ 9, 9, 8, 11, 11]])
In [18]: rng.shuffle(a, axis=1) # Shuffle in-place
In [19]: a
Out[19]:
array([[ 2, 0, 3, 1],
[ 6, 4, 7, 5],
[10, 8, 11, 9]])
```
Added a method to sample from the complex normal distribution (

*complex_normal*)Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.import numpy as np
import numba as nb
from numpy.random import PCG64
from timeit import timeit
bit_gen = PCG64()
next_d = bit_gen.cffi.next_double
state_addr = bit_gen.cffi.state_address
def normals(n, state):
out = np.empty(n)
for i in range((n + 1) // 2):
x1 = 2.0 * next_d(state) - 1.0
x2 = 2.0 * next_d(state) - 1.0
r2 = x1 * x1 + x2 * x2
while r2 >= 1.0 or r2 == 0.0:
x1 = 2.0 * next_d(state) - 1.0
x2 = 2.0 * next_d(state) - 1.0
r2 = x1 * x1 + x2 * x2
f = np.sqrt(-2.0 * np.log(r2) / r2)
out[2 * i] = f * x1
if 2 * i + 1 < n:
out[2 * i + 1] = f * x2
return out
# Compile using Numba
normalsj = nb.jit(normals, nopython=True)
# Must use state address not state with numba
n = 10000
def numbacall():
return normalsj(n, state_addr)
rg = np.random.Generator(PCG64())
def numpycall():
return rg.normal(size=n)
# Check that the functions work
r1 = numbacall()
r2 = numpycall()
assert r1.shape == (n,)
assert r1.shape == r2.shape
t1 = timeit(numbacall, number=1000)
print(f'{t1:.2f} secs for {n} PCG64 (Numba/PCG64) gaussian randoms')
t2 = timeit(numpycall, number=1000)
print(f'{t2:.2f} secs for {n} PCG64 (NumPy/PCG64) gaussian randoms')
# example 2
next_u32 = bit_gen.ctypes.next_uint32
ctypes_state = bit_gen.ctypes.state
@nb.jit(nopython=True)
def bounded_uint(lb, ub, state):
mask = delta = ub - lb
mask |= mask >> 1
mask |= mask >> 2
mask |= mask >> 4
mask |= mask >> 8
mask |= mask >> 16
val = next_u32(state) & mask
while val > delta:
val = next_u32(state) & mask
return lb + val
print(bounded_uint(323, 2394691, ctypes_state.value))
@nb.jit(nopython=True)
def bounded_uints(lb, ub, n, state):
out = np.empty(n, dtype=np.uint32)
for i in range(n):
out[i] = bounded_uint(lb, ub, state)
bounded_uints(323, 2394691, 10000000, ctypes_state.value)Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Legacy Random Generation[#](#legacy-random-generation)
The [ RandomState](#numpy.random.RandomState) provides access to
legacy generators. This generator is considered frozen and will have
no further improvements. It is guaranteed to produce the same values
as the final point release of NumPy v1.16. These all depend on Box-Muller
normals or inverse CDF exponentials or gammas. This class should only be used
if it is essential to have randoms that are identical to what
would have been produced by previous versions of NumPy.

[ RandomState](#numpy.random.RandomState) adds additional information
to the state which is required when using Box-Muller normals since these
are produced in pairs. It is important to use
[, and not the underlying bit generators](generated/numpy.random.RandomState.get_state.html#numpy.random.RandomState.get_state)
`RandomState.get_state`
*state*, when accessing the state so that these extra values are saved.
Although we provide the [ MT19937](bit_generators/mt19937.html#numpy.random.MT19937) BitGenerator for use independent of

[, note that its default seeding uses](#numpy.random.RandomState)
`RandomState`
[rather than the legacy seeding algorithm.](bit_generators/generated/numpy.random.SeedSequence.html#numpy.random.SeedSequence)
`SeedSequence`
[will use the legacy seeding algorithm. The methods to use the legacy seeding algorithm are currently private as the main reason to use them is just to implement](#numpy.random.RandomState)
`RandomState`
[. However, one can reset the state of](#numpy.random.RandomState)
`RandomState`
[using the state of the](bit_generators/mt19937.html#numpy.random.MT19937)
`MT19937`
[:](#numpy.random.RandomState)
`RandomState`
```
from numpy.random import MT19937
from numpy.random import RandomState
rs = RandomState(12345)
mt19937 = MT19937()
mt19937.state = rs.get_state()
rs2 = RandomState(mt19937)
# Same output
rs.standard_normal()
rs2.standard_normal()
rs.random()
rs2.random()
rs.standard_exponential()
rs2.standard_exponential()
```
*class*numpy.random.RandomState(*seed=None*)[#](#numpy.random.RandomState)
-
Container for the slow Mersenne Twister pseudo-random number generator. Consider using a different BitGenerator with the Generator container instead.

and`RandomState`
expose a number of methods for generating random numbers drawn from a variety of probability distributions. In addition to the distribution-specific arguments, each method takes a keyword argument`Generator`
*size*that defaults to`None`
. If*size*is`None`
, then a single value is generated and returned. If*size*is an integer, then a 1-D array filled with generated values is returned. If*size*is a tuple, then an array with that shape is filled and returned.**Compatibility Guarantee**A fixed bit generator using a fixed seed and a fixed series of calls to ‘RandomState’ methods using the same parameters will always produce the same results up to roundoff error except when the values were incorrect.

is effectively frozen and will only receive updates that are required by changes in the internals of Numpy. More substantial changes, including algorithmic improvements, are reserved for`RandomState`
.`Generator`
Parameters:
-
**seed**{None, int, array_like, BitGenerator}, optional
Random seed used to initialize the pseudo-random number generator or an instantized BitGenerator. If an integer or array, used as a seed for the MT19937 BitGenerator. Values can be any integer between 0 and 2**32 - 1 inclusive, an array (or other sequence) of such integers, or

`None`
(the default). Ifis`seed`
`None`
, then theBitGenerator is initialized by reading data from`MT19937`
`/dev/urandom`
(or the Windows analogue) if available or seed from the clock otherwise.
See also

Notes

The Python stdlib module “random” also contains a Mersenne Twister pseudo-random number generator with a number of methods that are similar to the ones available in

.`RandomState`
, besides being NumPy-aware, has the advantage that it provides a much larger number of probability distributions to choose from.`RandomState`
## Seeding and State[#](#seeding-and-state)
|
Return a tuple representing the internal state of the generator.

|
|
Set the internal state of the generator from a tuple.

|
|
Reseed a legacy MT19937 BitGenerator

|
## Simple random data[#](#simple-random-data)
|
Random values in a given shape.

|
|
Return a sample (or samples) from the "standard normal" distribution.

|
|
Return random integers from

|
|
Random integers of type

|
|
Return random floats in the half-open interval [0.0, 1.0).

|
|
Generates a random sample from a given 1-D array

|
|
Return random bytes.

|
## Permutations[#](#permutations)
|
Modify a sequence in-place by shuffling its contents.

|
|
Randomly permute a sequence, or return a permuted range.

|
## Distributions[#](#distributions)
|
Draw samples from a Beta distribution.

|
|
Draw samples from a binomial distribution.

|
|
Draw samples from a chi-square distribution.

|
|
Draw samples from the Dirichlet distribution.

|
|
Draw samples from an exponential distribution.

|
|
Draw samples from an F distribution.

|
|
Draw samples from a Gamma distribution.

|
|
Draw samples from the geometric distribution.

|
|
Draw samples from a Gumbel distribution.

|
|
Draw samples from a Hypergeometric distribution.

|
|
Draw samples from the Laplace or double exponential distribution with specified location (or mean) and scale (decay).

|
|
Draw samples from a logistic distribution.

|
|
Draw samples from a log-normal distribution.

|
|
Draw samples from a logarithmic series distribution.

|
|
Draw samples from a multinomial distribution.

|
|
Draw random samples from a multivariate normal distribution.

|
|
Draw samples from a negative binomial distribution.

|
|
Draw samples from a noncentral chi-square distribution.

|
|
Draw samples from the noncentral F distribution.

|
|
Draw random samples from a normal (Gaussian) distribution.

|
|
Draw samples from a Pareto II or Lomax distribution with specified shape.

|
|
Draw samples from a Poisson distribution.

|
|
Draws samples in [0, 1] from a power distribution with positive exponent a - 1.

|
|
Draw samples from a Rayleigh distribution.

|
|
Draw samples from a standard Cauchy distribution with mode = 0.

|
|
Draw samples from the standard exponential distribution.

|
|
Draw samples from a standard Gamma distribution.

|
|
Draw samples from a standard Normal distribution (mean=0, stdev=1).

|
|
Draw samples from a standard Student's t distribution with

|
|
Draw samples from the triangular distribution over the interval

|
|
Draw samples from a uniform distribution.

|
|
Draw samples from a von Mises distribution.

|
|
Draw samples from a Wald, or inverse Gaussian, distribution.

|
|
Draw samples from a Weibull distribution.

|
|
Draw samples from a Zipf distribution.

|
## Functions in `numpy.random`
[#](#functions-in-numpy-random)
`numpy.random`
Many of the RandomState methods above are exported as functions in
[ numpy.random](index.html#module-numpy.random) This usage is discouraged, as it is implemented via a global

[instance which is not advised on two counts:](#numpy.random.RandomState)
`RandomState`
It uses global state, which means results will change as the code changes

It uses a

rather than the more modern`RandomState`
.`Generator`
For backward compatible legacy reasons, we will not change this.

|
Draw samples from a Beta distribution.

|
|
Draw samples from a binomial distribution.

|
|
Return random bytes.

|
|
Draw samples from a chi-square distribution.

|
|
Generates a random sample from a given 1-D array

|
|
Draw samples from the Dirichlet distribution.

|
|
Draw samples from an exponential distribution.

|
|
Draw samples from an F distribution.

|
|
Draw samples from a Gamma distribution.

|
|
Draw samples from the geometric distribution.

|
|
Return a tuple representing the internal state of the generator.

|
|
Draw samples from a Gumbel distribution.

|
|
Draw samples from a Hypergeometric distribution.

|
|
Draw samples from the Laplace or double exponential distribution with specified location (or mean) and scale (decay).

|
|
Draw samples from a logistic distribution.

|
|
Draw samples from a log-normal distribution.

|
|
Draw samples from a logarithmic series distribution.

|
|
Draw samples from a multinomial distribution.

|
|
Draw random samples from a multivariate normal distribution.

|
|
Draw samples from a negative binomial distribution.

|
|
Draw samples from a noncentral chi-square distribution.

|
|
Draw samples from the noncentral F distribution.

|
|
Draw random samples from a normal (Gaussian) distribution.

|
|
Draw samples from a Pareto II or Lomax distribution with specified shape.

|
|
Randomly permute a sequence, or return a permuted range.

|
|
Draw samples from a Poisson distribution.

|
|
Draws samples in [0, 1] from a power distribution with positive exponent a - 1.

|
|
Random values in a given shape.

|
|
Return random integers from

|
|
Return a sample (or samples) from the "standard normal" distribution.

|
|
Return random floats in the half-open interval [0.0, 1.0).

|
|
Random integers of type

|
|
Return random floats in the half-open interval [0.0, 1.0).

|
This is an alias of

|
|
Draw samples from a Rayleigh distribution.

|
This is an alias of

|
|
Reseed the singleton RandomState instance.

|
|
Set the internal state of the generator from a tuple.

|
|
Modify a sequence in-place by shuffling its contents.

|
|
Draw samples from a standard Cauchy distribution with mode = 0.

|
|
Draw samples from the standard exponential distribution.

|
|
Draw samples from a standard Gamma distribution.

|
|
Draw samples from a standard Normal distribution (mean=0, stdev=1).

|
|
Draw samples from a standard Student's t distribution with

|
|
Draw samples from the triangular distribution over the interval

|
|
Draw samples from a uniform distribution.

|
|
Draw samples from a von Mises distribution.

|
|
Draw samples from a Wald, or inverse Gaussian, distribution.

|
|
Draw samples from a Weibull distribution.

|
|
Draw samples from a Zipf distribution.

|Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Release notes[#](#release-notes)
[1.26.0](release/1.26.0-notes.html)[New Features](release/1.26.0-notes.html#new-features)
[Improvements](release/1.26.0-notes.html#improvements)
[Build system changes](release/1.26.0-notes.html#build-system-changes)
[Contributors](release/1.26.0-notes.html#contributors)
[Pull requests merged](release/1.26.0-notes.html#pull-requests-merged)
[1.25.2](release/1.25.2-notes.html)
[1.25.1](release/1.25.1-notes.html)
[1.25.0](release/1.25.0-notes.html)[Deprecations](release/1.25.0-notes.html#deprecations)
[Expired deprecations](release/1.25.0-notes.html#expired-deprecations)
[Compatibility notes](release/1.25.0-notes.html#compatibility-notes)`np.pad`
with`mode=wrap`
pads with strict multiples of original data
[Cython](release/1.25.0-notes.html#cython-long-t-and-ulong-t-removed)`long_t`
and`ulong_t`
removed
[Changed error message and type for bad](release/1.25.0-notes.html#changed-error-message-and-type-for-bad-axes-argument-to-ufunc)`axes`
argument to`ufunc`
[Array-likes that define](release/1.25.0-notes.html#array-likes-that-define-array-ufunc-can-now-override-ufuncs-if-used-as-where)`__array_ufunc__`
can now override ufuncs if used as`where`
[Compiling against the NumPy C API is now backwards compatible by default](release/1.25.0-notes.html#compiling-against-the-numpy-c-api-is-now-backwards-compatible-by-default)
[New Features](release/1.25.0-notes.html#new-features)`np.einsum`
now accepts arrays with`object`
dtype
[Add support for inplace matrix multiplication](release/1.25.0-notes.html#add-support-for-inplace-matrix-multiplication)
[Added](release/1.25.0-notes.html#added-npy-enable-cpu-features-environment-variable)`NPY_ENABLE_CPU_FEATURES`
environment variable
[NumPy now has an](release/1.25.0-notes.html#numpy-now-has-an-np-exceptions-namespace)`np.exceptions`
namespace
`np.linalg`
functions return NamedTuples
[String functions in](release/1.25.0-notes.html#string-functions-in-np-char-are-compatible-with-nep-42-custom-dtypes)`np.char`
are compatible with NEP 42 custom dtypes
[String dtype instances can be created from the string abstract dtype classes](release/1.25.0-notes.html#string-dtype-instances-can-be-created-from-the-string-abstract-dtype-classes)
[Fujitsu C/C++ compiler is now supported](release/1.25.0-notes.html#fujitsu-c-c-compiler-is-now-supported)
[SSL2 is now supported](release/1.25.0-notes.html#ssl2-is-now-supported)
[Improvements](release/1.25.0-notes.html#improvements)`NDArrayOperatorsMixin`
specifies that it has no`__slots__`
[Fix power of complex zero](release/1.25.0-notes.html#fix-power-of-complex-zero)
[New](release/1.25.0-notes.html#new-dtypepromotionerror)`DTypePromotionError`
*np.show_config*uses information from Meson
[Fix](release/1.25.0-notes.html#fix-np-ma-diff-not-preserving-the-mask-when-called-with-arguments-prepend-append)`np.ma.diff`
not preserving the mask when called with arguments prepend/append.
[Corrected error handling for NumPy C-API in Cython](release/1.25.0-notes.html#corrected-error-handling-for-numpy-c-api-in-cython)
[Ability to directly spawn random number generators](release/1.25.0-notes.html#ability-to-directly-spawn-random-number-generators)
`numpy.logspace`
now supports a non-scalar`base`
argument
`np.ma.dot()`
now supports for non-2d arrays
[Explicitly show keys of .npz file in repr](release/1.25.0-notes.html#explicitly-show-keys-of-npz-file-in-repr)
[NumPy now exposes DType classes in](release/1.25.0-notes.html#numpy-now-exposes-dtype-classes-in-np-dtypes)`np.dtypes`
[Drop dtype metadata before saving in .npy or .npz files](release/1.25.0-notes.html#drop-dtype-metadata-before-saving-in-npy-or-npz-files)
`numpy.lib.recfunctions.structured_to_unstructured`
returns views in more cases
[Signed and unsigned integers always compare correctly](release/1.25.0-notes.html#signed-and-unsigned-integers-always-compare-correctly)
[Performance improvements and changes](release/1.25.0-notes.html#performance-improvements-and-changes)
[Changes](release/1.25.0-notes.html#changes)
[1.24.3](release/1.24.3-notes.html)
[1.24.2](release/1.24.2-notes.html)
[1.24.1](release/1.24.1-notes.html)
[1.24.0](release/1.24.0-notes.html)[Deprecations](release/1.24.0-notes.html#deprecations)
[Expired deprecations](release/1.24.0-notes.html#expired-deprecations)
[Compatibility notes](release/1.24.0-notes.html#compatibility-notes)
[New Features](release/1.24.0-notes.html#new-features)[New attribute](release/1.24.0-notes.html#new-attribute-symbol-added-to-polynomial-classes)`symbol`
added to polynomial classes
[F2PY support for Fortran](release/1.24.0-notes.html#f2py-support-for-fortran-character-strings)`character`
strings
[New function](release/1.24.0-notes.html#new-function-np-show-runtime)`np.show_runtime`
`strict`
option for`testing.assert_array_equal`
[New parameter](release/1.24.0-notes.html#new-parameter-equal-nan-added-to-np-unique)`equal_nan`
added to`np.unique`
`casting`
and`dtype`
keyword arguments for`numpy.stack`
`casting`
and`dtype`
keyword arguments for`numpy.vstack`
`casting`
and`dtype`
keyword arguments for`numpy.hstack`
[The bit generator underlying the singleton RandomState can be changed](release/1.24.0-notes.html#the-bit-generator-underlying-the-singleton-randomstate-can-be-changed)
`np.void`
now has a`dtype`
argument
[Improvements](release/1.24.0-notes.html#improvements)
[Performance improvements and changes](release/1.24.0-notes.html#performance-improvements-and-changes)
[Changes](release/1.24.0-notes.html#changes)
[1.23.5](release/1.23.5-notes.html)
[1.23.4](release/1.23.4-notes.html)
[1.23.3](release/1.23.3-notes.html)
[1.23.2](release/1.23.2-notes.html)
[1.23.1](release/1.23.1-notes.html)
[1.23.0](release/1.23.0-notes.html)[New functions](release/1.23.0-notes.html#new-functions)
[Deprecations](release/1.23.0-notes.html#deprecations)
[Expired deprecations](release/1.23.0-notes.html#expired-deprecations)
[New Features](release/1.23.0-notes.html#new-features)[crackfortran has support for operator and assignment overloading](release/1.23.0-notes.html#crackfortran-has-support-for-operator-and-assignment-overloading)
[f2py supports reading access type attributes from derived type statements](release/1.23.0-notes.html#f2py-supports-reading-access-type-attributes-from-derived-type-statements)
[New parameter](release/1.23.0-notes.html#new-parameter-ndmin-added-to-genfromtxt)`ndmin`
added to`genfromtxt`
`np.loadtxt`
now supports quote character and single converter function
[Changing to dtype of a different size now requires contiguity of only the last axis](release/1.23.0-notes.html#changing-to-dtype-of-a-different-size-now-requires-contiguity-of-only-the-last-axis)
[Deterministic output files for F2PY](release/1.23.0-notes.html#deterministic-output-files-for-f2py)
`keepdims`
parameter for`average`
[New parameter](release/1.23.0-notes.html#new-parameter-equal-nan-added-to-np-unique)`equal_nan`
added to`np.unique`
[Compatibility notes](release/1.23.0-notes.html#compatibility-notes)
[Improvements](release/1.23.0-notes.html#improvements)
[Performance improvements and changes](release/1.23.0-notes.html#performance-improvements-and-changes)
[1.22.4](release/1.22.4-notes.html)
[1.22.3](release/1.22.3-notes.html)
[1.22.2](release/1.22.2-notes.html)
[1.22.1](release/1.22.1-notes.html)
[1.22.0](release/1.22.0-notes.html)[Expired deprecations](release/1.22.0-notes.html#expired-deprecations)
[Deprecations](release/1.22.0-notes.html#deprecations)
[Compatibility notes](release/1.22.0-notes.html#compatibility-notes)[Distutils forces strict floating point model on clang](release/1.22.0-notes.html#distutils-forces-strict-floating-point-model-on-clang)
[Removed floor division support for complex types](release/1.22.0-notes.html#removed-floor-division-support-for-complex-types)
`numpy.vectorize`
functions now produce the same output class as the base function
[Python 3.7 is no longer supported](release/1.22.0-notes.html#python-3-7-is-no-longer-supported)
[str/repr of complex dtypes now include space after punctuation](release/1.22.0-notes.html#str-repr-of-complex-dtypes-now-include-space-after-punctuation)
[Corrected](release/1.22.0-notes.html#corrected-advance-in-pcg64dsxm-and-pcg64)`advance`
in`PCG64DSXM`
and`PCG64`
[Change in generation of random 32 bit floating point variates](release/1.22.0-notes.html#change-in-generation-of-random-32-bit-floating-point-variates)
[C API changes](release/1.22.0-notes.html#c-api-changes)
[New Features](release/1.22.0-notes.html#new-features)[NEP 49 configurable allocators](release/1.22.0-notes.html#nep-49-configurable-allocators)
[Implementation of the NEP 47 (adopting the array API standard)](release/1.22.0-notes.html#implementation-of-the-nep-47-adopting-the-array-api-standard)
[Generate C/C++ API reference documentation from comments blocks is now possible](release/1.22.0-notes.html#generate-c-c-api-reference-documentation-from-comments-blocks-is-now-possible)
[Assign the platform-specific](release/1.22.0-notes.html#assign-the-platform-specific-c-intp-precision-via-a-mypy-plugin)`c_intp`
precision via a mypy plugin
[Add NEP 47-compatible dlpack support](release/1.22.0-notes.html#add-nep-47-compatible-dlpack-support)
`keepdims`
optional argument added to`numpy.argmin`
,`numpy.argmax`
`bit_count`
to compute the number of 1-bits in an integer
[The](release/1.22.0-notes.html#the-ndim-and-axis-attributes-have-been-added-to-numpy-axiserror)`ndim`
and`axis`
attributes have been added to`numpy.AxisError`
[Preliminary support for](release/1.22.0-notes.html#preliminary-support-for-windows-arm64-target)`windows/arm64`
target
[Added support for LoongArch](release/1.22.0-notes.html#added-support-for-loongarch)
[A](release/1.22.0-notes.html#a-clang-format-file-has-been-added)`.clang-format`
file has been added
`is_integer`
is now available to`numpy.floating`
and`numpy.integer`
[Symbolic parser for Fortran dimension specifications](release/1.22.0-notes.html#symbolic-parser-for-fortran-dimension-specifications)
`ndarray`
,`dtype`
and`number`
are now runtime-subscriptable
[Improvements](release/1.22.0-notes.html#improvements)`ctypeslib.load_library`
can now take any path-like object
[Add](release/1.22.0-notes.html#add-smallest-normal-and-smallest-subnormal-attributes-to-finfo)`smallest_normal`
and`smallest_subnormal`
attributes to`finfo`
`numpy.linalg.qr`
accepts stacked matrices as inputs
`numpy.fromregex`
now accepts`os.PathLike`
implementations
[Add new methods for](release/1.22.0-notes.html#add-new-methods-for-quantile-and-percentile)`quantile`
and`percentile`
[Missing parameters have been added to the](release/1.22.0-notes.html#missing-parameters-have-been-added-to-the-nan-x-functions)`nan<x>`
functions
[Annotating the main Numpy namespace](release/1.22.0-notes.html#annotating-the-main-numpy-namespace)
[Vectorize umath module using AVX-512](release/1.22.0-notes.html#vectorize-umath-module-using-avx-512)
[OpenBLAS v0.3.18](release/1.22.0-notes.html#openblas-v0-3-18)
[1.21.6](release/1.21.6-notes.html)
[1.21.5](release/1.21.5-notes.html)
[1.21.4](release/1.21.4-notes.html)
[1.21.3](release/1.21.3-notes.html)
[1.21.2](release/1.21.2-notes.html)
[1.21.1](release/1.21.1-notes.html)
[1.21.0](release/1.21.0-notes.html)[New functions](release/1.21.0-notes.html#new-functions)
[Expired deprecations](release/1.21.0-notes.html#expired-deprecations)
[Deprecations](release/1.21.0-notes.html#deprecations)
[Expired deprecations](release/1.21.0-notes.html#id2)
[Compatibility notes](release/1.21.0-notes.html#compatibility-notes)[Error type changes in universal functions](release/1.21.0-notes.html#error-type-changes-in-universal-functions)
`__array_ufunc__`
argument validation
`__array_ufunc__`
and additional positional arguments
[Validate input values in](release/1.21.0-notes.html#validate-input-values-in-generator-uniform)`Generator.uniform`
`/usr/include`
removed from default include paths
[Changes to comparisons with](release/1.21.0-notes.html#changes-to-comparisons-with-dtype)`dtype=...`
[Changes to](release/1.21.0-notes.html#changes-to-dtype-and-signature-arguments-in-ufuncs)`dtype`
and`signature`
arguments in ufuncs
[Ufunc](release/1.21.0-notes.html#ufunc-signature-and-dtype-generalization-and-casting)`signature=...`
and`dtype=`
generalization and`casting`
[Distutils forces strict floating point model on clang](release/1.21.0-notes.html#distutils-forces-strict-floating-point-model-on-clang)
[C API changes](release/1.21.0-notes.html#c-api-changes)
[New Features](release/1.21.0-notes.html#new-features)[Added a mypy plugin for handling platform-specific](release/1.21.0-notes.html#added-a-mypy-plugin-for-handling-platform-specific-numpy-number-precisions)`numpy.number`
precisions
[Let the mypy plugin manage extended-precision](release/1.21.0-notes.html#let-the-mypy-plugin-manage-extended-precision-numpy-number-subclasses)`numpy.number`
subclasses
[New](release/1.21.0-notes.html#new-min-digits-argument-for-printing-float-values)`min_digits`
argument for printing float values
[f2py now recognizes Fortran abstract interface blocks](release/1.21.0-notes.html#f2py-now-recognizes-fortran-abstract-interface-blocks)
[BLAS and LAPACK configuration via environment variables](release/1.21.0-notes.html#blas-and-lapack-configuration-via-environment-variables)
[A runtime-subcriptable alias has been added for](release/1.21.0-notes.html#a-runtime-subcriptable-alias-has-been-added-for-ndarray)`ndarray`
[Improvements](release/1.21.0-notes.html#improvements)
[Performance improvements](release/1.21.0-notes.html#performance-improvements)
[Changes](release/1.21.0-notes.html#changes)
[1.20.3](release/1.20.3-notes.html)
[1.20.2](release/1.20.2-notes.html)
[1.20.1](release/1.20.1-notes.html)
[1.20.0](release/1.20.0-notes.html)[New functions](release/1.20.0-notes.html#new-functions)
[Deprecations](release/1.20.0-notes.html#deprecations)[Using the aliases of builtin types like](release/1.20.0-notes.html#using-the-aliases-of-builtin-types-like-np-int-is-deprecated)`np.int`
is deprecated
[Passing](release/1.20.0-notes.html#passing-shape-none-to-functions-with-a-non-optional-shape-argument-is-deprecated)`shape=None`
to functions with a non-optional shape argument is deprecated
[Indexing errors will be reported even when index result is empty](release/1.20.0-notes.html#indexing-errors-will-be-reported-even-when-index-result-is-empty)
[Inexact matches for](release/1.20.0-notes.html#inexact-matches-for-mode-and-searchside-are-deprecated)`mode`
and`searchside`
are deprecated
[Deprecation of](release/1.20.0-notes.html#deprecation-of-numpy-dual)*numpy.dual*
`outer`
and`ufunc.outer`
deprecated for matrix
[Further Numeric Style types Deprecated](release/1.20.0-notes.html#further-numeric-style-types-deprecated)
[The](release/1.20.0-notes.html#the-ndincr-method-of-ndindex-is-deprecated)`ndincr`
method of`ndindex`
is deprecated
[ArrayLike objects which do not define](release/1.20.0-notes.html#arraylike-objects-which-do-not-define-len-and-getitem)`__len__`
and`__getitem__`
[Future Changes](release/1.20.0-notes.html#future-changes)
[Expired deprecations](release/1.20.0-notes.html#expired-deprecations)
[Compatibility notes](release/1.20.0-notes.html#compatibility-notes)`isinstance(dtype, np.dtype)`
and not`type(dtype) is not np.dtype`
[Same kind casting in concatenate with](release/1.20.0-notes.html#same-kind-casting-in-concatenate-with-axis-none)`axis=None`
[NumPy Scalars are cast when assigned to arrays](release/1.20.0-notes.html#numpy-scalars-are-cast-when-assigned-to-arrays)
[Array coercion changes when Strings and other types are mixed](release/1.20.0-notes.html#array-coercion-changes-when-strings-and-other-types-are-mixed)
[Array coercion restructure](release/1.20.0-notes.html#array-coercion-restructure)
[Writing to the result of](release/1.20.0-notes.html#writing-to-the-result-of-numpy-broadcast-arrays-will-export-readonly-buffers)`numpy.broadcast_arrays`
will export readonly buffers
[Numeric-style type names have been removed from type dictionaries](release/1.20.0-notes.html#numeric-style-type-names-have-been-removed-from-type-dictionaries)
[The](release/1.20.0-notes.html#the-operator-concat-function-now-raises-typeerror-for-array-arguments)`operator.concat`
function now raises TypeError for array arguments
`nickname`
attribute removed from ABCPolyBase
`float->timedelta`
and`uint64->timedelta`
promotion will raise a TypeError
`numpy.genfromtxt`
now correctly unpacks structured arrays
`mgrid`
,`r_`
, etc. consistently return correct outputs for non-default precision input
[Boolean array indices with mismatching shapes now properly give](release/1.20.0-notes.html#boolean-array-indices-with-mismatching-shapes-now-properly-give-indexerror)`IndexError`
[Casting errors interrupt Iteration](release/1.20.0-notes.html#casting-errors-interrupt-iteration)
[f2py generated code may return unicode instead of byte strings](release/1.20.0-notes.html#f2py-generated-code-may-return-unicode-instead-of-byte-strings)
[The first element of the](release/1.20.0-notes.html#the-first-element-of-the-array-interface-data-tuple-must-be-an-integer)`__array_interface__["data"]`
tuple must be an integer
[poly1d respects the dtype of all-zero argument](release/1.20.0-notes.html#poly1d-respects-the-dtype-of-all-zero-argument)
[The numpy.i file for swig is Python 3 only.](release/1.20.0-notes.html#the-numpy-i-file-for-swig-is-python-3-only)
[Void dtype discovery in](release/1.20.0-notes.html#void-dtype-discovery-in-np-array)`np.array`
[C API changes](release/1.20.0-notes.html#c-api-changes)
[New Features](release/1.20.0-notes.html#new-features)`where`
keyword argument for`numpy.all`
and`numpy.any`
functions
`where`
keyword argument for`numpy`
functions`mean`
,`std`
,`var`
`norm=backward`
,`forward`
keyword options for`numpy.fft`
functions
[NumPy is now typed](release/1.20.0-notes.html#numpy-is-now-typed)
`numpy.typing`
is accessible at runtime
[New](release/1.20.0-notes.html#new-f2py-numpy-version-attribute-for-f2py-generated-modules)`__f2py_numpy_version__`
attribute for f2py generated modules.
`mypy`
tests can be run via runtests.py
[Negation of user defined BLAS/LAPACK detection order](release/1.20.0-notes.html#negation-of-user-defined-blas-lapack-detection-order)
[Allow passing optimizations arguments to asv build](release/1.20.0-notes.html#allow-passing-optimizations-arguments-to-asv-build)
[The NVIDIA HPC SDK nvfortran compiler is now supported](release/1.20.0-notes.html#the-nvidia-hpc-sdk-nvfortran-compiler-is-now-supported)
`dtype`
option for`cov`
and`corrcoef`
[Improvements](release/1.20.0-notes.html#improvements)[Improved string representation for polynomials (](release/1.20.0-notes.html#improved-string-representation-for-polynomials-str)`__str__`
)
[Remove the Accelerate library as a candidate LAPACK library](release/1.20.0-notes.html#remove-the-accelerate-library-as-a-candidate-lapack-library)
[Object arrays containing multi-line objects have a more readable](release/1.20.0-notes.html#object-arrays-containing-multi-line-objects-have-a-more-readable-repr)`repr`
[Concatenate supports providing an output dtype](release/1.20.0-notes.html#concatenate-supports-providing-an-output-dtype)
[Thread safe f2py callback functions](release/1.20.0-notes.html#thread-safe-f2py-callback-functions)
`numpy.core.records.fromfile`
now supports file-like objects
[RPATH support on AIX added to distutils](release/1.20.0-notes.html#rpath-support-on-aix-added-to-distutils)
[Use f90 compiler specified by the command line args](release/1.20.0-notes.html#use-f90-compiler-specified-by-the-command-line-args)
[Add NumPy declarations for Cython 3.0 and later](release/1.20.0-notes.html#add-numpy-declarations-for-cython-3-0-and-later)
[Make the window functions exactly symmetric](release/1.20.0-notes.html#make-the-window-functions-exactly-symmetric)
[Performance improvements and changes](release/1.20.0-notes.html#performance-improvements-and-changes)
[Changes](release/1.20.0-notes.html#changes)
[1.19.5](release/1.19.5-notes.html)
[1.19.4](release/1.19.4-notes.html)
[1.19.3](release/1.19.3-notes.html)
[1.19.2](release/1.19.2-notes.html)
[1.19.1](release/1.19.1-notes.html)
[1.19.0](release/1.19.0-notes.html)[Highlights](release/1.19.0-notes.html#highlights)
[Expired deprecations](release/1.19.0-notes.html#expired-deprecations)
[Compatibility notes](release/1.19.0-notes.html#compatibility-notes)[Changed random variate stream from](release/1.19.0-notes.html#changed-random-variate-stream-from-numpy-random-generator-dirichlet)`numpy.random.Generator.dirichlet`
[Scalar promotion in](release/1.19.0-notes.html#scalar-promotion-in-pyarray-converttocommontype)`PyArray_ConvertToCommonType`
[Fasttake and fastputmask slots are deprecated and NULL’ed](release/1.19.0-notes.html#fasttake-and-fastputmask-slots-are-deprecated-and-null-ed)
`np.ediff1d`
casting behaviour with`to_end`
and`to_begin`
[Converting of empty array-like objects to NumPy arrays](release/1.19.0-notes.html#converting-of-empty-array-like-objects-to-numpy-arrays)
[Removed](release/1.19.0-notes.html#removed-multiarray-int-asbuffer)`multiarray.int_asbuffer`
`numpy.distutils.compat`
has been removed
`issubdtype`
no longer interprets`float`
as`np.floating`
[Change output of](release/1.19.0-notes.html#change-output-of-round-on-scalars-to-be-consistent-with-python)`round`
on scalars to be consistent with Python
[The](release/1.19.0-notes.html#the-numpy-ndarray-constructor-no-longer-interprets-strides-as-strides-none)`numpy.ndarray`
constructor no longer interprets`strides=()`
as`strides=None`
[C-Level string to datetime casts changed](release/1.19.0-notes.html#c-level-string-to-datetime-casts-changed)
`SeedSequence`
with small seeds no longer conflicts with spawning
[Deprecations](release/1.19.0-notes.html#deprecations)[Deprecate automatic](release/1.19.0-notes.html#deprecate-automatic-dtype-object-for-ragged-input)`dtype=object`
for ragged input
[Passing](release/1.19.0-notes.html#passing-shape-0-to-factory-functions-in-numpy-rec-is-deprecated)`shape=0`
to factory functions in`numpy.rec`
is deprecated
[Deprecation of probably unused C-API functions](release/1.19.0-notes.html#deprecation-of-probably-unused-c-api-functions)
[Converting certain types to dtypes is Deprecated](release/1.19.0-notes.html#converting-certain-types-to-dtypes-is-deprecated)
[Deprecation of](release/1.19.0-notes.html#deprecation-of-round-for-np-complexfloating-scalars)`round`
for`np.complexfloating`
scalars
`numpy.ndarray.tostring()`
is deprecated in favor of`tobytes()`
[C API changes](release/1.19.0-notes.html#c-api-changes)
[New Features](release/1.19.0-notes.html#new-features)
[Improvements](release/1.19.0-notes.html#improvements)
[Improve detection of CPU features](release/1.19.0-notes.html#improve-detection-of-cpu-features)
[Changes](release/1.19.0-notes.html#changes)
[1.18.5](release/1.18.5-notes.html)
[1.18.4](release/1.18.4-notes.html)
[1.18.3](release/1.18.3-notes.html)
[1.18.2](release/1.18.2-notes.html)
[1.18.1](release/1.18.1-notes.html)
[1.18.0](release/1.18.0-notes.html)[Highlights](release/1.18.0-notes.html#highlights)
[New functions](release/1.18.0-notes.html#new-functions)
[Deprecations](release/1.18.0-notes.html#deprecations)
[Expired deprecations](release/1.18.0-notes.html#expired-deprecations)
[Compatibility notes](release/1.18.0-notes.html#compatibility-notes)`numpy.lib.recfunctions.drop_fields`
can no longer return None
`numpy.argmin/argmax/min/max`
returns`NaT`
if it exists in array
`np.can_cast(np.uint64, np.timedelta64, casting='safe')`
is now`False`
[Changed random variate stream from](release/1.18.0-notes.html#changed-random-variate-stream-from-numpy-random-generator-integers)`numpy.random.Generator.integers`
[Add more ufunc loops for](release/1.18.0-notes.html#add-more-ufunc-loops-for-datetime64-timedelta64)`datetime64`
,`timedelta64`
[Moved modules in](release/1.18.0-notes.html#moved-modules-in-numpy-random)`numpy.random`
[C API changes](release/1.18.0-notes.html#c-api-changes)
[New Features](release/1.18.0-notes.html#new-features)
[Improvements](release/1.18.0-notes.html#improvements)[Different C numeric types of the same size have unique names](release/1.18.0-notes.html#different-c-numeric-types-of-the-same-size-have-unique-names)
`argwhere`
now produces a consistent result on 0d arrays
[Add](release/1.18.0-notes.html#add-axis-argument-for-random-permutation-and-random-shuffle)`axis`
argument for`random.permutation`
and`random.shuffle`
`method`
keyword argument for`np.random.multivariate_normal`
[Add complex number support for](release/1.18.0-notes.html#add-complex-number-support-for-numpy-fromstring)`numpy.fromstring`
`numpy.unique`
has consistent axes order when`axis`
is not None
`numpy.matmul`
with boolean output now converts to boolean values
`numpy.random.randint`
produced incorrect value when the range was`2**32`
[Add complex number support for](release/1.18.0-notes.html#add-complex-number-support-for-numpy-fromfile)`numpy.fromfile`
`std=c99`
added if compiler is named`gcc`
[Changes](release/1.18.0-notes.html#changes)`NaT`
now sorts to the end of arrays
[Incorrect](release/1.18.0-notes.html#incorrect-threshold-in-np-set-printoptions-raises-typeerror-or-valueerror)`threshold`
in`np.set_printoptions`
raises`TypeError`
or`ValueError`
[Warn when saving a dtype with metadata](release/1.18.0-notes.html#warn-when-saving-a-dtype-with-metadata)
`numpy.distutils`
append behavior changed for LDFLAGS and similar
[Remove](release/1.18.0-notes.html#remove-numpy-random-entropy-without-a-deprecation)`numpy.random.entropy`
without a deprecation
[Add options to quiet build configuration and build with](release/1.18.0-notes.html#add-options-to-quiet-build-configuration-and-build-with-werror)`-Werror`
[1.17.5](release/1.17.5-notes.html)
[1.17.4](release/1.17.4-notes.html)
[1.17.3](release/1.17.3-notes.html)
[1.17.2](release/1.17.2-notes.html)
[1.17.1](release/1.17.1-notes.html)
[1.17.0](release/1.17.0-notes.html)[Highlights](release/1.17.0-notes.html#highlights)
[New functions](release/1.17.0-notes.html#new-functions)
[Deprecations](release/1.17.0-notes.html#deprecations)
[Future Changes](release/1.17.0-notes.html#future-changes)
[Compatibility notes](release/1.17.0-notes.html#compatibility-notes)`float16`
subnormal rounding
[Signed zero when using divmod](release/1.17.0-notes.html#signed-zero-when-using-divmod)
`MaskedArray.mask`
now returns a view of the mask, not the mask itself
[Do not lookup](release/1.17.0-notes.html#do-not-lookup-buffer-attribute-in-numpy-frombuffer)`__buffer__`
attribute in`numpy.frombuffer`
`out`
is buffered for memory overlaps in`take`
,`choose`
,`put`
[Unpickling while loading requires explicit opt-in](release/1.17.0-notes.html#unpickling-while-loading-requires-explicit-opt-in)
[Potential changes to the random stream in old random module](release/1.17.0-notes.html#potential-changes-to-the-random-stream-in-old-random-module)
`i0`
now always returns a result with the same shape as the input
`can_cast`
no longer assumes all unsafe casting is allowed
`ndarray.flags.writeable`
can be switched to true slightly more often
[C API changes](release/1.17.0-notes.html#c-api-changes)
[New Features](release/1.17.0-notes.html#new-features)[New extensible](release/1.17.0-notes.html#new-extensible-numpy-random-module-with-selectable-random-number-generators)`numpy.random`
module with selectable random number generators
[libFLAME](release/1.17.0-notes.html#libflame)
[User-defined BLAS detection order](release/1.17.0-notes.html#user-defined-blas-detection-order)
[User-defined LAPACK detection order](release/1.17.0-notes.html#user-defined-lapack-detection-order)
`ufunc.reduce`
and related functions now accept a`where`
mask
[Timsort and radix sort have replaced mergesort for stable sorting](release/1.17.0-notes.html#timsort-and-radix-sort-have-replaced-mergesort-for-stable-sorting)
`packbits`
and`unpackbits`
accept an`order`
keyword
`unpackbits`
now accepts a`count`
parameter
`linalg.svd`
and`linalg.pinv`
can be faster on hermitian inputs
[divmod operation is now supported for two](release/1.17.0-notes.html#divmod-operation-is-now-supported-for-two-timedelta64-operands)`timedelta64`
operands
`fromfile`
now takes an`offset`
argument
[New mode “empty” for](release/1.17.0-notes.html#new-mode-empty-for-pad)`pad`
`empty_like`
and related functions now accept a`shape`
argument
[Floating point scalars implement](release/1.17.0-notes.html#floating-point-scalars-implement-as-integer-ratio-to-match-the-builtin-float)`as_integer_ratio`
to match the builtin float
[Structured](release/1.17.0-notes.html#structured-dtype-objects-can-be-indexed-with-multiple-fields-names)`dtype`
objects can be indexed with multiple fields names
`.npy`
files support unicode field names
[Improvements](release/1.17.0-notes.html#improvements)[Array comparison assertions include maximum differences](release/1.17.0-notes.html#array-comparison-assertions-include-maximum-differences)
[Replacement of the fftpack based](release/1.17.0-notes.html#replacement-of-the-fftpack-based-fft-module-by-the-pocketfft-library)`fft`
module by the pocketfft library
[Further improvements to](release/1.17.0-notes.html#further-improvements-to-ctypes-support-in-numpy-ctypeslib)`ctypes`
support in`numpy.ctypeslib`
`numpy.errstate`
is now also a function decorator
`numpy.exp`
and`numpy.log`
speed up for float32 implementation
[Improve performance of](release/1.17.0-notes.html#improve-performance-of-numpy-pad)`numpy.pad`
`numpy.interp`
handles infinities more robustly
[Pathlib support for](release/1.17.0-notes.html#pathlib-support-for-fromfile-tofile-and-ndarray-dump)`fromfile`
,*tofile*and`ndarray.dump`
[Specialized](release/1.17.0-notes.html#specialized-isnan-isinf-and-isfinite-ufuncs-for-bool-and-int-types)`isnan`
,`isinf`
, and`isfinite`
ufuncs for bool and int types
`isfinite`
supports`datetime64`
and`timedelta64`
types
[New keywords added to](release/1.17.0-notes.html#new-keywords-added-to-nan-to-num)`nan_to_num`
[MemoryErrors caused by allocated overly large arrays are more descriptive](release/1.17.0-notes.html#memoryerrors-caused-by-allocated-overly-large-arrays-are-more-descriptive)
`floor`
,`ceil`
, and`trunc`
now respect builtin magic methods
`quantile`
now works on*fraction.Fraction*and`decimal.Decimal`
objects
[Support of object arrays in](release/1.17.0-notes.html#support-of-object-arrays-in-matmul)`matmul`
[Changes](release/1.17.0-notes.html#changes)`median`
and`percentile`
family of functions no longer warn about`nan`
`timedelta64 % 0`
behavior adjusted to return`NaT`
[NumPy functions now always support overrides with](release/1.17.0-notes.html#numpy-functions-now-always-support-overrides-with-array-function)`__array_function__`
`lib.recfunctions.structured_to_unstructured`
does not squeeze single-field views
`clip`
now uses a ufunc under the hood
`__array_interface__`
offset now works as documented
[Pickle protocol in](release/1.17.0-notes.html#pickle-protocol-in-savez-set-to-3-for-force-zip64-flag)`savez`
set to 3 for`force zip64`
flag
[Structured arrays indexed with non-existent fields raise](release/1.17.0-notes.html#structured-arrays-indexed-with-non-existent-fields-raise-keyerror-not-valueerror)`KeyError`
not`ValueError`
[1.16.6](release/1.16.6-notes.html)
[1.16.5](release/1.16.5-notes.html)
[1.16.4](release/1.16.4-notes.html)
[1.16.3](release/1.16.3-notes.html)
[1.16.2](release/1.16.2-notes.html)
[1.16.1](release/1.16.1-notes.html)[Contributors](release/1.16.1-notes.html#contributors)
[Enhancements](release/1.16.1-notes.html#enhancements)
[Compatibility notes](release/1.16.1-notes.html#compatibility-notes)
[New Features](release/1.16.1-notes.html#new-features)
[Improvements](release/1.16.1-notes.html#improvements)
[Changes](release/1.16.1-notes.html#changes)
[1.16.0](release/1.16.0-notes.html)[Highlights](release/1.16.0-notes.html#highlights)
[New functions](release/1.16.0-notes.html#new-functions)
[New deprecations](release/1.16.0-notes.html#new-deprecations)
[Expired deprecations](release/1.16.0-notes.html#expired-deprecations)
[Future changes](release/1.16.0-notes.html#future-changes)
[Compatibility notes](release/1.16.0-notes.html#compatibility-notes)
[C API changes](release/1.16.0-notes.html#c-api-changes)
[New Features](release/1.16.0-notes.html#new-features)
[Improvements](release/1.16.0-notes.html#improvements)[no-copy pickling of numpy arrays](release/1.16.0-notes.html#no-copy-pickling-of-numpy-arrays)
[build shell independence](release/1.16.0-notes.html#build-shell-independence)
*np.polynomial.Polynomial*classes render in LaTeX in Jupyter notebooks
`randint`
and`choice`
now work on empty distributions
`linalg.lstsq`
,`linalg.qr`
, and`linalg.svd`
now work with empty arrays
[Chain exceptions to give better error messages for invalid PEP3118 format strings](release/1.16.0-notes.html#chain-exceptions-to-give-better-error-messages-for-invalid-pep3118-format-strings)
[Einsum optimization path updates and efficiency improvements](release/1.16.0-notes.html#einsum-optimization-path-updates-and-efficiency-improvements)
`numpy.angle`
and`numpy.expand_dims`
now work on`ndarray`
subclasses
`NPY_NO_DEPRECATED_API`
compiler warning suppression
`np.diff`
Added kwargs prepend and append
[ARM support updated](release/1.16.0-notes.html#arm-support-updated)
[Appending to build flags](release/1.16.0-notes.html#appending-to-build-flags)
[Generalized ufunc signatures now allow fixed-size dimensions](release/1.16.0-notes.html#generalized-ufunc-signatures-now-allow-fixed-size-dimensions)
[Generalized ufunc signatures now allow flexible dimensions](release/1.16.0-notes.html#generalized-ufunc-signatures-now-allow-flexible-dimensions)
`np.clip`
and the`clip`
method check for memory overlap
[New value](release/1.16.0-notes.html#new-value-unscaled-for-option-cov-in-np-polyfit)`unscaled`
for option`cov`
in`np.polyfit`
[Detailed docstrings for scalar numeric types](release/1.16.0-notes.html#detailed-docstrings-for-scalar-numeric-types)
`__module__`
attribute now points to public modules
[Large allocations marked as suitable for transparent hugepages](release/1.16.0-notes.html#large-allocations-marked-as-suitable-for-transparent-hugepages)
[Alpine Linux (and other musl c library distros) support](release/1.16.0-notes.html#alpine-linux-and-other-musl-c-library-distros-support)
[Speedup](release/1.16.0-notes.html#speedup-np-block-for-large-arrays)`np.block`
for large arrays
[Speedup](release/1.16.0-notes.html#speedup-np-take-for-read-only-arrays)`np.take`
for read-only arrays
[Support path-like objects for more functions](release/1.16.0-notes.html#support-path-like-objects-for-more-functions)
[Better behaviour of ufunc identities during reductions](release/1.16.0-notes.html#better-behaviour-of-ufunc-identities-during-reductions)
[Improved conversion from ctypes objects](release/1.16.0-notes.html#improved-conversion-from-ctypes-objects)
[A new](release/1.16.0-notes.html#a-new-ndpointer-contents-member)`ndpointer.contents`
member
`matmul`
is now a`ufunc`
[Start and stop arrays for](release/1.16.0-notes.html#start-and-stop-arrays-for-linspace-logspace-and-geomspace)`linspace`
,`logspace`
and`geomspace`
[CI extended with additional services](release/1.16.0-notes.html#ci-extended-with-additional-services)
[Changes](release/1.16.0-notes.html#changes)[Comparison ufuncs will now error rather than return NotImplemented](release/1.16.0-notes.html#comparison-ufuncs-will-now-error-rather-than-return-notimplemented)
[Positive will now raise a deprecation warning for non-numerical arrays](release/1.16.0-notes.html#positive-will-now-raise-a-deprecation-warning-for-non-numerical-arrays)
`NDArrayOperatorsMixin`
now implements matrix multiplication
[The scaling of the covariance matrix in](release/1.16.0-notes.html#the-scaling-of-the-covariance-matrix-in-np-polyfit-is-different)`np.polyfit`
is different
`maximum`
and`minimum`
no longer emit warnings
[Umath and multiarray c-extension modules merged into a single module](release/1.16.0-notes.html#umath-and-multiarray-c-extension-modules-merged-into-a-single-module)
`getfield`
validity checks extended
[NumPy functions now support overrides with](release/1.16.0-notes.html#numpy-functions-now-support-overrides-with-array-function)`__array_function__`
[Arrays based off readonly buffers cannot be set](release/1.16.0-notes.html#arrays-based-off-readonly-buffers-cannot-be-set-writeable)`writeable`
[1.15.4](release/1.15.4-notes.html)
[1.15.3](release/1.15.3-notes.html)
[1.15.2](release/1.15.2-notes.html)
[1.15.1](release/1.15.1-notes.html)
[1.15.0](release/1.15.0-notes.html)[Highlights](release/1.15.0-notes.html#highlights)
[New functions](release/1.15.0-notes.html#new-functions)
[Deprecations](release/1.15.0-notes.html#deprecations)
[Future Changes](release/1.15.0-notes.html#future-changes)
[Compatibility notes](release/1.15.0-notes.html#compatibility-notes)[Compiled testing modules renamed and made private](release/1.15.0-notes.html#compiled-testing-modules-renamed-and-made-private)
[The](release/1.15.0-notes.html#the-npzfile-returned-by-np-savez-is-now-a-collections-abc-mapping)`NpzFile`
returned by`np.savez`
is now a`collections.abc.Mapping`
[Under certain conditions,](release/1.15.0-notes.html#under-certain-conditions-nditer-must-be-used-in-a-context-manager)`nditer`
must be used in a context manager
[Numpy has switched to using pytest instead of nose for testing](release/1.15.0-notes.html#numpy-has-switched-to-using-pytest-instead-of-nose-for-testing)
[Numpy no longer monkey-patches](release/1.15.0-notes.html#numpy-no-longer-monkey-patches-ctypes-with-array-interface)`ctypes`
with`__array_interface__`
`np.ma.notmasked_contiguous`
and`np.ma.flatnotmasked_contiguous`
always return lists
`np.squeeze`
restores old behavior of objects that cannot handle an`axis`
argument
[unstructured void array’s](release/1.15.0-notes.html#unstructured-void-array-s-item-method-now-returns-a-bytes-object)`.item`
method now returns a bytes object
`copy.copy`
and`copy.deepcopy`
no longer turn`masked`
into an array
[Multifield Indexing of Structured Arrays will still return a copy](release/1.15.0-notes.html#multifield-indexing-of-structured-arrays-will-still-return-a-copy)
[C API changes](release/1.15.0-notes.html#c-api-changes)
[New Features](release/1.15.0-notes.html#new-features)
[Improvements](release/1.15.0-notes.html#improvements)`np.einsum`
updates
`np.ufunc.reduce`
and related functions now accept an initial value
`np.flip`
can operate over multiple axes
`histogram`
and`histogramdd`
functions have moved to`np.lib.histograms`
`histogram`
will accept NaN values when explicit bins are given
`histogram`
works on datetime types, when explicit bin edges are given
`histogram`
“auto” estimator handles limited variance better
[The edges returned by](release/1.15.0-notes.html#the-edges-returned-by-histogram-and-histogramdd-now-match-the-data-float-type)*histogram`*and`histogramdd`
now match the data float type
`histogramdd`
allows explicit ranges to be given in a subset of axes
[The normed arguments of](release/1.15.0-notes.html#the-normed-arguments-of-histogramdd-and-histogram2d-have-been-renamed)`histogramdd`
and`histogram2d`
have been renamed
`np.r_`
works with 0d arrays, and`np.ma.mr_`
works with`np.ma.masked`
`np.ptp`
accepts a`keepdims`
argument, and extended axis tuples
`MaskedArray.astype`
now is identical to`ndarray.astype`
[Enable AVX2/AVX512 at compile time](release/1.15.0-notes.html#enable-avx2-avx512-at-compile-time)
`nan_to_num`
always returns scalars when receiving scalar or 0d inputs
`np.flatnonzero`
works on numpy-convertible types
`np.interp`
returns numpy scalars rather than builtin scalars
[Allow dtype field names to be unicode in Python 2](release/1.15.0-notes.html#allow-dtype-field-names-to-be-unicode-in-python-2)
[Comparison ufuncs accept](release/1.15.0-notes.html#comparison-ufuncs-accept-dtype-object-overriding-the-default-bool)`dtype=object`
, overriding the default`bool`
`sort`
functions accept`kind='stable'`
[Do not make temporary copies for in-place accumulation](release/1.15.0-notes.html#do-not-make-temporary-copies-for-in-place-accumulation)
`linalg.matrix_power`
can now handle stacks of matrices
[Increased performance in](release/1.15.0-notes.html#increased-performance-in-random-permutation-for-multidimensional-arrays)`random.permutation`
for multidimensional arrays
[Generalized ufuncs now accept](release/1.15.0-notes.html#generalized-ufuncs-now-accept-axes-axis-and-keepdims-arguments)`axes`
,`axis`
and`keepdims`
arguments
[float128 values now print correctly on ppc systems](release/1.15.0-notes.html#float128-values-now-print-correctly-on-ppc-systems)
[New](release/1.15.0-notes.html#new-np-take-along-axis-and-np-put-along-axis-functions)`np.take_along_axis`
and`np.put_along_axis`
functions
[1.14.6](release/1.14.6-notes.html)
[1.14.5](release/1.14.5-notes.html)
[1.14.4](release/1.14.4-notes.html)
[1.14.3](release/1.14.3-notes.html)
[1.14.2](release/1.14.2-notes.html)
[1.14.1](release/1.14.1-notes.html)
[1.14.0](release/1.14.0-notes.html)[Highlights](release/1.14.0-notes.html#highlights)
[New functions](release/1.14.0-notes.html#new-functions)
[Deprecations](release/1.14.0-notes.html#deprecations)
[Future Changes](release/1.14.0-notes.html#future-changes)
[Compatibility notes](release/1.14.0-notes.html#compatibility-notes)[The mask of a masked array view is also a view rather than a copy](release/1.14.0-notes.html#the-mask-of-a-masked-array-view-is-also-a-view-rather-than-a-copy)
`np.ma.masked`
is no longer writeable
`np.ma`
functions producing`fill_value`
s have changed
`a.flat.__array__()`
returns non-writeable arrays when`a`
is non-contiguous
`np.tensordot`
now returns zero array when contracting over 0-length dimension
`numpy.testing`
reorganized
`np.asfarray`
no longer accepts non-dtypes through the`dtype`
argument
[1D](release/1.14.0-notes.html#d-np-linalg-norm-preserves-float-input-types-even-for-arbitrary-orders)`np.linalg.norm`
preserves float input types, even for arbitrary orders
`count_nonzero(arr, axis=())`
now counts over no axes, not all axes
`__init__.py`
files added to test directories
`.astype(bool)`
on unstructured void arrays now calls`bool`
on each element
`MaskedArray.squeeze`
never returns`np.ma.masked`
[Renamed first parameter of](release/1.14.0-notes.html#renamed-first-parameter-of-can-cast-from-from-to-from)`can_cast`
from`from`
to`from_`
`isnat`
raises`TypeError`
when passed wrong type
`dtype.__getitem__`
raises`TypeError`
when passed wrong type
[User-defined types now need to implement](release/1.14.0-notes.html#user-defined-types-now-need-to-implement-str-and-repr)`__str__`
and`__repr__`
[Many changes to array printing, disableable with the new “legacy” printing mode](release/1.14.0-notes.html#many-changes-to-array-printing-disableable-with-the-new-legacy-printing-mode)
[C API changes](release/1.14.0-notes.html#c-api-changes)
[New Features](release/1.14.0-notes.html#new-features)[Encoding argument for text IO functions](release/1.14.0-notes.html#encoding-argument-for-text-io-functions)
[External](release/1.14.0-notes.html#external-nose-plugins-are-usable-by-numpy-testing-tester)`nose`
plugins are usable by`numpy.testing.Tester`
`parametrize`
decorator added to`numpy.testing`
`chebinterpolate`
function added to`numpy.polynomial.chebyshev`
[Support for reading lzma compressed text files in Python 3](release/1.14.0-notes.html#support-for-reading-lzma-compressed-text-files-in-python-3)
`sign`
option added to`np.setprintoptions`
and`np.array2string`
`hermitian`
option added to``np.linalg.matrix_rank``
`threshold`
and`edgeitems`
options added to`np.array2string`
`concatenate`
and`stack`
gained an`out`
argument
[Support for PGI flang compiler on Windows](release/1.14.0-notes.html#support-for-pgi-flang-compiler-on-windows)
[Improvements](release/1.14.0-notes.html#improvements)[Numerator degrees of freedom in](release/1.14.0-notes.html#numerator-degrees-of-freedom-in-random-noncentral-f-need-only-be-positive)`random.noncentral_f`
need only be positive.
[The GIL is released for all](release/1.14.0-notes.html#the-gil-is-released-for-all-np-einsum-variations)`np.einsum`
variations
[The](release/1.14.0-notes.html#the-np-einsum-function-will-use-blas-when-possible-and-optimize-by-default)*np.einsum*function will use BLAS when possible and optimize by default
`f2py`
now handles arrays of dimension 0
`numpy.distutils`
supports using MSVC and mingw64-gfortran together
`np.linalg.pinv`
now works on stacked matrices
`numpy.save`
aligns data to 64 bytes instead of 16
[NPZ files now can be written without using temporary files](release/1.14.0-notes.html#npz-files-now-can-be-written-without-using-temporary-files)
[Better support for empty structured and string types](release/1.14.0-notes.html#better-support-for-empty-structured-and-string-types)
[Support for](release/1.14.0-notes.html#support-for-decimal-decimal-in-np-lib-financial)`decimal.Decimal`
in`np.lib.financial`
[Float printing now uses “dragon4” algorithm for shortest decimal representation](release/1.14.0-notes.html#float-printing-now-uses-dragon4-algorithm-for-shortest-decimal-representation)
`void`
datatype elements are now printed in hex notation
[printing style for](release/1.14.0-notes.html#printing-style-for-void-datatypes-is-now-independently-customizable)`void`
datatypes is now independently customizable
[Reduced memory usage of](release/1.14.0-notes.html#reduced-memory-usage-of-np-loadtxt)`np.loadtxt`
[Changes](release/1.14.0-notes.html#changes)[Multiple-field indexing/assignment of structured arrays](release/1.14.0-notes.html#multiple-field-indexing-assignment-of-structured-arrays)
[Integer and Void scalars are now unaffected by](release/1.14.0-notes.html#integer-and-void-scalars-are-now-unaffected-by-np-set-string-function)`np.set_string_function`
[0d array printing changed,](release/1.14.0-notes.html#d-array-printing-changed-style-arg-of-array2string-deprecated)`style`
arg of array2string deprecated
[Seeding](release/1.14.0-notes.html#seeding-randomstate-using-an-array-requires-a-1-d-array)`RandomState`
using an array requires a 1-d array
`MaskedArray`
objects show a more useful`repr`
[The](release/1.14.0-notes.html#the-repr-of-np-polynomial-classes-is-more-explicit)`repr`
of`np.polynomial`
classes is more explicit
[1.13.3](release/1.13.3-notes.html)
[1.13.2](release/1.13.2-notes.html)
[1.13.1](release/1.13.1-notes.html)
[1.13.0](release/1.13.0-notes.html)[Highlights](release/1.13.0-notes.html#highlights)
[New functions](release/1.13.0-notes.html#new-functions)
[Deprecations](release/1.13.0-notes.html#deprecations)
[Future Changes](release/1.13.0-notes.html#future-changes)
[Build System Changes](release/1.13.0-notes.html#build-system-changes)
[Compatibility notes](release/1.13.0-notes.html#compatibility-notes)
[C API changes](release/1.13.0-notes.html#c-api-changes)
[New Features](release/1.13.0-notes.html#new-features)`__array_ufunc__`
added
[New](release/1.13.0-notes.html#new-positive-ufunc)`positive`
ufunc
[New](release/1.13.0-notes.html#new-divmod-ufunc)`divmod`
ufunc
`np.isnat`
ufunc tests for NaT special datetime and timedelta values
`np.heaviside`
ufunc computes the Heaviside function
`np.block`
function for creating blocked arrays
`isin`
function, improving on`in1d`
[Temporary elision](release/1.13.0-notes.html#temporary-elision)
`axes`
argument for`unique`
`np.gradient`
now supports unevenly spaced data
[Support for returning arrays of arbitrary dimensions in](release/1.13.0-notes.html#support-for-returning-arrays-of-arbitrary-dimensions-in-apply-along-axis)`apply_along_axis`
`.ndim`
property added to`dtype`
to complement`.shape`
[Support for tracemalloc in Python 3.6](release/1.13.0-notes.html#support-for-tracemalloc-in-python-3-6)
[NumPy may be built with relaxed stride checking debugging](release/1.13.0-notes.html#numpy-may-be-built-with-relaxed-stride-checking-debugging)
[Improvements](release/1.13.0-notes.html#improvements)[Ufunc behavior for overlapping inputs](release/1.13.0-notes.html#ufunc-behavior-for-overlapping-inputs)
[Partial support for 64-bit f2py extensions with MinGW](release/1.13.0-notes.html#partial-support-for-64-bit-f2py-extensions-with-mingw)
[Performance improvements for](release/1.13.0-notes.html#performance-improvements-for-packbits-and-unpackbits)`packbits`
and`unpackbits`
[Fix for PPC long double floating point information](release/1.13.0-notes.html#fix-for-ppc-long-double-floating-point-information)
[Better default repr for](release/1.13.0-notes.html#better-default-repr-for-ndarray-subclasses)`ndarray`
subclasses
[More reliable comparisons of masked arrays](release/1.13.0-notes.html#more-reliable-comparisons-of-masked-arrays)
[np.matrix with booleans elements can now be created using the string syntax](release/1.13.0-notes.html#np-matrix-with-booleans-elements-can-now-be-created-using-the-string-syntax)
[More](release/1.13.0-notes.html#more-linalg-operations-now-accept-empty-vectors-and-matrices)`linalg`
operations now accept empty vectors and matrices
[Bundled version of LAPACK is now 3.2.2](release/1.13.0-notes.html#bundled-version-of-lapack-is-now-3-2-2)
`reduce`
of`np.hypot.reduce`
and`np.logical_xor`
allowed in more cases
[Better](release/1.13.0-notes.html#better-repr-of-object-arrays)`repr`
of object arrays
[Changes](release/1.13.0-notes.html#changes)`argsort`
on masked arrays takes the same default arguments as`sort`
`average`
now preserves subclasses
`array == None`
and`array != None`
do element-wise comparison
`np.equal, np.not_equal`
for object arrays ignores object identity
[Boolean indexing changes](release/1.13.0-notes.html#boolean-indexing-changes)
`np.random.multivariate_normal`
behavior with bad covariance matrix
`assert_array_less`
compares`np.inf`
and`-np.inf`
now
`assert_array_`
and masked arrays`assert_equal`
hide less warnings
`offset`
attribute value in`memmap`
objects
`np.real`
and`np.imag`
return scalars for scalar inputs
[The polynomial convenience classes cannot be passed to ufuncs](release/1.13.0-notes.html#the-polynomial-convenience-classes-cannot-be-passed-to-ufuncs)
[Output arguments to ufuncs can be tuples also for ufunc methods](release/1.13.0-notes.html#output-arguments-to-ufuncs-can-be-tuples-also-for-ufunc-methods)
[1.12.1](release/1.12.1-notes.html)
[1.12.0](release/1.12.0-notes.html)[Highlights](release/1.12.0-notes.html#highlights)
[Dropped Support](release/1.12.0-notes.html#dropped-support)
[Added Support](release/1.12.0-notes.html#added-support)
[Build System Changes](release/1.12.0-notes.html#build-system-changes)
[Deprecations](release/1.12.0-notes.html#deprecations)
[Future Changes](release/1.12.0-notes.html#future-changes)
[Compatibility notes](release/1.12.0-notes.html#compatibility-notes)[DeprecationWarning to error](release/1.12.0-notes.html#deprecationwarning-to-error)
[FutureWarning to changed behavior](release/1.12.0-notes.html#futurewarning-to-changed-behavior)
`power`
and`**`
raise errors for integer to negative integer powers
[Relaxed stride checking is the default](release/1.12.0-notes.html#relaxed-stride-checking-is-the-default)
[The](release/1.12.0-notes.html#the-np-percentile-midpoint-interpolation-method-fixed-for-exact-indices)`np.percentile`
‘midpoint’ interpolation method fixed for exact indices
`keepdims`
kwarg is passed through to user-class methods
`bitwise_and`
identity changed
[ma.median warns and returns nan when unmasked invalid values are encountered](release/1.12.0-notes.html#ma-median-warns-and-returns-nan-when-unmasked-invalid-values-are-encountered)
[Greater consistency in](release/1.12.0-notes.html#greater-consistency-in-assert-almost-equal)`assert_almost_equal`
`NoseTester`
behaviour of warnings during testing
`assert_warns`
and`deprecated`
decorator more specific
[C API](release/1.12.0-notes.html#c-api)
[New Features](release/1.12.0-notes.html#new-features)[Writeable keyword argument for](release/1.12.0-notes.html#writeable-keyword-argument-for-as-strided)`as_strided`
`axes`
keyword argument for`rot90`
[Generalized](release/1.12.0-notes.html#generalized-flip)`flip`
[BLIS support in](release/1.12.0-notes.html#blis-support-in-numpy-distutils)`numpy.distutils`
[Hook in](release/1.12.0-notes.html#hook-in-numpy-init-py-to-run-distribution-specific-checks)`numpy/__init__.py`
to run distribution-specific checks
[New nanfunctions](release/1.12.0-notes.html#new-nanfunctions-nancumsum-and-nancumprod-added)`nancumsum`
and`nancumprod`
added
`np.interp`
can now interpolate complex values
[New polynomial evaluation function](release/1.12.0-notes.html#new-polynomial-evaluation-function-polyvalfromroots-added)`polyvalfromroots`
added
[New array creation function](release/1.12.0-notes.html#new-array-creation-function-geomspace-added)`geomspace`
added
[New context manager for testing warnings](release/1.12.0-notes.html#new-context-manager-for-testing-warnings)
[New masked array functions](release/1.12.0-notes.html#new-masked-array-functions-ma-convolve-and-ma-correlate-added)`ma.convolve`
and`ma.correlate`
added
[New](release/1.12.0-notes.html#new-float-power-ufunc)`float_power`
ufunc
`np.loadtxt`
now supports a single integer as`usecol`
argument
[Improved automated bin estimators for](release/1.12.0-notes.html#improved-automated-bin-estimators-for-histogram)`histogram`
`np.roll`
can now roll multiple axes at the same time
[The](release/1.12.0-notes.html#the-complex-method-has-been-implemented-for-the-ndarrays)`__complex__`
method has been implemented for the ndarrays
`pathlib.Path`
objects now supported
[New](release/1.12.0-notes.html#new-bits-attribute-for-np-finfo)`bits`
attribute for`np.finfo`
[New](release/1.12.0-notes.html#new-signature-argument-to-np-vectorize)`signature`
argument to`np.vectorize`
[Emit py3kwarnings for division of integer arrays](release/1.12.0-notes.html#emit-py3kwarnings-for-division-of-integer-arrays)
[numpy.sctypes now includes bytes on Python3 too](release/1.12.0-notes.html#numpy-sctypes-now-includes-bytes-on-python3-too)
[Improvements](release/1.12.0-notes.html#improvements)`bitwise_and`
identity changed
[Generalized Ufuncs will now unlock the GIL](release/1.12.0-notes.html#generalized-ufuncs-will-now-unlock-the-gil)
[Caches in](release/1.12.0-notes.html#caches-in-np-fft-are-now-bounded-in-total-size-and-item-count)*np.fft*are now bounded in total size and item count
[Improved handling of zero-width string/unicode dtypes](release/1.12.0-notes.html#improved-handling-of-zero-width-string-unicode-dtypes)
[Integer ufuncs vectorized with AVX2](release/1.12.0-notes.html#integer-ufuncs-vectorized-with-avx2)
[Order of operations optimization in](release/1.12.0-notes.html#order-of-operations-optimization-in-np-einsum)`np.einsum`
[quicksort has been changed to an introsort](release/1.12.0-notes.html#quicksort-has-been-changed-to-an-introsort)
`ediff1d`
improved performance and subclass handling
[Improved precision of](release/1.12.0-notes.html#improved-precision-of-ndarray-mean-for-float16-arrays)`ndarray.mean`
for float16 arrays
[Changes](release/1.12.0-notes.html#changes)
[1.11.3](release/1.11.3-notes.html)
[1.11.2](release/1.11.2-notes.html)
[1.11.1](release/1.11.1-notes.html)
[1.11.0](release/1.11.0-notes.html)[Highlights](release/1.11.0-notes.html#highlights)
[Build System Changes](release/1.11.0-notes.html#build-system-changes)
[Future Changes](release/1.11.0-notes.html#future-changes)
[Compatibility notes](release/1.11.0-notes.html#compatibility-notes)
[New Features](release/1.11.0-notes.html#new-features)
[Improvements](release/1.11.0-notes.html#improvements)`np.gradient`
now supports an`axis`
argument
`np.lexsort`
now supports arrays with object data-type
`np.ma.core.MaskedArray`
now supports an`order`
argument
[Memory and speed improvements for masked arrays](release/1.11.0-notes.html#memory-and-speed-improvements-for-masked-arrays)
`ndarray.tofile`
now uses fallocate on linux
[Optimizations for operations of the form](release/1.11.0-notes.html#optimizations-for-operations-of-the-form-a-t-a-and-a-a-t)`A.T @ A`
and`A @ A.T`
`np.testing.assert_warns`
can now be used as a context manager
[Speed improvement for np.random.shuffle](release/1.11.0-notes.html#speed-improvement-for-np-random-shuffle)
[Changes](release/1.11.0-notes.html#changes)
[Deprecations](release/1.11.0-notes.html#deprecations)
[FutureWarnings](release/1.11.0-notes.html#futurewarnings)
[1.10.4](release/1.10.4-notes.html)
[1.10.3](release/1.10.3-notes.html)
[1.10.2](release/1.10.2-notes.html)
[1.10.1](release/1.10.1-notes.html)
[1.10.0](release/1.10.0-notes.html)[Highlights](release/1.10.0-notes.html#highlights)
[Dropped Support](release/1.10.0-notes.html#dropped-support)
[Future Changes](release/1.10.0-notes.html#future-changes)
[Compatibility notes](release/1.10.0-notes.html#compatibility-notes)[Default casting rule change](release/1.10.0-notes.html#default-casting-rule-change)
[numpy version string](release/1.10.0-notes.html#numpy-version-string)
[relaxed stride checking](release/1.10.0-notes.html#relaxed-stride-checking)
[Concatenation of 1d arrays along any but](release/1.10.0-notes.html#concatenation-of-1d-arrays-along-any-but-axis-0-raises-indexerror)`axis=0`
raises`IndexError`
*np.ravel*,*np.diagonal*and*np.diag*now preserve subtypes
*rollaxis*and*swapaxes*always return a view
*nonzero*now returns base ndarrays
[C API](release/1.10.0-notes.html#c-api)
[recarray field return types](release/1.10.0-notes.html#recarray-field-return-types)
[recarray views](release/1.10.0-notes.html#recarray-views)
[‘out’ keyword argument of ufuncs now accepts tuples of arrays](release/1.10.0-notes.html#out-keyword-argument-of-ufuncs-now-accepts-tuples-of-arrays)
[byte-array indices now raises an IndexError](release/1.10.0-notes.html#byte-array-indices-now-raises-an-indexerror)
[Masked arrays containing objects with arrays](release/1.10.0-notes.html#masked-arrays-containing-objects-with-arrays)
[Median warns and returns nan when invalid values are encountered](release/1.10.0-notes.html#median-warns-and-returns-nan-when-invalid-values-are-encountered)
[Functions available from numpy.ma.testutils have changed](release/1.10.0-notes.html#functions-available-from-numpy-ma-testutils-have-changed)
[New Features](release/1.10.0-notes.html#new-features)[Reading extra flags from site.cfg](release/1.10.0-notes.html#reading-extra-flags-from-site-cfg)
*np.cbrt*to compute cube root for real floats
[numpy.distutils now allows parallel compilation](release/1.10.0-notes.html#numpy-distutils-now-allows-parallel-compilation)
*genfromtxt*has a new`max_rows`
argument
[New function](release/1.10.0-notes.html#new-function-np-broadcast-to-for-invoking-array-broadcasting)*np.broadcast_to*for invoking array broadcasting
[New context manager](release/1.10.0-notes.html#new-context-manager-clear-and-catch-warnings-for-testing-warnings)*clear_and_catch_warnings*for testing warnings
*cov*has new`fweights`
and`aweights`
arguments
[Support for the ‘@’ operator in Python 3.5+](release/1.10.0-notes.html#support-for-the-operator-in-python-3-5)
[New argument](release/1.10.0-notes.html#new-argument-norm-to-fft-functions)`norm`
to fft functions
[Improvements](release/1.10.0-notes.html#improvements)*np.digitize*using binary search
*np.poly*now casts integer inputs to float
*np.interp*can now be used with periodic functions
*np.pad*supports more input types for`pad_width`
and`constant_values`
*np.argmax*and*np.argmin*now support an`out`
argument
[More system C99 complex functions detected and used](release/1.10.0-notes.html#more-system-c99-complex-functions-detected-and-used)
*np.loadtxt*support for the strings produced by the`float.hex`
method
*np.isclose*properly handles minimal values of integer dtypes
*np.allclose*uses*np.isclose*internally.
*np.genfromtxt*now handles large integers correctly
*np.load*,*np.save*have pickle backward compatibility flags
[MaskedArray support for more complicated base classes](release/1.10.0-notes.html#maskedarray-support-for-more-complicated-base-classes)
[Changes](release/1.10.0-notes.html#changes)
[Deprecations](release/1.10.0-notes.html#deprecations)
[1.9.2](release/1.9.2-notes.html)
[1.9.1](release/1.9.1-notes.html)
[1.9.0](release/1.9.0-notes.html)[Highlights](release/1.9.0-notes.html#highlights)
[Dropped Support](release/1.9.0-notes.html#dropped-support)
[Future Changes](release/1.9.0-notes.html#future-changes)
[Compatibility notes](release/1.9.0-notes.html#compatibility-notes)[The diagonal and diag functions return readonly views.](release/1.9.0-notes.html#the-diagonal-and-diag-functions-return-readonly-views)
[Special scalar float values don’t cause upcast to double anymore](release/1.9.0-notes.html#special-scalar-float-values-don-t-cause-upcast-to-double-anymore)
[Percentile output changes](release/1.9.0-notes.html#percentile-output-changes)
[ndarray.tofile exception type](release/1.9.0-notes.html#ndarray-tofile-exception-type)
[Invalid fill value exceptions](release/1.9.0-notes.html#invalid-fill-value-exceptions)
[Polynomial Classes no longer derived from PolyBase](release/1.9.0-notes.html#polynomial-classes-no-longer-derived-from-polybase)
[Using numpy.random.binomial may change the RNG state vs. numpy < 1.9](release/1.9.0-notes.html#using-numpy-random-binomial-may-change-the-rng-state-vs-numpy-1-9)
[Random seed enforced to be a 32 bit unsigned integer](release/1.9.0-notes.html#random-seed-enforced-to-be-a-32-bit-unsigned-integer)
[Argmin and argmax out argument](release/1.9.0-notes.html#argmin-and-argmax-out-argument)
[Einsum](release/1.9.0-notes.html#einsum)
[Indexing](release/1.9.0-notes.html#indexing)
[Non-integer reduction axis indexes are deprecated](release/1.9.0-notes.html#non-integer-reduction-axis-indexes-are-deprecated)
`promote_types`
and string dtype
`can_cast`
and string dtype
[astype and string dtype](release/1.9.0-notes.html#astype-and-string-dtype)
*npyio.recfromcsv*keyword arguments change
[The](release/1.9.0-notes.html#the-doc-swig-directory-moved)`doc/swig`
directory moved
[The](release/1.9.0-notes.html#the-npy-3kcompat-h-header-changed)`npy_3kcompat.h`
header changed
[Negative indices in C-Api](release/1.9.0-notes.html#negative-indices-in-c-api-sq-item-and-sq-ass-item-sequence-methods)`sq_item`
and`sq_ass_item`
sequence methods
[NDIter](release/1.9.0-notes.html#nditer)
`zeros_like`
for string dtypes now returns empty strings
[New Features](release/1.9.0-notes.html#new-features)[Percentile supports more interpolation options](release/1.9.0-notes.html#percentile-supports-more-interpolation-options)
[Generalized axis support for median and percentile](release/1.9.0-notes.html#generalized-axis-support-for-median-and-percentile)
[Dtype parameter added to](release/1.9.0-notes.html#dtype-parameter-added-to-np-linspace-and-np-logspace)`np.linspace`
and`np.logspace`
[More general](release/1.9.0-notes.html#more-general-np-triu-and-np-tril-broadcasting)`np.triu`
and`np.tril`
broadcasting
`tobytes`
alias for`tostring`
method
[Build system](release/1.9.0-notes.html#build-system)
[Compatibility to python](release/1.9.0-notes.html#compatibility-to-python-numbers-module)`numbers`
module
`increasing`
parameter added to`np.vander`
`unique_counts`
parameter added to`np.unique`
[Support for median and percentile in nanfunctions](release/1.9.0-notes.html#support-for-median-and-percentile-in-nanfunctions)
[NumpyVersion class added](release/1.9.0-notes.html#numpyversion-class-added)
[Allow saving arrays with large number of named columns](release/1.9.0-notes.html#allow-saving-arrays-with-large-number-of-named-columns)
[Full broadcasting support for](release/1.9.0-notes.html#full-broadcasting-support-for-np-cross)`np.cross`
[Improvements](release/1.9.0-notes.html#improvements)[Better numerical stability for sum in some cases](release/1.9.0-notes.html#better-numerical-stability-for-sum-in-some-cases)
[Percentile implemented in terms of](release/1.9.0-notes.html#percentile-implemented-in-terms-of-np-partition)`np.partition`
[Performance improvement for](release/1.9.0-notes.html#performance-improvement-for-np-array)`np.array`
[Performance improvement for](release/1.9.0-notes.html#performance-improvement-for-np-searchsorted)`np.searchsorted`
[Optional reduced verbosity for np.distutils](release/1.9.0-notes.html#optional-reduced-verbosity-for-np-distutils)
[Covariance check in](release/1.9.0-notes.html#covariance-check-in-np-random-multivariate-normal)`np.random.multivariate_normal`
[Polynomial Classes no longer template based](release/1.9.0-notes.html#polynomial-classes-no-longer-template-based)
[More GIL releases](release/1.9.0-notes.html#more-gil-releases)
[MaskedArray support for more complicated base classes](release/1.9.0-notes.html#maskedarray-support-for-more-complicated-base-classes)
[C-API](release/1.9.0-notes.html#c-api)
[Deprecations](release/1.9.0-notes.html#deprecations)
[1.8.2](release/1.8.2-notes.html)
[1.8.1](release/1.8.1-notes.html)
[1.8.0](release/1.8.0-notes.html)[Highlights](release/1.8.0-notes.html#highlights)
[Dropped Support](release/1.8.0-notes.html#dropped-support)
[Future Changes](release/1.8.0-notes.html#future-changes)
[Compatibility notes](release/1.8.0-notes.html#compatibility-notes)
[New Features](release/1.8.0-notes.html#new-features)[Support for linear algebra on stacked arrays](release/1.8.0-notes.html#support-for-linear-algebra-on-stacked-arrays)
[In place fancy indexing for ufuncs](release/1.8.0-notes.html#in-place-fancy-indexing-for-ufuncs)
[New functions](release/1.8.0-notes.html#new-functions-partition-and-argpartition)*partition*and*argpartition*
[New functions](release/1.8.0-notes.html#new-functions-nanmean-nanvar-and-nanstd)*nanmean*,*nanvar*and*nanstd*
[New functions](release/1.8.0-notes.html#new-functions-full-and-full-like)*full*and*full_like*
[IO compatibility with large files](release/1.8.0-notes.html#io-compatibility-with-large-files)
[Building against OpenBLAS](release/1.8.0-notes.html#building-against-openblas)
[New constant](release/1.8.0-notes.html#new-constant)
[New modes for qr](release/1.8.0-notes.html#new-modes-for-qr)
[New](release/1.8.0-notes.html#new-invert-argument-to-in1d)*invert*argument to*in1d*
[Advanced indexing using](release/1.8.0-notes.html#advanced-indexing-using-np-newaxis)*np.newaxis*
[C-API](release/1.8.0-notes.html#c-api)
[runtests.py](release/1.8.0-notes.html#runtests-py)
[Improvements](release/1.8.0-notes.html#improvements)
[Changes](release/1.8.0-notes.html#changes)
[Deprecations](release/1.8.0-notes.html#deprecations)
[Authors](release/1.8.0-notes.html#authors)
[1.7.2](release/1.7.2-notes.html)
[1.7.1](release/1.7.1-notes.html)
[1.7.0](release/1.7.0-notes.html)[Highlights](release/1.7.0-notes.html#highlights)
[Compatibility notes](release/1.7.0-notes.html#compatibility-notes)
[New features](release/1.7.0-notes.html#new-features)[Reduction UFuncs Generalize axis= Parameter](release/1.7.0-notes.html#reduction-ufuncs-generalize-axis-parameter)
[Reduction UFuncs New keepdims= Parameter](release/1.7.0-notes.html#reduction-ufuncs-new-keepdims-parameter)
[Datetime support](release/1.7.0-notes.html#datetime-support)
[Custom formatter for printing arrays](release/1.7.0-notes.html#custom-formatter-for-printing-arrays)
[New function numpy.random.choice](release/1.7.0-notes.html#new-function-numpy-random-choice)
[New function isclose](release/1.7.0-notes.html#new-function-isclose)
[Preliminary multi-dimensional support in the polynomial package](release/1.7.0-notes.html#preliminary-multi-dimensional-support-in-the-polynomial-package)
[Ability to pad rank-n arrays](release/1.7.0-notes.html#ability-to-pad-rank-n-arrays)
[New argument to searchsorted](release/1.7.0-notes.html#new-argument-to-searchsorted)
[Build system](release/1.7.0-notes.html#build-system)
[C API](release/1.7.0-notes.html#c-api)
[Changes](release/1.7.0-notes.html#changes)
[Deprecations](release/1.7.0-notes.html#deprecations)
[1.6.2](release/1.6.2-notes.html)
[1.6.1](release/1.6.1-notes.html)
[1.6.0](release/1.6.0-notes.html)[Highlights](release/1.6.0-notes.html#highlights)
[New features](release/1.6.0-notes.html#new-features)
[Changes](release/1.6.0-notes.html#changes)
[Deprecated features](release/1.6.0-notes.html#deprecated-features)
[Removed features](release/1.6.0-notes.html#removed-features)
[1.5.0](release/1.5.0-notes.html)
[1.4.0](release/1.4.0-notes.html)[Highlights](release/1.4.0-notes.html#highlights)
[New features](release/1.4.0-notes.html#new-features)
[Improvements](release/1.4.0-notes.html#improvements)
[Deprecations](release/1.4.0-notes.html#deprecations)
[Internal changes](release/1.4.0-notes.html#internal-changes)
[1.3.0](release/1.3.0-notes.html)[Highlights](release/1.3.0-notes.html#highlights)
[New features](release/1.3.0-notes.html#new-features)
[Deprecated features](release/1.3.0-notes.html#deprecated-features)
[Documentation changes](release/1.3.0-notes.html#documentation-changes)
[New C API](release/1.3.0-notes.html#new-c-api)
[Internal changes](release/1.3.0-notes.html#internal-changes)NumPy user guide# This guide is an overview and explains the important features; details are found in NumPy reference. Getting started What is NumPy? Installation NumPy quickstart NumPy: the absolute basics for beginners Fundamentals and usage NumPy fundamentals Array creation Indexing on ndarrays I/O with NumPy Data types Broadcasting Copies and views Structured arrays Universal functions (ufunc) basics NumPy for MATLAB users NumPy Tutorials NumPy how-tos Advanced usage and interoperability Building from source Using NumPy C-API F2PY user guide and reference manual Under-the-hood documentation for developers Interoperability with NumPy# Git configuration[#](#git-configuration)
## Overview[#](#overview)
Your personal [git](https://git-scm.com/) configurations are saved in the `.gitconfig`
file in
your home directory.
Here is an example `.gitconfig`
file:

```
[user]
name = Your Name
email = you@yourdomain.example.com
[alias]
ci = commit -a
co = checkout
st = status -a
stat = status -a
br = branch
wdiff = diff --color-words
[core]
editor = vim
[merge]
summary = true
```
You can edit this file directly or you can use the `git config --global`
command:

```
git config --global user.name "Your Name"
git config --global user.email you@yourdomain.example.com
git config --global alias.ci "commit -a"
git config --global alias.co checkout
git config --global alias.st "status -a"
git config --global alias.stat "status -a"
git config --global alias.br branch
git config --global alias.wdiff "diff --color-words"
git config --global core.editor vim
git config --global merge.summary true
```
To set up on another computer, you can copy your `~/.gitconfig`
file,
or run the commands above.

## In detail[#](#in-detail)
### user.name and user.email[#](#user-name-and-user-email)
It is good practice to tell [git](https://git-scm.com/) who you are, for labeling any changes
you make to the code. The simplest way to do this is from the command
line:

```
git config --global user.name "Your Name"
git config --global user.email you@yourdomain.example.com
```
This will write the settings into your git configuration file, which should now contain a user section with your name and email:

```
[user]
name = Your Name
email = you@yourdomain.example.com
```
Of course you’ll need to replace `Your Name`
and `you@yourdomain.example.com`
with your actual name and email address.

### Aliases[#](#aliases)
You might well benefit from some aliases to common commands.

For example, you might well want to be able to shorten `git checkout`
to `git co`
. Or you may want to alias `git diff --color-words`
(which gives a nicely formatted output of the diff) to `git wdiff`

The following `git config --global`
commands:

```
git config --global alias.ci "commit -a"
git config --global alias.co checkout
git config --global alias.st "status -a"
git config --global alias.stat "status -a"
git config --global alias.br branch
git config --global alias.wdiff "diff --color-words"
```
will create an `alias`
section in your `.gitconfig`
file with contents
like this:

```
[alias]
ci = commit -a
co = checkout
st = status -a
stat = status -a
br = branch
wdiff = diff --color-words
```
### Editor[#](#editor)
You may also want to make sure that your editor of choice is used

```
git config --global core.editor vim
```
### Merging[#](#merging)
To enforce summaries when doing merges (`~/.gitconfig`
file again):

```
[merge]
log = true
```
Or from the command line:

```
git config --global merge.log true
```# numpy.issubdtype[#](#numpy-issubdtype)
numpy.issubdtype(*arg1*,*arg2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numerictypes.py#L357-L421)[#](#numpy.issubdtype)
-
Returns True if first argument is a typecode lower/equal in type hierarchy.

This is like the builtin

, but for`issubclass`
s.`dtype`
Parameters:
-
**arg1, arg2**dtype_like
or object coercible to one`dtype`
Returns:
-
**out**bool
See also

[Scalars](../arrays.scalars.html#arrays-scalars)
Overview of the numpy type hierarchy.

,`issubsctype`
`issubclass_`
Examples

can be used to check the type of arrays:`issubdtype`
>>> ints = np.array([1, 2, 3], dtype=np.int32) >>> np.issubdtype(ints.dtype, np.integer) True >>> np.issubdtype(ints.dtype, np.floating) False
>>> floats = np.array([1, 2, 3], dtype=np.float32) >>> np.issubdtype(floats.dtype, np.integer) False >>> np.issubdtype(floats.dtype, np.floating) True
Similar types of different sizes are not subdtypes of each other:

>>> np.issubdtype(np.float64, np.float32) False >>> np.issubdtype(np.float32, np.float64) False
but both are subtypes of

:`floating`
>>> np.issubdtype(np.float64, np.floating) True >>> np.issubdtype(np.float32, np.floating) True
For convenience, dtype-like objects are allowed too:

>>> np.issubdtype('S1', np.string_) True >>> np.issubdtype('i4', np.signedinteger) TrueSearch Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Under-the-hood documentation for developers# These documents are intended as a low-level look into NumPy; focused towards developers. Internal organization of NumPy arrays NumPy C code explanations Memory alignment Byte-swapping Writing custom array containers Subclassing ndarrayIndex Symbols | _ | A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | Y | Z Symbols (n,) -1 . . . .base : < > _ __abs__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __add__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __and__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __array__() (numpy.class method) (numpy.generic method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __array_finalize__ (ndarray attribute) __array_finalize__() (numpy.class method) __array_function__() (numpy.class method) __array_interface__ (numpy.generic attribute) __array_prepare__() (numpy.class method) __array_priority__ (ndarray attribute) (numpy.class attribute) (numpy.generic attribute) (numpy.ma.MaskedArray attribute) __array_struct__ (numpy.generic attribute) __array_ufunc__() (numpy.class method) __array_wrap__ (ndarray attribute) __array_wrap__() (numpy.class method) (numpy.generic method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __bool__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __call__() (numpy.errstate method) (numpy.poly1d method) (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) (numpy.testing.suppress_warnings method) (numpy.ufunc method) (numpy.vectorize method) __class_getitem__() (numpy.dtype method) (numpy.ndarray method) (numpy.number method) __complex__() (numpy.ndarray method) __contains__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __copy__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __deepcopy__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __delitem__() (numpy.ma.MaskedArray method) __div__() (numpy.ma.MaskedArray method) __divmod__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __eq__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __float__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __floordiv__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __ge__() (numpy.dtype method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __getitem__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __getstate__() (numpy.ma.MaskedArray method) __gt__() (numpy.dtype method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __iadd__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __iand__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __idiv__() (numpy.ma.MaskedArray method) __ifloordiv__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __ilshift__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __imod__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __imul__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __int__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __invert__() (numpy.ndarray method) __ior__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __ipow__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __irshift__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __isub__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __itruediv__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __ixor__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __le__() (numpy.dtype method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __len__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __lshift__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __lt__() (numpy.dtype method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __matmul__() (numpy.ndarray method) __mod__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __mul__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __ne__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __neg__() (numpy.ndarray method) __new__() (numpy.ma.MaskedArray static method) (numpy.ndarray method) __or__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __pos__() (numpy.ndarray method) __pow__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __radd__() (numpy.ma.MaskedArray method) __rand__() (numpy.ma.MaskedArray method) __rdivmod__() (numpy.ma.MaskedArray method) __reduce__() (numpy.dtype method) (numpy.generic method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __repr__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __rfloordiv__() (numpy.ma.MaskedArray method) __rlshift__() (numpy.ma.MaskedArray method) __rmod__() (numpy.ma.MaskedArray method) __rmul__() (numpy.ma.MaskedArray method) __ror__() (numpy.ma.MaskedArray method) __rpow__() (numpy.ma.MaskedArray method) __rrshift__() (numpy.ma.MaskedArray method) __rshift__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __rsub__() (numpy.ma.MaskedArray method) __rtruediv__() (numpy.ma.MaskedArray method) __rxor__() (numpy.ma.MaskedArray method) __setitem__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __setmask__() (numpy.ma.MaskedArray method) __setstate__() (numpy.dtype method) (numpy.generic method) (numpy.ma.MaskedArray method) (numpy.ndarray method) __str__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __sub__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __truediv__() (numpy.ma.MaskedArray method) (numpy.ndarray method) __xor__() (numpy.ma.MaskedArray method) (numpy.ndarray method) A A (numpy.matrix property) A1 (numpy.matrix property) absolute (in module numpy) abspath() (numpy.DataSource method) accumulate ufunc methods accumulate() (numpy.ufunc method) add (in module numpy) add_data_dir() (numpy.distutils.misc_util.Configuration method) add_data_files() (numpy.distutils.misc_util.Configuration method) add_extension() (numpy.distutils.misc_util.Configuration method) add_headers() (numpy.distutils.misc_util.Configuration method) add_include_dirs() (numpy.distutils.misc_util.Configuration method) add_installed_library() (numpy.distutils.misc_util.Configuration method) add_library() (numpy.distutils.misc_util.Configuration method) add_npy_pkg_config() (numpy.distutils.misc_util.Configuration method) add_scripts() (numpy.distutils.misc_util.Configuration method) add_subpackage() (numpy.distutils.misc_util.Configuration method) adding new dtype, [1] ufunc, [1], [2], [3], [4] advance() (numpy.random.PCG64 method) (numpy.random.PCG64DXSM method) (numpy.random.Philox method) advanced indexing aligned alignment (numpy.dtype attribute) all() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) all_strings() (in module numpy.distutils.misc_util) allclose() (in module numpy) allpath() (in module numpy.distutils.misc_util) along an axis amax() (in module numpy) amin() (in module numpy) angle() (in module numpy) anom() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) any() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) append() (in module numpy) append_fields() (in module numpy.lib.recfunctions) appendpath() (in module numpy.distutils.misc_util) apply_along_axis() (in module numpy) apply_along_fields() (in module numpy.lib.recfunctions) apply_over_axes() (in module numpy) arange() (in module numpy) arccos (in module numpy) arccosh (in module numpy) arcsin (in module numpy) arcsinh (in module numpy) arctan (in module numpy) arctan2 (in module numpy) arctanh (in module numpy) argmax() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) argmin() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) argpartition() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) argsort() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) argwhere() (in module numpy) arithmetic, [1] around() (in module numpy) array C-API interface protocol array iterator, [1], [2], [3] array scalar array scalars array() (in module numpy) array2string() (in module numpy) array_equal() (in module numpy) array_equiv() (in module numpy) array_like array_repr() (in module numpy) array_split() (in module numpy) array_str() (in module numpy) ArrayLike (in module numpy.typing) Arrayterator (class in numpy.lib) as_array() (in module numpy.ctypeslib) as_ctypes() (in module numpy.ctypeslib) as_ctypes_type() (in module numpy.ctypeslib) as_list() (in module numpy.distutils.misc_util) asanyarray() (in module numpy) asarray() (in module numpy) asarray_chkfinite() (in module numpy) ascontiguousarray() (in module numpy) asfarray() (in module numpy) asfortranarray() (in module numpy) asmatrix() (in module numpy) assign_fields_by_name() (in module numpy.lib.recfunctions) astype() (numpy.char.chararray method) (numpy.chararray method) (numpy.lib.user_array.container method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) at() (numpy.ufunc method) atleast_1d() (in module numpy) atleast_2d() (in module numpy) atleast_3d() (in module numpy) attributes ufunc average() (in module numpy) axis, [1] B bartlett() (in module numpy) base (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.dtype attribute) (numpy.flatiter attribute) (numpy.generic attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) base_repr() (in module numpy) baseclass (numpy.ma.masked_array property) (numpy.ma.MaskedArray attribute) basis() (numpy.polynomial.chebyshev.Chebyshev class method) (numpy.polynomial.hermite.Hermite class method) (numpy.polynomial.hermite_e.HermiteE class method) (numpy.polynomial.laguerre.Laguerre class method) (numpy.polynomial.legendre.Legendre class method) (numpy.polynomial.polynomial.Polynomial class method) basis_name (numpy.polynomial.chebyshev.Chebyshev attribute) (numpy.polynomial.hermite.Hermite attribute) (numpy.polynomial.hermite_e.HermiteE attribute) (numpy.polynomial.laguerre.Laguerre attribute) (numpy.polynomial.legendre.Legendre attribute) (numpy.polynomial.polynomial.Polynomial attribute) beta() (numpy.random.Generator method) (numpy.random.RandomState method) big-endian binary_repr() (in module numpy) bincount() (in module numpy) binomial() (numpy.random.Generator method) (numpy.random.RandomState method) binomial_t (C type) bit_generator (numpy.random.Generator attribute) bitgen_t (C type) BitGenerator (class in numpy.random) bitwise_and (in module numpy) bitwise_or (in module numpy) bitwise_xor (in module numpy) blackman() (in module numpy) BLAS block() (in module numpy) blue_text() (in module numpy.distutils.misc_util) bmat() (in module numpy) bool_ (class in numpy) Boost.Python broadcast (class in numpy) broadcast_arrays() (in module numpy) broadcast_shapes() (in module numpy) broadcast_to() (in module numpy) broadcastable broadcasting, [1], [2] buffers build_and_import_extension() (in module numpy.testing.extbuild) built-in function ndpointer() busday_count() (in module numpy) busday_offset() (in module numpy) busdaycalendar (class in numpy) byte (class in numpy) byte_bounds() (in module numpy) byteorder (numpy.dtype attribute) bytes() (numpy.random.Generator method) (numpy.random.RandomState method) bytes_ (class in numpy) byteswap() (numpy.char.chararray method) (numpy.chararray method) (numpy.generic method) (numpy.lib.user_array.container method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) C c (numpy.poly1d property) C order C-API array iterator, [1], [2] ndarray, [1] ufunc, [1] C-order c_ (in module numpy) c_intp (class in numpy.ctypeslib) cache_flush() (numpy.distutils.ccompiler_opt.CCompilerOpt method) cache_hash() (numpy.distutils.ccompiler_opt.CCompilerOpt method) can_cast() (in module numpy) capitalize() (numpy.char.chararray method) (numpy.chararray method) capsule (numpy.random.BitGenerator attribute) cast() (numpy.polynomial.chebyshev.Chebyshev class method) (numpy.polynomial.hermite.Hermite class method) (numpy.polynomial.hermite_e.HermiteE class method) (numpy.polynomial.laguerre.Laguerre class method) (numpy.polynomial.legendre.Legendre class method) (numpy.polynomial.polynomial.Polynomial class method) castfunc (C function) casting rules ufunc cbrt (in module numpy) cc_normalize_flags() (numpy.distutils.ccompiler_opt.CCompilerOpt method) cc_test_cexpr() (numpy.distutils.ccompiler_opt.CCompilerOpt method) cc_test_flags() (numpy.distutils.ccompiler_opt.CCompilerOpt method) CCompilerOpt (class in numpy.distutils.ccompiler_opt) cdouble (class in numpy) ceil (in module numpy) center() (numpy.char.chararray method) (numpy.chararray method) cffi (numpy.random.BitGenerator attribute) (numpy.random.MT19937 attribute) (numpy.random.PCG64 attribute) (numpy.random.PCG64DXSM attribute) (numpy.random.Philox attribute) (numpy.random.SFC64 attribute) cfloat (in module numpy) char (numpy.dtype attribute) char.add() (in module numpy) char.array() (in module numpy) char.asarray() (in module numpy) char.capitalize() (in module numpy) char.center() (in module numpy) char.compare_chararrays() (in module numpy) char.count() (in module numpy) char.decode() (in module numpy) char.encode() (in module numpy) char.endswith() (in module numpy) char.equal() (in module numpy) char.expandtabs() (in module numpy) char.find() (in module numpy) char.greater() (in module numpy) char.greater_equal() (in module numpy) char.index() (in module numpy) char.isalnum() (in module numpy) char.isalpha() (in module numpy) char.isdecimal() (in module numpy) char.isdigit() (in module numpy) char.islower() (in module numpy) char.isnumeric() (in module numpy) char.isspace() (in module numpy) char.istitle() (in module numpy) char.isupper() (in module numpy) char.join() (in module numpy) char.less() (in module numpy) char.less_equal() (in module numpy) char.ljust() (in module numpy) char.lower() (in module numpy) char.lstrip() (in module numpy) char.mod() (in module numpy) char.multiply() (in module numpy) char.not_equal() (in module numpy) char.partition() (in module numpy) char.replace() (in module numpy) char.rfind() (in module numpy) char.rindex() (in module numpy) char.rjust() (in module numpy) char.rpartition() (in module numpy) char.rsplit() (in module numpy) char.rstrip() (in module numpy) char.split() (in module numpy) char.splitlines() (in module numpy) char.startswith() (in module numpy) char.str_len() (in module numpy) char.strip() (in module numpy) char.swapcase() (in module numpy) char.title() (in module numpy) char.translate() (in module numpy) char.upper() (in module numpy) char.zfill() (in module numpy) character (class in numpy) character arrays chararray (class in numpy) (class in numpy.char) Chebyshev (class in numpy.polynomial.chebyshev) chisquare() (numpy.random.Generator method) (numpy.random.RandomState method) choice() (numpy.random.Generator method) (numpy.random.RandomState method) choose() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) class_modules (numpy.testing.clear_and_catch_warnings attribute) clear_and_catch_warnings (class in numpy.testing) clip() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) clongdouble (class in numpy) clongfloat (in module numpy) close() (numpy.nditer method) code generation coef (numpy.poly1d property) coefficients (numpy.poly1d property) coeffs (numpy.poly1d property) column-major, [1] column_stack() (in module numpy) common_type() (in module numpy) comparison, [1] compile() (in module numpy.f2py) complex128 (in module numpy) complex192 (in module numpy) complex256 (in module numpy) complex64 (in module numpy) complex_ (in module numpy) complexfloating (class in numpy) compress() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) compressed() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) concatenate() (in module numpy) conf_c_prefix (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_c_prefix_ (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_cache_factors (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_cc_flags (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_check_path (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_features (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_features_partial() (numpy.distutils.ccompiler_opt.CCompilerOpt method) conf_min_features (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_nocache (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_noopt (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_target_groups (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) conf_tmp_path (numpy.distutils.ccompiler_opt.CCompilerOpt attribute) Configuration (class in numpy.distutils.misc_util) conj (in module numpy) conj() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) conjugate (in module numpy) conjugate() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) construction from dict, dtype from dtype, dtype from list, dtype from None, dtype from string, dtype from tuple, dtype from type, dtype container (class in numpy.lib.user_array) container class contiguous, [1] convert() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) convolve() (in module numpy) coords (numpy.flatiter attribute) copy copy() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.flatiter method) (numpy.lib.user_array.container method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.nditer method) (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) (numpy.recarray method) (numpy.record method) copysign (in module numpy) copyto() (in module numpy) core.defchararray.array() (in module numpy) core.defchararray.asarray() (in module numpy) core.records.array() (in module numpy) core.records.fromarrays() (in module numpy) core.records.fromfile() (in module numpy) core.records.fromrecords() (in module numpy) core.records.fromstring() (in module numpy) corrcoef() (in module numpy) correlate() (in module numpy) cos (in module numpy) cosh (in module numpy) count() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) count_nonzero() (in module numpy) cov() (in module numpy) cpu_baseline_flags() (numpy.distutils.ccompiler_opt.CCompilerOpt method) cpu_baseline_names() (numpy.distutils.ccompiler_opt.CCompilerOpt method) cpu_dispatch_names() (numpy.distutils.ccompiler_opt.CCompilerOpt method) cross() (in module numpy) csingle (class in numpy) ctypes, [1] (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.random.BitGenerator attribute) (numpy.random.MT19937 attribute) (numpy.random.PCG64 attribute) (numpy.random.PCG64DXSM attribute) (numpy.random.Philox attribute) (numpy.random.SFC64 attribute) (numpy.recarray attribute) cumprod() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) cumsum() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) cutdeg() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) cyan_text() (in module numpy.distutils.misc_util) cyg2win32() (in module numpy.distutils.misc_util) cython, [1] D data (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.ma.masked_array property) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) DataSource (class in numpy) datetime64 (class in numpy) datetime_as_string() (in module numpy) datetime_data() (in module numpy) debug_print() (numpy.nditer method) decode() (numpy.char.chararray method) (numpy.chararray method) default_config_dict() (in module numpy.distutils.misc_util) default_rng() (in module numpy.random) deg2rad (in module numpy) degree() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) degrees (in module numpy) delete() (in module numpy) deprecate() (in module numpy) deprecate_with_doc() (in module numpy) deriv() (numpy.poly1d method) (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) descr (numpy.dtype attribute) diag() (in module numpy) diag_indices() (in module numpy) diag_indices_from() (in module numpy) diagflat() (in module numpy) diagonal() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) dict_append() (in module numpy.distutils.misc_util) diff() (in module numpy) digitize() (in module numpy) dimension dirichlet() (numpy.random.Generator method) (numpy.random.RandomState method) disp() (in module numpy) dist_compile() (numpy.distutils.ccompiler_opt.CCompilerOpt method) dist_error() (numpy.distutils.ccompiler_opt.CCompilerOpt static method) dist_fatal() (numpy.distutils.ccompiler_opt.CCompilerOpt static method) dist_info() (numpy.distutils.ccompiler_opt.CCompilerOpt method) dist_load_module() (numpy.distutils.ccompiler_opt.CCompilerOpt static method) dist_log() (numpy.distutils.ccompiler_opt.CCompilerOpt static method) dist_test() (numpy.distutils.ccompiler_opt.CCompilerOpt method) distutils distutils.ccompiler.CCompiler_compile() (in module numpy) distutils.ccompiler.CCompiler_customize() (in module numpy) distutils.ccompiler.CCompiler_customize_cmd() (in module numpy) distutils.ccompiler.CCompiler_cxx_compiler() (in module numpy) distutils.ccompiler.CCompiler_find_executables() (in module numpy) distutils.ccompiler.CCompiler_get_version() (in module numpy) distutils.ccompiler.CCompiler_object_filenames() (in module numpy) distutils.ccompiler.CCompiler_show_customization() (in module numpy) distutils.ccompiler.CCompiler_spawn() (in module numpy) distutils.ccompiler.gen_lib_options() (in module numpy) distutils.ccompiler.new_compiler() (in module numpy) distutils.ccompiler.replace_method() (in module numpy) distutils.ccompiler.simple_version_match() (in module numpy) distutils.ccompiler_opt.new_ccompiler_opt() (in module numpy) distutils.cpuinfo.cpu (in module numpy) distutils.exec_command.exec_command() (in module numpy) distutils.exec_command.filepath_from_subprocess_output() (in module numpy) distutils.exec_command.find_executable() (in module numpy) distutils.exec_command.forward_bytes_to_stdout() (in module numpy) distutils.exec_command.get_pythonexe() (in module numpy) distutils.exec_command.temp_file_name() (in module numpy) distutils.log.set_verbosity() (in module numpy) distutils.system_info.get_info() (in module numpy) distutils.system_info.get_standard_file() (in module numpy) divide (in module numpy) divmod (in module numpy) domain (numpy.polynomial.chebyshev.Chebyshev attribute) (numpy.polynomial.hermite.Hermite attribute) (numpy.polynomial.hermite_e.HermiteE attribute) (numpy.polynomial.laguerre.Laguerre attribute) (numpy.polynomial.legendre.Legendre attribute) (numpy.polynomial.polynomial.Polynomial attribute) dot() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) dot_join() (in module numpy.distutils.misc_util) double (class in numpy) doxy_javadoc_example (C++ function) doxy_reST_example (C++ function) DoxyLimbo (C++ class) DoxyLimbo::data (C++ function) DoxyLimbo::DoxyLimbo (C++ function), [1] DoxyLimbo::p_data (C++ member) drop_fields() (in module numpy.lib.recfunctions) dsplit() (in module numpy) dstack() (in module numpy) dtype, [1] adding new, [1] construction from dict construction from dtype construction from list construction from None construction from string construction from tuple construction from type field scalar sub-array, [1] dtype (class in numpy) (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.ma.masked_array property) (numpy.ma.MaskedArray property) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) DTypeLike (in module numpy.typing) dtypes (numpy.nditer attribute) dump() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) dumps() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) E e (in module numpy) ediff1d() (in module numpy) einsum() (in module numpy) einsum_path() (in module numpy) ellipsis emath.arccos() (in module numpy) emath.arcsin() (in module numpy) emath.arctanh() (in module numpy) emath.log() (in module numpy) emath.log10() (in module numpy) emath.log2() (in module numpy) emath.logn() (in module numpy) emath.power() (in module numpy) emath.sqrt() (in module numpy) empty() (in module numpy) empty_like() (in module numpy) enable_external_loop() (numpy.nditer method) encode() (numpy.char.chararray method) (numpy.chararray method) endswith() (numpy.char.chararray method) (numpy.chararray method) entropy (numpy.random.SeedSequence attribute) equal (in module numpy) error handling errstate (class in numpy) euler_gamma (in module numpy) exceptions.AxisError exceptions.ComplexWarning exceptions.DTypePromotionError exceptions.TooHardError exceptions.VisibleDeprecationWarning exec_mod_from_location() (in module numpy.distutils.misc_util) exists() (numpy.DataSource method) exp (in module numpy) exp2 (in module numpy) expand_dims() (in module numpy) expandtabs() (numpy.char.chararray method) (numpy.chararray method) expm1 (in module numpy) exponential() (numpy.random.Generator method) (numpy.random.RandomState method) Extension (class in numpy.distutils.core) extension module, [1] extract() (in module numpy) eye() (in module numpy) F f() (numpy.random.Generator method) (numpy.random.RandomState method) f2py fabs (in module numpy) fancy indexing feature_ahead() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_c_preprocessor() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_can_autovec() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_detect() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_extra_checks() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_flags() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_get_til() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_implies() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_implies_c() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_is_exist() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_is_supported() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_names() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_sorted() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_test() (numpy.distutils.ccompiler_opt.CCompilerOpt method) feature_untied() (numpy.distutils.ccompiler_opt.CCompilerOpt method) fft.fft() (in module numpy) fft.fft2() (in module numpy) fft.fftfreq() (in module numpy) fft.fftn() (in module numpy) fft.fftshift() (in module numpy) fft.hfft() (in module numpy) fft.ifft() (in module numpy) fft.ifft2() (in module numpy) fft.ifftn() (in module numpy) fft.ifftshift() (in module numpy) fft.ihfft() (in module numpy) fft.irfft() (in module numpy) fft.irfft2() (in module numpy) fft.irfftn() (in module numpy) fft.rfft() (in module numpy) fft.rfft2() (in module numpy) fft.rfftfreq() (in module numpy) fft.rfftn() (in module numpy) field dtype field() (numpy.recarray method) fields (numpy.dtype attribute) fill() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) fill_diagonal() (in module numpy) fill_value (numpy.ma.masked_array property) (numpy.ma.MaskedArray attribute) filled() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) filter() (numpy.testing.suppress_warnings method) filter_sources() (in module numpy.distutils.misc_util) find() (numpy.char.chararray method) (numpy.chararray method) find_common_type() (in module numpy) find_duplicates() (in module numpy.lib.recfunctions) finfo (class in numpy) finished (numpy.nditer attribute) fit() (numpy.polynomial.chebyshev.Chebyshev class method) (numpy.polynomial.hermite.Hermite class method) (numpy.polynomial.hermite_e.HermiteE class method) (numpy.polynomial.laguerre.Laguerre class method) (numpy.polynomial.legendre.Legendre class method) (numpy.polynomial.polynomial.Polynomial class method) fix() (in module numpy) flags (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.dtype attribute) (numpy.generic attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) flat (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.lib.Arrayterator property) (numpy.ma.masked_array property) (numpy.ma.MaskedArray property) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) flatiter (class in numpy) flatnonzero() (in module numpy) flatten() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) flatten_descr() (in module numpy.lib.recfunctions) flattened flexible (class in numpy) flip() (in module numpy) fliplr() (in module numpy) flipud() (in module numpy) float128 (in module numpy) float16 (in module numpy) float32 (in module numpy) float64 (in module numpy) float96 (in module numpy) float_ (in module numpy) float_power (in module numpy) floating (class in numpy) floor (in module numpy) floor_divide (in module numpy) flush() (numpy.memmap method) fmax (in module numpy) fmin (in module numpy) fmod (in module numpy) format_float_positional() (in module numpy) format_float_scientific() (in module numpy) format_parser (class in numpy) Fortran order Fortran-order frexp (in module numpy) from dict dtype construction from dtype dtype construction from list dtype construction from None dtype construction from string dtype construction from tuple dtype construction from type dtype construction from_dlpack() (in module numpy) frombuffer() (in module numpy) fromfile() (in module numpy) fromfunction() (in module numpy) fromiter() (in module numpy) frompyfunc() (in module numpy) fromregex() (in module numpy) fromroots() (numpy.polynomial.chebyshev.Chebyshev class method) (numpy.polynomial.hermite.Hermite class method) (numpy.polynomial.hermite_e.HermiteE class method) (numpy.polynomial.laguerre.Laguerre class method) (numpy.polynomial.legendre.Legendre class method) (numpy.polynomial.polynomial.Polynomial class method) fromstring() (in module numpy) full() (in module numpy) full_like() (in module numpy) G gamma() (numpy.random.Generator method) (numpy.random.RandomState method) gcd (in module numpy) generate_config_py() (in module numpy.distutils.misc_util) generate_dispatch_header() (numpy.distutils.ccompiler_opt.CCompilerOpt method) generate_state() (numpy.random.SeedSequence method) Generator (class in numpy.random) generic (class in numpy) genfromtxt() (in module numpy) geometric() (numpy.random.Generator method) (numpy.random.RandomState method) geomspace() (in module numpy) get_build_architecture() (in module numpy.distutils.misc_util) get_build_temp_dir() (numpy.distutils.misc_util.Configuration method) get_cmd() (in module numpy.distutils.misc_util) get_config_cmd() (numpy.distutils.misc_util.Configuration method) get_data_files() (in module numpy.distutils.misc_util) get_dependencies() (in module numpy.distutils.misc_util) get_distribution() (numpy.distutils.misc_util.Configuration method) get_ext_source_files() (in module numpy.distutils.misc_util) get_fieldstructure() (in module numpy.lib.recfunctions) get_fill_value() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) get_frame() (in module numpy.distutils.misc_util) get_imag() (numpy.ma.masked_array method) get_include() (in module numpy) (in module numpy.f2py) get_info() (in module numpy.distutils.misc_util) (numpy.distutils.misc_util.Configuration method) get_language() (in module numpy.distutils.misc_util) get_lib_source_files() (in module numpy.distutils.misc_util) get_mathlibs() (in module numpy.distutils.misc_util) get_names() (in module numpy.lib.recfunctions) get_names_flat() (in module numpy.lib.recfunctions) get_num_build_jobs() (in module numpy.distutils.misc_util) get_numpy_include_dirs() (in module numpy.distutils.misc_util) get_pkg_info() (in module numpy.distutils.misc_util) get_printoptions() (in module numpy) get_real() (numpy.ma.masked_array method) get_script_files() (in module numpy.distutils.misc_util) get_state() (numpy.random.RandomState method) get_subpackage() (numpy.distutils.misc_util.Configuration method) get_version() (numpy.distutils.misc_util.Configuration method) getA() (numpy.matrix method) getA1() (numpy.matrix method) getbufsize() (in module numpy) geterr() (in module numpy) geterrcall() (in module numpy) geterrobj() (in module numpy) getfield() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) getH() (numpy.matrix method) getI() (numpy.matrix method) getitem ndarray special methods getT() (numpy.matrix method) gpaths() (in module numpy.distutils.misc_util) gradient() (in module numpy) greater (in module numpy) greater_equal (in module numpy) green_text() (in module numpy.distutils.misc_util) gumbel() (numpy.random.Generator method) (numpy.random.RandomState method) H H (numpy.matrix property) half (class in numpy) hamming() (in module numpy) hanning() (in module numpy) harden_mask() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) hardmask (numpy.ma.masked_array property) (numpy.ma.MaskedArray attribute) has_cxx_sources() (in module numpy.distutils.misc_util) (numpy.distutils.core.Extension method) has_delayed_bufalloc (numpy.nditer attribute) has_f2py_sources() (numpy.distutils.core.Extension method) has_f_sources() (in module numpy.distutils.misc_util) has_index (numpy.nditer attribute) has_multi_index (numpy.nditer attribute) has_samecoef() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) has_samedomain() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) has_sametype() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) has_samewindow() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) hasobject (numpy.dtype attribute) have_f77c() (numpy.distutils.misc_util.Configuration method) have_f90c() (numpy.distutils.misc_util.Configuration method) heaviside (in module numpy) Hermite (class in numpy.polynomial.hermite) HermiteE (class in numpy.polynomial.hermite_e) histogram() (in module numpy) histogram2d() (in module numpy) histogram_bin_edges() (in module numpy) histogramdd() (in module numpy) holidays (numpy.busdaycalendar attribute) homogeneous hsplit() (in module numpy) hstack() (in module numpy) hypergeometric() (numpy.random.Generator method) (numpy.random.RandomState method) hypot (in module numpy) I I (numpy.matrix property) i0() (in module numpy) identity (numpy.ufunc attribute) identity() (in module numpy) (numpy.polynomial.chebyshev.Chebyshev class method) (numpy.polynomial.hermite.Hermite class method) (numpy.polynomial.hermite_e.HermiteE class method) (numpy.polynomial.laguerre.Laguerre class method) (numpy.polynomial.legendre.Legendre class method) (numpy.polynomial.polynomial.Polynomial class method) ids() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) iinfo (class in numpy) imag (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.ma.masked_array property) (numpy.ma.MaskedArray property) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) imag() (in module numpy) import_array (C function) import_ufunc (C function) in1d() (in module numpy) index (numpy.broadcast attribute) (numpy.flatiter attribute) (numpy.nditer attribute) index() (numpy.char.chararray method) (numpy.chararray method) indexing, [1], [2] indices() (in module numpy) inexact (class in numpy) Inf (in module numpy) inf (in module numpy) Infinity (in module numpy) info() (in module numpy) infty (in module numpy) inner() (in module numpy) insert() (in module numpy) int16 (in module numpy) int32 (in module numpy) int64 (in module numpy) int8 (in module numpy) int_ (class in numpy) intc (class in numpy) integ() (numpy.poly1d method) (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) integer (class in numpy) integers() (numpy.random.Generator method) interface array interp() (in module numpy) interpolate() (numpy.polynomial.chebyshev.Chebyshev class method) intersect1d() (in module numpy) intp (in module numpy) invert (in module numpy) is_busday() (in module numpy) is_cached() (numpy.distutils.ccompiler_opt.CCompilerOpt method) is_local_src_dir() (in module numpy.distutils.misc_util) is_sequence() (in module numpy.distutils.misc_util) is_string() (in module numpy.distutils.misc_util) isalignedstruct (numpy.dtype attribute) isalnum() (numpy.char.chararray method) (numpy.chararray method) isalpha() (numpy.char.chararray method) (numpy.chararray method) isbuiltin (numpy.dtype attribute) isclose() (in module numpy) iscomplex() (in module numpy) iscomplexobj() (in module numpy) iscontiguous() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) isdecimal() (numpy.char.chararray method) (numpy.chararray method) isdigit() (numpy.char.chararray method) (numpy.chararray method) isfinite (in module numpy) isfortran() (in module numpy) isin() (in module numpy) isinf (in module numpy) islower() (numpy.char.chararray method) (numpy.chararray method) isnan (in module numpy) isnat (in module numpy) isnative (numpy.dtype attribute) isneginf() (in module numpy) isnumeric() (numpy.char.chararray method) (numpy.chararray method) isposinf() (in module numpy) isreal() (in module numpy) isrealobj() (in module numpy) isscalar() (in module numpy) issctype() (in module numpy) isspace() (numpy.char.chararray method) (numpy.chararray method) issubclass_() (in module numpy) issubdtype() (in module numpy) issubsctype() (in module numpy) istitle() (numpy.char.chararray method) (numpy.chararray method) isupper() (numpy.char.chararray method) (numpy.chararray method) item() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) itemset() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) itemsize (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.dtype attribute) (numpy.generic attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) iterable() (in module numpy) iterationneedsapi (numpy.nditer attribute) iterator C-API, [1], [2] iterindex (numpy.nditer attribute) iternext() (numpy.nditer method) iterrange (numpy.nditer attribute) iters (numpy.broadcast attribute) itersize (numpy.nditer attribute) itviews (numpy.nditer attribute) ix_() (in module numpy) J join() (numpy.char.chararray method) (numpy.chararray method) join_by() (in module numpy.lib.recfunctions) jumped() (numpy.random.MT19937 method) (numpy.random.PCG64 method) (numpy.random.PCG64DXSM method) (numpy.random.Philox method) K kaiser() (in module numpy) keyword arguments ufunc kind (numpy.dtype attribute) kron() (in module numpy) L Laguerre (class in numpy.polynomial.laguerre) laplace() (numpy.random.Generator method) (numpy.random.RandomState method) lcm (in module numpy) ldexp (in module numpy) left_shift (in module numpy) Legendre (class in numpy.polynomial.legendre) less (in module numpy) less_equal (in module numpy) lexsort() (in module numpy) lib.format.descr_to_dtype() (in module numpy) lib.format.dtype_to_descr() (in module numpy) lib.format.header_data_from_array_1_0() (in module numpy) lib.format.magic() (in module numpy) lib.format.open_memmap() (in module numpy) lib.format.read_array() (in module numpy) lib.format.read_array_header_1_0() (in module numpy) lib.format.read_array_header_2_0() (in module numpy) lib.format.read_magic() (in module numpy) lib.format.write_array() (in module numpy) lib.format.write_array_header_1_0() (in module numpy) lib.format.write_array_header_2_0() (in module numpy) lib.stride_tricks.as_strided() (in module numpy) lib.stride_tricks.sliding_window_view() (in module numpy) linalg.cholesky() (in module numpy) linalg.cond() (in module numpy) linalg.det() (in module numpy) linalg.eig() (in module numpy) linalg.eigh() (in module numpy) linalg.eigvals() (in module numpy) linalg.eigvalsh() (in module numpy) linalg.inv() (in module numpy) linalg.LinAlgError linalg.lstsq() (in module numpy) linalg.matrix_power() (in module numpy) linalg.matrix_rank() (in module numpy) linalg.multi_dot() (in module numpy) linalg.norm() (in module numpy) linalg.pinv() (in module numpy) linalg.qr() (in module numpy) linalg.slogdet() (in module numpy) linalg.solve() (in module numpy) linalg.svd() (in module numpy) linalg.tensorinv() (in module numpy) linalg.tensorsolve() (in module numpy) linspace() (in module numpy) (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) little-endian ljust() (numpy.char.chararray method) (numpy.chararray method) load() (in module numpy) load_library() (in module numpy.ctypeslib) loadtxt() (in module numpy) lock (numpy.random.BitGenerator attribute) log (in module numpy) log10 (in module numpy) log1p (in module numpy) log2 (in module numpy) logaddexp (in module numpy) logaddexp2 (in module numpy) logical_and (in module numpy) logical_not (in module numpy) logical_or (in module numpy) logical_xor (in module numpy) logistic() (numpy.random.Generator method) (numpy.random.RandomState method) lognormal() (numpy.random.Generator method) (numpy.random.RandomState method) logseries() (numpy.random.Generator method) (numpy.random.RandomState method) logspace() (in module numpy) longcomplex (in module numpy) longdouble (class in numpy) longfloat (in module numpy) longlong (class in numpy) lookfor() (in module numpy) lower() (numpy.char.chararray method) (numpy.chararray method) lstrip() (numpy.char.chararray method) (numpy.chararray method) M ma.all (in module numpy) ma.allclose() (in module numpy) ma.allequal() (in module numpy) ma.anom (in module numpy) ma.anomalies (in module numpy) ma.any (in module numpy) ma.append() (in module numpy) ma.apply_along_axis() (in module numpy) ma.apply_over_axes() (in module numpy) ma.arange (in module numpy) ma.argmax (in module numpy) ma.argmin (in module numpy) ma.argsort() (in module numpy) ma.around (in module numpy) ma.array() (in module numpy) ma.asanyarray() (in module numpy) ma.asarray() (in module numpy) ma.atleast_1d (in module numpy) ma.atleast_2d (in module numpy) ma.atleast_3d (in module numpy) ma.average() (in module numpy) ma.choose() (in module numpy) ma.clip (in module numpy) ma.clump_masked() (in module numpy) ma.clump_unmasked() (in module numpy) ma.column_stack (in module numpy) ma.common_fill_value() (in module numpy) ma.compress_cols() (in module numpy) ma.compress_rowcols() (in module numpy) ma.compress_rows() (in module numpy) ma.compressed() (in module numpy) ma.concatenate() (in module numpy) ma.conjugate (in module numpy) ma.copy (in module numpy) ma.corrcoef() (in module numpy) ma.count (in module numpy) ma.count_masked() (in module numpy) ma.cov() (in module numpy) ma.cumprod (in module numpy) ma.cumsum (in module numpy) ma.default_fill_value() (in module numpy) ma.diag() (in module numpy) ma.diagflat (in module numpy) ma.diff() (in module numpy) ma.dot() (in module numpy) ma.dstack (in module numpy) ma.ediff1d() (in module numpy) ma.empty (in module numpy) ma.empty_like (in module numpy) ma.expand_dims() (in module numpy) ma.filled() (in module numpy) ma.fix_invalid() (in module numpy) ma.flatnotmasked_contiguous() (in module numpy) ma.flatnotmasked_edges() (in module numpy) ma.frombuffer (in module numpy) ma.fromfunction (in module numpy) ma.getdata() (in module numpy) ma.getmask() (in module numpy) ma.getmaskarray() (in module numpy) ma.harden_mask (in module numpy) ma.hsplit (in module numpy) ma.hstack (in module numpy) ma.identity (in module numpy) ma.in1d() (in module numpy) ma.indices (in module numpy) ma.inner() (in module numpy) ma.innerproduct() (in module numpy) ma.intersect1d() (in module numpy) ma.is_mask() (in module numpy) ma.is_masked() (in module numpy) ma.isarray() (in module numpy) ma.isin() (in module numpy) ma.isMA() (in module numpy) ma.isMaskedArray() (in module numpy) ma.make_mask() (in module numpy) ma.make_mask_descr() (in module numpy) ma.make_mask_none() (in module numpy) ma.mask_cols() (in module numpy) ma.mask_or() (in module numpy) ma.mask_rowcols() (in module numpy) ma.mask_rows() (in module numpy) ma.masked_all() (in module numpy) ma.masked_all_like() (in module numpy) ma.masked_equal() (in module numpy) ma.masked_greater() (in module numpy) ma.masked_greater_equal() (in module numpy) ma.masked_inside() (in module numpy) ma.masked_invalid() (in module numpy) ma.masked_less() (in module numpy) ma.masked_less_equal() (in module numpy) ma.masked_not_equal() (in module numpy) ma.masked_object() (in module numpy) ma.masked_outside() (in module numpy) ma.masked_values() (in module numpy) ma.masked_where() (in module numpy) ma.max() (in module numpy) ma.maximum_fill_value() (in module numpy) ma.mean (in module numpy) ma.median() (in module numpy) ma.min() (in module numpy) ma.minimum_fill_value() (in module numpy) ma.mr_ (in module numpy) ma.ndenumerate() (in module numpy) ma.nonzero (in module numpy) ma.notmasked_contiguous() (in module numpy) ma.notmasked_edges() (in module numpy) ma.ones (in module numpy) ma.ones_like (in module numpy) ma.outer() (in module numpy) ma.outerproduct() (in module numpy) ma.polyfit() (in module numpy) ma.power() (in module numpy) ma.prod (in module numpy) ma.ptp() (in module numpy) ma.ravel (in module numpy) ma.reshape() (in module numpy) ma.resize() (in module numpy) ma.round() (in module numpy) ma.row_stack (in module numpy) ma.set_fill_value() (in module numpy) ma.setdiff1d() (in module numpy) ma.setxor1d() (in module numpy) ma.shape() (in module numpy) ma.size() (in module numpy) ma.soften_mask (in module numpy) ma.sort() (in module numpy) ma.squeeze (in module numpy) ma.stack (in module numpy) ma.std (in module numpy) ma.sum (in module numpy) ma.swapaxes (in module numpy) ma.trace (in module numpy) ma.transpose() (in module numpy) ma.union1d() (in module numpy) ma.unique() (in module numpy) ma.vander() (in module numpy) ma.var (in module numpy) ma.vstack (in module numpy) ma.where() (in module numpy) ma.zeros (in module numpy) ma.zeros_like (in module numpy) make_config_py() (numpy.distutils.misc_util.Configuration method) make_svn_version_py() (numpy.distutils.misc_util.Configuration method) mapparms() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) mask (numpy.ma.masked_array property) (numpy.ma.MaskedArray attribute) mask_indices() (in module numpy) masked (in module numpy.ma) masked array masked arrays masked_array (in module numpy.ma) masked_print_option (in module numpy.ma) MaskedArray (class in numpy.ma) MaskType (in module numpy.ma) mat() (in module numpy) matlib.empty() (in module numpy) matlib.eye() (in module numpy) matlib.identity() (in module numpy) matlib.ones() (in module numpy) matlib.rand() (in module numpy) matlib.randn() (in module numpy) matlib.repmat() (in module numpy) matlib.zeros() (in module numpy) matmul (in module numpy) matrix, [1], [2] (class in numpy) max (numpy.iinfo property) max() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) maximum (in module numpy) maximum_sctype() (in module numpy) maxpower (numpy.polynomial.chebyshev.Chebyshev attribute) (numpy.polynomial.hermite.Hermite attribute) (numpy.polynomial.hermite_e.HermiteE attribute) (numpy.polynomial.laguerre.Laguerre attribute) (numpy.polynomial.legendre.Legendre attribute) (numpy.polynomial.polynomial.Polynomial attribute) may_share_memory() (in module numpy) me() (numpy.distutils.ccompiler_opt.CCompilerOpt static method) mean() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) median() (in module numpy) memmap (class in numpy) memory maps memory model ndarray merge_arrays() (in module numpy.lib.recfunctions) meshgrid() (in module numpy) metadata (numpy.dtype attribute) methods accumulate, ufunc reduce, ufunc reduceat, ufunc ufunc mgrid (in module numpy) min (numpy.iinfo property) min() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) min_scalar_type() (in module numpy) mingw32() (in module numpy.distutils.misc_util) minimum (in module numpy) minrelpath() (in module numpy.distutils.misc_util) mintypecode() (in module numpy) mod (in module numpy) modf (in module numpy) module numpy numpy.char numpy.ctypeslib numpy.distutils numpy.distutils.ccompiler numpy.distutils.ccompiler_opt numpy.distutils.exec_command numpy.distutils.misc_util numpy.doc.constants numpy.dtypes numpy.emath numpy.exceptions numpy.f2py numpy.fft numpy.lib.arraysetops numpy.lib.format numpy.lib.recfunctions numpy.linalg numpy.ma numpy.matlib numpy.polynomial numpy.polynomial.chebyshev numpy.polynomial.hermite numpy.polynomial.hermite_e numpy.polynomial.laguerre numpy.polynomial.legendre numpy.polynomial.polynomial numpy.polynomial.polyutils numpy.random numpy.testing numpy.testing.overrides numpy.typing numpy.typing.mypy_plugin moveaxis() (in module numpy) MT19937 (class in numpy.random) multi_index (numpy.nditer attribute) multinomial() (numpy.random.Generator method) (numpy.random.RandomState method) multiply (in module numpy) multivariate_hypergeometric() (numpy.random.Generator method) multivariate_normal() (numpy.random.Generator method) (numpy.random.RandomState method) N n_children_spawned (numpy.random.SeedSequence attribute) name (numpy.dtype attribute) names (numpy.dtype attribute) NAN (in module numpy) NaN (in module numpy) nan (in module numpy) nan_to_num() (in module numpy) nanargmax() (in module numpy) nanargmin() (in module numpy) nancumprod() (in module numpy) nancumsum() (in module numpy) nanmax() (in module numpy) nanmean() (in module numpy) nanmedian() (in module numpy) nanmin() (in module numpy) nanpercentile() (in module numpy) nanprod() (in module numpy) nanquantile() (in module numpy) nanstd() (in module numpy) nansum() (in module numpy) nanvar() (in module numpy) nargs (numpy.ufunc attribute) NBitBase (class in numpy.typing) nbytes (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) nd (numpy.broadcast attribute) ndarray, [1] C-API, [1] memory model special methods getitem special methods setitem subtyping, [1] view ndarray (class in numpy) NDArray (in module numpy.typing) NDArrayOperatorsMixin (class in numpy.lib.mixins) ndenumerate (class in numpy) ndim (numpy.broadcast attribute) (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.dtype attribute) (numpy.generic attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.nditer attribute) (numpy.recarray attribute) (numpy.record attribute) ndincr() (numpy.ndindex method) ndindex (class in numpy) nditer (class in numpy) ndpointer() built-in function ndpointer() (in module numpy.ctypeslib) negative (in module numpy) negative_binomial() (numpy.random.Generator method) (numpy.random.RandomState method) nested_iters() (in module numpy) newaxis (in module numpy) newbyteorder() (numpy.char.chararray method) (numpy.chararray method) (numpy.dtype method) (numpy.ma.masked_array method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) nextafter (in module numpy) nin (numpy.ufunc attribute) NINF (in module numpy) njoin() (in module numpy.distutils.misc_util) NO_IMPORT_ARRAY (C macro) NO_IMPORT_UFUNC (C macro) nomask (in module numpy.ma) non-contiguous noncentral_chisquare() (numpy.random.Generator method) (numpy.random.RandomState method) noncentral_f() (numpy.random.Generator method) (numpy.random.RandomState method) nonzero() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) nop (numpy.nditer attribute) normal() (numpy.random.Generator method) (numpy.random.RandomState method) not_equal (in module numpy) nout (numpy.ufunc attribute) NPY_1_PI (C macro) NPY_2_PI (C macro) NPY_ALLOW_C_API (C macro) NPY_ALLOW_C_API_DEF (C macro) NPY_ALLOW_THREADS (C macro) NPY_AO (C type) NPY_AO.base (C member) NPY_AO.data (C member) NPY_AO.descr (C member) NPY_AO.dimensions (C member) NPY_AO.flags (C member) NPY_AO.nd (C member) NPY_AO.PyObject_HEAD (C macro) NPY_AO.strides (C member) NPY_AO.weakreflist (C member) NPY_ARR_HAS_DESCR (C macro) NPY_ARRAY_ALIGNED (C macro) NPY_ARRAY_BEHAVED (C macro) NPY_ARRAY_C_CONTIGUOUS (C macro) NPY_ARRAY_CARRAY (C macro) NPY_ARRAY_CARRAY_RO (C macro) NPY_ARRAY_DEFAULT (C macro) NPY_ARRAY_ELEMENTSTRIDES (C macro) NPY_ARRAY_ENSUREARRAY (C macro) NPY_ARRAY_ENSURECOPY (C macro) NPY_ARRAY_F_CONTIGUOUS (C macro) NPY_ARRAY_FARRAY (C macro) NPY_ARRAY_FARRAY_RO (C macro) NPY_ARRAY_FORCECAST (C macro) NPY_ARRAY_IN_ARRAY (C macro) NPY_ARRAY_IN_ARRAY.NPY_ARRAY_IN_FARRAY (C macro) NPY_ARRAY_INOUT_ARRAY (C macro) NPY_ARRAY_INOUT_ARRAY.NPY_ARRAY_INOUT_FARRAY (C macro) NPY_ARRAY_NOTSWAPPED (C macro) NPY_ARRAY_NOTSWAPPED.NPY_ARRAY_BEHAVED_NS (C macro) NPY_ARRAY_OUT_ARRAY (C macro) NPY_ARRAY_OUT_ARRAY.NPY_ARRAY_OUT_FARRAY (C macro) NPY_ARRAY_OWNDATA (C macro) NPY_ARRAY_UPDATE_ALL (C macro) NPY_ARRAY_WRITEABLE (C macro) NPY_ARRAY_WRITEBACKIFCOPY (C macro) NPY_AUXDATA_CLONE (C function) NPY_AUXDATA_FREE (C function) NPY_BEGIN_ALLOW_THREADS (C macro) NPY_BEGIN_THREADS (C macro) NPY_BEGIN_THREADS_DEF (C macro) NPY_BEGIN_THREADS_DESCR (C function) NPY_BEGIN_THREADS_THRESHOLDED (C function) NPY_BIG (C macro) NPY_BIG_ENDIAN (C macro) npy_bool (C type) NPY_BUFSIZE (C macro) npy_byte (C type) NPY_BYTE_ORDER (C macro) NPY_CASTING (C enum) NPY_CASTING.NPY_EQUIV_CASTING (C enumerator) NPY_CASTING.NPY_NO_CASTING (C enumerator) NPY_CASTING.NPY_SAFE_CASTING (C enumerator) NPY_CASTING.NPY_SAME_KIND_CASTING (C enumerator) NPY_CASTING.NPY_UNSAFE_CASTING (C enumerator) npy_cdouble (C type) npy_cfloat (C type) npy_clear_floatstatus (C function) npy_clear_floatstatus_barrier (C function) NPY_CLIPMODE (C enum) NPY_CLIPMODE.NPY_CLIP (C enumerator) NPY_CLIPMODE.NPY_RAISE (C enumerator) NPY_CLIPMODE.NPY_WRAP (C enumerator) npy_clongdouble (C type) npy_copysign (C macro) NPY_CPU_AMD64 (C macro) NPY_CPU_IA64 (C macro) NPY_CPU_PARISC (C macro) NPY_CPU_PPC (C macro) NPY_CPU_PPC64 (C macro) NPY_CPU_S390 (C macro) NPY_CPU_SPARC (C macro) NPY_CPU_SPARC64 (C macro) NPY_CPU_X86 (C macro) NPY_DISABLE_C_API (C macro) npy_double (C type) npy_double_to_half (C function) npy_doublebits_to_halfbits (C function) NPY_E (C macro) NPY_END_ALLOW_THREADS (C macro) NPY_END_THREADS (C macro) NPY_END_THREADS_DESCR (C function) NPY_EULER (C macro) NPY_FAIL (C macro) NPY_FALSE (C macro) NPY_FEATURE_VERSION (C macro) npy_float (C type) npy_float_to_half (C function) npy_floatbits_to_halfbits (C function) NPY_FROM_FIELDS (C macro) npy_get_floatstatus (C function) npy_get_floatstatus_barrier (C function) npy_half (C type) npy_half_copysign (C function) npy_half_eq (C function) npy_half_eq_nonan (C function) npy_half_ge (C function) npy_half_gt (C function) npy_half_isfinite (C function) npy_half_isinf (C function) npy_half_isnan (C function) npy_half_iszero (C function) npy_half_le (C function) npy_half_le_nonan (C function) npy_half_lt (C function) npy_half_lt_nonan (C function) NPY_HALF_NAN (C macro) npy_half_ne (C function) NPY_HALF_NEGONE (C macro) npy_half_nextafter (C function) NPY_HALF_NINF (C macro) NPY_HALF_NZERO (C macro) NPY_HALF_ONE (C macro) NPY_HALF_PINF (C macro) NPY_HALF_PZERO (C macro) npy_half_signbit (C function) npy_half_spacing (C function) npy_half_to_double (C function) npy_half_to_float (C function) NPY_HALF_ZERO (C macro) npy_halfbits_to_doublebits (C function) npy_halfbits_to_floatbits (C function) NPY_IGNORE (C macro) NPY_INFINITY (C macro) npy_int (C type) npy_int16 (C type) npy_int32 (C type) npy_int64 (C type) npy_intp (C type) NPY_INTP_FMT (C macro) npy_isfinite (C macro) npy_isinf (C macro) npy_isnan (C macro) NPY_ITEM_HASOBJECT (C macro) NPY_ITEM_IS_POINTER (C macro) NPY_ITEM_REFCOUNT (C macro) NPY_ITER_ALIGNED (C macro) NPY_ITER_ALLOCATE (C macro) NPY_ITER_ARRAYMASK (C macro) NPY_ITER_BUFFERED (C macro) NPY_ITER_C_INDEX (C macro) NPY_ITER_COMMON_DTYPE (C macro) NPY_ITER_CONTIG (C macro) NPY_ITER_COPY (C macro) NPY_ITER_COPY_IF_OVERLAP (C macro) NPY_ITER_DELAY_BUFALLOC (C macro) NPY_ITER_DONT_NEGATE_STRIDES (C macro) NPY_ITER_EXTERNAL_LOOP (C macro) NPY_ITER_F_INDEX (C macro) NPY_ITER_GROWINNER (C macro) NPY_ITER_MULTI_INDEX (C macro) NPY_ITER_NBO (C macro) NPY_ITER_NO_BROADCAST (C macro) NPY_ITER_NO_SUBTYPE (C macro) NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE (C macro) NPY_ITER_RANGED (C macro) NPY_ITER_READONLY (C macro) NPY_ITER_READWRITE (C macro) NPY_ITER_REDUCE_OK (C macro) NPY_ITER_REFS_OK (C macro) NPY_ITER_UPDATEIFCOPY (C macro) NPY_ITER_WRITEMASKED (C macro) NPY_ITER_WRITEONLY (C macro) NPY_ITER_ZEROSIZE_OK (C macro) NPY_LIKELY (C macro) NPY_LIST_PICKLE (C macro) NPY_LITTLE (C macro) NPY_LITTLE_ENDIAN (C macro) NPY_LOG10E (C macro) NPY_LOG2E (C macro) NPY_LOGE10 (C macro) NPY_LOGE2 (C macro) npy_long (C type) npy_longdouble (C type) NPY_LONGDOUBLE_FMT (C macro) npy_longlong (C type) NPY_LONGLONG_FMT (C macro) NPY_LOOP_BEGIN_THREADS (C macro) NPY_LOOP_END_THREADS (C macro) NPY_MAX_BUFSIZE (C macro) NPY_MAXARGS (C macro) NPY_MAXDIMS (C macro) NPY_MIN_BUFSIZE (C macro) NPY_NAN (C macro) NPY_NATIVE (C macro) NPY_NEEDS_INIT (C macro) NPY_NEEDS_PYAPI (C macro) npy_nextafter (C function) NPY_NOTYPE (C macro) NPY_NTYPES (C macro) NPY_NUM_FLOATTYPE (C macro) NPY_NZERO (C macro) NPY_OBJECT_DTYPE_FLAGS (C macro) NPY_ORDER (C enum) NPY_ORDER.NPY_ANYORDER (C enumerator) NPY_ORDER.NPY_CORDER (C enumerator) NPY_ORDER.NPY_FORTRANORDER (C enumerator) NPY_ORDER.NPY_KEEPORDER (C enumerator) NPY_OUT_ARRAY (C macro) NPY_PI (C macro) NPY_PI_2 (C macro) NPY_PI_4 (C macro) NPY_PRIORITY (C macro) NPY_PZERO (C macro) NPY_SCALAR_PRIORITY (C macro) NPY_SCALARKIND (C enum) NPY_SCALARKIND.NPY_BOOL_SCALAR (C enumerator) NPY_SCALARKIND.NPY_COMPLEX_SCALAR (C enumerator) NPY_SCALARKIND.NPY_FLOAT_SCALAR (C enumerator) NPY_SCALARKIND.NPY_INTNEG_SCALAR (C enumerator) NPY_SCALARKIND.NPY_INTPOS_SCALAR (C enumerator) NPY_SCALARKIND.NPY_NOSCALAR (C enumerator) NPY_SCALARKIND.NPY_NSCALARKINDS (C enumerator) NPY_SCALARKIND.NPY_OBJECT_SCALAR (C enumerator) NPY_SEARCHSIDE (C enum) NPY_SEARCHSIDE.NPY_SEARCHLEFT (C enumerator) NPY_SEARCHSIDE.NPY_SEARCHRIGHT (C enumerator) NPY_SELECTKIND (C enum) NPY_SELECTKIND.NPY_INTROSELECT (C enumerator) npy_set_floatstatus_divbyzero (C function) npy_set_floatstatus_invalid (C function) npy_set_floatstatus_overflow (C function) npy_set_floatstatus_underflow (C function) npy_short (C type) npy_signbit (C macro) NPY_SIZEOF_DOUBLE (C macro) NPY_SIZEOF_FLOAT (C macro) NPY_SIZEOF_INT (C macro) NPY_SIZEOF_INTP (C macro) NPY_SIZEOF_LONG (C macro) NPY_SIZEOF_LONG_DOUBLE (C macro) NPY_SIZEOF_LONGDOUBLE (C macro) NPY_SIZEOF_LONGLONG (C macro) NPY_SIZEOF_PY_INTPTR_T (C macro) NPY_SIZEOF_PY_LONG_LONG (C macro) NPY_SIZEOF_SHORT (C macro) NPY_SORTKIND (C enum) NPY_SORTKIND.NPY_HEAPSORT (C enumerator) NPY_SORTKIND.NPY_MERGESORT (C enumerator) NPY_SORTKIND.NPY_NSORTS (C enumerator) NPY_SORTKIND.NPY_QUICKSORT (C enumerator) NPY_SORTKIND.NPY_STABLESORT (C enumerator) npy_spacing (C function) NPY_SUBTYPE_PRIORITY (C macro) NPY_SUCCEED (C macro) NPY_SWAP (C macro) NPY_TRUE (C macro) NPY_TYPES (C enum) NPY_TYPES.NPY_BOOL (C enumerator) NPY_TYPES.NPY_BYTE (C enumerator) NPY_TYPES.NPY_CDOUBLE (C enumerator) NPY_TYPES.NPY_CFLOAT (C enumerator) NPY_TYPES.NPY_CLONGDOUBLE (C enumerator) NPY_TYPES.NPY_COMPLEX128 (C enumerator) NPY_TYPES.NPY_COMPLEX64 (C enumerator) NPY_TYPES.NPY_DATETIME (C enumerator) NPY_TYPES.NPY_DEFAULT_TYPE (C enumerator) NPY_TYPES.NPY_DOUBLE (C enumerator) NPY_TYPES.NPY_FLOAT (C enumerator) NPY_TYPES.NPY_FLOAT16 (C enumerator) NPY_TYPES.NPY_FLOAT32 (C enumerator) NPY_TYPES.NPY_FLOAT64 (C enumerator) NPY_TYPES.NPY_HALF (C enumerator) NPY_TYPES.NPY_INT (C enumerator) NPY_TYPES.NPY_INT16 (C enumerator) NPY_TYPES.NPY_INT32 (C enumerator) NPY_TYPES.NPY_INT64 (C enumerator) NPY_TYPES.NPY_INT8 (C enumerator) NPY_TYPES.NPY_INTP (C enumerator) NPY_TYPES.NPY_LONG (C enumerator) NPY_TYPES.NPY_LONGDOUBLE (C enumerator) NPY_TYPES.NPY_LONGLONG (C enumerator) NPY_TYPES.NPY_MASK (C enumerator) NPY_TYPES.NPY_OBJECT (C enumerator) NPY_TYPES.NPY_SHORT (C enumerator) NPY_TYPES.NPY_STRING (C enumerator) NPY_TYPES.NPY_TIMEDELTA (C enumerator) NPY_TYPES.NPY_UBYTE (C enumerator) NPY_TYPES.NPY_UINT (C enumerator) NPY_TYPES.NPY_UINT16 (C enumerator) NPY_TYPES.NPY_UINT32 (C enumerator) NPY_TYPES.NPY_UINT64 (C enumerator) NPY_TYPES.NPY_UINT8 (C enumerator) NPY_TYPES.NPY_UINTP (C enumerator) NPY_TYPES.NPY_ULONG (C enumerator) NPY_TYPES.NPY_ULONGLONG (C enumerator) NPY_TYPES.NPY_UNICODE (C enumerator) NPY_TYPES.NPY_USHORT (C enumerator) NPY_TYPES.NPY_VOID (C enumerator) npy_ubyte (C type) npy_uint (C type) npy_uint16 (C type) npy_uint32 (C type) npy_uint64 (C type) npy_uintp (C type) NPY_UINTP_FMT (C macro) npy_ulong (C type) npy_ulonglong (C type) NPY_ULONGLONG_FMT (C macro) NPY_UNLIKELY (C macro) NPY_UNUSED (C macro) NPY_USE_GETITEM (C macro) NPY_USE_SETITEM (C macro) NPY_USERDEF (C macro) npy_ushort (C type) NPY_VERSION (C macro) NpyAuxData (C type) NpyAuxData_CloneFunc (C type) NpyAuxData_FreeFunc (C type) NpyIter (C type) NpyIter_AdvancedNew (C function) NpyIter_Copy (C function) NpyIter_CreateCompatibleStrides (C function) NpyIter_Deallocate (C function) NpyIter_EnableExternalLoop (C function) NpyIter_GetAxisStrideArray (C function) NpyIter_GetBufferSize (C function) NpyIter_GetDataPtrArray (C function) NpyIter_GetDescrArray (C function) NpyIter_GetGetMultiIndex (C function) NpyIter_GetIndexPtr (C function) NpyIter_GetInitialDataPtrArray (C function) NpyIter_GetInnerFixedStrideArray (C function) NpyIter_GetInnerLoopSizePtr (C function) NpyIter_GetInnerStrideArray (C function) NpyIter_GetIterIndex (C function) NpyIter_GetIterIndexRange (C function) NpyIter_GetIterNext (C function) NpyIter_GetIterSize (C function) NpyIter_GetIterView (C function) NpyIter_GetMultiIndexFunc (C type) NpyIter_GetNDim (C function) NpyIter_GetNOp (C function) NpyIter_GetOperandArray (C function) NpyIter_GetReadFlags (C function) NpyIter_GetShape (C function) NpyIter_GetWriteFlags (C function) NpyIter_GotoIndex (C function) NpyIter_GotoIterIndex (C function) NpyIter_GotoMultiIndex (C function) NpyIter_HasDelayedBufAlloc (C function) NpyIter_HasExternalLoop (C function) NpyIter_HasIndex (C function) NpyIter_HasMultiIndex (C function) NpyIter_IsBuffered (C function) NpyIter_IsFirstVisit (C function) NpyIter_IsGrowInner (C function) NpyIter_IterNextFunc (C type) NpyIter_MultiNew (C function) NpyIter_New (C function) NpyIter_RemoveAxis (C function) NpyIter_RemoveMultiIndex (C function) NpyIter_RequiresBuffering (C function) NpyIter_Reset (C function) NpyIter_ResetBasePointers (C function) NpyIter_ResetToIterIndexRange (C function) NpyIter_Type (C type) ntypes (numpy.ufunc attribute) num (numpy.dtype attribute) number (class in numpy) numiter (numpy.broadcast attribute) numpy module numpy.char module numpy.ctypeslib module numpy.distutils module numpy.distutils.ccompiler module numpy.distutils.ccompiler_opt module numpy.distutils.exec_command module numpy.distutils.misc_util module numpy.doc.constants module numpy.dtypes module numpy.emath module numpy.exceptions module numpy.f2py module numpy.fft module numpy.lib.arraysetops module numpy.lib.format module numpy.lib.recfunctions module numpy.linalg module numpy.ma module numpy.matlib module numpy.polynomial module numpy.polynomial.chebyshev module numpy.polynomial.hermite module numpy.polynomial.hermite_e module numpy.polynomial.laguerre module numpy.polynomial.legendre module numpy.polynomial.polynomial module numpy.polynomial.polyutils module numpy.random module numpy.testing module numpy.testing.overrides module numpy.typing module numpy.typing.mypy_plugin module NumpyVersion (class in numpy.lib) NZERO (in module numpy) O o (numpy.poly1d property) obj2sctype() (in module numpy) object array object.__array_interface__ (built-in variable) object.__array_struct__ (built-in variable) object_ (class in numpy) offset ogrid (in module numpy) ones() (in module numpy) ones_like() (in module numpy) open() (numpy.DataSource method) operands (numpy.nditer attribute) operation, [1] operator, [1] order (numpy.poly1d property) outer() (in module numpy) (numpy.ufunc method) P packbits() (in module numpy) pad() (in module numpy) pareto() (numpy.random.Generator method) (numpy.random.RandomState method) parse_targets() (numpy.distutils.ccompiler_opt.CCompilerOpt method) partition() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) paths() (numpy.distutils.misc_util.Configuration method) PCG64 (class in numpy.random) PCG64DXSM (class in numpy.random) percentile() (in module numpy) permutation() (numpy.random.Generator method) (numpy.random.RandomState method) permuted() (numpy.random.Generator method) Philox (class in numpy.random) pi (in module numpy) piecewise() (in module numpy) PINF (in module numpy) place() (in module numpy) poisson() (numpy.random.Generator method) (numpy.random.RandomState method) poly() (in module numpy) poly1d (class in numpy) polyadd() (in module numpy) polyder() (in module numpy) polydiv() (in module numpy) polyfit() (in module numpy) polyint() (in module numpy) polymul() (in module numpy) Polynomial (class in numpy.polynomial.polynomial) polynomial.chebyshev.cheb2poly() (in module numpy) polynomial.chebyshev.chebadd() (in module numpy) polynomial.chebyshev.chebcompanion() (in module numpy) polynomial.chebyshev.chebder() (in module numpy) polynomial.chebyshev.chebdiv() (in module numpy) polynomial.chebyshev.chebdomain (in module numpy) polynomial.chebyshev.chebfit() (in module numpy) polynomial.chebyshev.chebfromroots() (in module numpy) polynomial.chebyshev.chebgauss() (in module numpy) polynomial.chebyshev.chebgrid2d() (in module numpy) polynomial.chebyshev.chebgrid3d() (in module numpy) polynomial.chebyshev.chebint() (in module numpy) polynomial.chebyshev.chebinterpolate() (in module numpy) polynomial.chebyshev.chebline() (in module numpy) polynomial.chebyshev.chebmul() (in module numpy) polynomial.chebyshev.chebmulx() (in module numpy) polynomial.chebyshev.chebone (in module numpy) polynomial.chebyshev.chebpow() (in module numpy) polynomial.chebyshev.chebpts1() (in module numpy) polynomial.chebyshev.chebpts2() (in module numpy) polynomial.chebyshev.chebroots() (in module numpy) polynomial.chebyshev.chebsub() (in module numpy) polynomial.chebyshev.chebtrim() (in module numpy) polynomial.chebyshev.chebval() (in module numpy) polynomial.chebyshev.chebval2d() (in module numpy) polynomial.chebyshev.chebval3d() (in module numpy) polynomial.chebyshev.chebvander() (in module numpy) polynomial.chebyshev.chebvander2d() (in module numpy) polynomial.chebyshev.chebvander3d() (in module numpy) polynomial.chebyshev.chebweight() (in module numpy) polynomial.chebyshev.chebx (in module numpy) polynomial.chebyshev.chebzero (in module numpy) polynomial.chebyshev.poly2cheb() (in module numpy) polynomial.hermite.herm2poly() (in module numpy) polynomial.hermite.hermadd() (in module numpy) polynomial.hermite.hermcompanion() (in module numpy) polynomial.hermite.hermder() (in module numpy) polynomial.hermite.hermdiv() (in module numpy) polynomial.hermite.hermdomain (in module numpy) polynomial.hermite.hermfit() (in module numpy) polynomial.hermite.hermfromroots() (in module numpy) polynomial.hermite.hermgauss() (in module numpy) polynomial.hermite.hermgrid2d() (in module numpy) polynomial.hermite.hermgrid3d() (in module numpy) polynomial.hermite.hermint() (in module numpy) polynomial.hermite.hermline() (in module numpy) polynomial.hermite.hermmul() (in module numpy) polynomial.hermite.hermmulx() (in module numpy) polynomial.hermite.hermone (in module numpy) polynomial.hermite.hermpow() (in module numpy) polynomial.hermite.hermroots() (in module numpy) polynomial.hermite.hermsub() (in module numpy) polynomial.hermite.hermtrim() (in module numpy) polynomial.hermite.hermval() (in module numpy) polynomial.hermite.hermval2d() (in module numpy) polynomial.hermite.hermval3d() (in module numpy) polynomial.hermite.hermvander() (in module numpy) polynomial.hermite.hermvander2d() (in module numpy) polynomial.hermite.hermvander3d() (in module numpy) polynomial.hermite.hermweight() (in module numpy) polynomial.hermite.hermx (in module numpy) polynomial.hermite.hermzero (in module numpy) polynomial.hermite.poly2herm() (in module numpy) polynomial.hermite_e.herme2poly() (in module numpy) polynomial.hermite_e.hermeadd() (in module numpy) polynomial.hermite_e.hermecompanion() (in module numpy) polynomial.hermite_e.hermeder() (in module numpy) polynomial.hermite_e.hermediv() (in module numpy) polynomial.hermite_e.hermedomain (in module numpy) polynomial.hermite_e.hermefit() (in module numpy) polynomial.hermite_e.hermefromroots() (in module numpy) polynomial.hermite_e.hermegauss() (in module numpy) polynomial.hermite_e.hermegrid2d() (in module numpy) polynomial.hermite_e.hermegrid3d() (in module numpy) polynomial.hermite_e.hermeint() (in module numpy) polynomial.hermite_e.hermeline() (in module numpy) polynomial.hermite_e.hermemul() (in module numpy) polynomial.hermite_e.hermemulx() (in module numpy) polynomial.hermite_e.hermeone (in module numpy) polynomial.hermite_e.hermepow() (in module numpy) polynomial.hermite_e.hermeroots() (in module numpy) polynomial.hermite_e.hermesub() (in module numpy) polynomial.hermite_e.hermetrim() (in module numpy) polynomial.hermite_e.hermeval() (in module numpy) polynomial.hermite_e.hermeval2d() (in module numpy) polynomial.hermite_e.hermeval3d() (in module numpy) polynomial.hermite_e.hermevander() (in module numpy) polynomial.hermite_e.hermevander2d() (in module numpy) polynomial.hermite_e.hermevander3d() (in module numpy) polynomial.hermite_e.hermeweight() (in module numpy) polynomial.hermite_e.hermex (in module numpy) polynomial.hermite_e.hermezero (in module numpy) polynomial.hermite_e.poly2herme() (in module numpy) polynomial.laguerre.lag2poly() (in module numpy) polynomial.laguerre.lagadd() (in module numpy) polynomial.laguerre.lagcompanion() (in module numpy) polynomial.laguerre.lagder() (in module numpy) polynomial.laguerre.lagdiv() (in module numpy) polynomial.laguerre.lagdomain (in module numpy) polynomial.laguerre.lagfit() (in module numpy) polynomial.laguerre.lagfromroots() (in module numpy) polynomial.laguerre.laggauss() (in module numpy) polynomial.laguerre.laggrid2d() (in module numpy) polynomial.laguerre.laggrid3d() (in module numpy) polynomial.laguerre.lagint() (in module numpy) polynomial.laguerre.lagline() (in module numpy) polynomial.laguerre.lagmul() (in module numpy) polynomial.laguerre.lagmulx() (in module numpy) polynomial.laguerre.lagone (in module numpy) polynomial.laguerre.lagpow() (in module numpy) polynomial.laguerre.lagroots() (in module numpy) polynomial.laguerre.lagsub() (in module numpy) polynomial.laguerre.lagtrim() (in module numpy) polynomial.laguerre.lagval() (in module numpy) polynomial.laguerre.lagval2d() (in module numpy) polynomial.laguerre.lagval3d() (in module numpy) polynomial.laguerre.lagvander() (in module numpy) polynomial.laguerre.lagvander2d() (in module numpy) polynomial.laguerre.lagvander3d() (in module numpy) polynomial.laguerre.lagweight() (in module numpy) polynomial.laguerre.lagx (in module numpy) polynomial.laguerre.lagzero (in module numpy) polynomial.laguerre.poly2lag() (in module numpy) polynomial.legendre.leg2poly() (in module numpy) polynomial.legendre.legadd() (in module numpy) polynomial.legendre.legcompanion() (in module numpy) polynomial.legendre.legder() (in module numpy) polynomial.legendre.legdiv() (in module numpy) polynomial.legendre.legdomain (in module numpy) polynomial.legendre.legfit() (in module numpy) polynomial.legendre.legfromroots() (in module numpy) polynomial.legendre.leggauss() (in module numpy) polynomial.legendre.leggrid2d() (in module numpy) polynomial.legendre.leggrid3d() (in module numpy) polynomial.legendre.legint() (in module numpy) polynomial.legendre.legline() (in module numpy) polynomial.legendre.legmul() (in module numpy) polynomial.legendre.legmulx() (in module numpy) polynomial.legendre.legone (in module numpy) polynomial.legendre.legpow() (in module numpy) polynomial.legendre.legroots() (in module numpy) polynomial.legendre.legsub() (in module numpy) polynomial.legendre.legtrim() (in module numpy) polynomial.legendre.legval() (in module numpy) polynomial.legendre.legval2d() (in module numpy) polynomial.legendre.legval3d() (in module numpy) polynomial.legendre.legvander() (in module numpy) polynomial.legendre.legvander2d() (in module numpy) polynomial.legendre.legvander3d() (in module numpy) polynomial.legendre.legweight() (in module numpy) polynomial.legendre.legx (in module numpy) polynomial.legendre.legzero (in module numpy) polynomial.legendre.poly2leg() (in module numpy) polynomial.polynomial.polyadd() (in module numpy) polynomial.polynomial.polycompanion() (in module numpy) polynomial.polynomial.polyder() (in module numpy) polynomial.polynomial.polydiv() (in module numpy) polynomial.polynomial.polydomain (in module numpy) polynomial.polynomial.polyfit() (in module numpy) polynomial.polynomial.polyfromroots() (in module numpy) polynomial.polynomial.polygrid2d() (in module numpy) polynomial.polynomial.polygrid3d() (in module numpy) polynomial.polynomial.polyint() (in module numpy) polynomial.polynomial.polyline() (in module numpy) polynomial.polynomial.polymul() (in module numpy) polynomial.polynomial.polymulx() (in module numpy) polynomial.polynomial.polyone (in module numpy) polynomial.polynomial.polypow() (in module numpy) polynomial.polynomial.polyroots() (in module numpy) polynomial.polynomial.polysub() (in module numpy) polynomial.polynomial.polytrim() (in module numpy) polynomial.polynomial.polyval() (in module numpy) polynomial.polynomial.polyval2d() (in module numpy) polynomial.polynomial.polyval3d() (in module numpy) polynomial.polynomial.polyvalfromroots() (in module numpy) polynomial.polynomial.polyvander() (in module numpy) polynomial.polynomial.polyvander2d() (in module numpy) polynomial.polynomial.polyvander3d() (in module numpy) polynomial.polynomial.polyx (in module numpy) polynomial.polynomial.polyzero (in module numpy) polynomial.polyutils.as_series() (in module numpy) polynomial.polyutils.getdomain() (in module numpy) polynomial.polyutils.mapdomain() (in module numpy) polynomial.polyutils.mapparms() (in module numpy) polynomial.polyutils.RankWarning polynomial.polyutils.trimcoef() (in module numpy) polynomial.polyutils.trimseq() (in module numpy) polynomial.set_default_printstyle() (in module numpy) polysub() (in module numpy) polyval() (in module numpy) pool (numpy.random.SeedSequence attribute) pool_size (numpy.random.SeedSequence attribute) positive (in module numpy) power (in module numpy) power() (numpy.random.Generator method) (numpy.random.RandomState method) pprint() (numpy.record method) printoptions() (in module numpy) prod() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) product() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) promote_types() (in module numpy) protocol array ptp() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) put() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) put_along_axis() (in module numpy) putmask() (in module numpy) PY_ARRAY_UNIQUE_SYMBOL (C macro) PY_UFUNC_UNIQUE_SYMBOL (C macro) PyArray_All (C function) PyArray_Any (C function) PyArray_Arange (C function) PyArray_ArangeObj (C function) PyArray_ArgMax (C function) PyArray_ArgMin (C function) PyArray_ArgPartition (C function) PyArray_ArgSort (C function) PyArray_ArrFuncs (C type) PyArray_ArrFuncs.argmax (C member) PyArray_ArrFuncs.argmin (C member) PyArray_ArrFuncs.argsort (C member) PyArray_ArrFuncs.cancastscalarkindto (C member) PyArray_ArrFuncs.cancastto (C member) PyArray_ArrFuncs.cast (C member) PyArray_ArrFuncs.castdict (C member) PyArray_ArrFuncs.compare (C member) PyArray_ArrFuncs.copyswap (C member) PyArray_ArrFuncs.copyswapn (C member) PyArray_ArrFuncs.dotfunc (C member) PyArray_ArrFuncs.fastclip (C member) PyArray_ArrFuncs.fastputmask (C member) PyArray_ArrFuncs.fasttake (C member) PyArray_ArrFuncs.fill (C member) PyArray_ArrFuncs.fillwithscalar (C member) PyArray_ArrFuncs.fromstr (C member) PyArray_ArrFuncs.getitem (C member) PyArray_ArrFuncs.nonzero (C member) PyArray_ArrFuncs.scalarkind (C member) PyArray_ArrFuncs.scanfunc (C member) PyArray_ArrFuncs.setitem (C member) PyArray_ArrFuncs.sort (C member) PyArray_AsCArray (C function) PyArray_AxisConverter (C function) PyArray_BASE (C function) PyArray_BoolConverter (C function) PyArray_Broadcast (C function) PyArray_BroadcastToShape (C function) PyArray_BufferConverter (C function) PyArray_ByteorderConverter (C function) PyArray_BYTES (C function) PyArray_Byteswap (C function) PyArray_CanCastArrayTo (C function) PyArray_CanCastSafely (C function) PyArray_CanCastTo (C function) PyArray_CanCastTypeTo (C function) PyArray_CanCoerceScalar (C function) PyArray_Cast (C function) PyArray_CastingConverter (C function) PyArray_CastScalarToCtype (C function) PyArray_CastTo (C function) PyArray_CastToType (C function) PyArray_CEQ (C macro) PyArray_CGE (C macro) PyArray_CGT (C macro) PyArray_Check (C function) PyArray_CheckAnyScalar (C function) PyArray_CheckAxis (C function) PyArray_CheckExact (C function) PyArray_CheckFromAny (C function) PyArray_CheckScalar (C function) PyArray_CheckStrides (C function) PyArray_CHKFLAGS (C function) PyArray_Choose (C function) PyArray_Choose.NPY_CLIP (C macro) PyArray_Choose.NPY_RAISE (C macro) PyArray_Choose.NPY_WRAP (C macro) PyArray_Chunk (C type) PyArray_Chunk.base (C member) PyArray_Chunk.flags (C member) PyArray_Chunk.len (C member) PyArray_Chunk.ptr (C member) PyArray_CLE (C macro) PyArray_CLEARFLAGS (C function) PyArray_Clip (C function) PyArray_ClipmodeConverter (C function) PyArray_CLT (C macro) PyArray_CNE (C macro) PyArray_CompareLists (C function) PyArray_Compress (C function) PyArray_Concatenate (C function) PyArray_Conjugate (C function) PyArray_ContiguousFromAny (C function) PyArray_ContiguousFromObject (C function) PyArray_ConvertClipmodeSequence (C function) PyArray_Converter (C function) PyArray_ConvertToCommonType (C function) PyArray_CopyAndTranspose (C function) PyArray_CopyInto (C function) PyArray_CopyObject (C function) PyArray_Correlate (C function) PyArray_Correlate2 (C function) PyArray_CountNonzero (C function) PyArray_CumProd (C function) PyArray_CumSum (C function) PyArray_DATA (C function) PyArray_DESCR (C function) PyArray_Descr (C type) PyArray_Descr.alignment (C member) PyArray_Descr.byteorder (C member) PyArray_Descr.c_metadata (C member) PyArray_Descr.elsize (C member) PyArray_Descr.f (C member) PyArray_Descr.fields (C member) PyArray_Descr.flags (C member) PyArray_Descr.hash (C member) PyArray_Descr.kind (C member) PyArray_Descr.metadata (C member) PyArray_Descr.names (C member) PyArray_Descr.npy_hash_t (C type) PyArray_Descr.subarray (C member) PyArray_Descr.subarray.PyArray_ArrayDescr (C type) PyArray_Descr.subarray.PyArray_ArrayDescr.base (C member) PyArray_Descr.subarray.PyArray_ArrayDescr.shape (C member) PyArray_Descr.type (C member) PyArray_Descr.type_num (C member) PyArray_Descr.typeobj (C member) Pyarray_DescrAlignConverter (C function) Pyarray_DescrAlignConverter2 (C function) PyArray_DescrCheck (C function) PyArray_DescrConverter (C function) PyArray_DescrConverter2 (C function) PyArray_DescrFromObject (C function) PyArray_DescrFromScalar (C function) PyArray_DescrFromType (C function) PyArray_DescrNew (C function) PyArray_DescrNewByteorder (C function) PyArray_DescrNewFromType (C function) PyArray_Diagonal (C function) PyArray_DIM (C function) PyArray_DIMS (C function) PyArray_Dims (C type) PyArray_Dims.len (C member) PyArray_Dims.ptr (C member) PyArray_DiscardWritebackIfCopy (C function) PyArray_DTYPE (C function) PyArray_Dump (C function) PyArray_Dumps (C function) PyArray_EinsteinSum (C function) PyArray_EMPTY (C function) PyArray_Empty (C function) PyArray_ENABLEFLAGS (C function) PyArray_EnsureArray (C function) PyArray_EquivArrTypes (C function) PyArray_EquivByteorders (C function) PyArray_EquivTypenums (C function) PyArray_EquivTypes (C function) PyArray_FailUnlessWriteable (C function) PyArray_FieldNames (C function) PyArray_FillObjectArray (C function) PyArray_FILLWBYTE (C function) PyArray_FillWithScalar (C function) PyArray_FinalizeFunc (C function) PyArray_FLAGS (C function) PyArray_Flatten (C function) PyArray_Free (C function) PyArray_free (C function) PyArray_FROM_O (C function) PyArray_FROM_OF (C function) PyArray_FROM_OT (C function) PyArray_FROM_OTF (C function) PyArray_FROMANY (C function) PyArray_FromAny (C function) PyArray_FromAny.NPY_ARRAY_ALIGNED (C macro) PyArray_FromAny.NPY_ARRAY_BEHAVED (C macro) PyArray_FromAny.NPY_ARRAY_C_CONTIGUOUS (C macro) PyArray_FromAny.NPY_ARRAY_CARRAY (C macro) PyArray_FromAny.NPY_ARRAY_CARRAY_RO (C macro) PyArray_FromAny.NPY_ARRAY_DEFAULT (C macro) PyArray_FromAny.NPY_ARRAY_ENSUREARRAY (C macro) PyArray_FromAny.NPY_ARRAY_ENSURECOPY (C macro) PyArray_FromAny.NPY_ARRAY_F_CONTIGUOUS (C macro) PyArray_FromAny.NPY_ARRAY_FARRAY (C macro) PyArray_FromAny.NPY_ARRAY_FARRAY_RO (C macro) PyArray_FromAny.NPY_ARRAY_FORCECAST (C macro) PyArray_FromAny.NPY_ARRAY_WRITEABLE (C macro) PyArray_FromAny.NPY_ARRAY_WRITEBACKIFCOPY (C macro) PyArray_FromArray (C function) PyArray_FromArrayAttr (C function) PyArray_FromBuffer (C function) PyArray_FromFile (C function) PyArray_FromInterface (C function) PyArray_FromObject (C function) PyArray_FromScalar (C function) PyArray_FromString (C function) PyArray_FromStructInterface (C function) PyArray_GetCastFunc (C function) PyArray_GETCONTIGUOUS (C function) PyArray_GetEndianness (C function) PyArray_GetEndianness.NPY_CPU_BIG (C macro) PyArray_GetEndianness.NPY_CPU_LITTLE (C macro) PyArray_GetEndianness.NPY_CPU_UNKNOWN_ENDIAN (C macro) PyArray_GetField (C function) PyArray_GETITEM (C function) PyArray_GetNDArrayCFeatureVersion (C function) PyArray_GetNDArrayCVersion (C function) PyArray_GetNumericOps (C function) PyArray_GetPriority (C function) PyArray_GetPtr (C function) PyArray_GETPTR1 (C function) PyArray_GETPTR2 (C function) PyArray_GETPTR3 (C function) PyArray_GETPTR4 (C function) PyArray_HasArrayInterface (C function) PyArray_HasArrayInterfaceType (C function) PyArray_HASFIELDS (C function) PyArray_INCREF (C function) PyArray_InitArrFuncs (C function) PyArray_InnerProduct (C function) PyArray_IntpConverter (C function) PyArray_IntpFromSequence (C function) PyArray_IS_C_CONTIGUOUS (C function) PyArray_IS_F_CONTIGUOUS (C function) PyArray_ISALIGNED (C function) PyArray_IsAnyScalar (C function) PyArray_ISBEHAVED (C function) PyArray_ISBEHAVED_RO (C function) PyArray_ISBOOL (C function) PyArray_ISBYTESWAPPED (C function) PyArray_ISCARRAY (C function) PyArray_ISCARRAY_RO (C function) PyArray_ISCOMPLEX (C function) PyArray_ISEXTENDED (C function) PyArray_ISFARRAY (C function) PyArray_ISFARRAY_RO (C function) PyArray_ISFLEXIBLE (C function) PyArray_ISFLOAT (C function) PyArray_ISFORTRAN (C function) PyArray_ISINTEGER (C function) PyArray_ISNOTSWAPPED (C function) PyArray_ISNUMBER (C function) PyArray_ISOBJECT (C function) PyArray_ISONESEGMENT (C function) PyArray_ISPYTHON (C function) PyArray_IsPythonNumber (C function) PyArray_IsPythonScalar (C function) PyArray_IsScalar (C macro) PyArray_ISSIGNED (C function) PyArray_ISSTRING (C function) PyArray_ISUNSIGNED (C function) PyArray_ISUSERDEF (C function) PyArray_ISWRITEABLE (C function) PyArray_IsZeroDim (C function) PyArray_Item_INCREF (C function) PyArray_Item_XDECREF (C function) PyArray_ITEMSIZE (C function) PyArray_ITER_DATA (C function) PyArray_ITER_GOTO (C function) PyArray_ITER_GOTO1D (C function) PyArray_ITER_NEXT (C function) PyArray_ITER_NOTDONE (C function) PyArray_ITER_RESET (C function) PyArray_IterAllButAxis (C function) PyArray_IterNew (C function) PyArray_LexSort (C function) PyArray_malloc (C function) PyArray_MapIterArray (C function) PyArray_MapIterArrayCopyIfOverlap (C function) PyArray_MapIterNext (C function) PyArray_MapIterSwapAxes (C function) PyArray_MatrixProduct (C function) PyArray_MatrixProduct2 (C function) PyArray_Max (C function) PyArray_MAX (C macro) PyArray_Mean (C function) PyArray_Min (C function) PyArray_MIN (C macro) PyArray_MinScalarType (C function) PyArray_MoveInto (C function) PyArray_MultiIter_DATA (C function) PyArray_MultiIter_GOTO (C function) PyArray_MultiIter_GOTO1D (C function) PyArray_MultiIter_NEXT (C function) PyArray_MultiIter_NEXTi (C function) PyArray_MultiIter_NOTDONE (C function) PyArray_MultiIter_RESET (C function) PyArray_MultiIterNew (C function) PyArray_MultiplyIntList (C function) PyArray_MultiplyList (C function) PyArray_NBYTES (C function) PyArray_NDIM (C function) PyArray_NeighborhoodIterNew (C function) PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_CIRCULAR_PADDING (C macro) PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING (C macro) PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_MIRROR_PADDING (C macro) PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_ONE_PADDING (C macro) PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_ZERO_PADDING (C macro) PyArray_New (C function) PyArray_NewCopy (C function) PyArray_NewFromDescr (C function) PyArray_NewLikeArray (C function) PyArray_Newshape (C function) PyArray_Nonzero (C function) PyArray_ObjectType (C function) PyArray_One (C function) PyArray_OrderConverter (C function) PyArray_OutputConverter (C function) PyArray_Partition (C function) PyArray_Prod (C function) PyArray_PromoteTypes (C function) PyArray_Ptp (C function) PyArray_PutMask (C function) PyArray_PutTo (C function) PyArray_PyIntAsInt (C function) PyArray_PyIntAsIntp (C function) PyArray_Ravel (C function) PyArray_realloc (C function) PyArray_realloc.NPY_USE_PYMEM (C macro) PyArray_REFCOUNT (C function) PyArray_RegisterCanCast (C function) PyArray_RegisterCastFunc (C function) PyArray_RegisterDataType (C function) PyArray_RemoveSmallest (C function) PyArray_Repeat (C function) PyArray_Reshape (C function) PyArray_Resize (C function) PyArray_ResolveWritebackIfCopy (C function) PyArray_ResultType (C function) PyArray_Return (C function) PyArray_Round (C function) PyArray_SAMESHAPE (C function) PyArray_Scalar (C function) PyArray_ScalarAsCtype (C function) PyArray_ScalarKind (C function) PyArray_SearchsideConverter (C function) PyArray_SearchSorted (C function) PyArray_SetBaseObject (C function) PyArray_SetField (C function) PyArray_SETITEM (C function) PyArray_SetNumericOps (C function) PyArray_SetStringFunction (C function) PyArray_SetWritebackIfCopyBase (C function) PyArray_SHAPE (C function) PyArray_SimpleNew (C function) PyArray_SimpleNewFromData (C function) PyArray_SimpleNewFromDescr (C function) PyArray_SIZE (C function) PyArray_Size (C function) PyArray_Sort (C function) PyArray_SortkindConverter (C function) PyArray_Squeeze (C function) PyArray_Std (C function) PyArray_STRIDE (C function) PyArray_STRIDES (C function) PyArray_Sum (C function) PyArray_SwapAxes (C function) PyArray_TakeFrom (C function) PyArray_ToFile (C function) PyArray_ToList (C function) PyArray_ToScalar (C function) PyArray_ToString (C function) PyArray_Trace (C function) PyArray_Transpose (C function) PyArray_TYPE (C function) PyArray_Type (C var) PyArray_TypeNumFromName (C function) PyArray_TypeObjectFromType (C function) PyArray_TypestrConvert (C function) PyArray_UpdateFlags (C function) PyArray_ValidType (C function) PyArray_View (C function) PyArray_Where (C function) PyArray_XDECREF (C function) PyArray_Zero (C function) PyArray_ZEROS (C function) PyArray_Zeros (C function) PyArrayDescr_Type (C var) PyArrayFlags_Type (C var) PyArrayFlagsObject (C type) PyArrayInterface (C type) PyArrayInterface.data (C member) PyArrayInterface.descr (C member) PyArrayInterface.flags (C member) PyArrayInterface.itemsize (C member) PyArrayInterface.nd (C member) PyArrayInterface.shape (C member) PyArrayInterface.strides (C member) PyArrayInterface.two (C member) PyArrayInterface.typekind (C member) PyArrayIter_Check (C function) PyArrayIter_Type (C var) PyArrayIterObject (C type) PyArrayIterObject.ao (C member) PyArrayIterObject.backstrides (C member) PyArrayIterObject.contiguous (C member) PyArrayIterObject.coordinates (C member) PyArrayIterObject.dataptr (C member) PyArrayIterObject.dims_m1 (C member) PyArrayIterObject.factors (C member) PyArrayIterObject.index (C member) PyArrayIterObject.nd_m1 (C member) PyArrayIterObject.size (C member) PyArrayIterObject.strides (C member) PyArrayMapIter_Type (C var) PyArrayMapIterObject (C type) PyArrayMultiIter_Type (C var) PyArrayMultiIterObject (C type) PyArrayMultiIterObject.dimensions (C member) PyArrayMultiIterObject.index (C member) PyArrayMultiIterObject.iters (C member) PyArrayMultiIterObject.nd (C member) PyArrayMultiIterObject.numiter (C member) PyArrayMultiIterObject.size (C member) PyArrayNeighborhoodIter_Next (C function) PyArrayNeighborhoodIter_Reset (C function) PyArrayNeighborhoodIter_Type (C var) PyArrayNeighborhoodIterObject (C type) PyArrayObject (C type) PyDataMem_EventHookFunc (C function) PyDataMem_FREE (C function) PyDataMem_GetHandler (C function) PyDataMem_Handler (C type) PyDataMem_NEW (C function) PyDataMem_RENEW (C function) PyDataMem_SetEventHook (C function) PyDataMem_SetHandler (C function) PyDataType_FLAGCHK (C function) PyDataType_HASFIELDS (C function) PyDataType_ISBOOL (C function) PyDataType_ISCOMPLEX (C function) PyDataType_ISEXTENDED (C function) PyDataType_ISFLEXIBLE (C function) PyDataType_ISFLOAT (C function) PyDataType_ISINTEGER (C function) PyDataType_ISNUMBER (C function) PyDataType_ISOBJECT (C function) PyDataType_ISPYTHON (C function) PyDataType_ISSIGNED (C function) PyDataType_ISSTRING (C function) PyDataType_ISUNSIGNED (C function) PyDataType_ISUNSIZED (C function) PyDataType_ISUSERDEF (C function) PyDataType_REFCHK (C function) PyDimMem_FREE (C function) PyDimMem_NEW (C function) PyDimMem_RENEW (C function) PyModule_AddIntConstant (C function) PyModule_AddObject (C function) PyModule_AddStringConstant (C function) Python Enhancement Proposals PEP 3118, [1], [2] PEP 440 PEP 465, [1] PEP 484 PEP 585, [1], [2], [3] PEP 646, [1] PyTypeNum_ISBOOL (C function) PyTypeNum_ISCOMPLEX (C function) PyTypeNum_ISEXTENDED (C function) PyTypeNum_ISFLEXIBLE (C function) PyTypeNum_ISFLOAT (C function) PyTypeNum_ISINTEGER (C function) PyTypeNum_ISNUMBER (C function) PyTypeNum_ISOBJECT (C function) PyTypeNum_ISPYTHON (C function) PyTypeNum_ISSIGNED (C function) PyTypeNum_ISSTRING (C function) PyTypeNum_ISUNSIGNED (C function) PyTypeNum_ISUSERDEF (C function) PyUFunc_checkfperr (C function) PyUFunc_clearfperr (C function) PyUFunc_D_D (C function) PyUFunc_d_d (C function) PyUFunc_DD_D (C function) PyUFunc_dd_d (C function) PyUFunc_e_e (C function) PyUFunc_e_e_As_d_d (C function) PyUFunc_e_e_As_f_f (C function) PyUFunc_ee_e (C function) PyUFunc_ee_e_As_dd_d (C function) PyUFunc_ee_e_As_ff_f (C function) PyUFunc_F_F (C function) PyUFunc_f_f (C function) PyUFunc_F_F_As_D_D (C function) PyUFunc_f_f_As_d_d (C function) PyUFunc_FF_F (C function) PyUFunc_ff_f (C function) PyUFunc_FF_F_As_DD_D (C function) PyUFunc_ff_f_As_dd_d (C function) PyUFunc_FromFuncAndData (C function) PyUFunc_FromFuncAndDataAndSignature (C function) PyUFunc_FromFuncAndDataAndSignatureAndIdentity (C function) PyUFunc_G_G (C function) PyUFunc_g_g (C function) PyUFunc_GetPyValues (C function) PyUFunc_GG_G (C function) PyUFunc_gg_g (C function) PyUFunc_IdentityValue (C macro) PyUFunc_Loop1d (C type) PyUFunc_MinusOne (C macro) PyUFunc_None (C macro) PyUFunc_O_O (C function) PyUFunc_O_O_method (C function) PyUFunc_On_Om (C function) PyUFunc_On_Om.PyUFunc_PyFuncData (C type) PyUFunc_One (C macro) PyUFunc_OO_O (C function) PyUFunc_OO_O_method (C function) PyUFunc_RegisterLoopForDescr (C function) PyUFunc_RegisterLoopForType (C function) PyUFunc_ReorderableNone (C macro) PyUFunc_ReplaceLoopBySignature (C function) PyUFunc_Type (C var) PyUFunc_Zero (C macro) PyUFuncGenericFunction (C type) PyUFuncGenericFunction.loopfunc (C function) PyUFuncObject (C type) PyUFuncObject.core_dim_flags (C member) PyUFuncObject.core_dim_ixs (C member) PyUFuncObject.core_dim_sizes (C member) PyUFuncObject.core_enabled (C member) PyUFuncObject.core_num_dim_ix (C member) PyUFuncObject.core_num_dims (C member) PyUFuncObject.core_offsets (C member) PyUFuncObject.core_signature (C member) PyUFuncObject.data (C member) PyUFuncObject.doc (C member) PyUFuncObject.functions (C member) PyUFuncObject.identity (C member) PyUFuncObject.identity_value (C member) PyUFuncObject.iter_flags (C member) PyUFuncObject.legacy_inner_loop_selector (C member) PyUFuncObject.name (C member) PyUFuncObject.nargs (C member) PyUFuncObject.nin (C member) PyUFuncObject.nout (C member) PyUFuncObject.ntypes (C member) PyUFuncObject.obj (C member) PyUFuncObject.op_flags (C member) PyUFuncObject.ptr (C member) PyUFuncObject.reserved1 (C member) PyUFuncObject.reserved2 (C member) PyUFuncObject.type_resolver (C member) PyUFuncObject.types (C member) PyUFuncObject.userloops (C member) PZERO (in module numpy) Q quantile() (in module numpy) R r (numpy.poly1d property) r_ (in module numpy) rad2deg (in module numpy) radians (in module numpy) rand() (numpy.random.RandomState method) randint() (numpy.random.RandomState method) randn() (numpy.random.RandomState method) random() (numpy.random.Generator method) random.beta() (in module numpy) random.binomial() (in module numpy) random.bytes() (in module numpy) random.chisquare() (in module numpy) random.choice() (in module numpy) random.dirichlet() (in module numpy) random.exponential() (in module numpy) random.f() (in module numpy) random.gamma() (in module numpy) random.geometric() (in module numpy) random.get_state() (in module numpy) random.gumbel() (in module numpy) random.hypergeometric() (in module numpy) random.laplace() (in module numpy) random.logistic() (in module numpy) random.lognormal() (in module numpy) random.logseries() (in module numpy) random.multinomial() (in module numpy) random.multivariate_normal() (in module numpy) random.negative_binomial() (in module numpy) random.noncentral_chisquare() (in module numpy) random.noncentral_f() (in module numpy) random.normal() (in module numpy) random.pareto() (in module numpy) random.permutation() (in module numpy) random.poisson() (in module numpy) random.power() (in module numpy) random.rand() (in module numpy) random.randint() (in module numpy) random.randn() (in module numpy) random.random() (in module numpy) random.random_integers() (in module numpy) random.random_sample() (in module numpy) random.ranf() (in module numpy) random.rayleigh() (in module numpy) random.sample() (in module numpy) random.seed() (in module numpy) random.set_state() (in module numpy) random.shuffle() (in module numpy) random.standard_cauchy() (in module numpy) random.standard_exponential() (in module numpy) random.standard_gamma() (in module numpy) random.standard_normal() (in module numpy) random.standard_t() (in module numpy) random.triangular() (in module numpy) random.uniform() (in module numpy) random.vonmises() (in module numpy) random.wald() (in module numpy) random.weibull() (in module numpy) random.zipf() (in module numpy) random_beta (C function) random_binomial (C function) random_bounded_uint64 (C function) random_chisquare (C function) random_exponential (C function) random_f (C function) random_gamma (C function) random_gamma_f (C function) random_geometric (C function) random_geometric_inversion (C function) random_geometric_search (C function) random_gumbel (C function) random_hypergeometric (C function) random_integers() (numpy.random.RandomState method) random_interval (C function) random_laplace (C function) random_logistic (C function) random_lognormal (C function) random_logseries (C function) random_multinomial (C function) random_multivariate_hypergeometric_count (C function) random_multivariate_hypergeometric_marginals (C function) random_negative_binomial (C function) random_noncentral_chisquare (C function) random_noncentral_f (C function) random_normal (C function) random_pareto (C function) random_poisson (C function) random_positive_int (C function) random_positive_int32 (C function) random_positive_int64 (C function) random_power (C function) random_raw() (numpy.random.BitGenerator method) random_rayleigh (C function) random_sample() (numpy.random.RandomState method) random_standard_cauchy (C function) random_standard_exponential (C function) random_standard_exponential_f (C function) random_standard_exponential_fill (C function) random_standard_exponential_fill_f (C function) random_standard_exponential_inv_fill (C function) random_standard_exponential_inv_fill_f (C function) random_standard_gamma (C function) random_standard_gamma_f (C function) random_standard_normal (C function) random_standard_normal_f (C function) random_standard_normal_fill (C function) random_standard_normal_fill_f (C function) random_standard_t (C function) random_standard_uniform (C function) random_standard_uniform_f (C function) random_standard_uniform_fill (C function) random_standard_uniform_fill_f (C function) random_triangular (C function) random_uint (C function) random_uniform (C function) random_vonmises (C function) random_wald (C function) random_weibull (C function) random_zipf (C function) RandomState (class in numpy.random) RankWarning ravel ravel() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) ravel_multi_index() (in module numpy) rayleigh() (numpy.random.Generator method) (numpy.random.RandomState method) real (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.ma.masked_array property) (numpy.ma.MaskedArray property) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) real() (in module numpy) real_if_close() (in module numpy) rec_append_fields() (in module numpy.lib.recfunctions) rec_drop_fields() (in module numpy.lib.recfunctions) rec_join() (in module numpy.lib.recfunctions) recarray (class in numpy) reciprocal (in module numpy) record (class in numpy) record array record() (numpy.testing.suppress_warnings method) recordmask (numpy.ma.masked_array property) (numpy.ma.MaskedArray attribute) recursive_fill_fields() (in module numpy.lib.recfunctions) red_text() (in module numpy.distutils.misc_util) reduce ufunc methods reduce() (numpy.ufunc method) reduceat ufunc methods reduceat() (numpy.ufunc method) reference counting, [1] remainder (in module numpy) remove_axis() (numpy.nditer method) remove_multi_index() (numpy.nditer method) rename_fields() (in module numpy.lib.recfunctions) repack_fields() (in module numpy.lib.recfunctions) repeat() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) replace() (numpy.char.chararray method) (numpy.chararray method) report() (numpy.distutils.ccompiler_opt.CCompilerOpt method) require() (in module numpy) require_fields() (in module numpy.lib.recfunctions) reset() (numpy.broadcast method) (numpy.nditer method) reshape() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) resize() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) resolve_dtypes() (numpy.ufunc method) result_type() (in module numpy) rfind() (numpy.char.chararray method) (numpy.chararray method) right_shift (in module numpy) rindex() (numpy.char.chararray method) (numpy.chararray method) rint (in module numpy) rjust() (numpy.char.chararray method) (numpy.chararray method) roll() (in module numpy) rollaxis() (in module numpy) roots (numpy.poly1d property) roots() (in module numpy) (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) rot90() (in module numpy) round() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) row-major, [1] row_stack() (in module numpy) rpartition() (numpy.char.chararray method) (numpy.chararray method) rsplit() (numpy.char.chararray method) (numpy.chararray method) rstrip() (numpy.char.chararray method) (numpy.chararray method) run_main() (in module numpy.f2py) S s_ (in module numpy) sanitize_cxx_flags() (in module numpy.distutils.misc_util) save() (in module numpy) savetxt() (in module numpy) savez() (in module numpy) savez_compressed() (in module numpy) scalar dtype sctype2char() (in module numpy) searchsorted() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) seed() (numpy.random.RandomState method) seed_seq (numpy.random.BitGenerator attribute) SeedSequence (class in numpy.random) select() (in module numpy) set_fill_value() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) set_printoptions() (in module numpy) set_state() (numpy.random.RandomState method) set_string_function() (in module numpy) setbufsize() (in module numpy) setdiff1d() (in module numpy) seterr() (in module numpy) seterrcall() (in module numpy) seterrobj() (in module numpy) setfield() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) setflags() (numpy.char.chararray method) (numpy.chararray method) (numpy.generic method) (numpy.ma.masked_array method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) setitem ndarray special methods setxor1d() (in module numpy) SFC64 (class in numpy.random) shape (numpy.broadcast attribute) (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.dtype attribute) (numpy.generic attribute) (numpy.lib.Arrayterator property) (numpy.ma.masked_array property) (numpy.ma.MaskedArray property) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.nditer attribute) (numpy.recarray attribute) (numpy.record attribute) shape() (in module numpy) sharedmask (numpy.ma.masked_array property) (numpy.ma.MaskedArray attribute) shares_memory() (in module numpy) short (class in numpy) show_config() (in module numpy) show_runtime() (in module numpy) shrink_mask() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) shuffle() (numpy.random.Generator method) (numpy.random.RandomState method) sign (in module numpy) signature (numpy.ufunc attribute) signbit (in module numpy) signedinteger (class in numpy) sin (in module numpy) sinc() (in module numpy) single (class in numpy) single-segment singlecomplex (in module numpy) sinh (in module numpy) SIP size (numpy.broadcast attribute) (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) slicing smallest_normal (numpy.finfo property) soften_mask() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) sort() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) sort_complex() (in module numpy) source() (in module numpy) spacing (in module numpy) spawn() (numpy.random.BitGenerator method) (numpy.random.Generator method) (numpy.random.SeedSequence method) spawn_key (numpy.random.SeedSequence attribute) special methods getitem, ndarray setitem, ndarray split() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) splitlines() (numpy.char.chararray method) (numpy.chararray method) sqrt (in module numpy) square (in module numpy) squeeze() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.generic method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) stack() (in module numpy) stack_arrays() (in module numpy.lib.recfunctions) standard_cauchy() (numpy.random.Generator method) (numpy.random.RandomState method) standard_exponential() (numpy.random.Generator method) (numpy.random.RandomState method) standard_gamma() (numpy.random.Generator method) (numpy.random.RandomState method) standard_normal() (numpy.random.Generator method) (numpy.random.RandomState method) standard_t() (numpy.random.Generator method) (numpy.random.RandomState method) startswith() (numpy.char.chararray method) (numpy.chararray method) state (numpy.random.BitGenerator attribute) (numpy.random.MT19937 attribute) (numpy.random.PCG64 attribute) (numpy.random.PCG64DXSM attribute) (numpy.random.Philox attribute) (numpy.random.SeedSequence attribute) (numpy.random.SFC64 attribute) std() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) str (numpy.dtype attribute) str_ (class in numpy) stride, [1] strides (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.ma.masked_array attribute) (numpy.ma.MaskedArray attribute) (numpy.ma.MaskType attribute) (numpy.matrix attribute) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) string_ (in module numpy) strip() (numpy.char.chararray method) (numpy.chararray method) structured array structured data type structured_to_unstructured() (in module numpy.lib.recfunctions) sub-array dtype, [1] subarray subarray data type subdtype (numpy.dtype attribute) subtract (in module numpy) subtyping ndarray, [1] sum() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) suppress_warnings (class in numpy.testing) swapaxes() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) swapcase() (numpy.char.chararray method) (numpy.chararray method) swig symbol (numpy.polynomial.chebyshev.Chebyshev property) (numpy.polynomial.hermite.Hermite property) (numpy.polynomial.hermite_e.HermiteE property) (numpy.polynomial.laguerre.Laguerre property) (numpy.polynomial.legendre.Legendre property) (numpy.polynomial.polynomial.Polynomial property) T T (numpy.char.chararray attribute) (numpy.chararray attribute) (numpy.generic attribute) (numpy.ma.masked_array property) (numpy.ma.MaskedArray property) (numpy.ma.MaskType attribute) (numpy.matrix property) (numpy.memmap attribute) (numpy.ndarray attribute) (numpy.recarray attribute) (numpy.record attribute) take() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) take_along_axis() (in module numpy) tan (in module numpy) tanh (in module numpy) tensordot() (in module numpy) terminal_has_colors() (in module numpy.distutils.misc_util) test() (in module numpy) testing.assert_() (in module numpy) testing.assert_allclose() (in module numpy) testing.assert_almost_equal() (in module numpy) testing.assert_approx_equal() (in module numpy) testing.assert_array_almost_equal() (in module numpy) testing.assert_array_almost_equal_nulp() (in module numpy) testing.assert_array_equal() (in module numpy) testing.assert_array_less() (in module numpy) testing.assert_array_max_ulp() (in module numpy) testing.assert_equal() (in module numpy) testing.assert_no_gc_cycles() (in module numpy) testing.assert_no_warnings() (in module numpy) testing.assert_raises() (in module numpy) testing.assert_raises_regex() (in module numpy) testing.assert_string_equal() (in module numpy) testing.assert_warns() (in module numpy) testing.decorate_methods() (in module numpy) testing.measure() (in module numpy) testing.overrides.allows_array_function_override() (in module numpy) testing.overrides.allows_array_ufunc_override() (in module numpy) testing.overrides.get_overridable_numpy_array_functions() (in module numpy) testing.overrides.get_overridable_numpy_ufuncs() (in module numpy) testing.print_assert_equal() (in module numpy) testing.rundocs() (in module numpy) tile() (in module numpy) timedelta64 (class in numpy) tiny (numpy.finfo property) title title() (numpy.char.chararray method) (numpy.chararray method) tobytes() (numpy.char.chararray method) (numpy.chararray method) (numpy.lib.user_array.container method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) todict() (numpy.distutils.misc_util.Configuration method) tofile() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) toflex() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) tolist() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) torecords() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) tostring() (numpy.char.chararray method) (numpy.chararray method) (numpy.lib.user_array.container method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) trace() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) translate() (numpy.char.chararray method) (numpy.chararray method) transpose() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) trapz() (in module numpy) tri() (in module numpy) triangular() (numpy.random.Generator method) (numpy.random.RandomState method) tril() (in module numpy) tril_indices() (in module numpy) tril_indices_from() (in module numpy) trim() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) trim_zeros() (in module numpy) triu() (in module numpy) triu_indices() (in module numpy) triu_indices_from() (in module numpy) true_divide (in module numpy) trunc (in module numpy) truncate() (numpy.polynomial.chebyshev.Chebyshev method) (numpy.polynomial.hermite.Hermite method) (numpy.polynomial.hermite_e.HermiteE method) (numpy.polynomial.laguerre.Laguerre method) (numpy.polynomial.legendre.Legendre method) (numpy.polynomial.polynomial.Polynomial method) try_dispatch() (numpy.distutils.ccompiler_opt.CCompilerOpt method) type (numpy.dtype attribute) typename() (in module numpy) types (numpy.ufunc attribute) U ubyte (class in numpy) ufunc, [1], [2] adding new, [1], [2], [3], [4] attributes C-API, [1] casting rules keyword arguments methods methods accumulate methods reduce methods reduceat ufunc (class in numpy) UFUNC_CORE_DIM_CAN_IGNORE (C macro) UFUNC_CORE_DIM_SIZE_INFERRED (C macro) UFUNC_ERR_CALL (C macro) UFUNC_ERR_IGNORE (C macro) UFUNC_ERR_RAISE (C macro) UFUNC_ERR_WARN (C macro) UFUNC_FPE_DIVIDEBYZERO (C macro) UFUNC_FPE_INVALID (C macro) UFUNC_FPE_OVERFLOW (C macro) UFUNC_FPE_UNDERFLOW (C macro) UFUNC_MASK_DIVIDEBYZERO (C macro) UFUNC_MASK_INVALID (C macro) UFUNC_MASK_OVERFLOW (C macro) UFUNC_MASK_UNDERFLOW (C macro) UFUNC_SHIFT_DIVIDEBYZERO (C macro) UFUNC_SHIFT_INVALID (C macro) UFUNC_SHIFT_OVERFLOW (C macro) UFUNC_SHIFT_UNDERFLOW (C macro) uint (class in numpy) uint16 (in module numpy) uint32 (in module numpy) uint64 (in module numpy) uint8 (in module numpy) uintc (class in numpy) uintp (in module numpy) ulonglong (class in numpy) unicode_ (in module numpy) uniform() (numpy.random.Generator method) (numpy.random.RandomState method) union1d() (in module numpy) unique() (in module numpy) unpackbits() (in module numpy) unravel_index() (in module numpy) unshare_mask() (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) unsignedinteger (class in numpy) unstructured_to_structured() (in module numpy.lib.recfunctions) unwrap() (in module numpy) upper() (numpy.char.chararray method) (numpy.chararray method) user_array ushort (class in numpy) V value (numpy.nditer attribute) vander() (in module numpy) var() (in module numpy) (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) variable (numpy.poly1d property) vdot() (in module numpy) vectorization vectorize (class in numpy) view, [1] ndarray view() (numpy.char.chararray method) (numpy.chararray method) (numpy.ma.masked_array method) (numpy.ma.MaskedArray method) (numpy.ma.MaskType method) (numpy.matrix method) (numpy.memmap method) (numpy.ndarray method) (numpy.recarray method) (numpy.record method) void (class in numpy) vonmises() (numpy.random.Generator method) (numpy.random.RandomState method) vsplit() (in module numpy) vstack() (in module numpy) W wald() (numpy.random.Generator method) (numpy.random.RandomState method) weekmask (numpy.busdaycalendar attribute) weibull() (numpy.random.Generator method) (numpy.random.RandomState method) where() (in module numpy) who() (in module numpy) window (numpy.polynomial.chebyshev.Chebyshev attribute) (numpy.polynomial.hermite.Hermite attribute) (numpy.polynomial.hermite_e.HermiteE attribute) (numpy.polynomial.laguerre.Laguerre attribute) (numpy.polynomial.legendre.Legendre attribute) (numpy.polynomial.polynomial.Polynomial attribute) WITH_THREADS (C macro) Y yellow_text() (in module numpy.distutils.misc_util) Z zeros() (in module numpy) zeros_like() (in module numpy) zfill() (numpy.char.chararray method) (numpy.chararray method) zipf() (numpy.random.Generator method) (numpy.random.RandomState method)# numpy.ufunc.outer[#](#numpy-ufunc-outer)
method

ufunc.outer(*A*,*B*,*/*,***kwargs*)[#](#numpy.ufunc.outer)
-
Apply the ufunc

*op*to all pairs (a, b) with a in*A*and b in*B*.Let

`M = A.ndim`
,`N = B.ndim`
. Then the result,*C*, of`op.outer(A, B)`
is an array of dimension M + N such that:\[C[i_0, ..., i_{M-1}, j_0, ..., j_{N-1}] = op(A[i_0, ..., i_{M-1}], B[j_0, ..., j_{N-1}])\]For

*A*and*B*one-dimensional, this is equivalent to:r = empty(len(A),len(B)) for i in range(len(A)): for j in range(len(B)): r[i,j] = op(A[i], B[j]) # op = ufunc in question
Parameters:
-
Returns:
-
**r**ndarray
Output array

See also

`numpy.outer`
A less powerful version of

`np.multiply.outer`
thats all inputs to 1D. This exists primarily for compatibility with old code.`ravel`
`tensordot`
`np.tensordot(a, b, axes=((), ()))`
and`np.multiply.outer(a, b)`
behave same for all dimensions of a and b.
Examples

>>> np.multiply.outer([1, 2, 3], [4, 5, 6]) array([[ 4, 5, 6], [ 8, 10, 12], [12, 15, 18]])
A multi-dimensional example:

>>> A = np.array([[1, 2, 3], [4, 5, 6]]) >>> A.shape (2, 3) >>> B = np.array([[1, 2, 3, 4]]) >>> B.shape (1, 4) >>> C = np.multiply.outer(A, B) >>> C.shape; C (2, 3, 1, 4) array([[[[ 1, 2, 3, 4]], [[ 2, 4, 6, 8]], [[ 3, 6, 9, 12]]], [[[ 4, 8, 12, 16]], [[ 5, 10, 15, 20]], [[ 6, 12, 18, 24]]]])Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Git for development[#](#git-for-development)
These pages describe a general [git](https://git-scm.com/) and [github](https://github.com/numpy/numpy) workflow.

This is not a comprehensive [git](https://git-scm.com/) reference. It’s tailored to the [github](https://github.com/numpy/numpy)
hosting service. You may well find better or quicker ways of getting stuff done
with [git](https://git-scm.com/), but these should get you started.

For general resources for learning [git](https://git-scm.com/) see [Additional Git resources](git_resources.html#git-resources).

Have a look at the [github](https://github.com/numpy/numpy) install help pages available from [github help](https://help.github.com)

Contents:

[Install git](git_intro.html)
[Get the local copy of the code](following_latest.html)
[Updating the code](following_latest.html#updating-the-code)
[Setting up git for NumPy development](development_setup.html)
[Git configuration](configure_git.html)
[Two and three dots in difference specs](dot2_dot3.html)
[Additional Git resources](git_resources.html)Copyright (c) 2005-2023, NumPy Developers.
All rights reserved.
Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:
* Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.
* Redistributions in binary form must reproduce the above
copyright notice, this list of conditions and the following
disclaimer in the documentation and/or other materials provided
with the distribution.
* Neither the name of the NumPy Developers nor the names of any
contributors may be used to endorse or promote products derived
from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Install git[#](#install-git)
Developing with git can be done entirely without github. Git is a distributed
version control system. In order to use git on your machine you must [install
it](https://git-scm.com/downloads).

Developing with git can be done entirely without github. Git is a distributed
version control system. In order to use git on your machine you must [install
it](https://git-scm.com/downloads).# numpy.searchsorted[#](#numpy-searchsorted)
numpy.searchsorted(*a*,*v*,*side='left'*,*sorter=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L1332-L1400)[#](#numpy.searchsorted)
-
Find indices where elements should be inserted to maintain order.

Find the indices into a sorted array

*a*such that, if the corresponding elements in*v*were inserted before the indices, the order of*a*would be preserved.Assuming that

*a*is sorted:*side*returned index

*i*satisfiesleft

`a[i-1] < v <= a[i]`
right

`a[i-1] <= v < a[i]`
Parameters:
-
**a**1-D array_like
Input array. If

*sorter*is None, then it must be sorted in ascending order, otherwise*sorter*must be an array of indices that sort it.
**v**array_like
Values to insert into

*a*.
**side**{‘left’, ‘right’}, optional
If ‘left’, the index of the first suitable location found is given. If ‘right’, return the last such index. If there is no suitable index, return either 0 or N (where N is the length of

*a*).
**sorter**1-D array_like, optional
Optional array of integer indices that sort array a into ascending order. They are typically the result of argsort.

New in version 1.7.0.

Returns:
-
**indices**int or array of ints
Array of insertion points with the same shape as

*v*, or an integer if*v*is a scalar.
Notes

Binary search is used to find the required insertion points.

As of NumPy 1.4.0

works with real/complex arrays containing`searchsorted`
values. The enhanced sort order is documented in`nan`
.`sort`
This function uses the same algorithm as the builtin python

(`bisect.bisect_left`
`side='left'`
) and(`bisect.bisect_right`
`side='right'`
) functions, which is also vectorized in the*v*argument.Examples

>>> np.searchsorted([1,2,3,4,5], 3) 2 >>> np.searchsorted([1,2,3,4,5], 3, side='right') 3 >>> np.searchsorted([1,2,3,4,5], [-10, 10, 2, 3]) array([0, 5, 1, 2])NumPy governance# NumPy project governance and decision-making Summary The Project Governance Consensus-based decision making by the community Steering Council Institutional Partners and Funding Document history Acknowledgements License# Datetime support functions[#](#datetime-support-functions)
|
Convert an array of datetimes into an array of strings.

|
|
Get information about the step size of a date or time type.

|
## Business day functions[#](#business-day-functions)
|
A business day calendar object that efficiently stores information defining valid days for the busday family of functions.

|
|
Calculates which of the given dates are valid days, and which are not.

|
|
First adjusts the date to fall on a valid day according to the

|
|
Counts the number of valid days between

|Window functions# Various windows# bartlett(M) Return the Bartlett window. blackman(M) Return the Blackman window. hamming(M) Return the Hamming window. hanning(M) Return the Hanning window. kaiser(M, beta) Return the Kaiser window.# Set routines[#](#set-routines)
Set operations for arrays based on sorting.

|
## Making proper sets[#](#making-proper-sets)
|
Find the unique elements of an array.

|
## Boolean operations[#](#boolean-operations)
|
Test whether each element of a 1-D array is also present in a second array.

|
|
Find the intersection of two arrays.

|
|
Calculates

|
|
Find the set difference of two arrays.

|
|
Find the set exclusive-or of two arrays.

|
|
Find the union of two arrays.

|# Support for testing overrides (`numpy.testing.overrides`
)[#](#support-for-testing-overrides-numpy-testing-overrides)
`numpy.testing.overrides`
Support for testing custom array container implementations.

## Utility Functions[#](#utility-functions)
Determine if a Numpy function can be overridden via

|
Determine if a function can be overridden via

|
List all numpy ufuncs overridable via

|
List all numpy functions overridable via

|ufunc

numpy.ctypeslib

numpy.fft

numpy.linalg

numpy.matlib

numpy.random

numpy.testing

numpy.testing.overrides

numpy.typing

numpy.distutils

pad(array, pad_width[, mode])

pad

Pad an array.# Array manipulation routines[#](#array-manipulation-routines)
## Basic operations[#](#basic-operations)
|
Copies values from one array to another, broadcasting as necessary.

|
|
Return the shape of an array.

|
## Changing array shape[#](#changing-array-shape)
|
Gives a new shape to an array without changing its data.

|
|
Return a contiguous flattened array.

|
A 1-D iterator over the array.

|
|
Return a copy of the array collapsed into one dimension.

|
## Transpose-like operations[#](#transpose-like-operations)
|
Move axes of an array to new positions.

|
|
Roll the specified axis backwards, until it lies in a given position.

|
|
Interchange two axes of an array.

|
View of the transposed array.

|
|
Returns an array with axes transposed.

|
## Changing number of dimensions[#](#changing-number-of-dimensions)
|
Convert inputs to arrays with at least one dimension.

|
|
View inputs as arrays with at least two dimensions.

|
|
View inputs as arrays with at least three dimensions.

|
Produce an object that mimics broadcasting.

|
|
Broadcast an array to a new shape.

|
|
Broadcast any number of arrays against each other.

|
|
Expand the shape of an array.

|
|
Remove axes of length one from

|
## Changing kind of array[#](#changing-kind-of-array)
|
Convert the input to an array.

|
|
Convert the input to an ndarray, but pass ndarray subclasses through.

|
|
Interpret the input as a matrix.

|
|
Return an array converted to a float type.

|
|
Return an array (ndim >= 1) laid out in Fortran order in memory.

|
|
Return a contiguous array (ndim >= 1) in memory (C order).

|
|
Convert the input to an array, checking for NaNs or Infs.

|
|
Return an ndarray of the provided type that satisfies requirements.

|
## Joining arrays[#](#joining-arrays)
|
Join a sequence of arrays along an existing axis.

|
|
Join a sequence of arrays along a new axis.

|
|
Assemble an nd-array from nested lists of blocks.

|
|
Stack arrays in sequence vertically (row wise).

|
|
Stack arrays in sequence horizontally (column wise).

|
|
Stack arrays in sequence depth wise (along third axis).

|
|
Stack 1-D arrays as columns into a 2-D array.

|
|
Stack arrays in sequence vertically (row wise).

|
## Splitting arrays[#](#splitting-arrays)
|
Split an array into multiple sub-arrays as views into

|
|
Split an array into multiple sub-arrays.

|
|
Split array into multiple sub-arrays along the 3rd axis (depth).

|
|
Split an array into multiple sub-arrays horizontally (column-wise).

|
|
Split an array into multiple sub-arrays vertically (row-wise).

|
## Tiling arrays[#](#tiling-arrays)
|
Construct an array by repeating A the number of times given by reps.

|
|
Repeat each element of an array after themselves

|
## Adding and removing elements[#](#adding-and-removing-elements)
|
Return a new array with sub-arrays along an axis deleted.

|
|
Insert values along the given axis before the given indices.

|
|
Append values to the end of an array.

|
|
Return a new array with the specified shape.

|
|
Trim the leading and/or trailing zeros from a 1-D array or sequence.

|
|
Find the unique elements of an array.

|
## Rearranging elements[#](#rearranging-elements)
|
Reverse the order of elements in an array along the given axis.

|
|
Reverse the order of elements along axis 1 (left/right).

|
|
Reverse the order of elements along axis 0 (up/down).

|
|
Gives a new shape to an array without changing its data.

|
|
Roll array elements along a given axis.

|
|
Rotate an array by 90 degrees in the plane specified by axes.

|# Data type routines[#](#data-type-routines)
|
Returns True if cast between data types can occur according to the casting rule.

|
|
Returns the data type with the smallest size and smallest scalar kind to which both

|
|
For scalar

|
|
Returns the type that results from applying the NumPy type promotion rules to the arguments.

|
|
Return a scalar type which is common to the input arrays.

|
|
Return the scalar dtype or NumPy equivalent of Python type of an object.

|
## Creating data types[#](#creating-data-types)
|
Create a data type object.

|
|
Class to convert formats, names, titles description to a dtype.

|
## Data type information[#](#data-type-information)
|
Machine limits for floating point types.

|
|
Machine limits for integer types.

|
## Data type testing[#](#data-type-testing)
|
Determines whether the given object represents a scalar data-type.

|
|
Returns True if first argument is a typecode lower/equal in type hierarchy.

|
|
Determine if the first argument is a subclass of the second argument.

|
|
Determine if a class is a subclass of a second class.

|
|
Determine common type following standard coercion rules.

|
## Miscellaneous[#](#miscellaneous)
|
Return a description for the given data type code.

|
|
Return the string representation of a scalar dtype.

|
|
Return the character for the minimum-size type to which given types can be safely cast.

|
Return the scalar type of highest precision of the same kind as the input.

|# Statistics[#](#statistics)
## Order statistics[#](#order-statistics)
|
Range of values (maximum - minimum) along an axis.

|
|
Compute the q-th percentile of the data along the specified axis.

|
|
Compute the qth percentile of the data along the specified axis, while ignoring nan values.

|
|
Compute the q-th quantile of the data along the specified axis.

|
|
Compute the qth quantile of the data along the specified axis, while ignoring nan values.

|
## Averages and variances[#](#averages-and-variances)
|
Compute the median along the specified axis.

|
|
Compute the weighted average along the specified axis.

|
|
Compute the arithmetic mean along the specified axis.

|
|
Compute the standard deviation along the specified axis.

|
|
Compute the variance along the specified axis.

|
|
Compute the median along the specified axis, while ignoring NaNs.

|
|
Compute the arithmetic mean along the specified axis, ignoring NaNs.

|
|
Compute the standard deviation along the specified axis, while ignoring NaNs.

|
|
Compute the variance along the specified axis, while ignoring NaNs.

|
## Correlating[#](#correlating)
|
Return Pearson product-moment correlation coefficients.

|
|
Cross-correlation of two 1-dimensional sequences.

|
|
Estimate a covariance matrix, given data and weights.

|
## Histograms[#](#histograms)
|
Compute the histogram of a dataset.

|
|
Compute the bi-dimensional histogram of two data samples.

|
|
Compute the multidimensional histogram of some data.

|
|
Count number of occurrences of each value in array of non-negative ints.

|
|
Function to calculate only the edges of the bins used by the

|
|
Return the indices of the bins to which each value in input array belongs.

|# Matrix library (`numpy.matlib`
)[#](#matrix-library-numpy-matlib)
`numpy.matlib`
This module contains all functions in the [ numpy](index.html#module-numpy) namespace, with
the following replacement functions that return

[instead of](generated/numpy.matrix.html#numpy.matrix)
`matrices`
[.](generated/numpy.ndarray.html#numpy.ndarray)
`ndarrays`
Functions that are also in the numpy namespace and return matrices

|
Interpret the input as a matrix.

|
|
Note

It is no longer recommended to use this class, even for linear

|
|
Interpret the input as a matrix.

|
|
Build a matrix object from a string, nested sequence, or array.

|
Replacement functions in `matlib`

|
Return a new matrix of given shape and type, without initializing entries.

|
|
Return a matrix of given shape and type, filled with zeros.

|
|
Matrix of ones.

|
|
Return a matrix with ones on the diagonal and zeros elsewhere.

|
|
Returns the square identity matrix of given size.

|
|
Repeat a 0-D to 2-D array or matrix MxN times.

|
|
Return a matrix of random values with given shape.

|
|
Return a random matrix with data from the "standard normal" distribution.

|# NumPy 1.20.2 Release Notes[#](#numpy-1-20-2-release-notes)
NumPy 1.20.2 is a bugfix release containing several fixes merged to the main branch after the NumPy 1.20.1 release.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Bas van Beek

Charles Harris

Christoph Gohlke

Mateusz Sokół +

Michael Lamparski

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 20 pull requests were merged for this release.

[#18382](https://github.com/numpy/numpy/pull/18382): MAINT: Update f2py from master.
[#18459](https://github.com/numpy/numpy/pull/18459): BUG:`diagflat`
could overflow on windows or 32-bit platforms
[#18460](https://github.com/numpy/numpy/pull/18460): BUG: Fix refcount leak in f2py`complex_double_from_pyobj`
.
[#18461](https://github.com/numpy/numpy/pull/18461): BUG: Fix tiny memory leaks when`like=`
overrides are used
[#18462](https://github.com/numpy/numpy/pull/18462): BUG: Remove temporary change of descr/flags in VOID functions
[#18469](https://github.com/numpy/numpy/pull/18469): BUG: Segfault in nditer buffer dealloc for Object arrays
[#18485](https://github.com/numpy/numpy/pull/18485): BUG: Remove suspicious type casting
[#18486](https://github.com/numpy/numpy/pull/18486): BUG: remove nonsensical comparison of pointer < 0
[#18487](https://github.com/numpy/numpy/pull/18487): BUG: verify pointer against NULL before using it
[#18488](https://github.com/numpy/numpy/pull/18488): BUG: check if PyArray_malloc succeeded
[#18546](https://github.com/numpy/numpy/pull/18546): BUG: incorrect error fallthrough in nditer
[#18559](https://github.com/numpy/numpy/pull/18559): CI: Backport CI fixes from main.
[#18599](https://github.com/numpy/numpy/pull/18599): MAINT: Add annotations for`dtype.__getitem__`
,*__mul__*and…
[#18611](https://github.com/numpy/numpy/pull/18611): BUG: NameError in numpy.distutils.fcompiler.compaq
[#18612](https://github.com/numpy/numpy/pull/18612): BUG: Fixed`where`
keyword for`np.mean`
&`np.var`
methods
[#18617](https://github.com/numpy/numpy/pull/18617): CI: Update apt package list before Python install
[#18636](https://github.com/numpy/numpy/pull/18636): MAINT: Ensure that re-exported sub-modules are properly annotated
[#18638](https://github.com/numpy/numpy/pull/18638): BUG: Fix ma coercion list-of-ma-arrays if they do not cast to…
[#18661](https://github.com/numpy/numpy/pull/18661): BUG: Fix small valgrind-found issues
[#18671](https://github.com/numpy/numpy/pull/18671): BUG: Fix small issues found with pytest-leaks# NumPy 1.17.3 Release Notes[#](#numpy-1-17-3-release-notes)
This release contains fixes for bugs reported against NumPy 1.17.2 along with a some documentation improvements. The Python versions supported in this release are 3.5-3.8.

Downstream developers should use Cython >= 0.29.13 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

## Highlights[#](#highlights)
Wheels for Python 3.8

Boolean

`matmul`
fixed to use booleans instead of integers.
## Compatibility notes[#](#compatibility-notes)
The seldom used

`PyArray_DescrCheck`
macro has been changed/fixed.
## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Allan Haldane

Charles Harris

Kevin Sheppard

Matti Picus

Ralf Gommers

Sebastian Berg

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 12 pull requests were merged for this release.

[#14456](https://github.com/numpy/numpy/pull/14456): MAINT: clean up pocketfft modules inside numpy.fft namespace.
[#14463](https://github.com/numpy/numpy/pull/14463): BUG: random.hypergeometic assumes npy_long is npy_int64, hung…
[#14502](https://github.com/numpy/numpy/pull/14502): BUG: random: Revert gh-14458 and refix gh-14557.
[#14504](https://github.com/numpy/numpy/pull/14504): BUG: add a specialized loop for boolean matmul.
[#14506](https://github.com/numpy/numpy/pull/14506): MAINT: Update pytest version for Python 3.8
[#14512](https://github.com/numpy/numpy/pull/14512): DOC: random: fix doc linking, was referencing private submodules.
[#14513](https://github.com/numpy/numpy/pull/14513): BUG,MAINT: Some fixes and minor cleanup based on clang analysis
[#14515](https://github.com/numpy/numpy/pull/14515): BUG: Fix randint when range is 2**32
[#14519](https://github.com/numpy/numpy/pull/14519): MAINT: remove the entropy c-extension module
[#14563](https://github.com/numpy/numpy/pull/14563): DOC: remove note about Pocketfft license file (non-existing here).
[#14578](https://github.com/numpy/numpy/pull/14578): BUG: random: Create a legacy implementation of random.binomial.
[#14687](https://github.com/numpy/numpy/pull/14687): BUG: properly define PyArray_DescrCheck# NumPy 1.22.2 Release Notes[#](#numpy-1-22-2-release-notes)
The NumPy 1.22.2 is maintenance release that fixes bugs discovered after the 1.22.1 release. Notable fixes are:

Several build related fixes for downstream projects and other platforms.

Various Annotation fixes/additions.

Numpy wheels for Windows will use the 1.41 tool chain, fixing downstream link problems for projects using NumPy provided libraries on Windows.

Deal with CVE-2021-41495 complaint.

The Python versions supported for this release are 3.8-3.10.

## Contributors[#](#contributors)
A total of 14 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Andrew J. Hesford +

Bas van Beek

Brénainn Woodsend +

Charles Harris

Hood Chatham

Janus Heide +

Leo Singer

Matti Picus

Mukulika Pahari

Niyas Sait

Pearu Peterson

Ralf Gommers

Sebastian Berg

Serge Guelton

## Pull requests merged[#](#pull-requests-merged)
A total of 21 pull requests were merged for this release.

[#20842](https://github.com/numpy/numpy/pull/20842): BLD: Add NPY_DISABLE_SVML env var to opt out of SVML
[#20843](https://github.com/numpy/numpy/pull/20843): BUG: Fix build of third party extensions with Py_LIMITED_API
[#20844](https://github.com/numpy/numpy/pull/20844): TYP: Fix pyright being unable to infer the`real`
and`imag`
…
[#20845](https://github.com/numpy/numpy/pull/20845): BUG: Fix comparator function signatures
[#20906](https://github.com/numpy/numpy/pull/20906): BUG: Avoid importing`numpy.distutils`
on import numpy.testing
[#20907](https://github.com/numpy/numpy/pull/20907): MAINT: remove outdated mingw32 fseek support
[#20908](https://github.com/numpy/numpy/pull/20908): TYP: Relax the return type of`np.vectorize`
[#20909](https://github.com/numpy/numpy/pull/20909): BUG: fix f2py’s define for threading when building with Mingw
[#20910](https://github.com/numpy/numpy/pull/20910): BUG: distutils: fix building mixed C/Fortran extensions
[#20912](https://github.com/numpy/numpy/pull/20912): DOC,TST: Fix Pandas code example as per new release
[#20935](https://github.com/numpy/numpy/pull/20935): TYP, MAINT: Add annotations for`flatiter.__setitem__`
[#20936](https://github.com/numpy/numpy/pull/20936): MAINT, TYP: Added missing where typehints in`fromnumeric.pyi`
[#20937](https://github.com/numpy/numpy/pull/20937): BUG: Fix build_ext interaction with non numpy extensions
[#20938](https://github.com/numpy/numpy/pull/20938): BUG: Fix missing intrinsics for windows/arm64 target
[#20945](https://github.com/numpy/numpy/pull/20945): REL: Prepare for the NumPy 1.22.2 release.
[#20982](https://github.com/numpy/numpy/pull/20982): MAINT: f2py: don’t generate code that triggers`-Wsometimes-uninitialized`
.
[#20983](https://github.com/numpy/numpy/pull/20983): BUG: Fix incorrect return type in reduce without initial value
[#20984](https://github.com/numpy/numpy/pull/20984): ENH: review return values for PyArray_DescrNew
[#20985](https://github.com/numpy/numpy/pull/20985): MAINT: be more tolerant of setuptools >= 60
[#20986](https://github.com/numpy/numpy/pull/20986): BUG: Fix misplaced return.
[#20992](https://github.com/numpy/numpy/pull/20992): MAINT: Further small return value validation fixes# NumPy 1.24.1 Release Notes[#](#numpy-1-24-1-release-notes)
NumPy 1.24.1 is a maintenance release that fixes bugs and regressions discovered after the 1.24.0 release. The Python versions supported by this release are 3.8-3.11.

## Contributors[#](#contributors)
A total of 12 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Andrew Nelson

Ben Greiner +

Charles Harris

Clément Robert

Matteo Raso

Matti Picus

Melissa Weber Mendonça

Miles Cranmer

Ralf Gommers

Rohit Goswami

Sayed Adel

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 18 pull requests were merged for this release.

[#22820](https://github.com/numpy/numpy/pull/22820): BLD: add workaround in setup.py for newer setuptools
[#22830](https://github.com/numpy/numpy/pull/22830): BLD: CIRRUS_TAG redux
[#22831](https://github.com/numpy/numpy/pull/22831): DOC: fix a couple typos in 1.23 notes
[#22832](https://github.com/numpy/numpy/pull/22832): BUG: Fix refcounting errors found using pytest-leaks
[#22834](https://github.com/numpy/numpy/pull/22834): BUG, SIMD: Fix invalid value encountered in several ufuncs
[#22837](https://github.com/numpy/numpy/pull/22837): TST: ignore more np.distutils.log imports
[#22839](https://github.com/numpy/numpy/pull/22839): BUG: Do not use getdata() in np.ma.masked_invalid
[#22847](https://github.com/numpy/numpy/pull/22847): BUG: Ensure correct behavior for rows ending in delimiter in…
[#22848](https://github.com/numpy/numpy/pull/22848): BUG, SIMD: Fix the bitmask of the boolean comparison
[#22857](https://github.com/numpy/numpy/pull/22857): BLD: Help raspian arm + clang 13 about __builtin_mul_overflow
[#22858](https://github.com/numpy/numpy/pull/22858): API: Ensure a full mask is returned for masked_invalid
[#22866](https://github.com/numpy/numpy/pull/22866): BUG: Polynomials now copy properly (#22669)
[#22867](https://github.com/numpy/numpy/pull/22867): BUG, SIMD: Fix memory overlap in ufunc comparison loops
[#22868](https://github.com/numpy/numpy/pull/22868): BUG: Fortify string casts against floating point warnings
[#22875](https://github.com/numpy/numpy/pull/22875): TST: Ignore nan-warnings in randomized out tests
[#22883](https://github.com/numpy/numpy/pull/22883): MAINT: restore npymath implementations needed for freebsd
[#22884](https://github.com/numpy/numpy/pull/22884): BUG: Fix integer overflow in in1d for mixed integer dtypes #22877
[#22887](https://github.com/numpy/numpy/pull/22887): BUG: Use whole file for encoding checks with`charset_normalizer`
.# NumPy 1.9.2 Release Notes[#](#numpy-1-9-2-release-notes)
This is a bugfix only release in the 1.9.x series.

## Issues fixed[#](#issues-fixed)
[#5316](https://github.com/numpy/numpy/issues/5316): fix too large dtype alignment of strings and complex types
[#5424](https://github.com/numpy/numpy/issues/5424): fix ma.median when used on ndarrays
[#5481](https://github.com/numpy/numpy/issues/5481): Fix astype for structured array fields of different byte order
[#5354](https://github.com/numpy/numpy/issues/5354): fix segfault when clipping complex arrays
[#5524](https://github.com/numpy/numpy/issues/5524): allow np.argpartition on non ndarrays
[#5612](https://github.com/numpy/numpy/issues/5612): Fixes ndarray.fill to accept full range of uint64
[#5155](https://github.com/numpy/numpy/issues/5155): Fix loadtxt with comments=None and a string None data
[#4476](https://github.com/numpy/numpy/issues/4476): Masked array view fails if structured dtype has datetime component
[#5388](https://github.com/numpy/numpy/issues/5388): Make RandomState.set_state and RandomState.get_state threadsafe
[#5390](https://github.com/numpy/numpy/issues/5390): make seed, randint and shuffle threadsafe
[#5374](https://github.com/numpy/numpy/issues/5374): Fixed incorrect assert_array_almost_equal_nulp documentation
[#5393](https://github.com/numpy/numpy/issues/5393): Add support for ATLAS > 3.9.33.
[#5313](https://github.com/numpy/numpy/issues/5313): PyArray_AsCArray caused segfault for 3d arrays
[#5492](https://github.com/numpy/numpy/issues/5492): handle out of memory in rfftf
[#4181](https://github.com/numpy/numpy/issues/4181): fix a few bugs in the random.pareto docstring
[#5359](https://github.com/numpy/numpy/issues/5359): minor changes to linspace docstring
[#4723](https://github.com/numpy/numpy/issues/4723): fix a compile issues on AIX# NumPy 1.24.3 Release Notes[#](#numpy-1-24-3-release-notes)
NumPy 1.24.3 is a maintenance release that fixes bugs and regressions discovered after the 1.24.2 release. The Python versions supported by this release are 3.8-3.11.

## Contributors[#](#contributors)
A total of 12 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Aleksei Nikiforov +

Alexander Heger

Bas van Beek

Bob Eldering

Brock Mendel

Charles Harris

Kyle Sunden

Peter Hawkins

Rohit Goswami

Sebastian Berg

Warren Weckesser

dependabot[bot]

## Pull requests merged[#](#pull-requests-merged)
A total of 17 pull requests were merged for this release.

[#23206](https://github.com/numpy/numpy/pull/23206): BUG: fix for f2py string scalars (#23194)
[#23207](https://github.com/numpy/numpy/pull/23207): BUG: datetime64/timedelta64 comparisons return NotImplemented
[#23208](https://github.com/numpy/numpy/pull/23208): MAINT: Pin matplotlib to version 3.6.3 for refguide checks
[#23221](https://github.com/numpy/numpy/pull/23221): DOC: Fix matplotlib error in documentation
[#23226](https://github.com/numpy/numpy/pull/23226): CI: Ensure submodules are initialized in gitpod.
[#23341](https://github.com/numpy/numpy/pull/23341): TYP: Replace duplicate reduce in ufunc type signature with reduceat.
[#23342](https://github.com/numpy/numpy/pull/23342): TYP: Remove duplicate CLIP/WRAP/RAISE in`__init__.pyi`
.
[#23343](https://github.com/numpy/numpy/pull/23343): TYP: Mark`d`
argument to fftfreq and rfftfreq as optional…
[#23344](https://github.com/numpy/numpy/pull/23344): TYP: Add type annotations for comparison operators to MaskedArray.
[#23345](https://github.com/numpy/numpy/pull/23345): TYP: Remove some stray type-check-only imports of`msort`
[#23370](https://github.com/numpy/numpy/pull/23370): BUG: Ensure like is only stripped for`like=`
dispatched functions
[#23543](https://github.com/numpy/numpy/pull/23543): BUG: fix loading and storing big arrays on s390x
[#23544](https://github.com/numpy/numpy/pull/23544): MAINT: Bump larsoner/circleci-artifacts-redirector-action
[#23634](https://github.com/numpy/numpy/pull/23634): BUG: Ignore invalid and overflow warnings in masked setitem
[#23635](https://github.com/numpy/numpy/pull/23635): BUG: Fix masked array raveling when`order="A"`
or`order="K"`
[#23636](https://github.com/numpy/numpy/pull/23636): MAINT: Update conftest for newer hypothesis versions
[#23637](https://github.com/numpy/numpy/pull/23637): BUG: Fix bug in parsing F77 style string arrays.# NumPy 1.8.2 Release Notes[#](#numpy-1-8-2-release-notes)
This is a bugfix only release in the 1.8.x series.

## Issues fixed[#](#issues-fixed)
gh-4836: partition produces wrong results for multiple selections in equal ranges

gh-4656: Make fftpack._raw_fft threadsafe

gh-4628: incorrect argument order to _copyto in in np.nanmax, np.nanmin

gh-4642: Hold GIL for converting dtypes types with fields

gh-4733: fix np.linalg.svd(b, compute_uv=False)

gh-4853: avoid unaligned simd load on reductions on i386

gh-4722: Fix seg fault converting empty string to object

gh-4613: Fix lack of NULL check in array_richcompare

gh-4774: avoid unaligned access for strided byteswap

gh-650: Prevent division by zero when creating arrays from some buffers

gh-4602: ifort has issues with optimization flag O2, use O1# NumPy 1.7.2 Release Notes[#](#numpy-1-7-2-release-notes)
This is a bugfix only release in the 1.7.x series. It supports Python 2.4 - 2.7 and 3.1 - 3.3 and is the last series that supports Python 2.4 - 2.5.

## Issues fixed[#](#issues-fixed)
gh-3153: Do not reuse nditer buffers when not filled enough

gh-3192: f2py crashes with UnboundLocalError exception

gh-442: Concatenate with axis=None now requires equal number of array elements

gh-2485: Fix for astype(‘S’) string truncate issue

gh-3312: bug in count_nonzero

gh-2684: numpy.ma.average casts complex to float under certain conditions

gh-2403: masked array with named components does not behave as expected

gh-2495: np.ma.compress treated inputs in wrong order

gh-576: add __len__ method to ma.mvoid

gh-3364: reduce performance regression of mmap slicing

gh-3421: fix non-swapping strided copies in GetStridedCopySwap

gh-3373: fix small leak in datetime metadata initialization

gh-2791: add platform specific python include directories to search paths

gh-3168: fix undefined function and add integer divisions

gh-3301: memmap does not work with TemporaryFile in python3

gh-3057: distutils.misc_util.get_shared_lib_extension returns wrong debug extension

gh-3472: add module extensions to load_library search list

gh-3324: Make comparison function (gt, ge, …) respect __array_priority__

gh-3497: np.insert behaves incorrectly with argument ‘axis=-1’

gh-3541: make preprocessor tests consistent in halffloat.c

gh-3458: array_ass_boolean_subscript() writes ‘non-existent’ data to array

gh-2892: Regression in ufunc.reduceat with zero-sized index array

gh-3608: Regression when filling struct from tuple

gh-3701: add support for Python 3.4 ast.NameConstant

gh-3712: do not assume that GIL is enabled in xerbla

gh-3712: fix LAPACK error handling in lapack_litemodule

gh-3728: f2py fix decref on wrong object

gh-3743: Hash changed signature in Python 3.3

gh-3793: scalar int hashing broken on 64 bit python3

gh-3160: SandboxViolation easyinstalling 1.7.0 on Mac OS X 10.8.3

gh-3871: npy_math.h has invalid isinf for Solaris with SUNWspro12.2

gh-2561: Disable check for oldstyle classes in python3

gh-3900: Ensure NotImplemented is passed on in MaskedArray ufunc’s

gh-2052: del scalar subscript causes segfault

gh-3832: fix a few uninitialized uses and memleaks

gh-3971: f2py changed string.lowercase to string.ascii_lowercase for python3

gh-3480: numpy.random.binomial raised ValueError for n == 0

gh-3992: hypot(inf, 0) shouldn’t raise a warning, hypot(inf, inf) wrong result

gh-4018: Segmentation fault dealing with very large arrays

gh-4094: fix NaT handling in _strided_to_strided_string_to_datetime

gh-4051: fix uninitialized use in _strided_to_strided_string_to_datetime

gh-4123: lexsort segfault

gh-4141: Fix a few issues that show up with python 3.4b1# NumPy 1.17.5 Release Notes[#](#numpy-1-17-5-release-notes)
This release contains fixes for bugs reported against NumPy 1.17.4 along with some build improvements. The Python versions supported in this release are 3.5-3.8.

Downstream developers should use Cython >= 0.29.14 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

It is recommended that developers interested in the new random bit generators upgrade to the NumPy 1.18.x series, as it has updated documentation and many small improvements.

## Contributors[#](#contributors)
A total of 6 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Eric Wieser

Ilhan Polat

Matti Picus

Michael Hudson-Doyle

Ralf Gommers

## Pull requests merged[#](#pull-requests-merged)
A total of 8 pull requests were merged for this release.

[#14593](https://github.com/numpy/numpy/pull/14593): MAINT: backport Cython API cleanup to 1.17.x, remove docs
[#14937](https://github.com/numpy/numpy/pull/14937): BUG: fix integer size confusion in handling array’s ndmin argument
[#14939](https://github.com/numpy/numpy/pull/14939): BUILD: remove SSE2 flag from numpy.random builds
[#14993](https://github.com/numpy/numpy/pull/14993): MAINT: Added Python3.8 branch to dll lib discovery
[#15038](https://github.com/numpy/numpy/pull/15038): BUG: Fix refcounting in ufunc object loops
[#15067](https://github.com/numpy/numpy/pull/15067): BUG: Exceptions tracebacks are dropped
[#15175](https://github.com/numpy/numpy/pull/15175): ENH: Backport improvements to testing functions.
[#15213](https://github.com/numpy/numpy/pull/15213): REL: Prepare for the NumPy 1.17.5 release.# NumPy 1.14.6 Release Notes[#](#numpy-1-14-6-release-notes)
This is a bugfix release for bugs reported following the 1.14.5 release. The most significant fixes are:

Fix for behavior change in

`ma.masked_values(shrink=True)`
Fix the new cached allocations machinery to be thread safe.

The Python versions supported in this release are 2.7 and 3.4 - 3.7. The Python 3.6 wheels on PyPI should be compatible with all Python 3.6 versions.

## Contributors[#](#contributors)
A total of 4 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Eric Wieser

Julian Taylor

Matti Picus

## Pull requests merged[#](#pull-requests-merged)
A total of 4 pull requests were merged for this release.# NumPy 1.18.2 Release Notes[#](#numpy-1-18-2-release-notes)
This small release contains a fix for a performance regression in numpy/random and several bug/maintenance updates.

The Python versions supported in this release are 3.5-3.8. Downstream developers should use Cython >= 0.29.15 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

## Contributors[#](#contributors)
A total of 5 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Ganesh Kathiresan +

Matti Picus

Sebastian Berg

przemb +

## Pull requests merged[#](#pull-requests-merged)
A total of 7 pull requests were merged for this release.

[#15675](https://github.com/numpy/numpy/pull/15675): TST: move _no_tracing to testing._private
[#15676](https://github.com/numpy/numpy/pull/15676): MAINT: Large overhead in some random functions
[#15677](https://github.com/numpy/numpy/pull/15677): TST: Do not create gfortran link in azure Mac testing.
[#15679](https://github.com/numpy/numpy/pull/15679): BUG: Added missing error check in`ndarray.__contains__`
[#15722](https://github.com/numpy/numpy/pull/15722): MAINT: use list-based APIs to call subprocesses
[#15729](https://github.com/numpy/numpy/pull/15729): REL: Prepare for 1.18.2 release.
[#15734](https://github.com/numpy/numpy/pull/15734): BUG: fix logic error when nm fails on 32-bitSearch Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# numpy.polynomial.hermite_e.HermiteE.cast[#](#numpy-polynomial-hermite-e-hermitee-cast)
method

*classmethod*polynomial.hermite_e.HermiteE.cast(*series*,*domain=None*,*window=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1166-L1206)[#](#numpy.polynomial.hermite_e.HermiteE.cast)
-
Convert series to series of this class.

The

*series*is expected to be an instance of some polynomial series of one of the types supported by by the numpy.polynomial module, but could be some other class that supports the convert method.New in version 1.7.0.

Parameters:
-
**series**series
The series instance to be converted.

**domain**{None, array_like}, optional
If given, the array must be of the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the domain. If None is given then the class domain is used. The default is None.
**window**{None, array_like}, optional
If given, the resulting array must be if the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the window. If None is given then the class window is used. The default is None.
Returns:
-
**new_series**series
A series of the same kind as the calling class and equal to

*series*when evaluated.
See also

`convert`
similar instance method# numpy.ma.masked_array.dump[#](#numpy-ma-masked-array-dump)
method

ma.masked_array.dump(*file*)[#](#numpy.ma.masked_array.dump)
-
Dump a pickle of the array to the specified file. The array can be read back with pickle.load or numpy.load.

Parameters:
-
**file**str or Path
A string naming the dump file.

Changed in version 1.17.0:

objects are now accepted.`pathlib.Path`# numpy.ma.masked_array.resize[#](#numpy-ma-masked-array-resize)
method

ma.masked_array.resize(*newshape*,*refcheck=True*,*order=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4752-L4768)[#](#numpy.ma.masked_array.resize)
-
Warning

This method does nothing, except raise a ValueError exception. A masked array does not own its data and therefore cannot safely be resized in place. Use the

function instead.`numpy.ma.resize`
This method is difficult to implement safely and may be deprecated in future releases of NumPy.# numpy.memmap.diagonal[#](#numpy-memmap-diagonal)
method

memmap.diagonal(*offset=0*,*axis1=0*,*axis2=1*)[#](#numpy.memmap.diagonal)
-
Return specified diagonals. In NumPy 1.9 the returned array is a read-only view instead of a copy as in previous NumPy versions. In a future version the read-only restriction will be removed.

Refer to

for full documentation.`numpy.diagonal`
See also

`numpy.diagonal`
equivalent functionnumpy.ma.MaskedArray.__getstate__# method ma.MaskedArray.__getstate__()[source]# Return the internal state of the masked array, for pickling purposes.# numpy.distutils.ccompiler_opt.CCompilerOpt.conf_cc_flags[#](#numpy-distutils-ccompiler-opt-ccompileropt-conf-cc-flags)
attribute

distutils.ccompiler_opt.CCompilerOpt.conf_cc_flags*= {'clang': {'native': '-march=native', 'opt': '-O3', 'werror': '-Werror=switch -Werror'}, 'fcc': {'native': '-mcpu=a64fx', 'opt': None, 'werror': None}, 'gcc': {'native': '-march=native', 'opt': '-O3', 'werror': '-Werror'}, 'icc': {'native': '-xHost', 'opt': '-O3', 'werror': '-Werror'}, 'iccw': {'native': '/QxHost', 'opt': '/O3', 'werror': '/Werror'}, 'msvc': {'native': None, 'opt': '/O2', 'werror': '/WX'}}*[#](#numpy.distutils.ccompiler_opt.CCompilerOpt.conf_cc_flags)
-User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
poly1d.coef
numpy.poly1d.coef
#
property
property
poly1d.
coef
#
The polynomial coefficients# numpy.memmap.real[#](#numpy-memmap-real)
attribute

memmap.real[#](#numpy.memmap.real)
-
The real part of the array.

See also

`numpy.real`
equivalent function

Examples

>>> x = np.sqrt([1+0j, 0+1j]) >>> x.real array([ 1. , 0.70710678]) >>> x.real.dtype dtype('float64')
attribute

The real part of the array.

See also

`numpy.real`
equivalent function

Examples

```
>>> x = np.sqrt([1+0j, 0+1j])
>>> x.real
array([ 1. , 0.70710678])
>>> x.real.dtype
dtype('float64')
```# numpy.compress[#](#numpy-compress)
numpy.compress(*condition*,*a*,*axis=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L2032-L2093)[#](#numpy.compress)
-
Return selected slices of an array along given axis.

When working along a given axis, a slice along that axis is returned in

*output*for each index where*condition*evaluates to True. When working on a 1-D array,is equivalent to`compress`
.`extract`
Parameters:
-
**condition**1-D array of bools
Array that selects which entries to return. If len(condition) is less than the size of

*a*along the given axis, then output is truncated to the length of the condition array.
**a**array_like
Array from which to extract a part.

**axis**int, optional
Axis along which to take slices. If None (default), work on the flattened array.

**out**ndarray, optional
Output array. Its type is preserved and it must be of the right shape to hold the output.

Returns:
-
**compressed_array**ndarray
A copy of

*a*without the slices along axis for which*condition*is false.
See also

,`take`
,`choose`
,`diag`
,`diagonal`
`select`
`ndarray.compress`
Equivalent method in ndarray

`extract`
Equivalent method when working on 1-D arrays

[Output type determination](../../user/basics.ufuncs.html#ufuncs-output-type)
Examples

>>> a = np.array([[1, 2], [3, 4], [5, 6]]) >>> a array([[1, 2], [3, 4], [5, 6]]) >>> np.compress([0, 1], a, axis=0) array([[3, 4]]) >>> np.compress([False, True, True], a, axis=0) array([[3, 4], [5, 6]]) >>> np.compress([False, True], a, axis=1) array([[2], [4], [6]])
Working on the flattened array does not return slices along an axis but selects elements.

>>> np.compress([False, True], a) array([2])# numpy.column_stack[#](#numpy-column-stack)
numpy.column_stack(*tup*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L612-L652)[#](#numpy.column_stack)
-
Stack 1-D arrays as columns into a 2-D array.

Take a sequence of 1-D arrays and stack them as columns to make a single 2-D array. 2-D arrays are stacked as-is, just like with

. 1-D arrays are turned into 2-D columns first.`hstack`
Parameters:
-
**tup**sequence of 1-D or 2-D arrays.
Arrays to stack. All of them must have the same first dimension.

Returns:
-
**stacked**2-D array
The array formed by stacking the given arrays.

See also

Examples

>>> a = np.array((1,2,3)) >>> b = np.array((2,3,4)) >>> np.column_stack((a,b)) array([[1, 2], [2, 3], [3, 4]])# numpy.append[#](#numpy-append)
numpy.append(*arr*,*values*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L5562-L5617)[#](#numpy.append)
-
Append values to the end of an array.

Parameters:
-
**arr**array_like
Values are appended to a copy of this array.

**values**array_like
These values are appended to a copy of

*arr*. It must be of the correct shape (the same shape as*arr*, excluding*axis*). If*axis*is not specified,*values*can be any shape and will be flattened before use.
**axis**int, optional
The axis along which

*values*are appended. If*axis*is not given, both*arr*and*values*are flattened before use.
Returns:
-
**append**ndarray
A copy of

*arr*with*values*appended to*axis*. Note thatdoes not occur in-place: a new array is allocated and filled. If`append`
*axis*is None,*out*is a flattened array.
Examples

>>> np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]]) array([1, 2, 3, ..., 7, 8, 9])
When

*axis*is specified,*values*must have the correct shape.>>> np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0) Traceback (most recent call last): ... ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)# numpy.ufunc.nargs[#](#numpy-ufunc-nargs)
attribute

ufunc.nargs[#](#numpy.ufunc.nargs)
-
The number of arguments.

Data attribute containing the number of arguments the ufunc takes, including optional ones.

Notes

Typically this value will be one more than what you might expect because all ufuncs take the optional “out” argument.

Examples

>>> np.add.nargs 3 >>> np.multiply.nargs 3 >>> np.power.nargs 3 >>> np.exp.nargs 2numpy.record.resize# method record.resize()# Scalar method identical to the corresponding array attribute. Please see ndarray.resize.# numpy.char.zfill[#](#numpy-char-zfill)
char.zfill(*a*,*width*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1816-L1844)[#](#numpy.char.zfill)
-
Return the numeric string left-filled with zeros

Calls

*str.zfill*element-wise.Parameters:
-
**a**array_like, {str, unicode}
Input array.

**width**int
Width of string to left-fill elements in

*a*.
Returns:
-
**out**ndarray, {str, unicode}
Output array of str or unicode, depending on input type

See also# numpy.show_runtime[#](#numpy-show-runtime)
numpy.show_runtime()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/utils.py#L22-L72)[#](#numpy.show_runtime)
-
Print information about various resources in the system including available intrinsic support and BLAS/LAPACK library in use

New in version 1.24.0.

See also

`show_config`
Show libraries in the system on which NumPy was built.

Notes

Information is derived with the help of

[threadpoolctl](https://pypi.org/project/threadpoolctl/)library if available.
SIMD related information is derived from

`__cpu_features__`
,`__cpu_baseline__`
and`__cpu_dispatch__`# numpy.memmap.base[#](#numpy-memmap-base)
attribute

memmap.base[#](#numpy.memmap.base)
-
Base object if memory is from some other object.

Examples

The base of an array that owns its memory is None:

>>> x = np.array([1,2,3,4]) >>> x.base is None True
Slicing creates a view, whose memory is shared with x:

>>> y = x[2:] >>> y.base is x True# numpy.polynomial.hermite.hermpow[#](#numpy-polynomial-hermite-hermpow)
polynomial.hermite.hermpow(*c*,*pow*,*maxpower=16*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite.py#L560-L594)[#](#numpy.polynomial.hermite.hermpow)
-
Raise a Hermite series to a power.

Returns the Hermite series

*c*raised to the power*pow*. The argument*c*is a sequence of coefficients ordered from low to high. i.e., [1,2,3] is the series`P_0 + 2*P_1 + 3*P_2.`
Parameters:
-
**c**array_like
1-D array of Hermite series coefficients ordered from low to high.

**pow**integer
Power to which the series will be raised

**maxpower**integer, optional
Maximum power allowed. This is mainly to limit growth of the series to unmanageable size. Default is 16

Returns:
-
**coef**ndarray
Hermite series of power.

Examples

>>> from numpy.polynomial.hermite import hermpow >>> hermpow([1, 2, 3], 2) array([81., 52., 82., 12., 9.])# numpy.char.chararray.isnumeric[#](#numpy-char-chararray-isnumeric)
method

char.chararray.isnumeric()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2705-L2715)[#](#numpy.char.chararray.isnumeric)
-
For each element in

*self*, return True if there are only numeric characters in the element.See also

method

For each element in *self*, return True if there are only
numeric characters in the element.

See also# numpy.testing.overrides.allows_array_function_override[#](#numpy-testing-overrides-allows-array-function-override)
testing.overrides.allows_array_function_override(*func*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/overrides.py#L69-L83)[#](#numpy.testing.overrides.allows_array_function_override)
-
Determine if a Numpy function can be overridden via

*__array_function__*Parameters:
-
**func**callable
Function that may be overridable via

*__array_function__*
Returns:
-
bool
-
*True*if*func*is a function in the Numpy API that is overridable via*__array_function__*and*False*otherwise.numpy.record.flatten# method record.flatten()# Scalar method identical to the corresponding array attribute. Please see ndarray.flatten.# numpy.polynomial.hermite_e.HermiteE[#](#numpy-polynomial-hermite-e-hermitee)
*class*numpy.polynomial.hermite_e.HermiteE(*coef*,*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L1650-L1695)[#](#numpy.polynomial.hermite_e.HermiteE)
-
An HermiteE series class.

The HermiteE class provides the standard Python numerical methods ‘+’, ‘-’, ‘*’, ‘//’, ‘%’, ‘divmod’, ‘**’, and ‘()’ as well as the attributes and methods listed in the

`ABCPolyBase`
documentation.Parameters:
-
**coef**array_like
HermiteE coefficients in order of increasing degree, i.e,

`(1, 2, 3)`
gives`1*He_0(x) + 2*He_1(X) + 3*He_2(x)`
.
**domain**(2,) array_like, optional
Domain to use. The interval

`[domain[0], domain[1]]`
is mapped to the interval`[window[0], window[1]]`
by shifting and scaling. The default value is [-1, 1].
**window**(2,) array_like, optional
Window, see

for its use. The default value is [-1, 1].`domain`
New in version 1.6.0.

**symbol**str, optional
Symbol used to represent the independent variable in string representations of the polynomial expression, e.g. for printing. The symbol must be a valid Python identifier. Default value is ‘x’.

New in version 1.24.

Attributes:
-
**symbol**
Methods

(arg)`__call__`
Call self as a function.

(deg[, domain, window, symbol])`basis`
Series basis polynomial of degree

*deg*.(series[, domain, window])`cast`
Convert series to series of this class.

([domain, kind, window])`convert`
Convert series to a different kind and/or domain and/or window.

()`copy`
Return a copy.

(deg)`cutdeg`
Truncate series to the given degree.

()`degree`
The degree of the series.

([m])`deriv`
Differentiate.

(x, y, deg[, domain, rcond, full, w, ...])`fit`
Least squares fit to data.

(roots[, domain, window, symbol])`fromroots`
Return series instance that has the specified roots.

(other)`has_samecoef`
Check if coefficients match.

(other)`has_samedomain`
Check if domains match.

(other)`has_sametype`
Check if types match.

(other)`has_samewindow`
Check if windows match.

([domain, window, symbol])`identity`
Identity function.

([m, k, lbnd])`integ`
Integrate.

([n, domain])`linspace`
Return x, y values at equally spaced points in domain.

()`mapparms`
Return the mapping parameters.

()`roots`
Return the roots of the series polynomial.

([tol])`trim`
Remove trailing coefficients

(size)`truncate`
Truncate series to length

*size*.numpy.chararray.tostring# method chararray.tostring(order='C')# A compatibility alias for tobytes, with exactly the same behavior. Despite its name, it returns bytes not strs. Deprecated since version 1.19.0.numpy.nditer.iternext# method nditer.iternext()# Check whether iterations are left, and perform a single internal iteration without returning the result. Used in the C-style pattern do-while pattern. For an example, see nditer. Returns: iternextboolWhether or not there are iterations left.# numpy.asarray_chkfinite[#](#numpy-asarray-chkfinite)
numpy.asarray_chkfinite(*a*,*dtype=None*,*order=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L564-L632)[#](#numpy.asarray_chkfinite)
-
Convert the input to an array, checking for NaNs or Infs.

Parameters:
-
**a**array_like
Input data, in any form that can be converted to an array. This includes lists, lists of tuples, tuples, tuples of tuples, tuples of lists and ndarrays. Success requires no NaNs or Infs.

**dtype**data-type, optional
By default, the data-type is inferred from the input data.

**order**{‘C’, ‘F’, ‘A’, ‘K’}, optional
Memory layout. ‘A’ and ‘K’ depend on the order of input array a. ‘C’ row-major (C-style), ‘F’ column-major (Fortran-style) memory representation. ‘A’ (any) means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise ‘K’ (keep) preserve input order Defaults to ‘C’.
Returns:
-
**out**ndarray
Array interpretation of

*a*. No copy is performed if the input is already an ndarray. If*a*is a subclass of ndarray, a base class ndarray is returned.
Raises:
-
ValueError
-
Raises ValueError if

*a*contains NaN (Not a Number) or Inf (Infinity).
See also

`asarray`
Create and array.

`asanyarray`
Similar function which passes through subclasses.

`ascontiguousarray`
Convert input to a contiguous array.

`asfarray`
Convert input to a floating point ndarray.

`asfortranarray`
Convert input to an ndarray with column-major memory order.

`fromiter`
Create an array from an iterator.

`fromfunction`
Construct an array by executing a function on grid positions.

Examples

Convert a list into an array. If all elements are finite

`asarray_chkfinite`
is identical to`asarray`
.>>> a = [1, 2] >>> np.asarray_chkfinite(a, dtype=float) array([1., 2.])
Raises ValueError if array_like contains Nans or Infs.

>>> a = [1, 2, np.inf] >>> try: ... np.asarray_chkfinite(a) ... except ValueError: ... print('ValueError') ... ValueErrornumpy.ndarray.__array_wrap__# method ndarray.__array_wrap__(array, [context, ]/)# Returns a view of array with the same type as self.# numpy.ndarray.repeat[#](#numpy-ndarray-repeat)
method

ndarray.repeat(*repeats*,*axis=None*)[#](#numpy.ndarray.repeat)
-
Repeat elements of an array.

Refer to

for full documentation.`numpy.repeat`
See also

`numpy.repeat`
equivalent function

method

Repeat elements of an array.

Refer to [ numpy.repeat](numpy.repeat.html#numpy.repeat) for full documentation.

See also

`numpy.repeat`
equivalent functionnumpy.random.SFC64.state# attribute random.SFC64.state# Get or set the PRNG state Returns: statedictDictionary containing the information required to describe the state of the PRNGnumpy.distutils.exec_command.find_executable# distutils.exec_command.find_executable(exe, path=None, _cache={})[source]# Return full path of a executable or None. Symbolic links are not followed.# numpy.chararray.dtype[#](#numpy-chararray-dtype)
attribute

chararray.dtype[#](#numpy.chararray.dtype)
-
Data-type of the array’s elements.

Warning

Setting

`arr.dtype`
is discouraged and may be deprecated in the future. Setting will replace the`dtype`
without modifying the memory (see alsoand`ndarray.view`
).`ndarray.astype`
Parameters:
-
**None**
Returns:
-
**d**numpy dtype object
See also

`ndarray.astype`
Cast the values contained in the array to a new data-type.

`ndarray.view`
Create a view of the same data but a different data-type.

`numpy.dtype`
Examples

>>> x array([[0, 1], [2, 3]]) >>> x.dtype dtype('int32') >>> type(x.dtype) <type 'numpy.dtype'>numpy.lib.user_array.container# class numpy.lib.user_array.container(data, dtype=None, copy=True)[source]# Standard container-class for easy multiple-inheritance. Methods copy tostring byteswap astypeUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__str__
numpy.ndarray.__str__
#
method
ndarray.
__str__
(
/
)
#
Return str(self).# numpy.ma.masked_greater_equal[#](#numpy-ma-masked-greater-equal)
ma.masked_greater_equal(*x*,*value*,*copy=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L1976-L1999)[#](#numpy.ma.masked_greater_equal)
-
Mask an array where greater than or equal to a given value.

This function is a shortcut to

`masked_where`
, with*condition*= (x >= value).See also

`masked_where`
Mask where a condition is met.

Examples

>>> import numpy.ma as ma >>> a = np.arange(4) >>> a array([0, 1, 2, 3]) >>> ma.masked_greater_equal(a, 2) masked_array(data=[0, 1, --, --], mask=[False, False, True, True], fill_value=999999)numpy.recarray.all# method recarray.all(axis=None, out=None, keepdims=False, *, where=True)# Returns True if all elements evaluate to True. Refer to numpy.all for full documentation. See also numpy.allequivalent function# numpy.polynomial.laguerre.Laguerre[#](#numpy-polynomial-laguerre-laguerre)
*class*numpy.polynomial.laguerre.Laguerre(*coef*,*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/laguerre.py#L1606-L1651)[#](#numpy.polynomial.laguerre.Laguerre)
-
A Laguerre series class.

The Laguerre class provides the standard Python numerical methods ‘+’, ‘-’, ‘*’, ‘//’, ‘%’, ‘divmod’, ‘**’, and ‘()’ as well as the attributes and methods listed in the

`ABCPolyBase`
documentation.Parameters:
-
**coef**array_like
Laguerre coefficients in order of increasing degree, i.e,

`(1, 2, 3)`
gives`1*L_0(x) + 2*L_1(X) + 3*L_2(x)`
.
**domain**(2,) array_like, optional
Domain to use. The interval

`[domain[0], domain[1]]`
is mapped to the interval`[window[0], window[1]]`
by shifting and scaling. The default value is [0, 1].
**window**(2,) array_like, optional
Window, see

for its use. The default value is [0, 1].`domain`
New in version 1.6.0.

**symbol**str, optional
Symbol used to represent the independent variable in string representations of the polynomial expression, e.g. for printing. The symbol must be a valid Python identifier. Default value is ‘x’.

New in version 1.24.

Attributes:
-
**symbol**
Methods

(arg)`__call__`
Call self as a function.

(deg[, domain, window, symbol])`basis`
Series basis polynomial of degree

*deg*.(series[, domain, window])`cast`
Convert series to series of this class.

([domain, kind, window])`convert`
Convert series to a different kind and/or domain and/or window.

()`copy`
Return a copy.

(deg)`cutdeg`
Truncate series to the given degree.

()`degree`
The degree of the series.

([m])`deriv`
Differentiate.

(x, y, deg[, domain, rcond, full, w, ...])`fit`
Least squares fit to data.

(roots[, domain, window, symbol])`fromroots`
Return series instance that has the specified roots.

(other)`has_samecoef`
Check if coefficients match.

(other)`has_samedomain`
Check if domains match.

(other)`has_sametype`
Check if types match.

(other)`has_samewindow`
Check if windows match.

([domain, window, symbol])`identity`
Identity function.

([m, k, lbnd])`integ`
Integrate.

([n, domain])`linspace`
Return x, y values at equally spaced points in domain.

()`mapparms`
Return the mapping parameters.

()`roots`
Return the roots of the series polynomial.

([tol])`trim`
Remove trailing coefficients

(size)`truncate`
Truncate series to length

*size*.# numpy.char.chararray.ljust[#](#numpy-char-chararray-ljust)
method

char.chararray.ljust(*width*,*fillchar=' '*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2465-L2475)[#](#numpy.char.chararray.ljust)
-
Return an array with the elements of

*self*left-justified in a string of length*width*.See also

method

Return an array with the elements of *self* left-justified in a
string of length *width*.

See alsoUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__pos__
numpy.ndarray.__pos__
#
method
ndarray.
__pos__
(
/
)
#
+self# numpy.clip[#](#numpy-clip)
numpy.clip(*a*,*a_min*,*a_max*,*out=None*,***kwargs*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/fromnumeric.py#L2100-L2169)[#](#numpy.clip)
-
Clip (limit) the values in an array.

Given an interval, values outside the interval are clipped to the interval edges. For example, if an interval of

`[0, 1]`
is specified, values smaller than 0 become 0, and values larger than 1 become 1.Equivalent to but faster than

`np.minimum(a_max, np.maximum(a, a_min))`
.No check is performed to ensure

`a_min < a_max`
.Parameters:
-
**a**array_like
Array containing elements to clip.

**a_min, a_max**array_like or None
Minimum and maximum value. If

`None`
, clipping is not performed on the corresponding edge. Only one of*a_min*and*a_max*may be`None`
. Both are broadcast against*a*.
**out**ndarray, optional
The results will be placed in this array. It may be the input array for in-place clipping.

*out*must be of the right shape to hold the output. Its type is preserved.
****kwargs**
For other keyword-only arguments, see the

[ufunc docs](../ufuncs.html#ufuncs-kwargs).New in version 1.17.0.

Returns:
-
**clipped_array**ndarray
An array with the elements of

*a*, but where values <*a_min*are replaced with*a_min*, and those >*a_max*with*a_max*.
See also

Notes

When

*a_min*is greater than*a_max*,returns an array in which all values are equal to`clip`
*a_max*, as shown in the second example.Examples

>>> a = np.arange(10) >>> a array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) >>> np.clip(a, 1, 8) array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8]) >>> np.clip(a, 8, 1) array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) >>> np.clip(a, 3, 6, out=a) array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6]) >>> a array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6]) >>> a = np.arange(10) >>> a array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) >>> np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8) array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])# numpy.chararray.endswith[#](#numpy-chararray-endswith)
method

chararray.endswith(*suffix*,*start=0*,*end=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2317-L2327)[#](#numpy.chararray.endswith)
-
Returns a boolean array which is

*True*where the string element in*self*ends with*suffix*, otherwise*False*.See also

method

Returns a boolean array which is *True* where the string element
in *self* ends with *suffix*, otherwise *False*.

See also# numpy.char.chararray.startswith[#](#numpy-char-chararray-startswith)
method

char.chararray.startswith(*prefix*,*start=0*,*end=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2618-L2628)[#](#numpy.char.chararray.startswith)
-
Returns a boolean array which is

*True*where the string element in*self*starts with*prefix*, otherwise*False*.See also

method

Returns a boolean array which is *True* where the string element
in *self* starts with *prefix*, otherwise *False*.

See also# numpy.ma.masked_array.hardmask[#](#numpy-ma-masked-array-hardmask)
property

*property*ma.masked_array.hardmask[#](#numpy.ma.masked_array.hardmask)
-
Specifies whether values can be unmasked through assignments.

By default, assigning definite values to masked array entries will unmask them. When

is`hardmask`
`True`
, the mask will not change through assignments.Examples

>>> x = np.arange(10) >>> m = np.ma.masked_array(x, x>5) >>> assert not m.hardmask
Since

*m*has a soft mask, assigning an element value unmasks that element:>>> m[8] = 42 >>> m masked_array(data=[0, 1, 2, 3, 4, 5, --, --, 42, --], mask=[False, False, False, False, False, False, True, True, False, True], fill_value=999999)
After hardening, the mask is not affected by assignments:

>>> hardened = np.ma.harden_mask(m) >>> assert m.hardmask and hardened is m >>> m[:] = 23 >>> m masked_array(data=[23, 23, 23, 23, 23, 23, --, --, 23, --], mask=[False, False, False, False, False, False, True, True, False, True], fill_value=999999)# numpy.chararray.split[#](#numpy-chararray-split)
method

chararray.split(*sep=None*,*maxsplit=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2594-L2604)[#](#numpy.chararray.split)
-
For each element in

*self*, return a list of the words in the string, using*sep*as the delimiter string.See also

method

For each element in *self*, return a list of the words in the
string, using *sep* as the delimiter string.

See also# numpy.polynomial.legendre.legweight[#](#numpy-polynomial-legendre-legweight)
polynomial.legendre.legweight(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L1588-L1613)[#](#numpy.polynomial.legendre.legweight)
-
Weight function of the Legendre polynomials.

The weight function is \(1\) and the interval of integration is \([-1, 1]\). The Legendre polynomials are orthogonal, but not normalized, with respect to this weight function.

Parameters:
-
**x**array_like
Values at which the weight function will be computed.

Returns:
-
**w**ndarray
The weight function at

*x*.
Notes

New in version 1.7.0.numpy.ma.masked_array.dumps# method ma.masked_array.dumps()# Returns the pickle of the array as a string. pickle.loads will convert the string back to an array. Parameters: None# numpy.ma.MaskedArray.cumprod[#](#numpy-ma-maskedarray-cumprod)
method

ma.MaskedArray.cumprod(*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5275-L5304)[#](#numpy.ma.MaskedArray.cumprod)
-
Return the cumulative product of the array elements over the given axis.

Masked values are set to 1 internally during the computation. However, their position is saved, and the result will be masked at the same locations.

Refer to

for full documentation.`numpy.cumprod`
See also

`numpy.ndarray.cumprod`
corresponding function for ndarrays

`numpy.cumprod`
equivalent function

Notes

The mask is lost if

*out*is not a valid MaskedArray !Arithmetic is modular when using integer types, and no error is raised on overflow.# numpy.random.randint[#](#numpy-random-randint)
random.randint(*low*,*high=None*,*size=None*,*dtype=int*)[#](#numpy.random.randint)
-
Return random integers from

*low*(inclusive) to*high*(exclusive).Return random integers from the “discrete uniform” distribution of the specified dtype in the “half-open” interval [

*low*,*high*). If*high*is None (the default), then results are from [0,*low*).Note

New code should use the

method of a`integers`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**low**int or array-like of ints
Lowest (signed) integers to be drawn from the distribution (unless

`high=None`
, in which case this parameter is one above the*highest*such integer).
**high**int or array-like of ints, optional
If provided, one above the largest (signed) integer to be drawn from the distribution (see above for behavior if

`high=None`
). If array-like, must contain integer values
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
**dtype**dtype, optional
Desired dtype of the result. Byteorder must be native. The default value is int.

New in version 1.11.0.

Returns:
-
**out**int or ndarray of ints
`size`
-shaped array of random integers from the appropriate distribution, or a single such random int if`size`
not provided.
See also

`random_integers`
similar to

, only for the closed interval [`randint`
*low*,*high*], and 1 is the lowest value if*high*is omitted.
`random.Generator.integers`
which should be used for new code.

Examples

>>> np.random.randint(2, size=10) array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]) # random >>> np.random.randint(1, size=10) array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
Generate a 2 x 4 array of ints between 0 and 4, inclusive:

>>> np.random.randint(5, size=(2, 4)) array([[4, 0, 2, 1], # random [3, 2, 2, 0]])
Generate a 1 x 3 array with 3 different upper bounds

>>> np.random.randint(1, [3, 5, 10]) array([2, 2, 9]) # random
Generate a 1 by 3 array with 3 different lower bounds

>>> np.random.randint([1, 5, 7], 10) array([9, 8, 7]) # random
Generate a 2 by 4 array using broadcasting with dtype of uint8

>>> np.random.randint([1, 3, 5, 7], [[10], [20]], dtype=np.uint8) array([[ 8, 6, 9, 7], # random [ 1, 16, 9, 12]], dtype=uint8)numpy.polynomial.hermite_e.HermiteE.__call__# method polynomial.hermite_e.HermiteE.__call__(arg)[source]# Call self as a function.# numpy.char.rjust[#](#numpy-char-rjust)
char.rjust(*a*,*width*,*fillchar=' '*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1345-L1378)[#](#numpy.char.rjust)
-
Return an array with the elements of

*a*right-justified in a string of length*width*.Calls

*str.rjust*element-wise.Parameters:
-
**a**array_like of str or unicode
**width**int
The length of the resulting strings

**fillchar**str or unicode, optional
The character to use for padding

Returns:
-
**out**ndarray
Output array of str or unicode, depending on input type

See alsoUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__len__
numpy.ndarray.__len__
#
method
ndarray.
__len__
(
/
)
#
Return len(self).# numpy.polynomial.chebyshev.Chebyshev.basis[#](#numpy-polynomial-chebyshev-chebyshev-basis)
method

*classmethod*polynomial.chebyshev.Chebyshev.basis(*deg*,*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1125-L1164)[#](#numpy.polynomial.chebyshev.Chebyshev.basis)
-
Series basis polynomial of degree

*deg*.Returns the series representing the basis polynomial of degree

*deg*.New in version 1.7.0.

Parameters:
-
**deg**int
Degree of the basis polynomial for the series. Must be >= 0.

**domain**{None, array_like}, optional
If given, the array must be of the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the domain. If None is given then the class domain is used. The default is None.
**window**{None, array_like}, optional
If given, the resulting array must be if the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the window. If None is given then the class window is used. The default is None.
**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
A series with the coefficient of the

*deg*term set to one and all others zero.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
Scalars
Data type objects (
dtype
)
numpy.dtype
numpy.dtype.type
numpy.dtype.kind
numpy.dtype.char
numpy.dtype.num
numpy.dtype.str
numpy.dtype.name
numpy.dtype.itemsize
numpy.dtype.byteorder
numpy.dtype.fields
numpy.dtype.names
numpy.dtype.subdtype
numpy.dtype.shape
numpy.dtype.hasobject
numpy.dtype.flags
numpy.dtype.isbuiltin
numpy.dtype.isnative
numpy.dtype.descr
numpy.dtype.alignment
numpy.dtype.base
numpy.dtype.metadata
numpy.dtype.newbyteorder
numpy.dtype.__reduce__
numpy.dtype.__setstate__
numpy.dtype.__class_getitem__
numpy.dtype.__ge__
numpy.dtype.__gt__
numpy.dtype.__le__
numpy.dtype.__lt__
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
dtype.__gt__
numpy.dtype.__gt__
#
method
dtype.
__gt__
(
value
,
/
)
#
Return self>value.numpy.polynomial.chebyshev.Chebyshev.maxpower# attribute polynomial.chebyshev.Chebyshev.maxpower = 100## numpy.char.chararray.transpose[#](#numpy-char-chararray-transpose)
method

char.chararray.transpose(**axes*)[#](#numpy.char.chararray.transpose)
-
Returns a view of the array with axes transposed.

Refer to

for full documentation.`numpy.transpose`
Parameters:
-
**axes**None, tuple of ints, or*n*ints
None or no argument: reverses the order of the axes.

tuple of ints:

*i*in the*j*-th place in the tuple means that the array’s*i*-th axis becomes the transposed array’s*j*-th axis.
*n*ints: same as an n-tuple of the same ints (this form is intended simply as a “convenience” alternative to the tuple form).
Returns:
-
**p**ndarray
View of the array with its axes suitably permuted.

See also

`transpose`
Equivalent function.

`ndarray.T`
Array property returning the array transposed.

`ndarray.reshape`
Give a new shape to an array without changing its data.

Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> a array([[1, 2], [3, 4]]) >>> a.transpose() array([[1, 3], [2, 4]]) >>> a.transpose((1, 0)) array([[1, 3], [2, 4]]) >>> a.transpose(1, 0) array([[1, 3], [2, 4]])
>>> a = np.array([1, 2, 3, 4]) >>> a array([1, 2, 3, 4]) >>> a.transpose() array([1, 2, 3, 4])numpy.ma.MaskType.T# attribute ma.MaskType.T# Scalar attribute identical to the corresponding array attribute. Please see ndarray.T.numpy.exceptions.VisibleDeprecationWarning# exception exceptions.VisibleDeprecationWarning[source]# Visible deprecation warning. By default, python will not show deprecation warnings, so this class can be used when a very visible warning is helpful, for example because the usage is most likely a user bug.numpy.random.MT19937.state# attribute random.MT19937.state# Get or set the PRNG state Returns: statedictDictionary containing the information required to describe the state of the PRNG# numpy.distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags[#](#numpy-distutils-ccompiler-opt-ccompileropt-cc-normalize-flags)
method

distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags(*flags*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/ccompiler_opt.py#L1111-L1140)[#](#numpy.distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags)
-
Remove the conflicts that caused due gathering implied features flags.

Parameters:
-
**‘flags’ list, compiler flags**
flags should be sorted from the lowest to the highest interest.

Returns:
-
list, filtered from any conflicts.
-
Examples

>>> self.cc_normalize_flags(['-march=armv8.2-a+fp16', '-march=armv8.2-a+dotprod']) ['armv8.2-a+fp16+dotprod']
>>> self.cc_normalize_flags( ['-msse', '-msse2', '-msse3', '-mssse3', '-msse4.1', '-msse4.2', '-mavx', '-march=core-avx2'] ) ['-march=core-avx2']# numpy.ma.masked_array.compress[#](#numpy-ma-masked-array-compress)
method

ma.masked_array.compress(*condition*,*axis=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L3893-L3963)[#](#numpy.ma.masked_array.compress)
-
Return

*a*where condition is`True`
.If condition is a

, missing values are considered as`MaskedArray`
`False`
.Parameters:
-
**condition**var
Boolean 1-d array selecting which entries to return. If len(condition) is less than the size of a along the axis, then output is truncated to length of condition array.

**axis**{None, int}, optional
Axis along which the operation must be performed.

**out**{None, ndarray}, optional
Alternative output array in which to place the result. It must have the same shape as the expected output but the type will be cast if necessary.

Returns:
-
**result**MaskedArray
A

object.`MaskedArray`
Notes

Please note the difference with

! The output of`compressed`
has a mask, the output of`compress`
does not.`compressed`
Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.compress([1, 0, 1]) masked_array(data=[1, 3], mask=[False, False], fill_value=999999)
>>> x.compress([1, 0, 1], axis=1) masked_array( data=[[1, 3], [--, --], [7, 9]], mask=[[False, False], [ True, True], [False, False]], fill_value=999999)# numpy.isrealobj[#](#numpy-isrealobj)
numpy.isrealobj(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/type_check.py#L343-L389)[#](#numpy.isrealobj)
-
Return True if x is a not complex type or an array of complex numbers.

The type of the input is checked, not the value. So even if the input has an imaginary part equal to zero,

evaluates to False if the data type is complex.`isrealobj`
Parameters:
-
**x**any
The input can be of any type and shape.

Returns:
-
**y**bool
The return value, False if

*x*is of a complex type.
See also

Notes

The function is only meant for arrays with numerical values but it accepts all other objects. Since it assumes array input, the return value of other objects may be True.

>>> np.isrealobj('A string') True >>> np.isrealobj(False) True >>> np.isrealobj(None) True
Examples

>>> np.isrealobj(1) True >>> np.isrealobj(1+0j) False >>> np.isrealobj([3, 1+0j, True]) False# numpy.chararray.rsplit[#](#numpy-chararray-rsplit)
method

chararray.rsplit(*sep=None*,*maxsplit=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2570-L2580)[#](#numpy.chararray.rsplit)
-
For each element in

*self*, return a list of the words in the string, using*sep*as the delimiter string.See also

method

For each element in *self*, return a list of the words in
the string, using *sep* as the delimiter string.

See alsonumpy.memmap.var# method memmap.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)# Returns the variance of the array elements, along given axis. Refer to numpy.var for full documentation. See also numpy.varequivalent function# numpy.array_equal[#](#numpy-array-equal)
numpy.array_equal(*a1*,*a2*,*equal_nan=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/numeric.py#L2378-L2446)[#](#numpy.array_equal)
-
True if two arrays have the same shape and elements, False otherwise.

Parameters:
-
**a1, a2**array_like
Input arrays.

**equal_nan**bool
Whether to compare NaN’s as equal. If the dtype of a1 and a2 is complex, values will be considered equal if either the real or the imaginary component of a given value is

`nan`
.New in version 1.19.0.

Returns:
-
**b**bool
Returns True if the arrays are equal.

See also

`allclose`
Returns True if two arrays are element-wise equal within a tolerance.

`array_equiv`
Returns True if input arrays are shape consistent and all elements equal.

Examples

>>> np.array_equal([1, 2], [1, 2]) True >>> np.array_equal(np.array([1, 2]), np.array([1, 2])) True >>> np.array_equal([1, 2], [1, 2, 3]) False >>> np.array_equal([1, 2], [1, 4]) False >>> a = np.array([1, np.nan]) >>> np.array_equal(a, a) False >>> np.array_equal(a, a, equal_nan=True) True
When

`equal_nan`
is True, complex values with nan components are considered equal if either the real*or*the imaginary components are nan.>>> a = np.array([1 + 1j]) >>> b = a.copy() >>> a.real = np.nan >>> b.imag = np.nan >>> np.array_equal(a, b, equal_nan=True) True# numpy.polynomial.laguerre.Laguerre.deriv[#](#numpy-polynomial-laguerre-laguerre-deriv)
method

polynomial.laguerre.Laguerre.deriv(*m=1*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L886-L906)[#](#numpy.polynomial.laguerre.Laguerre.deriv)
-
Differentiate.

Return a series instance of that is the derivative of the current series.

Parameters:
-
**m**non-negative int
Find the derivative of order

*m*.
Returns:
-
**new_series**series
A new series representing the derivative. The domain is the same as the domain of the differentiated series.# numpy.take_along_axis[#](#numpy-take-along-axis)
numpy.take_along_axis(*arr*,*indices*,*axis*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L54-L170)[#](#numpy.take_along_axis)
-
Take values from the input array by matching 1d index and data slices.

This iterates over matching 1d slices oriented along the specified axis in the index and data arrays, and uses the former to look up values in the latter. These slices can be different lengths.

Functions returning an index along an axis, like

and`argsort`
, produce suitable indices for this function.`argpartition`
New in version 1.15.0.

Parameters:
-
**arr**ndarray (Ni…, M, Nk…)
Source array

**indices**ndarray (Ni…, J, Nk…)
Indices to take along each 1d slice of

*arr*. This must match the dimension of arr, but dimensions Ni and Nj only need to broadcast against*arr*.
**axis**int
The axis to take 1d slices along. If axis is None, the input array is treated as if it had first been flattened to 1d, for consistency with

and`sort`
.`argsort`
Returns:
-
out: ndarray (Ni…, J, Nk…)
-
The indexed result.

See also

`take`
Take along an axis, using the same indices for every 1d slice

`put_along_axis`
Put values into the destination array by matching 1d index and data slices

Notes

This is equivalent to (but faster than) the following use of

and`ndindex`
, which sets each of`s_`
`ii`
and`kk`
to a tuple of indices:Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:] J = indices.shape[axis] # Need not equal M out = np.empty(Ni + (J,) + Nk) for ii in ndindex(Ni): for kk in ndindex(Nk): a_1d = a [ii + s_[:,] + kk] indices_1d = indices[ii + s_[:,] + kk] out_1d = out [ii + s_[:,] + kk] for j in range(J): out_1d[j] = a_1d[indices_1d[j]]
Equivalently, eliminating the inner loop, the last two lines would be:

out_1d[:] = a_1d[indices_1d]
Examples

For this sample array

>>> a = np.array([[10, 30, 20], [60, 40, 50]])
We can sort either by using sort directly, or argsort and this function

>>> np.sort(a, axis=1) array([[10, 20, 30], [40, 50, 60]]) >>> ai = np.argsort(a, axis=1) >>> ai array([[0, 2, 1], [1, 2, 0]]) >>> np.take_along_axis(a, ai, axis=1) array([[10, 20, 30], [40, 50, 60]])
The same works for max and min, if you maintain the trivial dimension with

`keepdims`
:>>> np.max(a, axis=1, keepdims=True) array([[30], [60]]) >>> ai = np.argmax(a, axis=1, keepdims=True) >>> ai array([[1], [0]]) >>> np.take_along_axis(a, ai, axis=1) array([[30], [60]])
If we want to get the max and min at the same time, we can stack the indices first

>>> ai_min = np.argmin(a, axis=1, keepdims=True) >>> ai_max = np.argmax(a, axis=1, keepdims=True) >>> ai = np.concatenate([ai_min, ai_max], axis=1) >>> ai array([[0, 1], [1, 0]]) >>> np.take_along_axis(a, ai, axis=1) array([[10, 30], [40, 60]])numpy.busdaycalendar.holidays# attribute busdaycalendar.holidays# A copy of the holiday array indicating additional invalid days.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__lshift__
numpy.ndarray.__lshift__
#
method
ndarray.
__lshift__
(
value
,
/
)
#
Return self<<value.# numpy.distutils.exec_command.exec_command[#](#numpy-distutils-exec-command-exec-command)
distutils.exec_command.exec_command(*command*,*execute_in=''*,*use_shell=None*,*use_tee=None*,*_with_python=1*,***env*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/exec_command.py#L177-L250)[#](#numpy.distutils.exec_command.exec_command)
-
Return (status,output) of executed command.

Deprecated since version 1.17: Use subprocess.Popen instead

Parameters:
-
**command**str
A concatenated string of executable and arguments.

**execute_in**str
Before running command

`cd execute_in`
and after`cd -`
.
**use_shell**{bool, None}, optional
If True, execute

`sh -c command`
. Default None (True)
**use_tee**{bool, None}, optional
If True use tee. Default None (True)

Returns:
-
**res**str
Both stdout and stderr messages.

Notes

On NT, DOS systems the returned status is correct for external commands. Wild cards will not work for non-posix systems or when use_shell=0.# numpy.char.chararray.max[#](#numpy-char-chararray-max)
method

char.chararray.max(*axis=None*,*out=None*,*keepdims=False*,*initial=<no value>*,*where=True*)[#](#numpy.char.chararray.max)
-
Return the maximum along a given axis.

Refer to

for full documentation.`numpy.amax`
See also

`numpy.amax`
equivalent function# numpy.matrix.cumsum[#](#numpy-matrix-cumsum)
method

matrix.cumsum(*axis=None*,*dtype=None*,*out=None*)[#](#numpy.matrix.cumsum)
-
Return the cumulative sum of the elements along the given axis.

Refer to

for full documentation.`numpy.cumsum`
See also

`numpy.cumsum`
equivalent function

method

Return the cumulative sum of the elements along the given axis.

Refer to [ numpy.cumsum](numpy.cumsum.html#numpy.cumsum) for full documentation.

See also

`numpy.cumsum`
equivalent functionUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
record.tobytes
numpy.record.tobytes
#
method
record.
tobytes
(
)
#numpy.ma.MaskedArray.__isub__# method ma.MaskedArray.__isub__(other)[source]# Subtract other from self in-place.numpy.testing.overrides.get_overridable_numpy_array_functions# testing.overrides.get_overridable_numpy_array_functions()[source]# List all numpy functions overridable via __array_function__ Parameters: None Returns: setA set containing all functions in the public numpy API that are overridable via __array_function__.# numpy.char.less_equal[#](#numpy-char-less-equal)
char.less_equal(*x1*,*x2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L183-L206)[#](#numpy.char.less_equal)
-
Return (x1 <= x2) element-wise.

Unlike

, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.`numpy.less_equal`
Parameters:
-
**x1, x2**array_like of str or unicode
Input arrays of the same shape.

Returns:
-
**out**ndarray
Output array of bools.

See also# numpy.ma.MaskedArray.ids[#](#numpy-ma-maskedarray-ids)
method

ma.MaskedArray.ids()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4855-L4879)[#](#numpy.ma.MaskedArray.ids)
-
Return the addresses of the data and mask areas.

Parameters:
-
**None**
Examples

>>> x = np.ma.array([1, 2, 3], mask=[0, 1, 1]) >>> x.ids() (166670640, 166659832) # may vary
If the array has no mask, the address of

*nomask*is returned. This address is typically not close to the data in memory:>>> x = np.ma.array([1, 2, 3]) >>> x.ids() (166691080, 3083169284) # may varynumpy.memmap.all# method memmap.all(axis=None, out=None, keepdims=False, *, where=True)# Returns True if all elements evaluate to True. Refer to numpy.all for full documentation. See also numpy.allequivalent function# numpy.ma.empty_like[#](#numpy-ma-empty-like)
ma.empty_like(*prototype*,*dtype=None*,*order='K'*,*subok=True*,*shape=None*)*= <numpy.ma.core._convert2ma object>*[#](#numpy.ma.empty_like)
-
Return a new array with the same shape and type as a given array.

Parameters:
-
**prototype**array_like
The shape and data-type of

*prototype*define these same attributes of the returned array.
**dtype**data-type, optional
Overrides the data type of the result.

New in version 1.6.0.

**order**{‘C’, ‘F’, ‘A’, or ‘K’}, optional
Overrides the memory layout of the result. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*prototype*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*prototype*as closely as possible.New in version 1.6.0.

**subok**bool, optional.
If True, then the newly created array will use the sub-class type of

*prototype*, otherwise it will be a base-class array. Defaults to True.
**shape**int or sequence of ints, optional.
Overrides the shape of the result. If order=’K’ and the number of dimensions is unchanged, will try to keep order, otherwise, order=’C’ is implied.

New in version 1.17.0.

Returns:
-
**out**MaskedArray
Array of uninitialized (arbitrary) data with the same shape and type as

*prototype*.
See also

`ones_like`
Return an array of ones with shape and type of input.

`zeros_like`
Return an array of zeros with shape and type of input.

`full_like`
Return a new array with shape of input filled with value.

`empty`
Return a new uninitialized array.

Notes

This function does

*not*initialize the returned array; to do that useor`zeros_like`
instead. It may be marginally faster than the functions that do set the array values.`ones_like`
Examples

>>> a = ([1,2,3], [4,5,6]) # a is array-like >>> np.empty_like(a) array([[-1073741821, -1073741821, 3], # uninitialized [ 0, 0, -1073741821]]) >>> a = np.array([[1., 2., 3.],[4.,5.,6.]]) >>> np.empty_like(a) array([[ -2.00000715e+000, 1.48219694e-323, -2.00000572e+000], # uninitialized [ 4.38791518e-305, -2.00000715e+000, 4.17269252e-309]])numpy.distutils.ccompiler_opt.CCompilerOpt.feature_detect# method distutils.ccompiler_opt.CCompilerOpt.feature_detect(names)[source]# Return a list of CPU features that required to be detected sorted from the lowest to highest interest.# numpy.ma.masked_array.cumsum[#](#numpy-ma-masked-array-cumsum)
method

ma.masked_array.cumsum(*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5192-L5231)[#](#numpy.ma.masked_array.cumsum)
-
Return the cumulative sum of the array elements over the given axis.

Masked values are set to 0 internally during the computation. However, their position is saved, and the result will be masked at the same locations.

Refer to

for full documentation.`numpy.cumsum`
See also

`numpy.ndarray.cumsum`
corresponding function for ndarrays

`numpy.cumsum`
equivalent function

Notes

The mask is lost if

*out*is not a valid!`ma.MaskedArray`
Arithmetic is modular when using integer types, and no error is raised on overflow.

Examples

>>> marr = np.ma.array(np.arange(10), mask=[0,0,0,1,1,1,0,0,0,0]) >>> marr.cumsum() masked_array(data=[0, 1, 3, --, --, --, 9, 16, 24, 33], mask=[False, False, False, True, True, True, False, False, False, False], fill_value=999999)numpy.record.view# method record.view()# Scalar method identical to the corresponding array attribute. Please see ndarray.view.# numpy.polyadd[#](#numpy-polyadd)
numpy.polyadd(*a1*,*a2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/polynomial.py#L788-L853)[#](#numpy.polyadd)
-
Find the sum of two polynomials.

Note

This forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in

is preferred. A summary of the differences can be found in the`numpy.polynomial`
[transition guide](../routines.polynomials.html).Returns the polynomial resulting from the sum of two input polynomials. Each input must be either a poly1d object or a 1D sequence of polynomial coefficients, from highest to lowest degree.

Parameters:
-
**a1, a2**array_like or poly1d object
Input polynomials.

Returns:
-
**out**ndarray or poly1d object
The sum of the inputs. If either input is a poly1d object, then the output is also a poly1d object. Otherwise, it is a 1D array of polynomial coefficients from highest to lowest degree.

See also

Examples

>>> np.polyadd([1, 2], [9, 5, 4]) array([9, 6, 6])
Using poly1d objects:

>>> p1 = np.poly1d([1, 2]) >>> p2 = np.poly1d([9, 5, 4]) >>> print(p1) 1 x + 2 >>> print(p2) 2 9 x + 5 x + 4 >>> print(np.polyadd(p1, p2)) 2 9 x + 6 x + 6numpy.char.chararray.sum# method char.chararray.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)# Return the sum of the array elements over the given axis. Refer to numpy.sum for full documentation. See also numpy.sumequivalent function# numpy.ma.MaskedArray.choose[#](#numpy-ma-maskedarray-choose)
method

ma.MaskedArray.choose(*choices*,*out=None*,*mode='raise'*)[#](#numpy.ma.MaskedArray.choose)
-
Use an index array to construct a new array from a set of choices.

Refer to

for full documentation.`numpy.choose`
See also

`numpy.choose`
equivalent function# numpy.random.MT19937.cffi[#](#numpy-random-mt19937-cffi)
attribute

random.MT19937.cffi[#](#numpy.random.MT19937.cffi)
-
CFFI interface

Returns:
-
**interface**namedtuple
Named tuple containing CFFI wrapper

state_address - Memory address of the state struct

state - pointer to the state struct

next_uint64 - function pointer to produce 64 bit integers

next_uint32 - function pointer to produce 32 bit integers

next_double - function pointer to produce doubles

bitgen - pointer to the bit generator struct# numpy.matrix.tolist[#](#numpy-matrix-tolist)
method

matrix.tolist()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L265-L285)[#](#numpy.matrix.tolist)
-
Return the matrix as a (possibly nested) list.

See

for full documentation.`ndarray.tolist`
See also

Examples

>>> x = np.matrix(np.arange(12).reshape((3,4))); x matrix([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) >>> x.tolist() [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]numpy.ma.MaskedArray.__div__# method ma.MaskedArray.__div__(other)[source]# Divide other into self, and return a new masked array.# numpy.ma.stack[#](#numpy-ma-stack)
ma.stack*= <numpy.ma.extras._fromnxfunction_seq object>*[#](#numpy.ma.stack)
-
stack

Join a sequence of arrays along a new axis.

The

`axis`
parameter specifies the index of the new axis in the dimensions of the result. For example, if`axis=0`
it will be the first dimension and if`axis=-1`
it will be the last dimension.New in version 1.10.0.

Parameters:
-
**arrays**sequence of array_like
Each array must have the same shape.

**axis**int, optional
The axis in the result array along which the input arrays are stacked.

**out**ndarray, optional
If provided, the destination to place the result. The shape must be correct, matching that of what stack would have returned if no out argument were specified.

**dtype**str or dtype
If provided, the destination array will have this dtype. Cannot be provided together with

*out*.New in version 1.24.

**casting**{‘no’, ‘equiv’, ‘safe’, ‘same_kind’, ‘unsafe’}, optional
Controls what kind of data casting may occur. Defaults to ‘same_kind’.

New in version 1.24.

Returns:
-
**stacked**ndarray
The stacked array has one more dimension than the input arrays.

See also

`concatenate`
Join a sequence of arrays along an existing axis.

`block`
Assemble an nd-array from nested lists of blocks.

`split`
Split array into a list of multiple sub-arrays of equal size.

Notes

The function is applied to both the _data and the _mask, if any.

Examples

>>> arrays = [np.random.randn(3, 4) for _ in range(10)] >>> np.stack(arrays, axis=0).shape (10, 3, 4)
>>> np.stack(arrays, axis=1).shape (3, 10, 4)
>>> np.stack(arrays, axis=2).shape (3, 4, 10)
>>> a = np.array([1, 2, 3]) >>> b = np.array([4, 5, 6]) >>> np.stack((a, b)) array([[1, 2, 3], [4, 5, 6]])
>>> np.stack((a, b), axis=-1) array([[1, 4], [2, 5], [3, 6]])# numpy.ma.unique[#](#numpy-ma-unique)
ma.unique(*ar1*,*return_index=False*,*return_inverse=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L1180-L1227)[#](#numpy.ma.unique)
-
Finds the unique elements of an array.

Masked values are considered the same element (masked). The output array is always a masked array. See

for more details.`numpy.unique`
See also

`numpy.unique`
Equivalent function for ndarrays.

Examples

>>> import numpy.ma as ma >>> a = [1, 2, 1000, 2, 3] >>> mask = [0, 0, 1, 0, 0] >>> masked_a = ma.masked_array(a, mask) >>> masked_a masked_array(data=[1, 2, --, 2, 3], mask=[False, False, True, False, False], fill_value=999999) >>> ma.unique(masked_a) masked_array(data=[1, 2, 3, --], mask=[False, False, False, True], fill_value=999999) >>> ma.unique(masked_a, return_index=True) (masked_array(data=[1, 2, 3, --], mask=[False, False, False, True], fill_value=999999), array([0, 1, 4, 2])) >>> ma.unique(masked_a, return_inverse=True) (masked_array(data=[1, 2, 3, --], mask=[False, False, False, True], fill_value=999999), array([0, 1, 3, 1, 2])) >>> ma.unique(masked_a, return_index=True, return_inverse=True) (masked_array(data=[1, 2, 3, --], mask=[False, False, False, True], fill_value=999999), array([0, 1, 4, 2]), array([0, 1, 3, 1, 2]))# numpy.chararray.strip[#](#numpy-chararray-strip)
method

chararray.strip(*chars=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2630-L2640)[#](#numpy.chararray.strip)
-
For each element in

*self*, return a copy with the leading and trailing characters removed.See also

method

For each element in *self*, return a copy with the leading and
trailing characters removed.

See alsonumpy.polynomial.polynomial.Polynomial.has_samedomain# method polynomial.polynomial.Polynomial.has_samedomain(other)[source]# Check if domains match. New in version 1.6.0. Parameters: otherclass instanceThe other class must have the domain attribute. Returns: boolbooleanTrue if the domains are the same, False otherwise.# numpy.ndarray.fill[#](#numpy-ndarray-fill)
method

ndarray.fill(*value*)[#](#numpy.ndarray.fill)
-
Fill the array with a scalar value.

Parameters:
-
**value**scalar
All elements of

*a*will be assigned this value.
Examples

>>> a = np.array([1, 2]) >>> a.fill(0) >>> a array([0, 0]) >>> a = np.empty(2) >>> a.fill(1) >>> a array([1., 1.])
Fill expects a scalar value and always behaves the same as assigning to a single array element. The following is a rare example where this distinction is important:

>>> a = np.array([None, None], dtype=object) >>> a[0] = np.array(3) >>> a array([array(3), None], dtype=object) >>> a.fill(np.array(3)) >>> a array([array(3), array(3)], dtype=object)
Where other forms of assignments will unpack the array being assigned:

>>> a[...] = np.array(3) >>> a array([3, 3], dtype=object)numpy.record.tolist# method record.tolist()# Scalar method identical to the corresponding array attribute. Please see ndarray.tolist.# numpy.ma.around[#](#numpy-ma-around)
ma.around*= <numpy.ma.core._MaskedUnaryOperation object>*[#](#numpy.ma.around)
-
Round an array to the given number of decimals.

`round_`
is a disrecommended backwards-compatibility alias ofand`around`
.`round`
Deprecated since version 1.25.0:

`round_`
is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please useinstead.`round`
See also

`around`
equivalent function; see for details.# numpy.chararray.rstrip[#](#numpy-chararray-rstrip)
method

chararray.rstrip(*chars=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2582-L2592)[#](#numpy.chararray.rstrip)
-
For each element in

*self*, return a copy with the trailing characters removed.See also

method

For each element in *self*, return a copy with the trailing
characters removed.

See alsonumpy.polynomial.legendre.Legendre.roots# method polynomial.legendre.Legendre.roots()[source]# Return the roots of the series polynomial. Compute the roots for the series. Note that the accuracy of the roots decreases the further outside the domain they lie. Returns: rootsndarrayArray containing the roots of the series.# numpy.ma.MaskedArray.repeat[#](#numpy-ma-maskedarray-repeat)
method

ma.MaskedArray.repeat(*repeats*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2571-L2581)[#](#numpy.ma.MaskedArray.repeat)
-
Repeat elements of an array.

Refer to

for full documentation.`numpy.repeat`
See also

`numpy.repeat`
equivalent function

method

Repeat elements of an array.

Refer to [ numpy.repeat](numpy.repeat.html#numpy.repeat) for full documentation.

See also

`numpy.repeat`
equivalent function# numpy.polynomial.hermite.Hermite.identity[#](#numpy-polynomial-hermite-hermite-identity)
method

*classmethod*polynomial.hermite.Hermite.identity(*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1090-L1123)[#](#numpy.polynomial.hermite.Hermite.identity)
-
Identity function.

If

`p`
is the returned series, then`p(x) == x`
for all values of x.Parameters:
-
**domain**{None, array_like}, optional
If given, the array must be of the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the domain. If None is given then the class domain is used. The default is None.
**window**{None, array_like}, optional
If given, the resulting array must be if the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the window. If None is given then the class window is used. The default is None.
**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
Series of representing the identity.# numpy.distutils.ccompiler.CCompiler_object_filenames[#](#numpy-distutils-ccompiler-ccompiler-object-filenames)
distutils.ccompiler.CCompiler_object_filenames(*self*,*source_filenames*,*strip_dir=0*,*output_dir=''*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/ccompiler.py#L187-L230)[#](#numpy.distutils.ccompiler.CCompiler_object_filenames)
-
Return the name of the object files for the given source files.

Parameters:
-
**source_filenames**list of str
The list of paths to source files. Paths can be either relative or absolute, this is handled transparently.

**strip_dir**bool, optional
Whether to strip the directory from the returned paths. If True, the file name prepended by

*output_dir*is returned. Default is False.
**output_dir**str, optional
If given, this path is prepended to the returned paths to the object files.

Returns:
-
**obj_names**list of str
The list of paths to the object files corresponding to the source files in

*source_filenames*.# numpy.ma.transpose[#](#numpy-ma-transpose)
ma.transpose(*a*,*axes=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7320-L7355)[#](#numpy.ma.transpose)
-
Permute the dimensions of an array.

This function is exactly equivalent to

.`numpy.transpose`
See also

`numpy.transpose`
Equivalent function in top-level NumPy module.

Examples

>>> import numpy.ma as ma >>> x = ma.arange(4).reshape((2,2)) >>> x[1, 1] = ma.masked >>> x masked_array( data=[[0, 1], [2, --]], mask=[[False, False], [False, True]], fill_value=999999)
>>> ma.transpose(x) masked_array( data=[[0, 2], [1, --]], mask=[[False, False], [False, True]], fill_value=999999)# numpy.random.RandomState.bytes[#](#numpy-random-randomstate-bytes)
method

random.RandomState.bytes(*length*)[#](#numpy.random.RandomState.bytes)
-
Return random bytes.

Note

New code should use the

method of a`bytes`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**length**int
Number of random bytes.

Returns:
-
**out**bytes
String of length

*length*.
See also

`random.Generator.bytes`
which should be used for new code.

Examples

>>> np.random.bytes(10) b' eh\x85\x022SZ\xbf\xa4' #random# numpy.polynomial.polynomial.Polynomial.fromroots[#](#numpy-polynomial-polynomial-polynomial-fromroots)
method

*classmethod*polynomial.polynomial.Polynomial.fromroots(*roots*,*domain=[]*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1047-L1088)[#](#numpy.polynomial.polynomial.Polynomial.fromroots)
-
Return series instance that has the specified roots.

Returns a series representing the product

`(x - r[0])*(x - r[1])*...*(x - r[n-1])`
, where`r`
is a list of roots.Parameters:
-
**roots**array_like
List of roots.

**domain**{[], None, array_like}, optional
Domain for the resulting series. If None the domain is the interval from the smallest root to the largest. If [] the domain is the class domain. The default is [].

**window**{None, array_like}, optional
Window for the returned series. If None the class window is used. The default is None.

**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
Series with the specified roots.# numpy.ma.MaskType.byteswap[#](#numpy-ma-masktype-byteswap)
method

ma.MaskType.byteswap()[#](#numpy.ma.MaskType.byteswap)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.byteswap`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.byteswap](numpy.ndarray.byteswap.html#numpy.ndarray.byteswap).# numpy.matrix.argmin[#](#numpy-matrix-argmin)
method

matrix.argmin(*axis=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L721-L758)[#](#numpy.matrix.argmin)
-
Indexes of the minimum values along an axis.

Return the indexes of the first occurrences of the minimum values along the specified axis. If axis is None, the index is for the flattened matrix.

Parameters:
-
**See `numpy.argmin` for complete descriptions.**
See also

Notes

This is the same as

, but returns a`ndarray.argmin`
object where`matrix`
would return an`ndarray.argmin`
.`ndarray`
Examples

>>> x = -np.matrix(np.arange(12).reshape((3,4))); x matrix([[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]]) >>> x.argmin() 11 >>> x.argmin(0) matrix([[2, 2, 2, 2]]) >>> x.argmin(1) matrix([[3], [3], [3]])# numpy.lib.arraysetops[#](#module-numpy.lib.arraysetops)
Set operations for arrays based on sorting.

## Notes[#](#notes)
For floating point arrays, inaccurate results may appear due to usual round-off and floating point comparison issues.

Speed could be gained in some operations by an implementation of
[ numpy.sort](numpy.sort.html#numpy.sort), that can provide directly the permutation vectors, thus avoiding
calls to

[.](numpy.argsort.html#numpy.argsort)
`numpy.argsort`
Original author: Robert Cimrman# numpy.insert[#](#numpy-insert)
numpy.insert(*arr*,*obj*,*values*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L5368-L5555)[#](#numpy.insert)
-
Insert values along the given axis before the given indices.

Parameters:
-
**arr**array_like
Input array.

**obj**int, slice or sequence of ints
Object that defines the index or indices before which

*values*is inserted.New in version 1.8.0.

Support for multiple insertions when

*obj*is a single scalar or a sequence with one element (similar to calling insert multiple times).
**values**array_like
Values to insert into

*arr*. If the type of*values*is different from that of*arr*,*values*is converted to the type of*arr*.*values*should be shaped so that`arr[...,obj,...] = values`
is legal.
**axis**int, optional
Axis along which to insert

*values*. If*axis*is None then*arr*is flattened first.
Returns:
-
**out**ndarray
A copy of

*arr*with*values*inserted. Note thatdoes not occur in-place: a new array is returned. If`insert`
*axis*is None,*out*is a flattened array.
See also

`append`
Append elements at the end of an array.

`concatenate`
Join a sequence of arrays along an existing axis.

`delete`
Delete elements from an array.

Notes

Note that for higher dimensional inserts

`obj=0`
behaves very different from`obj=[0]`
just like`arr[:,0,:] = values`
is different from`arr[:,[0],:] = values`
.Examples

>>> a = np.array([[1, 1], [2, 2], [3, 3]]) >>> a array([[1, 1], [2, 2], [3, 3]]) >>> np.insert(a, 1, 5) array([1, 5, 1, ..., 2, 3, 3]) >>> np.insert(a, 1, 5, axis=1) array([[1, 5, 1], [2, 5, 2], [3, 5, 3]])
Difference between sequence and scalars:

>>> np.insert(a, [1], [[1],[2],[3]], axis=1) array([[1, 1, 1], [2, 2, 2], [3, 3, 3]]) >>> np.array_equal(np.insert(a, 1, [1, 2, 3], axis=1), ... np.insert(a, [1], [[1],[2],[3]], axis=1)) True
>>> b = a.flatten() >>> b array([1, 1, 2, 2, 3, 3]) >>> np.insert(b, [2, 2], [5, 6]) array([1, 1, 5, ..., 2, 3, 3])
>>> np.insert(b, slice(2, 4), [5, 6]) array([1, 1, 5, ..., 2, 3, 3])
>>> np.insert(b, [2, 2], [7.13, False]) # type casting array([1, 1, 7, ..., 2, 3, 3])
>>> x = np.arange(8).reshape(2, 4) >>> idx = (1, 3) >>> np.insert(x, idx, 999, axis=1) array([[ 0, 999, 1, 2, 999, 3], [ 4, 999, 5, 6, 999, 7]])numpy.polynomial.hermite_e.HermiteE.copy# method polynomial.hermite_e.HermiteE.copy()[source]# Return a copy. Returns: new_seriesseriesCopy of self.numpy.polynomial.laguerre.Laguerre.roots# method polynomial.laguerre.Laguerre.roots()[source]# Return the roots of the series polynomial. Compute the roots for the series. Note that the accuracy of the roots decreases the further outside the domain they lie. Returns: rootsndarrayArray containing the roots of the series.# numpy.matrix.clip[#](#numpy-matrix-clip)
method

matrix.clip(*min=None*,*max=None*,*out=None*,***kwargs*)[#](#numpy.matrix.clip)
-
Return an array whose values are limited to

`[min, max]`
. One of max or min must be given.Refer to

for full documentation.`numpy.clip`
See also

`numpy.clip`
equivalent function# numpy.matrix.swapaxes[#](#numpy-matrix-swapaxes)
method

matrix.swapaxes(*axis1*,*axis2*)[#](#numpy.matrix.swapaxes)
-
Return a view of the array with

*axis1*and*axis2*interchanged.Refer to

for full documentation.`numpy.swapaxes`
See also

`numpy.swapaxes`
equivalent function

method

Return a view of the array with *axis1* and *axis2* interchanged.

Refer to [ numpy.swapaxes](numpy.swapaxes.html#numpy.swapaxes) for full documentation.

See also

`numpy.swapaxes`
equivalent function# numpy.char.chararray.mean[#](#numpy-char-chararray-mean)
method

char.chararray.mean(*axis=None*,*dtype=None*,*out=None*,*keepdims=False*,***,*where=True*)[#](#numpy.char.chararray.mean)
-
Returns the average of the array elements along given axis.

Refer to

for full documentation.`numpy.mean`
See also

`numpy.mean`
equivalent function# numpy.ma.append[#](#numpy-ma-append)
ma.append(*a*,*b*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L8525-L8565)[#](#numpy.ma.append)
-
Append values to the end of an array.

New in version 1.9.0.

Parameters:
-
**a**array_like
Values are appended to a copy of this array.

**b**array_like
These values are appended to a copy of

*a*. It must be of the correct shape (the same shape as*a*, excluding*axis*). If*axis*is not specified,*b*can be any shape and will be flattened before use.
**axis**int, optional
The axis along which

*v*are appended. If*axis*is not given, both*a*and*b*are flattened before use.
Returns:
-
**append**MaskedArray
A copy of

*a*with*b*appended to*axis*. Note thatdoes not occur in-place: a new array is allocated and filled. If`append`
*axis*is None, the result is a flattened array.
See also

`numpy.append`
Equivalent function in the top-level NumPy module.

Examples

>>> import numpy.ma as ma >>> a = ma.masked_values([1, 2, 3], 2) >>> b = ma.masked_values([[4, 5, 6], [7, 8, 9]], 7) >>> ma.append(a, b) masked_array(data=[1, --, 3, 4, 5, 6, --, 8, 9], mask=[False, True, False, False, False, False, True, False, False], fill_value=999999)numpy.broadcast.ndim# attribute broadcast.ndim# Number of dimensions of broadcasted result. Alias for nd. New in version 1.12.0. Examples >>> x = np.array([1, 2, 3]) >>> y = np.array([[4], [5], [6]]) >>> b = np.broadcast(x, y) >>> b.ndim 2# numpy.chararray.conj[#](#numpy-chararray-conj)
method

chararray.conj()[#](#numpy.chararray.conj)
-
Complex-conjugate all elements.

Refer to

for full documentation.`numpy.conjugate`
See also

`numpy.conjugate`
equivalent function

method

Complex-conjugate all elements.

Refer to [ numpy.conjugate](numpy.conjugate.html#numpy.conjugate) for full documentation.

See also

`numpy.conjugate`
equivalent functionnumpy.recarray.put# method recarray.put(indices, values, mode='raise')# Set a.flat[n] = values[n] for all n in indices. Refer to numpy.put for full documentation. See also numpy.putequivalent function# numpy.char.count[#](#numpy-char-count)
char.count(*a*,*sub*,*start=0*,*end=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L522-L565)[#](#numpy.char.count)
-
Returns an array with the number of non-overlapping occurrences of substring

*sub*in the range [*start*,*end*].Calls

*str.count*element-wise.Parameters:
-
**a**array_like of str or unicode
**sub**str or unicode
The substring to search for.

**start, end**int, optional
Optional arguments

*start*and*end*are interpreted as slice notation to specify the range in which to count.
Returns:
-
**out**ndarray
Output array of ints.

See also

Examples

>>> c = np.array(['aAaAaA', ' aA ', 'abBABba']) >>> c array(['aAaAaA', ' aA ', 'abBABba'], dtype='<U7') >>> np.char.count(c, 'A') array([3, 1, 1]) >>> np.char.count(c, 'aA') array([3, 1, 0]) >>> np.char.count(c, 'A', start=1, end=4) array([2, 1, 1]) >>> np.char.count(c, 'A', start=1, end=3) array([1, 0, 0])numpy.polynomial.legendre.Legendre.has_sametype# method polynomial.legendre.Legendre.has_sametype(other)[source]# Check if types match. New in version 1.7.0. Parameters: otherobjectClass instance. Returns: boolbooleanTrue if other is same class as selfndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__iand__

method

Return self&=value.Increment the multi-dimensional index by one.

This method is for backward compatibility only: do not use.

Deprecated since version 1.20.0: This method has been advised against since numpy 1.8.0, but only
started emitting DeprecationWarning as of this version.# numpy.ma.MaskType.argsort[#](#numpy-ma-masktype-argsort)
method

ma.MaskType.argsort()[#](#numpy.ma.MaskType.argsort)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.argsort`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.argsort](numpy.ndarray.argsort.html#numpy.ndarray.argsort).numpy.distutils.ccompiler_opt.CCompilerOpt.conf_cache_factors# attribute distutils.ccompiler_opt.CCompilerOpt.conf_cache_factors = None#numpy.flatiter.base# attribute flatiter.base# A reference to the array that is iterated over. Examples >>> x = np.arange(5) >>> fl = x.flat >>> fl.base is x True# numpy.ma.MaskType.setfield[#](#numpy-ma-masktype-setfield)
method

ma.MaskType.setfield()[#](#numpy.ma.MaskType.setfield)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.setfield`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.setfield](numpy.ndarray.setfield.html#numpy.ndarray.setfield).# numpy.hsplit[#](#numpy-hsplit)
numpy.hsplit(*ary*,*indices_or_sections*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L873-L940)[#](#numpy.hsplit)
-
Split an array into multiple sub-arrays horizontally (column-wise).

Please refer to the

documentation.`split`
is equivalent to`hsplit`
with`split`
`axis=1`
, the array is always split along the second axis except for 1-D arrays, where it is split at`axis=0`
.See also

`split`
Split an array into multiple sub-arrays of equal size.

Examples

>>> x = np.arange(16.0).reshape(4, 4) >>> x array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]]) >>> np.hsplit(x, 2) [array([[ 0., 1.], [ 4., 5.], [ 8., 9.], [12., 13.]]), array([[ 2., 3.], [ 6., 7.], [10., 11.], [14., 15.]])] >>> np.hsplit(x, np.array([3, 6])) [array([[ 0., 1., 2.], [ 4., 5., 6.], [ 8., 9., 10.], [12., 13., 14.]]), array([[ 3.], [ 7.], [11.], [15.]]), array([], shape=(4, 0), dtype=float64)]
With a higher dimensional array the split is still along the second axis.

>>> x = np.arange(8.0).reshape(2, 2, 2) >>> x array([[[0., 1.], [2., 3.]], [[4., 5.], [6., 7.]]]) >>> np.hsplit(x, 2) [array([[[0., 1.]], [[4., 5.]]]), array([[[2., 3.]], [[6., 7.]]])]
With a 1-D array, the split is along axis 0.

>>> x = np.array([0, 1, 2, 3, 4, 5]) >>> np.hsplit(x, 2) [array([0, 1, 2]), array([3, 4, 5])]# numpy.dtype.names[#](#numpy-dtype-names)
attribute

dtype.names[#](#numpy.dtype.names)
-
Ordered list of field names, or

`None`
if there are no fields.The names are ordered according to increasing byte offset. This can be used, for example, to walk through all of the named fields in offset order.

Examples

>>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))]) >>> dt.names ('name', 'grades')ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__le__

method

Return self<=value.# numpy.testing.suppress_warnings.filter[#](#numpy-testing-suppress-warnings-filter)
method

testing.suppress_warnings.filter(*category=<class 'Warning'>*,*message=''*,*module=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/_private/utils.py#L2125-L2146)[#](#numpy.testing.suppress_warnings.filter)
-
Add a new suppressing filter or apply it if the state is entered.

Parameters:
-
**category**class, optional
Warning class to filter

**message**string, optional
Regular expression matching the warning message.

**module**module, optional
Module to filter for. Note that the module (and its file) must match exactly and cannot be a submodule. This may make it unreliable for external modules.

Notes

When added within a context, filters are only added inside the context and will be forgotten when the context is exited.# numpy.chararray.ravel[#](#numpy-chararray-ravel)
method

chararray.ravel([*order*])[#](#numpy.chararray.ravel)
-
Return a flattened array.

Refer to

for full documentation.`numpy.ravel`
See also

`numpy.ravel`
equivalent function

`ndarray.flat`
a flat iterator on the array.

method

Return a flattened array.

Refer to [ numpy.ravel](numpy.ravel.html#numpy.ravel) for full documentation.

See also

`numpy.ravel`
equivalent function

`ndarray.flat`
a flat iterator on the array.# numpy.matrix.real[#](#numpy-matrix-real)
attribute

matrix.real[#](#numpy.matrix.real)
-
The real part of the array.

See also

`numpy.real`
equivalent function

Examples

>>> x = np.sqrt([1+0j, 0+1j]) >>> x.real array([ 1. , 0.70710678]) >>> x.real.dtype dtype('float64')
attribute

The real part of the array.

See also

`numpy.real`
equivalent function

Examples

```
>>> x = np.sqrt([1+0j, 0+1j])
>>> x.real
array([ 1. , 0.70710678])
>>> x.real.dtype
dtype('float64')
```# numpy.polynomial.laguerre.Laguerre.degree[#](#numpy-polynomial-laguerre-laguerre-degree)
method

polynomial.laguerre.Laguerre.degree()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L675-L708)[#](#numpy.polynomial.laguerre.Laguerre.degree)
-
The degree of the series.

New in version 1.5.0.

Returns:
-
**degree**int
Degree of the series, one less than the number of coefficients.

Examples

Create a polynomial object for

`1 + 7*x + 4*x**2`
:>>> poly = np.polynomial.Polynomial([1, 7, 4]) >>> print(poly) 1.0 + 7.0·x + 4.0·x² >>> poly.degree() 2
Note that this method does not check for non-zero coefficients. You must trim the polynomial to remove any trailing zeroes:

>>> poly = np.polynomial.Polynomial([1, 7, 0]) >>> print(poly) 1.0 + 7.0·x + 0.0·x² >>> poly.degree() 2 >>> poly.trim().degree() 1numpy.memmap.tostring# method memmap.tostring(order='C')# A compatibility alias for tobytes, with exactly the same behavior. Despite its name, it returns bytes not strs. Deprecated since version 1.19.0.# numpy.char.rsplit[#](#numpy-char-rsplit)
char.rsplit(*a*,*sep=None*,*maxsplit=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1421-L1456)[#](#numpy.char.rsplit)
-
For each element in

*a*, return a list of the words in the string, using*sep*as the delimiter string.Calls

*str.rsplit*element-wise.Except for splitting from the right,

behaves like`rsplit`
.`split`
Parameters:
-
**a**array_like of str or unicode
**sep**str or unicode, optional
If

*sep*is not specified or None, any whitespace string is a separator.
**maxsplit**int, optional
If

*maxsplit*is given, at most*maxsplit*splits are done, the rightmost ones.
Returns:
-
**out**ndarray
Array of list objects

See also# numpy.chararray.rjust[#](#numpy-chararray-rjust)
method

chararray.rjust(*width*,*fillchar=' '*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2548-L2558)[#](#numpy.chararray.rjust)
-
Return an array with the elements of

*self*right-justified in a string of length*width*.See also

method

Return an array with the elements of *self*
right-justified in a string of length *width*.

See alsonumpy.matrix.put# method matrix.put(indices, values, mode='raise')# Set a.flat[n] = values[n] for all n in indices. Refer to numpy.put for full documentation. See also numpy.putequivalent function# numpy.testing.assert_string_equal[#](#numpy-testing-assert-string-equal)
testing.assert_string_equal(*actual*,*desired*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/_private/utils.py#L1122-L1190)[#](#numpy.testing.assert_string_equal)
-
Test if two strings are equal.

If the given strings are equal,

does nothing. If they are not equal, an AssertionError is raised, and the diff between the strings is shown.`assert_string_equal`
Parameters:
-
**actual**str
The string to test for equality against the expected string.

**desired**str
The expected string.

Examples

>>> np.testing.assert_string_equal('abc', 'abc') >>> np.testing.assert_string_equal('abc', 'abcd') Traceback (most recent call last): File "<stdin>", line 1, in <module> ... AssertionError: Differences in strings: - abc+ abcd? +numpy.polynomial.hermite_e.HermiteE.roots# method polynomial.hermite_e.HermiteE.roots()[source]# Return the roots of the series polynomial. Compute the roots for the series. Note that the accuracy of the roots decreases the further outside the domain they lie. Returns: rootsndarrayArray containing the roots of the series.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
ma.MaskType.itemsize
numpy.ma.MaskType.itemsize
#
attribute
ma.MaskType.
itemsize
#
The length of one element in bytes.# numpy.random.BitGenerator.seed_seq[#](#numpy-random-bitgenerator-seed-seq)
attribute

random.BitGenerator.seed_seq[#](#numpy.random.BitGenerator.seed_seq)
-
Get the seed sequence used to initialize the bit generator.

New in version 1.25.0.

Returns:
-
**seed_seq**ISeedSequence
The SeedSequence object used to initialize the BitGenerator. This is normally a

*np.random.SeedSequence*instance.# numpy.record[#](#numpy-record)
*class*numpy.record[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/src/multiarray/scalartypes.c.src)[#](#numpy.record)
-
A data-type scalar that allows field access as attribute lookup.

Attributes:
-
`T`
Scalar attribute identical to the corresponding array attribute.

`base`
base object

`data`
Pointer to start of data.

`dtype`
dtype object

`flags`
integer value of flags

`flat`
A 1-D view of the scalar.

`imag`
The imaginary part of the scalar.

`itemsize`
The length of one element in bytes.

`nbytes`
The length of the scalar in bytes.

`ndim`
The number of array dimensions.

`real`
The real part of the scalar.

`shape`
Tuple of array dimensions.

`size`
The number of elements in the gentype.

`strides`
Tuple of bytes steps in each dimension.

Methods

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

([new_order])`newbyteorder`
Return a new

with a different byte order.`dtype`
Scalar method identical to the corresponding array attribute.

()`pprint`
Pretty-print all fields.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

Scalar method identical to the corresponding array attribute.

**conj****tobytes**User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
ma.MaskType.shape
numpy.ma.MaskType.shape
#
attribute
ma.MaskType.
shape
#
Tuple of array dimensions.# numpy.matrix.compress[#](#numpy-matrix-compress)
method

matrix.compress(*condition*,*axis=None*,*out=None*)[#](#numpy.matrix.compress)
-
Return selected slices of this array along given axis.

Refer to

for full documentation.`numpy.compress`
See also

`numpy.compress`
equivalent function

method

Return selected slices of this array along given axis.

Refer to [ numpy.compress](numpy.compress.html#numpy.compress) for full documentation.

See also

`numpy.compress`
equivalent function# numpy.random.RandomState.seed[#](#numpy-random-randomstate-seed)
method

random.RandomState.seed(*seed=None*)[#](#numpy.random.RandomState.seed)
-
Reseed a legacy MT19937 BitGenerator

Notes

This is a convenience, legacy function.

The best practice is to

**not**reseed a BitGenerator, rather to recreate a new one. This method is here for legacy reasons. This example demonstrates best practice.>>> from numpy.random import MT19937 >>> from numpy.random import RandomState, SeedSequence >>> rs = RandomState(MT19937(SeedSequence(123456789))) # Later, you want to restart the stream >>> rs = RandomState(MT19937(SeedSequence(987654321)))ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__imod__

method

Return self%=value.# numpy.polynomial.laguerre.Laguerre.convert[#](#numpy-polynomial-laguerre-laguerre-convert)
method

polynomial.laguerre.Laguerre.convert(*domain=None*,*kind=None*,*window=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L787-L822)[#](#numpy.polynomial.laguerre.Laguerre.convert)
-
Convert series to a different kind and/or domain and/or window.

Parameters:
-
**domain**array_like, optional
The domain of the converted series. If the value is None, the default domain of

*kind*is used.
**kind**class, optional
The polynomial series type class to which the current instance should be converted. If kind is None, then the class of the current instance is used.

**window**array_like, optional
The window of the converted series. If the value is None, the default window of

*kind*is used.
Returns:
-
**new_series**series
The returned class can be of different type than the current instance and/or have a different domain and/or different window.

Notes

Conversion between domains and class types can result in numerically ill defined series.# numpy.ma.isMA[#](#numpy-ma-isma)
ma.isMA(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L6485-L6533)[#](#numpy.ma.isMA)
-
Test whether input is an instance of MaskedArray.

This function returns True if

*x*is an instance of MaskedArray and returns False otherwise. Any object is accepted as input.Parameters:
-
**x**object
Object to test.

Returns:
-
**result**bool
True if

*x*is a MaskedArray.
Examples

>>> import numpy.ma as ma >>> a = np.eye(3, 3) >>> a array([[ 1., 0., 0.], [ 0., 1., 0.], [ 0., 0., 1.]]) >>> m = ma.masked_values(a, 0) >>> m masked_array( data=[[1.0, --, --], [--, 1.0, --], [--, --, 1.0]], mask=[[False, True, True], [ True, False, True], [ True, True, False]], fill_value=0.0) >>> ma.isMaskedArray(a) False >>> ma.isMaskedArray(m) True >>> ma.isMaskedArray([0, 1, 2]) False# numpy.recarray.max[#](#numpy-recarray-max)
method

recarray.max(*axis=None*,*out=None*,*keepdims=False*,*initial=<no value>*,*where=True*)[#](#numpy.recarray.max)
-
Return the maximum along a given axis.

Refer to

for full documentation.`numpy.amax`
See also

`numpy.amax`
equivalent function

method

Return the maximum along a given axis.

Refer to [ numpy.amax](numpy.amax.html#numpy.amax) for full documentation.

See also

`numpy.amax`
equivalent function# numpy.ma.flatnotmasked_edges[#](#numpy-ma-flatnotmasked-edges)
ma.flatnotmasked_edges(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L1733-L1785)[#](#numpy.ma.flatnotmasked_edges)
-
Find the indices of the first and last unmasked values.

Expects a 1-D

, returns None if all values are masked.`MaskedArray`
Parameters:
-
**a**array_like
Input 1-D

`MaskedArray`
Returns:
-
**edges**ndarray or None
The indices of first and last non-masked value in the array. Returns None if all values are masked.

See also

Notes

Only accepts 1-D arrays.

Examples

>>> a = np.ma.arange(10) >>> np.ma.flatnotmasked_edges(a) array([0, 9])
>>> mask = (a < 3) | (a > 8) | (a == 5) >>> a[mask] = np.ma.masked >>> np.array(a[~a.mask]) array([3, 4, 6, 7, 8])
>>> np.ma.flatnotmasked_edges(a) array([3, 8])
>>> a[:] = np.ma.masked >>> print(np.ma.flatnotmasked_edges(a)) Nonenumpy.char.chararray.rpartition# method char.chararray.rpartition(sep)[source]# Partition each element in self around sep. See also rpartitionnumpy.distutils.ccompiler_opt.CCompilerOpt.conf_target_groups# attribute distutils.ccompiler_opt.CCompilerOpt.conf_target_groups = {}## numpy.finfo.smallest_normal[#](#numpy-finfo-smallest-normal)
property

*property*finfo.smallest_normal[#](#numpy.finfo.smallest_normal)
-
Return the value for the smallest normal.

Returns:
-
**smallest_normal**float
Value for the smallest normal.

Warns:
-
UserWarning
-
If the calculated value for the smallest normal is requested for double-double.# numpy.distutils.ccompiler_opt.CCompilerOpt.feature_ahead[#](#numpy-distutils-ccompiler-opt-ccompileropt-feature-ahead)
method

distutils.ccompiler_opt.CCompilerOpt.feature_ahead(*names*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/ccompiler_opt.py#L1404-L1440)[#](#numpy.distutils.ccompiler_opt.CCompilerOpt.feature_ahead)
-
Return list of features in ‘names’ after remove any implied features and keep the origins.

Parameters:
-
**‘names’: sequence**
sequence of CPU feature names in uppercase.

Returns:
-
list of CPU features sorted as-is ‘names’
-
Examples

>>> self.feature_ahead(["SSE2", "SSE3", "SSE41"]) ["SSE41"] # assume AVX2 and FMA3 implies each other and AVX2 # is the highest interest >>> self.feature_ahead(["SSE2", "SSE3", "SSE41", "AVX2", "FMA3"]) ["AVX2"] # assume AVX2 and FMA3 don't implies each other >>> self.feature_ahead(["SSE2", "SSE3", "SSE41", "AVX2", "FMA3"]) ["AVX2", "FMA3"]numpy.memmap.flush# method memmap.flush()[source]# Write any changes in the array to the file on disk. For further information, see memmap. Parameters: None See also memmapnumpy.memmap.ptp# method memmap.ptp(axis=None, out=None, keepdims=False)# Peak to peak (maximum - minimum) value along a given axis. Refer to numpy.ptp for full documentation. See also numpy.ptpequivalent functionnumpy.nditer.close# method nditer.close()# Resolve all writeback semantics in writeable operands. New in version 1.15.0. See also Modifying array valuesnumpy.vectorize.__call__# method vectorize.__call__(*args, **kwargs)[source]# Call self as a function.# numpy.char.chararray.fill[#](#numpy-char-chararray-fill)
method

char.chararray.fill(*value*)[#](#numpy.char.chararray.fill)
-
Fill the array with a scalar value.

Parameters:
-
**value**scalar
All elements of

*a*will be assigned this value.
Examples

>>> a = np.array([1, 2]) >>> a.fill(0) >>> a array([0, 0]) >>> a = np.empty(2) >>> a.fill(1) >>> a array([1., 1.])
Fill expects a scalar value and always behaves the same as assigning to a single array element. The following is a rare example where this distinction is important:

>>> a = np.array([None, None], dtype=object) >>> a[0] = np.array(3) >>> a array([array(3), None], dtype=object) >>> a.fill(np.array(3)) >>> a array([array(3), array(3)], dtype=object)
Where other forms of assignments will unpack the array being assigned:

>>> a[...] = np.array(3) >>> a array([3, 3], dtype=object)numpy.ma.MaskedArray.__getitem__# method ma.MaskedArray.__getitem__(indx)[source]# x.__getitem__(y) <==> x[y] Return the item described by i, as a masked array.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__complex__
numpy.ndarray.__complex__
#
method
ndarray.
__complex__
(
)
#User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__itruediv__
numpy.ndarray.__itruediv__
#
method
ndarray.
__itruediv__
(
value
,
/
)
#
Return self/=value.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
distutils.misc_util
numpy.distutils.ccompiler
numpy.distutils.ccompiler_opt
numpy.distutils.cpuinfo.cpu
numpy.distutils.core.Extension
numpy.distutils.exec_command
numpy.distutils.log.set_verbosity
numpy.distutils.system_info.get_info
numpy.distutils.system_info.get_standard_file
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
distutils.cpuinfo.cpu
numpy.distutils.cpuinfo.cpu
#
distutils.cpuinfo.
cpu
=
<numpy.distutils.cpuinfo.LinuxCPUInfo
object>
## numpy.ma.MaskedArray.dump[#](#numpy-ma-maskedarray-dump)
method

ma.MaskedArray.dump(*file*)[#](#numpy.ma.MaskedArray.dump)
-
Dump a pickle of the array to the specified file. The array can be read back with pickle.load or numpy.load.

Parameters:
-
**file**str or Path
A string naming the dump file.

Changed in version 1.17.0:

objects are now accepted.`pathlib.Path`# numpy.ma.diag[#](#numpy-ma-diag)
ma.diag(*v*,*k=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7155-L7202)[#](#numpy.ma.diag)
-
Extract a diagonal or construct a diagonal array.

This function is the equivalent of

that takes masked values into account, see`numpy.diag`
for details.`numpy.diag`
See also

`numpy.diag`
Equivalent function for ndarrays.

Examples

Create an array with negative values masked:

>>> import numpy as np >>> x = np.array([[11.2, -3.973, 18], [0.801, -1.41, 12], [7, 33, -12]]) >>> masked_x = np.ma.masked_array(x, mask=x < 0) >>> masked_x masked_array( data=[[11.2, --, 18.0], [0.801, --, 12.0], [7.0, 33.0, --]], mask=[[False, True, False], [False, True, False], [False, False, True]], fill_value=1e+20)
Isolate the main diagonal from the masked array:

>>> np.ma.diag(masked_x) masked_array(data=[11.2, --, --], mask=[False, True, True], fill_value=1e+20)
Isolate the first diagonal below the main diagonal:

>>> np.ma.diag(masked_x, -1) masked_array(data=[0.801, 33.0], mask=[False, False], fill_value=1e+20)# numpy.matrix.argsort[#](#numpy-matrix-argsort)
method

matrix.argsort(*axis=-1*,*kind=None*,*order=None*)[#](#numpy.matrix.argsort)
-
Returns the indices that would sort this array.

Refer to

for full documentation.`numpy.argsort`
See also

`numpy.argsort`
equivalent function

method

Returns the indices that would sort this array.

Refer to [ numpy.argsort](numpy.argsort.html#numpy.argsort) for full documentation.

See also

`numpy.argsort`
equivalent functionSearch Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# numpy.testing.overrides.allows_array_ufunc_override[#](#numpy-testing-overrides-allows-array-ufunc-override)
testing.overrides.allows_array_ufunc_override(*func*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/overrides.py#L27-L47)[#](#numpy.testing.overrides.allows_array_ufunc_override)
-
Determine if a function can be overridden via

*__array_ufunc__*Parameters:
-
**func**callable
Function that may be overridable via

*__array_ufunc__*
Returns:
-
bool
-
*True*if*func*is overridable via*__array_ufunc__*and*False*otherwise.
Notes

This function is equivalent to

`isinstance(func, np.ufunc)`
and will work correctly for ufuncs defined outside of Numpy.# numpy.ma.reshape[#](#numpy-ma-reshape)
ma.reshape(*a*,*new_shape*,*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7358-L7374)[#](#numpy.ma.reshape)
-
Returns an array containing the same data with a new shape.

Refer to

for full documentation.`MaskedArray.reshape`
See also

`MaskedArray.reshape`
equivalent function

Returns an array containing the same data with a new shape.

Refer to [ MaskedArray.reshape](numpy.ma.MaskedArray.reshape.html#numpy.ma.MaskedArray.reshape) for full documentation.

See also

`MaskedArray.reshape`
equivalent functionnumpy.polynomial.legendre.Legendre.domain# attribute polynomial.legendre.Legendre.domain = array([-1, 1])## numpy.polynomial.hermite_e.hermemulx[#](#numpy-polynomial-hermite-e-hermemulx)
polynomial.hermite_e.hermemulx(*c*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/hermite_e.py#L392-L438)[#](#numpy.polynomial.hermite_e.hermemulx)
-
Multiply a Hermite series by x.

Multiply the Hermite series

*c*by x, where x is the independent variable.Parameters:
-
**c**array_like
1-D array of Hermite series coefficients ordered from low to high.

Returns:
-
**out**ndarray
Array representing the result of the multiplication.

Notes

The multiplication uses the recursion relationship for Hermite polynomials in the form

\[xP_i(x) = (P_{i + 1}(x) + iP_{i - 1}(x)))\]Examples

>>> from numpy.polynomial.hermite_e import hermemulx >>> hermemulx([1, 2, 3]) array([2., 7., 2., 3.])# numpy.ediff1d[#](#numpy-ediff1d)
numpy.ediff1d(*ary*,*to_end=None*,*to_begin=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/arraysetops.py#L37-L122)[#](#numpy.ediff1d)
-
The differences between consecutive elements of an array.

Parameters:
-
**ary**array_like
If necessary, will be flattened before the differences are taken.

**to_end**array_like, optional
Number(s) to append at the end of the returned differences.

**to_begin**array_like, optional
Number(s) to prepend at the beginning of the returned differences.

Returns:
-
**ediff1d**ndarray
The differences. Loosely, this is

`ary.flat[1:] - ary.flat[:-1]`
.
Notes

When applied to masked arrays, this function drops the mask information if the

*to_begin*and/or*to_end*parameters are used.Examples

>>> x = np.array([1, 2, 4, 7, 0]) >>> np.ediff1d(x) array([ 1, 2, 3, -7])
>>> np.ediff1d(x, to_begin=-99, to_end=np.array([88, 99])) array([-99, 1, 2, ..., -7, 88, 99])
The returned array is always 1D.

>>> y = [[1, 2, 4], [1, 6, 24]] >>> np.ediff1d(y) array([ 1, 2, -3, 5, 18])# numpy.testing.assert_approx_equal[#](#numpy-testing-assert-approx-equal)
testing.assert_approx_equal(*actual*,*desired*,*significant=7*,*err_msg=''*,*verbose=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/_private/utils.py#L540-L638)[#](#numpy.testing.assert_approx_equal)
-
Raises an AssertionError if two items are not equal up to significant digits.

Note

It is recommended to use one of

,`assert_allclose`
or`assert_array_almost_equal_nulp`
instead of this function for more consistent floating point comparisons.`assert_array_max_ulp`
Given two numbers, check that they are approximately equal. Approximately equal is defined as the number of significant digits that agree.

Parameters:
-
**actual**scalar
The object to check.

**desired**scalar
The expected object.

**significant**int, optional
Desired precision, default is 7.

**err_msg**str, optional
The error message to be printed in case of failure.

**verbose**bool, optional
If True, the conflicting values are appended to the error message.

Raises:
-
AssertionError
-
If actual and desired are not equal up to specified precision.

See also

`assert_allclose`
Compare two array_like objects for equality with desired relative and/or absolute precision.

,`assert_array_almost_equal_nulp`
,`assert_array_max_ulp`
`assert_equal`
Examples

>>> np.testing.assert_approx_equal(0.12345677777777e-20, 0.1234567e-20) >>> np.testing.assert_approx_equal(0.12345670e-20, 0.12345671e-20, ... significant=8) >>> np.testing.assert_approx_equal(0.12345670e-20, 0.12345672e-20, ... significant=8) Traceback (most recent call last): ... AssertionError: Items are not equal to 8 significant digits: ACTUAL: 1.234567e-21 DESIRED: 1.2345672e-21
the evaluated condition that raises the exception is

>>> abs(0.12345670e-20/1e-21 - 0.12345672e-20/1e-21) >= 10**-(8-1) True# numpy.chararray.take[#](#numpy-chararray-take)
method

chararray.take(*indices*,*axis=None*,*out=None*,*mode='raise'*)[#](#numpy.chararray.take)
-
Return an array formed from the elements of

*a*at the given indices.Refer to

for full documentation.`numpy.take`
See also

`numpy.take`
equivalent function# numpy.chararray.max[#](#numpy-chararray-max)
method

chararray.max(*axis=None*,*out=None*,*keepdims=False*,*initial=<no value>*,*where=True*)[#](#numpy.chararray.max)
-
Return the maximum along a given axis.

Refer to

for full documentation.`numpy.amax`
See also

`numpy.amax`
equivalent functionUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
poly1d.coefficients
numpy.poly1d.coefficients
#
property
property
poly1d.
coefficients
#
The polynomial coefficients# numpy.record.setflags[#](#numpy-record-setflags)
method

record.setflags()[#](#numpy.record.setflags)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.setflags`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.setflags](numpy.ndarray.setflags.html#numpy.ndarray.setflags).User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
lib.user_array.container.tobytes
numpy.lib.user_array.container.tobytes
#
method
lib.user_array.container.
tobytes
(
)
[source]
#numpy.record.reshape# method record.reshape()# Scalar method identical to the corresponding array attribute. Please see ndarray.reshape.# numpy.matrix.A[#](#numpy-matrix-a)
property

*property*matrix.A[#](#numpy.matrix.A)
-
Return

*self*as anobject.`ndarray`
Equivalent to

`np.asarray(self)`
.Parameters:
-
**None**
Returns:
-
**ret**ndarray
*self*as an`ndarray`
Examples

>>> x = np.matrix(np.arange(12).reshape((3,4))); x matrix([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) >>> x.getA() array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])# numpy.ndarray.conjugate[#](#numpy-ndarray-conjugate)
method

ndarray.conjugate()[#](#numpy.ndarray.conjugate)
-
Return the complex conjugate, element-wise.

Refer to

for full documentation.`numpy.conjugate`
See also

`numpy.conjugate`
equivalent function

method

Return the complex conjugate, element-wise.

Refer to [ numpy.conjugate](numpy.conjugate.html#numpy.conjugate) for full documentation.

See also

`numpy.conjugate`
equivalent function# numpy.polynomial.polyutils.mapdomain[#](#numpy-polynomial-polyutils-mapdomain)
polynomial.polyutils.mapdomain(*x*,*old*,*new*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polyutils.py#L307-L372)[#](#numpy.polynomial.polyutils.mapdomain)
-
Apply linear map to input points.

The linear map

`offset + scale*x`
that maps the domain*old*to the domain*new*is applied to the points*x*.Parameters:
-
**x**array_like
Points to be mapped. If

*x*is a subtype of ndarray the subtype will be preserved.
**old, new**array_like
The two domains that determine the map. Each must (successfully) convert to 1-d arrays containing precisely two values.

Returns:
-
**x_out**ndarray
Array of points of the same shape as

*x*, after application of the linear map between the two domains.
Notes

Effectively, this implements:

\[x\_out = new[0] + m(x - old[0])\]where

\[m = \frac{new[1]-new[0]}{old[1]-old[0]}\]Examples

>>> from numpy.polynomial import polyutils as pu >>> old_domain = (-1,1) >>> new_domain = (0,2*np.pi) >>> x = np.linspace(-1,1,6); x array([-1. , -0.6, -0.2, 0.2, 0.6, 1. ]) >>> x_out = pu.mapdomain(x, old_domain, new_domain); x_out array([ 0. , 1.25663706, 2.51327412, 3.76991118, 5.02654825, # may vary 6.28318531]) >>> x - pu.mapdomain(x_out, new_domain, old_domain) array([0., 0., 0., 0., 0., 0.])
Also works for complex numbers (and thus can be used to map any line in the complex plane to any other line therein).

>>> i = complex(0,1) >>> old = (-1 - i, 1 + i) >>> new = (-1 + i, 1 - i) >>> z = np.linspace(old[0], old[1], 6); z array([-1. -1.j , -0.6-0.6j, -0.2-0.2j, 0.2+0.2j, 0.6+0.6j, 1. +1.j ]) >>> new_z = pu.mapdomain(z, old, new); new_z array([-1.0+1.j , -0.6+0.6j, -0.2+0.2j, 0.2-0.2j, 0.6-0.6j, 1.0-1.j ]) # may vary# numpy.ma.set_fill_value[#](#numpy-ma-set-fill-value)
ma.set_fill_value(*a*,*fill_value*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L477-L539)[#](#numpy.ma.set_fill_value)
-
Set the filling value of a, if a is a masked array.

This function changes the fill value of the masked array

*a*in place. If*a*is not a masked array, the function returns silently, without doing anything.Parameters:
-
**a**array_like
Input array.

**fill_value**dtype
Filling value. A consistency test is performed to make sure the value is compatible with the dtype of

*a*.
Returns:
-
None
-
Nothing returned by this function.

See also

`maximum_fill_value`
Return the default fill value for a dtype.

`MaskedArray.fill_value`
Return current fill value.

`MaskedArray.set_fill_value`
Equivalent method.

Examples

>>> import numpy.ma as ma >>> a = np.arange(5) >>> a array([0, 1, 2, 3, 4]) >>> a = ma.masked_where(a < 3, a) >>> a masked_array(data=[--, --, --, 3, 4], mask=[ True, True, True, False, False], fill_value=999999) >>> ma.set_fill_value(a, -999) >>> a masked_array(data=[--, --, --, 3, 4], mask=[ True, True, True, False, False], fill_value=-999)
Nothing happens if

*a*is not a masked array.>>> a = list(range(5)) >>> a [0, 1, 2, 3, 4] >>> ma.set_fill_value(a, 100) >>> a [0, 1, 2, 3, 4] >>> a = np.arange(5) >>> a array([0, 1, 2, 3, 4]) >>> ma.set_fill_value(a, 100) >>> a array([0, 1, 2, 3, 4])# numpy.ma.MaskedArray.tolist[#](#numpy-ma-maskedarray-tolist)
method

ma.MaskedArray.tolist(*fill_value=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L6102-L6151)[#](#numpy.ma.MaskedArray.tolist)
-
Return the data portion of the masked array as a hierarchical Python list.

Data items are converted to the nearest compatible Python type. Masked values are converted to

. If`fill_value`
is None, the corresponding entries in the output list will be`fill_value`
`None`
.Parameters:
-
**fill_value**scalar, optional
The value to use for invalid entries. Default is None.

Returns:
-
**result**list
The Python list representation of the masked array.

Examples

>>> x = np.ma.array([[1,2,3], [4,5,6], [7,8,9]], mask=[0] + [1,0]*4) >>> x.tolist() [[1, None, 3], [None, 5, None], [7, None, 9]] >>> x.tolist(-999) [[1, -999, 3], [-999, 5, -999], [7, -999, 9]]# numpy.ndarray.argmax[#](#numpy-ndarray-argmax)
method

ndarray.argmax(*axis=None*,*out=None*,***,*keepdims=False*)[#](#numpy.ndarray.argmax)
-
Return indices of the maximum values along the given axis.

Refer to

for full documentation.`numpy.argmax`
See also

`numpy.argmax`
equivalent function

method

Return indices of the maximum values along the given axis.

Refer to [ numpy.argmax](numpy.argmax.html#numpy.argmax) for full documentation.

See also

`numpy.argmax`
equivalent functionndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__len__

method

Return len(self).numpy.ndarray.any# method ndarray.any(axis=None, out=None, keepdims=False, *, where=True)# Returns True if any of the elements of a evaluate to True. Refer to numpy.any for full documentation. See also numpy.anyequivalent function# numpy.recarray.cumprod[#](#numpy-recarray-cumprod)
method

recarray.cumprod(*axis=None*,*dtype=None*,*out=None*)[#](#numpy.recarray.cumprod)
-
Return the cumulative product of the elements along the given axis.

Refer to

for full documentation.`numpy.cumprod`
See also

`numpy.cumprod`
equivalent function# numpy.dtype.__class_getitem__[#](#numpy-dtype-class-getitem)
method

dtype.__class_getitem__(*item*,*/*)[#](#numpy.dtype.__class_getitem__)
-
Return a parametrized wrapper around the

type.`dtype`
New in version 1.22.

Returns:
-
**alias**types.GenericAlias
A parametrized

type.`dtype`
See also

**PEP 585**
Type hinting generics in standard collections.

Examples

>>> import numpy as np
>>> np.dtype[np.int64] numpy.dtype[numpy.int64]numpy.ma.MaskedArray.__rtruediv__# method ma.MaskedArray.__rtruediv__(other)[source]# Divide self into other, and return a new masked array.# numpy.char.isdigit[#](#numpy-char-isdigit)
char.isdigit(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L871-L903)[#](#numpy.char.isdigit)
-
Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.

Calls

*str.isdigit*element-wise.For 8-bit strings, this method is locale-dependent.

Parameters:
-
**a**array_like of str or unicode
Returns:
-
**out**ndarray
Output array of bools

See also

Examples

>>> a = np.array(['a', 'b', '0']) >>> np.char.isdigit(a) array([False, False, True]) >>> a = np.array([['a', 'b', '0'], ['c', '1', '2']]) >>> np.char.isdigit(a) array([[False, False, True], [False, True, True]])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__iand__
numpy.ndarray.__iand__
#
method
ndarray.
__iand__
(
value
,
/
)
#
Return self&=value.# numpy.ma.MaskedArray.nbytes[#](#numpy-ma-maskedarray-nbytes)
attribute

ma.MaskedArray.nbytes[#](#numpy.ma.MaskedArray.nbytes)
-
Total bytes consumed by the elements of the array.

See also

`sys.getsizeof`
Memory consumed by the object itself without parents in case view. This does include memory consumed by non-element attributes.

Notes

Does not include memory consumed by non-element attributes of the array object.

Examples

>>> x = np.zeros((3,5,2), dtype=np.complex128) >>> x.nbytes 480 >>> np.prod(x.shape) * x.itemsize 480# numpy.ma.MaskType.squeeze[#](#numpy-ma-masktype-squeeze)
method

ma.MaskType.squeeze()[#](#numpy.ma.MaskType.squeeze)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.squeeze`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.squeeze](numpy.ndarray.squeeze.html#numpy.ndarray.squeeze).numpy.nditer.enable_external_loop# method nditer.enable_external_loop()# When the “external_loop” was not used during construction, but is desired, this modifies the iterator to behave as if the flag was specified.# numpy.ma.power[#](#numpy-ma-power)
ma.power(*a*,*b*,*third=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L6921-L6996)[#](#numpy.ma.power)
-
Returns element-wise base array raised to power from second array.

This is the masked array version of

. For details see`numpy.power`
.`numpy.power`
See also

Notes

The

*out*argument tois not supported,`numpy.power`
*third*has to be None.Examples

>>> import numpy.ma as ma >>> x = [11.2, -3.973, 0.801, -1.41] >>> mask = [0, 0, 0, 1] >>> masked_x = ma.masked_array(x, mask) >>> masked_x masked_array(data=[11.2, -3.973, 0.801, --], mask=[False, False, False, True], fill_value=1e+20) >>> ma.power(masked_x, 2) masked_array(data=[125.43999999999998, 15.784728999999999, 0.6416010000000001, --], mask=[False, False, False, True], fill_value=1e+20) >>> y = [-0.5, 2, 0, 17] >>> masked_y = ma.masked_array(y, mask) >>> masked_y masked_array(data=[-0.5, 2.0, 0.0, --], mask=[False, False, False, True], fill_value=1e+20) >>> ma.power(masked_x, masked_y) masked_array(data=[0.29880715233359845, 15.784728999999999, 1.0, --], mask=[False, False, False, True], fill_value=1e+20)# numpy.matrix.flat[#](#numpy-matrix-flat)
attribute

matrix.flat[#](#numpy.matrix.flat)
-
A 1-D iterator over the array.

This is a

instance, which acts similarly to, but is not a subclass of, Python’s built-in iterator object.`numpy.flatiter`
Examples

>>> x = np.arange(1, 7).reshape(2, 3) >>> x array([[1, 2, 3], [4, 5, 6]]) >>> x.flat[3] 4 >>> x.T array([[1, 4], [2, 5], [3, 6]]) >>> x.T.flat[3] 5 >>> type(x.flat) <class 'numpy.flatiter'>
An assignment example:

>>> x.flat = 3; x array([[3, 3, 3], [3, 3, 3]]) >>> x.flat[[1,4]] = 1; x array([[3, 1, 3], [3, 1, 3]])# numpy.setxor1d[#](#numpy-setxor1d)
numpy.setxor1d(*ar1*,*ar2*,*assume_unique=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/arraysetops.py#L476-L516)[#](#numpy.setxor1d)
-
Find the set exclusive-or of two arrays.

Return the sorted, unique values that are in only one (not both) of the input arrays.

Parameters:
-
**ar1, ar2**array_like
Input arrays.

**assume_unique**bool
If True, the input arrays are both assumed to be unique, which can speed up the calculation. Default is False.

Returns:
-
**setxor1d**ndarray
Sorted 1D array of unique values that are in only one of the input arrays.

Examples

>>> a = np.array([1, 2, 3, 2, 4]) >>> b = np.array([2, 3, 5, 7, 5]) >>> np.setxor1d(a,b) array([1, 4, 5, 7])numpy.ma.MaskedArray.__reduce__# method ma.MaskedArray.__reduce__()[source]# Return a 3-tuple for pickling a MaskedArray.# numpy.ma.MaskType.reshape[#](#numpy-ma-masktype-reshape)
method

ma.MaskType.reshape()[#](#numpy.ma.MaskType.reshape)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.reshape`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.reshape](numpy.ndarray.reshape.html#numpy.ndarray.reshape).# numpy.dsplit[#](#numpy-dsplit)
numpy.dsplit(*ary*,*indices_or_sections*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/shape_base.py#L992-L1034)[#](#numpy.dsplit)
-
Split array into multiple sub-arrays along the 3rd axis (depth).

Please refer to the

documentation.`split`
is equivalent to`dsplit`
with`split`
`axis=2`
, the array is always split along the third axis provided the array dimension is greater than or equal to 3.See also

`split`
Split an array into multiple sub-arrays of equal size.

Examples

>>> x = np.arange(16.0).reshape(2, 2, 4) >>> x array([[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.]], [[ 8., 9., 10., 11.], [12., 13., 14., 15.]]]) >>> np.dsplit(x, 2) [array([[[ 0., 1.], [ 4., 5.]], [[ 8., 9.], [12., 13.]]]), array([[[ 2., 3.], [ 6., 7.]], [[10., 11.], [14., 15.]]])] >>> np.dsplit(x, np.array([3, 6])) [array([[[ 0., 1., 2.], [ 4., 5., 6.]], [[ 8., 9., 10.], [12., 13., 14.]]]), array([[[ 3.], [ 7.]], [[11.], [15.]]]), array([], shape=(2, 2, 0), dtype=float64)]# numpy.ma.MaskType.tofile[#](#numpy-ma-masktype-tofile)
method

ma.MaskType.tofile()[#](#numpy.ma.MaskType.tofile)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.tofile`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.tofile](numpy.ndarray.tofile.html#numpy.ndarray.tofile).numpy.record.argmin# method record.argmin()# Scalar method identical to the corresponding array attribute. Please see ndarray.argmin.# numpy.matrix.take[#](#numpy-matrix-take)
method

matrix.take(*indices*,*axis=None*,*out=None*,*mode='raise'*)[#](#numpy.matrix.take)
-
Return an array formed from the elements of

*a*at the given indices.Refer to

for full documentation.`numpy.take`
See also

`numpy.take`
equivalent function# numpy.chararray.compress[#](#numpy-chararray-compress)
method

chararray.compress(*condition*,*axis=None*,*out=None*)[#](#numpy.chararray.compress)
-
Return selected slices of this array along given axis.

Refer to

for full documentation.`numpy.compress`
See also

`numpy.compress`
equivalent function

method

Return selected slices of this array along given axis.

Refer to [ numpy.compress](numpy.compress.html#numpy.compress) for full documentation.

See also

`numpy.compress`
equivalent function# numpy.emath.power[#](#numpy-emath-power)
emath.power(*x*,*p*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/scimath.py#L441-L483)[#](#numpy.emath.power)
-
Return x to the power p, (x**p).

If

*x*contains negative values, the output is converted to the complex domain.Parameters:
-
**x**array_like
The input value(s).

**p**array_like of ints
The power(s) to which

*x*is raised. If*x*contains multiple values,*p*has to either be a scalar, or contain the same number of values as*x*. In the latter case, the result is`x[0]**p[0], x[1]**p[1], ...`
.
Returns:
-
**out**ndarray or scalar
The result of

`x**p`
. If*x*and*p*are scalars, so is*out*, otherwise an array is returned.
See also

Examples

>>> np.set_printoptions(precision=4)
>>> np.emath.power([2, 4], 2) array([ 4, 16]) >>> np.emath.power([2, 4], -2) array([0.25 , 0.0625]) >>> np.emath.power([-2, 4], 2) array([ 4.-0.j, 16.+0.j])numpy.lib.format.write_array_header_1_0# lib.format.write_array_header_1_0(fp, d)[source]# Write the header for an array using the 1.0 format. Parameters: fpfilelike object ddictThis has the appropriate entries for writing its string representation to the header of the file.numpy.ma.MaskedArray.__imul__# method ma.MaskedArray.__imul__(other)[source]# Multiply self by other in-place.# numpy.matrix.cumprod[#](#numpy-matrix-cumprod)
method

matrix.cumprod(*axis=None*,*dtype=None*,*out=None*)[#](#numpy.matrix.cumprod)
-
Return the cumulative product of the elements along the given axis.

Refer to

for full documentation.`numpy.cumprod`
See also

`numpy.cumprod`
equivalent function# numpy.matlib.repmat[#](#numpy-matlib-repmat)
matlib.repmat(*a*,*m*,*n*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matlib.py#L330-L378)[#](#numpy.matlib.repmat)
-
Repeat a 0-D to 2-D array or matrix MxN times.

Parameters:
-
**a**array_like
The array or matrix to be repeated.

**m, n**int
The number of times

*a*is repeated along the first and second axes.
Returns:
-
**out**ndarray
The result of repeating

*a*.
Examples

>>> import numpy.matlib >>> a0 = np.array(1) >>> np.matlib.repmat(a0, 2, 3) array([[1, 1, 1], [1, 1, 1]])
>>> a1 = np.arange(4) >>> np.matlib.repmat(a1, 2, 2) array([[0, 1, 2, 3, 0, 1, 2, 3], [0, 1, 2, 3, 0, 1, 2, 3]])
>>> a2 = np.asmatrix(np.arange(6).reshape(2, 3)) >>> np.matlib.repmat(a2, 2, 3) matrix([[0, 1, 2, 0, 1, 2, 0, 1, 2], [3, 4, 5, 3, 4, 5, 3, 4, 5], [0, 1, 2, 0, 1, 2, 0, 1, 2], [3, 4, 5, 3, 4, 5, 3, 4, 5]])# numpy.char.chararray.splitlines[#](#numpy-char-chararray-splitlines)
method

char.chararray.splitlines(*keepends=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2606-L2616)[#](#numpy.char.chararray.splitlines)
-
For each element in

*self*, return a list of the lines in the element, breaking at line boundaries.See also

method

For each element in *self*, return a list of the lines in the
element, breaking at line boundaries.

See also# numpy.positive[#](#numpy-positive)
numpy.positive(*x*,*/*,*out=None*,***,*where=True*,*casting='same_kind'*,*order='K'*,*dtype=None*,*subok=True*[,*signature*,*extobj*])*= <ufunc 'positive'>*[#](#numpy.positive)
-
Numerical positive, element-wise.

New in version 1.13.0.

Parameters:
-
**x**array_like or scalar
Input array.

Returns:
-
**y**ndarray or scalar
Returned array or scalar:

*y = +x*. This is a scalar if*x*is a scalar.
Notes

Equivalent to

*x.copy()*, but only defined for types that support arithmetic.Examples

>>> x1 = np.array(([1., -1.])) >>> np.positive(x1) array([ 1., -1.])
The unary

`+`
operator can be used as a shorthand for`np.positive`
on ndarrays.>>> x1 = np.array(([1., -1.])) >>> +x1 array([ 1., -1.])numpy.polynomial.hermite_e.HermiteE.basis_name# attribute polynomial.hermite_e.HermiteE.basis_name = 'He'## numpy.ma.notmasked_edges[#](#numpy-ma-notmasked-edges)
ma.notmasked_edges(*a*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L1788-L1836)[#](#numpy.ma.notmasked_edges)
-
Find the indices of the first and last unmasked values along an axis.

If all values are masked, return None. Otherwise, return a list of two tuples, corresponding to the indices of the first and last unmasked values respectively.

Parameters:
-
**a**array_like
The input array.

**axis**int, optional
Axis along which to perform the operation. If None (default), applies to a flattened version of the array.

Returns:
-
**edges**ndarray or list
An array of start and end indexes if there are any masked data in the array. If there are no masked data in the array,

*edges*is a list of the first and last index.
See also

Examples

>>> a = np.arange(9).reshape((3, 3)) >>> m = np.zeros_like(a) >>> m[1:, 1:] = 1
>>> am = np.ma.array(a, mask=m) >>> np.array(am[~am.mask]) array([0, 1, 2, 3, 6])
>>> np.ma.notmasked_edges(am) array([0, 6])# numpy.polynomial.chebyshev.chebpow[#](#numpy-polynomial-chebyshev-chebpow)
polynomial.chebyshev.chebpow(*c*,*pow*,*maxpower=16*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L817-L872)[#](#numpy.polynomial.chebyshev.chebpow)
-
Raise a Chebyshev series to a power.

Returns the Chebyshev series

*c*raised to the power*pow*. The argument*c*is a sequence of coefficients ordered from low to high. i.e., [1,2,3] is the series`T_0 + 2*T_1 + 3*T_2.`
Parameters:
-
**c**array_like
1-D array of Chebyshev series coefficients ordered from low to high.

**pow**integer
Power to which the series will be raised

**maxpower**integer, optional
Maximum power allowed. This is mainly to limit growth of the series to unmanageable size. Default is 16

Returns:
-
**coef**ndarray
Chebyshev series of power.

Examples

>>> from numpy.polynomial import chebyshev as C >>> C.chebpow([1, 2, 3, 4], 2) array([15.5, 22. , 16. , ..., 12.5, 12. , 8. ])numpy.record.dump# method record.dump()# Scalar method identical to the corresponding array attribute. Please see ndarray.dump.# F2PY and PGI Fortran on Windows[#](#f2py-and-pgi-fortran-on-windows)
A variant of these are part of the so called “classic” Flang, however, as classic Flang requires a custom LLVM and compilation from sources.

Warning

Since the proprietary compilers are no longer available for
usage they are not recommended and will not be ported to the
new `f2py`
CLI.

Note

**As of November 2021**
As of 29-01-2022, [PGI compiler toolchains](https://www.pgroup.com/index.html) have been superseded by the Nvidia
HPC SDK, with no [native Windows support](https://developer.nvidia.com/nvidia-hpc-sdk-downloads#collapseFour).User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array broadcasting in Numpy
#
Note
Please refer to the updated
Broadcasting
document.F2PY user guide# Three ways to wrap - getting started The quick way The smart way The quick and smart way Using F2PY Using f2py as a command-line tool Python module numpy.f2py Automatic extension module generation F2PY examples F2PY walkthrough: a basic extension module A filtering example depends keyword example Read more# Using NumPy C-API[#](#using-numpy-c-api)
[How to extend NumPy](c-info.how-to-extend.html)[Writing an extension module](c-info.how-to-extend.html#writing-an-extension-module)
[Required subroutine](c-info.how-to-extend.html#required-subroutine)
[Defining functions](c-info.how-to-extend.html#defining-functions)
[Dealing with array objects](c-info.how-to-extend.html#dealing-with-array-objects)
[Example](c-info.how-to-extend.html#example)
[Using Python as glue](c-info.python-as-glue.html)[Calling other compiled libraries from Python](c-info.python-as-glue.html#calling-other-compiled-libraries-from-python)
[Hand-generated wrappers](c-info.python-as-glue.html#hand-generated-wrappers)
[f2py](c-info.python-as-glue.html#f2py)
[Cython](c-info.python-as-glue.html#cython)
[ctypes](c-info.python-as-glue.html#index-2)
[Additional tools you may find useful](c-info.python-as-glue.html#additional-tools-you-may-find-useful)
[Writing your own ufunc](c-info.ufunc-tutorial.html)
[Beyond the Basics](c-info.beyond-basics.html)[Iterating over elements in the array](c-info.beyond-basics.html#iterating-over-elements-in-the-array)
[User-defined data-types](c-info.beyond-basics.html#user-defined-data-types)
[Subtyping the ndarray in C](c-info.beyond-basics.html#subtyping-the-ndarray-in-c)# Indexing routines[#](#indexing-routines)
See also

## Generating index arrays[#](#generating-index-arrays)
Translates slice objects to concatenation along the second axis.

|
Translates slice objects to concatenation along the first axis.

|
A nicer way to build up index tuples for arrays.

|
|
Return the indices of the elements that are non-zero.

|
|
Return elements chosen from

|
|
Return an array representing the indices of a grid.

|
|
Construct an open mesh from multiple sequences.

|
An instance which returns an open multi-dimensional "meshgrid".

|
|
Converts a tuple of index arrays into an array of flat indices, applying boundary modes to the multi-index.

|
|
Converts a flat index or array of flat indices into a tuple of coordinate arrays.

|
|
Return the indices to access the main diagonal of an array.

|
|
Return the indices to access the main diagonal of an n-dimensional array.

|
|
Return the indices to access (n, n) arrays, given a masking function.

|
|
Return the indices for the lower-triangle of an (n, m) array.

|
|
Return the indices for the lower-triangle of arr.

|
|
Return the indices for the upper-triangle of an (n, m) array.

|
|
Return the indices for the upper-triangle of arr.

|
## Indexing-like operations[#](#indexing-like-operations)
|
Take elements from an array along an axis.

|
|
Take values from the input array by matching 1d index and data slices.

|
|
Construct an array from an index array and a list of arrays to choose from.

|
|
Return selected slices of an array along given axis.

|
|
Extract a diagonal or construct a diagonal array.

|
|
Return specified diagonals.

|
|
Return an array drawn from elements in choicelist, depending on conditions.

|
Create a sliding window view into the array with the given window shape.

|
|
Create a view into the array with the given shape and strides.

|
## Inserting data into arrays[#](#inserting-data-into-arrays)
|
Change elements of an array based on conditional and input values.

|
|
Replaces specified elements of an array with given values.

|
|
Put values into the destination array by matching 1d index and data slices.

|
|
Changes elements of an array based on conditional and input values.

|
|
Fill the main diagonal of the given array of any dimensionality.

|
## Iterating over arrays[#](#iterating-over-arrays)
|
Efficient multi-dimensional iterator object to iterate over arrays.

|
|
Multidimensional index iterator.

|
|
An N-dimensional iterator object to index arrays.

|
|
Create nditers for use in nested loops

|
|
Flat iterator object to iterate over arrays.

|
|
Buffered iterator for big arrays.

|
|
Check whether or not an object can be iterated over.

|I/O with NumPy# Importing data with genfromtxt Defining the input Splitting the lines into columns Skipping lines and choosing columns Choosing the data type Setting the names Tweaking the conversion Shortcut functions# Floating point error handling[#](#floating-point-error-handling)
## Setting and getting error handling[#](#setting-and-getting-error-handling)
|
Set how floating-point errors are handled.

|
|
Get the current way of handling floating-point errors.

|
|
Set the floating-point error callback function or log object.

|
Return the current callback function used on floating-point errors.

|
|
Context manager for floating-point error handling.

|
## Internal functions[#](#internal-functions)
|
Set the object that defines floating-point error handling.

|
Return the current object that defines floating-point error handling.

|# Masked array operations[#](#masked-array-operations)
## Constants[#](#constants)
alias of

|
## Creation[#](#creation)
### From existing data[#](#from-existing-data)
alias of

|
|
An array class with possibly masked values.

|
|
Return a copy of the array.

|
|
Interpret a buffer as a 1-dimensional array.

|
|
Construct an array by executing a function over each coordinate.

|
|
Return a copy of the array.

|
diagflat

|
### Ones and zeros[#](#ones-and-zeros)
|
Return a new array of given shape and type, without initializing entries.

|
|
Return a new array with the same shape and type as a given array.

|
|
Empty masked array with all elements masked.

|
|
Empty masked array with the properties of an existing array.

|
|
Return a new array of given shape and type, filled with ones.

|
Return an array of ones with the same shape and type as a given array.

|
|
Return a new array of given shape and type, filled with zeros.

|
Return an array of zeros with the same shape and type as a given array.

|
## Inspecting the array[#](#inspecting-the-array)
|
Returns True if all elements evaluate to True.

|
|
Returns True if any of the elements of

|
|
Count the non-masked elements of the array along the given axis.

|
|
Count the number of masked elements along the given axis.

|
|
Return the mask of a masked array, or nomask.

|
|
Return the mask of a masked array, or full boolean array of False.

|
|
Return the data of a masked array as an ndarray.

|
|
Return the indices of unmasked elements that are not zero.

|
|
Return the shape of an array.

|
|
Return the number of elements along a given axis.

|
|
Determine whether input has masked values.

|
|
Return True if m is a valid, standard mask.

|
Test whether input is an instance of MaskedArray.

|
|
Test whether input is an instance of MaskedArray.

|
|
Test whether input is an instance of MaskedArray.

|
|
Calculates

|
|
Test whether each element of an array is also present in a second array.

|
|
Finds the unique elements of an array.

|
|
Returns True if all elements evaluate to True.

|
|
Returns True if any of the elements of

|
|
Count the non-masked elements of the array along the given axis.

|
Return the indices of unmasked elements that are not zero.

|
|
Return the shape of an array.

|
|
Return the number of elements along a given axis.

|
Returns the underlying data, as a view of the masked array.

|
Current mask.

|
Get or set the mask of the array if it has no named fields.

|
## Manipulating a MaskedArray[#](#manipulating-a-maskedarray)
### Changing the shape[#](#changing-the-shape)
|
Returns a 1D version of self, as a view.

|
|
Returns an array containing the same data with a new shape.

|
|
Return a new masked array with the specified size and shape.

|
|
Return a copy of the array collapsed into one dimension.

|
|
Returns a 1D version of self, as a view.

|
|
Give a new shape to the array without changing its data.

|
|
### Modifying axes[#](#modifying-axes)
|
Return a view of the array with

|
|
Permute the dimensions of an array.

|
|
Return a view of the array with

|
|
Returns a view of the array with axes transposed.

|
### Changing the number of dimensions[#](#changing-the-number-of-dimensions)
atleast_1d

|
atleast_2d

|
atleast_3d

|
|
Expand the shape of an array.

|
Remove axes of length one from

|
|
Remove axes of length one from

|
stack

|
column_stack

|
|
Concatenate a sequence of arrays along the given axis.

|
dstack

|
hstack

|
hsplit

|
Translate slice objects to concatenation along the first axis.

|
vstack

|
vstack

|
### Joining arrays[#](#joining-arrays)
|
Concatenate a sequence of arrays along the given axis.

|
stack

|
vstack

|
hstack

|
dstack

|
column_stack

|
|
Append values to the end of an array.

|
## Operations on masks[#](#operations-on-masks)
### Creating a mask[#](#creating-a-mask)
|
Create a boolean mask from an array.

|
|
Return a boolean mask of the given shape, filled with False.

|
|
Combine two masks with the

|
|
Construct a dtype description list from a given dtype.

|
### Accessing a mask[#](#accessing-a-mask)
|
Return the mask of a masked array, or nomask.

|
|
Return the mask of a masked array, or full boolean array of False.

|
Current mask.

|
### Finding masked data[#](#finding-masked-data)
|
Multidimensional index iterator.

|
Find contiguous unmasked data in a masked array.

|
Find the indices of the first and last unmasked values.

|
|
Find contiguous unmasked data in a masked array along the given axis.

|
|
Find the indices of the first and last unmasked values along an axis.

|
Returns a list of slices corresponding to the masked clumps of a 1-D array.

|
Return list of slices corresponding to the unmasked clumps of a 1-D array.

|
### Modifying a mask[#](#modifying-a-mask)
|
Mask columns of a 2D array that contain masked values.

|
|
Combine two masks with the

|
|
Mask rows and/or columns of a 2D array that contain masked values.

|
|
Mask rows of a 2D array that contain masked values.

|
|
Force the mask to hard, preventing unmasking by assignment.

|
|
Force the mask to soft (default), allowing unmasking by assignment.

|
Force the mask to hard, preventing unmasking by assignment.

|
Force the mask to soft (default), allowing unmasking by assignment.

|
Reduce a mask to nomask when possible.

|
Copy the mask and set the

|
## Conversion operations[#](#conversion-operations)
### > to a masked array[#](#to-a-masked-array)
|
Convert the input to a masked array of the given data-type.

|
|
Convert the input to a masked array, conserving subclasses.

|
|
Return input with invalid data masked and replaced by a fill value.

|
|
Mask an array where equal to a given value.

|
|
Mask an array where greater than a given value.

|
|
Mask an array where greater than or equal to a given value.

|
|
Mask an array inside a given interval.

|
|
Mask an array where invalid values occur (NaNs or infs).

|
|
Mask an array where less than a given value.

|
|
Mask an array where less than or equal to a given value.

|
|
Mask an array where

|
|
Mask the array

|
|
Mask an array outside a given interval.

|
|
Mask using floating point equality.

|
|
Mask an array where a condition is met.

|
### > to a ndarray[#](#to-a-ndarray)
Suppress whole columns of a 2-D array that contain masked values.

|
|
Suppress the rows and/or columns of a 2-D array that contain masked values.

|
Suppress whole rows of a 2-D array that contain masked values.

|
Return all the non-masked data as a 1-D array.

|
|
Return input as an array with masked data replaced by a fill value.

|
Return all the non-masked data as a 1-D array.

|
|
Return a copy of self, with masked values filled with a given value.

|
### > to another object[#](#to-another-object)
|
Save a masked array to a file in binary format.

|
|
Return the data portion of the masked array as a hierarchical Python list.

|
Transforms a masked array into a flexible-type array.

|
|
Return the array data as a string containing the raw bytes in the array.

|
### Filling a masked array[#](#filling-a-masked-array)
|
Return the common filling value of two masked arrays, if any.

|
Return the default fill value for the argument object.

|
Return the minimum value that can be represented by the dtype of an object.

|
Return the maximum value that can be represented by the dtype of an object.

|
|
Set the filling value of a, if a is a masked array.

|
The filling value of the masked array is a scalar.

|
|
The filling value of the masked array is a scalar.

|
## Masked arrays arithmetic[#](#masked-arrays-arithmetic)
### Arithmetic[#](#arithmetic)
|
Compute the anomalies (deviations from the arithmetic mean) along the given axis.

|
|
Compute the anomalies (deviations from the arithmetic mean) along the given axis.

|
|
Return the weighted average of array over the given axis.

|
|
Return the complex conjugate, element-wise.

|
|
Return Pearson product-moment correlation coefficients.

|
|
Estimate the covariance matrix.

|
|
Return the cumulative sum of the array elements over the given axis.

|
|
Return the cumulative product of the array elements over the given axis.

|
|
Returns the average of the array elements along given axis.

|
|
Compute the median along the specified axis.

|
|
Returns element-wise base array raised to power from second array.

|
|
Return the product of the array elements over the given axis.

|
|
Returns the standard deviation of the array elements along given axis.

|
|
Return the sum of the array elements over the given axis.

|
|
Compute the variance along the specified axis.

|
|
Compute the anomalies (deviations from the arithmetic mean) along the given axis.

|
|
Return the cumulative product of the array elements over the given axis.

|
|
Return the cumulative sum of the array elements over the given axis.

|
|
Returns the average of the array elements along given axis.

|
|
Return the product of the array elements over the given axis.

|
|
Returns the standard deviation of the array elements along given axis.

|
|
Return the sum of the array elements over the given axis.

|
|
Compute the variance along the specified axis.

|
### Minimum/maximum[#](#minimum-maximum)
|
Returns array of indices of the maximum values along the given axis.

|
|
Return array of indices to the minimum values along the given axis.

|
|
Return the maximum along a given axis.

|
|
Return the minimum along a given axis.

|
|
Return (maximum - minimum) along the given dimension (i.e.

|
|
Calculate the n-th discrete difference along the given axis.

|
|
Returns array of indices of the maximum values along the given axis.

|
|
Return array of indices to the minimum values along the given axis.

|
|
Return the maximum along a given axis.

|
|
Return the minimum along a given axis.

|
|
Return (maximum - minimum) along the given dimension (i.e.

|
### Sorting[#](#sorting)
|
Return an ndarray of indices that sort the array along the specified axis.

|
|
Return a sorted copy of the masked array.

|
|
Return an ndarray of indices that sort the array along the specified axis.

|
|
Sort the array, in-place

|
### Algebra[#](#algebra)
|
Extract a diagonal or construct a diagonal array.

|
|
Return the dot product of two arrays.

|
|
Return the identity array.

|
|
Inner product of two arrays.

|
|
Inner product of two arrays.

|
|
Compute the outer product of two vectors.

|
|
Compute the outer product of two vectors.

|
|
Return the sum along diagonals of the array.

|
|
Permute the dimensions of an array.

|
|
Return the sum along diagonals of the array.

|
|
Returns a view of the array with axes transposed.

|
### Polynomial fit[#](#polynomial-fit)
|
Generate a Vandermonde matrix.

|
|
Least squares polynomial fit.

|
### Clipping and rounding[#](#clipping-and-rounding)
Round an array to the given number of decimals.

|
Clip (limit) the values in an array.

|
|
Return a copy of a, rounded to 'decimals' places.

|
|
Return an array whose values are limited to

|
|
Return each element rounded to the given number of decimals.

|
### Set operations[#](#set-operations)
|
Returns the unique elements common to both arrays.

|
|
Set difference of 1D arrays with unique elements.

|
|
Set exclusive-or of 1-D arrays with unique elements.

|
|
Union of two arrays.

|
### Miscellanea[#](#miscellanea)
|
Return True if all entries of a and b are equal, using fill_value as a truth value where either or both are masked.

|
|
Returns True if two arrays are element-wise equal within a tolerance.

|
|
Apply a function to 1-D slices along the given axis.

|
|
Apply a function repeatedly over multiple axes.

|
|
Return evenly spaced values within a given interval.

|
|
Use an index array to construct a new array from a list of choices.

|
|
Compute the differences between consecutive elements of an array.

|
|
Return an array representing the indices of a grid.

|
|
Return a masked array with elements from

|# Logic functions[#](#logic-functions)
## Truth value testing[#](#truth-value-testing)
|
Test whether all array elements along a given axis evaluate to True.

|
|
Test whether any array element along a given axis evaluates to True.

|
## Array contents[#](#array-contents)
|
Test element-wise for finiteness (not infinity and not Not a Number).

|
|
Test element-wise for positive or negative infinity.

|
|
Test element-wise for NaN and return result as a boolean array.

|
|
Test element-wise for NaT (not a time) and return result as a boolean array.

|
|
Test element-wise for negative infinity, return result as bool array.

|
|
Test element-wise for positive infinity, return result as bool array.

|
## Array type testing[#](#array-type-testing)
|
Returns a bool array, where True if input element is complex.

|
|
Check for a complex type or an array of complex numbers.

|
|
Check if the array is Fortran contiguous but

|
|
Returns a bool array, where True if input element is real.

|
|
Return True if x is a not complex type or an array of complex numbers.

|
|
Returns True if the type of

|
## Logical operations[#](#logical-operations)
|
Compute the truth value of x1 AND x2 element-wise.

|
|
Compute the truth value of x1 OR x2 element-wise.

|
|
Compute the truth value of NOT x element-wise.

|
|
Compute the truth value of x1 XOR x2, element-wise.

|
## Comparison[#](#comparison)
|
Returns True if two arrays are element-wise equal within a tolerance.

|
|
Returns a boolean array where two arrays are element-wise equal within a tolerance.

|
|
True if two arrays have the same shape and elements, False otherwise.

|
|
Returns True if input arrays are shape consistent and all elements equal.

|
|
Return the truth value of (x1 > x2) element-wise.

|
|
Return the truth value of (x1 >= x2) element-wise.

|
|
Return the truth value of (x1 < x2) element-wise.

|
|
Return the truth value of (x1 <= x2) element-wise.

|
|
Return (x1 == x2) element-wise.

|
|
Return (x1 != x2) element-wise.

|# Sorting, searching, and counting[#](#sorting-searching-and-counting)
## Sorting[#](#sorting)
|
Return a sorted copy of an array.

|
|
Perform an indirect stable sort using a sequence of keys.

|
|
Returns the indices that would sort an array.

|
|
Sort an array in-place.

|
|
Sort a complex array using the real part first, then the imaginary part.

|
|
Return a partitioned copy of an array.

|
|
Perform an indirect partition along the given axis using the algorithm specified by the

|
## Searching[#](#searching)
|
Returns the indices of the maximum values along an axis.

|
|
Return the indices of the maximum values in the specified axis ignoring NaNs.

|
|
Returns the indices of the minimum values along an axis.

|
|
Return the indices of the minimum values in the specified axis ignoring NaNs.

|
|
Find the indices of array elements that are non-zero, grouped by element.

|
|
Return the indices of the elements that are non-zero.

|
|
Return indices that are non-zero in the flattened version of a.

|
|
Return elements chosen from

|
|
Find indices where elements should be inserted to maintain order.

|
|
Return the elements of an array that satisfy some condition.

|
## Counting[#](#counting)
|
Counts the number of non-zero values in the array

|# NumPy 1.24.2 Release Notes[#](#numpy-1-24-2-release-notes)
NumPy 1.24.2 is a maintenance release that fixes bugs and regressions discovered after the 1.24.1 release. The Python versions supported by this release are 3.8-3.11.

## Contributors[#](#contributors)
A total of 14 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Bas van Beek

Charles Harris

Khem Raj +

Mark Harfouche

Matti Picus

Panagiotis Zestanakis +

Peter Hawkins

Pradipta Ghosh

Ross Barnowski

Sayed Adel

Sebastian Berg

Syam Gadde +

dmbelov +

pkubaj +

## Pull requests merged[#](#pull-requests-merged)
A total of 17 pull requests were merged for this release.

[#22965](https://github.com/numpy/numpy/pull/22965): MAINT: Update python 3.11-dev to 3.11.
[#22966](https://github.com/numpy/numpy/pull/22966): DOC: Remove dangling deprecation warning
[#22967](https://github.com/numpy/numpy/pull/22967): ENH: Detect CPU features on FreeBSD/powerpc64*
[#22968](https://github.com/numpy/numpy/pull/22968): BUG: np.loadtxt cannot load text file with quoted fields separated…
[#22969](https://github.com/numpy/numpy/pull/22969): TST: Add fixture to avoid issue with randomizing test order.
[#22970](https://github.com/numpy/numpy/pull/22970): BUG: Fix fill violating read-only flag. (#22959)
[#22971](https://github.com/numpy/numpy/pull/22971): MAINT: Add additional information to missing scalar AttributeError
[#22972](https://github.com/numpy/numpy/pull/22972): MAINT: Move export for scipy arm64 helper into main module
[#22976](https://github.com/numpy/numpy/pull/22976): BUG, SIMD: Fix spurious invalid exception for sin/cos on arm64/clang
[#22989](https://github.com/numpy/numpy/pull/22989): BUG: Ensure correct loop order in sin, cos, and arctan2
[#23030](https://github.com/numpy/numpy/pull/23030): DOC: Add version added information for the strict parameter in…
[#23031](https://github.com/numpy/numpy/pull/23031): BUG: use`_Alignof`
rather than`offsetof()`
on most compilers
[#23147](https://github.com/numpy/numpy/pull/23147): BUG: Fix for npyv__trunc_s32_f32 (VXE)
[#23148](https://github.com/numpy/numpy/pull/23148): BUG: Fix integer / float scalar promotion
[#23149](https://github.com/numpy/numpy/pull/23149): BUG: Add missing <type_traits> header.
[#23150](https://github.com/numpy/numpy/pull/23150): TYP, MAINT: Add a missing explicit`Any`
parameter to the`npt.ArrayLike`
…
[#23161](https://github.com/numpy/numpy/pull/23161): BLD: remove redundant definition of npy_nextafter [wheel build]# NumPy 1.21.6 Release Notes[#](#numpy-1-21-6-release-notes)
NumPy 1.21.6 is a very small release that achieves two things:

Backs out the mistaken backport of C++ code into 1.21.5.

Provides a 32 bit Windows wheel for Python 3.10.

The provision of the 32 bit wheel is intended to make life easier for oldest-supported-numpy.# NumPy 1.25.1 Release Notes[#](#numpy-1-25-1-release-notes)
NumPy 1.25.1 is a maintenance release that fixes bugs and regressions discovered after the 1.25.0 release. The Python versions supported by this release are 3.9-3.11.

## Contributors[#](#contributors)
A total of 10 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Andrew Nelson

Charles Harris

Developer-Ecosystem-Engineering

Hood Chatham

Nathan Goldbaum

Rohit Goswami

Sebastian Berg

Tim Paine +

dependabot[bot]

matoro +

## Pull requests merged[#](#pull-requests-merged)
A total of 14 pull requests were merged for this release.

[#23968](https://github.com/numpy/numpy/pull/23968): MAINT: prepare 1.25.x for further development
[#24036](https://github.com/numpy/numpy/pull/24036): BLD: Port long double identification to C for meson
[#24037](https://github.com/numpy/numpy/pull/24037): BUG: Fix reduction`return NULL`
to be`goto fail`
[#24038](https://github.com/numpy/numpy/pull/24038): BUG: Avoid undefined behavior in array.astype()
[#24039](https://github.com/numpy/numpy/pull/24039): BUG: Ensure`__array_ufunc__`
works without any kwargs passed
[#24117](https://github.com/numpy/numpy/pull/24117): MAINT: Pin urllib3 to avoid anaconda-client bug.
[#24118](https://github.com/numpy/numpy/pull/24118): TST: Pin pydantic<2 in Pyodide workflow
[#24119](https://github.com/numpy/numpy/pull/24119): MAINT: Bump pypa/cibuildwheel from 2.13.0 to 2.13.1
[#24120](https://github.com/numpy/numpy/pull/24120): MAINT: Bump actions/checkout from 3.5.2 to 3.5.3
[#24122](https://github.com/numpy/numpy/pull/24122): BUG: Multiply or Divides using SIMD without a full vector can…
[#24127](https://github.com/numpy/numpy/pull/24127): MAINT: testing for IS_MUSL closes #24074
[#24128](https://github.com/numpy/numpy/pull/24128): BUG: Only replace dtype temporarily if dimensions changed
[#24129](https://github.com/numpy/numpy/pull/24129): MAINT: Bump actions/setup-node from 3.6.0 to 3.7.0
[#24134](https://github.com/numpy/numpy/pull/24134): BUG: Fix private procedures in f2py modules# NumPy 1.20.1 Release Notes[#](#numpy-1-20-1-release-notes)
NumPy 1,20.1 is a rapid bugfix release fixing several bugs and regressions reported after the 1.20.0 release.

## Highlights[#](#highlights)
The distutils bug that caused problems with downstream projects is fixed.

The

`random.shuffle`
regression is fixed.
## Contributors[#](#contributors)
A total of 8 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Bas van Beek

Charles Harris

Nicholas McKibben +

Pearu Peterson

Ralf Gommers

Sebastian Berg

Tyler Reddy

@Aerysv +

## Pull requests merged[#](#pull-requests-merged)
A total of 15 pull requests were merged for this release.

[#18306](https://github.com/numpy/numpy/pull/18306): MAINT: Add missing placeholder annotations
[#18310](https://github.com/numpy/numpy/pull/18310): BUG: Fix typo in`numpy.__init__.py`
[#18326](https://github.com/numpy/numpy/pull/18326): BUG: don’t mutate list of fake libraries while iterating over…
[#18327](https://github.com/numpy/numpy/pull/18327): MAINT: gracefully shuffle memoryviews
[#18328](https://github.com/numpy/numpy/pull/18328): BUG: Use C linkage for random distributions
[#18336](https://github.com/numpy/numpy/pull/18336): CI: fix when GitHub Actions builds trigger, and allow ci skips
[#18337](https://github.com/numpy/numpy/pull/18337): BUG: Allow unmodified use of isclose, allclose, etc. with timedelta
[#18345](https://github.com/numpy/numpy/pull/18345): BUG: Allow pickling all relevant DType types/classes
[#18351](https://github.com/numpy/numpy/pull/18351): BUG: Fix missing signed_char dependency. Closes #18335.
[#18352](https://github.com/numpy/numpy/pull/18352): DOC: Change license date 2020 -> 2021
[#18353](https://github.com/numpy/numpy/pull/18353): CI: CircleCI seems to occasionally time out, increase the limit
[#18354](https://github.com/numpy/numpy/pull/18354): BUG: Fix f2py bugs when wrapping F90 subroutines.
[#18356](https://github.com/numpy/numpy/pull/18356): MAINT: crackfortran regex simplify
[#18357](https://github.com/numpy/numpy/pull/18357): BUG: threads.h existence test requires GLIBC > 2.12.
[#18359](https://github.com/numpy/numpy/pull/18359): REL: Prepare for the NumPy 1.20.1 release.# NumPy 1.21.3 Release Notes[#](#numpy-1-21-3-release-notes)
NumPy 1.21.3 is a maintenance release that fixes a few bugs discovered after 1.21.2. It also provides 64 bit Python 3.10.0 wheels. Note a few oddities about Python 3.10:

There are no 32 bit wheels for Windows, Mac, or Linux.

The Mac Intel builds are only available in universal2 wheels.

The Python versions supported in this release are 3.7-3.10. If you want to compile your own version using gcc-11, you will need to use gcc-11.2+ to avoid problems.

## Contributors[#](#contributors)
A total of 7 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Aaron Meurer

Bas van Beek

Charles Harris

Developer-Ecosystem-Engineering +

Kevin Sheppard

Sebastian Berg

Warren Weckesser

## Pull requests merged[#](#pull-requests-merged)
A total of 8 pull requests were merged for this release.

[#19745](https://github.com/numpy/numpy/pull/19745): ENH: Add dtype-support to 3``generic`
/`ndarray`
methods
[#19955](https://github.com/numpy/numpy/pull/19955): BUG: Resolve Divide by Zero on Apple silicon + test failures…
[#19958](https://github.com/numpy/numpy/pull/19958): MAINT: Mark type-check-only ufunc subclasses as ufunc aliases…
[#19994](https://github.com/numpy/numpy/pull/19994): BUG: np.tan(np.inf) test failure
[#20080](https://github.com/numpy/numpy/pull/20080): BUG: Correct incorrect advance in PCG with emulated int128
[#20081](https://github.com/numpy/numpy/pull/20081): BUG: Fix NaT handling in the PyArray_CompareFunc for datetime…
[#20082](https://github.com/numpy/numpy/pull/20082): DOC: Ensure that we add documentation also as to the dict for…
[#20106](https://github.com/numpy/numpy/pull/20106): BUG: core: result_type(0, np.timedelta64(4)) would seg. fault.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
1.26.0
1.25.2
1.25.1
1.25.0
1.24.3
1.24.2
1.24.1
1.24.0
1.23.5
1.23.4
1.23.3
1.23.2
1.23.1
1.23.0
1.22.4
1.22.3
1.22.2
1.22.1
1.22.0
1.21.6
1.21.5
1.21.4
1.21.3
1.21.2
1.21.1
1.21.0
1.20.3
1.20.2
1.20.1
1.20.0
1.19.5
1.19.4
1.19.3
1.19.2
1.19.1
1.19.0
1.18.5
1.18.4
1.18.3
1.18.2
1.18.1
1.18.0
1.17.5
1.17.4
1.17.3
1.17.2
1.17.1
1.17.0
1.16.6
1.16.5
1.16.4
1.16.3
1.16.2
1.16.1
1.16.0
1.15.4
1.15.3
1.15.2
1.15.1
1.15.0
1.14.6
1.14.5
1.14.4
1.14.3
1.14.2
1.14.1
1.14.0
1.13.3
1.13.2
1.13.1
1.13.0
1.12.1
1.12.0
1.11.3
1.11.2
1.11.1
1.11.0
1.10.4
1.10.3
1.10.2
1.10.1
1.10.0
1.9.2
1.9.1
1.9.0
1.8.2
1.8.1
1.8.0
1.7.2
1.7.1
1.7.0
1.6.2
1.6.1
1.6.0
1.5.0
1.4.0
1.3.0
NumPy 1.10.3 Release Notes
#
N/A this release did not happen due to various screwups involving PyPI.# NumPy 1.23.2 Release Notes[#](#numpy-1-23-2-release-notes)
NumPy 1.23.2 is a maintenance release that fixes bugs discovered after the 1.23.1 release. Notable features are:

Typing changes needed for Python 3.11

Wheels for Python 3.11.0rc1

The Python versions supported for this release are 3.8-3.11.

## Contributors[#](#contributors)
A total of 9 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Alexander Grund +

Bas van Beek

Charles Harris

Jon Cusick +

Matti Picus

Michael Osthege +

Pal Barta +

Ross Barnowski

Sebastian Berg

## Pull requests merged[#](#pull-requests-merged)
A total of 15 pull requests were merged for this release.

[#22030](https://github.com/numpy/numpy/pull/22030): ENH: Add`__array_ufunc__`
typing support to the`nin=1`
ufuncs
[#22031](https://github.com/numpy/numpy/pull/22031): MAINT, TYP: Fix`np.angle`
dtype-overloads
[#22032](https://github.com/numpy/numpy/pull/22032): MAINT: Do not let`_GenericAlias`
wrap the underlying classes’…
[#22033](https://github.com/numpy/numpy/pull/22033): TYP,MAINT: Allow`einsum`
subscripts to be passed via integer…
[#22034](https://github.com/numpy/numpy/pull/22034): MAINT,TYP: Add object-overloads for the`np.generic`
rich comparisons
[#22035](https://github.com/numpy/numpy/pull/22035): MAINT,TYP: Allow the`squeeze`
and`transpose`
method to…
[#22036](https://github.com/numpy/numpy/pull/22036): BUG: Fix subarray to object cast ownership details
[#22037](https://github.com/numpy/numpy/pull/22037): BUG: Use`Popen`
to silently invoke f77 -v
[#22038](https://github.com/numpy/numpy/pull/22038): BUG: Avoid errors on NULL during deepcopy
[#22039](https://github.com/numpy/numpy/pull/22039): DOC: Add versionchanged for converter callable behavior.
[#22057](https://github.com/numpy/numpy/pull/22057): MAINT: Quiet the anaconda uploads.
[#22078](https://github.com/numpy/numpy/pull/22078): ENH: reorder includes for testing on top of system installations…
[#22106](https://github.com/numpy/numpy/pull/22106): TST: fix test_linear_interpolation_formula_symmetric
[#22107](https://github.com/numpy/numpy/pull/22107): BUG: Fix skip condition for test_loss_of_precision[complex256]
[#22115](https://github.com/numpy/numpy/pull/22115): BLD: Build python3.11.0rc1 wheels.# NumPy 1.21.1 Release Notes[#](#numpy-1-21-1-release-notes)
The NumPy 1.21.1 is maintenance release that fixes bugs discovered after the 1.21.0 release and updates OpenBLAS to v0.3.17 to deal with problems on arm64.

The Python versions supported for this release are 3.7-3.9. The 1.21.x series is compatible with development Python 3.10. Python 3.10 will be officially supported after it is released.

Warning

There are unresolved problems compiling NumPy 1.20.0 with gcc-11.1.

Optimization level

*-O3*results in many incorrect warnings when running the tests.
On some hardware NumPY will hang in an infinite loop.

## Contributors[#](#contributors)
A total of 11 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Bas van Beek

Charles Harris

Ganesh Kathiresan

Gregory R. Lee

Hugo Defois +

Kevin Sheppard

Matti Picus

Ralf Gommers

Sayed Adel

Sebastian Berg

Thomas J. Fan

## Pull requests merged[#](#pull-requests-merged)
A total of 26 pull requests were merged for this release.

[#19311](https://github.com/numpy/numpy/pull/19311): REV,BUG: Replace`NotImplemented`
with`typing.Any`
[#19324](https://github.com/numpy/numpy/pull/19324): MAINT: Fixed the return-dtype of`ndarray.real`
and`imag`
[#19330](https://github.com/numpy/numpy/pull/19330): MAINT: Replace`"dtype[Any]"`
with`dtype`
in the definiton of…
[#19342](https://github.com/numpy/numpy/pull/19342): DOC: Fix some docstrings that crash pdf generation.
[#19343](https://github.com/numpy/numpy/pull/19343): MAINT: bump scipy-mathjax
[#19347](https://github.com/numpy/numpy/pull/19347): BUG: Fix arr.flat.index for large arrays and big-endian machines
[#19348](https://github.com/numpy/numpy/pull/19348): ENH: add`numpy.f2py.get_include`
function
[#19349](https://github.com/numpy/numpy/pull/19349): BUG: Fix reference count leak in ufunc dtype handling
[#19350](https://github.com/numpy/numpy/pull/19350): MAINT: Annotate missing attributes of`np.number`
subclasses
[#19351](https://github.com/numpy/numpy/pull/19351): BUG: Fix cast safety and comparisons for zero sized voids
[#19352](https://github.com/numpy/numpy/pull/19352): BUG: Correct Cython declaration in random
[#19353](https://github.com/numpy/numpy/pull/19353): BUG: protect against accessing base attribute of a NULL subarray
[#19365](https://github.com/numpy/numpy/pull/19365): BUG, SIMD: Fix detecting AVX512 features on Darwin
[#19366](https://github.com/numpy/numpy/pull/19366): MAINT: remove`print()`
’s in distutils template handling
[#19390](https://github.com/numpy/numpy/pull/19390): ENH: SIMD architectures to show_config
[#19391](https://github.com/numpy/numpy/pull/19391): BUG: Do not raise deprecation warning for all nans in unique…
[#19392](https://github.com/numpy/numpy/pull/19392): BUG: Fix NULL special case in object-to-any cast code
[#19430](https://github.com/numpy/numpy/pull/19430): MAINT: Use arm64-graviton2 for testing on travis
[#19495](https://github.com/numpy/numpy/pull/19495): BUILD: update OpenBLAS to v0.3.17
[#19496](https://github.com/numpy/numpy/pull/19496): MAINT: Avoid unicode characters in division SIMD code comments
[#19499](https://github.com/numpy/numpy/pull/19499): BUG, SIMD: Fix infinite loop during count non-zero on GCC-11
[#19500](https://github.com/numpy/numpy/pull/19500): BUG: fix a numpy.npiter leak in npyiter_multi_index_set
[#19501](https://github.com/numpy/numpy/pull/19501): TST: Fix a`GenericAlias`
test failure for python 3.9.0
[#19502](https://github.com/numpy/numpy/pull/19502): MAINT: Start testing with Python 3.10.0b3.
[#19503](https://github.com/numpy/numpy/pull/19503): MAINT: Add missing dtype overloads for object- and ctypes-based…
[#19510](https://github.com/numpy/numpy/pull/19510): REL: Prepare for NumPy 1.21.1 release.# NumPy 1.18.5 Release Notes[#](#numpy-1-18-5-release-notes)
This is a short release to allow pickle `protocol=5`
to be used in
Python3.5. It is motivated by the recent backport of pickle5 to Python3.5.

The Python versions supported in this release are 3.5-3.8. Downstream developers should use Cython >= 0.29.15 for Python 3.8 support and OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.

## Contributors[#](#contributors)
A total of 3 people contributed to this release. People with a “+” by their names contributed a patch for the first time.

Charles Harris

Matti Picus

Siyuan Zhuang +

## Pull requests merged[#](#pull-requests-merged)
A total of 2 pull requests were merged for this release.# NumPy 1.6.1 Release Notes[#](#numpy-1-6-1-release-notes)
This is a bugfix only release in the 1.6.x series.

## Issues Fixed[#](#issues-fixed)
#1834: einsum fails for specific shapes

#1837: einsum throws nan or freezes python for specific array shapes

#1838: object <-> structured type arrays regression

#1851: regression for SWIG based code in 1.6.0

#1863: Buggy results when operating on array copied with astype()

#1870: Fix corner case of object array assignment

#1843: Py3k: fix error with recarray

#1885: nditer: Error in detecting double reduction loop

#1874: f2py: fix –include_paths bug

#1749: Fix ctypes.load_library()

#1895/1896: iter: writeonly operands weren’t always being buffered correctly# NumPy 1.7.1 Release Notes[#](#numpy-1-7-1-release-notes)
This is a bugfix only release in the 1.7.x series. It supports Python 2.4 - 2.7 and 3.1 - 3.3 and is the last series that supports Python 2.4 - 2.5.

## Issues fixed[#](#issues-fixed)
gh-2973: Fix

*1*is printed during numpy.test()
gh-2983: BUG: gh-2969: Backport memory leak fix 80b3a34.

gh-3007: Backport gh-3006

gh-2984: Backport fix complex polynomial fit

gh-2982: BUG: Make nansum work with booleans.

gh-2985: Backport large sort fixes

gh-3039: Backport object take

gh-3105: Backport nditer fix op axes initialization

gh-3108: BUG: npy-pkg-config ini files were missing after Bento build.

gh-3124: BUG: PyArray_LexSort allocates too much temporary memory.

gh-3131: BUG: Exported f2py_size symbol prevents linking multiple f2py modules.

gh-3117: Backport gh-2992

gh-3135: DOC: Add mention of PyArray_SetBaseObject stealing a reference

gh-3134: DOC: Fix typo in fft docs (the indexing variable is ‘m’, not ‘n’).

gh-3136: Backport #3128# numpy.unravel_index[#](#numpy-unravel-index)
numpy.unravel_index(*indices*,*shape*,*order='C'*)[#](#numpy.unravel_index)
-
Converts a flat index or array of flat indices into a tuple of coordinate arrays.

Parameters:
-
**indices**array_like
An integer array whose elements are indices into the flattened version of an array of dimensions

`shape`
. Before version 1.6.0, this function accepted just one index value.
**shape**tuple of ints
The shape of the array to use for unraveling

`indices`
.Changed in version 1.16.0: Renamed from

`dims`
to`shape`
.
**order**{‘C’, ‘F’}, optional
Determines whether the indices should be viewed as indexing in row-major (C-style) or column-major (Fortran-style) order.

New in version 1.6.0.

Returns:
-
**unraveled_coords**tuple of ndarray
Each array in the tuple has the same shape as the

`indices`
array.
See also

Examples

>>> np.unravel_index([22, 41, 37], (7,6)) (array([3, 6, 6]), array([4, 5, 1])) >>> np.unravel_index([31, 41, 13], (7,6), order='F') (array([3, 6, 6]), array([4, 5, 1]))
>>> np.unravel_index(1621, (6,7,8,9)) (3, 1, 4, 1)# numpy.chararray.tobytes[#](#numpy-chararray-tobytes)
method

chararray.tobytes(*order='C'*)[#](#numpy.chararray.tobytes)
-
Construct Python bytes containing the raw data bytes in the array.

Constructs Python bytes showing a copy of the raw contents of data memory. The bytes object is produced in C-order by default. This behavior is controlled by the

`order`
parameter.New in version 1.9.0.

Parameters:
-
**order**{‘C’, ‘F’, ‘A’}, optional
Controls the memory layout of the bytes object. ‘C’ means C-order, ‘F’ means F-order, ‘A’ (short for

*Any*) means ‘F’ if*a*is Fortran contiguous, ‘C’ otherwise. Default is ‘C’.
Returns:
-
**s**bytes
Python bytes exhibiting a copy of

*a*’s raw data.
See also

`frombuffer`
Inverse of this operation, construct a 1-dimensional array from Python bytes.

Examples

>>> x = np.array([[0, 1], [2, 3]], dtype='<u2') >>> x.tobytes() b'\x00\x00\x01\x00\x02\x00\x03\x00' >>> x.tobytes('C') == x.tobytes() True >>> x.tobytes('F') b'\x00\x00\x02\x00\x01\x00\x03\x00'numpy.poly1d.deriv# method poly1d.deriv(m=1)[source]# Return a derivative of this polynomial. Refer to polyder for full documentation. See also polyderequivalent function# numpy.record.compress[#](#numpy-record-compress)
method

record.compress()[#](#numpy.record.compress)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.compress`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.compress](numpy.ndarray.compress.html#numpy.ndarray.compress).# numpy.polynomial.chebyshev.Chebyshev.deriv[#](#numpy-polynomial-chebyshev-chebyshev-deriv)
method

polynomial.chebyshev.Chebyshev.deriv(*m=1*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L886-L906)[#](#numpy.polynomial.chebyshev.Chebyshev.deriv)
-
Differentiate.

Return a series instance of that is the derivative of the current series.

Parameters:
-
**m**non-negative int
Find the derivative of order

*m*.
Returns:
-
**new_series**series
A new series representing the derivative. The domain is the same as the domain of the differentiated series.# numpy.record.getfield[#](#numpy-record-getfield)
method

record.getfield()[#](#numpy.record.getfield)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.getfield`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.getfield](numpy.ndarray.getfield.html#numpy.ndarray.getfield).# numpy.memmap.dtype[#](#numpy-memmap-dtype)
attribute

memmap.dtype[#](#numpy.memmap.dtype)
-
Data-type of the array’s elements.

Warning

Setting

`arr.dtype`
is discouraged and may be deprecated in the future. Setting will replace the`dtype`
without modifying the memory (see alsoand`ndarray.view`
).`ndarray.astype`
Parameters:
-
**None**
Returns:
-
**d**numpy dtype object
See also

`ndarray.astype`
Cast the values contained in the array to a new data-type.

`ndarray.view`
Create a view of the same data but a different data-type.

`numpy.dtype`
Examples

>>> x array([[0, 1], [2, 3]]) >>> x.dtype dtype('int32') >>> type(x.dtype) <type 'numpy.dtype'>numpy.char.chararray.lower# method char.chararray.lower()[source]# Return an array with the elements of self converted to lowercase. See also char.lowerUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
polynomial.laguerre.Laguerre.maxpower
numpy.polynomial.laguerre.Laguerre.maxpower
#
attribute
polynomial.laguerre.Laguerre.
maxpower
=
100
#numpy.random.ranf# random.ranf()# This is an alias of random_sample. See random_sample for the complete documentation.# numpy.linalg.inv[#](#numpy-linalg-inv)
linalg.inv(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L492-L562)[#](#numpy.linalg.inv)
-
Compute the (multiplicative) inverse of a matrix.

Given a square matrix

*a*, return the matrix*ainv*satisfying`dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])`
.Parameters:
-
**a**(…, M, M) array_like
Matrix to be inverted.

Returns:
-
**ainv**(…, M, M) ndarray or matrix
(Multiplicative) inverse of the matrix

*a*.
Raises:
-
LinAlgError
-
If

*a*is not square or inversion fails.
See also

`scipy.linalg.inv`
Similar function in SciPy.

Notes

New in version 1.8.0.

Broadcasting rules apply, see the

documentation for details.`numpy.linalg`
Examples

>>> from numpy.linalg import inv >>> a = np.array([[1., 2.], [3., 4.]]) >>> ainv = inv(a) >>> np.allclose(np.dot(a, ainv), np.eye(2)) True >>> np.allclose(np.dot(ainv, a), np.eye(2)) True
If a is a matrix object, then the return value is a matrix as well:

>>> ainv = inv(np.matrix(a)) >>> ainv matrix([[-2. , 1. ], [ 1.5, -0.5]])
Inverses of several matrices can be computed at once:

>>> a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]]) >>> inv(a) array([[[-2. , 1. ], [ 1.5 , -0.5 ]], [[-1.25, 0.75], [ 0.75, -0.25]]])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
random.BitGenerator.capsule
numpy.random.BitGenerator.capsule
#
attribute
random.BitGenerator.
capsule
#User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__invert__
numpy.ndarray.__invert__
#
method
ndarray.
__invert__
(
/
)
#
~selfnumpy.polynomial.laguerre.Laguerre.has_samewindow# method polynomial.laguerre.Laguerre.has_samewindow(other)[source]# Check if windows match. New in version 1.6.0. Parameters: otherclass instanceThe other class must have the window attribute. Returns: boolbooleanTrue if the windows are the same, False otherwise.# numpy.char.chararray.swapaxes[#](#numpy-char-chararray-swapaxes)
method

char.chararray.swapaxes(*axis1*,*axis2*)[#](#numpy.char.chararray.swapaxes)
-
Return a view of the array with

*axis1*and*axis2*interchanged.Refer to

for full documentation.`numpy.swapaxes`
See also

`numpy.swapaxes`
equivalent function

method

Return a view of the array with *axis1* and *axis2* interchanged.

Refer to [ numpy.swapaxes](numpy.swapaxes.html#numpy.swapaxes) for full documentation.

See also

`numpy.swapaxes`
equivalent function# numpy.ma.MaskedArray.__eq__[#](#numpy-ma-maskedarray-eq)
method

ma.MaskedArray.__eq__(*other*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4171-L4182)[#](#numpy.ma.MaskedArray.__eq__)
-
Check whether other equals self elementwise.

When either of the elements is masked, the result is masked as well, but the underlying boolean data are still set, with self and other considered equal if both are masked, and unequal otherwise.

For structured arrays, all fields are combined, with masked values ignored. The result is masked if all fields were masked, with self and other considered equal only if both were fully masked.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
record.real
numpy.record.real
#
attribute
record.
real
#
The real part of the scalar.# numpy.ndarray.setfield[#](#numpy-ndarray-setfield)
method

ndarray.setfield(*val*,*dtype*,*offset=0*)[#](#numpy.ndarray.setfield)
-
Put a value into a specified place in a field defined by a data-type.

Place

*val*into*a*’s field defined byand beginning`dtype`
*offset*bytes into the field.Parameters:
-
**val**object
Value to be placed in field.

**dtype**dtype object
Data-type of the field in which to place

*val*.
**offset**int, optional
The number of bytes into the field at which to place

*val*.
Returns:
-
None
-
See also

Examples

>>> x = np.eye(3) >>> x.getfield(np.float64) array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) >>> x.setfield(3, np.int32) >>> x.getfield(np.int32) array([[3, 3, 3], [3, 3, 3], [3, 3, 3]], dtype=int32) >>> x array([[1.0e+000, 1.5e-323, 1.5e-323], [1.5e-323, 1.0e+000, 1.5e-323], [1.5e-323, 1.5e-323, 1.0e+000]]) >>> x.setfield(np.eye(3), np.int32) >>> x array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])# numpy.ndarray.nbytes[#](#numpy-ndarray-nbytes)
attribute

ndarray.nbytes[#](#numpy.ndarray.nbytes)
-
Total bytes consumed by the elements of the array.

See also

`sys.getsizeof`
Memory consumed by the object itself without parents in case view. This does include memory consumed by non-element attributes.

Notes

Does not include memory consumed by non-element attributes of the array object.

Examples

>>> x = np.zeros((3,5,2), dtype=np.complex128) >>> x.nbytes 480 >>> np.prod(x.shape) * x.itemsize 480User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
Scalars
numpy.generic.flags
numpy.generic.shape
numpy.generic.strides
numpy.generic.ndim
numpy.generic.data
numpy.generic.size
numpy.generic.itemsize
numpy.generic.base
numpy.generic.dtype
numpy.generic.real
numpy.generic.imag
numpy.generic.flat
numpy.generic.T
numpy.generic.__array_interface__
numpy.generic.__array_struct__
numpy.generic.__array_priority__
numpy.generic.__array_wrap__
numpy.generic.__array__
numpy.generic.__array_wrap__
numpy.generic.squeeze
numpy.generic.byteswap
numpy.generic.__reduce__
numpy.generic.__setstate__
numpy.generic.setflags
numpy.number.__class_getitem__
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
generic.data
numpy.generic.data
#
attribute
generic.
data
#
Pointer to start of data.numpy.polynomial.hermite_e.HermiteE.has_samedomain# method polynomial.hermite_e.HermiteE.has_samedomain(other)[source]# Check if domains match. New in version 1.6.0. Parameters: otherclass instanceThe other class must have the domain attribute. Returns: boolbooleanTrue if the domains are the same, False otherwise.# numpy.ma.masked_array.setfield[#](#numpy-ma-masked-array-setfield)
method

ma.masked_array.setfield(*val*,*dtype*,*offset=0*)[#](#numpy.ma.masked_array.setfield)
-
Put a value into a specified place in a field defined by a data-type.

Place

*val*into*a*’s field defined byand beginning`dtype`
*offset*bytes into the field.Parameters:
-
**val**object
Value to be placed in field.

**dtype**dtype object
Data-type of the field in which to place

*val*.
**offset**int, optional
The number of bytes into the field at which to place

*val*.
Returns:
-
None
-
See also

Examples

>>> x = np.eye(3) >>> x.getfield(np.float64) array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) >>> x.setfield(3, np.int32) >>> x.getfield(np.int32) array([[3, 3, 3], [3, 3, 3], [3, 3, 3]], dtype=int32) >>> x array([[1.0e+000, 1.5e-323, 1.5e-323], [1.5e-323, 1.0e+000, 1.5e-323], [1.5e-323, 1.5e-323, 1.0e+000]]) >>> x.setfield(np.eye(3), np.int32) >>> x array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])numpy.recarray.ndim# attribute recarray.ndim# Number of array dimensions. Examples >>> x = np.array([1, 2, 3]) >>> x.ndim 1 >>> y = np.zeros((2, 3, 4)) >>> y.ndim 3# numpy.ma.masked_array.compressed[#](#numpy-ma-masked-array-compressed)
method

ma.masked_array.compressed()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L3866-L3891)[#](#numpy.ma.masked_array.compressed)
-
Return all the non-masked data as a 1-D array.

Returns:
-
**data**ndarray
A new

holding the non-masked data is returned.`ndarray`
Notes

The result is

**not**a MaskedArray!Examples

>>> x = np.ma.array(np.arange(5), mask=[0]*2 + [1]*3) >>> x.compressed() array([0, 1]) >>> type(x.compressed()) <class 'numpy.ndarray'># numpy.ma.concatenate[#](#numpy-ma-concatenate)
ma.concatenate(*arrays*,*axis=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L7095-L7152)[#](#numpy.ma.concatenate)
-
Concatenate a sequence of arrays along the given axis.

Parameters:
-
**arrays**sequence of array_like
The arrays must have the same shape, except in the dimension corresponding to

*axis*(the first, by default).
**axis**int, optional
The axis along which the arrays will be joined. Default is 0.

Returns:
-
**result**MaskedArray
The concatenated array with any masked entries preserved.

See also

`numpy.concatenate`
Equivalent function in the top-level NumPy module.

Examples

>>> import numpy.ma as ma >>> a = ma.arange(3) >>> a[1] = ma.masked >>> b = ma.arange(2, 5) >>> a masked_array(data=[0, --, 2], mask=[False, True, False], fill_value=999999) >>> b masked_array(data=[2, 3, 4], mask=False, fill_value=999999) >>> ma.concatenate([a, b]) masked_array(data=[0, --, 2, 2, 3, 4], mask=[False, True, False, False, False, False], fill_value=999999)# numpy.ma.getmask[#](#numpy-ma-getmask)
ma.getmask(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L1362-L1418)[#](#numpy.ma.getmask)
-
Return the mask of a masked array, or nomask.

Return the mask of

*a*as an ndarray if*a*is aand the mask is not`MaskedArray`
, else return`nomask`
. To guarantee a full array of booleans of the same shape as a, use`nomask`
.`getmaskarray`
Parameters:
-
**a**array_like
Input

for which the mask is required.`MaskedArray`
See also

`getdata`
Return the data of a masked array as an ndarray.

`getmaskarray`
Return the mask of a masked array, or full array of False.

Examples

>>> import numpy.ma as ma >>> a = ma.masked_equal([[1,2],[3,4]], 2) >>> a masked_array( data=[[1, --], [3, 4]], mask=[[False, True], [False, False]], fill_value=2) >>> ma.getmask(a) array([[False, True], [False, False]])
Equivalently use the

`MaskedArray`
*mask*attribute.>>> a.mask array([[False, True], [False, False]])
Result when mask ==

`nomask`
>>> b = ma.masked_array([[1,2],[3,4]]) >>> b masked_array( data=[[1, 2], [3, 4]], mask=False, fill_value=999999) >>> ma.nomask False >>> ma.getmask(b) == ma.nomask True >>> b.mask == ma.nomask True# numpy.ndarray.take[#](#numpy-ndarray-take)
method

ndarray.take(*indices*,*axis=None*,*out=None*,*mode='raise'*)[#](#numpy.ndarray.take)
-
Return an array formed from the elements of

*a*at the given indices.Refer to

for full documentation.`numpy.take`
See also

`numpy.take`
equivalent function# numpy.testing.assert_[#](#numpy-testing-assert)
testing.assert_(*val*,*msg=''*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/testing/_private/utils.py#L71-L88)[#](#numpy.testing.assert_)
-
Assert that works in release mode. Accepts callable msg to allow deferring evaluation until failure.

The Python built-in

`assert`
does not work when executing code in optimized mode (the`-O`
flag) - no byte-code is generated for it.For documentation on usage, refer to the Python documentation.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
ma.MaskType.real
numpy.ma.MaskType.real
#
attribute
ma.MaskType.
real
#
The real part of the scalar.numpy.memmap.put# method memmap.put(indices, values, mode='raise')# Set a.flat[n] = values[n] for all n in indices. Refer to numpy.put for full documentation. See also numpy.putequivalent function# numpy.ma.anomalies[#](#numpy-ma-anomalies)
ma.anomalies(*self*,*axis=None*,*dtype=None*)*= <numpy.ma.core._frommethod object>*[#](#numpy.ma.anomalies)
-
Compute the anomalies (deviations from the arithmetic mean) along the given axis.

Returns an array of anomalies, with the same shape as the input and where the arithmetic mean is computed along the given axis.

Parameters:
-
**axis**int, optional
Axis over which the anomalies are taken. The default is to use the mean of the flattened array as reference.

**dtype**dtype, optional
Type to use in computing the variance. For arrays of integer type
-
the default is float32; for arrays of float types it is the same as the array type.

See also

`mean`
Compute the mean of the array.

Examples

>>> a = np.ma.array([1,2,3]) >>> a.anom() masked_array(data=[-1., 0., 1.], mask=False, fill_value=1e+20)numpy.polynomial.laguerre.Laguerre.has_samedomain# method polynomial.laguerre.Laguerre.has_samedomain(other)[source]# Check if domains match. New in version 1.6.0. Parameters: otherclass instanceThe other class must have the domain attribute. Returns: boolbooleanTrue if the domains are the same, False otherwise.# numpy.ma.masked_array.round[#](#numpy-ma-masked-array-round)
method

ma.masked_array.round(*decimals=0*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5486-L5509)[#](#numpy.ma.masked_array.round)
-
Return each element rounded to the given number of decimals.

Refer to

for full documentation.`numpy.around`
See also

`numpy.ndarray.round`
corresponding function for ndarrays

`numpy.around`
equivalent functionnumpy.random.PCG64DXSM.state# attribute random.PCG64DXSM.state# Get or set the PRNG state Returns: statedictDictionary containing the information required to describe the state of the PRNG# numpy.chararray.isnumeric[#](#numpy-chararray-isnumeric)
method

chararray.isnumeric()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2705-L2715)[#](#numpy.chararray.isnumeric)
-
For each element in

*self*, return True if there are only numeric characters in the element.See also

method

For each element in *self*, return True if there are only
numeric characters in the element.

See also# numpy.polynomial.hermite_e.HermiteE.degree[#](#numpy-polynomial-hermite-e-hermitee-degree)
method

polynomial.hermite_e.HermiteE.degree()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L675-L708)[#](#numpy.polynomial.hermite_e.HermiteE.degree)
-
The degree of the series.

New in version 1.5.0.

Returns:
-
**degree**int
Degree of the series, one less than the number of coefficients.

Examples

Create a polynomial object for

`1 + 7*x + 4*x**2`
:>>> poly = np.polynomial.Polynomial([1, 7, 4]) >>> print(poly) 1.0 + 7.0·x + 4.0·x² >>> poly.degree() 2
Note that this method does not check for non-zero coefficients. You must trim the polynomial to remove any trailing zeroes:

>>> poly = np.polynomial.Polynomial([1, 7, 0]) >>> print(poly) 1.0 + 7.0·x + 0.0·x² >>> poly.degree() 2 >>> poly.trim().degree() 1numpy.distutils.ccompiler_opt.CCompilerOpt.feature_implies_c# method distutils.ccompiler_opt.CCompilerOpt.feature_implies_c(names)[source]# same as feature_implies() but combining ‘names’# numpy.random.PCG64DXSM.ctypes[#](#numpy-random-pcg64dxsm-ctypes)
attribute

random.PCG64DXSM.ctypes[#](#numpy.random.PCG64DXSM.ctypes)
-
ctypes interface

Returns:
-
**interface**namedtuple
Named tuple containing ctypes wrapper

state_address - Memory address of the state struct

state - pointer to the state struct

next_uint64 - function pointer to produce 64 bit integers

next_uint32 - function pointer to produce 32 bit integers

next_double - function pointer to produce doubles

bitgen - pointer to the bit generator struct# numpy.chararray.mean[#](#numpy-chararray-mean)
method

chararray.mean(*axis=None*,*dtype=None*,*out=None*,*keepdims=False*,***,*where=True*)[#](#numpy.chararray.mean)
-
Returns the average of the array elements along given axis.

Refer to

for full documentation.`numpy.mean`
See also

`numpy.mean`
equivalent functionnumpy.record.item# method record.item()# Scalar method identical to the corresponding array attribute. Please see ndarray.item.ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__and__

method

Return self&value.# numpy.random.RandomState.standard_normal[#](#numpy-random-randomstate-standard-normal)
method

random.RandomState.standard_normal(*size=None*)[#](#numpy.random.RandomState.standard_normal)
-
Draw samples from a standard Normal distribution (mean=0, stdev=1).

Note

New code should use the

method of a`standard_normal`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**out**float or ndarray
A floating-point array of shape

`size`
of drawn samples, or a single sample if`size`
was not specified.
See also

`normal`
Equivalent function with additional

`loc`
and`scale`
arguments for setting the mean and standard deviation.
`random.Generator.standard_normal`
which should be used for new code.

Notes

For random samples from the normal distribution with mean

`mu`
and standard deviation`sigma`
, use one of:mu + sigma * np.random.standard_normal(size=...) np.random.normal(mu, sigma, size=...)
Examples

>>> np.random.standard_normal() 2.1923875335537315 #random
>>> s = np.random.standard_normal(8000) >>> s array([ 0.6888893 , 0.78096262, -0.89086505, ..., 0.49876311, # random -0.38672696, -0.4685006 ]) # random >>> s.shape (8000,) >>> s = np.random.standard_normal(size=(3, 4, 2)) >>> s.shape (3, 4, 2)
Two-by-four array of samples from the normal distribution with mean 3 and standard deviation 2.5:

>>> 3 + 2.5 * np.random.standard_normal(size=(2, 4)) array([[-4.49401501, 4.00950034, -1.81814867, 7.29718677], # random [ 0.39924804, 4.68456316, 4.99394529, 4.84057254]]) # randomnumpy.record.ravel# method record.ravel()# Scalar method identical to the corresponding array attribute. Please see ndarray.ravel.numpy.ma.MaskType.ptp# method ma.MaskType.ptp()# Scalar method identical to the corresponding array attribute. Please see ndarray.ptp.# numpy.matrix.all[#](#numpy-matrix-all)
method

matrix.all(*axis=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L572-L610)[#](#numpy.matrix.all)
-
Test whether all matrix elements along a given axis evaluate to True.

Parameters:
-
**See `numpy.all` for complete descriptions**
See also

Notes

This is the same as

, but it returns a`ndarray.all`
object.`matrix`
Examples

>>> x = np.matrix(np.arange(12).reshape((3,4))); x matrix([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) >>> y = x[0]; y matrix([[0, 1, 2, 3]]) >>> (x == y) matrix([[ True, True, True, True], [False, False, False, False], [False, False, False, False]]) >>> (x == y).all() False >>> (x == y).all(0) matrix([[False, False, False, False]]) >>> (x == y).all(1) matrix([[ True], [False], [False]])# numpy.polynomial.polynomial.Polynomial.convert[#](#numpy-polynomial-polynomial-polynomial-convert)
method

polynomial.polynomial.Polynomial.convert(*domain=None*,*kind=None*,*window=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L787-L822)[#](#numpy.polynomial.polynomial.Polynomial.convert)
-
Convert series to a different kind and/or domain and/or window.

Parameters:
-
**domain**array_like, optional
The domain of the converted series. If the value is None, the default domain of

*kind*is used.
**kind**class, optional
The polynomial series type class to which the current instance should be converted. If kind is None, then the class of the current instance is used.

**window**array_like, optional
The window of the converted series. If the value is None, the default window of

*kind*is used.
Returns:
-
**new_series**series
The returned class can be of different type than the current instance and/or have a different domain and/or different window.

Notes

Conversion between domains and class types can result in numerically ill defined series.# numpy.random.SeedSequence.spawn[#](#numpy-random-seedsequence-spawn)
method

random.SeedSequence.spawn(*n_children*)[#](#numpy.random.SeedSequence.spawn)
-
Spawn a number of child

*SeedSequence*s by extending the.`spawn_key`
See

[SeedSequence spawning](../../parallel.html#seedsequence-spawn)for additional notes on spawning children.Parameters:
-
**n_children**int
Returns:
-
**seqs**list of*SeedSequence*s
See also

,`random.Generator.spawn`
`random.BitGenerator.spawn`
Equivalent method on the generator and bit generator.# numpy.random.get_state[#](#numpy-random-get-state)
random.get_state(*legacy=True*)[#](#numpy.random.get_state)
-
Return a tuple representing the internal state of the generator.

For more details, see

.`set_state`
Parameters:
-
**legacy**bool, optional
Flag indicating to return a legacy tuple state when the BitGenerator is MT19937, instead of a dict. Raises ValueError if the underlying bit generator is not an instance of MT19937.

Returns:
-
**out**{tuple(str, ndarray of 624 uints, int, int, float), dict}
If legacy is True, the returned tuple has the following items:

the string ‘MT19937’.

a 1-D array of 624 unsigned integer keys.

an integer

`pos`
.
an integer

`has_gauss`
.
a float

`cached_gaussian`
.
If

*legacy*is False, or the BitGenerator is not MT19937, then state is returned as a dictionary.
See also

Notes

and`set_state`
are not needed to work with any of the random distributions in NumPy. If the internal state is manually altered, the user should know exactly what he/she is doing.`get_state`# numpy.ma.MaskedArray.fill[#](#numpy-ma-maskedarray-fill)
method

ma.MaskedArray.fill(*value*)[#](#numpy.ma.MaskedArray.fill)
-
Fill the array with a scalar value.

Parameters:
-
**value**scalar
All elements of

*a*will be assigned this value.
Examples

>>> a = np.array([1, 2]) >>> a.fill(0) >>> a array([0, 0]) >>> a = np.empty(2) >>> a.fill(1) >>> a array([1., 1.])
Fill expects a scalar value and always behaves the same as assigning to a single array element. The following is a rare example where this distinction is important:

>>> a = np.array([None, None], dtype=object) >>> a[0] = np.array(3) >>> a array([array(3), None], dtype=object) >>> a.fill(np.array(3)) >>> a array([array(3), array(3)], dtype=object)
Where other forms of assignments will unpack the array being assigned:

>>> a[...] = np.array(3) >>> a array([3, 3], dtype=object)# numpy.record.setfield[#](#numpy-record-setfield)
method

record.setfield()[#](#numpy.record.setfield)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.setfield`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.setfield](numpy.ndarray.setfield.html#numpy.ndarray.setfield).numpy.ma.masked_array.tofile# method ma.masked_array.tofile(fid, sep='', format='%s')[source]# Save a masked array to a file in binary format. Warning This function is not implemented yet. Raises: NotImplementedErrorWhen tofile is called.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
nditer.itviews
numpy.nditer.itviews
#
attribute
nditer.
itviews
#numpy.ufunc.nin# attribute ufunc.nin# The number of inputs. Data attribute containing the number of arguments the ufunc treats as input. Examples >>> np.add.nin 2 >>> np.multiply.nin 2 >>> np.power.nin 2 >>> np.exp.nin 1# numpy.ma.is_mask[#](#numpy-ma-is-mask)
ma.is_mask(*m*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L1477-L1542)[#](#numpy.ma.is_mask)
-
Return True if m is a valid, standard mask.

This function does not check the contents of the input, only that the type is MaskType. In particular, this function returns False if the mask has a flexible dtype.

Parameters:
-
**m**array_like
Array to test.

Returns:
-
**result**bool
True if

*m.dtype.type*is MaskType, False otherwise.
See also

`ma.isMaskedArray`
Test whether input is an instance of MaskedArray.

Examples

>>> import numpy.ma as ma >>> m = ma.masked_equal([0, 1, 0, 2, 3], 0) >>> m masked_array(data=[--, 1, --, 2, 3], mask=[ True, False, True, False, False], fill_value=0) >>> ma.is_mask(m) False >>> ma.is_mask(m.mask) True
Input must be an ndarray (or have similar attributes) for it to be considered a valid mask.

>>> m = [False, True, False] >>> ma.is_mask(m) False >>> m = np.array([False, True, False]) >>> m array([False, True, False]) >>> ma.is_mask(m) True
Arrays with complex dtypes don’t return True.

>>> dtype = np.dtype({'names':['monty', 'pithon'], ... 'formats':[bool, bool]}) >>> dtype dtype([('monty', '|b1'), ('pithon', '|b1')]) >>> m = np.array([(True, False), (False, True), (True, False)], ... dtype=dtype) >>> m array([( True, False), (False, True), ( True, False)], dtype=[('monty', '?'), ('pithon', '?')]) >>> ma.is_mask(m) Falsenumpy.ma.masked_array.tostring# method ma.masked_array.tostring(fill_value=None, order='C')[source]# A compatibility alias for tobytes, with exactly the same behavior. Despite its name, it returns bytes not strs. Deprecated since version 1.19.0.numpy.recarray.data# attribute recarray.data# Python buffer object pointing to the start of the array’s data.# numpy.ma.masked_array.std[#](#numpy-ma-masked-array-std)
method

ma.masked_array.std(*axis=None*,*dtype=None*,*out=None*,*ddof=0*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5462-L5484)[#](#numpy.ma.masked_array.std)
-
Returns the standard deviation of the array elements along given axis.

Masked entries are ignored.

Refer to

for full documentation.`numpy.std`
See also

`numpy.ndarray.std`
corresponding function for ndarrays

`numpy.std`
Equivalent function# numpy.ma.zeros_like[#](#numpy-ma-zeros-like)
ma.zeros_like*= <numpy.ma.core._convert2ma object>*[#](#numpy.ma.zeros_like)
-
Return an array of zeros with the same shape and type as a given array.

Parameters:
-
**a**array_like
The shape and data-type of

*a*define these same attributes of the returned array.
**dtype**data-type, optional
Overrides the data type of the result.

New in version 1.6.0.

**order**{‘C’, ‘F’, ‘A’, or ‘K’}, optional
Overrides the memory layout of the result. ‘C’ means C-order, ‘F’ means F-order, ‘A’ means ‘F’ if

*a*is Fortran contiguous, ‘C’ otherwise. ‘K’ means match the layout of*a*as closely as possible.New in version 1.6.0.

**subok**bool, optional.
If True, then the newly created array will use the sub-class type of

*a*, otherwise it will be a base-class array. Defaults to True.
**shape**int or sequence of ints, optional.
Overrides the shape of the result. If order=’K’ and the number of dimensions is unchanged, will try to keep order, otherwise, order=’C’ is implied.

New in version 1.17.0.

Returns:
-
**out**MaskedArray
Array of zeros with the same shape and type as

*a*.
See also

`empty_like`
Return an empty array with shape and type of input.

`ones_like`
Return an array of ones with shape and type of input.

`full_like`
Return a new array with shape of input filled with value.

`zeros`
Return a new array setting values to zero.

Examples

>>> x = np.arange(6) >>> x = x.reshape((2, 3)) >>> x array([[0, 1, 2], [3, 4, 5]]) >>> np.zeros_like(x) array([[0, 0, 0], [0, 0, 0]])
>>> y = np.arange(3, dtype=float) >>> y array([0., 1., 2.]) >>> np.zeros_like(y) array([0., 0., 0.])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
poly1d.coeffs
numpy.poly1d.coeffs
#
property
property
poly1d.
coeffs
#
The polynomial coefficients# numpy.matrix.min[#](#numpy-matrix-min)
method

matrix.min(*axis=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L686-L719)[#](#numpy.matrix.min)
-
Return the minimum value along an axis.

Parameters:
-
**See `amin` for complete descriptions.**
See also

Notes

This is the same as

, but returns a`ndarray.min`
object where`matrix`
would return an ndarray.`ndarray.min`
Examples

>>> x = -np.matrix(np.arange(12).reshape((3,4))); x matrix([[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]]) >>> x.min() -11 >>> x.min(0) matrix([[ -8, -9, -10, -11]]) >>> x.min(1) matrix([[ -3], [ -7], [-11]])# numpy.matrix.trace[#](#numpy-matrix-trace)
method

matrix.trace(*offset=0*,*axis1=0*,*axis2=1*,*dtype=None*,*out=None*)[#](#numpy.matrix.trace)
-
Return the sum along diagonals of the array.

Refer to

for full documentation.`numpy.trace`
See also

`numpy.trace`
equivalent function

method

Return the sum along diagonals of the array.

Refer to [ numpy.trace](numpy.trace.html#numpy.trace) for full documentation.

See also

`numpy.trace`
equivalent function# numpy.char.startswith[#](#numpy-char-startswith)
char.startswith(*a*,*prefix*,*start=0*,*end=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L1581-L1610)[#](#numpy.char.startswith)
-
Returns a boolean array which is

*True*where the string element in*a*starts with*prefix*, otherwise*False*.Calls

*str.startswith*element-wise.Parameters:
-
**a**array_like of str or unicode
**prefix**str
**start, end**int, optional
With optional

*start*, test beginning at that position. With optional*end*, stop comparing at that position.
Returns:
-
**out**ndarray
Array of booleans

See also# numpy.polynomial.laguerre.Laguerre.identity[#](#numpy-polynomial-laguerre-laguerre-identity)
method

*classmethod*polynomial.laguerre.Laguerre.identity(*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1090-L1123)[#](#numpy.polynomial.laguerre.Laguerre.identity)
-
Identity function.

If

`p`
is the returned series, then`p(x) == x`
for all values of x.Parameters:
-
**domain**{None, array_like}, optional
If given, the array must be of the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the domain. If None is given then the class domain is used. The default is None.
**window**{None, array_like}, optional
If given, the resulting array must be if the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the window. If None is given then the class window is used. The default is None.
**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
Series of representing the identity.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__contains__
numpy.ndarray.__contains__
#
method
ndarray.
__contains__
(
key
,
/
)
#
Return key in self.numpy.ndarray.put# method ndarray.put(indices, values, mode='raise')# Set a.flat[n] = values[n] for all n in indices. Refer to numpy.put for full documentation. See also numpy.putequivalent function# numpy.memmap.transpose[#](#numpy-memmap-transpose)
method

memmap.transpose(**axes*)[#](#numpy.memmap.transpose)
-
Returns a view of the array with axes transposed.

Refer to

for full documentation.`numpy.transpose`
Parameters:
-
**axes**None, tuple of ints, or*n*ints
None or no argument: reverses the order of the axes.

tuple of ints:

*i*in the*j*-th place in the tuple means that the array’s*i*-th axis becomes the transposed array’s*j*-th axis.
*n*ints: same as an n-tuple of the same ints (this form is intended simply as a “convenience” alternative to the tuple form).
Returns:
-
**p**ndarray
View of the array with its axes suitably permuted.

See also

`transpose`
Equivalent function.

`ndarray.T`
Array property returning the array transposed.

`ndarray.reshape`
Give a new shape to an array without changing its data.

Examples

>>> a = np.array([[1, 2], [3, 4]]) >>> a array([[1, 2], [3, 4]]) >>> a.transpose() array([[1, 3], [2, 4]]) >>> a.transpose((1, 0)) array([[1, 3], [2, 4]]) >>> a.transpose(1, 0) array([[1, 3], [2, 4]])
>>> a = np.array([1, 2, 3, 4]) >>> a array([1, 2, 3, 4]) >>> a.transpose() array([1, 2, 3, 4])# numpy.broadcast.iters[#](#numpy-broadcast-iters)
attribute

broadcast.iters[#](#numpy.broadcast.iters)
-
tuple of iterators along

`self`
’s “components.”Returns a tuple of

objects, one for each “component” of`numpy.flatiter`
`self`
.See also

Examples

>>> x = np.array([1, 2, 3]) >>> y = np.array([[4], [5], [6]]) >>> b = np.broadcast(x, y) >>> row, col = b.iters >>> next(row), next(col) (1, 4)numpy.ma.MaskedArray.__iadd__# method ma.MaskedArray.__iadd__(other)[source]# Add other to self in-place.numpy.char.chararray.index# method char.chararray.index(sub, start=0, end=None)[source]# Like find, but raises ValueError when the substring is not found. See also char.indexUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
lib.user_array.container.tostring
numpy.lib.user_array.container.tostring
#
method
lib.user_array.container.
tostring
(
)
[source]
## numpy.source[#](#numpy-source)
numpy.source(*object*,*output=<_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/utils.py#L695-L741)[#](#numpy.source)
-
Print or write to a file the source code for a NumPy object.

The source code is only returned for objects written in Python. Many functions and classes are defined in C and will therefore not return useful information.

Parameters:
-
**object**numpy object
Input object. This can be any object (function, class, module, …).

**output**file object, optional
If

*output*not supplied then source code is printed to screen (sys.stdout). File object must be created with either write ‘w’ or append ‘a’ modes.
Examples

>>> np.source(np.interp) In file: /usr/lib/python2.6/dist-packages/numpy/lib/function_base.py def interp(x, xp, fp, left=None, right=None): """.... (full docstring printed)""" if isinstance(x, (float, int, number)): return compiled_interp([x], xp, fp, left, right).item() else: return compiled_interp(x, xp, fp, left, right)
The source code is only returned for objects written in Python.

>>> np.source(np.array) Not available for this object.# numpy.union1d[#](#numpy-union1d)
numpy.union1d(*ar1*,*ar2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/arraysetops.py#L898-L932)[#](#numpy.union1d)
-
Find the union of two arrays.

Return the unique, sorted array of values that are in either of the two input arrays.

Parameters:
-
**ar1, ar2**array_like
Input arrays. They are flattened if they are not already 1D.

Returns:
-
**union1d**ndarray
Unique, sorted union of the input arrays.

See also

`numpy.lib.arraysetops`
Module with a number of other functions for performing set operations on arrays.

Examples

>>> np.union1d([-1, 0, 1], [-2, 0, 2]) array([-2, -1, 0, 1, 2])
To find the union of more than two arrays, use functools.reduce:

>>> from functools import reduce >>> reduce(np.union1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2])) array([1, 2, 3, 4, 6])# numpy.char.chararray.isalnum[#](#numpy-char-chararray-isalnum)
method

char.chararray.isalnum()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2364-L2375)[#](#numpy.char.chararray.isalnum)
-
Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.

See also

method

Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.

See also# numpy.ma.masked_array.toflex[#](#numpy-ma-masked-array-toflex)
method

ma.masked_array.toflex()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L6223-L6280)[#](#numpy.ma.masked_array.toflex)
-
Transforms a masked array into a flexible-type array.

The flexible type array that is returned will have two fields:

the

`_data`
field stores the`_data`
part of the array.
the

`_mask`
field stores the`_mask`
part of the array.
Parameters:
-
**None**
Returns:
-
**record**ndarray
A new flexible-type

with two fields: the first element containing a value, the second element containing the corresponding mask boolean. The returned record shape matches self.shape.`ndarray`
Notes

A side-effect of transforming a masked array into a flexible

is that meta information (`ndarray`
`fill_value`
, …) will be lost.Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.toflex() array([[(1, False), (2, True), (3, False)], [(4, True), (5, False), (6, True)], [(7, False), (8, True), (9, False)]], dtype=[('_data', '<i8'), ('_mask', '?')])# numpy.polysub[#](#numpy-polysub)
numpy.polysub(*a1*,*a2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/polynomial.py#L856-L907)[#](#numpy.polysub)
-
Difference (subtraction) of two polynomials.

Note

This forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in

is preferred. A summary of the differences can be found in the`numpy.polynomial`
[transition guide](../routines.polynomials.html).Given two polynomials

*a1*and*a2*, returns`a1 - a2`
.*a1*and*a2*can be either array_like sequences of the polynomials’ coefficients (including coefficients equal to zero), orobjects.`poly1d`
Parameters:
-
**a1, a2**array_like or poly1d
Minuend and subtrahend polynomials, respectively.

Returns:
-
**out**ndarray or poly1d
Array or

object of the difference polynomial’s coefficients.`poly1d`
Examples

\[(2 x^2 + 10 x - 2) - (3 x^2 + 10 x -4) = (-x^2 + 2)\]>>> np.polysub([2, 10, -2], [3, 10, -4]) array([-1, 0, 2])# numpy.sort_complex[#](#numpy-sort-complex)
numpy.sort_complex(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L1763-L1797)[#](#numpy.sort_complex)
-
Sort a complex array using the real part first, then the imaginary part.

Parameters:
-
**a**array_like
Input array

Returns:
-
**out**complex ndarray
Always returns a sorted complex array.

Examples

>>> np.sort_complex([5, 3, 6, 2, 1]) array([1.+0.j, 2.+0.j, 3.+0.j, 5.+0.j, 6.+0.j])
>>> np.sort_complex([1 + 2j, 2 - 1j, 3 - 2j, 3 - 3j, 3 + 5j]) array([1.+2.j, 2.-1.j, 3.-3.j, 3.-2.j, 3.+5.j])# numpy.ma.masked_array.tobytes[#](#numpy-ma-masked-array-tobytes)
method

ma.masked_array.tobytes(*fill_value=None*,*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L6168-L6206)[#](#numpy.ma.masked_array.tobytes)
-
Return the array data as a string containing the raw bytes in the array.

The array is filled with a fill value before the string conversion.

New in version 1.9.0.

Parameters:
-
**fill_value**scalar, optional
Value used to fill in the masked values. Default is None, in which case

*MaskedArray.fill_value*is used.
**order**{‘C’,’F’,’A’}, optional
Order of the data item in the copy. Default is ‘C’.

‘C’ – C order (row major).

‘F’ – Fortran order (column major).

‘A’ – Any, current order of array.

None – Same as ‘A’.

See also

Notes

As for

, information about the shape, dtype, etc., but also about`ndarray.tobytes`
, will be lost.`fill_value`
Examples

>>> x = np.ma.array(np.array([[1, 2], [3, 4]]), mask=[[0, 1], [1, 0]]) >>> x.tobytes() b'\x01\x00\x00\x00\x00\x00\x00\x00?B\x0f\x00\x00\x00\x00\x00?B\x0f\x00\x00\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00'# numpy.ma.cumsum[#](#numpy-ma-cumsum)
ma.cumsum(*self*,*axis=None*,*dtype=None*,*out=None*)*= <numpy.ma.core._frommethod object>*[#](#numpy.ma.cumsum)
-
Return the cumulative sum of the array elements over the given axis.

Masked values are set to 0 internally during the computation. However, their position is saved, and the result will be masked at the same locations.

Refer to

for full documentation.`numpy.cumsum`
See also

`numpy.ndarray.cumsum`
corresponding function for ndarrays

`numpy.cumsum`
equivalent function

Notes

The mask is lost if

*out*is not a valid!`ma.MaskedArray`
Arithmetic is modular when using integer types, and no error is raised on overflow.

Examples

>>> marr = np.ma.array(np.arange(10), mask=[0,0,0,1,1,1,0,0,0,0]) >>> marr.cumsum() masked_array(data=[0, 1, 3, --, --, --, 9, 16, 24, 33], mask=[False, False, False, True, True, True, False, False, False, False], fill_value=999999)# numpy.iinfo[#](#numpy-iinfo)
*class*numpy.iinfo(*type*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/__init__.py)[#](#numpy.iinfo)
-
Machine limits for integer types.

Parameters:
-
**int_type**integer type, dtype, or instance
The kind of integer data type to get information about.

See also

`finfo`
The equivalent for floating point data types.

Examples

With types:

>>> ii16 = np.iinfo(np.int16) >>> ii16.min -32768 >>> ii16.max 32767 >>> ii32 = np.iinfo(np.int32) >>> ii32.min -2147483648 >>> ii32.max 2147483647
With instances:

>>> ii32 = np.iinfo(np.int32(10)) >>> ii32.min -2147483648 >>> ii32.max 2147483647numpy.distutils.ccompiler_opt.CCompilerOpt.dist_compile# method distutils.ccompiler_opt.CCompilerOpt.dist_compile(sources, flags, ccompiler=None, **kwargs)[source]# Wrap CCompiler.compile()# numpy.ma.MaskedArray.any[#](#numpy-ma-maskedarray-any)
method

ma.MaskedArray.any(*axis=None*,*out=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4948-L4976)[#](#numpy.ma.MaskedArray.any)
-
Returns True if any of the elements of

*a*evaluate to True.Masked values are considered as False during computation.

Refer to

for full documentation.`numpy.any`
See also

`numpy.ndarray.any`
corresponding function for ndarrays

`numpy.any`
equivalent function# numpy.matlib.eye[#](#numpy-matlib-eye)
matlib.eye(*n*,*M=None*,*k=0*,*dtype=<class 'float'>*,*order='C'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matlib.py#L187-L229)[#](#numpy.matlib.eye)
-
Return a matrix with ones on the diagonal and zeros elsewhere.

Parameters:
-
**n**int
Number of rows in the output.

**M**int, optional
Number of columns in the output, defaults to

*n*.
**k**int, optional
Index of the diagonal: 0 refers to the main diagonal, a positive value refers to an upper diagonal, and a negative value to a lower diagonal.

**dtype**dtype, optional
Data-type of the returned matrix.

**order**{‘C’, ‘F’}, optional
Whether the output should be stored in row-major (C-style) or column-major (Fortran-style) order in memory.

New in version 1.14.0.

Returns:
-
**I**matrix
A

*n*x*M*matrix where all elements are equal to zero, except for the*k*-th diagonal, whose values are equal to one.
Examples

>>> import numpy.matlib >>> np.matlib.eye(3, k=1, dtype=float) matrix([[0., 1., 0.], [0., 0., 1.], [0., 0., 0.]])# numpy.memmap.ravel[#](#numpy-memmap-ravel)
method

memmap.ravel([*order*])[#](#numpy.memmap.ravel)
-
Return a flattened array.

Refer to

for full documentation.`numpy.ravel`
See also

`numpy.ravel`
equivalent function

`ndarray.flat`
a flat iterator on the array.

method

Return a flattened array.

Refer to [ numpy.ravel](numpy.ravel.html#numpy.ravel) for full documentation.

See also

`numpy.ravel`
equivalent function

`ndarray.flat`
a flat iterator on the array.# numpy.polynomial.hermite_e.HermiteE.convert[#](#numpy-polynomial-hermite-e-hermitee-convert)
method

polynomial.hermite_e.HermiteE.convert(*domain=None*,*kind=None*,*window=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L787-L822)[#](#numpy.polynomial.hermite_e.HermiteE.convert)
-
Convert series to a different kind and/or domain and/or window.

Parameters:
-
**domain**array_like, optional
The domain of the converted series. If the value is None, the default domain of

*kind*is used.
**kind**class, optional
The polynomial series type class to which the current instance should be converted. If kind is None, then the class of the current instance is used.

**window**array_like, optional
The window of the converted series. If the value is None, the default window of

*kind*is used.
Returns:
-
**new_series**series
The returned class can be of different type than the current instance and/or have a different domain and/or different window.

Notes

Conversion between domains and class types can result in numerically ill defined series.# numpy.ma.flatnotmasked_contiguous[#](#numpy-ma-flatnotmasked-contiguous)
ma.flatnotmasked_contiguous(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L1839-L1893)[#](#numpy.ma.flatnotmasked_contiguous)
-
Find contiguous unmasked data in a masked array.

Parameters:
-
**a**array_like
The input array.

Returns:
-
**slice_list**list
A sorted sequence of

*slice*objects (start index, end index).Changed in version 1.15.0: Now returns an empty list instead of None for a fully masked array

Notes

Only accepts 2-D arrays at most.

Examples

>>> a = np.ma.arange(10) >>> np.ma.flatnotmasked_contiguous(a) [slice(0, 10, None)]
>>> mask = (a < 3) | (a > 8) | (a == 5) >>> a[mask] = np.ma.masked >>> np.array(a[~a.mask]) array([3, 4, 6, 7, 8])
>>> np.ma.flatnotmasked_contiguous(a) [slice(3, 5, None), slice(6, 9, None)] >>> a[:] = np.ma.masked >>> np.ma.flatnotmasked_contiguous(a) []# numpy.nanargmin[#](#numpy-nanargmin)
numpy.nanargmin(*a*,*axis=None*,*out=None*,***,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/nanfunctions.py#L501-L554)[#](#numpy.nanargmin)
-
Return the indices of the minimum values in the specified axis ignoring NaNs. For all-NaN slices

`ValueError`
is raised. Warning: the results cannot be trusted if a slice contains only NaNs and Infs.Parameters:
-
**a**array_like
Input data.

**axis**int, optional
Axis along which to operate. By default flattened input is used.

**out**array, optional
If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.

New in version 1.22.0.

**keepdims**bool, optional
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.

New in version 1.22.0.

Returns:
-
**index_array**ndarray
An array of indices or a single index value.

Examples

>>> a = np.array([[np.nan, 4], [2, 3]]) >>> np.argmin(a) 0 >>> np.nanargmin(a) 2 >>> np.nanargmin(a, axis=0) array([1, 1]) >>> np.nanargmin(a, axis=1) array([1, 0])# numpy.memmap.choose[#](#numpy-memmap-choose)
method

memmap.choose(*choices*,*out=None*,*mode='raise'*)[#](#numpy.memmap.choose)
-
Use an index array to construct a new array from a set of choices.

Refer to

for full documentation.`numpy.choose`
See also

`numpy.choose`
equivalent function

method

Use an index array to construct a new array from a set of choices.

Refer to [ numpy.choose](numpy.choose.html#numpy.choose) for full documentation.

See also

`numpy.choose`
equivalent functionndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__ilshift__

method

Return self<<=value.numpy.ma.MaskedArray.__new__# method static ma.MaskedArray.__new__(cls, data=None, mask=False, dtype=None, copy=False, subok=True, ndmin=0, fill_value=None, keep_mask=True, hard_mask=None, shrink=True, order=None)[source]# Create a new masked array from scratch. Notes A masked array can also be created by taking a .view(MaskedArray).numpy.record.argmax# method record.argmax()# Scalar method identical to the corresponding array attribute. Please see ndarray.argmax.numpy.ma.MaskedArray.__rsub__# method ma.MaskedArray.__rsub__(other)[source]# Subtract self from other, and return a new masked array.# numpy.polynomial.legendre.Legendre[#](#numpy-polynomial-legendre-legendre)
*class*numpy.polynomial.legendre.Legendre(*coef*,*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L1619-L1664)[#](#numpy.polynomial.legendre.Legendre)
-
A Legendre series class.

The Legendre class provides the standard Python numerical methods ‘+’, ‘-’, ‘*’, ‘//’, ‘%’, ‘divmod’, ‘**’, and ‘()’ as well as the attributes and methods listed in the

`ABCPolyBase`
documentation.Parameters:
-
**coef**array_like
Legendre coefficients in order of increasing degree, i.e.,

`(1, 2, 3)`
gives`1*P_0(x) + 2*P_1(x) + 3*P_2(x)`
.
**domain**(2,) array_like, optional
Domain to use. The interval

`[domain[0], domain[1]]`
is mapped to the interval`[window[0], window[1]]`
by shifting and scaling. The default value is [-1, 1].
**window**(2,) array_like, optional
Window, see

for its use. The default value is [-1, 1].`domain`
New in version 1.6.0.

**symbol**str, optional
Symbol used to represent the independent variable in string representations of the polynomial expression, e.g. for printing. The symbol must be a valid Python identifier. Default value is ‘x’.

New in version 1.24.

Attributes:
-
**symbol**
Methods

(arg)`__call__`
Call self as a function.

(deg[, domain, window, symbol])`basis`
Series basis polynomial of degree

*deg*.(series[, domain, window])`cast`
Convert series to series of this class.

([domain, kind, window])`convert`
Convert series to a different kind and/or domain and/or window.

()`copy`
Return a copy.

(deg)`cutdeg`
Truncate series to the given degree.

()`degree`
The degree of the series.

([m])`deriv`
Differentiate.

(x, y, deg[, domain, rcond, full, w, ...])`fit`
Least squares fit to data.

(roots[, domain, window, symbol])`fromroots`
Return series instance that has the specified roots.

(other)`has_samecoef`
Check if coefficients match.

(other)`has_samedomain`
Check if domains match.

(other)`has_sametype`
Check if types match.

(other)`has_samewindow`
Check if windows match.

([domain, window, symbol])`identity`
Identity function.

([m, k, lbnd])`integ`
Integrate.

([n, domain])`linspace`
Return x, y values at equally spaced points in domain.

()`mapparms`
Return the mapping parameters.

()`roots`
Return the roots of the series polynomial.

([tol])`trim`
Remove trailing coefficients

(size)`truncate`
Truncate series to length

*size*.numpy.poly1d.integ# method poly1d.integ(m=1, k=0)[source]# Return an antiderivative (indefinite integral) of this polynomial. Refer to polyint for full documentation. See also polyintequivalent function# numpy.polynomial.legendre.legline[#](#numpy-polynomial-legendre-legline)
polynomial.legendre.legline(*off*,*scl*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/legendre.py#L227-L264)[#](#numpy.polynomial.legendre.legline)
-
Legendre series whose graph is a straight line.

Parameters:
-
**off, scl**scalars
The specified line is given by

`off + scl*x`
.
Returns:
-
**y**ndarray
This module’s representation of the Legendre series for

`off + scl*x`
.
See also

Examples

>>> import numpy.polynomial.legendre as L >>> L.legline(3,2) array([3, 2]) >>> L.legval(-3, L.legline(3,2)) # should be -3 -3.0numpy.distutils.ccompiler_opt.CCompilerOpt.conf_check_path# attribute distutils.ccompiler_opt.CCompilerOpt.conf_check_path = '/home/charris/Workspace/numpy.git/build-install/usr/lib64/python3.11/site-packages/numpy/distutils/checks'## numpy.ma.MaskedArray.product[#](#numpy-ma-maskedarray-product)
method

ma.MaskedArray.product(*axis=None*,*dtype=None*,*out=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L5233-L5272)[#](#numpy.ma.MaskedArray.product)
-
Return the product of the array elements over the given axis.

Masked elements are set to 1 internally for computation.

Refer to

for full documentation.`numpy.prod`
See also

`numpy.ndarray.prod`
corresponding function for ndarrays

`numpy.prod`
equivalent function

Notes

Arithmetic is modular when using integer types, and no error is raised on overflow.numpy.polynomial.chebyshev.Chebyshev.copy# method polynomial.chebyshev.Chebyshev.copy()[source]# Return a copy. Returns: new_seriesseriesCopy of self.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__and__
numpy.ndarray.__and__
#
method
ndarray.
__and__
(
value
,
/
)
#
Return self&value.# numpy.chararray.dump[#](#numpy-chararray-dump)
method

chararray.dump(*file*)[#](#numpy.chararray.dump)
-
Dump a pickle of the array to the specified file. The array can be read back with pickle.load or numpy.load.

Parameters:
-
**file**str or Path
A string naming the dump file.

Changed in version 1.17.0:

objects are now accepted.`pathlib.Path`# numpy.ma.masked_array.all[#](#numpy-ma-masked-array-all)
method

ma.masked_array.all(*axis=None*,*out=None*,*keepdims=<no value>*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4908-L4946)[#](#numpy.ma.masked_array.all)
-
Returns True if all elements evaluate to True.

The output array is masked where all the values along the given axis are masked: if the output would have been a scalar and that all the values are masked, then the output is

*masked*.Refer to

for full documentation.`numpy.all`
See also

`numpy.ndarray.all`
corresponding function for ndarrays

`numpy.all`
equivalent function

Examples

>>> np.ma.array([1,2,3]).all() True >>> a = np.ma.array([1,2,3], mask=True) >>> (a.all() is np.ma.masked) True# numpy.matrix.choose[#](#numpy-matrix-choose)
method

matrix.choose(*choices*,*out=None*,*mode='raise'*)[#](#numpy.matrix.choose)
-
Use an index array to construct a new array from a set of choices.

Refer to

for full documentation.`numpy.choose`
See also

`numpy.choose`
equivalent function

method

Use an index array to construct a new array from a set of choices.

Refer to [ numpy.choose](numpy.choose.html#numpy.choose) for full documentation.

See also

`numpy.choose`
equivalent functionUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
random.SeedSequence.n_children_spawned
numpy.random.SeedSequence.n_children_spawned
#
attribute
random.SeedSequence.
n_children_spawned
## numpy.recarray.mean[#](#numpy-recarray-mean)
method

recarray.mean(*axis=None*,*dtype=None*,*out=None*,*keepdims=False*,***,*where=True*)[#](#numpy.recarray.mean)
-
Returns the average of the array elements along given axis.

Refer to

for full documentation.`numpy.mean`
See also

`numpy.mean`
equivalent function# numpy.ma.MaskType.conjugate[#](#numpy-ma-masktype-conjugate)
method

ma.MaskType.conjugate()[#](#numpy.ma.MaskType.conjugate)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.conjugate`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.conjugate](numpy.ndarray.conjugate.html#numpy.ndarray.conjugate).# numpy.dtype.alignment[#](#numpy-dtype-alignment)
attribute

dtype.alignment[#](#numpy.dtype.alignment)
-
The required alignment (bytes) of this data-type according to the compiler.

More information is available in the C-API section of the manual.

Examples

>>> x = np.dtype('i4') >>> x.alignment 4
>>> x = np.dtype(float) >>> x.alignment 8# numpy.ma.MaskedArray.resize[#](#numpy-ma-maskedarray-resize)
method

ma.MaskedArray.resize(*newshape*,*refcheck=True*,*order=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L4752-L4768)[#](#numpy.ma.MaskedArray.resize)
-
Warning

This method does nothing, except raise a ValueError exception. A masked array does not own its data and therefore cannot safely be resized in place. Use the

function instead.`numpy.ma.resize`
This method is difficult to implement safely and may be deprecated in future releases of NumPy.# numpy.polynomial.chebyshev.chebline[#](#numpy-polynomial-chebyshev-chebline)
polynomial.chebyshev.chebline(*off*,*scl*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L476-L511)[#](#numpy.polynomial.chebyshev.chebline)
-
Chebyshev series whose graph is a straight line.

Parameters:
-
**off, scl**scalars
The specified line is given by

`off + scl*x`
.
Returns:
-
**y**ndarray
This module’s representation of the Chebyshev series for

`off + scl*x`
.
See also

Examples

>>> import numpy.polynomial.chebyshev as C >>> C.chebline(3,2) array([3, 2]) >>> C.chebval(-3, C.chebline(3,2)) # should be -3 -3.0numpy.ma.MaskType.prod# method ma.MaskType.prod()# Scalar method identical to the corresponding array attribute. Please see ndarray.prod.numpy.distutils.ccompiler_opt.CCompilerOpt.feature_get_til# method distutils.ccompiler_opt.CCompilerOpt.feature_get_til(names, keyisfalse)[source]# same as feature_implies_c() but stop collecting implied features when feature’s option that provided through parameter ‘keyisfalse’ is False, also sorting the returned features.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
record.flat
numpy.record.flat
#
attribute
record.
flat
#
A 1-D view of the scalar.# numpy.ndarray.cumsum[#](#numpy-ndarray-cumsum)
method

ndarray.cumsum(*axis=None*,*dtype=None*,*out=None*)[#](#numpy.ndarray.cumsum)
-
Return the cumulative sum of the elements along the given axis.

Refer to

for full documentation.`numpy.cumsum`
See also

`numpy.cumsum`
equivalent function

method

Return the cumulative sum of the elements along the given axis.

Refer to [ numpy.cumsum](numpy.cumsum.html#numpy.cumsum) for full documentation.

See also

`numpy.cumsum`
equivalent function# numpy.ma.masked_values[#](#numpy-ma-masked-values)
ma.masked_values(*x*,*value*,*rtol=1e-05*,*atol=1e-08*,*copy=True*,*shrink=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2260-L2329)[#](#numpy.ma.masked_values)
-
Mask using floating point equality.

Return a MaskedArray, masked where the data in array

*x*are approximately equal to*value*, determined using. The default tolerances for`isclose`
are the same as those for`masked_values`
.`isclose`
For integer types, exact equality is used, in the same way as

.`masked_equal`
The fill_value is set to

*value*and the mask is set to`nomask`
if possible.Parameters:
-
**x**array_like
Array to mask.

**value**float
Masking value.

**rtol, atol**float, optional
Tolerance parameters passed on to

`isclose`
**copy**bool, optional
Whether to return a copy of

*x*.
**shrink**bool, optional
Whether to collapse a mask full of False to

`nomask`
.
Returns:
-
**result**MaskedArray
The result of masking

*x*where approximately equal to*value*.
See also

`masked_where`
Mask where a condition is met.

`masked_equal`
Mask where equal to a given value (integers).

Examples

>>> import numpy.ma as ma >>> x = np.array([1, 1.1, 2, 1.1, 3]) >>> ma.masked_values(x, 1.1) masked_array(data=[1.0, --, 2.0, --, 3.0], mask=[False, True, False, True, False], fill_value=1.1)
Note that

*mask*is set to`nomask`
if possible.>>> ma.masked_values(x, 2.1) masked_array(data=[1. , 1.1, 2. , 1.1, 3. ], mask=False, fill_value=2.1)
Unlike

,`masked_equal`
can perform approximate equalities.`masked_values`
>>> ma.masked_values(x, 2.1, atol=1e-1) masked_array(data=[1.0, 1.1, --, 1.1, 3.0], mask=[False, False, True, False, False], fill_value=2.1)ufunc

numpy.ctypeslib

numpy.fft

numpy.linalg

numpy.matlib

numpy.polynomial.polynomial

numpy.polynomial.chebyshev

numpy.polynomial.hermite

numpy.polynomial.hermite_e

numpy.polynomial.laguerre

numpy.polynomial.legendre

numpy.random

numpy.testing

numpy.testing.overrides

numpy.typing

numpy.distutils

poly1d.__call__

method

Call self as a function.numpy.ma.MaskedArray.take# method ma.MaskedArray.take(indices, axis=None, out=None, mode='raise')[source]## numpy.ma.MaskType.astype[#](#numpy-ma-masktype-astype)
method

ma.MaskType.astype()[#](#numpy.ma.MaskType.astype)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.astype`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.astype](numpy.ndarray.astype.html#numpy.ndarray.astype).# numpy.tril_indices_from[#](#numpy-tril-indices-from)
numpy.tril_indices_from(*arr*,*k=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/twodim_base.py#L971-L1030)[#](#numpy.tril_indices_from)
-
Return the indices for the lower-triangle of arr.

See

for full details.`tril_indices`
Parameters:
-
**arr**array_like
The indices will be valid for square arrays whose dimensions are the same as arr.

**k**int, optional
Diagonal offset (see

for details).`tril`
See also

Notes

New in version 1.4.0.

Examples

Create a 4 by 4 array.

>>> a = np.arange(16).reshape(4, 4) >>> a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]])
Pass the array to get the indices of the lower triangular elements.

>>> trili = np.tril_indices_from(a) >>> trili (array([0, 1, 1, 2, 2, 2, 3, 3, 3, 3]), array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3]))
>>> a[trili] array([ 0, 4, 5, 8, 9, 10, 12, 13, 14, 15])
This is syntactic sugar for tril_indices().

>>> np.tril_indices(a.shape[0]) (array([0, 1, 1, 2, 2, 2, 3, 3, 3, 3]), array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3]))
Use the

*k*parameter to return the indices for the lower triangular array up to the k-th diagonal.>>> trili1 = np.tril_indices_from(a, k=1) >>> a[trili1] array([ 0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15])# numpy.ma.compress_rowcols[#](#numpy-ma-compress-rowcols)
ma.compress_rowcols(*x*,*axis=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L866-L918)[#](#numpy.ma.compress_rowcols)
-
Suppress the rows and/or columns of a 2-D array that contain masked values.

The suppression behavior is selected with the

*axis*parameter.If axis is None, both rows and columns are suppressed.

If axis is 0, only rows are suppressed.

If axis is 1 or -1, only columns are suppressed.

Parameters:
-
**x**array_like, MaskedArray
The array to operate on. If not a MaskedArray instance (or if no array elements are masked),

*x*is interpreted as a MaskedArray with*mask*set to. Must be a 2D array.`nomask`
**axis**int, optional
Axis along which to perform the operation. Default is None.

Returns:
-
**compressed_array**ndarray
The compressed array.

Examples

>>> x = np.ma.array(np.arange(9).reshape(3, 3), mask=[[1, 0, 0], ... [1, 0, 0], ... [0, 0, 0]]) >>> x masked_array( data=[[--, 1, 2], [--, 4, 5], [6, 7, 8]], mask=[[ True, False, False], [ True, False, False], [False, False, False]], fill_value=999999)
>>> np.ma.compress_rowcols(x) array([[7, 8]]) >>> np.ma.compress_rowcols(x, 0) array([[6, 7, 8]]) >>> np.ma.compress_rowcols(x, 1) array([[1, 2], [4, 5], [7, 8]])numpy.random.sample# random.sample()# This is an alias of random_sample. See random_sample for the complete documentation.# numpy.ma.masked_array.choose[#](#numpy-ma-masked-array-choose)
method

ma.masked_array.choose(*choices*,*out=None*,*mode='raise'*)[#](#numpy.ma.masked_array.choose)
-
Use an index array to construct a new array from a set of choices.

Refer to

for full documentation.`numpy.choose`
See also

`numpy.choose`
equivalent functionnumpy.record.dumps# method record.dumps()# Scalar method identical to the corresponding array attribute. Please see ndarray.dumps.# numpy.ma.MaskedArray.toflex[#](#numpy-ma-maskedarray-toflex)
method

ma.MaskedArray.toflex()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L6223-L6280)[#](#numpy.ma.MaskedArray.toflex)
-
Transforms a masked array into a flexible-type array.

The flexible type array that is returned will have two fields:

the

`_data`
field stores the`_data`
part of the array.
the

`_mask`
field stores the`_mask`
part of the array.
Parameters:
-
**None**
Returns:
-
**record**ndarray
A new flexible-type

with two fields: the first element containing a value, the second element containing the corresponding mask boolean. The returned record shape matches self.shape.`ndarray`
Notes

A side-effect of transforming a masked array into a flexible

is that meta information (`ndarray`
`fill_value`
, …) will be lost.Examples

>>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.toflex() array([[(1, False), (2, True), (3, False)], [(4, True), (5, False), (6, True)], [(7, False), (8, True), (9, False)]], dtype=[('_data', '<i8'), ('_mask', '?')])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__mod__
numpy.ndarray.__mod__
#
method
ndarray.
__mod__
(
value
,
/
)
#
Return self%value.# numpy.char.str_len[#](#numpy-char-str-len)
char.str_len(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L265-L298)[#](#numpy.char.str_len)
-
Return len(a) element-wise.

Parameters:
-
**a**array_like of str or unicode
Returns:
-
**out**ndarray
Output array of integers

See also

Examples

>>> a = np.array(['Grace Hopper Conference', 'Open Source Day']) >>> np.char.str_len(a) array([23, 15]) >>> a = np.array([u'Р', u'о']) >>> np.char.str_len(a) array([1, 1]) >>> a = np.array([['hello', 'world'], [u'Р', u'о']]) >>> np.char.str_len(a) array([[5, 5], [1, 1]])numpy.testing.clear_and_catch_warnings.class_modules# attribute testing.clear_and_catch_warnings.class_modules = ()#numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names# method distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names()[source]# return a list of final CPU baseline feature namesnumpy.ma.MaskedArray.__divmod__# method ma.MaskedArray.__divmod__(value, /)# Return divmod(self, value).# numpy.char.chararray.expandtabs[#](#numpy-char-chararray-expandtabs)
method

char.chararray.expandtabs(*tabsize=8*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2329-L2339)[#](#numpy.char.chararray.expandtabs)
-
Return a copy of each string element where all tab characters are replaced by one or more spaces.

See also

method

Return a copy of each string element where all tab characters are replaced by one or more spaces.

See alsonumpy.distutils.ccompiler_opt.CCompilerOpt.cache_flush# method distutils.ccompiler_opt.CCompilerOpt.cache_flush()[source]# Force update the cache.numpy.ndarray.ptp# method ndarray.ptp(axis=None, out=None, keepdims=False)# Peak to peak (maximum - minimum) value along a given axis. Refer to numpy.ptp for full documentation. See also numpy.ptpequivalent functionnumpy.nditer.operands# attribute nditer.operands# operands[Slice] The array(s) to be iterated over. Valid only before the iterator is closed.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__ipow__
numpy.ndarray.__ipow__
#
method
ndarray.
__ipow__
(
value
,
/
)
#
Return self**=value.# numpy.random.PCG64DXSM.cffi[#](#numpy-random-pcg64dxsm-cffi)
attribute

random.PCG64DXSM.cffi[#](#numpy.random.PCG64DXSM.cffi)
-
CFFI interface

Returns:
-
**interface**namedtuple
Named tuple containing CFFI wrapper

state_address - Memory address of the state struct

state - pointer to the state struct

next_uint64 - function pointer to produce 64 bit integers

next_uint32 - function pointer to produce 32 bit integers

next_double - function pointer to produce doubles

bitgen - pointer to the bit generator structUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
poly1d.r
numpy.poly1d.r
#
property
property
poly1d.
r
#
The roots of the polynomial, where self(x) == 0# numpy.chararray.capitalize[#](#numpy-chararray-capitalize)
method

chararray.capitalize()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2260-L2270)[#](#numpy.chararray.capitalize)
-
Return a copy of

*self*with only the first character of each element capitalized.See also

method

Return a copy of *self* with only the first character of each element
capitalized.

See alsonumpy.chararray.data# attribute chararray.data# Python buffer object pointing to the start of the array’s data.# numpy.random.Generator.permutation[#](#numpy-random-generator-permutation)
method

random.Generator.permutation(*x*,*axis=0*)[#](#numpy.random.Generator.permutation)
-
Randomly permute a sequence, or return a permuted range.

Parameters:
-
**x**int or array_like
If

*x*is an integer, randomly permute`np.arange(x)`
. If*x*is an array, make a copy and shuffle the elements randomly.
**axis**int, optional
The axis which

*x*is shuffled along. Default is 0.
Returns:
-
**out**ndarray
Permuted sequence or array range.

Examples

>>> rng = np.random.default_rng() >>> rng.permutation(10) array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random
>>> rng.permutation([1, 4, 9, 12, 15]) array([15, 1, 9, 4, 12]) # random
>>> arr = np.arange(9).reshape((3, 3)) >>> rng.permutation(arr) array([[6, 7, 8], # random [0, 1, 2], [3, 4, 5]])
>>> rng.permutation("abc") Traceback (most recent call last): ... numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0
>>> arr = np.arange(9).reshape((3, 3)) >>> rng.permutation(arr, axis=1) array([[0, 2, 1], # random [3, 5, 4], [6, 8, 7]])# numpy.ufunc.identity[#](#numpy-ufunc-identity)
attribute

ufunc.identity[#](#numpy.ufunc.identity)
-
The identity value.

Data attribute containing the identity element for the ufunc, if it has one. If it does not, the attribute value is None.

Examples

>>> np.add.identity 0 >>> np.multiply.identity 1 >>> np.power.identity 1 >>> print(np.exp.identity) None# numpy.ma.MaskType.searchsorted[#](#numpy-ma-masktype-searchsorted)
method

ma.MaskType.searchsorted()[#](#numpy.ma.MaskType.searchsorted)
-
Scalar method identical to the corresponding array attribute.

Please see

.`ndarray.searchsorted`
method

Scalar method identical to the corresponding array attribute.

Please see [ ndarray.searchsorted](numpy.ndarray.searchsorted.html#numpy.ndarray.searchsorted).# numpy.char.isupper[#](#numpy-char-isupper)
char.isupper(*a*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L986-L1020)[#](#numpy.char.isupper)
-
Return true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise.

Call

*str.isupper*element-wise.For 8-bit strings, this method is locale-dependent.

Parameters:
-
**a**array_like of str or unicode
Returns:
-
**out**ndarray
Output array of bools

See also

Examples

>>> str = "GHC" >>> np.char.isupper(str) array(True) >>> a = np.array(["hello", "HELLO", "Hello"]) >>> np.char.isupper(a) array([False, True, False])numpy.ma.MaskedArray.__idiv__# method ma.MaskedArray.__idiv__(other)[source]# Divide self by other in-place.# numpy.triu[#](#numpy-triu)
numpy.triu(*m*,*k=0*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/twodim_base.py#L485-L526)[#](#numpy.triu)
-
Upper triangle of an array.

Return a copy of an array with the elements below the

*k*-th diagonal zeroed. For arrays with`ndim`
exceeding 2,will apply to the final two axes.`triu`
Please refer to the documentation for

for further details.`tril`
See also

`tril`
lower triangle of an array

Examples

>>> np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1) array([[ 1, 2, 3], [ 4, 5, 6], [ 0, 8, 9], [ 0, 0, 12]])
>>> np.triu(np.arange(3*4*5).reshape(3, 4, 5)) array([[[ 0, 1, 2, 3, 4], [ 0, 6, 7, 8, 9], [ 0, 0, 12, 13, 14], [ 0, 0, 0, 18, 19]], [[20, 21, 22, 23, 24], [ 0, 26, 27, 28, 29], [ 0, 0, 32, 33, 34], [ 0, 0, 0, 38, 39]], [[40, 41, 42, 43, 44], [ 0, 46, 47, 48, 49], [ 0, 0, 52, 53, 54], [ 0, 0, 0, 58, 59]]])# numpy.ma.masked_object[#](#numpy-ma-masked-object)
ma.masked_object(*x*,*value*,*copy=True*,*shrink=True*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/core.py#L2192-L2257)[#](#numpy.ma.masked_object)
-
Mask the array

*x*where the data are exactly equal to value.This function is similar to

, but only suitable for object arrays: for floating point, use`masked_values`
instead.`masked_values`
Parameters:
-
**x**array_like
Array to mask

**value**object
Comparison value

**copy**{True, False}, optional
Whether to return a copy of

*x*.
**shrink**{True, False}, optional
Whether to collapse a mask full of False to nomask

Returns:
-
**result**MaskedArray
The result of masking

*x*where equal to*value*.
See also

`masked_where`
Mask where a condition is met.

`masked_equal`
Mask where equal to a given value (integers).

`masked_values`
Mask using floating point equality.

Examples

>>> import numpy.ma as ma >>> food = np.array(['green_eggs', 'ham'], dtype=object) >>> # don't eat spoiled food >>> eat = ma.masked_object(food, 'green_eggs') >>> eat masked_array(data=[--, 'ham'], mask=[ True, False], fill_value='green_eggs', dtype=object) >>> # plain ol` ham is boring >>> fresh_food = np.array(['cheese', 'ham', 'pineapple'], dtype=object) >>> eat = ma.masked_object(fresh_food, 'green_eggs') >>> eat masked_array(data=['cheese', 'ham', 'pineapple'], mask=False, fill_value='green_eggs', dtype=object)
Note that

*mask*is set to`nomask`
if possible.>>> eat masked_array(data=['cheese', 'ham', 'pineapple'], mask=False, fill_value='green_eggs', dtype=object)numpy.record.min# method record.min()# Scalar method identical to the corresponding array attribute. Please see ndarray.min.numpy.recarray.std# method recarray.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)# Returns the standard deviation of the array elements along given axis. Refer to numpy.std for full documentation. See also numpy.stdequivalent function# numpy.ndarray.clip[#](#numpy-ndarray-clip)
method

ndarray.clip(*min=None*,*max=None*,*out=None*,***kwargs*)[#](#numpy.ndarray.clip)
-
Return an array whose values are limited to

`[min, max]`
. One of max or min must be given.Refer to

for full documentation.`numpy.clip`
See also

`numpy.clip`
equivalent function# numpy.recarray.fill[#](#numpy-recarray-fill)
method

recarray.fill(*value*)[#](#numpy.recarray.fill)
-
Fill the array with a scalar value.

Parameters:
-
**value**scalar
All elements of

*a*will be assigned this value.
Examples

>>> a = np.array([1, 2]) >>> a.fill(0) >>> a array([0, 0]) >>> a = np.empty(2) >>> a.fill(1) >>> a array([1., 1.])
Fill expects a scalar value and always behaves the same as assigning to a single array element. The following is a rare example where this distinction is important:

>>> a = np.array([None, None], dtype=object) >>> a[0] = np.array(3) >>> a array([array(3), None], dtype=object) >>> a.fill(np.array(3)) >>> a array([array(3), array(3)], dtype=object)
Where other forms of assignments will unpack the array being assigned:

>>> a[...] = np.array(3) >>> a array([3, 3], dtype=object)# numpy.random.Philox.cffi[#](#numpy-random-philox-cffi)
attribute

random.Philox.cffi[#](#numpy.random.Philox.cffi)
-
CFFI interface

Returns:
-
**interface**namedtuple
Named tuple containing CFFI wrapper

state_address - Memory address of the state struct

state - pointer to the state struct

next_uint64 - function pointer to produce 64 bit integers

next_uint32 - function pointer to produce 32 bit integers

next_double - function pointer to produce doubles

bitgen - pointer to the bit generator struct# numpy.chararray.lstrip[#](#numpy-chararray-lstrip)
method

chararray.lstrip(*chars=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L2489-L2499)[#](#numpy.chararray.lstrip)
-
For each element in

*self*, return a copy with the leading characters removed.See also

method

For each element in *self*, return a copy with the leading characters
removed.

See also# numpy.random.standard_exponential[#](#numpy-random-standard-exponential)
random.standard_exponential(*size=None*)[#](#numpy.random.standard_exponential)
-
Draw samples from the standard exponential distribution.

is identical to the exponential distribution with a scale parameter of 1.`standard_exponential`
Note

New code should use the

method of a`standard_exponential`
instance instead; please see the`Generator`
[Quick Start](../index.html#random-quick-start).Parameters:
-
**size**int or tuple of ints, optional
Output shape. If the given shape is, e.g.,

`(m, n, k)`
, then`m * n * k`
samples are drawn. Default is None, in which case a single value is returned.
Returns:
-
**out**float or ndarray
Drawn samples.

See also

`random.Generator.standard_exponential`
which should be used for new code.

Examples

Output a 3x8000 array:

>>> n = np.random.standard_exponential((3, 8000))numpy.ndarray.var# method ndarray.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)# Returns the variance of the array elements, along given axis. Refer to numpy.var for full documentation. See also numpy.varequivalent function# numpy.polynomial.laguerre.Laguerre.basis[#](#numpy-polynomial-laguerre-laguerre-basis)
method

*classmethod*polynomial.laguerre.Laguerre.basis(*deg*,*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L1125-L1164)[#](#numpy.polynomial.laguerre.Laguerre.basis)
-
Series basis polynomial of degree

*deg*.Returns the series representing the basis polynomial of degree

*deg*.New in version 1.7.0.

Parameters:
-
**deg**int
Degree of the basis polynomial for the series. Must be >= 0.

**domain**{None, array_like}, optional
If given, the array must be of the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the domain. If None is given then the class domain is used. The default is None.
**window**{None, array_like}, optional
If given, the resulting array must be if the form

`[beg, end]`
, where`beg`
and`end`
are the endpoints of the window. If None is given then the class window is used. The default is None.
**symbol**str, optional
Symbol representing the independent variable. Default is ‘x’.

Returns:
-
**new_series**series
A series with the coefficient of the

*deg*term set to one and all others zero.# numpy.matrix.T[#](#numpy-matrix-t)
property

*property*matrix.T[#](#numpy.matrix.T)
-
Returns the transpose of the matrix.

Does

*not*conjugate! For the complex conjugate transpose, use`.H`
.Parameters:
-
**None**
Returns:
-
**ret**matrix object
The (non-conjugated) transpose of the matrix.

Examples

>>> m = np.matrix('[1, 2; 3, 4]') >>> m matrix([[1, 2], [3, 4]]) >>> m.getT() matrix([[1, 3], [2, 4]])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
record.itemsize
numpy.record.itemsize
#
attribute
record.
itemsize
#
The length of one element in bytes.# numpy.distutils.ccompiler.CCompiler_spawn[#](#numpy-distutils-ccompiler-ccompiler-spawn)
distutils.ccompiler.CCompiler_spawn(*self*,*cmd*,*display=None*,*env=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/ccompiler.py#L114-L183)[#](#numpy.distutils.ccompiler.CCompiler_spawn)
-
Execute a command in a sub-process.

Parameters:
-
**cmd**str
The command to execute.

**display**str or sequence of str, optional
The text to add to the log file kept by

. If not given,`numpy.distutils`
*display*is equal to.`cmd`
**env**a dictionary for environment variables, optional
Returns:
-
None
-
Raises:
-
DistutilsExecError
-
If the command failed, i.e. the exit status was not 0.# numpy.polynomial.polynomial.Polynomial[#](#numpy-polynomial-polynomial-polynomial)
*class*numpy.polynomial.polynomial.Polynomial(*coef*,*domain=None*,*window=None*,*symbol='x'*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L1472-L1542)[#](#numpy.polynomial.polynomial.Polynomial)
-
A power series class.

The Polynomial class provides the standard Python numerical methods ‘+’, ‘-’, ‘*’, ‘//’, ‘%’, ‘divmod’, ‘**’, and ‘()’ as well as the attributes and methods listed in the

`ABCPolyBase`
documentation.Parameters:
-
**coef**array_like
Polynomial coefficients in order of increasing degree, i.e.,

`(1, 2, 3)`
give`1 + 2*x + 3*x**2`
.
**domain**(2,) array_like, optional
Domain to use. The interval

`[domain[0], domain[1]]`
is mapped to the interval`[window[0], window[1]]`
by shifting and scaling. The default value is [-1, 1].
**window**(2,) array_like, optional
Window, see

for its use. The default value is [-1, 1].`domain`
New in version 1.6.0.

**symbol**str, optional
Symbol used to represent the independent variable in string representations of the polynomial expression, e.g. for printing. The symbol must be a valid Python identifier. Default value is ‘x’.

New in version 1.24.

Attributes:
-
**basis_name**
**symbol**
Methods

(arg)`__call__`
Call self as a function.

(deg[, domain, window, symbol])`basis`
Series basis polynomial of degree

*deg*.(series[, domain, window])`cast`
Convert series to series of this class.

([domain, kind, window])`convert`
Convert series to a different kind and/or domain and/or window.

()`copy`
Return a copy.

(deg)`cutdeg`
Truncate series to the given degree.

()`degree`
The degree of the series.

([m])`deriv`
Differentiate.

(x, y, deg[, domain, rcond, full, w, ...])`fit`
Least squares fit to data.

(roots[, domain, window, symbol])`fromroots`
Return series instance that has the specified roots.

(other)`has_samecoef`
Check if coefficients match.

(other)`has_samedomain`
Check if domains match.

(other)`has_sametype`
Check if types match.

(other)`has_samewindow`
Check if windows match.

([domain, window, symbol])`identity`
Identity function.

([m, k, lbnd])`integ`
Integrate.

([n, domain])`linspace`
Return x, y values at equally spaced points in domain.

()`mapparms`
Return the mapping parameters.

()`roots`
Return the roots of the series polynomial.

([tol])`trim`
Remove trailing coefficients

(size)`truncate`
Truncate series to length

*size*.# numpy.random.PCG64DXSM.jumped[#](#numpy-random-pcg64dxsm-jumped)
method

random.PCG64DXSM.jumped(*jumps=1*)[#](#numpy.random.PCG64DXSM.jumped)
-
Returns a new bit generator with the state jumped.

Jumps the state as-if jumps * 210306068529402873165736369884012333109 random numbers have been generated.

Parameters:
-
**jumps**integer, positive
Number of times to jump the state of the bit generator returned

Returns:
-
**bit_generator**PCG64DXSM
New instance of generator jumped iter times

Notes

The step size is phi-1 when multiplied by 2**128 where phi is the golden ratio.# numpy.ma.masked_array.conjugate[#](#numpy-ma-masked-array-conjugate)
method

ma.masked_array.conjugate()[#](#numpy.ma.masked_array.conjugate)
-
Return the complex conjugate, element-wise.

Refer to

for full documentation.`numpy.conjugate`
See also

`numpy.conjugate`
equivalent function

method

Return the complex conjugate, element-wise.

Refer to [ numpy.conjugate](numpy.conjugate.html#numpy.conjugate) for full documentation.

See also

`numpy.conjugate`
equivalent function# numpy.lib.format.write_array[#](#numpy-lib-format-write-array)
lib.format.write_array(*fp*,*array*,*version=None*,*allow_pickle=True*,*pickle_kwargs=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/format.py#L666-L735)[#](#numpy.lib.format.write_array)
-
Write an array to an NPY file, including a header.

If the array is neither C-contiguous nor Fortran-contiguous AND the file_like object is not a real file object, this function will have to copy data in memory.

Parameters:
-
**fp**file_like object
An open, writable file object, or similar object with a

`.write()`
method.
**array**ndarray
The array to write to disk.

**version**(int, int) or None, optional
The version number of the format. None means use the oldest supported version that is able to store the data. Default: None

**allow_pickle**bool, optional
Whether to allow writing pickled data. Default: True

**pickle_kwargs**dict, optional
Additional keyword arguments to pass to pickle.dump, excluding ‘protocol’. These are only useful when pickling objects in object arrays on Python 3 to Python 2 compatible format.

Raises:
-
ValueError
-
If the array cannot be persisted. This includes the case of allow_pickle=False and array being an object array.

Various other errors
-
If the array contains Python objects as part of its dtype, the process of pickling them may raise various errors if the objects are not picklable.# numpy.distutils.ccompiler_opt.CCompilerOpt.conf_features[#](#numpy-distutils-ccompiler-opt-ccompileropt-conf-features)
attribute

distutils.ccompiler_opt.CCompilerOpt.conf_features*= {'ASIMD': {'implies': 'NEON_FP16 NEON_VFPV4', 'implies_detect': False, 'interest': 4}, 'ASIMDDP': {'implies': 'ASIMD', 'interest': 6}, 'ASIMDFHM': {'implies': 'ASIMDHP', 'interest': 7}, 'ASIMDHP': {'implies': 'ASIMD', 'interest': 5}, 'AVX': {'headers': 'immintrin.h', 'implies': 'SSE42', 'implies_detect': False, 'interest': 8}, 'AVX2': {'implies': 'F16C', 'interest': 13}, 'AVX512CD': {'implies': 'AVX512F', 'interest': 21}, 'AVX512F': {'extra_checks': 'AVX512F_REDUCE', 'implies': 'FMA3 AVX2', 'implies_detect': False, 'interest': 20}, 'AVX512_CLX': {'detect': 'AVX512_CLX', 'group': 'AVX512VNNI', 'implies': 'AVX512_SKX', 'interest': 43}, 'AVX512_CNL': {'detect': 'AVX512_CNL', 'group': 'AVX512IFMA AVX512VBMI', 'implies': 'AVX512_SKX', 'implies_detect': False, 'interest': 44}, 'AVX512_ICL': {'detect': 'AVX512_ICL', 'group': 'AVX512VBMI2 AVX512BITALG AVX512VPOPCNTDQ', 'implies': 'AVX512_CLX AVX512_CNL', 'implies_detect': False, 'interest': 45}, 'AVX512_KNL': {'detect': 'AVX512_KNL', 'group': 'AVX512ER AVX512PF', 'implies': 'AVX512CD', 'implies_detect': False, 'interest': 40}, 'AVX512_KNM': {'detect': 'AVX512_KNM', 'group': 'AVX5124FMAPS AVX5124VNNIW AVX512VPOPCNTDQ', 'implies': 'AVX512_KNL', 'implies_detect': False, 'interest': 41}, 'AVX512_SKX': {'detect': 'AVX512_SKX', 'extra_checks': 'AVX512BW_MASK AVX512DQ_MASK', 'group': 'AVX512VL AVX512BW AVX512DQ', 'implies': 'AVX512CD', 'implies_detect': False, 'interest': 42}, 'AVX512_SPR': {'detect': 'AVX512_SPR', 'group': 'AVX512FP16', 'implies': 'AVX512_ICL', 'implies_detect': False, 'interest': 46}, 'F16C': {'implies': 'AVX', 'interest': 11}, 'FMA3': {'implies': 'F16C', 'interest': 12}, 'FMA4': {'headers': 'x86intrin.h', 'implies': 'AVX', 'interest': 10}, 'NEON': {'headers': 'arm_neon.h', 'interest': 1}, 'NEON_FP16': {'implies': 'NEON', 'interest': 2}, 'NEON_VFPV4': {'implies': 'NEON_FP16', 'interest': 3}, 'POPCNT': {'headers': 'popcntintrin.h', 'implies': 'SSE41', 'interest': 6}, 'SSE': {'headers': 'xmmintrin.h', 'implies': 'SSE2', 'interest': 1}, 'SSE2': {'headers': 'emmintrin.h', 'implies': 'SSE', 'interest': 2}, 'SSE3': {'headers': 'pmmintrin.h', 'implies': 'SSE2', 'interest': 3}, 'SSE41': {'headers': 'smmintrin.h', 'implies': 'SSSE3', 'interest': 5}, 'SSE42': {'implies': 'POPCNT', 'interest': 7}, 'SSSE3': {'headers': 'tmmintrin.h', 'implies': 'SSE3', 'interest': 4}, 'VSX': {'extra_checks': 'VSX_ASM', 'headers': 'altivec.h', 'interest': 1}, 'VSX2': {'implies': 'VSX', 'implies_detect': False, 'interest': 2}, 'VSX3': {'implies': 'VSX2', 'implies_detect': False, 'interest': 3}, 'VSX4': {'extra_checks': 'VSX4_MMA', 'implies': 'VSX3', 'implies_detect': False, 'interest': 4}, 'VX': {'headers': 'vecintrin.h', 'interest': 1}, 'VXE': {'implies': 'VX', 'implies_detect': False, 'interest': 2}, 'VXE2': {'implies': 'VXE', 'implies_detect': False, 'interest': 3}, 'XOP': {'headers': 'x86intrin.h', 'implies': 'AVX', 'interest': 9}}*[#](#numpy.distutils.ccompiler_opt.CCompilerOpt.conf_features)
-# numpy.recarray.argsort[#](#numpy-recarray-argsort)
method

recarray.argsort(*axis=-1*,*kind=None*,*order=None*)[#](#numpy.recarray.argsort)
-
Returns the indices that would sort this array.

Refer to

for full documentation.`numpy.argsort`
See also

`numpy.argsort`
equivalent function

method

Returns the indices that would sort this array.

Refer to [ numpy.argsort](numpy.argsort.html#numpy.argsort) for full documentation.

See also

`numpy.argsort`
equivalent function# numpy.char.center[#](#numpy-char-center)
char.center(*a*,*width*,*fillchar=' '*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L465-L515)[#](#numpy.char.center)
-
Return a copy of

*a*with its elements centered in a string of length*width*.Calls

*str.center*element-wise.Parameters:
-
**a**array_like of str or unicode
**width**int
The length of the resulting strings

**fillchar**str or unicode, optional
The padding character to use (default is space).

Returns:
-
**out**ndarray
Output array of str or unicode, depending on input types

See also

Notes

This function is intended to work with arrays of strings. The fill character is not applied to numeric types.

Examples

>>> c = np.array(['a1b2','1b2a','b2a1','2a1b']); c array(['a1b2', '1b2a', 'b2a1', '2a1b'], dtype='<U4') >>> np.char.center(c, width=9) array([' a1b2 ', ' 1b2a ', ' b2a1 ', ' 2a1b '], dtype='<U9') >>> np.char.center(c, width=9, fillchar='*') array(['***a1b2**', '***1b2a**', '***b2a1**', '***2a1b**'], dtype='<U9') >>> np.char.center(c, width=1) array(['a', '1', 'b', '2'], dtype='<U1')# numpy.matrix.prod[#](#numpy-matrix-prod)
method

matrix.prod(*axis=None*,*dtype=None*,*out=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/matrixlib/defmatrix.py#L516-L547)[#](#numpy.matrix.prod)
-
Return the product of the array elements over the given axis.

Refer to

for full documentation.`prod`
See also

Notes

Same as

, except, where that returns an`ndarray.prod`
, this returns a`ndarray`
object instead.`matrix`
Examples

>>> x = np.matrix(np.arange(12).reshape((3,4))); x matrix([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) >>> x.prod() 0 >>> x.prod(0) matrix([[ 0, 45, 120, 231]]) >>> x.prod(1) matrix([[ 0], [ 840], [7920]])# numpy.DataSource.open[#](#numpy-datasource-open)
method

DataSource.open(*path*,*mode='r'*,*encoding=None*,*newline=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/_datasource.py#L487-L533)[#](#numpy.DataSource.open)
-
Open and return file-like object.

If

`path`
is an URL, it will be downloaded, stored in thedirectory and opened from there.`DataSource`
Parameters:
-
**path**str
Local file path or URL to open.

**mode**{‘r’, ‘w’, ‘a’}, optional
Mode to open

`path`
. Mode ‘r’ for reading, ‘w’ for writing, ‘a’ to append. Available modes depend on the type of object specified by`path`
. Default is ‘r’.
**encoding**{None, str}, optional
Open text file with given encoding. The default encoding will be what

uses.`io.open`
**newline**{None, str}, optional
Newline to use when reading text file.

Returns:
-
**out**file object
File object.numpy.chararray.std# method chararray.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)# Returns the standard deviation of the array elements along given axis. Refer to numpy.std for full documentation. See also numpy.stdequivalent functionnumpy.record.squeeze# method record.squeeze()# Scalar method identical to the corresponding array attribute. Please see ndarray.squeeze.numpy.polynomial.chebyshev.Chebyshev.__call__# method polynomial.chebyshev.Chebyshev.__call__(arg)[source]# Call self as a function.# numpy.matrix.conj[#](#numpy-matrix-conj)
method

matrix.conj()[#](#numpy.matrix.conj)
-
Complex-conjugate all elements.

Refer to

for full documentation.`numpy.conjugate`
See also

`numpy.conjugate`
equivalent function

method

Complex-conjugate all elements.

Refer to [ numpy.conjugate](numpy.conjugate.html#numpy.conjugate) for full documentation.

See also

`numpy.conjugate`
equivalent function# numpy.random.Generator.bytes[#](#numpy-random-generator-bytes)
method

random.Generator.bytes(*length*)[#](#numpy.random.Generator.bytes)
-
Return random bytes.

Parameters:
-
**length**int
Number of random bytes.

Returns:
-
**out**bytes
String of length

*length*.
Examples

>>> np.random.default_rng().bytes(10) b'\xfeC\x9b\x86\x17\xf2\xa1\xafcp' # randomnumpy.distutils.ccompiler_opt.CCompilerOpt.feature_flags# method distutils.ccompiler_opt.CCompilerOpt.feature_flags(*args, **kwargs)[source]## numpy.ma.setdiff1d[#](#numpy-ma-setdiff1d)
ma.setdiff1d(*ar1*,*ar2*,*assume_unique=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/ma/extras.py#L1368-L1393)[#](#numpy.ma.setdiff1d)
-
Set difference of 1D arrays with unique elements.

The output is always a masked array. See

for more details.`numpy.setdiff1d`
See also

`numpy.setdiff1d`
Equivalent function for ndarrays.

Examples

>>> x = np.ma.array([1, 2, 3, 4], mask=[0, 1, 0, 1]) >>> np.ma.setdiff1d(x, [1, 2]) masked_array(data=[3, --], mask=[False, True], fill_value=999999)# numpy.polynomial.chebyshev.chebpts2[#](#numpy-polynomial-chebyshev-chebpts2)
polynomial.chebyshev.chebpts2(*npts*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L1957-L1988)[#](#numpy.polynomial.chebyshev.chebpts2)
-
Chebyshev points of the second kind.

The Chebyshev points of the second kind are the points

`cos(x)`
, where`x = [pi*k/(npts - 1) for k in range(npts)]`
sorted in ascending order.Parameters:
-
**npts**int
Number of sample points desired.

Returns:
-
**pts**ndarray
The Chebyshev points of the second kind.

Notes

New in version 1.5.0.# numpy.polynomial.chebyshev.chebweight[#](#numpy-polynomial-chebyshev-chebweight)
polynomial.chebyshev.chebweight(*x*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/chebyshev.py#L1892-L1917)[#](#numpy.polynomial.chebyshev.chebweight)
-
The weight function of the Chebyshev polynomials.

The weight function is \(1/\sqrt{1 - x^2}\) and the interval of integration is \([-1, 1]\). The Chebyshev polynomials are orthogonal, but not normalized, with respect to this weight function.

Parameters:
-
**x**array_like
Values at which the weight function will be computed.

Returns:
-
**w**ndarray
The weight function at

*x*.
Notes

New in version 1.7.0.# numpy.core.records.fromarrays[#](#numpy-core-records-fromarrays)
core.records.fromarrays(*arrayList*,*dtype=None*,*shape=None*,*formats=None*,*names=None*,*titles=None*,*aligned=False*,*byteorder=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/records.py#L588-L680)[#](#numpy.core.records.fromarrays)
-
Create a record array from a (flat) list of arrays

Parameters:
-
**arrayList**list or tuple
List of array-like objects (such as lists, tuples, and ndarrays).

**dtype**data-type, optional
valid dtype for all arrays

**shape**int or tuple of ints, optional
Shape of the resulting array. If not provided, inferred from

`arrayList[0]`
.
**formats, names, titles, aligned, byteorder**
If

is`dtype`
`None`
, these arguments are passed toto construct a dtype. See that function for detailed documentation.`numpy.format_parser`
Returns:
-
np.recarray
-
Record array consisting of given arrayList columns.

Examples

>>> x1=np.array([1,2,3,4]) >>> x2=np.array(['a','dd','xyz','12']) >>> x3=np.array([1.1,2,3,4]) >>> r = np.core.records.fromarrays([x1,x2,x3],names='a,b,c') >>> print(r[1]) (2, 'dd', 2.0) # may vary >>> x1[1]=34 >>> r.a array([1, 2, 3, 4])
>>> x1 = np.array([1, 2, 3, 4]) >>> x2 = np.array(['a', 'dd', 'xyz', '12']) >>> x3 = np.array([1.1, 2, 3,4]) >>> r = np.core.records.fromarrays( ... [x1, x2, x3], ... dtype=np.dtype([('a', np.int32), ('b', 'S3'), ('c', np.float32)])) >>> r rec.array([(1, b'a', 1.1), (2, b'dd', 2. ), (3, b'xyz', 3. ), (4, b'12', 4. )], dtype=[('a', '<i4'), ('b', 'S3'), ('c', '<f4')])numpy.char.chararray.all# method char.chararray.all(axis=None, out=None, keepdims=False, *, where=True)# Returns True if all elements evaluate to True. Refer to numpy.all for full documentation. See also numpy.allequivalent function# numpy.polynomial.polynomial.polysub[#](#numpy-polynomial-polynomial-polysub)
polynomial.polynomial.polysub(*c1*,*c2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/polynomial.py#L251-L285)[#](#numpy.polynomial.polynomial.polysub)
-
Subtract one polynomial from another.

Returns the difference of two polynomials

*c1*-*c2*. The arguments are sequences of coefficients from lowest order term to highest, i.e., [1,2,3] represents the polynomial`1 + 2*x + 3*x**2`
.Parameters:
-
**c1, c2**array_like
1-D arrays of polynomial coefficients ordered from low to high.

Returns:
-
**out**ndarray
Of coefficients representing their difference.

Examples

>>> from numpy.polynomial import polynomial as P >>> c1 = (1,2,3) >>> c2 = (3,2,1) >>> P.polysub(c1,c2) array([-2., 0., 2.]) >>> P.polysub(c2,c1) # -P.polysub(c1,c2) array([ 2., 0., -2.])# numpy.distutils.ccompiler_opt.CCompilerOpt.feature_sorted[#](#numpy-distutils-ccompiler-opt-ccompileropt-feature-sorted)
method

distutils.ccompiler_opt.CCompilerOpt.feature_sorted(*names*,*reverse=False*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/distutils/ccompiler_opt.py#L1321-L1345)[#](#numpy.distutils.ccompiler_opt.CCompilerOpt.feature_sorted)
-
Sort a list of CPU features ordered by the lowest interest.

Parameters:
-
**‘names’: sequence**
sequence of supported feature names in uppercase.

**‘reverse’: bool, optional**
If true, the sorted features is reversed. (highest interest)

Returns:
-
list, sorted CPU features
-# numpy.polynomial.polynomial.Polynomial.degree[#](#numpy-polynomial-polynomial-polynomial-degree)
method

polynomial.polynomial.Polynomial.degree()[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/polynomial/_polybase.py#L675-L708)[#](#numpy.polynomial.polynomial.Polynomial.degree)
-
The degree of the series.

New in version 1.5.0.

Returns:
-
**degree**int
Degree of the series, one less than the number of coefficients.

Examples

Create a polynomial object for

`1 + 7*x + 4*x**2`
:>>> poly = np.polynomial.Polynomial([1, 7, 4]) >>> print(poly) 1.0 + 7.0·x + 4.0·x² >>> poly.degree() 2
Note that this method does not check for non-zero coefficients. You must trim the polynomial to remove any trailing zeroes:

>>> poly = np.polynomial.Polynomial([1, 7, 0]) >>> print(poly) 1.0 + 7.0·x + 0.0·x² >>> poly.degree() 2 >>> poly.trim().degree() 1# numpy.interp[#](#numpy-interp)
numpy.interp(*x*,*xp*,*fp*,*left=None*,*right=None*,*period=None*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/lib/function_base.py#L1461-L1599)[#](#numpy.interp)
-
One-dimensional linear interpolation for monotonically increasing sample points.

Returns the one-dimensional piecewise linear interpolant to a function with given discrete data points (

*xp*,*fp*), evaluated at*x*.Parameters:
-
**x**array_like
The x-coordinates at which to evaluate the interpolated values.

**xp**1-D sequence of floats
The x-coordinates of the data points, must be increasing if argument

*period*is not specified. Otherwise,*xp*is internally sorted after normalizing the periodic boundaries with`xp = xp % period`
.
**fp**1-D sequence of float or complex
The y-coordinates of the data points, same length as

*xp*.
**left**optional float or complex corresponding to fp
Value to return for

*x < xp[0]*, default is*fp[0]*.
**right**optional float or complex corresponding to fp
Value to return for

*x > xp[-1]*, default is*fp[-1]*.
**period**None or float, optional
A period for the x-coordinates. This parameter allows the proper interpolation of angular x-coordinates. Parameters

*left*and*right*are ignored if*period*is specified.New in version 1.10.0.

Returns:
-
**y**float or complex (corresponding to fp) or ndarray
The interpolated values, same shape as

*x*.
Raises:
-
ValueError
-
If

*xp*and*fp*have different length If*xp*or*fp*are not 1-D sequences If*period == 0*
Warning

The x-coordinate sequence is expected to be increasing, but this is not explicitly enforced. However, if the sequence

*xp*is non-increasing, interpolation results are meaningless.Note that, since NaN is unsortable,

*xp*also cannot contain NaNs.A simple check for

*xp*being strictly increasing is:np.all(np.diff(xp) > 0)
See also

Examples

>>> xp = [1, 2, 3] >>> fp = [3, 2, 0] >>> np.interp(2.5, xp, fp) 1.0 >>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp) array([3. , 3. , 2.5 , 0.56, 0. ]) >>> UNDEF = -99.0 >>> np.interp(3.14, xp, fp, right=UNDEF) -99.0
Plot an interpolant to the sine function:

>>> x = np.linspace(0, 2*np.pi, 10) >>> y = np.sin(x) >>> xvals = np.linspace(0, 2*np.pi, 50) >>> yinterp = np.interp(xvals, x, y) >>> import matplotlib.pyplot as plt >>> plt.plot(x, y, 'o') [<matplotlib.lines.Line2D object at 0x...>] >>> plt.plot(xvals, yinterp, '-x') [<matplotlib.lines.Line2D object at 0x...>] >>> plt.show()
Interpolation with periodic x-coordinates:

>>> x = [-180, -170, -185, 185, -10, -5, 0, 365] >>> xp = [190, -190, 350, -350] >>> fp = [5, 10, 3, 4] >>> np.interp(x, xp, fp, period=360) array([7.5 , 5. , 8.75, 6.25, 3. , 3.25, 3.5 , 3.75])
Complex interpolation:

>>> x = [1.5, 4.0] >>> xp = [2,3,5] >>> fp = [1.0j, 0, 2+3j] >>> np.interp(x, xp, fp) array([0.+1.j , 1.+1.5j])User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
poly1d.variable
numpy.poly1d.variable
#
property
property
poly1d.
variable
#
The name of the polynomial variable# numpy.chararray.nonzero[#](#numpy-chararray-nonzero)
method

chararray.nonzero()[#](#numpy.chararray.nonzero)
-
Return the indices of the elements that are non-zero.

Refer to

for full documentation.`numpy.nonzero`
See also

`numpy.nonzero`
equivalent function

method

Return the indices of the elements that are non-zero.

Refer to [ numpy.nonzero](numpy.nonzero.html#numpy.nonzero) for full documentation.

See also

`numpy.nonzero`
equivalent functionUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__or__
numpy.ndarray.__or__
#
method
ndarray.
__or__
(
value
,
/
)
#
Return self|value.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
random.SeedSequence.pool_size
numpy.random.SeedSequence.pool_size
#
attribute
random.SeedSequence.
pool_size
## numpy.broadcast.reset[#](#numpy-broadcast-reset)
method

broadcast.reset()[#](#numpy.broadcast.reset)
-
Reset the broadcasted result’s iterator(s).

Parameters:
-
**None**
Returns:
-
None
-
Examples

>>> x = np.array([1, 2, 3]) >>> y = np.array([[4], [5], [6]]) >>> b = np.broadcast(x, y) >>> b.index 0 >>> next(b), next(b), next(b) ((1, 4), (2, 4), (3, 4)) >>> b.index 3 >>> b.reset() >>> b.index 0ndarray

dtype

numpy.ma

ufunc

numpy.typing

numpy.distutils

ma.MaskedArray.__ge__

method

Return self>=value.# numpy.char.greater_equal[#](#numpy-char-greater-equal)
char.greater_equal(*x1*,*x2*)[[source]](https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/defchararray.py#L156-L180)[#](#numpy.char.greater_equal)
-
Return (x1 >= x2) element-wise.

Unlike

, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.`numpy.greater_equal`
Parameters:
-
**x1, x2**array_like of str or unicode
Input arrays of the same shape.

Returns:
-
**out**ndarray
Output array of bools.

See also# numpy.char.chararray.cumprod[#](#numpy-char-chararray-cumprod)
method

char.chararray.cumprod(*axis=None*,*dtype=None*,*out=None*)[#](#numpy.char.chararray.cumprod)
-
Return the cumulative product of the elements along the given axis.

Refer to

for full documentation.`numpy.cumprod`
See also

`numpy.cumprod`
equivalent function# numpy.ndarray.prod[#](#numpy-ndarray-prod)
method

ndarray.prod(*axis=None*,*dtype=None*,*out=None*,*keepdims=False*,*initial=1*,*where=True*)[#](#numpy.ndarray.prod)
-
Return the product of the array elements over the given axis

Refer to

for full documentation.`numpy.prod`
See also

`numpy.prod`
equivalent functionUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
On this page
poly1d.order
numpy.poly1d.order
#
property
property
poly1d.
order
#
The order or degree of the polynomialUser Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Array objects
The N-dimensional array (
ndarray
)
numpy.ndarray
numpy.ndarray.flags
numpy.ndarray.shape
numpy.ndarray.strides
numpy.ndarray.ndim
numpy.ndarray.data
numpy.ndarray.size
numpy.ndarray.itemsize
numpy.ndarray.nbytes
numpy.ndarray.base
numpy.ndarray.dtype
numpy.ndarray.T
numpy.ndarray.real
numpy.ndarray.imag
numpy.ndarray.flat
numpy.ndarray.ctypes
numpy.ndarray.item
numpy.ndarray.tolist
numpy.ndarray.itemset
numpy.ndarray.tostring
numpy.ndarray.tobytes
numpy.ndarray.tofile
numpy.ndarray.dump
numpy.ndarray.dumps
numpy.ndarray.astype
numpy.ndarray.byteswap
numpy.ndarray.copy
numpy.ndarray.view
numpy.ndarray.getfield
numpy.ndarray.setflags
numpy.ndarray.fill
numpy.ndarray.reshape
numpy.ndarray.resize
numpy.ndarray.transpose
numpy.ndarray.swapaxes
numpy.ndarray.flatten
numpy.ndarray.ravel
numpy.ndarray.squeeze
numpy.ndarray.take
numpy.ndarray.put
numpy.ndarray.repeat
numpy.ndarray.choose
numpy.ndarray.sort
numpy.ndarray.argsort
numpy.ndarray.partition
numpy.ndarray.argpartition
numpy.ndarray.searchsorted
numpy.ndarray.nonzero
numpy.ndarray.compress
numpy.ndarray.diagonal
numpy.ndarray.max
numpy.ndarray.argmax
numpy.ndarray.min
numpy.ndarray.argmin
numpy.ndarray.ptp
numpy.ndarray.clip
numpy.ndarray.conj
numpy.ndarray.round
numpy.ndarray.trace
numpy.ndarray.sum
numpy.ndarray.cumsum
numpy.ndarray.mean
numpy.ndarray.var
numpy.ndarray.std
numpy.ndarray.prod
numpy.ndarray.cumprod
numpy.ndarray.all
numpy.ndarray.any
numpy.ndarray.__lt__
numpy.ndarray.__le__
numpy.ndarray.__gt__
numpy.ndarray.__ge__
numpy.ndarray.__eq__
numpy.ndarray.__ne__
numpy.ndarray.__bool__
numpy.ndarray.__neg__
numpy.ndarray.__pos__
numpy.ndarray.__abs__
numpy.ndarray.__invert__
numpy.ndarray.__add__
numpy.ndarray.__sub__
numpy.ndarray.__mul__
numpy.ndarray.__truediv__
numpy.ndarray.__floordiv__
numpy.ndarray.__mod__
numpy.ndarray.__divmod__
numpy.ndarray.__pow__
numpy.ndarray.__lshift__
numpy.ndarray.__rshift__
numpy.ndarray.__and__
numpy.ndarray.__or__
numpy.ndarray.__xor__
numpy.ndarray.__iadd__
numpy.ndarray.__isub__
numpy.ndarray.__imul__
numpy.ndarray.__itruediv__
numpy.ndarray.__ifloordiv__
numpy.ndarray.__imod__
numpy.ndarray.__ipow__
numpy.ndarray.__ilshift__
numpy.ndarray.__irshift__
numpy.ndarray.__iand__
numpy.ndarray.__ior__
numpy.ndarray.__ixor__
numpy.ndarray.__matmul__
numpy.ndarray.__copy__
numpy.ndarray.__deepcopy__
numpy.ndarray.__reduce__
numpy.ndarray.__setstate__
numpy.ndarray.__new__
numpy.ndarray.__array__
numpy.ndarray.__array_wrap__
numpy.ndarray.__len__
numpy.ndarray.__getitem__
numpy.ndarray.__setitem__
numpy.ndarray.__contains__
numpy.ndarray.__int__
numpy.ndarray.__float__
numpy.ndarray.__complex__
numpy.ndarray.__str__
numpy.ndarray.__repr__
numpy.ndarray.__class_getitem__
Scalars
Data type objects (
dtype
)
Indexing routines
Iterating over arrays
Standard array subclasses
Masked arrays
The array interface protocol
Datetimes and Timedeltas
Array API Standard Compatibility
Constants
Universal functions (
ufunc
)
Routines
Typing (
numpy.typing
)
Global state
Packaging (
numpy.distutils
)
NumPy distutils - users guide
Status of
numpy.distutils
and migration advice
NumPy C-API
CPU/SIMD Optimizations
NumPy security
NumPy and SWIG
On this page
ndarray.__lt__
numpy.ndarray.__lt__
#
method
ndarray.
__lt__
(
value
,
/
)
#
Return self<value.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
NumPy C code explanations
#
This document has been moved to
NumPy C code explanations
.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
NumPy internals
#
This document has been moved to
Internal organization of NumPy arrays
.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Poly1d[#](#poly1d)
## Basics[#](#basics)
|
A one-dimensional polynomial class.

|
|
Evaluate a polynomial at specific values.

|
|
Find the coefficients of a polynomial with the given sequence of roots.

|
|
Return the roots of a polynomial with coefficients given in p.

|
## Fitting[#](#fitting)
|
Least squares polynomial fit.

|
## Calculus[#](#calculus)
|
Return the derivative of the specified order of a polynomial.

|
|
Return an antiderivative (indefinite integral) of a polynomial.

|
## Arithmetic[#](#arithmetic)
|
Find the sum of two polynomials.

|
|
Returns the quotient and remainder of polynomial division.

|
|
Find the product of two polynomials.

|
|
Difference (subtraction) of two polynomials.

|
## Warnings[#](#warnings)
Issued by

|Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.NumPy 1.xx.x Release Notes# Highlights# New functions# Deprecations# Future Changes# Expired deprecations# Compatibility notes# C API changes# New Features# Improvements# Changes#Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.User Guide
API reference
Development
Release notes
Learn
1.26
GitHub
Twitter
Installing NumPy
#
See
Installing NumPy
.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.# Extending `numpy.random`
via Cython[#](#extending-numpy-random-via-cython)
`numpy.random`
Starting with NumPy 1.26.0, Meson is the default build system for NumPy.
See [Status of numpy.distutils and migration advice](../../../distutils_status_migration.html#distutils-status-migration).

`numpy.random`
Starting with NumPy 1.26.0, Meson is the default build system for NumPy.
See [Status of numpy.distutils and migration advice](../../../distutils_status_migration.html#distutils-status-migration).Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words."""
Use cffi to access any of the underlying C functions from distributions.h
"""
import os
import numpy as np
import cffi
from .parse import parse_distributions_h
ffi = cffi.FFI()
inc_dir = os.path.join(np.get_include(), 'numpy')
# Basic numpy types
ffi.cdef('''
typedef intptr_t npy_intp;
typedef unsigned char npy_bool;
''')
parse_distributions_h(ffi, inc_dir)
lib = ffi.dlopen(np.random._generator.__file__)
# Compare the distributions.h random_standard_normal_fill to
# Generator.standard_random
bit_gen = np.random.PCG64()
rng = np.random.Generator(bit_gen)
state = bit_gen.state
interface = rng.bit_generator.cffi
n = 100
vals_cffi = ffi.new('double[%d]' % n)
lib.random_standard_normal_fill(interface.bit_generator, n, vals_cffi)
# reset the state
bit_gen.state = state
vals = rng.standard_normal(n)
for i in range(n):
assert vals[i] == vals_cffi[i]Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.#!/usr/bin/env python3
#cython: language_level=3
"""
This file shows how the to use a BitGenerator to create a distribution.
"""
import numpy as np
cimport numpy as np
cimport cython
from cpython.pycapsule cimport PyCapsule_IsValid, PyCapsule_GetPointer
from libc.stdint cimport uint16_t, uint64_t
from numpy.random cimport bitgen_t
from numpy.random import PCG64
from numpy.random.c_distributions cimport (
random_standard_uniform_fill, random_standard_uniform_fill_f)
@cython.boundscheck(False)
@cython.wraparound(False)
def uniforms(Py_ssize_t n):
"""
Create an array of `n` uniformly distributed doubles.
A 'real' distribution would want to process the values into
some non-uniform distribution
"""
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef const char *capsule_name = "BitGenerator"
cdef double[::1] random_values
x = PCG64()
capsule = x.capsule
# Optional check that the capsule if from a BitGenerator
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
# Cast the pointer
rng = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)
random_values = np.empty(n, dtype='float64')
with x.lock, nogil:
for i in range(n):
# Call the function
random_values[i] = rng.next_double(rng.state)
randoms = np.asarray(random_values)
return randoms
# cython example 2
@cython.boundscheck(False)
@cython.wraparound(False)
def uint10_uniforms(Py_ssize_t n):
"""Uniform 10 bit integers stored as 16-bit unsigned integers"""
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef const char *capsule_name = "BitGenerator"
cdef uint16_t[::1] random_values
cdef int bits_remaining
cdef int width = 10
cdef uint64_t buff, mask = 0x3FF
x = PCG64()
capsule = x.capsule
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
rng = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)
random_values = np.empty(n, dtype='uint16')
# Best practice is to release GIL and acquire the lock
bits_remaining = 0
with x.lock, nogil:
for i in range(n):
if bits_remaining < width:
buff = rng.next_uint64(rng.state)
random_values[i] = buff & mask
buff >>= width
randoms = np.asarray(random_values)
return randoms
# cython example 3
def uniforms_ex(bit_generator, Py_ssize_t n, dtype=np.float64):
"""
Create an array of `n` uniformly distributed doubles via a "fill" function.
A 'real' distribution would want to process the values into
some non-uniform distribution
Parameters
----------
bit_generator: BitGenerator instance
n: int
Output vector length
dtype: {str, dtype}, optional
Desired dtype, either 'd' (or 'float64') or 'f' (or 'float32'). The
default dtype value is 'd'
"""
cdef Py_ssize_t i
cdef bitgen_t *rng
cdef const char *capsule_name = "BitGenerator"
cdef np.ndarray randoms
capsule = bit_generator.capsule
# Optional check that the capsule if from a BitGenerator
if not PyCapsule_IsValid(capsule, capsule_name):
raise ValueError("Invalid pointer to anon_func_state")
# Cast the pointer
rng = <bitgen_t *> PyCapsule_GetPointer(capsule, capsule_name)
_dtype = np.dtype(dtype)
randoms = np.empty(n, dtype=_dtype)
if _dtype == np.float32:
with bit_generator.lock:
random_standard_uniform_fill_f(rng, n, <float*>np.PyArray_DATA(randoms))
elif _dtype == np.float64:
with bit_generator.lock:
random_standard_uniform_fill(rng, n, <double*>np.PyArray_DATA(randoms))
else:
raise TypeError('Unsupported dtype %r for random' % _dtype)
return randomsSearch Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.project('random-build-examples', 'c', 'cpp', 'cython')
py_mod = import('python')
py3 = py_mod.find_installation(pure: false)
cc = meson.get_compiler('c')
cy = meson.get_compiler('cython')
if not cy.version().version_compare('>=0.29.35')
error('tests requires Cython >= 0.29.35')
endif
_numpy_abs = run_command(py3, ['-c',
'import os; os.chdir(".."); import numpy; print(os.path.abspath(numpy.get_include() + "../../.."))'],
check: true).stdout().strip()
npymath_path = _numpy_abs / 'core' / 'lib'
npy_include_path = _numpy_abs / 'core' / 'include'
npyrandom_path = _numpy_abs / 'random' / 'lib'
npymath_lib = cc.find_library('npymath', dirs: npymath_path)
npyrandom_lib = cc.find_library('npyrandom', dirs: npyrandom_path)
py3.extension_module(
'extending_distributions',
'extending_distributions.pyx',
install: false,
include_directories: [npy_include_path],
dependencies: [npyrandom_lib, npymath_lib],
)
py3.extension_module(
'extending',
'extending.pyx',
install: false,
include_directories: [npy_include_path],
dependencies: [npyrandom_lib, npymath_lib],
)
py3.extension_module(
'extending_cpp',
'extending_distributions.pyx',
install: false,
override_options : ['cython_language=cpp'],
cython_args: ['--module-name', 'extending_cpp'],
include_directories: [npy_include_path],
dependencies: [npyrandom_lib, npymath_lib],
)Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.Search Please activate JavaScript to enable the search functionality. Searching for multiple words only shows matches that contain all words.